INFO:root:Output: std_22
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12227.752722537878
INFO:root:current train perplexity16562.955078125
INFO:root:current mean train loss 10541.292657133323
INFO:root:current train perplexity4102.923828125
INFO:root:current mean train loss 9171.569019126255
INFO:root:current train perplexity1381.8681640625
INFO:root:current mean train loss 8224.615262521538
INFO:root:current train perplexity654.1701049804688
INFO:root:current mean train loss 7532.598146488289
INFO:root:current train perplexity379.7992858886719
INFO:root:current mean train loss 7007.46242639099
INFO:root:current train perplexity250.9649658203125
INFO:root:current mean train loss 6598.694404743942
INFO:root:current train perplexity181.23158264160156
INFO:root:current mean train loss 6273.777345583347
INFO:root:current train perplexity139.81265258789062
INFO:root:current mean train loss 5997.471610437378
INFO:root:current train perplexity113.00324249267578
INFO:root:current mean train loss 5773.973581980418
INFO:root:current train perplexity94.2514877319336
INFO:root:current mean train loss 5575.1821800002845
INFO:root:current train perplexity80.76396942138672
INFO:root:current mean train loss 5406.057870694654
INFO:root:current train perplexity70.72246551513672
INFO:root:current mean train loss 5259.834614930656
INFO:root:current train perplexity62.847808837890625
INFO:root:current mean train loss 5124.41180188695
INFO:root:current train perplexity56.62760925292969
INFO:root:current mean train loss 5005.973272057674
INFO:root:current train perplexity51.65190887451172
INFO:root:current mean train loss 4899.597104605173
INFO:root:current train perplexity47.52216720581055
INFO:root:current mean train loss 4804.346371745558
INFO:root:current train perplexity44.052391052246094
INFO:root:current mean train loss 4716.114622598492
INFO:root:current train perplexity41.13876724243164
INFO:root:current mean train loss 4633.673391268842
INFO:root:current train perplexity38.60893249511719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it]
INFO:root:final mean train loss: 4569.587158634034
INFO:root:final train perplexity: 36.73944854736328
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 3475.863770264405
INFO:root:eval perplexity: 17.32585334777832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/1
  1%|          | 1/100 [05:17<8:44:24, 317.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3097.567581176758
INFO:root:current train perplexity11.423506736755371
INFO:root:current mean train loss 3098.883294467268
INFO:root:current train perplexity11.540848731994629
INFO:root:current mean train loss 3079.30911593967
INFO:root:current train perplexity11.462326049804688
INFO:root:current mean train loss 3077.821107502225
INFO:root:current train perplexity11.44040298461914
INFO:root:current mean train loss 3071.7529995258037
INFO:root:current train perplexity11.35373592376709
INFO:root:current mean train loss 3062.2971087315286
INFO:root:current train perplexity11.21893310546875
INFO:root:current mean train loss 3044.340589250837
INFO:root:current train perplexity11.088083267211914
INFO:root:current mean train loss 3033.2224189289454
INFO:root:current train perplexity10.9854154586792
INFO:root:current mean train loss 3024.5737971885533
INFO:root:current train perplexity10.90970230102539
INFO:root:current mean train loss 3018.822353846121
INFO:root:current train perplexity10.835171699523926
INFO:root:current mean train loss 3006.2788170041063
INFO:root:current train perplexity10.74868106842041
INFO:root:current mean train loss 2997.8500495281696
INFO:root:current train perplexity10.656140327453613
INFO:root:current mean train loss 2991.0858355070413
INFO:root:current train perplexity10.58386516571045
INFO:root:current mean train loss 2982.3002512273815
INFO:root:current train perplexity10.502992630004883
INFO:root:current mean train loss 2973.489954544326
INFO:root:current train perplexity10.432807922363281
INFO:root:current mean train loss 2965.86403541263
INFO:root:current train perplexity10.363417625427246
INFO:root:current mean train loss 2957.076947656008
INFO:root:current train perplexity10.294320106506348
INFO:root:current mean train loss 2949.9557678649476
INFO:root:current train perplexity10.234556198120117
INFO:root:current mean train loss 2940.155396045567
INFO:root:current train perplexity10.166808128356934
INFO:root:current mean train loss 2932.523408575197
INFO:root:current train perplexity10.098896026611328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it]
INFO:root:final mean train loss: 2926.9688266402113
INFO:root:final train perplexity: 10.058154106140137
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it]
INFO:root:eval mean loss: 3233.0353102125564
INFO:root:eval perplexity: 14.195734024047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/2
  2%|â–         | 2/100 [10:35<8:39:15, 317.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2809.978937322443
INFO:root:current train perplexity9.146526336669922
INFO:root:current mean train loss 2759.30506931391
INFO:root:current train perplexity8.886682510375977
INFO:root:current mean train loss 2757.5206073548147
INFO:root:current train perplexity8.853759765625
INFO:root:current mean train loss 2745.113181540916
INFO:root:current train perplexity8.78170108795166
INFO:root:current mean train loss 2747.418140155889
INFO:root:current train perplexity8.745595932006836
INFO:root:current mean train loss 2743.2195373878694
INFO:root:current train perplexity8.701393127441406
INFO:root:current mean train loss 2739.111161122013
INFO:root:current train perplexity8.663273811340332
INFO:root:current mean train loss 2733.3378616478726
INFO:root:current train perplexity8.62791633605957
INFO:root:current mean train loss 2729.162033758816
INFO:root:current train perplexity8.598891258239746
INFO:root:current mean train loss 2722.947926086884
INFO:root:current train perplexity8.566226959228516
INFO:root:current mean train loss 2718.266799143877
INFO:root:current train perplexity8.53543472290039
INFO:root:current mean train loss 2713.3054841353846
INFO:root:current train perplexity8.511512756347656
INFO:root:current mean train loss 2708.0462823699186
INFO:root:current train perplexity8.480445861816406
INFO:root:current mean train loss 2701.7403169762165
INFO:root:current train perplexity8.442328453063965
INFO:root:current mean train loss 2700.8323551239205
INFO:root:current train perplexity8.425342559814453
INFO:root:current mean train loss 2699.5304549902153
INFO:root:current train perplexity8.400843620300293
INFO:root:current mean train loss 2695.3685177898233
INFO:root:current train perplexity8.373382568359375
INFO:root:current mean train loss 2691.9802813829883
INFO:root:current train perplexity8.34560775756836
INFO:root:current mean train loss 2687.766528306993
INFO:root:current train perplexity8.313562393188477
INFO:root:current mean train loss 2683.07137772609
INFO:root:current train perplexity8.287787437438965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.94s/it]
INFO:root:final mean train loss: 2679.2383007640137
INFO:root:final train perplexity: 8.273093223571777
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.11s/it]
INFO:root:eval mean loss: 3115.742697042746
INFO:root:eval perplexity: 12.893125534057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/3
  3%|â–Ž         | 3/100 [16:02<8:40:27, 321.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2605.7696142578125
INFO:root:current train perplexity7.761980056762695
INFO:root:current mean train loss 2593.080068359375
INFO:root:current train perplexity7.722555637359619
INFO:root:current mean train loss 2585.4394912109374
INFO:root:current train perplexity7.694823741912842
INFO:root:current mean train loss 2579.165982142857
INFO:root:current train perplexity7.644892692565918
INFO:root:current mean train loss 2583.861095377604
INFO:root:current train perplexity7.640408515930176
INFO:root:current mean train loss 2576.3731884765625
INFO:root:current train perplexity7.603872776031494
INFO:root:current mean train loss 2572.4677092097354
INFO:root:current train perplexity7.587246417999268
INFO:root:current mean train loss 2569.6633587239585
INFO:root:current train perplexity7.5735182762146
INFO:root:current mean train loss 2567.5837278837316
INFO:root:current train perplexity7.5706353187561035
INFO:root:current mean train loss 2564.8153387129933
INFO:root:current train perplexity7.551830768585205
INFO:root:current mean train loss 2561.221704799107
INFO:root:current train perplexity7.532051086425781
INFO:root:current mean train loss 2560.600623938519
INFO:root:current train perplexity7.524026870727539
INFO:root:current mean train loss 2557.4683234375
INFO:root:current train perplexity7.510293006896973
INFO:root:current mean train loss 2555.165814163773
INFO:root:current train perplexity7.49542236328125
INFO:root:current mean train loss 2554.5313365436423
INFO:root:current train perplexity7.489696979522705
INFO:root:current mean train loss 2551.8177924962197
INFO:root:current train perplexity7.476642608642578
INFO:root:current mean train loss 2550.4099745501894
INFO:root:current train perplexity7.466271877288818
INFO:root:current mean train loss 2547.747054827009
INFO:root:current train perplexity7.449738502502441
INFO:root:current mean train loss 2546.462203995988
INFO:root:current train perplexity7.442113876342773
INFO:root:current mean train loss 2544.279519856771
INFO:root:current train perplexity7.431966304779053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.42s/it]
INFO:root:final mean train loss: 2542.742380547151
INFO:root:final train perplexity: 7.428765296936035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.65s/it]
INFO:root:eval mean loss: 3047.3390636730483
INFO:root:eval perplexity: 12.18936824798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/4
  4%|â–         | 4/100 [21:24<8:34:51, 321.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2521.4802901993935
INFO:root:current train perplexity7.154886722564697
INFO:root:current mean train loss 2484.8374812874254
INFO:root:current train perplexity7.064945697784424
INFO:root:current mean train loss 2481.738928634129
INFO:root:current train perplexity7.069270133972168
INFO:root:current mean train loss 2481.919389023118
INFO:root:current train perplexity7.077648639678955
INFO:root:current mean train loss 2482.9555193555943
INFO:root:current train perplexity7.088857173919678
INFO:root:current mean train loss 2478.2487814497904
INFO:root:current train perplexity7.056693077087402
INFO:root:current mean train loss 2479.108881960387
INFO:root:current train perplexity7.053820610046387
INFO:root:current mean train loss 2475.936241100167
INFO:root:current train perplexity7.038386344909668
INFO:root:current mean train loss 2476.1123977537936
INFO:root:current train perplexity7.0271406173706055
INFO:root:current mean train loss 2472.539279752335
INFO:root:current train perplexity7.011425495147705
INFO:root:current mean train loss 2472.0133594344907
INFO:root:current train perplexity7.006979942321777
INFO:root:current mean train loss 2470.984089960067
INFO:root:current train perplexity6.997527599334717
INFO:root:current mean train loss 2468.086723779258
INFO:root:current train perplexity6.986767768859863
INFO:root:current mean train loss 2467.8564798708107
INFO:root:current train perplexity6.982919216156006
INFO:root:current mean train loss 2465.5567517114805
INFO:root:current train perplexity6.979219913482666
INFO:root:current mean train loss 2463.3272077198917
INFO:root:current train perplexity6.974562168121338
INFO:root:current mean train loss 2459.7525310367614
INFO:root:current train perplexity6.958776950836182
INFO:root:current mean train loss 2458.4346753883037
INFO:root:current train perplexity6.947856426239014
INFO:root:current mean train loss 2456.460015924716
INFO:root:current train perplexity6.937806129455566
INFO:root:current mean train loss 2454.5705984064207
INFO:root:current train perplexity6.925559043884277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.39s/it]
INFO:root:final mean train loss: 2453.5529507527854
INFO:root:final train perplexity: 6.9241790771484375
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it]
INFO:root:eval mean loss: 3011.625826265719
INFO:root:eval perplexity: 11.837336540222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/5
  5%|â–Œ         | 5/100 [26:40<8:26:09, 319.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2413.635750906808
INFO:root:current train perplexity6.649799346923828
INFO:root:current mean train loss 2409.7296341605806
INFO:root:current train perplexity6.672112941741943
INFO:root:current mean train loss 2407.280269569075
INFO:root:current train perplexity6.692434787750244
INFO:root:current mean train loss 2408.185530980428
INFO:root:current train perplexity6.693811893463135
INFO:root:current mean train loss 2413.807021968621
INFO:root:current train perplexity6.704865455627441
INFO:root:current mean train loss 2406.949161059236
INFO:root:current train perplexity6.6692328453063965
INFO:root:current mean train loss 2405.243373223913
INFO:root:current train perplexity6.649504661560059
INFO:root:current mean train loss 2405.049081452039
INFO:root:current train perplexity6.654762268066406
INFO:root:current mean train loss 2403.4205819384547
INFO:root:current train perplexity6.643089294433594
INFO:root:current mean train loss 2399.0822994573327
INFO:root:current train perplexity6.624441146850586
INFO:root:current mean train loss 2398.2782506062977
INFO:root:current train perplexity6.623457908630371
INFO:root:current mean train loss 2396.809003572206
INFO:root:current train perplexity6.616937637329102
INFO:root:current mean train loss 2395.3603861681027
INFO:root:current train perplexity6.61027193069458
INFO:root:current mean train loss 2395.2374502193034
INFO:root:current train perplexity6.606468677520752
INFO:root:current mean train loss 2395.6352806399773
INFO:root:current train perplexity6.608501434326172
INFO:root:current mean train loss 2394.8385249436506
INFO:root:current train perplexity6.600113868713379
INFO:root:current mean train loss 2394.126962765945
INFO:root:current train perplexity6.595108985900879
INFO:root:current mean train loss 2390.9494749334362
INFO:root:current train perplexity6.588194847106934
INFO:root:current mean train loss 2390.40966427554
INFO:root:current train perplexity6.581803798675537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.67s/it]
INFO:root:final mean train loss: 2388.0078807682685
INFO:root:final train perplexity: 6.575342178344727
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 2974.89599316113
INFO:root:eval perplexity: 11.485888481140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/6
  6%|â–Œ         | 6/100 [31:55<8:18:25, 318.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2454.8388671875
INFO:root:current train perplexity6.048045635223389
INFO:root:current mean train loss 2331.012215491569
INFO:root:current train perplexity6.304272174835205
INFO:root:current mean train loss 2341.5290278344605
INFO:root:current train perplexity6.355243682861328
INFO:root:current mean train loss 2350.4337356922238
INFO:root:current train perplexity6.368074417114258
INFO:root:current mean train loss 2347.0416941654653
INFO:root:current train perplexity6.362461090087891
INFO:root:current mean train loss 2344.1203028513287
INFO:root:current train perplexity6.362064838409424
INFO:root:current mean train loss 2341.3773173048176
INFO:root:current train perplexity6.352578163146973
INFO:root:current mean train loss 2343.76105145551
INFO:root:current train perplexity6.356422424316406
INFO:root:current mean train loss 2344.0911621398545
INFO:root:current train perplexity6.355987071990967
INFO:root:current mean train loss 2343.4090914879735
INFO:root:current train perplexity6.349523067474365
INFO:root:current mean train loss 2340.6333287074253
INFO:root:current train perplexity6.339951515197754
INFO:root:current mean train loss 2339.5114104143604
INFO:root:current train perplexity6.331636905670166
INFO:root:current mean train loss 2339.4677832966345
INFO:root:current train perplexity6.330002784729004
INFO:root:current mean train loss 2339.3209729557493
INFO:root:current train perplexity6.330437660217285
INFO:root:current mean train loss 2338.9399055083422
INFO:root:current train perplexity6.329226493835449
INFO:root:current mean train loss 2339.4104786262283
INFO:root:current train perplexity6.325822353363037
INFO:root:current mean train loss 2338.2554209588247
INFO:root:current train perplexity6.320190906524658
INFO:root:current mean train loss 2338.267619460979
INFO:root:current train perplexity6.321136474609375
INFO:root:current mean train loss 2338.131791609913
INFO:root:current train perplexity6.317399501800537
INFO:root:current mean train loss 2337.916421198958
INFO:root:current train perplexity6.316163539886475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.02s/it]
INFO:root:final mean train loss: 2336.557581114276
INFO:root:final train perplexity: 6.313877105712891
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it]
INFO:root:eval mean loss: 2950.931786522851
INFO:root:eval perplexity: 11.262232780456543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/7
  7%|â–‹         | 7/100 [37:10<8:11:40, 317.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2296.345499674479
INFO:root:current train perplexity6.100094795227051
INFO:root:current mean train loss 2287.708660578324
INFO:root:current train perplexity6.147346496582031
INFO:root:current mean train loss 2304.2674689336654
INFO:root:current train perplexity6.193329811096191
INFO:root:current mean train loss 2307.199926604265
INFO:root:current train perplexity6.19014310836792
INFO:root:current mean train loss 2306.2358199854216
INFO:root:current train perplexity6.164655685424805
INFO:root:current mean train loss 2306.059797485823
INFO:root:current train perplexity6.160688400268555
INFO:root:current mean train loss 2305.0274259203075
INFO:root:current train perplexity6.150298118591309
INFO:root:current mean train loss 2306.097316561303
INFO:root:current train perplexity6.1540961265563965
INFO:root:current mean train loss 2304.8046731738996
INFO:root:current train perplexity6.14332389831543
INFO:root:current mean train loss 2303.4733381416804
INFO:root:current train perplexity6.140429496765137
INFO:root:current mean train loss 2300.8729016616912
INFO:root:current train perplexity6.1323323249816895
INFO:root:current mean train loss 2301.233246450134
INFO:root:current train perplexity6.127074241638184
INFO:root:current mean train loss 2301.0631923331025
INFO:root:current train perplexity6.123513698577881
INFO:root:current mean train loss 2301.629209202953
INFO:root:current train perplexity6.129879951477051
INFO:root:current mean train loss 2301.7798534226517
INFO:root:current train perplexity6.127268314361572
INFO:root:current mean train loss 2302.0036380652227
INFO:root:current train perplexity6.124232769012451
INFO:root:current mean train loss 2300.1160613296943
INFO:root:current train perplexity6.118234634399414
INFO:root:current mean train loss 2298.1569729717285
INFO:root:current train perplexity6.110855579376221
INFO:root:current mean train loss 2297.1274145480957
INFO:root:current train perplexity6.110224723815918
INFO:root:current mean train loss 2294.989615367774
INFO:root:current train perplexity6.107107639312744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.88s/it]
INFO:root:final mean train loss: 2294.497888762243
INFO:root:final train perplexity: 6.107876300811768
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it]
INFO:root:eval mean loss: 2929.410939992727
INFO:root:eval perplexity: 11.065093994140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/8
  8%|â–Š         | 8/100 [42:28<8:06:55, 317.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2263.8260986328123
INFO:root:current train perplexity5.9325690269470215
INFO:root:current mean train loss 2270.324072265625
INFO:root:current train perplexity5.944823265075684
INFO:root:current mean train loss 2262.8664867644616
INFO:root:current train perplexity5.9516425132751465
INFO:root:current mean train loss 2263.9532846023785
INFO:root:current train perplexity5.96222448348999
INFO:root:current mean train loss 2261.5032883216595
INFO:root:current train perplexity5.968505382537842
INFO:root:current mean train loss 2260.1868577048044
INFO:root:current train perplexity5.954997539520264
INFO:root:current mean train loss 2263.2800181471457
INFO:root:current train perplexity5.952881336212158
INFO:root:current mean train loss 2265.5589365433675
INFO:root:current train perplexity5.9566755294799805
INFO:root:current mean train loss 2266.3111687757296
INFO:root:current train perplexity5.962223052978516
INFO:root:current mean train loss 2268.381304050384
INFO:root:current train perplexity5.96675968170166
INFO:root:current mean train loss 2267.160572114659
INFO:root:current train perplexity5.966274261474609
INFO:root:current mean train loss 2264.1287666488847
INFO:root:current train perplexity5.957808017730713
INFO:root:current mean train loss 2262.1713143661436
INFO:root:current train perplexity5.95375919342041
INFO:root:current mean train loss 2263.005331775222
INFO:root:current train perplexity5.956005096435547
INFO:root:current mean train loss 2262.4465554054605
INFO:root:current train perplexity5.953822135925293
INFO:root:current mean train loss 2263.078690022521
INFO:root:current train perplexity5.952095031738281
INFO:root:current mean train loss 2262.138872936377
INFO:root:current train perplexity5.950502872467041
INFO:root:current mean train loss 2260.8559813045977
INFO:root:current train perplexity5.945699691772461
INFO:root:current mean train loss 2259.4729025193715
INFO:root:current train perplexity5.9404215812683105
INFO:root:current mean train loss 2259.5831062888606
INFO:root:current train perplexity5.940479278564453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.58s/it]
INFO:root:final mean train loss: 2259.797415852126
INFO:root:final train perplexity: 5.94298791885376
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it]
INFO:root:eval mean loss: 2913.8081729190126
INFO:root:eval perplexity: 10.92432689666748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/9
  9%|â–‰         | 9/100 [47:43<8:00:20, 316.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2211.2909381573018
INFO:root:current train perplexity5.76042366027832
INFO:root:current mean train loss 2222.48963606985
INFO:root:current train perplexity5.734339714050293
INFO:root:current mean train loss 2233.065209767175
INFO:root:current train perplexity5.787923812866211
INFO:root:current mean train loss 2229.218520077792
INFO:root:current train perplexity5.798768043518066
INFO:root:current mean train loss 2235.478004928184
INFO:root:current train perplexity5.81483268737793
INFO:root:current mean train loss 2237.514279794002
INFO:root:current train perplexity5.821941375732422
INFO:root:current mean train loss 2240.174808431988
INFO:root:current train perplexity5.82899284362793
INFO:root:current mean train loss 2236.68591357292
INFO:root:current train perplexity5.819606781005859
INFO:root:current mean train loss 2236.231766248533
INFO:root:current train perplexity5.821775436401367
INFO:root:current mean train loss 2233.0894427900553
INFO:root:current train perplexity5.814966201782227
INFO:root:current mean train loss 2234.417772300343
INFO:root:current train perplexity5.819266319274902
INFO:root:current mean train loss 2234.1093995836045
INFO:root:current train perplexity5.813263893127441
INFO:root:current mean train loss 2233.6219977723144
INFO:root:current train perplexity5.812517166137695
INFO:root:current mean train loss 2234.231646204841
INFO:root:current train perplexity5.818589210510254
INFO:root:current mean train loss 2233.0639502154895
INFO:root:current train perplexity5.814779758453369
INFO:root:current mean train loss 2230.6007469413207
INFO:root:current train perplexity5.807492733001709
INFO:root:current mean train loss 2230.450402285227
INFO:root:current train perplexity5.803606033325195
INFO:root:current mean train loss 2231.926967046032
INFO:root:current train perplexity5.807225704193115
INFO:root:current mean train loss 2230.2390898669514
INFO:root:current train perplexity5.802641868591309
INFO:root:current mean train loss 2230.355972102431
INFO:root:current train perplexity5.802850246429443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.31s/it]
INFO:root:final mean train loss: 2229.4979434568836
INFO:root:final train perplexity: 5.802659034729004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it]
INFO:root:eval mean loss: 2904.2481055274025
INFO:root:eval perplexity: 10.838967323303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/10
 10%|â–ˆ         | 10/100 [52:59<7:54:38, 316.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2219.14477362149
INFO:root:current train perplexity5.698984622955322
INFO:root:current mean train loss 2221.9585661577753
INFO:root:current train perplexity5.6898627281188965
INFO:root:current mean train loss 2204.425189957743
INFO:root:current train perplexity5.655099391937256
INFO:root:current mean train loss 2203.2170148813307
INFO:root:current train perplexity5.659215450286865
INFO:root:current mean train loss 2203.8723417822994
INFO:root:current train perplexity5.658977508544922
INFO:root:current mean train loss 2207.6924156363275
INFO:root:current train perplexity5.672004222869873
INFO:root:current mean train loss 2203.410554940034
INFO:root:current train perplexity5.663489818572998
INFO:root:current mean train loss 2205.2245892151436
INFO:root:current train perplexity5.676702976226807
INFO:root:current mean train loss 2206.6864586798315
INFO:root:current train perplexity5.673140525817871
INFO:root:current mean train loss 2205.961533868276
INFO:root:current train perplexity5.675294876098633
INFO:root:current mean train loss 2204.548710165568
INFO:root:current train perplexity5.677281856536865
INFO:root:current mean train loss 2204.4536626732583
INFO:root:current train perplexity5.677365779876709
INFO:root:current mean train loss 2203.7173888534894
INFO:root:current train perplexity5.673682689666748
INFO:root:current mean train loss 2204.361140784075
INFO:root:current train perplexity5.676549911499023
INFO:root:current mean train loss 2205.09847833414
INFO:root:current train perplexity5.677834987640381
INFO:root:current mean train loss 2203.638918505268
INFO:root:current train perplexity5.676246643066406
INFO:root:current mean train loss 2203.0357500719697
INFO:root:current train perplexity5.676360130310059
INFO:root:current mean train loss 2201.871379155773
INFO:root:current train perplexity5.674933433532715
INFO:root:current mean train loss 2201.1364878679483
INFO:root:current train perplexity5.674707412719727
INFO:root:current mean train loss 2202.7567093414723
INFO:root:current train perplexity5.6794114112854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.90s/it]
INFO:root:final mean train loss: 2202.3249928161345
INFO:root:final train perplexity: 5.679629802703857
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 2885.6409285261825
INFO:root:eval perplexity: 10.674726486206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/11
 11%|â–ˆ         | 11/100 [58:14<7:48:32, 315.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2209.4724135287975
INFO:root:current train perplexity5.630815029144287
INFO:root:current mean train loss 2177.200938891339
INFO:root:current train perplexity5.565606594085693
INFO:root:current mean train loss 2178.0602348701104
INFO:root:current train perplexity5.5633931159973145
INFO:root:current mean train loss 2187.085689564443
INFO:root:current train perplexity5.591479778289795
INFO:root:current mean train loss 2182.450300303016
INFO:root:current train perplexity5.572640895843506
INFO:root:current mean train loss 2181.8948303847587
INFO:root:current train perplexity5.567214012145996
INFO:root:current mean train loss 2183.1095988548877
INFO:root:current train perplexity5.571667671203613
INFO:root:current mean train loss 2183.182055136023
INFO:root:current train perplexity5.5797319412231445
INFO:root:current mean train loss 2180.6349532771055
INFO:root:current train perplexity5.575442314147949
INFO:root:current mean train loss 2180.7406493645412
INFO:root:current train perplexity5.5793352127075195
INFO:root:current mean train loss 2177.662649474311
INFO:root:current train perplexity5.5718464851379395
INFO:root:current mean train loss 2180.7764844202875
INFO:root:current train perplexity5.577189922332764
INFO:root:current mean train loss 2179.7234806517604
INFO:root:current train perplexity5.576145648956299
INFO:root:current mean train loss 2179.772166154429
INFO:root:current train perplexity5.577253818511963
INFO:root:current mean train loss 2179.546961500699
INFO:root:current train perplexity5.5763349533081055
INFO:root:current mean train loss 2179.218023581583
INFO:root:current train perplexity5.57390832901001
INFO:root:current mean train loss 2179.281916028947
INFO:root:current train perplexity5.573979377746582
INFO:root:current mean train loss 2179.479265133985
INFO:root:current train perplexity5.575801849365234
INFO:root:current mean train loss 2179.520978423975
INFO:root:current train perplexity5.575789928436279

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it]
INFO:root:final mean train loss: 2179.2567222391303
INFO:root:final train perplexity: 5.577233791351318
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.48s/it]
INFO:root:eval mean loss: 2877.7155871692003
INFO:root:eval perplexity: 10.60552978515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/12
 12%|â–ˆâ–        | 12/100 [1:03:29<7:43:10, 315.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.5638020833333
INFO:root:current train perplexity5.085086822509766
INFO:root:current mean train loss 2157.258512922861
INFO:root:current train perplexity5.470850944519043
INFO:root:current mean train loss 2163.835473873345
INFO:root:current train perplexity5.500062465667725
INFO:root:current mean train loss 2158.5770783377166
INFO:root:current train perplexity5.490195274353027
INFO:root:current mean train loss 2153.6542114560716
INFO:root:current train perplexity5.484078884124756
INFO:root:current mean train loss 2157.9447373376925
INFO:root:current train perplexity5.498681545257568
INFO:root:current mean train loss 2155.945058439897
INFO:root:current train perplexity5.496307849884033
INFO:root:current mean train loss 2154.090071741921
INFO:root:current train perplexity5.490440845489502
INFO:root:current mean train loss 2154.028774845793
INFO:root:current train perplexity5.486083984375
INFO:root:current mean train loss 2157.4251279102214
INFO:root:current train perplexity5.491077423095703
INFO:root:current mean train loss 2156.7869107521187
INFO:root:current train perplexity5.487132549285889
INFO:root:current mean train loss 2155.4255698680445
INFO:root:current train perplexity5.482752323150635
INFO:root:current mean train loss 2154.142800855121
INFO:root:current train perplexity5.483922481536865
INFO:root:current mean train loss 2153.1947368115348
INFO:root:current train perplexity5.481398105621338
INFO:root:current mean train loss 2153.3413346957414
INFO:root:current train perplexity5.479960918426514
INFO:root:current mean train loss 2154.062608588162
INFO:root:current train perplexity5.476635456085205
INFO:root:current mean train loss 2156.1448379868802
INFO:root:current train perplexity5.4782938957214355
INFO:root:current mean train loss 2155.1502008891707
INFO:root:current train perplexity5.477093696594238
INFO:root:current mean train loss 2156.3243524654004
INFO:root:current train perplexity5.480238437652588
INFO:root:current mean train loss 2157.224589489663
INFO:root:current train perplexity5.481715202331543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.29s/it]
INFO:root:final mean train loss: 2157.663602966524
INFO:root:final train perplexity: 5.483060359954834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 2876.2786223723724
INFO:root:eval perplexity: 10.593033790588379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/13
 13%|â–ˆâ–Ž        | 13/100 [1:08:45<7:37:50, 315.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2201.190362548828
INFO:root:current train perplexity5.451537609100342
INFO:root:current mean train loss 2140.8972208658856
INFO:root:current train perplexity5.3681640625
INFO:root:current mean train loss 2148.002488014915
INFO:root:current train perplexity5.400186061859131
INFO:root:current mean train loss 2138.6997623443604
INFO:root:current train perplexity5.383954048156738
INFO:root:current mean train loss 2140.9822832380023
INFO:root:current train perplexity5.381040096282959
INFO:root:current mean train loss 2141.3750309870793
INFO:root:current train perplexity5.394923686981201
INFO:root:current mean train loss 2141.3263608870966
INFO:root:current train perplexity5.394359111785889
INFO:root:current mean train loss 2142.023633999295
INFO:root:current train perplexity5.395252704620361
INFO:root:current mean train loss 2142.61714715725
INFO:root:current train perplexity5.397946357727051
INFO:root:current mean train loss 2143.3300050154976
INFO:root:current train perplexity5.399491786956787
INFO:root:current mean train loss 2141.495967610677
INFO:root:current train perplexity5.400537014007568
INFO:root:current mean train loss 2142.1300422668455
INFO:root:current train perplexity5.403528213500977
INFO:root:current mean train loss 2139.9317795049947
INFO:root:current train perplexity5.404595851898193
INFO:root:current mean train loss 2138.973191972212
INFO:root:current train perplexity5.404533386230469
INFO:root:current mean train loss 2138.5146721638425
INFO:root:current train perplexity5.398894786834717
INFO:root:current mean train loss 2137.569587466591
INFO:root:current train perplexity5.3974785804748535
INFO:root:current mean train loss 2137.7260326997734
INFO:root:current train perplexity5.396273136138916
INFO:root:current mean train loss 2137.3698963253996
INFO:root:current train perplexity5.394369125366211
INFO:root:current mean train loss 2137.90435093471
INFO:root:current train perplexity5.397194862365723
INFO:root:current mean train loss 2138.830480893453
INFO:root:current train perplexity5.398137092590332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.36s/it]
INFO:root:final mean train loss: 2137.873590004787
INFO:root:final train perplexity: 5.398147106170654
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it]
INFO:root:eval mean loss: 2863.441992040869
INFO:root:eval perplexity: 10.482039451599121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/14
 14%|â–ˆâ–        | 14/100 [1:14:05<7:34:32, 317.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.0863400021117
INFO:root:current train perplexity5.278717994689941
INFO:root:current mean train loss 2101.266728087933
INFO:root:current train perplexity5.304120063781738
INFO:root:current mean train loss 2114.336215119825
INFO:root:current train perplexity5.317777633666992
INFO:root:current mean train loss 2110.723422721161
INFO:root:current train perplexity5.311675548553467
INFO:root:current mean train loss 2110.0111366114847
INFO:root:current train perplexity5.321595668792725
INFO:root:current mean train loss 2113.0814165793763
INFO:root:current train perplexity5.322831153869629
INFO:root:current mean train loss 2111.9898760210212
INFO:root:current train perplexity5.31162166595459
INFO:root:current mean train loss 2109.667078812701
INFO:root:current train perplexity5.3108415603637695
INFO:root:current mean train loss 2111.191401437192
INFO:root:current train perplexity5.313242435455322
INFO:root:current mean train loss 2112.6806645836114
INFO:root:current train perplexity5.318434715270996
INFO:root:current mean train loss 2113.5424469200143
INFO:root:current train perplexity5.321447849273682
INFO:root:current mean train loss 2116.1657757788453
INFO:root:current train perplexity5.3239006996154785
INFO:root:current mean train loss 2118.211961430123
INFO:root:current train perplexity5.3288140296936035
INFO:root:current mean train loss 2118.1852214759024
INFO:root:current train perplexity5.328083515167236
INFO:root:current mean train loss 2118.6738069729417
INFO:root:current train perplexity5.324390888214111
INFO:root:current mean train loss 2119.8806170610615
INFO:root:current train perplexity5.330564975738525
INFO:root:current mean train loss 2119.9263741522936
INFO:root:current train perplexity5.329414367675781
INFO:root:current mean train loss 2120.5427255932464
INFO:root:current train perplexity5.3256731033325195
INFO:root:current mean train loss 2120.4623425379355
INFO:root:current train perplexity5.323301792144775
INFO:root:current mean train loss 2121.3929506379673
INFO:root:current train perplexity5.324434757232666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.68s/it]
INFO:root:final mean train loss: 2120.203668499137
INFO:root:final train perplexity: 5.323441505432129
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it]
INFO:root:eval mean loss: 2863.3127045502533
INFO:root:eval perplexity: 10.480924606323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/15
 15%|â–ˆâ–Œ        | 15/100 [1:19:20<7:28:23, 316.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2107.77752911603
INFO:root:current train perplexity5.213067531585693
INFO:root:current mean train loss 2102.5522175578326
INFO:root:current train perplexity5.193804740905762
INFO:root:current mean train loss 2098.9098563607286
INFO:root:current train perplexity5.22346830368042
INFO:root:current mean train loss 2095.5908241056454
INFO:root:current train perplexity5.233063697814941
INFO:root:current mean train loss 2096.3246914363644
INFO:root:current train perplexity5.232315540313721
INFO:root:current mean train loss 2095.215644698711
INFO:root:current train perplexity5.232723712921143
INFO:root:current mean train loss 2096.9914379061543
INFO:root:current train perplexity5.232819080352783
INFO:root:current mean train loss 2098.5868269619323
INFO:root:current train perplexity5.240631580352783
INFO:root:current mean train loss 2099.606244482536
INFO:root:current train perplexity5.239549160003662
INFO:root:current mean train loss 2098.1383669551315
INFO:root:current train perplexity5.237757682800293
INFO:root:current mean train loss 2099.0062295236894
INFO:root:current train perplexity5.239099502563477
INFO:root:current mean train loss 2098.4238470596497
INFO:root:current train perplexity5.241078853607178
INFO:root:current mean train loss 2100.270477732973
INFO:root:current train perplexity5.245314121246338
INFO:root:current mean train loss 2102.4917466404518
INFO:root:current train perplexity5.251391887664795
INFO:root:current mean train loss 2101.9714760970546
INFO:root:current train perplexity5.247561931610107
INFO:root:current mean train loss 2102.3987524162694
INFO:root:current train perplexity5.250133037567139
INFO:root:current mean train loss 2101.8529181151753
INFO:root:current train perplexity5.249073028564453
INFO:root:current mean train loss 2101.9107201118427
INFO:root:current train perplexity5.248405456542969
INFO:root:current mean train loss 2101.8475545905812
INFO:root:current train perplexity5.248936176300049
INFO:root:current mean train loss 2103.5009379547964
INFO:root:current train perplexity5.25151252746582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.65s/it]
INFO:root:final mean train loss: 2103.2093706539767
INFO:root:final train perplexity: 5.252569675445557
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it]
INFO:root:eval mean loss: 2853.2753055790167
INFO:root:eval perplexity: 10.394953727722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/16
 16%|â–ˆâ–Œ        | 16/100 [1:24:38<7:23:37, 316.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2103.0830593915052
INFO:root:current train perplexity5.262529373168945
INFO:root:current mean train loss 2081.9340199253015
INFO:root:current train perplexity5.197604179382324
INFO:root:current mean train loss 2079.0568595407635
INFO:root:current train perplexity5.197697162628174
INFO:root:current mean train loss 2080.420858953841
INFO:root:current train perplexity5.190296649932861
INFO:root:current mean train loss 2082.6030620728834
INFO:root:current train perplexity5.188488960266113
INFO:root:current mean train loss 2083.1504692972853
INFO:root:current train perplexity5.18076753616333
INFO:root:current mean train loss 2081.9665068897866
INFO:root:current train perplexity5.178731441497803
INFO:root:current mean train loss 2084.4012618998763
INFO:root:current train perplexity5.178005218505859
INFO:root:current mean train loss 2083.6153442522964
INFO:root:current train perplexity5.180518627166748
INFO:root:current mean train loss 2084.5966772988945
INFO:root:current train perplexity5.179827690124512
INFO:root:current mean train loss 2084.495163006609
INFO:root:current train perplexity5.177234172821045
INFO:root:current mean train loss 2085.5225470434593
INFO:root:current train perplexity5.176929950714111
INFO:root:current mean train loss 2084.5395204317465
INFO:root:current train perplexity5.177280902862549
INFO:root:current mean train loss 2084.9762725941373
INFO:root:current train perplexity5.181521892547607
INFO:root:current mean train loss 2084.8616176581886
INFO:root:current train perplexity5.182574272155762
INFO:root:current mean train loss 2085.821910991705
INFO:root:current train perplexity5.185885906219482
INFO:root:current mean train loss 2085.7424059992845
INFO:root:current train perplexity5.1819376945495605
INFO:root:current mean train loss 2086.934590783919
INFO:root:current train perplexity5.186604022979736
INFO:root:current mean train loss 2086.9166017712787
INFO:root:current train perplexity5.1878485679626465
INFO:root:current mean train loss 2088.4903277702465
INFO:root:current train perplexity5.190499782562256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.09s/it]
INFO:root:final mean train loss: 2088.3700980428366
INFO:root:final train perplexity: 5.191456317901611
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it]
INFO:root:eval mean loss: 2851.429854659347
INFO:root:eval perplexity: 10.379225730895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/17
 17%|â–ˆâ–‹        | 17/100 [1:29:55<7:18:15, 316.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2052.9993743896484
INFO:root:current train perplexity5.067002773284912
INFO:root:current mean train loss 2061.815958225981
INFO:root:current train perplexity5.089420795440674
INFO:root:current mean train loss 2069.7299851311577
INFO:root:current train perplexity5.102569103240967
INFO:root:current mean train loss 2062.6235191109254
INFO:root:current train perplexity5.096538066864014
INFO:root:current mean train loss 2067.0540956591
INFO:root:current train perplexity5.116372108459473
INFO:root:current mean train loss 2069.432297271936
INFO:root:current train perplexity5.11912727355957
INFO:root:current mean train loss 2070.097293587618
INFO:root:current train perplexity5.123283386230469
INFO:root:current mean train loss 2068.5409562938707
INFO:root:current train perplexity5.122891426086426
INFO:root:current mean train loss 2069.483836405986
INFO:root:current train perplexity5.123566627502441
INFO:root:current mean train loss 2073.323107144128
INFO:root:current train perplexity5.127801895141602
INFO:root:current mean train loss 2074.6370833901797
INFO:root:current train perplexity5.126771926879883
INFO:root:current mean train loss 2074.5367427530514
INFO:root:current train perplexity5.122861862182617
INFO:root:current mean train loss 2072.3467790117916
INFO:root:current train perplexity5.120595455169678
INFO:root:current mean train loss 2071.5881689769735
INFO:root:current train perplexity5.118323802947998
INFO:root:current mean train loss 2071.9425783054803
INFO:root:current train perplexity5.1187424659729
INFO:root:current mean train loss 2072.3830208189843
INFO:root:current train perplexity5.123593330383301
INFO:root:current mean train loss 2073.4710501720556
INFO:root:current train perplexity5.12774133682251
INFO:root:current mean train loss 2073.5815662494974
INFO:root:current train perplexity5.130646228790283
INFO:root:current mean train loss 2073.714539414745
INFO:root:current train perplexity5.131712436676025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.81s/it]
INFO:root:final mean train loss: 2073.7173778324254
INFO:root:final train perplexity: 5.131809234619141
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.30s/it]
INFO:root:eval mean loss: 2850.758838183887
INFO:root:eval perplexity: 10.37351131439209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/18
 18%|â–ˆâ–Š        | 18/100 [1:35:11<7:12:55, 316.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2076.370849609375
INFO:root:current train perplexity5.133103847503662
INFO:root:current mean train loss 2056.9173130580357
INFO:root:current train perplexity5.0745415687561035
INFO:root:current mean train loss 2059.600487685785
INFO:root:current train perplexity5.069843769073486
INFO:root:current mean train loss 2063.4034563908813
INFO:root:current train perplexity5.0829176902771
INFO:root:current mean train loss 2059.4482207875194
INFO:root:current train perplexity5.0779194831848145
INFO:root:current mean train loss 2057.2650368869895
INFO:root:current train perplexity5.070580005645752
INFO:root:current mean train loss 2061.766599948347
INFO:root:current train perplexity5.080641269683838
INFO:root:current mean train loss 2061.150626108156
INFO:root:current train perplexity5.083327293395996
INFO:root:current mean train loss 2061.558823484812
INFO:root:current train perplexity5.078988552093506
INFO:root:current mean train loss 2062.731341856224
INFO:root:current train perplexity5.082911014556885
INFO:root:current mean train loss 2064.9275733150653
INFO:root:current train perplexity5.087278366088867
INFO:root:current mean train loss 2063.1628095393808
INFO:root:current train perplexity5.0811004638671875
INFO:root:current mean train loss 2062.444533579973
INFO:root:current train perplexity5.0780134201049805
INFO:root:current mean train loss 2061.4630130694745
INFO:root:current train perplexity5.077060699462891
INFO:root:current mean train loss 2061.0830981705963
INFO:root:current train perplexity5.074949264526367
INFO:root:current mean train loss 2059.680449202528
INFO:root:current train perplexity5.074045181274414
INFO:root:current mean train loss 2058.793911771685
INFO:root:current train perplexity5.072801113128662
INFO:root:current mean train loss 2059.721266939493
INFO:root:current train perplexity5.075088024139404
INFO:root:current mean train loss 2059.0086186374656
INFO:root:current train perplexity5.073464393615723
INFO:root:current mean train loss 2059.4389269731178
INFO:root:current train perplexity5.075260639190674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.45s/it]
INFO:root:final mean train loss: 2060.3194297525056
INFO:root:final train perplexity: 5.077869892120361
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it]
INFO:root:eval mean loss: 2844.7115115603883
INFO:root:eval perplexity: 10.322163581848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/19
 19%|â–ˆâ–‰        | 19/100 [1:40:27<7:07:06, 316.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.9598666104403
INFO:root:current train perplexity4.9357194900512695
INFO:root:current mean train loss 2031.5910634525487
INFO:root:current train perplexity4.943782806396484
INFO:root:current mean train loss 2030.4889625343117
INFO:root:current train perplexity4.9608473777771
INFO:root:current mean train loss 2032.0719028259657
INFO:root:current train perplexity4.965634346008301
INFO:root:current mean train loss 2041.1073657573681
INFO:root:current train perplexity4.9736504554748535
INFO:root:current mean train loss 2042.6385752944655
INFO:root:current train perplexity4.98525333404541
INFO:root:current mean train loss 2042.4794309560891
INFO:root:current train perplexity4.992516994476318
INFO:root:current mean train loss 2041.152179918791
INFO:root:current train perplexity4.996616363525391
INFO:root:current mean train loss 2043.5447399575635
INFO:root:current train perplexity4.997954368591309
INFO:root:current mean train loss 2044.7138924753847
INFO:root:current train perplexity5.000342845916748
INFO:root:current mean train loss 2043.8379671876912
INFO:root:current train perplexity5.003877639770508
INFO:root:current mean train loss 2043.9005132392979
INFO:root:current train perplexity5.006924629211426
INFO:root:current mean train loss 2045.179997670475
INFO:root:current train perplexity5.010948181152344
INFO:root:current mean train loss 2047.3176336937702
INFO:root:current train perplexity5.0182271003723145
INFO:root:current mean train loss 2047.284197543073
INFO:root:current train perplexity5.016664028167725
INFO:root:current mean train loss 2048.0824232865884
INFO:root:current train perplexity5.020015239715576
INFO:root:current mean train loss 2047.8788648574773
INFO:root:current train perplexity5.019691467285156
INFO:root:current mean train loss 2048.1196800878793
INFO:root:current train perplexity5.0240159034729
INFO:root:current mean train loss 2048.716521245326
INFO:root:current train perplexity5.026673793792725
INFO:root:current mean train loss 2049.138704837795
INFO:root:current train perplexity5.028059005737305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.55s/it]
INFO:root:final mean train loss: 2047.2526817918124
INFO:root:final train perplexity: 5.0258097648620605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it]
INFO:root:eval mean loss: 2841.3940165751687
INFO:root:eval perplexity: 10.29410457611084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/20
 20%|â–ˆâ–ˆ        | 20/100 [1:45:41<7:01:10, 315.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.1983673878206
INFO:root:current train perplexity4.9375128746032715
INFO:root:current mean train loss 2047.5322845239434
INFO:root:current train perplexity4.968966960906982
INFO:root:current mean train loss 2042.3503085978361
INFO:root:current train perplexity4.96167516708374
INFO:root:current mean train loss 2041.487427117902
INFO:root:current train perplexity4.963392734527588
INFO:root:current mean train loss 2038.7219357848983
INFO:root:current train perplexity4.962563991546631
INFO:root:current mean train loss 2038.7311085433819
INFO:root:current train perplexity4.970113277435303
INFO:root:current mean train loss 2036.6308941430702
INFO:root:current train perplexity4.974547386169434
INFO:root:current mean train loss 2037.9576204581253
INFO:root:current train perplexity4.975854396820068
INFO:root:current mean train loss 2036.4958955857978
INFO:root:current train perplexity4.976304531097412
INFO:root:current mean train loss 2036.826187865041
INFO:root:current train perplexity4.97476053237915
INFO:root:current mean train loss 2036.0397899873676
INFO:root:current train perplexity4.972818374633789
INFO:root:current mean train loss 2036.953822054708
INFO:root:current train perplexity4.975557327270508
INFO:root:current mean train loss 2035.2832999733594
INFO:root:current train perplexity4.9712114334106445
INFO:root:current mean train loss 2036.6324411838068
INFO:root:current train perplexity4.9743266105651855
INFO:root:current mean train loss 2037.260759068662
INFO:root:current train perplexity4.9791388511657715
INFO:root:current mean train loss 2038.4148500478445
INFO:root:current train perplexity4.983356952667236
INFO:root:current mean train loss 2037.14676173305
INFO:root:current train perplexity4.981146335601807
INFO:root:current mean train loss 2037.4895828887607
INFO:root:current train perplexity4.98343563079834
INFO:root:current mean train loss 2037.3863023568133
INFO:root:current train perplexity4.98219633102417
INFO:root:current mean train loss 2036.5389681300162
INFO:root:current train perplexity4.98165225982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.40s/it]
INFO:root:final mean train loss: 2035.5378576173846
INFO:root:final train perplexity: 4.97959041595459
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 2849.5957199875656
INFO:root:eval perplexity: 10.363617897033691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/21
 21%|â–ˆâ–ˆ        | 21/100 [1:50:59<6:56:23, 316.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1999.909905569894
INFO:root:current train perplexity4.926009654998779
INFO:root:current mean train loss 2008.1350363706931
INFO:root:current train perplexity4.918263912200928
INFO:root:current mean train loss 2012.9838705062866
INFO:root:current train perplexity4.926263332366943
INFO:root:current mean train loss 2018.7260070114994
INFO:root:current train perplexity4.937552452087402
INFO:root:current mean train loss 2019.8496361448053
INFO:root:current train perplexity4.9366583824157715
INFO:root:current mean train loss 2019.7453646213887
INFO:root:current train perplexity4.924210071563721
INFO:root:current mean train loss 2018.0681786886075
INFO:root:current train perplexity4.922330379486084
INFO:root:current mean train loss 2018.804341472646
INFO:root:current train perplexity4.918994426727295
INFO:root:current mean train loss 2019.217763312509
INFO:root:current train perplexity4.921940326690674
INFO:root:current mean train loss 2021.1218737997272
INFO:root:current train perplexity4.923286437988281
INFO:root:current mean train loss 2021.1037631179347
INFO:root:current train perplexity4.924244403839111
INFO:root:current mean train loss 2021.5808547920835
INFO:root:current train perplexity4.924318790435791
INFO:root:current mean train loss 2021.443332939391
INFO:root:current train perplexity4.922374248504639
INFO:root:current mean train loss 2022.4672126882547
INFO:root:current train perplexity4.925981044769287
INFO:root:current mean train loss 2023.1827918251793
INFO:root:current train perplexity4.926217555999756
INFO:root:current mean train loss 2023.657732416854
INFO:root:current train perplexity4.927773475646973
INFO:root:current mean train loss 2024.3218327766456
INFO:root:current train perplexity4.927507400512695
INFO:root:current mean train loss 2024.4968933244502
INFO:root:current train perplexity4.9291558265686035
INFO:root:current mean train loss 2025.0887530096645
INFO:root:current train perplexity4.9318108558654785
INFO:root:current mean train loss 2024.6982577271256
INFO:root:current train perplexity4.934266567230225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.03s/it]
INFO:root:final mean train loss: 2024.3070272117689
INFO:root:final train perplexity: 4.9356794357299805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it]
INFO:root:eval mean loss: 2840.4894902226447
INFO:root:eval perplexity: 10.28646469116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/22
 22%|â–ˆâ–ˆâ–       | 22/100 [1:56:15<6:51:05, 316.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.8122090378852
INFO:root:current train perplexity4.884843826293945
INFO:root:current mean train loss 2011.4064066451408
INFO:root:current train perplexity4.876529693603516
INFO:root:current mean train loss 2009.6287689767914
INFO:root:current train perplexity4.873600006103516
INFO:root:current mean train loss 2008.6109242784435
INFO:root:current train perplexity4.881007671356201
INFO:root:current mean train loss 2005.9106055616576
INFO:root:current train perplexity4.862000465393066
INFO:root:current mean train loss 2008.2193198744956
INFO:root:current train perplexity4.8705291748046875
INFO:root:current mean train loss 2008.7384366946624
INFO:root:current train perplexity4.874823570251465
INFO:root:current mean train loss 2007.0223826103654
INFO:root:current train perplexity4.873870849609375
INFO:root:current mean train loss 2007.9840223524307
INFO:root:current train perplexity4.877688884735107
INFO:root:current mean train loss 2010.4101645302062
INFO:root:current train perplexity4.881554126739502
INFO:root:current mean train loss 2012.5144956505198
INFO:root:current train perplexity4.887174129486084
INFO:root:current mean train loss 2012.6032711721748
INFO:root:current train perplexity4.8876423835754395
INFO:root:current mean train loss 2012.407243918923
INFO:root:current train perplexity4.889324188232422
INFO:root:current mean train loss 2011.8306209066882
INFO:root:current train perplexity4.889265537261963
INFO:root:current mean train loss 2012.7773237778715
INFO:root:current train perplexity4.888594627380371
INFO:root:current mean train loss 2014.259574254758
INFO:root:current train perplexity4.895214557647705
INFO:root:current mean train loss 2014.723067188434
INFO:root:current train perplexity4.894672870635986
INFO:root:current mean train loss 2013.8331442723756
INFO:root:current train perplexity4.892030715942383
INFO:root:current mean train loss 2014.118447763552
INFO:root:current train perplexity4.892977237701416
INFO:root:current mean train loss 2014.6764684446077
INFO:root:current train perplexity4.895567417144775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.38s/it]
INFO:root:final mean train loss: 2013.7672458327424
INFO:root:final train perplexity: 4.894822120666504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 2843.3477368970534
INFO:root:eval perplexity: 10.310617446899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:01:31<6:45:43, 316.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2018.253822157118
INFO:root:current train perplexity4.844758987426758
INFO:root:current mean train loss 2000.9697105006169
INFO:root:current train perplexity4.812032699584961
INFO:root:current mean train loss 2002.3559212520204
INFO:root:current train perplexity4.827499866485596
INFO:root:current mean train loss 2006.2563924153646
INFO:root:current train perplexity4.837695121765137
INFO:root:current mean train loss 1998.6607663524394
INFO:root:current train perplexity4.827239513397217
INFO:root:current mean train loss 2001.3586018190545
INFO:root:current train perplexity4.835224628448486
INFO:root:current mean train loss 2003.6753566576087
INFO:root:current train perplexity4.8436055183410645
INFO:root:current mean train loss 2004.856682190714
INFO:root:current train perplexity4.842376708984375
INFO:root:current mean train loss 2004.100190923455
INFO:root:current train perplexity4.843286037445068
INFO:root:current mean train loss 2005.9029808583887
INFO:root:current train perplexity4.85091495513916
INFO:root:current mean train loss 2003.996301045549
INFO:root:current train perplexity4.850891590118408
INFO:root:current mean train loss 2002.6526177414326
INFO:root:current train perplexity4.843614101409912
INFO:root:current mean train loss 2001.5538754012234
INFO:root:current train perplexity4.838897228240967
INFO:root:current mean train loss 2001.2380889233925
INFO:root:current train perplexity4.841080188751221
INFO:root:current mean train loss 2001.6757274243655
INFO:root:current train perplexity4.844380855560303
INFO:root:current mean train loss 2003.2344987593358
INFO:root:current train perplexity4.849339962005615
INFO:root:current mean train loss 2002.7961244481555
INFO:root:current train perplexity4.851557731628418
INFO:root:current mean train loss 2003.2779306422399
INFO:root:current train perplexity4.853629112243652
INFO:root:current mean train loss 2003.8627977482226
INFO:root:current train perplexity4.8553900718688965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.63s/it]
INFO:root:final mean train loss: 2003.57516871927
INFO:root:final train perplexity: 4.855635166168213
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2834.55358263537
INFO:root:eval perplexity: 10.236481666564941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:06:52<6:42:15, 317.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1928.062290736607
INFO:root:current train perplexity4.719350337982178
INFO:root:current mean train loss 1968.7118992315275
INFO:root:current train perplexity4.760440826416016
INFO:root:current mean train loss 1977.702409679763
INFO:root:current train perplexity4.777773380279541
INFO:root:current mean train loss 1981.6147779036035
INFO:root:current train perplexity4.789555072784424
INFO:root:current mean train loss 1982.4907577477159
INFO:root:current train perplexity4.787955284118652
INFO:root:current mean train loss 1982.425149469921
INFO:root:current train perplexity4.784841060638428
INFO:root:current mean train loss 1983.9156037633854
INFO:root:current train perplexity4.792594909667969
INFO:root:current mean train loss 1987.0082595156139
INFO:root:current train perplexity4.8012871742248535
INFO:root:current mean train loss 1986.1643842392252
INFO:root:current train perplexity4.798847675323486
INFO:root:current mean train loss 1987.6950612262697
INFO:root:current train perplexity4.802527904510498
INFO:root:current mean train loss 1987.8452948501117
INFO:root:current train perplexity4.805769443511963
INFO:root:current mean train loss 1988.9390053133116
INFO:root:current train perplexity4.805615425109863
INFO:root:current mean train loss 1992.0079476167668
INFO:root:current train perplexity4.815157890319824
INFO:root:current mean train loss 1991.7098384935982
INFO:root:current train perplexity4.8135857582092285
INFO:root:current mean train loss 1991.9394481797208
INFO:root:current train perplexity4.814508438110352
INFO:root:current mean train loss 1993.2122815694727
INFO:root:current train perplexity4.815972805023193
INFO:root:current mean train loss 1995.0401435097183
INFO:root:current train perplexity4.818581581115723
INFO:root:current mean train loss 1994.3582543416126
INFO:root:current train perplexity4.818885803222656
INFO:root:current mean train loss 1994.4215086539543
INFO:root:current train perplexity4.819468975067139
INFO:root:current mean train loss 1994.0403869020795
INFO:root:current train perplexity4.818675994873047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it]
INFO:root:final mean train loss: 1993.4957472377514
INFO:root:final train perplexity: 4.8171892166137695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it]
INFO:root:eval mean loss: 2839.5236017267266
INFO:root:eval perplexity: 10.278315544128418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:12:09<6:36:45, 317.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.310338338216
INFO:root:current train perplexity4.705151557922363
INFO:root:current mean train loss 1958.0863283218875
INFO:root:current train perplexity4.765498638153076
INFO:root:current mean train loss 1970.270501273019
INFO:root:current train perplexity4.778585433959961
INFO:root:current mean train loss 1976.2678866916233
INFO:root:current train perplexity4.76509952545166
INFO:root:current mean train loss 1975.5548760756008
INFO:root:current train perplexity4.762262344360352
INFO:root:current mean train loss 1977.2369445334864
INFO:root:current train perplexity4.761548042297363
INFO:root:current mean train loss 1981.0824060684595
INFO:root:current train perplexity4.772052764892578
INFO:root:current mean train loss 1983.6976552720887
INFO:root:current train perplexity4.780578136444092
INFO:root:current mean train loss 1984.326141949996
INFO:root:current train perplexity4.778971195220947
INFO:root:current mean train loss 1983.2799783021342
INFO:root:current train perplexity4.773464202880859
INFO:root:current mean train loss 1984.0117729902267
INFO:root:current train perplexity4.78005838394165
INFO:root:current mean train loss 1984.839530754768
INFO:root:current train perplexity4.7776570320129395
INFO:root:current mean train loss 1983.5691225139144
INFO:root:current train perplexity4.772698879241943
INFO:root:current mean train loss 1983.7666096759347
INFO:root:current train perplexity4.775938987731934
INFO:root:current mean train loss 1984.711673779434
INFO:root:current train perplexity4.777787685394287
INFO:root:current mean train loss 1985.0943298339844
INFO:root:current train perplexity4.7788777351379395
INFO:root:current mean train loss 1985.8686073190472
INFO:root:current train perplexity4.779819011688232
INFO:root:current mean train loss 1986.9548594746955
INFO:root:current train perplexity4.783092975616455
INFO:root:current mean train loss 1986.0867237291839
INFO:root:current train perplexity4.78480863571167
INFO:root:current mean train loss 1986.3162595625975
INFO:root:current train perplexity4.7847394943237305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.37s/it]
INFO:root:final mean train loss: 1984.8763750300404
INFO:root:final train perplexity: 4.784554958343506
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2838.8201035508164
INFO:root:eval perplexity: 10.272384643554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:17:25<6:31:15, 317.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.4619676543446
INFO:root:current train perplexity4.7426676750183105
INFO:root:current mean train loss 1968.0345554216533
INFO:root:current train perplexity4.736201286315918
INFO:root:current mean train loss 1969.4546217542465
INFO:root:current train perplexity4.7453107833862305
INFO:root:current mean train loss 1978.4883428221224
INFO:root:current train perplexity4.75399112701416
INFO:root:current mean train loss 1972.190823301977
INFO:root:current train perplexity4.749762535095215
INFO:root:current mean train loss 1974.068603515625
INFO:root:current train perplexity4.750227451324463
INFO:root:current mean train loss 1973.9402908587047
INFO:root:current train perplexity4.750955581665039
INFO:root:current mean train loss 1973.9606984662303
INFO:root:current train perplexity4.753596305847168
INFO:root:current mean train loss 1977.7530836905935
INFO:root:current train perplexity4.759836196899414
INFO:root:current mean train loss 1976.1217197981703
INFO:root:current train perplexity4.753756046295166
INFO:root:current mean train loss 1974.2458466778112
INFO:root:current train perplexity4.749765872955322
INFO:root:current mean train loss 1975.5143301560104
INFO:root:current train perplexity4.747836589813232
INFO:root:current mean train loss 1975.194162127474
INFO:root:current train perplexity4.744631290435791
INFO:root:current mean train loss 1975.540807531984
INFO:root:current train perplexity4.746704578399658
INFO:root:current mean train loss 1975.8878622802904
INFO:root:current train perplexity4.749009132385254
INFO:root:current mean train loss 1975.75145882341
INFO:root:current train perplexity4.7495598793029785
INFO:root:current mean train loss 1975.005807824283
INFO:root:current train perplexity4.7475996017456055
INFO:root:current mean train loss 1975.1774431170575
INFO:root:current train perplexity4.7479400634765625
INFO:root:current mean train loss 1975.3089543911894
INFO:root:current train perplexity4.747219085693359
INFO:root:current mean train loss 1975.4226180503565
INFO:root:current train perplexity4.747503757476807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it]
INFO:root:final mean train loss: 1975.1384322281383
INFO:root:final train perplexity: 4.747950553894043
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 2836.519089157517
INFO:root:eval perplexity: 10.253005981445312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:22:43<6:26:10, 317.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.770139496902
INFO:root:current train perplexity4.685052871704102
INFO:root:current mean train loss 1958.885543630093
INFO:root:current train perplexity4.669908046722412
INFO:root:current mean train loss 1950.0406271764475
INFO:root:current train perplexity4.6844353675842285
INFO:root:current mean train loss 1949.5558301190424
INFO:root:current train perplexity4.678258419036865
INFO:root:current mean train loss 1954.0549364381482
INFO:root:current train perplexity4.692069053649902
INFO:root:current mean train loss 1959.4311978466621
INFO:root:current train perplexity4.700207710266113
INFO:root:current mean train loss 1961.6617691364695
INFO:root:current train perplexity4.704720973968506
INFO:root:current mean train loss 1962.9924111882112
INFO:root:current train perplexity4.7070136070251465
INFO:root:current mean train loss 1964.0552874656269
INFO:root:current train perplexity4.711280345916748
INFO:root:current mean train loss 1963.8196802318469
INFO:root:current train perplexity4.709072113037109
INFO:root:current mean train loss 1962.9722164276643
INFO:root:current train perplexity4.707054138183594
INFO:root:current mean train loss 1964.3060320654888
INFO:root:current train perplexity4.708111763000488
INFO:root:current mean train loss 1965.9163422455658
INFO:root:current train perplexity4.711095809936523
INFO:root:current mean train loss 1965.6572295288624
INFO:root:current train perplexity4.708924770355225
INFO:root:current mean train loss 1965.8223696945463
INFO:root:current train perplexity4.709794521331787
INFO:root:current mean train loss 1966.8860680478529
INFO:root:current train perplexity4.712784290313721
INFO:root:current mean train loss 1966.7334653626592
INFO:root:current train perplexity4.712492942810059
INFO:root:current mean train loss 1966.1196505011687
INFO:root:current train perplexity4.71074104309082
INFO:root:current mean train loss 1966.79871781496
INFO:root:current train perplexity4.715077877044678
INFO:root:current mean train loss 1967.099470035292
INFO:root:current train perplexity4.7158122062683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it]
INFO:root:final mean train loss: 1966.8617735000432
INFO:root:final train perplexity: 4.71705961227417
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2839.616670625704
INFO:root:eval perplexity: 10.279099464416504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:27:59<6:20:27, 317.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1979.207618815104
INFO:root:current train perplexity4.726248741149902
INFO:root:current mean train loss 1967.9247607421876
INFO:root:current train perplexity4.684112071990967
INFO:root:current mean train loss 1960.9834015447443
INFO:root:current train perplexity4.6764750480651855
INFO:root:current mean train loss 1961.6757291666668
INFO:root:current train perplexity4.684808254241943
INFO:root:current mean train loss 1961.9474370374178
INFO:root:current train perplexity4.689265727996826
INFO:root:current mean train loss 1957.5815427564537
INFO:root:current train perplexity4.678328990936279
INFO:root:current mean train loss 1956.7208195891203
INFO:root:current train perplexity4.677096366882324
INFO:root:current mean train loss 1960.1880067099294
INFO:root:current train perplexity4.6843414306640625
INFO:root:current mean train loss 1960.1678472377232
INFO:root:current train perplexity4.68219518661499
INFO:root:current mean train loss 1961.1197781450321
INFO:root:current train perplexity4.681344985961914
INFO:root:current mean train loss 1961.6185733103198
INFO:root:current train perplexity4.681710243225098
INFO:root:current mean train loss 1960.1061977435172
INFO:root:current train perplexity4.68276309967041
INFO:root:current mean train loss 1958.260502355239
INFO:root:current train perplexity4.679773807525635
INFO:root:current mean train loss 1957.2762993607955
INFO:root:current train perplexity4.681307315826416
INFO:root:current mean train loss 1957.287168879105
INFO:root:current train perplexity4.679745674133301
INFO:root:current mean train loss 1958.6699663628472
INFO:root:current train perplexity4.681153297424316
INFO:root:current mean train loss 1959.045185182486
INFO:root:current train perplexity4.682750701904297
INFO:root:current mean train loss 1958.3710147997358
INFO:root:current train perplexity4.682317733764648
INFO:root:current mean train loss 1958.58792578125
INFO:root:current train perplexity4.683862686157227
INFO:root:current mean train loss 1957.98243343305
INFO:root:current train perplexity4.68277645111084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.19s/it]
INFO:root:final mean train loss: 1957.610012929727
INFO:root:final train perplexity: 4.682766437530518
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.09s/it]
INFO:root:eval mean loss: 2838.9323906425957
INFO:root:eval perplexity: 10.273329734802246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:33:15<6:14:43, 316.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.975341796875
INFO:root:current train perplexity4.622323989868164
INFO:root:current mean train loss 1942.1884860992432
INFO:root:current train perplexity4.632742881774902
INFO:root:current mean train loss 1949.5120494267712
INFO:root:current train perplexity4.634283542633057
INFO:root:current mean train loss 1950.8407001106107
INFO:root:current train perplexity4.637712001800537
INFO:root:current mean train loss 1958.313338365012
INFO:root:current train perplexity4.648806095123291
INFO:root:current mean train loss 1957.9288794027793
INFO:root:current train perplexity4.65428352355957
INFO:root:current mean train loss 1956.9651559818687
INFO:root:current train perplexity4.646961212158203
INFO:root:current mean train loss 1954.7969440498737
INFO:root:current train perplexity4.645949363708496
INFO:root:current mean train loss 1956.280741054381
INFO:root:current train perplexity4.647888660430908
INFO:root:current mean train loss 1955.7166046634798
INFO:root:current train perplexity4.6493730545043945
INFO:root:current mean train loss 1954.432089892936
INFO:root:current train perplexity4.645856857299805
INFO:root:current mean train loss 1954.078711797727
INFO:root:current train perplexity4.648047924041748
INFO:root:current mean train loss 1953.578218064441
INFO:root:current train perplexity4.6479597091674805
INFO:root:current mean train loss 1953.0108311971028
INFO:root:current train perplexity4.649961471557617
INFO:root:current mean train loss 1954.3916049987956
INFO:root:current train perplexity4.653725624084473
INFO:root:current mean train loss 1953.5018897128464
INFO:root:current train perplexity4.652564525604248
INFO:root:current mean train loss 1952.5002724938358
INFO:root:current train perplexity4.65207052230835
INFO:root:current mean train loss 1950.6083314078194
INFO:root:current train perplexity4.652750015258789
INFO:root:current mean train loss 1950.4979026746043
INFO:root:current train perplexity4.6545515060424805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.38s/it]
INFO:root:final mean train loss: 1949.9622532492988
INFO:root:final train perplexity: 4.65460729598999
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.51s/it]
INFO:root:eval mean loss: 2838.2116625903245
INFO:root:eval perplexity: 10.267254829406738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:38:39<6:12:02, 318.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1903.8944363064236
INFO:root:current train perplexity4.6962480545043945
INFO:root:current mean train loss 1928.1398477816801
INFO:root:current train perplexity4.619319915771484
INFO:root:current mean train loss 1938.1878031315416
INFO:root:current train perplexity4.622237682342529
INFO:root:current mean train loss 1939.2021219691799
INFO:root:current train perplexity4.631422519683838
INFO:root:current mean train loss 1943.3700425723946
INFO:root:current train perplexity4.626111030578613
INFO:root:current mean train loss 1938.5541361450914
INFO:root:current train perplexity4.610016822814941
INFO:root:current mean train loss 1938.8306794565888
INFO:root:current train perplexity4.609057426452637
INFO:root:current mean train loss 1937.956793479758
INFO:root:current train perplexity4.609703063964844
INFO:root:current mean train loss 1939.753981695187
INFO:root:current train perplexity4.611477375030518
INFO:root:current mean train loss 1940.1413811913417
INFO:root:current train perplexity4.613879680633545
INFO:root:current mean train loss 1941.460594880451
INFO:root:current train perplexity4.6169233322143555
INFO:root:current mean train loss 1941.2834501275079
INFO:root:current train perplexity4.617786407470703
INFO:root:current mean train loss 1941.8999963449585
INFO:root:current train perplexity4.622305393218994
INFO:root:current mean train loss 1942.5187258097485
INFO:root:current train perplexity4.623279571533203
INFO:root:current mean train loss 1943.1617867420377
INFO:root:current train perplexity4.623086929321289
INFO:root:current mean train loss 1943.0041351823952
INFO:root:current train perplexity4.624264717102051
INFO:root:current mean train loss 1943.1894528973985
INFO:root:current train perplexity4.6248369216918945
INFO:root:current mean train loss 1943.3019265252433
INFO:root:current train perplexity4.627353668212891
INFO:root:current mean train loss 1943.1422047612416
INFO:root:current train perplexity4.628005504608154
INFO:root:current mean train loss 1942.9808022852278
INFO:root:current train perplexity4.627924919128418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.92s/it]
INFO:root:final mean train loss: 1942.5342296421438
INFO:root:final train perplexity: 4.627419471740723
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it]
INFO:root:eval mean loss: 2836.8721480269332
INFO:root:eval perplexity: 10.255976676940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:44:00<6:07:19, 319.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1928.113990196815
INFO:root:current train perplexity4.593175888061523
INFO:root:current mean train loss 1929.2244669596355
INFO:root:current train perplexity4.575206279754639
INFO:root:current mean train loss 1930.5257022823907
INFO:root:current train perplexity4.5715155601501465
INFO:root:current mean train loss 1921.9777008243866
INFO:root:current train perplexity4.549455642700195
INFO:root:current mean train loss 1921.4070431704813
INFO:root:current train perplexity4.5491509437561035
INFO:root:current mean train loss 1924.460467784577
INFO:root:current train perplexity4.557789325714111
INFO:root:current mean train loss 1926.336305465942
INFO:root:current train perplexity4.564718723297119
INFO:root:current mean train loss 1929.4436156217716
INFO:root:current train perplexity4.568753242492676
INFO:root:current mean train loss 1933.0289319941264
INFO:root:current train perplexity4.575699329376221
INFO:root:current mean train loss 1931.6484976123786
INFO:root:current train perplexity4.576254844665527
INFO:root:current mean train loss 1931.9111008077105
INFO:root:current train perplexity4.58193826675415
INFO:root:current mean train loss 1934.2488497637517
INFO:root:current train perplexity4.590969085693359
INFO:root:current mean train loss 1934.4947896089288
INFO:root:current train perplexity4.593967437744141
INFO:root:current mean train loss 1935.2699766317285
INFO:root:current train perplexity4.593804359436035
INFO:root:current mean train loss 1934.3646678523296
INFO:root:current train perplexity4.595338821411133
INFO:root:current mean train loss 1933.2412730925673
INFO:root:current train perplexity4.595922470092773
INFO:root:current mean train loss 1934.3269940853706
INFO:root:current train perplexity4.598106861114502
INFO:root:current mean train loss 1934.9960120633193
INFO:root:current train perplexity4.599801540374756
INFO:root:current mean train loss 1934.840352220316
INFO:root:current train perplexity4.598905086517334
INFO:root:current mean train loss 1935.0822723483743
INFO:root:current train perplexity4.601009368896484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.18s/it]
INFO:root:final mean train loss: 1935.2611602306126
INFO:root:final train perplexity: 4.600953102111816
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it]
INFO:root:eval mean loss: 2840.6893196907845
INFO:root:eval perplexity: 10.288151741027832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:49:24<6:03:24, 320.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.8208036200945
INFO:root:current train perplexity4.465824127197266
INFO:root:current mean train loss 1921.781895350743
INFO:root:current train perplexity4.5124945640563965
INFO:root:current mean train loss 1928.3692581741898
INFO:root:current train perplexity4.540944576263428
INFO:root:current mean train loss 1929.0529834980866
INFO:root:current train perplexity4.553238391876221
INFO:root:current mean train loss 1924.922694496861
INFO:root:current train perplexity4.551273345947266
INFO:root:current mean train loss 1921.0349993345708
INFO:root:current train perplexity4.546633720397949
INFO:root:current mean train loss 1919.0162421859811
INFO:root:current train perplexity4.5507378578186035
INFO:root:current mean train loss 1920.6337228520883
INFO:root:current train perplexity4.555294990539551
INFO:root:current mean train loss 1921.1011438697824
INFO:root:current train perplexity4.558081150054932
INFO:root:current mean train loss 1924.3801600920433
INFO:root:current train perplexity4.563207626342773
INFO:root:current mean train loss 1925.2568125299617
INFO:root:current train perplexity4.5667500495910645
INFO:root:current mean train loss 1925.6454980938663
INFO:root:current train perplexity4.568129062652588
INFO:root:current mean train loss 1927.0660221655332
INFO:root:current train perplexity4.569252967834473
INFO:root:current mean train loss 1927.4041506269486
INFO:root:current train perplexity4.568514823913574
INFO:root:current mean train loss 1927.4304124775317
INFO:root:current train perplexity4.568933963775635
INFO:root:current mean train loss 1928.4494275274171
INFO:root:current train perplexity4.569301605224609
INFO:root:current mean train loss 1929.180418138742
INFO:root:current train perplexity4.570259094238281
INFO:root:current mean train loss 1928.6418429017408
INFO:root:current train perplexity4.571379661560059
INFO:root:current mean train loss 1928.20240801078
INFO:root:current train perplexity4.573484420776367
INFO:root:current mean train loss 1928.4696191933986
INFO:root:current train perplexity4.574195384979248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.53s/it]
INFO:root:final mean train loss: 1927.5463439356602
INFO:root:final train perplexity: 4.5730438232421875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 2841.654402449324
INFO:root:eval perplexity: 10.296300888061523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [2:54:58<6:02:48, 324.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1891.4085489908855
INFO:root:current train perplexity4.4775471687316895
INFO:root:current mean train loss 1900.68861618042
INFO:root:current train perplexity4.518584251403809
INFO:root:current mean train loss 1903.7399578387922
INFO:root:current train perplexity4.52675724029541
INFO:root:current mean train loss 1906.2854807535807
INFO:root:current train perplexity4.5308966636657715
INFO:root:current mean train loss 1905.5710573942765
INFO:root:current train perplexity4.533242702484131
INFO:root:current mean train loss 1908.1533820016043
INFO:root:current train perplexity4.531745433807373
INFO:root:current mean train loss 1910.4267722389916
INFO:root:current train perplexity4.536463737487793
INFO:root:current mean train loss 1913.1503127248664
INFO:root:current train perplexity4.535703182220459
INFO:root:current mean train loss 1916.657889290743
INFO:root:current train perplexity4.539605617523193
INFO:root:current mean train loss 1917.2523756663004
INFO:root:current train perplexity4.535151481628418
INFO:root:current mean train loss 1917.5434543825545
INFO:root:current train perplexity4.536556720733643
INFO:root:current mean train loss 1917.051971646013
INFO:root:current train perplexity4.537072658538818
INFO:root:current mean train loss 1917.7611341688369
INFO:root:current train perplexity4.539647579193115
INFO:root:current mean train loss 1917.0632643755744
INFO:root:current train perplexity4.53875732421875
INFO:root:current mean train loss 1916.9047966944029
INFO:root:current train perplexity4.537633419036865
INFO:root:current mean train loss 1916.5770517985027
INFO:root:current train perplexity4.538651943206787
INFO:root:current mean train loss 1917.011417839326
INFO:root:current train perplexity4.539496898651123
INFO:root:current mean train loss 1918.9209150140937
INFO:root:current train perplexity4.542201519012451
INFO:root:current mean train loss 1920.112086076634
INFO:root:current train perplexity4.545420169830322
INFO:root:current mean train loss 1921.6482360839843
INFO:root:current train perplexity4.550124645233154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.16s/it]
INFO:root:final mean train loss: 1920.8386179375275
INFO:root:final train perplexity: 4.548915863037109
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it]
INFO:root:eval mean loss: 2839.136891774587
INFO:root:eval perplexity: 10.275054931640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:00:17<5:55:27, 323.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.1125440721387
INFO:root:current train perplexity4.499514102935791
INFO:root:current mean train loss 1923.867770954714
INFO:root:current train perplexity4.509650230407715
INFO:root:current mean train loss 1914.1056793984094
INFO:root:current train perplexity4.502080917358398
INFO:root:current mean train loss 1910.8823705212824
INFO:root:current train perplexity4.500332355499268
INFO:root:current mean train loss 1909.060102098893
INFO:root:current train perplexity4.5082502365112305
INFO:root:current mean train loss 1911.0161382453693
INFO:root:current train perplexity4.512991905212402
INFO:root:current mean train loss 1909.831655843219
INFO:root:current train perplexity4.508751392364502
INFO:root:current mean train loss 1910.519899503298
INFO:root:current train perplexity4.50474739074707
INFO:root:current mean train loss 1909.7356068383872
INFO:root:current train perplexity4.503936290740967
INFO:root:current mean train loss 1910.5964472916135
INFO:root:current train perplexity4.507665157318115
INFO:root:current mean train loss 1910.9577195814836
INFO:root:current train perplexity4.510191917419434
INFO:root:current mean train loss 1912.1707467052424
INFO:root:current train perplexity4.513153553009033
INFO:root:current mean train loss 1913.7467286685714
INFO:root:current train perplexity4.5192179679870605
INFO:root:current mean train loss 1913.8864622870994
INFO:root:current train perplexity4.519707679748535
INFO:root:current mean train loss 1913.2363657295987
INFO:root:current train perplexity4.519556045532227
INFO:root:current mean train loss 1913.0348954669419
INFO:root:current train perplexity4.518376350402832
INFO:root:current mean train loss 1913.9365765748453
INFO:root:current train perplexity4.5206379890441895
INFO:root:current mean train loss 1914.1256892816632
INFO:root:current train perplexity4.5215840339660645
INFO:root:current mean train loss 1914.5478026563333
INFO:root:current train perplexity4.523702144622803
INFO:root:current mean train loss 1914.0775514485924
INFO:root:current train perplexity4.52314567565918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.64s/it]
INFO:root:final mean train loss: 1913.5398326571758
INFO:root:final train perplexity: 4.522806644439697
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it]
INFO:root:eval mean loss: 2839.948900560717
INFO:root:eval perplexity: 10.281904220581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:05:40<5:49:53, 322.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.00416857131
INFO:root:current train perplexity4.546918869018555
INFO:root:current mean train loss 1915.5230668844636
INFO:root:current train perplexity4.5092644691467285
INFO:root:current mean train loss 1913.272977867905
INFO:root:current train perplexity4.495677947998047
INFO:root:current mean train loss 1909.1793448356202
INFO:root:current train perplexity4.486396789550781
INFO:root:current mean train loss 1907.4971313476562
INFO:root:current train perplexity4.493856430053711
INFO:root:current mean train loss 1908.8067458438552
INFO:root:current train perplexity4.494820594787598
INFO:root:current mean train loss 1908.105005093885
INFO:root:current train perplexity4.498104572296143
INFO:root:current mean train loss 1908.5852924029832
INFO:root:current train perplexity4.494835376739502
INFO:root:current mean train loss 1908.8163371587493
INFO:root:current train perplexity4.498887538909912
INFO:root:current mean train loss 1907.073181275151
INFO:root:current train perplexity4.4961419105529785
INFO:root:current mean train loss 1908.8357773803489
INFO:root:current train perplexity4.498808860778809
INFO:root:current mean train loss 1909.9370075270558
INFO:root:current train perplexity4.498775482177734
INFO:root:current mean train loss 1909.6056439312754
INFO:root:current train perplexity4.502622604370117
INFO:root:current mean train loss 1909.999210133272
INFO:root:current train perplexity4.503172397613525
INFO:root:current mean train loss 1910.066413031684
INFO:root:current train perplexity4.502748489379883
INFO:root:current mean train loss 1908.6927183909877
INFO:root:current train perplexity4.500710964202881
INFO:root:current mean train loss 1908.0326240476497
INFO:root:current train perplexity4.499727249145508
INFO:root:current mean train loss 1908.7776091882881
INFO:root:current train perplexity4.501856803894043
INFO:root:current mean train loss 1908.7575548246518
INFO:root:current train perplexity4.503241539001465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.04s/it]
INFO:root:final mean train loss: 1908.2243350091992
INFO:root:final train perplexity: 4.5038862228393555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it]
INFO:root:eval mean loss: 2845.5342676661035
INFO:root:eval perplexity: 10.329133033752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:11:07<5:45:42, 324.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.9159712357955
INFO:root:current train perplexity4.565032958984375
INFO:root:current mean train loss 1885.303964975718
INFO:root:current train perplexity4.46535062789917
INFO:root:current mean train loss 1880.2005921856487
INFO:root:current train perplexity4.4369611740112305
INFO:root:current mean train loss 1886.602314547327
INFO:root:current train perplexity4.450587272644043
INFO:root:current mean train loss 1888.8496260074514
INFO:root:current train perplexity4.44035005569458
INFO:root:current mean train loss 1891.9500952196215
INFO:root:current train perplexity4.45198917388916
INFO:root:current mean train loss 1896.2011025486522
INFO:root:current train perplexity4.463307857513428
INFO:root:current mean train loss 1896.5262094060413
INFO:root:current train perplexity4.462576389312744
INFO:root:current mean train loss 1894.5915735058954
INFO:root:current train perplexity4.462643623352051
INFO:root:current mean train loss 1893.9136938771353
INFO:root:current train perplexity4.464906692504883
INFO:root:current mean train loss 1894.3546898423976
INFO:root:current train perplexity4.465969085693359
INFO:root:current mean train loss 1894.1886595031574
INFO:root:current train perplexity4.466541767120361
INFO:root:current mean train loss 1895.655269808655
INFO:root:current train perplexity4.467203140258789
INFO:root:current mean train loss 1895.0212731961528
INFO:root:current train perplexity4.466920852661133
INFO:root:current mean train loss 1898.2215500905274
INFO:root:current train perplexity4.469266414642334
INFO:root:current mean train loss 1898.5391432877648
INFO:root:current train perplexity4.472168445587158
INFO:root:current mean train loss 1899.5548232852266
INFO:root:current train perplexity4.4742560386657715
INFO:root:current mean train loss 1900.4381348940449
INFO:root:current train perplexity4.473947525024414
INFO:root:current mean train loss 1900.7387728340912
INFO:root:current train perplexity4.475737571716309
INFO:root:current mean train loss 1900.6170325965422
INFO:root:current train perplexity4.47585916519165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.82s/it]
INFO:root:final mean train loss: 1901.095711681618
INFO:root:final train perplexity: 4.478635311126709
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.34s/it]
INFO:root:eval mean loss: 2844.6032663522897
INFO:root:eval perplexity: 10.321248054504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:16:33<5:41:02, 324.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1882.3819100516182
INFO:root:current train perplexity4.403313159942627
INFO:root:current mean train loss 1886.6389150619507
INFO:root:current train perplexity4.427804470062256
INFO:root:current mean train loss 1886.7933146158855
INFO:root:current train perplexity4.4210968017578125
INFO:root:current mean train loss 1881.0811596381955
INFO:root:current train perplexity4.417912483215332
INFO:root:current mean train loss 1880.9739126045013
INFO:root:current train perplexity4.423691272735596
INFO:root:current mean train loss 1883.7922002618964
INFO:root:current train perplexity4.432863235473633
INFO:root:current mean train loss 1884.8545260095293
INFO:root:current train perplexity4.43420934677124
INFO:root:current mean train loss 1883.7356052608282
INFO:root:current train perplexity4.4342217445373535
INFO:root:current mean train loss 1884.452001894154
INFO:root:current train perplexity4.43933629989624
INFO:root:current mean train loss 1884.9379898597454
INFO:root:current train perplexity4.4414753913879395
INFO:root:current mean train loss 1887.2383091551785
INFO:root:current train perplexity4.443216800689697
INFO:root:current mean train loss 1888.6863429292719
INFO:root:current train perplexity4.443767070770264
INFO:root:current mean train loss 1888.3456533226981
INFO:root:current train perplexity4.445721626281738
INFO:root:current mean train loss 1889.2754216021801
INFO:root:current train perplexity4.446112155914307
INFO:root:current mean train loss 1888.8272789706702
INFO:root:current train perplexity4.446026802062988
INFO:root:current mean train loss 1891.0575146899798
INFO:root:current train perplexity4.450377941131592
INFO:root:current mean train loss 1893.8133853096926
INFO:root:current train perplexity4.4549641609191895
INFO:root:current mean train loss 1895.4390302587437
INFO:root:current train perplexity4.456731796264648
INFO:root:current mean train loss 1896.2449712106384
INFO:root:current train perplexity4.459020614624023
INFO:root:current mean train loss 1895.9328389781144
INFO:root:current train perplexity4.458131790161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.63s/it]
INFO:root:final mean train loss: 1895.3921498631926
INFO:root:final train perplexity: 4.458535194396973
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 2851.1544589022615
INFO:root:eval perplexity: 10.376880645751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:21:55<5:34:40, 323.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1869.2823784722223
INFO:root:current train perplexity4.414608478546143
INFO:root:current mean train loss 1888.488994308998
INFO:root:current train perplexity4.413540840148926
INFO:root:current mean train loss 1891.7743856624681
INFO:root:current train perplexity4.423110008239746
INFO:root:current mean train loss 1884.6141222967617
INFO:root:current train perplexity4.415663719177246
INFO:root:current mean train loss 1886.4053691735428
INFO:root:current train perplexity4.418639183044434
INFO:root:current mean train loss 1885.0909869552752
INFO:root:current train perplexity4.417750835418701
INFO:root:current mean train loss 1885.8206376423207
INFO:root:current train perplexity4.416781425476074
INFO:root:current mean train loss 1883.6721720650692
INFO:root:current train perplexity4.411369800567627
INFO:root:current mean train loss 1884.9111797626201
INFO:root:current train perplexity4.4119415283203125
INFO:root:current mean train loss 1885.1043110842427
INFO:root:current train perplexity4.412485122680664
INFO:root:current mean train loss 1885.613793010803
INFO:root:current train perplexity4.416163921356201
INFO:root:current mean train loss 1887.0379779399223
INFO:root:current train perplexity4.420398235321045
INFO:root:current mean train loss 1887.7646777539846
INFO:root:current train perplexity4.423698425292969
INFO:root:current mean train loss 1886.569080996602
INFO:root:current train perplexity4.426568508148193
INFO:root:current mean train loss 1888.2319826753082
INFO:root:current train perplexity4.428263187408447
INFO:root:current mean train loss 1888.3419688795761
INFO:root:current train perplexity4.428508758544922
INFO:root:current mean train loss 1888.7339308718417
INFO:root:current train perplexity4.429630756378174
INFO:root:current mean train loss 1889.4795857863987
INFO:root:current train perplexity4.431769847869873
INFO:root:current mean train loss 1889.712027597815
INFO:root:current train perplexity4.433616638183594
INFO:root:current mean train loss 1889.6582596099774
INFO:root:current train perplexity4.434916973114014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.29s/it]
INFO:root:final mean train loss: 1889.232189184238
INFO:root:final train perplexity: 4.436927318572998
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it]
INFO:root:eval mean loss: 2846.9320196661506
INFO:root:eval perplexity: 10.34099006652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:27:26<5:31:37, 326.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.9687303112398
INFO:root:current train perplexity4.369880199432373
INFO:root:current mean train loss 1871.0538654091918
INFO:root:current train perplexity4.377283096313477
INFO:root:current mean train loss 1877.618760902463
INFO:root:current train perplexity4.380124568939209
INFO:root:current mean train loss 1878.231714406725
INFO:root:current train perplexity4.384576797485352
INFO:root:current mean train loss 1874.7250366210938
INFO:root:current train perplexity4.387900352478027
INFO:root:current mean train loss 1877.54886743946
INFO:root:current train perplexity4.401410102844238
INFO:root:current mean train loss 1877.432947256774
INFO:root:current train perplexity4.402848243713379
INFO:root:current mean train loss 1877.4570060990302
INFO:root:current train perplexity4.402451038360596
INFO:root:current mean train loss 1879.9067176057679
INFO:root:current train perplexity4.408936977386475
INFO:root:current mean train loss 1879.3048633726123
INFO:root:current train perplexity4.40913724899292
INFO:root:current mean train loss 1880.52829881801
INFO:root:current train perplexity4.407106876373291
INFO:root:current mean train loss 1880.6404852809676
INFO:root:current train perplexity4.404632091522217
INFO:root:current mean train loss 1879.6549187371545
INFO:root:current train perplexity4.403383255004883
INFO:root:current mean train loss 1880.8975202697663
INFO:root:current train perplexity4.407402038574219
INFO:root:current mean train loss 1880.6197808679249
INFO:root:current train perplexity4.4100022315979
INFO:root:current mean train loss 1881.7148400769497
INFO:root:current train perplexity4.411772727966309
INFO:root:current mean train loss 1882.6161086246568
INFO:root:current train perplexity4.412498950958252
INFO:root:current mean train loss 1882.8450680406897
INFO:root:current train perplexity4.413674354553223
INFO:root:current mean train loss 1883.377379387713
INFO:root:current train perplexity4.414050102233887
INFO:root:current mean train loss 1883.5879581929712
INFO:root:current train perplexity4.414144039154053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.85s/it]
INFO:root:final mean train loss: 1883.0255665589148
INFO:root:final train perplexity: 4.415261745452881
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2849.854047895552
INFO:root:eval perplexity: 10.365812301635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:33:04<5:29:44, 329.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1872.442265377769
INFO:root:current train perplexity4.390665531158447
INFO:root:current mean train loss 1877.8120730948847
INFO:root:current train perplexity4.3837432861328125
INFO:root:current mean train loss 1874.9789601534499
INFO:root:current train perplexity4.384244441986084
INFO:root:current mean train loss 1875.4011890743527
INFO:root:current train perplexity4.391129493713379
INFO:root:current mean train loss 1873.8923630365996
INFO:root:current train perplexity4.390543460845947
INFO:root:current mean train loss 1876.2950886411782
INFO:root:current train perplexity4.385044574737549
INFO:root:current mean train loss 1876.917991402223
INFO:root:current train perplexity4.385985851287842
INFO:root:current mean train loss 1879.091173203827
INFO:root:current train perplexity4.392407417297363
INFO:root:current mean train loss 1878.2022044037524
INFO:root:current train perplexity4.392367839813232
INFO:root:current mean train loss 1878.7635776102848
INFO:root:current train perplexity4.393205642700195
INFO:root:current mean train loss 1878.9409959172629
INFO:root:current train perplexity4.392426013946533
INFO:root:current mean train loss 1878.8068118754638
INFO:root:current train perplexity4.395641326904297
INFO:root:current mean train loss 1879.60910766697
INFO:root:current train perplexity4.394250392913818
INFO:root:current mean train loss 1880.657604104112
INFO:root:current train perplexity4.3989644050598145
INFO:root:current mean train loss 1881.1569569183412
INFO:root:current train perplexity4.400160312652588
INFO:root:current mean train loss 1879.8965244981744
INFO:root:current train perplexity4.399587154388428
INFO:root:current mean train loss 1879.111697025992
INFO:root:current train perplexity4.396410942077637
INFO:root:current mean train loss 1878.3207582384766
INFO:root:current train perplexity4.396697044372559
INFO:root:current mean train loss 1877.9885357851167
INFO:root:current train perplexity4.397177696228027
INFO:root:current mean train loss 1878.0989118039217
INFO:root:current train perplexity4.3963398933410645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.41s/it]
INFO:root:final mean train loss: 1877.5339139090966
INFO:root:final train perplexity: 4.396181106567383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 2850.0876802095063
INFO:root:eval perplexity: 10.367799758911133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:38:32<5:23:31, 329.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.072301228841
INFO:root:current train perplexity4.341060161590576
INFO:root:current mean train loss 1856.6210445481904
INFO:root:current train perplexity4.336122035980225
INFO:root:current mean train loss 1862.1089114627323
INFO:root:current train perplexity4.351235866546631
INFO:root:current mean train loss 1864.2055765787761
INFO:root:current train perplexity4.354362487792969
INFO:root:current mean train loss 1862.8898957775484
INFO:root:current train perplexity4.35813570022583
INFO:root:current mean train loss 1865.8559189354814
INFO:root:current train perplexity4.353607177734375
INFO:root:current mean train loss 1862.9129836860745
INFO:root:current train perplexity4.350585460662842
INFO:root:current mean train loss 1864.2097390333013
INFO:root:current train perplexity4.35460901260376
INFO:root:current mean train loss 1865.4784014565605
INFO:root:current train perplexity4.3566694259643555
INFO:root:current mean train loss 1865.7180499341114
INFO:root:current train perplexity4.359378814697266
INFO:root:current mean train loss 1866.120351526859
INFO:root:current train perplexity4.355885982513428
INFO:root:current mean train loss 1867.1490372367527
INFO:root:current train perplexity4.357691764831543
INFO:root:current mean train loss 1868.9408043755425
INFO:root:current train perplexity4.361045837402344
INFO:root:current mean train loss 1868.9541008629567
INFO:root:current train perplexity4.363775253295898
INFO:root:current mean train loss 1870.0410463873716
INFO:root:current train perplexity4.367926120758057
INFO:root:current mean train loss 1872.5570115780174
INFO:root:current train perplexity4.372214317321777
INFO:root:current mean train loss 1872.743997393914
INFO:root:current train perplexity4.3738555908203125
INFO:root:current mean train loss 1872.6076974847535
INFO:root:current train perplexity4.374837875366211
INFO:root:current mean train loss 1873.086452113928
INFO:root:current train perplexity4.376715660095215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.11s/it]
INFO:root:final mean train loss: 1872.3303362393824
INFO:root:final train perplexity: 4.378176689147949
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.82s/it]
INFO:root:eval mean loss: 2848.3530002170137
INFO:root:eval perplexity: 10.353055953979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:43:55<5:16:25, 327.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.4839242788462
INFO:root:current train perplexity4.412601947784424
INFO:root:current mean train loss 1849.217559544386
INFO:root:current train perplexity4.357607364654541
INFO:root:current mean train loss 1849.5434134756456
INFO:root:current train perplexity4.347352981567383
INFO:root:current mean train loss 1853.6685436114717
INFO:root:current train perplexity4.332412242889404
INFO:root:current mean train loss 1853.786161778337
INFO:root:current train perplexity4.334826946258545
INFO:root:current mean train loss 1856.7690294053818
INFO:root:current train perplexity4.3319268226623535
INFO:root:current mean train loss 1858.1706425478562
INFO:root:current train perplexity4.339809894561768
INFO:root:current mean train loss 1861.1861895846116
INFO:root:current train perplexity4.339590549468994
INFO:root:current mean train loss 1861.1490759292358
INFO:root:current train perplexity4.344337463378906
INFO:root:current mean train loss 1863.0053940905668
INFO:root:current train perplexity4.343685626983643
INFO:root:current mean train loss 1864.3200002747485
INFO:root:current train perplexity4.345586776733398
INFO:root:current mean train loss 1864.7637165134702
INFO:root:current train perplexity4.349228858947754
INFO:root:current mean train loss 1864.9755186126533
INFO:root:current train perplexity4.351716041564941
INFO:root:current mean train loss 1864.872802734375
INFO:root:current train perplexity4.350837707519531
INFO:root:current mean train loss 1866.5749418416601
INFO:root:current train perplexity4.354146957397461
INFO:root:current mean train loss 1866.5886697611586
INFO:root:current train perplexity4.355513572692871
INFO:root:current mean train loss 1865.2899110135422
INFO:root:current train perplexity4.351536750793457
INFO:root:current mean train loss 1865.6988232507388
INFO:root:current train perplexity4.353369235992432
INFO:root:current mean train loss 1865.0259211898442
INFO:root:current train perplexity4.35196590423584
INFO:root:current mean train loss 1866.0208365026097
INFO:root:current train perplexity4.354483604431152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.46s/it]
INFO:root:final mean train loss: 1865.9291009407602
INFO:root:final train perplexity: 4.3561296463012695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it]
INFO:root:eval mean loss: 2851.286354225319
INFO:root:eval perplexity: 10.37800407409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:49:38<5:15:20, 331.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.1018880208333
INFO:root:current train perplexity4.382391452789307
INFO:root:current mean train loss 1864.1450354942908
INFO:root:current train perplexity4.335263729095459
INFO:root:current mean train loss 1872.1955226732337
INFO:root:current train perplexity4.351955413818359
INFO:root:current mean train loss 1868.5097637754498
INFO:root:current train perplexity4.335135459899902
INFO:root:current mean train loss 1863.9910579237826
INFO:root:current train perplexity4.333439350128174
INFO:root:current mean train loss 1863.8099975585938
INFO:root:current train perplexity4.32740592956543
INFO:root:current mean train loss 1861.5889419797868
INFO:root:current train perplexity4.3276686668396
INFO:root:current mean train loss 1862.619700309022
INFO:root:current train perplexity4.331511497497559
INFO:root:current mean train loss 1864.2044921875
INFO:root:current train perplexity4.331758499145508
INFO:root:current mean train loss 1864.029279548891
INFO:root:current train perplexity4.332756996154785
INFO:root:current mean train loss 1863.0936294703808
INFO:root:current train perplexity4.334085464477539
INFO:root:current mean train loss 1862.931610377489
INFO:root:current train perplexity4.334057807922363
INFO:root:current mean train loss 1863.5497945645961
INFO:root:current train perplexity4.337716102600098
INFO:root:current mean train loss 1863.1137059261923
INFO:root:current train perplexity4.336742877960205
INFO:root:current mean train loss 1863.3872232503825
INFO:root:current train perplexity4.339451789855957
INFO:root:current mean train loss 1862.104741434334
INFO:root:current train perplexity4.3386993408203125
INFO:root:current mean train loss 1862.134549193587
INFO:root:current train perplexity4.341932773590088
INFO:root:current mean train loss 1863.0322780013773
INFO:root:current train perplexity4.342433452606201
INFO:root:current mean train loss 1862.8917070899504
INFO:root:current train perplexity4.343738079071045
INFO:root:current mean train loss 1862.0961076647507
INFO:root:current train perplexity4.341370105743408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.87s/it]
INFO:root:final mean train loss: 1862.002125242294
INFO:root:final train perplexity: 4.3426594734191895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it]
INFO:root:eval mean loss: 2854.4055732979073
INFO:root:eval perplexity: 10.4045991897583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [3:55:17<5:11:51, 334.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1845.6560266373006
INFO:root:current train perplexity4.305002689361572
INFO:root:current mean train loss 1827.9959567323024
INFO:root:current train perplexity4.264148235321045
INFO:root:current mean train loss 1840.522676908053
INFO:root:current train perplexity4.268278121948242
INFO:root:current mean train loss 1848.1603979281115
INFO:root:current train perplexity4.295236587524414
INFO:root:current mean train loss 1849.1097961016148
INFO:root:current train perplexity4.296992778778076
INFO:root:current mean train loss 1850.1876633555187
INFO:root:current train perplexity4.301464557647705
INFO:root:current mean train loss 1850.3344764296755
INFO:root:current train perplexity4.30408239364624
INFO:root:current mean train loss 1850.8047520485588
INFO:root:current train perplexity4.297024726867676
INFO:root:current mean train loss 1853.6157788633598
INFO:root:current train perplexity4.30452823638916
INFO:root:current mean train loss 1853.7562999624638
INFO:root:current train perplexity4.302367210388184
INFO:root:current mean train loss 1853.593018394259
INFO:root:current train perplexity4.307789325714111
INFO:root:current mean train loss 1855.415375474233
INFO:root:current train perplexity4.311098098754883
INFO:root:current mean train loss 1853.8531703627768
INFO:root:current train perplexity4.310335159301758
INFO:root:current mean train loss 1852.929224140306
INFO:root:current train perplexity4.310159206390381
INFO:root:current mean train loss 1853.761279313747
INFO:root:current train perplexity4.311282634735107
INFO:root:current mean train loss 1855.1094063263827
INFO:root:current train perplexity4.317704677581787
INFO:root:current mean train loss 1854.5318157332697
INFO:root:current train perplexity4.317306995391846
INFO:root:current mean train loss 1854.430269901863
INFO:root:current train perplexity4.316103935241699
INFO:root:current mean train loss 1855.0260935702322
INFO:root:current train perplexity4.31813383102417
INFO:root:current mean train loss 1856.3284900823985
INFO:root:current train perplexity4.321290969848633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.81s/it]
INFO:root:final mean train loss: 1855.7663144233306
INFO:root:final train perplexity: 4.321354866027832
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2852.7009981172578
INFO:root:eval perplexity: 10.390058517456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:00:40<5:03:12, 330.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1843.2506217956543
INFO:root:current train perplexity4.2770161628723145
INFO:root:current mean train loss 1851.7741021877382
INFO:root:current train perplexity4.290385723114014
INFO:root:current mean train loss 1851.2785422585227
INFO:root:current train perplexity4.298233509063721
INFO:root:current mean train loss 1852.5491098257212
INFO:root:current train perplexity4.316093444824219
INFO:root:current mean train loss 1851.9096332418508
INFO:root:current train perplexity4.308579444885254
INFO:root:current mean train loss 1851.1344888024296
INFO:root:current train perplexity4.3068461418151855
INFO:root:current mean train loss 1848.3981510759836
INFO:root:current train perplexity4.300846576690674
INFO:root:current mean train loss 1847.8871590978813
INFO:root:current train perplexity4.301995754241943
INFO:root:current mean train loss 1850.086609310574
INFO:root:current train perplexity4.305229187011719
INFO:root:current mean train loss 1850.7407158182864
INFO:root:current train perplexity4.305644989013672
INFO:root:current mean train loss 1849.5504251351033
INFO:root:current train perplexity4.305612087249756
INFO:root:current mean train loss 1850.7291655130812
INFO:root:current train perplexity4.304740905761719
INFO:root:current mean train loss 1852.0339994792696
INFO:root:current train perplexity4.306272506713867
INFO:root:current mean train loss 1853.0815005484214
INFO:root:current train perplexity4.306097030639648
INFO:root:current mean train loss 1853.936487666896
INFO:root:current train perplexity4.305999279022217
INFO:root:current mean train loss 1853.4784865903732
INFO:root:current train perplexity4.305177688598633
INFO:root:current mean train loss 1852.2103711641753
INFO:root:current train perplexity4.306065559387207
INFO:root:current mean train loss 1852.1359224557336
INFO:root:current train perplexity4.305476188659668
INFO:root:current mean train loss 1851.7737674303833
INFO:root:current train perplexity4.3061652183532715
INFO:root:current mean train loss 1851.8813351633107
INFO:root:current train perplexity4.305919170379639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.81s/it]
INFO:root:final mean train loss: 1851.2548084499497
INFO:root:final train perplexity: 4.30600643157959
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.57s/it]
INFO:root:eval mean loss: 2853.4223508176146
INFO:root:eval perplexity: 10.396208763122559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:06:13<4:58:12, 331.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1853.9309986255787
INFO:root:current train perplexity4.294023513793945
INFO:root:current mean train loss 1852.4995016024257
INFO:root:current train perplexity4.279361248016357
INFO:root:current mean train loss 1850.8196448057995
INFO:root:current train perplexity4.2744927406311035
INFO:root:current mean train loss 1850.2913116695374
INFO:root:current train perplexity4.272241115570068
INFO:root:current mean train loss 1846.0639808321694
INFO:root:current train perplexity4.272130489349365
INFO:root:current mean train loss 1846.8894511500241
INFO:root:current train perplexity4.2756500244140625
INFO:root:current mean train loss 1847.6375440241832
INFO:root:current train perplexity4.28327751159668
INFO:root:current mean train loss 1848.879462052857
INFO:root:current train perplexity4.283708572387695
INFO:root:current mean train loss 1851.232635255569
INFO:root:current train perplexity4.2850799560546875
INFO:root:current mean train loss 1848.2779012168705
INFO:root:current train perplexity4.282660961151123
INFO:root:current mean train loss 1848.503623941229
INFO:root:current train perplexity4.284163951873779
INFO:root:current mean train loss 1848.5678964173965
INFO:root:current train perplexity4.284427642822266
INFO:root:current mean train loss 1848.9365578382672
INFO:root:current train perplexity4.288146495819092
INFO:root:current mean train loss 1848.604575453419
INFO:root:current train perplexity4.288820743560791
INFO:root:current mean train loss 1847.9921820599995
INFO:root:current train perplexity4.289307117462158
INFO:root:current mean train loss 1846.8545710197511
INFO:root:current train perplexity4.2874884605407715
INFO:root:current mean train loss 1847.0886370620863
INFO:root:current train perplexity4.286296844482422
INFO:root:current mean train loss 1847.1422411122394
INFO:root:current train perplexity4.287808418273926
INFO:root:current mean train loss 1846.0691975781665
INFO:root:current train perplexity4.287123203277588
INFO:root:current mean train loss 1846.4782042563534
INFO:root:current train perplexity4.287901878356934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.76s/it]
INFO:root:final mean train loss: 1845.880989324788
INFO:root:final train perplexity: 4.287795543670654
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it]
INFO:root:eval mean loss: 2857.9071415165167
INFO:root:eval perplexity: 10.434536933898926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:11:55<4:55:42, 334.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.5914306640625
INFO:root:current train perplexity4.227965354919434
INFO:root:current mean train loss 1837.1899167455808
INFO:root:current train perplexity4.233484268188477
INFO:root:current mean train loss 1836.1438102978188
INFO:root:current train perplexity4.253072261810303
INFO:root:current mean train loss 1834.8922505594378
INFO:root:current train perplexity4.255622386932373
INFO:root:current mean train loss 1835.4910258710624
INFO:root:current train perplexity4.252411365509033
INFO:root:current mean train loss 1836.0803336969586
INFO:root:current train perplexity4.254293918609619
INFO:root:current mean train loss 1839.3667581552763
INFO:root:current train perplexity4.262228965759277
INFO:root:current mean train loss 1839.4696321798149
INFO:root:current train perplexity4.265317916870117
INFO:root:current mean train loss 1840.2026813056793
INFO:root:current train perplexity4.2679243087768555
INFO:root:current mean train loss 1839.0832574572973
INFO:root:current train perplexity4.2662553787231445
INFO:root:current mean train loss 1841.053538838371
INFO:root:current train perplexity4.266002655029297
INFO:root:current mean train loss 1841.7287818768586
INFO:root:current train perplexity4.268864154815674
INFO:root:current mean train loss 1839.9014516398424
INFO:root:current train perplexity4.2664313316345215
INFO:root:current mean train loss 1840.414180029786
INFO:root:current train perplexity4.268945693969727
INFO:root:current mean train loss 1840.5758771297928
INFO:root:current train perplexity4.271045684814453
INFO:root:current mean train loss 1841.1305273101386
INFO:root:current train perplexity4.273936748504639
INFO:root:current mean train loss 1841.4836412840934
INFO:root:current train perplexity4.2745561599731445
INFO:root:current mean train loss 1841.5132884194243
INFO:root:current train perplexity4.273717880249023
INFO:root:current mean train loss 1841.5880182907379
INFO:root:current train perplexity4.273037910461426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.05s/it]
INFO:root:final mean train loss: 1841.7224698203775
INFO:root:final train perplexity: 4.273756504058838
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2860.923020921312
INFO:root:eval perplexity: 10.460391998291016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:17:14<4:45:53, 329.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.2810139973958
INFO:root:current train perplexity4.05146598815918
INFO:root:current mean train loss 1834.108740234375
INFO:root:current train perplexity4.242992401123047
INFO:root:current mean train loss 1837.5747598337573
INFO:root:current train perplexity4.232054710388184
INFO:root:current mean train loss 1835.56407218812
INFO:root:current train perplexity4.227682113647461
INFO:root:current mean train loss 1838.265618822948
INFO:root:current train perplexity4.235764503479004
INFO:root:current mean train loss 1834.323379664745
INFO:root:current train perplexity4.228061199188232
INFO:root:current mean train loss 1830.814347330729
INFO:root:current train perplexity4.22659969329834
INFO:root:current mean train loss 1832.6557074273383
INFO:root:current train perplexity4.235292911529541
INFO:root:current mean train loss 1832.15510643333
INFO:root:current train perplexity4.238958835601807
INFO:root:current mean train loss 1831.3336070910177
INFO:root:current train perplexity4.2408766746521
INFO:root:current mean train loss 1833.5150468798106
INFO:root:current train perplexity4.245299339294434
INFO:root:current mean train loss 1834.6133379606922
INFO:root:current train perplexity4.243055820465088
INFO:root:current mean train loss 1835.7046700183257
INFO:root:current train perplexity4.243354797363281
INFO:root:current mean train loss 1835.941867610801
INFO:root:current train perplexity4.245056629180908
INFO:root:current mean train loss 1835.3547096710745
INFO:root:current train perplexity4.247014045715332
INFO:root:current mean train loss 1834.655443046746
INFO:root:current train perplexity4.248701572418213
INFO:root:current mean train loss 1835.7309424432808
INFO:root:current train perplexity4.25070858001709
INFO:root:current mean train loss 1835.43083631332
INFO:root:current train perplexity4.251739978790283
INFO:root:current mean train loss 1836.4259128707172
INFO:root:current train perplexity4.253525257110596
INFO:root:current mean train loss 1836.6430923501755
INFO:root:current train perplexity4.256429195404053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.43s/it]
INFO:root:final mean train loss: 1837.068803303421
INFO:root:final train perplexity: 4.25809907913208
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it]
INFO:root:eval mean loss: 2861.4967381932715
INFO:root:eval perplexity: 10.46531867980957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:22:34<4:37:58, 327.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.9075813293457
INFO:root:current train perplexity4.291554927825928
INFO:root:current mean train loss 1833.8726917613637
INFO:root:current train perplexity4.207979202270508
INFO:root:current mean train loss 1828.9444922085465
INFO:root:current train perplexity4.203071594238281
INFO:root:current mean train loss 1830.6757371282004
INFO:root:current train perplexity4.215195655822754
INFO:root:current mean train loss 1831.8239183779117
INFO:root:current train perplexity4.2217488288879395
INFO:root:current mean train loss 1828.3652965574336
INFO:root:current train perplexity4.223572254180908
INFO:root:current mean train loss 1828.7743453013745
INFO:root:current train perplexity4.22794771194458
INFO:root:current mean train loss 1829.7422867238197
INFO:root:current train perplexity4.230531215667725
INFO:root:current mean train loss 1829.4161501664382
INFO:root:current train perplexity4.2312331199646
INFO:root:current mean train loss 1829.7331422470158
INFO:root:current train perplexity4.233174800872803
INFO:root:current mean train loss 1828.8310685268668
INFO:root:current train perplexity4.231399059295654
INFO:root:current mean train loss 1830.9455187902013
INFO:root:current train perplexity4.234560489654541
INFO:root:current mean train loss 1831.419425072608
INFO:root:current train perplexity4.235067844390869
INFO:root:current mean train loss 1830.4918447500236
INFO:root:current train perplexity4.2336835861206055
INFO:root:current mean train loss 1830.1410828489165
INFO:root:current train perplexity4.234130382537842
INFO:root:current mean train loss 1830.3239775575482
INFO:root:current train perplexity4.2341532707214355
INFO:root:current mean train loss 1831.3607758166743
INFO:root:current train perplexity4.236019134521484
INFO:root:current mean train loss 1830.7371911451944
INFO:root:current train perplexity4.236468315124512
INFO:root:current mean train loss 1832.1133123672685
INFO:root:current train perplexity4.239154815673828
INFO:root:current mean train loss 1832.1680484242568
INFO:root:current train perplexity4.2412543296813965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.31s/it]
INFO:root:final mean train loss: 1832.573492114615
INFO:root:final train perplexity: 4.243030071258545
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.17s/it]
INFO:root:eval mean loss: 2860.6412782411317
INFO:root:eval perplexity: 10.457975387573242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:28:16<4:36:17, 331.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1807.0201665138711
INFO:root:current train perplexity4.187587738037109
INFO:root:current mean train loss 1818.6154752385696
INFO:root:current train perplexity4.170711517333984
INFO:root:current mean train loss 1819.1260451964106
INFO:root:current train perplexity4.190318584442139
INFO:root:current mean train loss 1821.532125128716
INFO:root:current train perplexity4.202146530151367
INFO:root:current mean train loss 1825.9500705234723
INFO:root:current train perplexity4.203205108642578
INFO:root:current mean train loss 1825.68384167058
INFO:root:current train perplexity4.2042341232299805
INFO:root:current mean train loss 1823.4519725734904
INFO:root:current train perplexity4.204901218414307
INFO:root:current mean train loss 1825.608493942444
INFO:root:current train perplexity4.2102742195129395
INFO:root:current mean train loss 1825.4814171313678
INFO:root:current train perplexity4.210450649261475
INFO:root:current mean train loss 1827.4985512350584
INFO:root:current train perplexity4.216534614562988
INFO:root:current mean train loss 1828.457113987838
INFO:root:current train perplexity4.222531795501709
INFO:root:current mean train loss 1828.0732830900852
INFO:root:current train perplexity4.225197792053223
INFO:root:current mean train loss 1827.9797004595864
INFO:root:current train perplexity4.227418899536133
INFO:root:current mean train loss 1826.669183842777
INFO:root:current train perplexity4.225863456726074
INFO:root:current mean train loss 1826.5746140252977
INFO:root:current train perplexity4.226417541503906
INFO:root:current mean train loss 1826.3499103346664
INFO:root:current train perplexity4.225961685180664
INFO:root:current mean train loss 1826.7538214152044
INFO:root:current train perplexity4.226982593536377
INFO:root:current mean train loss 1827.0883894451963
INFO:root:current train perplexity4.228092670440674
INFO:root:current mean train loss 1827.7649296151424
INFO:root:current train perplexity4.228416919708252
INFO:root:current mean train loss 1829.346290302619
INFO:root:current train perplexity4.230678558349609

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.09s/it]
INFO:root:final mean train loss: 1828.5321423506052
INFO:root:final train perplexity: 4.229527950286865
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 2861.694345468515
INFO:root:eval perplexity: 10.467015266418457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:33:38<4:28:20, 328.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1821.4868589459043
INFO:root:current train perplexity4.1737751960754395
INFO:root:current mean train loss 1817.674397296216
INFO:root:current train perplexity4.196653842926025
INFO:root:current mean train loss 1821.7499513554394
INFO:root:current train perplexity4.188299655914307
INFO:root:current mean train loss 1821.563381841274
INFO:root:current train perplexity4.203955173492432
INFO:root:current mean train loss 1821.6106462601429
INFO:root:current train perplexity4.201769828796387
INFO:root:current mean train loss 1826.9775847849492
INFO:root:current train perplexity4.203938961029053
INFO:root:current mean train loss 1827.3882594752956
INFO:root:current train perplexity4.20456075668335
INFO:root:current mean train loss 1824.2590716090588
INFO:root:current train perplexity4.201724052429199
INFO:root:current mean train loss 1826.2786015252868
INFO:root:current train perplexity4.207198619842529
INFO:root:current mean train loss 1824.816387042249
INFO:root:current train perplexity4.205242156982422
INFO:root:current mean train loss 1824.6710802833313
INFO:root:current train perplexity4.210848808288574
INFO:root:current mean train loss 1823.4754620874317
INFO:root:current train perplexity4.208359241485596
INFO:root:current mean train loss 1824.1862090052023
INFO:root:current train perplexity4.209516525268555
INFO:root:current mean train loss 1823.2079059383007
INFO:root:current train perplexity4.210723876953125
INFO:root:current mean train loss 1822.615897851296
INFO:root:current train perplexity4.210874557495117
INFO:root:current mean train loss 1823.834075654908
INFO:root:current train perplexity4.213443756103516
INFO:root:current mean train loss 1823.6243762397537
INFO:root:current train perplexity4.2130327224731445
INFO:root:current mean train loss 1824.5641867960567
INFO:root:current train perplexity4.2139058113098145
INFO:root:current mean train loss 1824.419617942164
INFO:root:current train perplexity4.214471817016602
INFO:root:current mean train loss 1824.5921142205582
INFO:root:current train perplexity4.21479606628418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.60s/it]
INFO:root:final mean train loss: 1824.37444658996
INFO:root:final train perplexity: 4.215682029724121
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 2866.2169083145645
INFO:root:eval perplexity: 10.505932807922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:39:05<4:22:28, 328.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.693603515625
INFO:root:current train perplexity4.19067907333374
INFO:root:current mean train loss 1812.3625921864327
INFO:root:current train perplexity4.186179161071777
INFO:root:current mean train loss 1807.4328962669777
INFO:root:current train perplexity4.169863224029541
INFO:root:current mean train loss 1810.4687449004568
INFO:root:current train perplexity4.181619167327881
INFO:root:current mean train loss 1809.6172623091356
INFO:root:current train perplexity4.177187919616699
INFO:root:current mean train loss 1809.9131883258067
INFO:root:current train perplexity4.1836113929748535
INFO:root:current mean train loss 1812.647894170937
INFO:root:current train perplexity4.185984134674072
INFO:root:current mean train loss 1813.004037362558
INFO:root:current train perplexity4.183338642120361
INFO:root:current mean train loss 1814.7342616391209
INFO:root:current train perplexity4.184514045715332
INFO:root:current mean train loss 1815.4044399319685
INFO:root:current train perplexity4.187872886657715
INFO:root:current mean train loss 1815.3916606251444
INFO:root:current train perplexity4.187852382659912
INFO:root:current mean train loss 1816.2557862153621
INFO:root:current train perplexity4.193295001983643
INFO:root:current mean train loss 1815.3665389955183
INFO:root:current train perplexity4.194772243499756
INFO:root:current mean train loss 1816.5913100942528
INFO:root:current train perplexity4.197118759155273
INFO:root:current mean train loss 1818.176384769576
INFO:root:current train perplexity4.198238372802734
INFO:root:current mean train loss 1819.5896071664758
INFO:root:current train perplexity4.199800491333008
INFO:root:current mean train loss 1819.6274040525893
INFO:root:current train perplexity4.1985063552856445
INFO:root:current mean train loss 1820.4988125701066
INFO:root:current train perplexity4.200547218322754
INFO:root:current mean train loss 1820.601094833917
INFO:root:current train perplexity4.201409339904785
INFO:root:current mean train loss 1820.139779587677
INFO:root:current train perplexity4.201626777648926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.65s/it]
INFO:root:final mean train loss: 1820.139779587677
INFO:root:final train perplexity: 4.201626777648926
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 2865.787916578688
INFO:root:eval perplexity: 10.50223445892334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:44:26<4:15:18, 325.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1808.9929760742189
INFO:root:current train perplexity4.237344741821289
INFO:root:current mean train loss 1822.9500134277343
INFO:root:current train perplexity4.212158679962158
INFO:root:current mean train loss 1810.9423006184895
INFO:root:current train perplexity4.190155029296875
INFO:root:current mean train loss 1811.0765145874022
INFO:root:current train perplexity4.184676170349121
INFO:root:current mean train loss 1809.9306323242188
INFO:root:current train perplexity4.179501056671143
INFO:root:current mean train loss 1815.2704829915365
INFO:root:current train perplexity4.187751770019531
INFO:root:current mean train loss 1813.2549128069197
INFO:root:current train perplexity4.180176734924316
INFO:root:current mean train loss 1813.0452033996582
INFO:root:current train perplexity4.182568550109863
INFO:root:current mean train loss 1814.1061694335938
INFO:root:current train perplexity4.18394136428833
INFO:root:current mean train loss 1814.2387740478516
INFO:root:current train perplexity4.185657978057861
INFO:root:current mean train loss 1816.8336076216265
INFO:root:current train perplexity4.189186096191406
INFO:root:current mean train loss 1817.2135821533202
INFO:root:current train perplexity4.18954610824585
INFO:root:current mean train loss 1817.8420997971755
INFO:root:current train perplexity4.189088821411133
INFO:root:current mean train loss 1815.3414882986885
INFO:root:current train perplexity4.185556411743164
INFO:root:current mean train loss 1815.3982392578125
INFO:root:current train perplexity4.185943603515625
INFO:root:current mean train loss 1815.898104095459
INFO:root:current train perplexity4.186922073364258
INFO:root:current mean train loss 1816.5860083725872
INFO:root:current train perplexity4.1867995262146
INFO:root:current mean train loss 1817.994910820855
INFO:root:current train perplexity4.189402103424072
INFO:root:current mean train loss 1816.6181002647
INFO:root:current train perplexity4.187856674194336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it]
INFO:root:final mean train loss: 1815.7601195550362
INFO:root:final train perplexity: 4.18713903427124
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it]
INFO:root:eval mean loss: 2867.2237119932433
INFO:root:eval perplexity: 10.514616012573242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:50:07<4:13:18, 330.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.553861730239
INFO:root:current train perplexity4.243706226348877
INFO:root:current mean train loss 1803.5360545622996
INFO:root:current train perplexity4.168807029724121
INFO:root:current mean train loss 1808.2896137852822
INFO:root:current train perplexity4.160756587982178
INFO:root:current mean train loss 1805.7439665689078
INFO:root:current train perplexity4.161531448364258
INFO:root:current mean train loss 1812.4660296177121
INFO:root:current train perplexity4.177346229553223
INFO:root:current mean train loss 1810.7369753101577
INFO:root:current train perplexity4.170350074768066
INFO:root:current mean train loss 1809.1095398048142
INFO:root:current train perplexity4.166780471801758
INFO:root:current mean train loss 1809.0500496793825
INFO:root:current train perplexity4.171908378601074
INFO:root:current mean train loss 1809.4279779179735
INFO:root:current train perplexity4.172813415527344
INFO:root:current mean train loss 1810.2211935361572
INFO:root:current train perplexity4.17482328414917
INFO:root:current mean train loss 1810.572823763597
INFO:root:current train perplexity4.1761674880981445
INFO:root:current mean train loss 1811.1569095293964
INFO:root:current train perplexity4.179222583770752
INFO:root:current mean train loss 1811.2100298465425
INFO:root:current train perplexity4.180085182189941
INFO:root:current mean train loss 1810.4318660426159
INFO:root:current train perplexity4.180200576782227
INFO:root:current mean train loss 1811.0225626771182
INFO:root:current train perplexity4.179447650909424
INFO:root:current mean train loss 1810.6641130340515
INFO:root:current train perplexity4.175973892211914
INFO:root:current mean train loss 1811.1153211906212
INFO:root:current train perplexity4.177119731903076
INFO:root:current mean train loss 1811.310287875496
INFO:root:current train perplexity4.17714262008667
INFO:root:current mean train loss 1811.625337725625
INFO:root:current train perplexity4.176124572753906
INFO:root:current mean train loss 1811.9462087011361
INFO:root:current train perplexity4.174302101135254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.79s/it]
INFO:root:final mean train loss: 1812.058208517516
INFO:root:final train perplexity: 4.174931526184082
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.35s/it]
INFO:root:eval mean loss: 2868.082957957958
INFO:root:eval perplexity: 10.522031784057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [4:55:33<4:06:51, 329.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.418166216682
INFO:root:current train perplexity4.124584197998047
INFO:root:current mean train loss 1800.9720796044194
INFO:root:current train perplexity4.138983726501465
INFO:root:current mean train loss 1810.4057032919338
INFO:root:current train perplexity4.1493425369262695
INFO:root:current mean train loss 1811.7451032992608
INFO:root:current train perplexity4.1536712646484375
INFO:root:current mean train loss 1811.7823193809404
INFO:root:current train perplexity4.15792179107666
INFO:root:current mean train loss 1810.5826230852792
INFO:root:current train perplexity4.154726028442383
INFO:root:current mean train loss 1807.7681651792316
INFO:root:current train perplexity4.147825241088867
INFO:root:current mean train loss 1807.2806369875043
INFO:root:current train perplexity4.1474199295043945
INFO:root:current mean train loss 1806.453788190151
INFO:root:current train perplexity4.148010730743408
INFO:root:current mean train loss 1804.1296863760122
INFO:root:current train perplexity4.147449016571045
INFO:root:current mean train loss 1803.5723900564403
INFO:root:current train perplexity4.151158809661865
INFO:root:current mean train loss 1803.592190535611
INFO:root:current train perplexity4.15008020401001
INFO:root:current mean train loss 1804.762438608723
INFO:root:current train perplexity4.15457820892334
INFO:root:current mean train loss 1804.8763966710492
INFO:root:current train perplexity4.155652046203613
INFO:root:current mean train loss 1805.165765525573
INFO:root:current train perplexity4.158131122589111
INFO:root:current mean train loss 1806.4135540063253
INFO:root:current train perplexity4.159337520599365
INFO:root:current mean train loss 1807.1601518423204
INFO:root:current train perplexity4.161064147949219
INFO:root:current mean train loss 1808.1087243103239
INFO:root:current train perplexity4.16361141204834
INFO:root:current mean train loss 1807.74546955404
INFO:root:current train perplexity4.161766529083252
INFO:root:current mean train loss 1808.8269907054882
INFO:root:current train perplexity4.162712097167969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.80s/it]
INFO:root:final mean train loss: 1808.3824565693158
INFO:root:final train perplexity: 4.16284704208374
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it]
INFO:root:eval mean loss: 2874.6283270575263
INFO:root:eval perplexity: 10.57869815826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:00:56<4:00:08, 327.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1805.1692277496936
INFO:root:current train perplexity4.146437644958496
INFO:root:current mean train loss 1803.9120366178602
INFO:root:current train perplexity4.139309883117676
INFO:root:current mean train loss 1801.212942176606
INFO:root:current train perplexity4.142782688140869
INFO:root:current mean train loss 1799.779131332354
INFO:root:current train perplexity4.13218879699707
INFO:root:current mean train loss 1799.634533123008
INFO:root:current train perplexity4.131948471069336
INFO:root:current mean train loss 1801.493397125964
INFO:root:current train perplexity4.134039878845215
INFO:root:current mean train loss 1802.8788336828557
INFO:root:current train perplexity4.138308525085449
INFO:root:current mean train loss 1800.390235870402
INFO:root:current train perplexity4.136405944824219
INFO:root:current mean train loss 1799.8212519106658
INFO:root:current train perplexity4.136544704437256
INFO:root:current mean train loss 1799.5442904724057
INFO:root:current train perplexity4.137742519378662
INFO:root:current mean train loss 1800.9574787637146
INFO:root:current train perplexity4.141750335693359
INFO:root:current mean train loss 1801.99057481436
INFO:root:current train perplexity4.141330718994141
INFO:root:current mean train loss 1803.5807867377973
INFO:root:current train perplexity4.142739772796631
INFO:root:current mean train loss 1804.3942743692462
INFO:root:current train perplexity4.1444525718688965
INFO:root:current mean train loss 1804.4880261726826
INFO:root:current train perplexity4.145792007446289
INFO:root:current mean train loss 1804.669947847407
INFO:root:current train perplexity4.14741849899292
INFO:root:current mean train loss 1804.4157635730949
INFO:root:current train perplexity4.147145748138428
INFO:root:current mean train loss 1804.630245189133
INFO:root:current train perplexity4.148414134979248
INFO:root:current mean train loss 1805.4077576441998
INFO:root:current train perplexity4.149697780609131
INFO:root:current mean train loss 1804.67638941168
INFO:root:current train perplexity4.148975849151611

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.02s/it]
INFO:root:final mean train loss: 1804.149246223515
INFO:root:final train perplexity: 4.1489715576171875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it]
INFO:root:eval mean loss: 2873.915741425019
INFO:root:eval perplexity: 10.572513580322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:06:20<3:53:48, 326.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.8333847943475
INFO:root:current train perplexity4.079649448394775
INFO:root:current mean train loss 1781.0665726434618
INFO:root:current train perplexity4.0912861824035645
INFO:root:current mean train loss 1791.4331082016674
INFO:root:current train perplexity4.102197170257568
INFO:root:current mean train loss 1789.2454273389733
INFO:root:current train perplexity4.103595733642578
INFO:root:current mean train loss 1791.9960074139456
INFO:root:current train perplexity4.107346534729004
INFO:root:current mean train loss 1793.4073580889635
INFO:root:current train perplexity4.11215353012085
INFO:root:current mean train loss 1792.7926526098195
INFO:root:current train perplexity4.110929012298584
INFO:root:current mean train loss 1793.724135716756
INFO:root:current train perplexity4.1138916015625
INFO:root:current mean train loss 1795.7141871298513
INFO:root:current train perplexity4.116833209991455
INFO:root:current mean train loss 1798.452951100247
INFO:root:current train perplexity4.123530864715576
INFO:root:current mean train loss 1797.2774005561287
INFO:root:current train perplexity4.124335765838623
INFO:root:current mean train loss 1797.3316366117294
INFO:root:current train perplexity4.126932621002197
INFO:root:current mean train loss 1799.0282149931609
INFO:root:current train perplexity4.129487991333008
INFO:root:current mean train loss 1797.6154264929698
INFO:root:current train perplexity4.130205154418945
INFO:root:current mean train loss 1798.5248924484044
INFO:root:current train perplexity4.134680271148682
INFO:root:current mean train loss 1799.1353193010602
INFO:root:current train perplexity4.1349687576293945
INFO:root:current mean train loss 1799.403808008281
INFO:root:current train perplexity4.134673118591309
INFO:root:current mean train loss 1800.2534930889424
INFO:root:current train perplexity4.136023044586182
INFO:root:current mean train loss 1800.546427038548
INFO:root:current train perplexity4.136502742767334
INFO:root:current mean train loss 1801.359061636576
INFO:root:current train perplexity4.138969421386719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.88s/it]
INFO:root:final mean train loss: 1801.0352412929333
INFO:root:final train perplexity: 4.138795375823975
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.39s/it]
INFO:root:eval mean loss: 2872.7509428373687
INFO:root:eval perplexity: 10.56241512298584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:11:44<3:47:55, 325.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1795.4969453699448
INFO:root:current train perplexity4.129317760467529
INFO:root:current mean train loss 1792.7066287478885
INFO:root:current train perplexity4.109793186187744
INFO:root:current mean train loss 1787.6469375342654
INFO:root:current train perplexity4.093366622924805
INFO:root:current mean train loss 1786.4924693714488
INFO:root:current train perplexity4.0902485847473145
INFO:root:current mean train loss 1789.0215405021745
INFO:root:current train perplexity4.0957465171813965
INFO:root:current mean train loss 1789.5786729600695
INFO:root:current train perplexity4.099091053009033
INFO:root:current mean train loss 1786.4532322793111
INFO:root:current train perplexity4.097945690155029
INFO:root:current mean train loss 1788.3696771123607
INFO:root:current train perplexity4.0987749099731445
INFO:root:current mean train loss 1789.613773531294
INFO:root:current train perplexity4.103309154510498
INFO:root:current mean train loss 1790.195329230449
INFO:root:current train perplexity4.107463359832764
INFO:root:current mean train loss 1790.8480702764978
INFO:root:current train perplexity4.1064772605896
INFO:root:current mean train loss 1792.2318260482596
INFO:root:current train perplexity4.109893321990967
INFO:root:current mean train loss 1791.897320152906
INFO:root:current train perplexity4.112395286560059
INFO:root:current mean train loss 1793.2625511196977
INFO:root:current train perplexity4.11346960067749
INFO:root:current mean train loss 1793.5636318425136
INFO:root:current train perplexity4.115957736968994
INFO:root:current mean train loss 1794.1383141358192
INFO:root:current train perplexity4.120567798614502
INFO:root:current mean train loss 1794.4263535677856
INFO:root:current train perplexity4.122413635253906
INFO:root:current mean train loss 1796.0703724067753
INFO:root:current train perplexity4.124431610107422
INFO:root:current mean train loss 1796.6085021163171
INFO:root:current train perplexity4.125284671783447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.27s/it]
INFO:root:final mean train loss: 1797.7775983555534
INFO:root:final train perplexity: 4.128175735473633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it]
INFO:root:eval mean loss: 2875.708300341357
INFO:root:eval perplexity: 10.588074684143066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:17:25<3:45:33, 330.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1843.4380493164062
INFO:root:current train perplexity4.242984771728516
INFO:root:current mean train loss 1793.5362608666514
INFO:root:current train perplexity4.084473133087158
INFO:root:current mean train loss 1786.1396659624459
INFO:root:current train perplexity4.084991931915283
INFO:root:current mean train loss 1783.694165766634
INFO:root:current train perplexity4.077260494232178
INFO:root:current mean train loss 1786.905985514323
INFO:root:current train perplexity4.086225986480713
INFO:root:current mean train loss 1791.0547426991254
INFO:root:current train perplexity4.094364643096924
INFO:root:current mean train loss 1789.9591768081007
INFO:root:current train perplexity4.095794200897217
INFO:root:current mean train loss 1793.235026737224
INFO:root:current train perplexity4.10180139541626
INFO:root:current mean train loss 1792.8690783721847
INFO:root:current train perplexity4.109133243560791
INFO:root:current mean train loss 1791.7365027044934
INFO:root:current train perplexity4.109787464141846
INFO:root:current mean train loss 1791.105120934888
INFO:root:current train perplexity4.109992980957031
INFO:root:current mean train loss 1791.8939449358766
INFO:root:current train perplexity4.109893798828125
INFO:root:current mean train loss 1791.3875472438515
INFO:root:current train perplexity4.110113143920898
INFO:root:current mean train loss 1791.9732756958945
INFO:root:current train perplexity4.112349987030029
INFO:root:current mean train loss 1792.1229592838913
INFO:root:current train perplexity4.113115310668945
INFO:root:current mean train loss 1793.8558132613546
INFO:root:current train perplexity4.113254547119141
INFO:root:current mean train loss 1794.3945804743582
INFO:root:current train perplexity4.113323211669922
INFO:root:current mean train loss 1794.1161176275843
INFO:root:current train perplexity4.113916397094727
INFO:root:current mean train loss 1794.0203229457504
INFO:root:current train perplexity4.113592147827148
INFO:root:current mean train loss 1793.8091247109335
INFO:root:current train perplexity4.114465236663818

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it]
INFO:root:final mean train loss: 1793.8704352289874
INFO:root:final train perplexity: 4.115474224090576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 2876.623493366413
INFO:root:eval perplexity: 10.59603214263916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:23:08<3:42:44, 334.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.0177258943256
INFO:root:current train perplexity4.072444438934326
INFO:root:current mean train loss 1779.0586768398766
INFO:root:current train perplexity4.096858978271484
INFO:root:current mean train loss 1791.3899962542807
INFO:root:current train perplexity4.102489471435547
INFO:root:current mean train loss 1791.2100554558924
INFO:root:current train perplexity4.1047773361206055
INFO:root:current mean train loss 1791.7376373946524
INFO:root:current train perplexity4.1065568923950195
INFO:root:current mean train loss 1789.5683088063734
INFO:root:current train perplexity4.107969760894775
INFO:root:current mean train loss 1788.3243449616316
INFO:root:current train perplexity4.103520393371582
INFO:root:current mean train loss 1785.4494673048505
INFO:root:current train perplexity4.100030422210693
INFO:root:current mean train loss 1785.2231188949938
INFO:root:current train perplexity4.099461078643799
INFO:root:current mean train loss 1784.9569369410535
INFO:root:current train perplexity4.09616756439209
INFO:root:current mean train loss 1787.659280434441
INFO:root:current train perplexity4.098794460296631
INFO:root:current mean train loss 1787.629141663525
INFO:root:current train perplexity4.100700378417969
INFO:root:current mean train loss 1787.8611058148329
INFO:root:current train perplexity4.099616050720215
INFO:root:current mean train loss 1786.8177305139131
INFO:root:current train perplexity4.097557067871094
INFO:root:current mean train loss 1788.0906760475852
INFO:root:current train perplexity4.100908279418945
INFO:root:current mean train loss 1788.3926514154048
INFO:root:current train perplexity4.101790904998779
INFO:root:current mean train loss 1788.5820485162765
INFO:root:current train perplexity4.10114049911499
INFO:root:current mean train loss 1789.7731783047466
INFO:root:current train perplexity4.102038860321045
INFO:root:current mean train loss 1790.3568621232262
INFO:root:current train perplexity4.103655815124512
INFO:root:current mean train loss 1791.4241038168886
INFO:root:current train perplexity4.105391502380371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.11s/it]
INFO:root:final mean train loss: 1790.961458345645
INFO:root:final train perplexity: 4.106043815612793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it]
INFO:root:eval mean loss: 2880.0700500304993
INFO:root:eval perplexity: 10.626041412353516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:28:45<3:37:42, 334.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.8777635362412
INFO:root:current train perplexity4.03824520111084
INFO:root:current mean train loss 1775.4833006017348
INFO:root:current train perplexity4.041416168212891
INFO:root:current mean train loss 1782.0826659121756
INFO:root:current train perplexity4.066315174102783
INFO:root:current mean train loss 1784.6291405814034
INFO:root:current train perplexity4.0868988037109375
INFO:root:current mean train loss 1786.1694985485951
INFO:root:current train perplexity4.088850021362305
INFO:root:current mean train loss 1787.5284947637301
INFO:root:current train perplexity4.090206623077393
INFO:root:current mean train loss 1786.18201297784
INFO:root:current train perplexity4.08873176574707
INFO:root:current mean train loss 1787.7974909906802
INFO:root:current train perplexity4.092313766479492
INFO:root:current mean train loss 1789.7555144825621
INFO:root:current train perplexity4.098836898803711
INFO:root:current mean train loss 1789.8276950151492
INFO:root:current train perplexity4.098309516906738
INFO:root:current mean train loss 1788.494067100024
INFO:root:current train perplexity4.094414234161377
INFO:root:current mean train loss 1788.4260425836267
INFO:root:current train perplexity4.0926713943481445
INFO:root:current mean train loss 1787.966362419252
INFO:root:current train perplexity4.091090202331543
INFO:root:current mean train loss 1788.2809471084686
INFO:root:current train perplexity4.091529369354248
INFO:root:current mean train loss 1787.8291742436402
INFO:root:current train perplexity4.0930938720703125
INFO:root:current mean train loss 1787.6664272944133
INFO:root:current train perplexity4.0941338539123535
INFO:root:current mean train loss 1787.0549413405888
INFO:root:current train perplexity4.093405246734619
INFO:root:current mean train loss 1787.185991419076
INFO:root:current train perplexity4.093224048614502
INFO:root:current mean train loss 1787.3464251084006
INFO:root:current train perplexity4.0931396484375
INFO:root:current mean train loss 1787.8833885508136
INFO:root:current train perplexity4.094503879547119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.54s/it]
INFO:root:final mean train loss: 1787.459915815191
INFO:root:final train perplexity: 4.094719886779785
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2880.484816359328
INFO:root:eval perplexity: 10.629656791687012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:34:25<3:33:01, 336.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.9703092755012
INFO:root:current train perplexity4.055920600891113
INFO:root:current mean train loss 1771.8019389233557
INFO:root:current train perplexity4.057037353515625
INFO:root:current mean train loss 1773.4689632611783
INFO:root:current train perplexity4.055309295654297
INFO:root:current mean train loss 1778.392201539815
INFO:root:current train perplexity4.068928241729736
INFO:root:current mean train loss 1777.894069646368
INFO:root:current train perplexity4.068315029144287
INFO:root:current mean train loss 1780.2926672164613
INFO:root:current train perplexity4.0736002922058105
INFO:root:current mean train loss 1780.5666223499713
INFO:root:current train perplexity4.072047233581543
INFO:root:current mean train loss 1781.9320449322502
INFO:root:current train perplexity4.075665473937988
INFO:root:current mean train loss 1784.2501917634452
INFO:root:current train perplexity4.0785980224609375
INFO:root:current mean train loss 1784.2618506832864
INFO:root:current train perplexity4.077302932739258
INFO:root:current mean train loss 1784.9033725952265
INFO:root:current train perplexity4.078301906585693
INFO:root:current mean train loss 1784.8503375619987
INFO:root:current train perplexity4.080509662628174
INFO:root:current mean train loss 1784.0569339639553
INFO:root:current train perplexity4.081073760986328
INFO:root:current mean train loss 1784.0326849802811
INFO:root:current train perplexity4.080434322357178
INFO:root:current mean train loss 1784.97284343008
INFO:root:current train perplexity4.083183765411377
INFO:root:current mean train loss 1785.4368148184712
INFO:root:current train perplexity4.08502197265625
INFO:root:current mean train loss 1785.0610250391098
INFO:root:current train perplexity4.085221290588379
INFO:root:current mean train loss 1784.7313759559506
INFO:root:current train perplexity4.084252834320068
INFO:root:current mean train loss 1784.7063931641678
INFO:root:current train perplexity4.084928035736084
INFO:root:current mean train loss 1784.8306883515545
INFO:root:current train perplexity4.08436918258667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it]
INFO:root:final mean train loss: 1784.1590193894194
INFO:root:final train perplexity: 4.0840744972229
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it]
INFO:root:eval mean loss: 2886.004641604495
INFO:root:eval perplexity: 10.677910804748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:39:52<3:25:50, 333.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.0998046875
INFO:root:current train perplexity4.086790084838867
INFO:root:current mean train loss 1782.0105899586397
INFO:root:current train perplexity4.0788750648498535
INFO:root:current mean train loss 1781.6957524052373
INFO:root:current train perplexity4.070282936096191
INFO:root:current mean train loss 1777.2939545502534
INFO:root:current train perplexity4.057841777801514
INFO:root:current mean train loss 1779.2027125581783
INFO:root:current train perplexity4.069056034088135
INFO:root:current mean train loss 1777.8369515402276
INFO:root:current train perplexity4.072098731994629
INFO:root:current mean train loss 1779.3258519414646
INFO:root:current train perplexity4.0674824714660645
INFO:root:current mean train loss 1780.9145501471185
INFO:root:current train perplexity4.070882320404053
INFO:root:current mean train loss 1782.8359220658226
INFO:root:current train perplexity4.07352352142334
INFO:root:current mean train loss 1783.9876030676144
INFO:root:current train perplexity4.074029445648193
INFO:root:current mean train loss 1783.5372160439179
INFO:root:current train perplexity4.07224178314209
INFO:root:current mean train loss 1783.0888384957598
INFO:root:current train perplexity4.0689826011657715
INFO:root:current mean train loss 1783.1898234690268
INFO:root:current train perplexity4.067984580993652
INFO:root:current mean train loss 1782.3943687271899
INFO:root:current train perplexity4.067845344543457
INFO:root:current mean train loss 1781.969229977147
INFO:root:current train perplexity4.068563938140869
INFO:root:current mean train loss 1781.2246139623558
INFO:root:current train perplexity4.067727088928223
INFO:root:current mean train loss 1781.6767164401665
INFO:root:current train perplexity4.070405960083008
INFO:root:current mean train loss 1781.862881245586
INFO:root:current train perplexity4.070422172546387
INFO:root:current mean train loss 1781.578824260528
INFO:root:current train perplexity4.071565628051758
INFO:root:current mean train loss 1781.5666842233106
INFO:root:current train perplexity4.07377290725708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.14s/it]
INFO:root:final mean train loss: 1781.1194656533662
INFO:root:final train perplexity: 4.074295520782471
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2882.977474544857
INFO:root:eval perplexity: 10.651421546936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:45:13<3:17:53, 329.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1777.543602954382
INFO:root:current train perplexity4.04171895980835
INFO:root:current mean train loss 1779.485468410553
INFO:root:current train perplexity4.056620121002197
INFO:root:current mean train loss 1778.2075863083896
INFO:root:current train perplexity4.047067165374756
INFO:root:current mean train loss 1771.4515049660852
INFO:root:current train perplexity4.047782897949219
INFO:root:current mean train loss 1770.0736577780094
INFO:root:current train perplexity4.048278331756592
INFO:root:current mean train loss 1768.3687332387271
INFO:root:current train perplexity4.04549503326416
INFO:root:current mean train loss 1769.1497841825305
INFO:root:current train perplexity4.046128273010254
INFO:root:current mean train loss 1768.81706732201
INFO:root:current train perplexity4.04416561126709
INFO:root:current mean train loss 1772.561920200421
INFO:root:current train perplexity4.0486741065979
INFO:root:current mean train loss 1774.2241207227157
INFO:root:current train perplexity4.051586627960205
INFO:root:current mean train loss 1774.1156622387448
INFO:root:current train perplexity4.051593780517578
INFO:root:current mean train loss 1775.66925701858
INFO:root:current train perplexity4.057184219360352
INFO:root:current mean train loss 1775.490113158326
INFO:root:current train perplexity4.05679988861084
INFO:root:current mean train loss 1776.3929989903456
INFO:root:current train perplexity4.059074401855469
INFO:root:current mean train loss 1777.4771860683213
INFO:root:current train perplexity4.060244083404541
INFO:root:current mean train loss 1778.4434039110497
INFO:root:current train perplexity4.06330680847168
INFO:root:current mean train loss 1777.7931787369869
INFO:root:current train perplexity4.06384801864624
INFO:root:current mean train loss 1777.4923380556625
INFO:root:current train perplexity4.062281608581543
INFO:root:current mean train loss 1777.562027761907
INFO:root:current train perplexity4.062433242797852

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.27s/it]
INFO:root:final mean train loss: 1777.7206558173675
INFO:root:final train perplexity: 4.063389301300049
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.61s/it]
INFO:root:eval mean loss: 2885.437115826764
INFO:root:eval perplexity: 10.67293930053711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:50:47<3:13:12, 331.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.7867431640625
INFO:root:current train perplexity3.9904088973999023
INFO:root:current mean train loss 1761.3568725585938
INFO:root:current train perplexity4.023255348205566
INFO:root:current mean train loss 1776.5694783528645
INFO:root:current train perplexity4.054181098937988
INFO:root:current mean train loss 1772.756896571109
INFO:root:current train perplexity4.040523529052734
INFO:root:current mean train loss 1772.6825573609608
INFO:root:current train perplexity4.0431084632873535
INFO:root:current mean train loss 1773.4427417573474
INFO:root:current train perplexity4.043215274810791
INFO:root:current mean train loss 1772.9700438644713
INFO:root:current train perplexity4.040126323699951
INFO:root:current mean train loss 1772.7326304695823
INFO:root:current train perplexity4.042360782623291
INFO:root:current mean train loss 1774.9647646472229
INFO:root:current train perplexity4.048035621643066
INFO:root:current mean train loss 1775.1649804579474
INFO:root:current train perplexity4.046468734741211
INFO:root:current mean train loss 1774.9210996589813
INFO:root:current train perplexity4.044826507568359
INFO:root:current mean train loss 1773.9475767716117
INFO:root:current train perplexity4.045449256896973
INFO:root:current mean train loss 1774.4085090104925
INFO:root:current train perplexity4.047328948974609
INFO:root:current mean train loss 1774.8082060082559
INFO:root:current train perplexity4.049095153808594
INFO:root:current mean train loss 1774.5029183846932
INFO:root:current train perplexity4.050033092498779
INFO:root:current mean train loss 1774.007224387311
INFO:root:current train perplexity4.049230575561523
INFO:root:current mean train loss 1774.2279103723845
INFO:root:current train perplexity4.048544406890869
INFO:root:current mean train loss 1773.4381261118142
INFO:root:current train perplexity4.04967737197876
INFO:root:current mean train loss 1773.7124063360718
INFO:root:current train perplexity4.051163673400879
INFO:root:current mean train loss 1774.5055740099995
INFO:root:current train perplexity4.0525407791137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.78s/it]
INFO:root:final mean train loss: 1774.9512075788737
INFO:root:final train perplexity: 4.0545244216918945
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it]
INFO:root:eval mean loss: 2884.742875199418
INFO:root:eval perplexity: 10.666862487792969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [5:56:14<3:06:53, 329.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.7444661458333
INFO:root:current train perplexity3.9507994651794434
INFO:root:current mean train loss 1768.3409676039514
INFO:root:current train perplexity3.9945554733276367
INFO:root:current mean train loss 1761.353452104249
INFO:root:current train perplexity4.010105133056641
INFO:root:current mean train loss 1768.659515856211
INFO:root:current train perplexity4.031850814819336
INFO:root:current mean train loss 1771.7682145723538
INFO:root:current train perplexity4.040010929107666
INFO:root:current mean train loss 1771.7884266097349
INFO:root:current train perplexity4.042892932891846
INFO:root:current mean train loss 1771.5920498612998
INFO:root:current train perplexity4.041090488433838
INFO:root:current mean train loss 1770.5950152308535
INFO:root:current train perplexity4.033054828643799
INFO:root:current mean train loss 1771.5541647238506
INFO:root:current train perplexity4.034924030303955
INFO:root:current mean train loss 1772.0635462790954
INFO:root:current train perplexity4.035533428192139
INFO:root:current mean train loss 1770.9728156228957
INFO:root:current train perplexity4.036279678344727
INFO:root:current mean train loss 1771.0131891473502
INFO:root:current train perplexity4.037259578704834
INFO:root:current mean train loss 1771.0681619230204
INFO:root:current train perplexity4.037052154541016
INFO:root:current mean train loss 1769.207835195283
INFO:root:current train perplexity4.0379252433776855
INFO:root:current mean train loss 1770.0309724425197
INFO:root:current train perplexity4.039879322052002
INFO:root:current mean train loss 1769.7726310815253
INFO:root:current train perplexity4.040842533111572
INFO:root:current mean train loss 1770.5698879272536
INFO:root:current train perplexity4.041009902954102
INFO:root:current mean train loss 1770.6409475890653
INFO:root:current train perplexity4.042503356933594
INFO:root:current mean train loss 1771.7362710784125
INFO:root:current train perplexity4.0428900718688965
INFO:root:current mean train loss 1771.2348966424754
INFO:root:current train perplexity4.0422492027282715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it]
INFO:root:final mean train loss: 1771.8094310058348
INFO:root:final train perplexity: 4.044489860534668
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 2887.36865234375
INFO:root:eval perplexity: 10.68986988067627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:01:36<3:00:09, 327.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.1708759508635
INFO:root:current train perplexity4.004843711853027
INFO:root:current mean train loss 1753.879097316576
INFO:root:current train perplexity4.001161575317383
INFO:root:current mean train loss 1757.508009966682
INFO:root:current train perplexity4.00692892074585
INFO:root:current mean train loss 1758.3641725799741
INFO:root:current train perplexity4.0153656005859375
INFO:root:current mean train loss 1761.1904720498003
INFO:root:current train perplexity4.020209312438965
INFO:root:current mean train loss 1765.8508008084775
INFO:root:current train perplexity4.025171279907227
INFO:root:current mean train loss 1769.2330293565708
INFO:root:current train perplexity4.028050422668457
INFO:root:current mean train loss 1765.8001087054326
INFO:root:current train perplexity4.024889945983887
INFO:root:current mean train loss 1767.1176887457582
INFO:root:current train perplexity4.026350021362305
INFO:root:current mean train loss 1769.247028147488
INFO:root:current train perplexity4.028845310211182
INFO:root:current mean train loss 1769.456161940029
INFO:root:current train perplexity4.031803607940674
INFO:root:current mean train loss 1770.4876530920474
INFO:root:current train perplexity4.030832290649414
INFO:root:current mean train loss 1770.262552436989
INFO:root:current train perplexity4.030804634094238
INFO:root:current mean train loss 1769.4342730740261
INFO:root:current train perplexity4.031468391418457
INFO:root:current mean train loss 1769.6313752451592
INFO:root:current train perplexity4.0326995849609375
INFO:root:current mean train loss 1770.7089858036513
INFO:root:current train perplexity4.034785270690918
INFO:root:current mean train loss 1770.401807847914
INFO:root:current train perplexity4.03501033782959
INFO:root:current mean train loss 1770.9345427097194
INFO:root:current train perplexity4.037391185760498
INFO:root:current mean train loss 1771.3886513528419
INFO:root:current train perplexity4.038391590118408
INFO:root:current mean train loss 1770.1134941486873
INFO:root:current train perplexity4.037660598754883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.43s/it]
INFO:root:final mean train loss: 1769.8653463497344
INFO:root:final train perplexity: 4.038293838500977
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 2888.853781027121
INFO:root:eval perplexity: 10.702906608581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:07:00<2:54:03, 326.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.2415460759944
INFO:root:current train perplexity3.994408130645752
INFO:root:current mean train loss 1768.3247275075605
INFO:root:current train perplexity4.004025936126709
INFO:root:current mean train loss 1766.1507381663603
INFO:root:current train perplexity4.012871742248535
INFO:root:current mean train loss 1769.624463922205
INFO:root:current train perplexity4.024117946624756
INFO:root:current mean train loss 1768.7344337547217
INFO:root:current train perplexity4.02808141708374
INFO:root:current mean train loss 1766.1165538341074
INFO:root:current train perplexity4.021122455596924
INFO:root:current mean train loss 1765.630298783397
INFO:root:current train perplexity4.020362854003906
INFO:root:current mean train loss 1765.5061625297496
INFO:root:current train perplexity4.0150885581970215
INFO:root:current mean train loss 1764.375940298337
INFO:root:current train perplexity4.014590740203857
INFO:root:current mean train loss 1765.0779007996564
INFO:root:current train perplexity4.0164031982421875
INFO:root:current mean train loss 1764.536069289655
INFO:root:current train perplexity4.0163679122924805
INFO:root:current mean train loss 1766.3267751454275
INFO:root:current train perplexity4.019957542419434
INFO:root:current mean train loss 1766.7924844567044
INFO:root:current train perplexity4.021161079406738
INFO:root:current mean train loss 1766.7812113519085
INFO:root:current train perplexity4.022729396820068
INFO:root:current mean train loss 1767.4362092427782
INFO:root:current train perplexity4.024258136749268
INFO:root:current mean train loss 1767.9343764130326
INFO:root:current train perplexity4.024951934814453
INFO:root:current mean train loss 1768.9547981377455
INFO:root:current train perplexity4.027778625488281
INFO:root:current mean train loss 1767.8863174829728
INFO:root:current train perplexity4.0266642570495605
INFO:root:current mean train loss 1767.4715441927435
INFO:root:current train perplexity4.026770114898682
INFO:root:current mean train loss 1766.9488477311781
INFO:root:current train perplexity4.026761054992676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.67s/it]
INFO:root:final mean train loss: 1766.4815470069811
INFO:root:final train perplexity: 4.027531147003174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]
INFO:root:eval mean loss: 2891.4832628038193
INFO:root:eval perplexity: 10.726022720336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:12:27<2:48:41, 326.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1746.8473256429036
INFO:root:current train perplexity3.9979872703552246
INFO:root:current mean train loss 1752.0753216410792
INFO:root:current train perplexity4.003321647644043
INFO:root:current mean train loss 1753.3092310288373
INFO:root:current train perplexity4.007767200469971
INFO:root:current mean train loss 1753.3560876333586
INFO:root:current train perplexity4.004589080810547
INFO:root:current mean train loss 1758.071164405952
INFO:root:current train perplexity4.0063958168029785
INFO:root:current mean train loss 1760.3671766161085
INFO:root:current train perplexity4.014003753662109
INFO:root:current mean train loss 1761.5745864141554
INFO:root:current train perplexity4.018056869506836
INFO:root:current mean train loss 1760.5363113324258
INFO:root:current train perplexity4.015468597412109
INFO:root:current mean train loss 1758.772202797986
INFO:root:current train perplexity4.01494026184082
INFO:root:current mean train loss 1758.9704136475614
INFO:root:current train perplexity4.014609336853027
INFO:root:current mean train loss 1758.8242771661103
INFO:root:current train perplexity4.014327049255371
INFO:root:current mean train loss 1760.3231537594322
INFO:root:current train perplexity4.01615047454834
INFO:root:current mean train loss 1760.7363121944404
INFO:root:current train perplexity4.016096591949463
INFO:root:current mean train loss 1760.009096017732
INFO:root:current train perplexity4.016246795654297
INFO:root:current mean train loss 1760.9628341508949
INFO:root:current train perplexity4.017812728881836
INFO:root:current mean train loss 1760.9929575058643
INFO:root:current train perplexity4.0178117752075195
INFO:root:current mean train loss 1762.5798580771998
INFO:root:current train perplexity4.018699645996094
INFO:root:current mean train loss 1763.2788419357541
INFO:root:current train perplexity4.019046783447266
INFO:root:current mean train loss 1764.457652882633
INFO:root:current train perplexity4.020108699798584
INFO:root:current mean train loss 1764.7692840761877
INFO:root:current train perplexity4.020930767059326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.65s/it]
INFO:root:final mean train loss: 1764.5783050583277
INFO:root:final train perplexity: 4.021490573883057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 2892.367355392502
INFO:root:eval perplexity: 10.733809471130371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:17:56<2:43:39, 327.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.8526940506497
INFO:root:current train perplexity4.0338544845581055
INFO:root:current mean train loss 1745.6153041294642
INFO:root:current train perplexity4.00417423248291
INFO:root:current mean train loss 1752.1511200901546
INFO:root:current train perplexity4.005473613739014
INFO:root:current mean train loss 1750.5936925736062
INFO:root:current train perplexity4.000360012054443
INFO:root:current mean train loss 1754.6948983596146
INFO:root:current train perplexity4.004263401031494
INFO:root:current mean train loss 1754.4548408236285
INFO:root:current train perplexity4.004773139953613
INFO:root:current mean train loss 1754.9823671293882
INFO:root:current train perplexity4.002017021179199
INFO:root:current mean train loss 1754.2351105161795
INFO:root:current train perplexity3.997346878051758
INFO:root:current mean train loss 1756.1998937754852
INFO:root:current train perplexity4.000429153442383
INFO:root:current mean train loss 1758.6553140453188
INFO:root:current train perplexity4.001136302947998
INFO:root:current mean train loss 1757.102651044357
INFO:root:current train perplexity4.001018524169922
INFO:root:current mean train loss 1756.5193122626354
INFO:root:current train perplexity4.002284526824951
INFO:root:current mean train loss 1756.6988049988788
INFO:root:current train perplexity4.002437114715576
INFO:root:current mean train loss 1756.8331637179963
INFO:root:current train perplexity4.003683090209961
INFO:root:current mean train loss 1757.6632060402587
INFO:root:current train perplexity4.006115913391113
INFO:root:current mean train loss 1757.5313082311498
INFO:root:current train perplexity4.006555557250977
INFO:root:current mean train loss 1758.7290869487538
INFO:root:current train perplexity4.00670051574707
INFO:root:current mean train loss 1759.687055729567
INFO:root:current train perplexity4.006529808044434
INFO:root:current mean train loss 1760.9170991363444
INFO:root:current train perplexity4.007907390594482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.42s/it]
INFO:root:final mean train loss: 1761.2219277063043
INFO:root:final train perplexity: 4.010859489440918
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it]
INFO:root:eval mean loss: 2890.2371397276183
INFO:root:eval perplexity: 10.715062141418457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [6:23:32<2:39:24, 329.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1811.3335774739583
INFO:root:current train perplexity4.0470709800720215
INFO:root:current mean train loss 1751.1852175154777
INFO:root:current train perplexity3.9581193923950195
INFO:root:current mean train loss 1746.3220422244767
INFO:root:current train perplexity3.9629695415496826
INFO:root:current mean train loss 1747.4003411585988
INFO:root:current train perplexity3.9638540744781494
INFO:root:current mean train loss 1749.6622371579626
INFO:root:current train perplexity3.9748024940490723
INFO:root:current mean train loss 1749.8555647657795
INFO:root:current train perplexity3.977850914001465
INFO:root:current mean train loss 1752.0736335779575
INFO:root:current train perplexity3.9837582111358643
INFO:root:current mean train loss 1754.5937015868449
INFO:root:current train perplexity3.989485740661621
INFO:root:current mean train loss 1756.0487099924396
INFO:root:current train perplexity3.9907896518707275
INFO:root:current mean train loss 1756.2446209568589
INFO:root:current train perplexity3.9914257526397705
INFO:root:current mean train loss 1757.116617191383
INFO:root:current train perplexity3.995837450027466
INFO:root:current mean train loss 1752.9475256590472
INFO:root:current train perplexity3.991429090499878
INFO:root:current mean train loss 1754.8185213256634
INFO:root:current train perplexity3.9928085803985596
INFO:root:current mean train loss 1756.5232777617427
INFO:root:current train perplexity3.9945311546325684
INFO:root:current mean train loss 1757.083143600529
INFO:root:current train perplexity3.997812032699585
INFO:root:current mean train loss 1757.2895840952597
INFO:root:current train perplexity3.9965195655822754
INFO:root:current mean train loss 1757.4070620032057
INFO:root:current train perplexity3.999629497528076
INFO:root:current mean train loss 1756.4225699993817
INFO:root:current train perplexity3.9985482692718506
INFO:root:current mean train loss 1757.5045991984184
INFO:root:current train perplexity4.001511096954346
INFO:root:current mean train loss 1759.7104675357014
INFO:root:current train perplexity4.004005432128906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.24s/it]
INFO:root:final mean train loss: 1759.651234344467
INFO:root:final train perplexity: 4.005893707275391
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 2894.0580028270456
INFO:root:eval perplexity: 10.748708724975586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:29:09<2:34:58, 332.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1774.5486476732337
INFO:root:current train perplexity3.980625867843628
INFO:root:current mean train loss 1764.1955893911966
INFO:root:current train perplexity3.991715908050537
INFO:root:current mean train loss 1755.950873541725
INFO:root:current train perplexity3.9811480045318604
INFO:root:current mean train loss 1755.1497591095442
INFO:root:current train perplexity3.980128288269043
INFO:root:current mean train loss 1755.1828318927305
INFO:root:current train perplexity3.9832401275634766
INFO:root:current mean train loss 1755.8624213895196
INFO:root:current train perplexity3.9832770824432373
INFO:root:current mean train loss 1754.7920356860704
INFO:root:current train perplexity3.9808509349823
INFO:root:current mean train loss 1754.0435005916104
INFO:root:current train perplexity3.9871199131011963
INFO:root:current mean train loss 1754.0495380016896
INFO:root:current train perplexity3.987638473510742
INFO:root:current mean train loss 1755.1471634985696
INFO:root:current train perplexity3.990614891052246
INFO:root:current mean train loss 1756.4121565086984
INFO:root:current train perplexity3.991330623626709
INFO:root:current mean train loss 1756.4281717845615
INFO:root:current train perplexity3.992128610610962
INFO:root:current mean train loss 1756.116525745158
INFO:root:current train perplexity3.9928252696990967
INFO:root:current mean train loss 1755.7659399100353
INFO:root:current train perplexity3.9928696155548096
INFO:root:current mean train loss 1755.8389683265714
INFO:root:current train perplexity3.9940364360809326
INFO:root:current mean train loss 1756.7788994050857
INFO:root:current train perplexity3.9963200092315674
INFO:root:current mean train loss 1757.6423512080976
INFO:root:current train perplexity3.997311592102051
INFO:root:current mean train loss 1757.6288705428394
INFO:root:current train perplexity3.9971418380737305
INFO:root:current mean train loss 1757.655397114882
INFO:root:current train perplexity3.995447874069214
INFO:root:current mean train loss 1757.4195031033664
INFO:root:current train perplexity3.996570587158203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.43s/it]
INFO:root:final mean train loss: 1757.0732356007509
INFO:root:final train perplexity: 3.997758150100708
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.68s/it]
INFO:root:eval mean loss: 2894.5895365580423
INFO:root:eval perplexity: 10.753399848937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:34:40<2:29:14, 331.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.250341796875
INFO:root:current train perplexity3.9977285861968994
INFO:root:current mean train loss 1745.0503513881138
INFO:root:current train perplexity3.970881700515747
INFO:root:current mean train loss 1742.4652369181315
INFO:root:current train perplexity3.96860408782959
INFO:root:current mean train loss 1747.1202905991497
INFO:root:current train perplexity3.977846622467041
INFO:root:current mean train loss 1752.015669666637
INFO:root:current train perplexity3.982832193374634
INFO:root:current mean train loss 1752.3916978624131
INFO:root:current train perplexity3.9881343841552734
INFO:root:current mean train loss 1752.2106336593629
INFO:root:current train perplexity3.9809229373931885
INFO:root:current mean train loss 1752.1345544763512
INFO:root:current train perplexity3.9818780422210693
INFO:root:current mean train loss 1752.716914876302
INFO:root:current train perplexity3.9830055236816406
INFO:root:current mean train loss 1752.7468348726313
INFO:root:current train perplexity3.9859609603881836
INFO:root:current mean train loss 1753.4490912804238
INFO:root:current train perplexity3.988163471221924
INFO:root:current mean train loss 1753.5457551655015
INFO:root:current train perplexity3.9912595748901367
INFO:root:current mean train loss 1754.3506804435483
INFO:root:current train perplexity3.992095708847046
INFO:root:current mean train loss 1754.6117335077543
INFO:root:current train perplexity3.9915008544921875
INFO:root:current mean train loss 1753.7046338399252
INFO:root:current train perplexity3.9884543418884277
INFO:root:current mean train loss 1753.3336856990666
INFO:root:current train perplexity3.9882099628448486
INFO:root:current mean train loss 1754.042715751834
INFO:root:current train perplexity3.9886393547058105
INFO:root:current mean train loss 1754.2704005449668
INFO:root:current train perplexity3.98858380317688
INFO:root:current mean train loss 1754.7051034015158
INFO:root:current train perplexity3.989793539047241
INFO:root:current mean train loss 1754.9755939287008
INFO:root:current train perplexity3.989497661590576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it]
INFO:root:final mean train loss: 1754.3648344300577
INFO:root:final train perplexity: 3.989227056503296
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2894.548809062969
INFO:root:eval perplexity: 10.75304126739502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:40:11<2:23:38, 331.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.8618249725878
INFO:root:current train perplexity3.9531619548797607
INFO:root:current mean train loss 1759.9015677871218
INFO:root:current train perplexity3.9919962882995605
INFO:root:current mean train loss 1756.055447945799
INFO:root:current train perplexity3.9738872051239014
INFO:root:current mean train loss 1751.3200232241334
INFO:root:current train perplexity3.9702086448669434
INFO:root:current mean train loss 1747.0168606614127
INFO:root:current train perplexity3.9647037982940674
INFO:root:current mean train loss 1750.143434808755
INFO:root:current train perplexity3.975184917449951
INFO:root:current mean train loss 1750.4816047285246
INFO:root:current train perplexity3.970750570297241
INFO:root:current mean train loss 1748.8120381646302
INFO:root:current train perplexity3.9694221019744873
INFO:root:current mean train loss 1749.051541020183
INFO:root:current train perplexity3.9725213050842285
INFO:root:current mean train loss 1748.5626021717035
INFO:root:current train perplexity3.9714412689208984
INFO:root:current mean train loss 1747.6398633597814
INFO:root:current train perplexity3.9679818153381348
INFO:root:current mean train loss 1749.714324239007
INFO:root:current train perplexity3.9692304134368896
INFO:root:current mean train loss 1748.2676810641656
INFO:root:current train perplexity3.96819806098938
INFO:root:current mean train loss 1749.4064192972205
INFO:root:current train perplexity3.972832441329956
INFO:root:current mean train loss 1749.798457138491
INFO:root:current train perplexity3.9744713306427
INFO:root:current mean train loss 1750.102402252805
INFO:root:current train perplexity3.9763166904449463
INFO:root:current mean train loss 1750.7400860046866
INFO:root:current train perplexity3.977938652038574
INFO:root:current mean train loss 1750.8169065506945
INFO:root:current train perplexity3.977980375289917
INFO:root:current mean train loss 1752.3712724840764
INFO:root:current train perplexity3.982851266860962
INFO:root:current mean train loss 1751.9953814132762
INFO:root:current train perplexity3.981393337249756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.16s/it]
INFO:root:final mean train loss: 1751.9347881061287
INFO:root:final train perplexity: 3.9815893173217773
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it]
INFO:root:eval mean loss: 2894.327683640672
INFO:root:eval perplexity: 10.751087188720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:45:34<2:17:07, 329.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.1243352116765
INFO:root:current train perplexity3.9917101860046387
INFO:root:current mean train loss 1739.5167046908675
INFO:root:current train perplexity3.9560632705688477
INFO:root:current mean train loss 1745.8604981359774
INFO:root:current train perplexity3.9573514461517334
INFO:root:current mean train loss 1745.9204656427557
INFO:root:current train perplexity3.95398211479187
INFO:root:current mean train loss 1748.6387998685555
INFO:root:current train perplexity3.9632210731506348
INFO:root:current mean train loss 1747.425554122659
INFO:root:current train perplexity3.9676408767700195
INFO:root:current mean train loss 1746.5417654337443
INFO:root:current train perplexity3.9650683403015137
INFO:root:current mean train loss 1748.5106352576913
INFO:root:current train perplexity3.9698944091796875
INFO:root:current mean train loss 1748.279169636951
INFO:root:current train perplexity3.9677014350891113
INFO:root:current mean train loss 1749.8168969124984
INFO:root:current train perplexity3.9703586101531982
INFO:root:current mean train loss 1749.6685417075842
INFO:root:current train perplexity3.9683148860931396
INFO:root:current mean train loss 1749.8535926727866
INFO:root:current train perplexity3.9672861099243164
INFO:root:current mean train loss 1748.636529416454
INFO:root:current train perplexity3.967057704925537
INFO:root:current mean train loss 1750.7967496424956
INFO:root:current train perplexity3.9729886054992676
INFO:root:current mean train loss 1749.949189516065
INFO:root:current train perplexity3.9725656509399414
INFO:root:current mean train loss 1749.5334250075693
INFO:root:current train perplexity3.972886323928833
INFO:root:current mean train loss 1749.9933960252622
INFO:root:current train perplexity3.9744415283203125
INFO:root:current mean train loss 1749.8558200978105
INFO:root:current train perplexity3.9744632244110107
INFO:root:current mean train loss 1750.559384536336
INFO:root:current train perplexity3.975942850112915
INFO:root:current mean train loss 1750.635959180776
INFO:root:current train perplexity3.9763925075531006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.89s/it]
INFO:root:final mean train loss: 1750.3577246500035
INFO:root:final train perplexity: 3.976639986038208
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it]
INFO:root:eval mean loss: 2895.1650126689187
INFO:root:eval perplexity: 10.758480072021484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:51:09<2:12:20, 330.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.0640158181661
INFO:root:current train perplexity3.97552752494812
INFO:root:current mean train loss 1751.0504789502208
INFO:root:current train perplexity3.988962173461914
INFO:root:current mean train loss 1745.5375204708978
INFO:root:current train perplexity3.9701356887817383
INFO:root:current mean train loss 1744.989150415601
INFO:root:current train perplexity3.9641706943511963
INFO:root:current mean train loss 1745.5338475369144
INFO:root:current train perplexity3.9651174545288086
INFO:root:current mean train loss 1744.1386388271997
INFO:root:current train perplexity3.9569239616394043
INFO:root:current mean train loss 1744.2592549082513
INFO:root:current train perplexity3.957575798034668
INFO:root:current mean train loss 1746.9456885876757
INFO:root:current train perplexity3.9609429836273193
INFO:root:current mean train loss 1746.5917465946357
INFO:root:current train perplexity3.9619932174682617
INFO:root:current mean train loss 1746.531594654626
INFO:root:current train perplexity3.9634103775024414
INFO:root:current mean train loss 1747.4912894832007
INFO:root:current train perplexity3.9638583660125732
INFO:root:current mean train loss 1748.332551509367
INFO:root:current train perplexity3.965585947036743
INFO:root:current mean train loss 1747.4745239919696
INFO:root:current train perplexity3.9650702476501465
INFO:root:current mean train loss 1747.9046420242014
INFO:root:current train perplexity3.966945171356201
INFO:root:current mean train loss 1748.1664536371877
INFO:root:current train perplexity3.966492176055908
INFO:root:current mean train loss 1748.674480522151
INFO:root:current train perplexity3.9678595066070557
INFO:root:current mean train loss 1747.9462586712514
INFO:root:current train perplexity3.9656431674957275
INFO:root:current mean train loss 1748.2047594199296
INFO:root:current train perplexity3.9669594764709473
INFO:root:current mean train loss 1747.8747362997215
INFO:root:current train perplexity3.967259168624878

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.15s/it]
INFO:root:final mean train loss: 1747.9733192339968
INFO:root:final train perplexity: 3.969169855117798
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 2897.6968132683464
INFO:root:eval perplexity: 10.780852317810059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [6:56:54<2:08:23, 334.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1695.1398315429688
INFO:root:current train perplexity3.83492112159729
INFO:root:current mean train loss 1737.2635215476707
INFO:root:current train perplexity3.949671506881714
INFO:root:current mean train loss 1743.3310282780574
INFO:root:current train perplexity3.9458534717559814
INFO:root:current mean train loss 1744.5380023114094
INFO:root:current train perplexity3.951789617538452
INFO:root:current mean train loss 1745.1072803572113
INFO:root:current train perplexity3.9482851028442383
INFO:root:current mean train loss 1743.4584393839198
INFO:root:current train perplexity3.947601795196533
INFO:root:current mean train loss 1743.7421192369964
INFO:root:current train perplexity3.950660467147827
INFO:root:current mean train loss 1742.6991978877008
INFO:root:current train perplexity3.952392578125
INFO:root:current mean train loss 1745.8458454396466
INFO:root:current train perplexity3.9567394256591797
INFO:root:current mean train loss 1746.5536875451714
INFO:root:current train perplexity3.9596688747406006
INFO:root:current mean train loss 1747.1342203049433
INFO:root:current train perplexity3.959026336669922
INFO:root:current mean train loss 1745.4068488936991
INFO:root:current train perplexity3.9579546451568604
INFO:root:current mean train loss 1744.3681163661527
INFO:root:current train perplexity3.955498218536377
INFO:root:current mean train loss 1744.6809910765483
INFO:root:current train perplexity3.956483840942383
INFO:root:current mean train loss 1745.39296280254
INFO:root:current train perplexity3.959559679031372
INFO:root:current mean train loss 1745.3252894555858
INFO:root:current train perplexity3.9591240882873535
INFO:root:current mean train loss 1744.8327501591166
INFO:root:current train perplexity3.959383726119995
INFO:root:current mean train loss 1746.2895336999827
INFO:root:current train perplexity3.9609313011169434
INFO:root:current mean train loss 1746.398905593737
INFO:root:current train perplexity3.962129831314087
INFO:root:current mean train loss 1745.78504793499
INFO:root:current train perplexity3.961622476577759

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.78s/it]
INFO:root:final mean train loss: 1746.1948284047214
INFO:root:final train perplexity: 3.963606119155884
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it]
INFO:root:eval mean loss: 2899.6591686901747
INFO:root:eval perplexity: 10.798226356506348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [7:02:35<2:03:31, 336.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.703037109375
INFO:root:current train perplexity3.9736557006835938
INFO:root:current mean train loss 1730.349400390625
INFO:root:current train perplexity3.9279093742370605
INFO:root:current mean train loss 1740.8356070963541
INFO:root:current train perplexity3.9602584838867188
INFO:root:current mean train loss 1736.0212965745193
INFO:root:current train perplexity3.9535436630249023
INFO:root:current mean train loss 1739.5941794002758
INFO:root:current train perplexity3.952749252319336
INFO:root:current mean train loss 1739.1031849888393
INFO:root:current train perplexity3.950294017791748
INFO:root:current mean train loss 1740.36815859375
INFO:root:current train perplexity3.9486303329467773
INFO:root:current mean train loss 1740.6154153758082
INFO:root:current train perplexity3.9464900493621826
INFO:root:current mean train loss 1740.2725821200283
INFO:root:current train perplexity3.948784589767456
INFO:root:current mean train loss 1738.641801229941
INFO:root:current train perplexity3.946927547454834
INFO:root:current mean train loss 1738.533018530869
INFO:root:current train perplexity3.948198080062866
INFO:root:current mean train loss 1740.323484592014
INFO:root:current train perplexity3.9498038291931152
INFO:root:current mean train loss 1741.136308992347
INFO:root:current train perplexity3.9517922401428223
INFO:root:current mean train loss 1742.190962006191
INFO:root:current train perplexity3.9523115158081055
INFO:root:current mean train loss 1741.5346501507674
INFO:root:current train perplexity3.950443744659424
INFO:root:current mean train loss 1741.8747054303278
INFO:root:current train perplexity3.951197862625122
INFO:root:current mean train loss 1742.045235952524
INFO:root:current train perplexity3.9499545097351074
INFO:root:current mean train loss 1743.252884609941
INFO:root:current train perplexity3.9514353275299072
INFO:root:current mean train loss 1743.1845661654538
INFO:root:current train perplexity3.9549663066864014
INFO:root:current mean train loss 1743.7617455737623
INFO:root:current train perplexity3.9553940296173096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.62s/it]
INFO:root:final mean train loss: 1743.6156985561354
INFO:root:final train perplexity: 3.955552101135254
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.26s/it]
INFO:root:eval mean loss: 2901.4744348841027
INFO:root:eval perplexity: 10.814323425292969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:08:20<1:58:46, 339.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.586149669829
INFO:root:current train perplexity3.9241783618927
INFO:root:current mean train loss 1739.2203180017605
INFO:root:current train perplexity3.942561388015747
INFO:root:current mean train loss 1738.6772264212616
INFO:root:current train perplexity3.9417355060577393
INFO:root:current mean train loss 1744.4710500616777
INFO:root:current train perplexity3.949552536010742
INFO:root:current mean train loss 1743.063254239872
INFO:root:current train perplexity3.9418303966522217
INFO:root:current mean train loss 1744.3054863623588
INFO:root:current train perplexity3.943951368331909
INFO:root:current mean train loss 1743.578532851745
INFO:root:current train perplexity3.9402801990509033
INFO:root:current mean train loss 1742.925494993472
INFO:root:current train perplexity3.943812608718872
INFO:root:current mean train loss 1743.6772360903633
INFO:root:current train perplexity3.9493701457977295
INFO:root:current mean train loss 1744.7413600913533
INFO:root:current train perplexity3.952732801437378
INFO:root:current mean train loss 1743.2529606151031
INFO:root:current train perplexity3.9513750076293945
INFO:root:current mean train loss 1741.9236820040567
INFO:root:current train perplexity3.9487357139587402
INFO:root:current mean train loss 1742.7043591682077
INFO:root:current train perplexity3.949284553527832
INFO:root:current mean train loss 1742.4084038769968
INFO:root:current train perplexity3.950075149536133
INFO:root:current mean train loss 1742.3914352184195
INFO:root:current train perplexity3.948911190032959
INFO:root:current mean train loss 1742.3917856970959
INFO:root:current train perplexity3.9488914012908936
INFO:root:current mean train loss 1743.6984223936129
INFO:root:current train perplexity3.952120304107666
INFO:root:current mean train loss 1743.1238553280398
INFO:root:current train perplexity3.951899290084839
INFO:root:current mean train loss 1741.8156491754885
INFO:root:current train perplexity3.950995445251465
INFO:root:current mean train loss 1742.1168473122907
INFO:root:current train perplexity3.9511375427246094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.10s/it]
INFO:root:final mean train loss: 1741.761251090815
INFO:root:final train perplexity: 3.9497714042663574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 2902.075715852571
INFO:root:eval perplexity: 10.819662094116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:13:50<1:52:08, 336.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.8289132845605
INFO:root:current train perplexity3.944960355758667
INFO:root:current mean train loss 1742.6026933778007
INFO:root:current train perplexity3.957810878753662
INFO:root:current mean train loss 1734.5508208403717
INFO:root:current train perplexity3.9357409477233887
INFO:root:current mean train loss 1732.8680549132791
INFO:root:current train perplexity3.9353432655334473
INFO:root:current mean train loss 1733.4057154437296
INFO:root:current train perplexity3.9315967559814453
INFO:root:current mean train loss 1733.5396590940854
INFO:root:current train perplexity3.9263877868652344
INFO:root:current mean train loss 1734.2926532936385
INFO:root:current train perplexity3.9242780208587646
INFO:root:current mean train loss 1735.8457709954505
INFO:root:current train perplexity3.9295921325683594
INFO:root:current mean train loss 1736.6286936572321
INFO:root:current train perplexity3.9338014125823975
INFO:root:current mean train loss 1736.0721012946835
INFO:root:current train perplexity3.9349758625030518
INFO:root:current mean train loss 1735.7753349498716
INFO:root:current train perplexity3.9350359439849854
INFO:root:current mean train loss 1737.5765130188672
INFO:root:current train perplexity3.936779499053955
INFO:root:current mean train loss 1738.8365500816
INFO:root:current train perplexity3.9398138523101807
INFO:root:current mean train loss 1738.8432741144109
INFO:root:current train perplexity3.9415886402130127
INFO:root:current mean train loss 1739.1242057481313
INFO:root:current train perplexity3.942760944366455
INFO:root:current mean train loss 1739.4884694841444
INFO:root:current train perplexity3.942624807357788
INFO:root:current mean train loss 1739.888693654875
INFO:root:current train perplexity3.9444844722747803
INFO:root:current mean train loss 1739.6773336734739
INFO:root:current train perplexity3.943690299987793
INFO:root:current mean train loss 1739.8390206454453
INFO:root:current train perplexity3.943405866622925
INFO:root:current mean train loss 1740.1994278709642
INFO:root:current train perplexity3.9444854259490967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.44s/it]
INFO:root:final mean train loss: 1740.205256521251
INFO:root:final train perplexity: 3.944927453994751
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 2904.6169587556305
INFO:root:eval perplexity: 10.842244148254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [7:19:14<1:45:20, 332.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.5056875128496
INFO:root:current train perplexity3.973468065261841
INFO:root:current mean train loss 1745.4329847856002
INFO:root:current train perplexity3.9603042602539062
INFO:root:current mean train loss 1745.0443606169326
INFO:root:current train perplexity3.9495434761047363
INFO:root:current mean train loss 1738.612466365733
INFO:root:current train perplexity3.935425281524658
INFO:root:current mean train loss 1737.3444383124342
INFO:root:current train perplexity3.934833288192749
INFO:root:current mean train loss 1737.851169374254
INFO:root:current train perplexity3.93471360206604
INFO:root:current mean train loss 1737.8373783269578
INFO:root:current train perplexity3.934528350830078
INFO:root:current mean train loss 1737.0256791262282
INFO:root:current train perplexity3.9362106323242188
INFO:root:current mean train loss 1739.0172211111408
INFO:root:current train perplexity3.93356990814209
INFO:root:current mean train loss 1739.3814839847753
INFO:root:current train perplexity3.9348835945129395
INFO:root:current mean train loss 1737.2401941008727
INFO:root:current train perplexity3.933324098587036
INFO:root:current mean train loss 1736.9541362321295
INFO:root:current train perplexity3.9352400302886963
INFO:root:current mean train loss 1738.579770079227
INFO:root:current train perplexity3.9375205039978027
INFO:root:current mean train loss 1739.403367153434
INFO:root:current train perplexity3.9380786418914795
INFO:root:current mean train loss 1739.6119595659457
INFO:root:current train perplexity3.936469316482544
INFO:root:current mean train loss 1739.9178029946265
INFO:root:current train perplexity3.9375436305999756
INFO:root:current mean train loss 1740.572344431729
INFO:root:current train perplexity3.9383397102355957
INFO:root:current mean train loss 1739.7289997135197
INFO:root:current train perplexity3.9386613368988037
INFO:root:current mean train loss 1739.0766580089578
INFO:root:current train perplexity3.9394164085388184
INFO:root:current mean train loss 1739.0182858362855
INFO:root:current train perplexity3.939539909362793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.54s/it]
INFO:root:final mean train loss: 1738.3663919807623
INFO:root:final train perplexity: 3.9392096996307373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.54s/it]
INFO:root:eval mean loss: 2903.1444168778153
INFO:root:eval perplexity: 10.829154014587402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [7:24:49<1:40:01, 333.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1738.558588499664
INFO:root:current train perplexity3.934799909591675
INFO:root:current mean train loss 1749.003225059707
INFO:root:current train perplexity3.9449729919433594
INFO:root:current mean train loss 1735.3593991640892
INFO:root:current train perplexity3.9326353073120117
INFO:root:current mean train loss 1734.7571005784828
INFO:root:current train perplexity3.930879592895508
INFO:root:current mean train loss 1733.9756854755642
INFO:root:current train perplexity3.9268717765808105
INFO:root:current mean train loss 1732.7869891573566
INFO:root:current train perplexity3.9288530349731445
INFO:root:current mean train loss 1733.7170811772862
INFO:root:current train perplexity3.9328346252441406
INFO:root:current mean train loss 1733.3122572447883
INFO:root:current train perplexity3.9335291385650635
INFO:root:current mean train loss 1734.1481288384484
INFO:root:current train perplexity3.937793254852295
INFO:root:current mean train loss 1736.1213046993014
INFO:root:current train perplexity3.940282106399536
INFO:root:current mean train loss 1735.6240879906936
INFO:root:current train perplexity3.938201665878296
INFO:root:current mean train loss 1734.6584978127619
INFO:root:current train perplexity3.935406446456909
INFO:root:current mean train loss 1735.04765745843
INFO:root:current train perplexity3.9359352588653564
INFO:root:current mean train loss 1735.8651769765402
INFO:root:current train perplexity3.935056209564209
INFO:root:current mean train loss 1736.047170650536
INFO:root:current train perplexity3.9347872734069824
INFO:root:current mean train loss 1736.897905540107
INFO:root:current train perplexity3.935612916946411
INFO:root:current mean train loss 1737.3447533848014
INFO:root:current train perplexity3.9355857372283936
INFO:root:current mean train loss 1737.2677761062987
INFO:root:current train perplexity3.9367363452911377
INFO:root:current mean train loss 1737.8837087785384
INFO:root:current train perplexity3.9359889030456543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.00s/it]
INFO:root:final mean train loss: 1736.9076358950986
INFO:root:final train perplexity: 3.934680461883545
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 31.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 31.00s/it]
INFO:root:eval mean loss: 2905.47217823292
INFO:root:eval perplexity: 10.849857330322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [7:30:15<1:33:49, 331.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.4435546875
INFO:root:current train perplexity3.9539401531219482
INFO:root:current mean train loss 1736.3131980202415
INFO:root:current train perplexity3.913038969039917
INFO:root:current mean train loss 1738.5080624534971
INFO:root:current train perplexity3.914879322052002
INFO:root:current mean train loss 1737.577124810988
INFO:root:current train perplexity3.9219741821289062
INFO:root:current mean train loss 1732.6148339248284
INFO:root:current train perplexity3.9198176860809326
INFO:root:current mean train loss 1731.4167822744332
INFO:root:current train perplexity3.92556095123291
INFO:root:current mean train loss 1732.672714083312
INFO:root:current train perplexity3.930647611618042
INFO:root:current mean train loss 1732.156474368673
INFO:root:current train perplexity3.9307262897491455
INFO:root:current mean train loss 1733.023210238233
INFO:root:current train perplexity3.9302663803100586
INFO:root:current mean train loss 1733.9611576289922
INFO:root:current train perplexity3.929837226867676
INFO:root:current mean train loss 1733.5508082021581
INFO:root:current train perplexity3.9271252155303955
INFO:root:current mean train loss 1733.9851100612332
INFO:root:current train perplexity3.9296109676361084
INFO:root:current mean train loss 1734.9027065308626
INFO:root:current train perplexity3.9315555095672607
INFO:root:current mean train loss 1736.0131370020276
INFO:root:current train perplexity3.93243145942688
INFO:root:current mean train loss 1735.3994362256205
INFO:root:current train perplexity3.9324820041656494
INFO:root:current mean train loss 1736.3091162271057
INFO:root:current train perplexity3.9330005645751953
INFO:root:current mean train loss 1736.4383422093363
INFO:root:current train perplexity3.9323129653930664
INFO:root:current mean train loss 1736.2524664627879
INFO:root:current train perplexity3.9316482543945312
INFO:root:current mean train loss 1735.1248955320916
INFO:root:current train perplexity3.9315435886383057
INFO:root:current mean train loss 1735.8583659706314
INFO:root:current train perplexity3.930990695953369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.14s/it]
INFO:root:final mean train loss: 1735.4821270718096
INFO:root:final train perplexity: 3.930260181427002
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.29s/it]
INFO:root:eval mean loss: 2906.808062945758
INFO:root:eval perplexity: 10.8617582321167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:35:47<1:28:23, 331.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.0034722222222
INFO:root:current train perplexity3.897644519805908
INFO:root:current mean train loss 1720.8198049950788
INFO:root:current train perplexity3.9154088497161865
INFO:root:current mean train loss 1727.1365429042194
INFO:root:current train perplexity3.9229679107666016
INFO:root:current mean train loss 1730.5451107666763
INFO:root:current train perplexity3.920567274093628
INFO:root:current mean train loss 1730.0251722134806
INFO:root:current train perplexity3.9136831760406494
INFO:root:current mean train loss 1728.2611544932993
INFO:root:current train perplexity3.9152512550354004
INFO:root:current mean train loss 1728.1536923641222
INFO:root:current train perplexity3.9177327156066895
INFO:root:current mean train loss 1727.896535587442
INFO:root:current train perplexity3.916280508041382
INFO:root:current mean train loss 1727.8232293457622
INFO:root:current train perplexity3.915377616882324
INFO:root:current mean train loss 1729.2899744060562
INFO:root:current train perplexity3.9159233570098877
INFO:root:current mean train loss 1729.7552004092624
INFO:root:current train perplexity3.916001319885254
INFO:root:current mean train loss 1731.2528683815578
INFO:root:current train perplexity3.91814923286438
INFO:root:current mean train loss 1732.211105334244
INFO:root:current train perplexity3.9192984104156494
INFO:root:current mean train loss 1732.6048068842138
INFO:root:current train perplexity3.920560121536255
INFO:root:current mean train loss 1733.8104209552382
INFO:root:current train perplexity3.921966314315796
INFO:root:current mean train loss 1734.3765225613438
INFO:root:current train perplexity3.922186851501465
INFO:root:current mean train loss 1734.6919580798392
INFO:root:current train perplexity3.923006534576416
INFO:root:current mean train loss 1734.6192446710336
INFO:root:current train perplexity3.9241254329681396
INFO:root:current mean train loss 1733.8798506746673
INFO:root:current train perplexity3.9235024452209473
INFO:root:current mean train loss 1733.501505069307
INFO:root:current train perplexity3.923055648803711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.15s/it]
INFO:root:final mean train loss: 1733.5163444638313
INFO:root:final train perplexity: 3.9241716861724854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2904.473928273977
INFO:root:eval perplexity: 10.840975761413574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:41:29<1:23:39, 334.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.4555996981535
INFO:root:current train perplexity3.897068977355957
INFO:root:current mean train loss 1706.3626352945964
INFO:root:current train perplexity3.9116570949554443
INFO:root:current mean train loss 1722.5786593077612
INFO:root:current train perplexity3.9251561164855957
INFO:root:current mean train loss 1725.0335274629815
INFO:root:current train perplexity3.9168384075164795
INFO:root:current mean train loss 1728.1629545194608
INFO:root:current train perplexity3.9206535816192627
INFO:root:current mean train loss 1731.7316302131203
INFO:root:current train perplexity3.9220662117004395
INFO:root:current mean train loss 1734.6873692103795
INFO:root:current train perplexity3.920292377471924
INFO:root:current mean train loss 1732.621574812038
INFO:root:current train perplexity3.9168150424957275
INFO:root:current mean train loss 1734.4243213237744
INFO:root:current train perplexity3.919618606567383
INFO:root:current mean train loss 1732.893733654992
INFO:root:current train perplexity3.917691469192505
INFO:root:current mean train loss 1732.1187458842194
INFO:root:current train perplexity3.9218082427978516
INFO:root:current mean train loss 1732.411154473578
INFO:root:current train perplexity3.921034574508667
INFO:root:current mean train loss 1732.2379748966916
INFO:root:current train perplexity3.9207799434661865
INFO:root:current mean train loss 1731.317031497047
INFO:root:current train perplexity3.9206385612487793
INFO:root:current mean train loss 1732.1618587250855
INFO:root:current train perplexity3.9214954376220703
INFO:root:current mean train loss 1732.1720751036016
INFO:root:current train perplexity3.920543909072876
INFO:root:current mean train loss 1732.7072024751465
INFO:root:current train perplexity3.920768976211548
INFO:root:current mean train loss 1732.7168694592397
INFO:root:current train perplexity3.9194881916046143
INFO:root:current mean train loss 1733.0518589640387
INFO:root:current train perplexity3.9210398197174072
INFO:root:current mean train loss 1733.1925644737212
INFO:root:current train perplexity3.9200987815856934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.69s/it]
INFO:root:final mean train loss: 1732.2516161850829
INFO:root:final train perplexity: 3.920259714126587
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.54s/it]
INFO:root:eval mean loss: 2907.0248356266425
INFO:root:eval perplexity: 10.863690376281738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:47:13<1:18:43, 337.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1726.9136902856046
INFO:root:current train perplexity3.902716636657715
INFO:root:current mean train loss 1713.3155062657706
INFO:root:current train perplexity3.8957841396331787
INFO:root:current mean train loss 1717.657741970486
INFO:root:current train perplexity3.8943252563476562
INFO:root:current mean train loss 1721.6315075987925
INFO:root:current train perplexity3.900801658630371
INFO:root:current mean train loss 1722.8398612264439
INFO:root:current train perplexity3.909578800201416
INFO:root:current mean train loss 1724.0744567979891
INFO:root:current train perplexity3.9157581329345703
INFO:root:current mean train loss 1724.2347565389798
INFO:root:current train perplexity3.9127628803253174
INFO:root:current mean train loss 1725.520069578474
INFO:root:current train perplexity3.9143691062927246
INFO:root:current mean train loss 1727.4012088221816
INFO:root:current train perplexity3.916142702102661
INFO:root:current mean train loss 1727.585799932728
INFO:root:current train perplexity3.913492441177368
INFO:root:current mean train loss 1728.4461356980075
INFO:root:current train perplexity3.9162118434906006
INFO:root:current mean train loss 1729.4145070420166
INFO:root:current train perplexity3.9155290126800537
INFO:root:current mean train loss 1728.9134049079041
INFO:root:current train perplexity3.91255259513855
INFO:root:current mean train loss 1729.4093582635412
INFO:root:current train perplexity3.9139244556427
INFO:root:current mean train loss 1730.6414102271026
INFO:root:current train perplexity3.9187612533569336
INFO:root:current mean train loss 1731.0137779142976
INFO:root:current train perplexity3.9181809425354004
INFO:root:current mean train loss 1730.7821615955186
INFO:root:current train perplexity3.9164745807647705
INFO:root:current mean train loss 1730.7784773887795
INFO:root:current train perplexity3.9161763191223145
INFO:root:current mean train loss 1731.2710306617537
INFO:root:current train perplexity3.916194200515747
INFO:root:current mean train loss 1731.644115613347
INFO:root:current train perplexity3.916989326477051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.34s/it]
INFO:root:final mean train loss: 1731.134804622248
INFO:root:final train perplexity: 3.9168081283569336
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it]
INFO:root:eval mean loss: 2907.0944956186654
INFO:root:eval perplexity: 10.864309310913086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [7:52:56<1:13:28, 339.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.1557163336338
INFO:root:current train perplexity3.9208881855010986
INFO:root:current mean train loss 1730.9794359528616
INFO:root:current train perplexity3.894946575164795
INFO:root:current mean train loss 1734.2640806788163
INFO:root:current train perplexity3.901703357696533
INFO:root:current mean train loss 1735.7465035574776
INFO:root:current train perplexity3.911539077758789
INFO:root:current mean train loss 1735.8329255810343
INFO:root:current train perplexity3.912362813949585
INFO:root:current mean train loss 1734.5303860040685
INFO:root:current train perplexity3.91398549079895
INFO:root:current mean train loss 1732.6063084785214
INFO:root:current train perplexity3.910918951034546
INFO:root:current mean train loss 1730.128242708417
INFO:root:current train perplexity3.9097647666931152
INFO:root:current mean train loss 1728.6629068639663
INFO:root:current train perplexity3.906255006790161
INFO:root:current mean train loss 1727.5382475745703
INFO:root:current train perplexity3.9049625396728516
INFO:root:current mean train loss 1728.2517622061252
INFO:root:current train perplexity3.905090570449829
INFO:root:current mean train loss 1729.1320461927326
INFO:root:current train perplexity3.904357433319092
INFO:root:current mean train loss 1729.4428462594142
INFO:root:current train perplexity3.904616594314575
INFO:root:current mean train loss 1728.0954296626962
INFO:root:current train perplexity3.904179096221924
INFO:root:current mean train loss 1728.8419587544402
INFO:root:current train perplexity3.9080584049224854
INFO:root:current mean train loss 1729.1912482083976
INFO:root:current train perplexity3.9084725379943848
INFO:root:current mean train loss 1730.31717933773
INFO:root:current train perplexity3.9111838340759277
INFO:root:current mean train loss 1729.6791790338953
INFO:root:current train perplexity3.911341905593872
INFO:root:current mean train loss 1729.8254999032797
INFO:root:current train perplexity3.9118287563323975
INFO:root:current mean train loss 1729.796273226685
INFO:root:current train perplexity3.911435604095459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it]
INFO:root:final mean train loss: 1729.3414175521227
INFO:root:final train perplexity: 3.9112720489501953
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it]
INFO:root:eval mean loss: 2908.392452022335
INFO:root:eval perplexity: 10.87588882446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [7:58:39<1:08:02, 340.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1746.9994770250823
INFO:root:current train perplexity3.9382147789001465
INFO:root:current mean train loss 1737.9257831280047
INFO:root:current train perplexity3.9134881496429443
INFO:root:current mean train loss 1734.7679190942797
INFO:root:current train perplexity3.9148144721984863
INFO:root:current mean train loss 1729.3932768616496
INFO:root:current train perplexity3.9046664237976074
INFO:root:current mean train loss 1728.1252493193656
INFO:root:current train perplexity3.8989908695220947
INFO:root:current mean train loss 1725.900015181854
INFO:root:current train perplexity3.8941898345947266
INFO:root:current mean train loss 1727.1950866260117
INFO:root:current train perplexity3.902325391769409
INFO:root:current mean train loss 1729.6622483355445
INFO:root:current train perplexity3.906547784805298
INFO:root:current mean train loss 1729.6686267021648
INFO:root:current train perplexity3.910322427749634
INFO:root:current mean train loss 1728.8889484041301
INFO:root:current train perplexity3.9075515270233154
INFO:root:current mean train loss 1729.407535695812
INFO:root:current train perplexity3.907924175262451
INFO:root:current mean train loss 1728.8082396950183
INFO:root:current train perplexity3.9063034057617188
INFO:root:current mean train loss 1728.7847732602859
INFO:root:current train perplexity3.9060416221618652
INFO:root:current mean train loss 1727.1567423940132
INFO:root:current train perplexity3.905921459197998
INFO:root:current mean train loss 1727.8588961904263
INFO:root:current train perplexity3.903963088989258
INFO:root:current mean train loss 1727.7269739420062
INFO:root:current train perplexity3.904284715652466
INFO:root:current mean train loss 1727.9720780184136
INFO:root:current train perplexity3.905534267425537
INFO:root:current mean train loss 1728.5705854750609
INFO:root:current train perplexity3.908583879470825
INFO:root:current mean train loss 1729.0101920014636
INFO:root:current train perplexity3.9093923568725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.70s/it]
INFO:root:final mean train loss: 1728.7284367994653
INFO:root:final train perplexity: 3.909381628036499
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it]
INFO:root:eval mean loss: 2908.3948875633446
INFO:root:eval perplexity: 10.875908851623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [8:04:16<1:02:11, 339.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.8924967447917
INFO:root:current train perplexity3.8633179664611816
INFO:root:current mean train loss 1732.468352181571
INFO:root:current train perplexity3.9088664054870605
INFO:root:current mean train loss 1724.7441630813312
INFO:root:current train perplexity3.9008946418762207
INFO:root:current mean train loss 1723.428490663186
INFO:root:current train perplexity3.900686264038086
INFO:root:current mean train loss 1726.4188022057988
INFO:root:current train perplexity3.908442258834839
INFO:root:current mean train loss 1724.8787608146667
INFO:root:current train perplexity3.903498411178589
INFO:root:current mean train loss 1722.9072351393356
INFO:root:current train perplexity3.900712490081787
INFO:root:current mean train loss 1722.3994632678086
INFO:root:current train perplexity3.8988616466522217
INFO:root:current mean train loss 1722.0249803665236
INFO:root:current train perplexity3.8948962688446045
INFO:root:current mean train loss 1721.8960292883087
INFO:root:current train perplexity3.8939929008483887
INFO:root:current mean train loss 1723.4241501879787
INFO:root:current train perplexity3.8952691555023193
INFO:root:current mean train loss 1723.368848841825
INFO:root:current train perplexity3.897737979888916
INFO:root:current mean train loss 1723.7630866022394
INFO:root:current train perplexity3.8998851776123047
INFO:root:current mean train loss 1725.4043746576076
INFO:root:current train perplexity3.9002790451049805
INFO:root:current mean train loss 1726.6100041116601
INFO:root:current train perplexity3.900963544845581
INFO:root:current mean train loss 1726.71690530121
INFO:root:current train perplexity3.901559352874756
INFO:root:current mean train loss 1726.1469369893039
INFO:root:current train perplexity3.901989459991455
INFO:root:current mean train loss 1726.7541660059278
INFO:root:current train perplexity3.904012441635132
INFO:root:current mean train loss 1727.0224819562293
INFO:root:current train perplexity3.9043490886688232
INFO:root:current mean train loss 1728.0688221185278
INFO:root:current train perplexity3.906280994415283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.94s/it]
INFO:root:final mean train loss: 1727.8708110738148
INFO:root:final train perplexity: 3.90673828125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2908.8082638302367
INFO:root:eval perplexity: 10.879599571228027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:10:00<56:46, 340.65s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.879078832166
INFO:root:current train perplexity3.9211738109588623
INFO:root:current mean train loss 1715.0859346611555
INFO:root:current train perplexity3.8732337951660156
INFO:root:current mean train loss 1724.2283823604666
INFO:root:current train perplexity3.8825759887695312
INFO:root:current mean train loss 1727.5732529474972
INFO:root:current train perplexity3.890122890472412
INFO:root:current mean train loss 1731.814227764423
INFO:root:current train perplexity3.893078088760376
INFO:root:current mean train loss 1729.695368112373
INFO:root:current train perplexity3.8948442935943604
INFO:root:current mean train loss 1730.0495467678732
INFO:root:current train perplexity3.8981478214263916
INFO:root:current mean train loss 1729.6161205150463
INFO:root:current train perplexity3.893070697784424
INFO:root:current mean train loss 1730.0237842739275
INFO:root:current train perplexity3.896179437637329
INFO:root:current mean train loss 1728.2153693487621
INFO:root:current train perplexity3.8949437141418457
INFO:root:current mean train loss 1728.0668755504435
INFO:root:current train perplexity3.894815444946289
INFO:root:current mean train loss 1725.7045274570623
INFO:root:current train perplexity3.8924381732940674
INFO:root:current mean train loss 1726.2904831441658
INFO:root:current train perplexity3.8946080207824707
INFO:root:current mean train loss 1725.5864688594868
INFO:root:current train perplexity3.89608097076416
INFO:root:current mean train loss 1725.0776171567475
INFO:root:current train perplexity3.89787220954895
INFO:root:current mean train loss 1725.4345557822207
INFO:root:current train perplexity3.899423122406006
INFO:root:current mean train loss 1725.2081065777988
INFO:root:current train perplexity3.8984978199005127
INFO:root:current mean train loss 1725.7487764728075
INFO:root:current train perplexity3.9000377655029297
INFO:root:current mean train loss 1726.7086733593324
INFO:root:current train perplexity3.9010908603668213
INFO:root:current mean train loss 1726.4118266958471
INFO:root:current train perplexity3.9002864360809326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.63s/it]
INFO:root:final mean train loss: 1725.7484668879815
INFO:root:final train perplexity: 3.900204658508301
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 2909.8948545713683
INFO:root:eval perplexity: 10.889305114746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:15:45<51:19, 342.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.7680743673573
INFO:root:current train perplexity3.9216229915618896
INFO:root:current mean train loss 1722.718209880672
INFO:root:current train perplexity3.898683786392212
INFO:root:current mean train loss 1725.5647463914825
INFO:root:current train perplexity3.9028143882751465
INFO:root:current mean train loss 1723.2299674149883
INFO:root:current train perplexity3.895793914794922
INFO:root:current mean train loss 1724.9035236717875
INFO:root:current train perplexity3.9039673805236816
INFO:root:current mean train loss 1725.4276999449119
INFO:root:current train perplexity3.90439510345459
INFO:root:current mean train loss 1725.6178364000823
INFO:root:current train perplexity3.9040510654449463
INFO:root:current mean train loss 1723.1831755037283
INFO:root:current train perplexity3.8986716270446777
INFO:root:current mean train loss 1722.020717178958
INFO:root:current train perplexity3.8991899490356445
INFO:root:current mean train loss 1723.241036477603
INFO:root:current train perplexity3.9003236293792725
INFO:root:current mean train loss 1725.1223258899229
INFO:root:current train perplexity3.9037277698516846
INFO:root:current mean train loss 1725.237187517043
INFO:root:current train perplexity3.9030497074127197
INFO:root:current mean train loss 1725.3579182877395
INFO:root:current train perplexity3.899979591369629
INFO:root:current mean train loss 1725.6467140957293
INFO:root:current train perplexity3.9024813175201416
INFO:root:current mean train loss 1726.070514599812
INFO:root:current train perplexity3.901045322418213
INFO:root:current mean train loss 1726.1047381441774
INFO:root:current train perplexity3.901034116744995
INFO:root:current mean train loss 1725.4884676927495
INFO:root:current train perplexity3.900221347808838
INFO:root:current mean train loss 1725.529188507884
INFO:root:current train perplexity3.9002530574798584
INFO:root:current mean train loss 1725.4016082201592
INFO:root:current train perplexity3.899078845977783
INFO:root:current mean train loss 1725.339516054567
INFO:root:current train perplexity3.8983726501464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.41s/it]
INFO:root:final mean train loss: 1725.166571928285
INFO:root:final train perplexity: 3.8984150886535645
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it]
INFO:root:eval mean loss: 2910.1870190503005
INFO:root:eval perplexity: 10.891914367675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [8:21:29<45:42, 342.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.614722842262
INFO:root:current train perplexity3.895214796066284
INFO:root:current mean train loss 1722.4092351059242
INFO:root:current train perplexity3.8713088035583496
INFO:root:current mean train loss 1721.4965783180846
INFO:root:current train perplexity3.8874170780181885
INFO:root:current mean train loss 1719.467593526709
INFO:root:current train perplexity3.88997220993042
INFO:root:current mean train loss 1725.3624947797146
INFO:root:current train perplexity3.897515058517456
INFO:root:current mean train loss 1725.797034580373
INFO:root:current train perplexity3.898503303527832
INFO:root:current mean train loss 1726.0254990705716
INFO:root:current train perplexity3.898149251937866
INFO:root:current mean train loss 1727.3131709867505
INFO:root:current train perplexity3.8954694271087646
INFO:root:current mean train loss 1727.4666861205912
INFO:root:current train perplexity3.8997368812561035
INFO:root:current mean train loss 1727.7249749521352
INFO:root:current train perplexity3.90083384513855
INFO:root:current mean train loss 1727.8549700187045
INFO:root:current train perplexity3.9015932083129883
INFO:root:current mean train loss 1726.2075969928928
INFO:root:current train perplexity3.8981339931488037
INFO:root:current mean train loss 1725.4540901576727
INFO:root:current train perplexity3.896122694015503
INFO:root:current mean train loss 1725.1581702564713
INFO:root:current train perplexity3.893974781036377
INFO:root:current mean train loss 1724.2103034519448
INFO:root:current train perplexity3.8941261768341064
INFO:root:current mean train loss 1724.5691874693848
INFO:root:current train perplexity3.895446538925171
INFO:root:current mean train loss 1724.2996498057446
INFO:root:current train perplexity3.894136905670166
INFO:root:current mean train loss 1723.997020875062
INFO:root:current train perplexity3.893691062927246
INFO:root:current mean train loss 1723.6381936843716
INFO:root:current train perplexity3.892219066619873
INFO:root:current mean train loss 1724.5293640976224
INFO:root:current train perplexity3.8944790363311768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.38s/it]
INFO:root:final mean train loss: 1723.9618400693
INFO:root:final train perplexity: 3.8947129249572754
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2910.280074019332
INFO:root:eval perplexity: 10.892745971679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [8:27:10<39:55, 342.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.5913208007812
INFO:root:current train perplexity3.8769843578338623
INFO:root:current mean train loss 1718.9479926215279
INFO:root:current train perplexity3.872519016265869
INFO:root:current mean train loss 1724.0701843261718
INFO:root:current train perplexity3.879054069519043
INFO:root:current mean train loss 1723.9359933953535
INFO:root:current train perplexity3.8942689895629883
INFO:root:current mean train loss 1723.0161616007488
INFO:root:current train perplexity3.8921754360198975
INFO:root:current mean train loss 1723.1570899700296
INFO:root:current train perplexity3.893656015396118
INFO:root:current mean train loss 1722.9204634722541
INFO:root:current train perplexity3.8927481174468994
INFO:root:current mean train loss 1722.62400778746
INFO:root:current train perplexity3.894111156463623
INFO:root:current mean train loss 1721.9387544111771
INFO:root:current train perplexity3.891087055206299
INFO:root:current mean train loss 1721.720008943519
INFO:root:current train perplexity3.891026496887207
INFO:root:current mean train loss 1721.4542469165942
INFO:root:current train perplexity3.890031576156616
INFO:root:current mean train loss 1720.4963857877053
INFO:root:current train perplexity3.8889856338500977
INFO:root:current mean train loss 1721.4884024620055
INFO:root:current train perplexity3.890915632247925
INFO:root:current mean train loss 1721.9108776147814
INFO:root:current train perplexity3.8893210887908936
INFO:root:current mean train loss 1723.8592083080396
INFO:root:current train perplexity3.8919551372528076
INFO:root:current mean train loss 1723.8525339633604
INFO:root:current train perplexity3.8911030292510986
INFO:root:current mean train loss 1723.3198353358678
INFO:root:current train perplexity3.891326427459717
INFO:root:current mean train loss 1723.950099645036
INFO:root:current train perplexity3.892131805419922
INFO:root:current mean train loss 1723.3933322338348
INFO:root:current train perplexity3.891493558883667
INFO:root:current mean train loss 1723.6309519758129
INFO:root:current train perplexity3.8923754692077637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it]
INFO:root:final mean train loss: 1723.1813721688059
INFO:root:final train perplexity: 3.8923161029815674
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it]
INFO:root:eval mean loss: 2911.206858958568
INFO:root:eval perplexity: 10.901033401489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [8:32:54<34:16, 342.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.8053947527385
INFO:root:current train perplexity3.9076080322265625
INFO:root:current mean train loss 1725.4402989421399
INFO:root:current train perplexity3.9058713912963867
INFO:root:current mean train loss 1725.782464948969
INFO:root:current train perplexity3.892674446105957
INFO:root:current mean train loss 1725.5403219458437
INFO:root:current train perplexity3.8992841243743896
INFO:root:current mean train loss 1725.1294203207526
INFO:root:current train perplexity3.8959858417510986
INFO:root:current mean train loss 1726.45322989459
INFO:root:current train perplexity3.8901233673095703
INFO:root:current mean train loss 1725.4338681892823
INFO:root:current train perplexity3.886920213699341
INFO:root:current mean train loss 1723.5492963419954
INFO:root:current train perplexity3.887418508529663
INFO:root:current mean train loss 1724.0185433922536
INFO:root:current train perplexity3.8872697353363037
INFO:root:current mean train loss 1724.2775495676483
INFO:root:current train perplexity3.889498233795166
INFO:root:current mean train loss 1724.8607428106484
INFO:root:current train perplexity3.892967700958252
INFO:root:current mean train loss 1724.3139163011697
INFO:root:current train perplexity3.892489194869995
INFO:root:current mean train loss 1724.4791720941055
INFO:root:current train perplexity3.894014358520508
INFO:root:current mean train loss 1724.0844258203963
INFO:root:current train perplexity3.8913228511810303
INFO:root:current mean train loss 1723.859043444963
INFO:root:current train perplexity3.8915491104125977
INFO:root:current mean train loss 1724.1930909273246
INFO:root:current train perplexity3.892388105392456
INFO:root:current mean train loss 1723.944197610328
INFO:root:current train perplexity3.892880439758301
INFO:root:current mean train loss 1723.817497070856
INFO:root:current train perplexity3.893510580062866
INFO:root:current mean train loss 1724.1738366190862
INFO:root:current train perplexity3.8950016498565674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.66s/it]
INFO:root:final mean train loss: 1722.9445940518824
INFO:root:final train perplexity: 3.891589641571045
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2911.3502640824418
INFO:root:eval perplexity: 10.902315139770508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [8:38:29<28:22, 340.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1698.425013950893
INFO:root:current train perplexity3.8407506942749023
INFO:root:current mean train loss 1710.452173065721
INFO:root:current train perplexity3.8497002124786377
INFO:root:current mean train loss 1715.1288994049357
INFO:root:current train perplexity3.8496620655059814
INFO:root:current mean train loss 1716.0959239400877
INFO:root:current train perplexity3.859164237976074
INFO:root:current mean train loss 1715.327290263153
INFO:root:current train perplexity3.8597705364227295
INFO:root:current mean train loss 1716.8447771480576
INFO:root:current train perplexity3.865522623062134
INFO:root:current mean train loss 1718.2649888029316
INFO:root:current train perplexity3.875227928161621
INFO:root:current mean train loss 1720.4186061143207
INFO:root:current train perplexity3.875530958175659
INFO:root:current mean train loss 1719.7440067075688
INFO:root:current train perplexity3.875950574874878
INFO:root:current mean train loss 1720.5572155841853
INFO:root:current train perplexity3.877443313598633
INFO:root:current mean train loss 1720.7767651800573
INFO:root:current train perplexity3.8761537075042725
INFO:root:current mean train loss 1721.929034303292
INFO:root:current train perplexity3.878821849822998
INFO:root:current mean train loss 1722.1106212433715
INFO:root:current train perplexity3.880911111831665
INFO:root:current mean train loss 1721.603509214915
INFO:root:current train perplexity3.881584644317627
INFO:root:current mean train loss 1721.5974306702783
INFO:root:current train perplexity3.8838586807250977
INFO:root:current mean train loss 1722.8198029330415
INFO:root:current train perplexity3.88484787940979
INFO:root:current mean train loss 1722.7962781109627
INFO:root:current train perplexity3.8868188858032227
INFO:root:current mean train loss 1723.3978847650553
INFO:root:current train perplexity3.8876922130584717
INFO:root:current mean train loss 1723.5833101619564
INFO:root:current train perplexity3.8874313831329346
INFO:root:current mean train loss 1723.316183729979
INFO:root:current train perplexity3.887676477432251

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.93s/it]
INFO:root:final mean train loss: 1721.767206312248
INFO:root:final train perplexity: 3.8879778385162354
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2910.6672839832017
INFO:root:eval perplexity: 10.896207809448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:44:13<22:45, 341.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.5707732169858
INFO:root:current train perplexity3.9395413398742676
INFO:root:current mean train loss 1727.8855651389551
INFO:root:current train perplexity3.9275760650634766
INFO:root:current mean train loss 1726.69934399097
INFO:root:current train perplexity3.9138708114624023
INFO:root:current mean train loss 1726.2195819958458
INFO:root:current train perplexity3.9025676250457764
INFO:root:current mean train loss 1729.5685131666003
INFO:root:current train perplexity3.904865264892578
INFO:root:current mean train loss 1727.4830696982403
INFO:root:current train perplexity3.898516893386841
INFO:root:current mean train loss 1726.2064056154666
INFO:root:current train perplexity3.8933510780334473
INFO:root:current mean train loss 1725.42574401104
INFO:root:current train perplexity3.890702724456787
INFO:root:current mean train loss 1725.1480019543
INFO:root:current train perplexity3.891832113265991
INFO:root:current mean train loss 1723.2856259125772
INFO:root:current train perplexity3.8884437084198
INFO:root:current mean train loss 1722.3970035586278
INFO:root:current train perplexity3.8880372047424316
INFO:root:current mean train loss 1722.1628027257404
INFO:root:current train perplexity3.887239456176758
INFO:root:current mean train loss 1722.7467895805303
INFO:root:current train perplexity3.8880088329315186
INFO:root:current mean train loss 1722.6426093992122
INFO:root:current train perplexity3.887082815170288
INFO:root:current mean train loss 1721.246478813166
INFO:root:current train perplexity3.8871190547943115
INFO:root:current mean train loss 1720.929614146187
INFO:root:current train perplexity3.8877785205841064
INFO:root:current mean train loss 1722.5115623263623
INFO:root:current train perplexity3.8905510902404785
INFO:root:current mean train loss 1722.260084516943
INFO:root:current train perplexity3.888136863708496
INFO:root:current mean train loss 1721.8185907152426
INFO:root:current train perplexity3.8880810737609863
INFO:root:current mean train loss 1721.9196082598678
INFO:root:current train perplexity3.887643575668335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.19s/it]
INFO:root:final mean train loss: 1721.4012925479367
INFO:root:final train perplexity: 3.8868558406829834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.00s/it]
INFO:root:eval mean loss: 2911.4285452444633
INFO:root:eval perplexity: 10.903018951416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:49:56<17:05, 341.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1718.8318430582683
INFO:root:current train perplexity3.8880608081817627
INFO:root:current mean train loss 1719.7773668443836
INFO:root:current train perplexity3.908736228942871
INFO:root:current mean train loss 1723.978751397902
INFO:root:current train perplexity3.91367769241333
INFO:root:current mean train loss 1721.192413680855
INFO:root:current train perplexity3.8956007957458496
INFO:root:current mean train loss 1724.5901121412005
INFO:root:current train perplexity3.89697003364563
INFO:root:current mean train loss 1725.7074930232807
INFO:root:current train perplexity3.8893322944641113
INFO:root:current mean train loss 1726.7904184600454
INFO:root:current train perplexity3.889572858810425
INFO:root:current mean train loss 1725.4675248905937
INFO:root:current train perplexity3.884544849395752
INFO:root:current mean train loss 1723.3603340004975
INFO:root:current train perplexity3.8855481147766113
INFO:root:current mean train loss 1723.4058844328933
INFO:root:current train perplexity3.88600754737854
INFO:root:current mean train loss 1723.10664833593
INFO:root:current train perplexity3.886770248413086
INFO:root:current mean train loss 1721.1578932705656
INFO:root:current train perplexity3.8865208625793457
INFO:root:current mean train loss 1721.706831809802
INFO:root:current train perplexity3.885404586791992
INFO:root:current mean train loss 1722.8933204175457
INFO:root:current train perplexity3.8868415355682373
INFO:root:current mean train loss 1722.429467132737
INFO:root:current train perplexity3.886396646499634
INFO:root:current mean train loss 1721.6256461525456
INFO:root:current train perplexity3.884608745574951
INFO:root:current mean train loss 1721.7017405982156
INFO:root:current train perplexity3.883805990219116
INFO:root:current mean train loss 1721.5872107184998
INFO:root:current train perplexity3.8838558197021484
INFO:root:current mean train loss 1720.9716950783998
INFO:root:current train perplexity3.8846592903137207
INFO:root:current mean train loss 1720.7270782909354
INFO:root:current train perplexity3.8847432136535645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.68s/it]
INFO:root:final mean train loss: 1720.6948069208388
INFO:root:final train perplexity: 3.8846912384033203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.06s/it]
INFO:root:eval mean loss: 2911.290186426661
INFO:root:eval perplexity: 10.901779174804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [8:55:43<11:27, 343.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.7036527193509
INFO:root:current train perplexity3.8611412048339844
INFO:root:current mean train loss 1717.6609611742424
INFO:root:current train perplexity3.879316568374634
INFO:root:current mean train loss 1717.6446887897996
INFO:root:current train perplexity3.884538412094116
INFO:root:current mean train loss 1717.1695118525256
INFO:root:current train perplexity3.8855020999908447
INFO:root:current mean train loss 1720.5336801180276
INFO:root:current train perplexity3.8870925903320312
INFO:root:current mean train loss 1723.328555162818
INFO:root:current train perplexity3.883923053741455
INFO:root:current mean train loss 1723.1488848463932
INFO:root:current train perplexity3.881340742111206
INFO:root:current mean train loss 1723.3635048062195
INFO:root:current train perplexity3.880545139312744
INFO:root:current mean train loss 1723.6524696305996
INFO:root:current train perplexity3.882998466491699
INFO:root:current mean train loss 1723.3617502479356
INFO:root:current train perplexity3.8830647468566895
INFO:root:current mean train loss 1722.271172952428
INFO:root:current train perplexity3.8789587020874023
INFO:root:current mean train loss 1721.9707055349718
INFO:root:current train perplexity3.8819234371185303
INFO:root:current mean train loss 1721.9254765084609
INFO:root:current train perplexity3.882344961166382
INFO:root:current mean train loss 1722.0174973707933
INFO:root:current train perplexity3.8832485675811768
INFO:root:current mean train loss 1720.7588986341457
INFO:root:current train perplexity3.881354331970215
INFO:root:current mean train loss 1720.318633545702
INFO:root:current train perplexity3.8809123039245605
INFO:root:current mean train loss 1720.0091115773978
INFO:root:current train perplexity3.8797647953033447
INFO:root:current mean train loss 1720.2938169484773
INFO:root:current train perplexity3.879934072494507
INFO:root:current mean train loss 1719.8455792874497
INFO:root:current train perplexity3.879382848739624
INFO:root:current mean train loss 1720.3088819974555
INFO:root:current train perplexity3.881500005722046

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it]
INFO:root:final mean train loss: 1719.8450313381516
INFO:root:final train perplexity: 3.8820886611938477
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 2911.2932070253846
INFO:root:eval perplexity: 10.901805877685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [9:01:30<05:44, 344.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1715.1396990520198
INFO:root:current train perplexity3.839329242706299
INFO:root:current mean train loss 1709.1455956762964
INFO:root:current train perplexity3.8499209880828857
INFO:root:current mean train loss 1714.7266287296377
INFO:root:current train perplexity3.8624393939971924
INFO:root:current mean train loss 1717.0212993521966
INFO:root:current train perplexity3.8630995750427246
INFO:root:current mean train loss 1718.0441550100493
INFO:root:current train perplexity3.8652420043945312
INFO:root:current mean train loss 1718.5939133896452
INFO:root:current train perplexity3.8733487129211426
INFO:root:current mean train loss 1720.0448187774928
INFO:root:current train perplexity3.8774325847625732
INFO:root:current mean train loss 1720.5938214938658
INFO:root:current train perplexity3.8790857791900635
INFO:root:current mean train loss 1719.6873848497733
INFO:root:current train perplexity3.8776817321777344
INFO:root:current mean train loss 1720.0845094513747
INFO:root:current train perplexity3.878507375717163
INFO:root:current mean train loss 1719.970973439666
INFO:root:current train perplexity3.878265142440796
INFO:root:current mean train loss 1720.1062591088
INFO:root:current train perplexity3.877910614013672
INFO:root:current mean train loss 1720.04528932378
INFO:root:current train perplexity3.8778584003448486
INFO:root:current mean train loss 1720.122525205488
INFO:root:current train perplexity3.8783276081085205
INFO:root:current mean train loss 1721.8709813991861
INFO:root:current train perplexity3.8814587593078613
INFO:root:current mean train loss 1719.978832760894
INFO:root:current train perplexity3.8788938522338867
INFO:root:current mean train loss 1719.061853288612
INFO:root:current train perplexity3.878948926925659
INFO:root:current mean train loss 1718.835930170301
INFO:root:current train perplexity3.8786520957946777
INFO:root:current mean train loss 1719.752625679235
INFO:root:current train perplexity3.8811168670654297
INFO:root:current mean train loss 1720.4009861335023
INFO:root:current train perplexity3.882350444793701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.86s/it]
INFO:root:final mean train loss: 1719.8902204689568
INFO:root:final train perplexity: 3.88222599029541
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.22s/it]
INFO:root:eval mean loss: 2911.3267393369933
INFO:root:eval perplexity: 10.902109146118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_22/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:07:15<00:00, 344.58s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:07:15<00:00, 328.35s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2911.3267393369933
INFO:root:eval perplexity: 10.902109146118164
INFO:root:evalaution complete
INFO:root:save model final: std_22/final
