INFO:root:Output: small_topk_1
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97675.30595012626
INFO:root:current train perplexity14944.7431640625
INFO:root:current mean train loss 81206.88662060302
INFO:root:current train perplexity2980.61962890625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.88s/it]
INFO:root:final mean train loss: 74852.27184664819
INFO:root:final train perplexity: 1608.1591796875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it]
INFO:root:eval mean loss: 44047.97423735119
INFO:root:eval perplexity: 95.46654510498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/1

  0%|          | 1/200 [04:02<13:24:43, 242.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42786.40333946078
INFO:root:current train perplexity68.72480010986328
INFO:root:current mean train loss 39032.866721854305
INFO:root:current train perplexity46.88528823852539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.04s/it]
INFO:root:final mean train loss: 36455.356350806454
INFO:root:final train perplexity: 36.44021987915039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 31744.44019717262
INFO:root:eval perplexity: 26.720012664794922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/2

  1%|          | 2/200 [07:58<13:07:49, 238.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31208.139322916668
INFO:root:current train perplexity22.04711151123047
INFO:root:current mean train loss 29673.55857478762
INFO:root:current train perplexity18.6218204498291
INFO:root:current mean train loss 28771.90637507697
INFO:root:current train perplexity17.038902282714844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.30s/it]
INFO:root:final mean train loss: 28390.86591166835
INFO:root:final train perplexity: 16.448833465576172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 28527.275948660714
INFO:root:eval perplexity: 19.152830123901367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/3

  2%|â–         | 3/200 [11:55<13:01:32, 238.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26358.585191761365
INFO:root:current train perplexity13.38693904876709
INFO:root:current mean train loss 25882.631161794354
INFO:root:current train perplexity12.812899589538574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.38s/it]
INFO:root:final mean train loss: 25517.52257907006
INFO:root:final train perplexity: 12.389511108398438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 27130.875418526786
INFO:root:eval perplexity: 16.57554817199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/4

  2%|â–         | 4/200 [15:54<12:57:53, 238.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24858.173270089286
INFO:root:current train perplexity11.293660163879395
INFO:root:current mean train loss 24371.2925671729
INFO:root:current train perplexity11.010687828063965
INFO:root:current mean train loss 24093.417742300724
INFO:root:current train perplexity10.757707595825195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.35s/it]
INFO:root:final mean train loss: 23982.206023185485
INFO:root:final train perplexity: 10.648493766784668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.10s/it]
INFO:root:eval mean loss: 26323.337751116072
INFO:root:eval perplexity: 15.246529579162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/5

  2%|â–Ž         | 5/200 [19:56<12:58:30, 239.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23338.48036943856
INFO:root:current train perplexity9.987024307250977
INFO:root:current mean train loss 23109.91144604953
INFO:root:current train perplexity9.755636215209961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.56s/it]
INFO:root:final mean train loss: 22963.30433310232
INFO:root:final train perplexity: 9.630374908447266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.37s/it]
INFO:root:eval mean loss: 25773.198660714286
INFO:root:eval perplexity: 14.402685165405273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/6

  3%|â–Ž         | 6/200 [23:57<12:56:44, 240.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22301.88689630682
INFO:root:current train perplexity9.075033187866211
INFO:root:current mean train loss 22395.037672438062
INFO:root:current train perplexity9.097441673278809
INFO:root:current mean train loss 22276.923846638034
INFO:root:current train perplexity8.989080429077148


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it]
INFO:root:final mean train loss: 22226.395452683973
INFO:root:final train perplexity: 8.955244064331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it]
INFO:root:eval mean loss: 25356.162272135418
INFO:root:eval perplexity: 13.794276237487793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/7

  4%|â–Ž         | 7/200 [27:59<12:54:51, 240.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21871.62162078373
INFO:root:current train perplexity8.63366413116455
INFO:root:current mean train loss 21781.831575920245
INFO:root:current train perplexity8.542098045349121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.89s/it]
INFO:root:final mean train loss: 21666.19498172883
INFO:root:final train perplexity: 8.473851203918457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.38s/it]
INFO:root:eval mean loss: 25075.142438616072
INFO:root:eval perplexity: 13.398855209350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/8

  4%|â–         | 8/200 [31:59<12:49:48, 240.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21447.899609375
INFO:root:current train perplexity8.216767311096191
INFO:root:current mean train loss 21358.59004755435
INFO:root:current train perplexity8.188970565795898
INFO:root:current mean train loss 21247.179587572675
INFO:root:current train perplexity8.11793041229248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.47s/it]
INFO:root:final mean train loss: 21211.00257528982
INFO:root:final train perplexity: 8.101818084716797
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.70s/it]
INFO:root:eval mean loss: 24795.787644159227
INFO:root:eval perplexity: 13.017010688781738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/9

  4%|â–         | 9/200 [35:57<12:42:58, 239.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20986.25784165112
INFO:root:current train perplexity7.884988307952881
INFO:root:current mean train loss 20929.003789296406
INFO:root:current train perplexity7.858023643493652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.45s/it]
INFO:root:final mean train loss: 20838.835220829133
INFO:root:final train perplexity: 7.809811592102051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it]
INFO:root:eval mean loss: 24581.268880208332
INFO:root:eval perplexity: 12.731197357177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/10

  5%|â–Œ         | 10/200 [39:52<12:34:14, 238.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20777.321957236843
INFO:root:current train perplexity7.6301398277282715
INFO:root:current mean train loss 20624.53617384454
INFO:root:current train perplexity7.5990118980407715
INFO:root:current mean train loss 20538.75771439783
INFO:root:current train perplexity7.570006847381592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.09s/it]
INFO:root:final mean train loss: 20514.109378937752
INFO:root:final train perplexity: 7.563640594482422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 24396.94396391369
INFO:root:eval perplexity: 12.490625381469727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/11

  6%|â–Œ         | 11/200 [43:48<12:28:18, 237.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20337.575044014084
INFO:root:current train perplexity7.385002613067627
INFO:root:current mean train loss 20281.61079130117
INFO:root:current train perplexity7.377737045288086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.18s/it]
INFO:root:final mean train loss: 20236.152828093498
INFO:root:final train perplexity: 7.35909366607666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it]
INFO:root:eval mean loss: 24252.38158017113
INFO:root:eval perplexity: 12.30514144897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/12

  6%|â–Œ         | 12/200 [47:46<12:24:35, 237.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20119.646314538044
INFO:root:current train perplexity7.24544620513916
INFO:root:current mean train loss 20022.38457507622
INFO:root:current train perplexity7.210557460784912
INFO:root:current mean train loss 19994.99682945628
INFO:root:current train perplexity7.182818412780762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.68s/it]
INFO:root:final mean train loss: 19990.612036920364
INFO:root:final train perplexity: 7.183012008666992
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it]
INFO:root:eval mean loss: 24121.623046875
INFO:root:eval perplexity: 12.13973617553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/13

  6%|â–‹         | 13/200 [51:42<12:19:34, 237.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19868.943567708335
INFO:root:current train perplexity7.052499771118164
INFO:root:current mean train loss 19800.833738839287
INFO:root:current train perplexity7.040197372436523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.66s/it]
INFO:root:final mean train loss: 19766.578955865676
INFO:root:final train perplexity: 7.026029586791992
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it]
INFO:root:eval mean loss: 23977.20812406994
INFO:root:eval perplexity: 11.95964241027832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/14

  7%|â–‹         | 14/200 [55:39<12:14:41, 237.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19583.45623553241
INFO:root:current train perplexity6.928389072418213
INFO:root:current mean train loss 19542.528927780513
INFO:root:current train perplexity6.901745796203613
INFO:root:current mean train loss 19582.341048320486
INFO:root:current train perplexity6.8919477462768555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.68s/it]
INFO:root:final mean train loss: 19562.197155367943
INFO:root:final train perplexity: 6.885813236236572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.26s/it]
INFO:root:eval mean loss: 23883.52811104911
INFO:root:eval perplexity: 11.844244003295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/15

  8%|â–Š         | 15/200 [59:33<12:08:26, 236.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19391.06699960443
INFO:root:current train perplexity6.778237819671631
INFO:root:current mean train loss 19392.75099292947
INFO:root:current train perplexity6.7692365646362305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.84s/it]
INFO:root:final mean train loss: 19378.78890105217
INFO:root:final train perplexity: 6.762369632720947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 23778.57287016369
INFO:root:eval perplexity: 11.71628475189209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/16

  8%|â–Š         | 16/200 [1:03:27<12:02:31, 235.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19189.90511592742
INFO:root:current train perplexity6.7014079093933105
INFO:root:current mean train loss 19215.02124582538
INFO:root:current train perplexity6.650818824768066
INFO:root:current mean train loss 19211.228997564936
INFO:root:current train perplexity6.6473069190979


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.25s/it]
INFO:root:final mean train loss: 19208.735146799394
INFO:root:final train perplexity: 6.649891376495361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it]
INFO:root:eval mean loss: 23669.15359933036
INFO:root:eval perplexity: 11.584352493286133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/17

  8%|â–Š         | 17/200 [1:07:24<11:59:46, 235.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19055.21194935994
INFO:root:current train perplexity6.547466278076172
INFO:root:current mean train loss 19065.274953039618
INFO:root:current train perplexity6.539527893066406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:35<00:00, 215.40s/it]
INFO:root:final mean train loss: 19048.10437405494
INFO:root:final train perplexity: 6.545364856719971
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.34s/it]
INFO:root:eval mean loss: 23611.37853422619
INFO:root:eval perplexity: 11.51529312133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/18

  9%|â–‰         | 18/200 [1:11:34<12:08:00, 240.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18986.241685267858
INFO:root:current train perplexity6.495525360107422
INFO:root:current mean train loss 18977.279991319443
INFO:root:current train perplexity6.481966495513916
INFO:root:current mean train loss 18906.65431349734
INFO:root:current train perplexity6.450531005859375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.20s/it]
INFO:root:final mean train loss: 18905.39309003276
INFO:root:final train perplexity: 6.4538774490356445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 23540.309012276786
INFO:root:eval perplexity: 11.430906295776367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/19

 10%|â–‰         | 19/200 [1:15:37<12:06:56, 240.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18759.941967492818
INFO:root:current train perplexity6.346940517425537
INFO:root:current mean train loss 18800.54428475936
INFO:root:current train perplexity6.3676886558532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.98s/it]
INFO:root:final mean train loss: 18770.91585811492
INFO:root:final train perplexity: 6.368839740753174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 23442.24523344494
INFO:root:eval perplexity: 11.315478324890137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/20

 10%|â–ˆ         | 20/200 [1:19:41<12:05:44, 241.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18791.19035456731
INFO:root:current train perplexity6.31405782699585
INFO:root:current mean train loss 18676.68542041367
INFO:root:current train perplexity6.2954277992248535
INFO:root:current mean train loss 18668.80626470973
INFO:root:current train perplexity6.294076442718506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it]
INFO:root:final mean train loss: 18645.640054025956
INFO:root:final train perplexity: 6.290630340576172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.36s/it]
INFO:root:eval mean loss: 23387.331728980655
INFO:root:eval perplexity: 11.251347541809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/21

 10%|â–ˆ         | 21/200 [1:23:44<12:03:03, 242.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18513.557220123625
INFO:root:current train perplexity6.211978435516357
INFO:root:current mean train loss 18537.561589905104
INFO:root:current train perplexity6.209935665130615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.81s/it]
INFO:root:final mean train loss: 18525.207236013106
INFO:root:final train perplexity: 6.216349124908447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it]
INFO:root:eval mean loss: 23310.319149925595
INFO:root:eval perplexity: 11.162026405334473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/22

 11%|â–ˆ         | 22/200 [1:27:46<11:58:13, 242.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18455.93391170058
INFO:root:current train perplexity6.165986061096191
INFO:root:current mean train loss 18421.789677119756
INFO:root:current train perplexity6.146706581115723
INFO:root:current mean train loss 18432.43688914609
INFO:root:current train perplexity6.147716522216797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.40s/it]
INFO:root:final mean train loss: 18409.659447454636
INFO:root:final train perplexity: 6.145903587341309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it]
INFO:root:eval mean loss: 23275.9658203125
INFO:root:eval perplexity: 11.12240982055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/23

 12%|â–ˆâ–        | 23/200 [1:31:44<11:50:59, 241.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18362.490337171053
INFO:root:current train perplexity6.0868940353393555
INFO:root:current mean train loss 18330.360546875
INFO:root:current train perplexity6.082834720611572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.38s/it]
INFO:root:final mean train loss: 18306.86547064012
INFO:root:final train perplexity: 6.083906650543213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.25s/it]
INFO:root:eval mean loss: 23203.90108816964
INFO:root:eval perplexity: 11.039765357971191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/24

 12%|â–ˆâ–        | 24/200 [1:35:43<11:44:34, 240.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18148.394115691488
INFO:root:current train perplexity6.008462429046631
INFO:root:current mean train loss 18204.826384460033
INFO:root:current train perplexity6.022468090057373
INFO:root:current mean train loss 18214.755250506074
INFO:root:current train perplexity6.021577835083008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.41s/it]
INFO:root:final mean train loss: 18201.42462355091
INFO:root:final train perplexity: 6.020962238311768
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.14s/it]
INFO:root:eval mean loss: 23183.91882905506
INFO:root:eval perplexity: 11.016958236694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/25

 12%|â–ˆâ–Ž        | 25/200 [1:39:38<11:36:12, 238.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18158.97060448232
INFO:root:current train perplexity5.983885765075684
INFO:root:current mean train loss 18142.578812028896
INFO:root:current train perplexity5.9677276611328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.78s/it]
INFO:root:final mean train loss: 18112.496645035284
INFO:root:final train perplexity: 5.9683837890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 23129.12913876488
INFO:root:eval perplexity: 10.954663276672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/26

 13%|â–ˆâ–Ž        | 26/200 [1:43:35<11:31:15, 238.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18038.12136182598
INFO:root:current train perplexity5.934732437133789
INFO:root:current mean train loss 18051.103696709437
INFO:root:current train perplexity5.9246954917907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.23s/it]
INFO:root:final mean train loss: 18019.420756678428
INFO:root:final train perplexity: 5.913842678070068
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.96s/it]
INFO:root:eval mean loss: 23103.395647321428
INFO:root:eval perplexity: 10.925525665283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/27

 14%|â–ˆâ–Ž        | 27/200 [1:47:34<11:27:41, 238.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18088.39453125
INFO:root:current train perplexity5.854394435882568
INFO:root:current mean train loss 17967.813125758494
INFO:root:current train perplexity5.8798394203186035
INFO:root:current mean train loss 17964.74657481527
INFO:root:current train perplexity5.867504119873047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.84s/it]
INFO:root:final mean train loss: 17936.54515814012
INFO:root:final train perplexity: 5.865697383880615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it]
INFO:root:eval mean loss: 23026.539388020832
INFO:root:eval perplexity: 10.838967323303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/28

 14%|â–ˆâ–        | 28/200 [1:51:40<11:30:17, 240.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17913.545916193183
INFO:root:current train perplexity5.836156368255615
INFO:root:current mean train loss 17887.09364919355
INFO:root:current train perplexity5.8228983879089355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.09s/it]
INFO:root:final mean train loss: 17848.40761639995
INFO:root:final train perplexity: 5.814927577972412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 23011.469075520832
INFO:root:eval perplexity: 10.82207202911377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/29

 14%|â–ˆâ–        | 29/200 [1:55:43<11:28:17, 241.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17904.07449776786
INFO:root:current train perplexity5.787610054016113
INFO:root:current mean train loss 17882.14600978388
INFO:root:current train perplexity5.780958652496338
INFO:root:current mean train loss 17824.869159495775
INFO:root:current train perplexity5.776873588562012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.66s/it]
INFO:root:final mean train loss: 17777.022740517892
INFO:root:final train perplexity: 5.774129390716553
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it]
INFO:root:eval mean loss: 22971.007486979168
INFO:root:eval perplexity: 10.776848793029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/30

 15%|â–ˆâ–Œ        | 30/200 [1:59:45<11:23:57, 241.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17723.89294226695
INFO:root:current train perplexity5.735531330108643
INFO:root:current mean train loss 17716.54111389544
INFO:root:current train perplexity5.731146335601807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.55s/it]
INFO:root:final mean train loss: 17703.70974829889
INFO:root:final train perplexity: 5.732527256011963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.63s/it]
INFO:root:eval mean loss: 22926.042061941964
INFO:root:eval perplexity: 10.726812362670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/31

 16%|â–ˆâ–Œ        | 31/200 [2:03:47<11:20:20, 241.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17558.857421875
INFO:root:current train perplexity5.660210609436035
INFO:root:current mean train loss 17645.329954954956
INFO:root:current train perplexity5.679004669189453
INFO:root:current mean train loss 17645.903037988744
INFO:root:current train perplexity5.695459842681885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.26s/it]
INFO:root:final mean train loss: 17634.52837937878
INFO:root:final train perplexity: 5.693543910980225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 22951.017485119046
INFO:root:eval perplexity: 10.754573822021484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/32

 16%|â–ˆâ–Œ        | 32/200 [2:07:45<11:13:31, 240.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17564.48601810516
INFO:root:current train perplexity5.636106491088867
INFO:root:current mean train loss 17583.383687212423
INFO:root:current train perplexity5.655582427978516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.55s/it]
INFO:root:final mean train loss: 17565.01497527092
INFO:root:final train perplexity: 5.6546406745910645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it]
INFO:root:eval mean loss: 22891.521995907737
INFO:root:eval perplexity: 10.688554763793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/33

 16%|â–ˆâ–‹        | 33/200 [2:11:49<11:12:51, 241.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17345.507682291667
INFO:root:current train perplexity5.570720672607422
INFO:root:current mean train loss 17503.23286345109
INFO:root:current train perplexity5.62040901184082
INFO:root:current mean train loss 17487.821257267442
INFO:root:current train perplexity5.609447002410889


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.75s/it]
INFO:root:final mean train loss: 17503.650894657258
INFO:root:final train perplexity: 5.620520114898682
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it]
INFO:root:eval mean loss: 22840.112397693454
INFO:root:eval perplexity: 10.631836891174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/34

 17%|â–ˆâ–‹        | 34/200 [2:15:47<11:05:14, 240.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17427.554629197763
INFO:root:current train perplexity5.576744556427002
INFO:root:current mean train loss 17455.229930763475
INFO:root:current train perplexity5.5824666023254395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.49s/it]
INFO:root:final mean train loss: 17435.58244077621
INFO:root:final train perplexity: 5.582911968231201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 22828.980771019345
INFO:root:eval perplexity: 10.619598388671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/35

 18%|â–ˆâ–Š        | 35/200 [2:19:46<11:00:18, 240.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17543.01644736842
INFO:root:current train perplexity5.592129707336426
INFO:root:current mean train loss 17416.327616202732
INFO:root:current train perplexity5.5603766441345215
INFO:root:current mean train loss 17388.882504815923
INFO:root:current train perplexity5.546894550323486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.56s/it]
INFO:root:final mean train loss: 17372.309719947076
INFO:root:final train perplexity: 5.548178195953369
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 22827.063383556546
INFO:root:eval perplexity: 10.617488861083984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/36

 18%|â–ˆâ–Š        | 36/200 [2:23:45<10:55:10, 239.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17283.1396346831
INFO:root:current train perplexity5.498708248138428
INFO:root:current mean train loss 17303.315412554824
INFO:root:current train perplexity5.51372766494751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.36s/it]
INFO:root:final mean train loss: 17314.55382513231
INFO:root:final train perplexity: 5.516663551330566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it]
INFO:root:eval mean loss: 22789.772763206845
INFO:root:eval perplexity: 10.576589584350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/37

 18%|â–ˆâ–Š        | 37/200 [2:27:42<10:49:02, 238.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17190.881199048912
INFO:root:current train perplexity5.451145172119141
INFO:root:current mean train loss 17200.18279979675
INFO:root:current train perplexity5.4711737632751465
INFO:root:current mean train loss 17274.29001716648
INFO:root:current train perplexity5.487730979919434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.65s/it]
INFO:root:final mean train loss: 17258.151493195564
INFO:root:final train perplexity: 5.486057758331299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 22750.97619047619
INFO:root:eval perplexity: 10.534210205078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/38

 19%|â–ˆâ–‰        | 38/200 [2:31:48<10:50:35, 240.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17229.9875
INFO:root:current train perplexity5.452658176422119
INFO:root:current mean train loss 17207.95658482143
INFO:root:current train perplexity5.451247692108154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.51s/it]
INFO:root:final mean train loss: 17204.683392924646
INFO:root:final train perplexity: 5.457202911376953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it]
INFO:root:eval mean loss: 22760.970145089286
INFO:root:eval perplexity: 10.545108795166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/39

 20%|â–ˆâ–‰        | 39/200 [2:35:47<10:45:43, 240.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17062.039641203704
INFO:root:current train perplexity5.386232852935791
INFO:root:current mean train loss 17155.63744924951
INFO:root:current train perplexity5.4280595779418945
INFO:root:current mean train loss 17157.327101115086
INFO:root:current train perplexity5.425393581390381


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.35s/it]
INFO:root:final mean train loss: 17148.201951549898
INFO:root:final train perplexity: 5.426884651184082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it]
INFO:root:eval mean loss: 22727.709984188987
INFO:root:eval perplexity: 10.50887393951416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/40

 20%|â–ˆâ–ˆ        | 40/200 [2:39:48<10:41:37, 240.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17139.378572488135
INFO:root:current train perplexity5.408289909362793
INFO:root:current mean train loss 17150.343569963337
INFO:root:current train perplexity5.412641525268555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it]
INFO:root:final mean train loss: 17096.319076045867
INFO:root:final train perplexity: 5.399186611175537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.16s/it]
INFO:root:eval mean loss: 22702.35791015625
INFO:root:eval perplexity: 10.481334686279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/41

 20%|â–ˆâ–ˆ        | 41/200 [2:43:49<10:37:40, 240.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16967.020444808466
INFO:root:current train perplexity5.339437007904053
INFO:root:current mean train loss 17024.64890714456
INFO:root:current train perplexity5.357693672180176
INFO:root:current mean train loss 17067.49468175054
INFO:root:current train perplexity5.372897624969482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.07s/it]
INFO:root:final mean train loss: 17047.977566626763
INFO:root:final train perplexity: 5.373503684997559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it]
INFO:root:eval mean loss: 22681.813523065477
INFO:root:eval perplexity: 10.459073066711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/42

 21%|â–ˆâ–ˆ        | 42/200 [2:47:50<10:34:27, 240.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16990.236116340362
INFO:root:current train perplexity5.3452534675598145
INFO:root:current mean train loss 17026.150726818647
INFO:root:current train perplexity5.3502655029296875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.65s/it]
INFO:root:final mean train loss: 17000.128331338205
INFO:root:final train perplexity: 5.348203182220459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it]
INFO:root:eval mean loss: 22695.124372209822
INFO:root:eval perplexity: 10.473490715026855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/43

 22%|â–ˆâ–ˆâ–       | 43/200 [2:51:47<10:27:13, 239.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17080.443917410714
INFO:root:current train perplexity5.35853910446167
INFO:root:current mean train loss 16997.63323929398
INFO:root:current train perplexity5.324622631072998
INFO:root:current mean train loss 16966.079641788565
INFO:root:current train perplexity5.322901248931885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.30s/it]
INFO:root:final mean train loss: 16949.308270854333
INFO:root:final train perplexity: 5.321462631225586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it]
INFO:root:eval mean loss: 22665.21216982887
INFO:root:eval perplexity: 10.441123962402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/44

 22%|â–ˆâ–ˆâ–       | 44/200 [2:55:41<10:18:28, 237.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16890.305383441093
INFO:root:current train perplexity5.2843337059021
INFO:root:current mean train loss 16914.12914125167
INFO:root:current train perplexity5.293575763702393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.88s/it]
INFO:root:final mean train loss: 16905.87041645665
INFO:root:final train perplexity: 5.29871129989624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.02s/it]
INFO:root:eval mean loss: 22645.456240699405
INFO:root:eval perplexity: 10.419795036315918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:59:35<10:11:54, 236.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16902.546774839742
INFO:root:current train perplexity5.2886199951171875
INFO:root:current mean train loss 16867.229969930308
INFO:root:current train perplexity5.277039051055908
INFO:root:current mean train loss 16878.25566733133
INFO:root:current train perplexity5.27687931060791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.32s/it]
INFO:root:final mean train loss: 16861.83888687626
INFO:root:final train perplexity: 5.275750160217285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 22632.550944010418
INFO:root:eval perplexity: 10.405884742736816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:03:30<10:06:18, 236.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16868.07668698489
INFO:root:current train perplexity5.2558746337890625
INFO:root:current mean train loss 16855.240633180627
INFO:root:current train perplexity5.260135650634766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:20<00:00, 200.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:20<00:00, 200.71s/it]
INFO:root:final mean train loss: 16822.88653761341
INFO:root:final train perplexity: 5.255519390106201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.93s/it]
INFO:root:eval mean loss: 22638.245628720237
INFO:root:eval perplexity: 10.412018775939941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:07:24<10:00:52, 235.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16773.605809411336
INFO:root:current train perplexity5.225454807281494
INFO:root:current mean train loss 16788.568079381555
INFO:root:current train perplexity5.230081081390381
INFO:root:current mean train loss 16782.591676311727
INFO:root:current train perplexity5.229549407958984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.50s/it]
INFO:root:final mean train loss: 16771.583956810737
INFO:root:final train perplexity: 5.2289934158325195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it]
INFO:root:eval mean loss: 22631.209170386905
INFO:root:eval perplexity: 10.404440879821777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/48

 24%|â–ˆâ–ˆâ–       | 48/200 [3:11:20<9:57:23, 235.81s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16717.140707236842
INFO:root:current train perplexity5.192777156829834
INFO:root:current mean train loss 16730.46987179487
INFO:root:current train perplexity5.199298858642578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.66s/it]
INFO:root:final mean train loss: 16735.385754000756
INFO:root:final train perplexity: 5.210357666015625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it]
INFO:root:eval mean loss: 22579.751325334822
INFO:root:eval perplexity: 10.349176406860352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/49

 24%|â–ˆâ–ˆâ–       | 49/200 [3:15:17<9:54:03, 236.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16718.328436668882
INFO:root:current train perplexity5.167000770568848
INFO:root:current mean train loss 16699.622741284013
INFO:root:current train perplexity5.184810161590576
INFO:root:current mean train loss 16705.054319806426
INFO:root:current train perplexity5.188919544219971


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.57s/it]
INFO:root:final mean train loss: 16694.370455834174
INFO:root:final train perplexity: 5.189322471618652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.03s/it]
INFO:root:eval mean loss: 22600.25023251488
INFO:root:eval perplexity: 10.371156692504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:19:19<9:54:46, 237.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16666.344391177397
INFO:root:current train perplexity5.153859615325928
INFO:root:current mean train loss 16639.281416849873
INFO:root:current train perplexity5.165038108825684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.77s/it]
INFO:root:final mean train loss: 16651.69644657258
INFO:root:final train perplexity: 5.1675262451171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.63s/it]
INFO:root:eval mean loss: 22584.973586309523
INFO:root:eval perplexity: 10.354771614074707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:23:18<9:51:41, 238.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16627.08038449755
INFO:root:current train perplexity5.144315242767334
INFO:root:current mean train loss 16635.06440785389
INFO:root:current train perplexity5.147136688232422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.19s/it]
INFO:root:final mean train loss: 16615.33238170993
INFO:root:final train perplexity: 5.1490254402160645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it]
INFO:root:eval mean loss: 22573.733723958332
INFO:root:eval perplexity: 10.342735290527344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:27:20<9:50:24, 239.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16692.414713541668
INFO:root:current train perplexity5.2532453536987305
INFO:root:current mean train loss 16542.62665920813
INFO:root:current train perplexity5.11122989654541
INFO:root:current mean train loss 16585.319292641627
INFO:root:current train perplexity5.128081321716309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.57s/it]
INFO:root:final mean train loss: 16577.563070974044
INFO:root:final train perplexity: 5.129879474639893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it]
INFO:root:eval mean loss: 22550.13488188244
INFO:root:eval perplexity: 10.317505836486816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [3:31:24<9:49:27, 240.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16534.625355113636
INFO:root:current train perplexity5.119297504425049
INFO:root:current mean train loss 16590.310345262096
INFO:root:current train perplexity5.128192901611328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.03s/it]
INFO:root:final mean train loss: 16544.112564579133
INFO:root:final train perplexity: 5.11298131942749
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 22554.57103329613
INFO:root:eval perplexity: 10.32224178314209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:35:24<9:45:27, 240.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16368.7919921875
INFO:root:current train perplexity5.089649200439453
INFO:root:current mean train loss 16501.104136244157
INFO:root:current train perplexity5.094335556030273
INFO:root:current mean train loss 16504.708658854168
INFO:root:current train perplexity5.096032619476318


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.76s/it]
INFO:root:final mean train loss: 16505.61947139617
INFO:root:final train perplexity: 5.093606472015381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it]
INFO:root:eval mean loss: 22528.262881324405
INFO:root:eval perplexity: 10.294173240661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:39:29<9:44:05, 241.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16511.806938559323
INFO:root:current train perplexity5.075661659240723
INFO:root:current mean train loss 16455.96418656643
INFO:root:current train perplexity5.071064472198486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it]
INFO:root:final mean train loss: 16475.08919795867
INFO:root:final train perplexity: 5.078291416168213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 22546.8115234375
INFO:root:eval perplexity: 10.313957214355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:43:31<9:40:25, 241.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16584.98162286932
INFO:root:current train perplexity5.103369235992432
INFO:root:current mean train loss 16424.946887317004
INFO:root:current train perplexity5.051731109619141
INFO:root:current mean train loss 16464.348679095085
INFO:root:current train perplexity5.062617301940918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.57s/it]
INFO:root:final mean train loss: 16435.24513687626
INFO:root:final train perplexity: 5.05837345123291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 22537.702125186013
INFO:root:eval perplexity: 10.304235458374023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:47:27<9:31:57, 239.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16374.924231150793
INFO:root:current train perplexity5.0183258056640625
INFO:root:current mean train loss 16409.144980588575
INFO:root:current train perplexity5.04136323928833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.96s/it]
INFO:root:final mean train loss: 16407.283081054688
INFO:root:final train perplexity: 5.044441223144531
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.08s/it]
INFO:root:eval mean loss: 22538.392275855655
INFO:root:eval perplexity: 10.304970741271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:51:23<9:25:38, 239.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16376.41796875
INFO:root:current train perplexity5.035531520843506
INFO:root:current mean train loss 16324.634239130435
INFO:root:current train perplexity5.004471302032471
INFO:root:current mean train loss 16358.724014353198
INFO:root:current train perplexity5.022045135498047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.51s/it]
INFO:root:final mean train loss: 16374.17072123866
INFO:root:final train perplexity: 5.027994155883789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.41s/it]
INFO:root:eval mean loss: 22501.341703869046
INFO:root:eval perplexity: 10.265531539916992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [3:55:19<9:19:12, 237.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16343.217350746268
INFO:root:current train perplexity4.99155855178833
INFO:root:current mean train loss 16339.933886133982
INFO:root:current train perplexity5.009781837463379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.81s/it]
INFO:root:final mean train loss: 16339.583484280494
INFO:root:final train perplexity: 5.010869979858398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it]
INFO:root:eval mean loss: 22500.020112537204
INFO:root:eval perplexity: 10.264129638671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [3:59:16<9:14:53, 237.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16303.357319078947
INFO:root:current train perplexity5.001341342926025
INFO:root:current mean train loss 16284.967986804097
INFO:root:current train perplexity4.990010738372803
INFO:root:current mean train loss 16310.121334546233
INFO:root:current train perplexity4.993556976318359


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.56s/it]
INFO:root:final mean train loss: 16311.130485288559
INFO:root:final train perplexity: 4.996827602386475
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it]
INFO:root:eval mean loss: 22502.241071428572
INFO:root:eval perplexity: 10.266489028930664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:03:15<9:11:54, 238.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16311.056186729753
INFO:root:current train perplexity4.986583232879639
INFO:root:current mean train loss 16310.417220623172
INFO:root:current train perplexity4.98521089553833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.70s/it]
INFO:root:final mean train loss: 16279.837819745464
INFO:root:final train perplexity: 4.981429100036621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.15s/it]
INFO:root:eval mean loss: 22504.680338541668
INFO:root:eval perplexity: 10.269079208374023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:07:18<9:10:55, 239.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16172.942680027174
INFO:root:current train perplexity4.932371616363525
INFO:root:current mean train loss 16264.322400597053
INFO:root:current train perplexity4.960109233856201
INFO:root:current mean train loss 16265.102372652747
INFO:root:current train perplexity4.968684673309326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.96s/it]
INFO:root:final mean train loss: 16249.065914030998
INFO:root:final train perplexity: 4.96633243560791
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 22512.61451357887
INFO:root:eval perplexity: 10.27751636505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:11:20<9:08:32, 240.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16209.135572916666
INFO:root:current train perplexity4.9536614418029785
INFO:root:current mean train loss 16242.372237723213
INFO:root:current train perplexity4.948716640472412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.42s/it]
INFO:root:final mean train loss: 16219.385454731602
INFO:root:final train perplexity: 4.951815605163574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.94s/it]
INFO:root:eval mean loss: 22490.22391183036
INFO:root:eval perplexity: 10.253726959228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:15:18<9:03:02, 239.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16309.990993923611
INFO:root:current train perplexity4.954561233520508
INFO:root:current mean train loss 16176.094565083662
INFO:root:current train perplexity4.927545070648193
INFO:root:current mean train loss 16199.125765762665
INFO:root:current train perplexity4.936884880065918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.89s/it]
INFO:root:final mean train loss: 16193.04138577369
INFO:root:final train perplexity: 4.93896484375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it]
INFO:root:eval mean loss: 22497.475074404763
INFO:root:eval perplexity: 10.261425971984863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:19:19<9:00:08, 240.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16173.573662480221
INFO:root:current train perplexity4.915156364440918
INFO:root:current mean train loss 16169.27049144553
INFO:root:current train perplexity4.919668674468994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.30s/it]
INFO:root:final mean train loss: 16158.022586945564
INFO:root:final train perplexity: 4.92193603515625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 22499.706496465773
INFO:root:eval perplexity: 10.2637939453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:23:23<8:58:27, 241.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16072.853799143146
INFO:root:current train perplexity4.872136116027832
INFO:root:current mean train loss 16139.03515625
INFO:root:current train perplexity4.899824142456055
INFO:root:current mean train loss 16141.731737012988
INFO:root:current train perplexity4.908453464508057


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.64s/it]
INFO:root:final mean train loss: 16132.132548670616
INFO:root:final train perplexity: 4.9093828201293945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.50s/it]
INFO:root:eval mean loss: 22476.875418526786
INFO:root:eval perplexity: 10.239572525024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:27:24<8:54:53, 241.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16113.063735410391
INFO:root:current train perplexity4.890442848205566
INFO:root:current mean train loss 16121.581892503415
INFO:root:current train perplexity4.892712593078613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.10s/it]
INFO:root:final mean train loss: 16109.525288243447
INFO:root:final train perplexity: 4.8984479904174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.48s/it]
INFO:root:eval mean loss: 22493.06787109375
INFO:root:eval perplexity: 10.256744384765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [4:31:24<8:49:32, 240.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16172.419280133929
INFO:root:current train perplexity4.908148288726807
INFO:root:current mean train loss 16103.833080150464
INFO:root:current train perplexity4.884161949157715
INFO:root:current mean train loss 16097.703943650266
INFO:root:current train perplexity4.883957862854004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.81s/it]
INFO:root:final mean train loss: 16080.898776146674
INFO:root:final train perplexity: 4.884636878967285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it]
INFO:root:eval mean loss: 22474.265718005954
INFO:root:eval perplexity: 10.236804008483887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [4:35:23<8:44:50, 240.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16059.182471264368
INFO:root:current train perplexity4.878457546234131
INFO:root:current mean train loss 16039.111761572527
INFO:root:current train perplexity4.870715618133545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.02s/it]
INFO:root:final mean train loss: 16058.286392704133
INFO:root:final train perplexity: 4.873754501342773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.39s/it]
INFO:root:eval mean loss: 22482.722609747023
INFO:root:eval perplexity: 10.245772361755371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [4:39:22<8:39:58, 239.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15927.632461939103
INFO:root:current train perplexity4.8488664627075195
INFO:root:current mean train loss 15991.832614377248
INFO:root:current train perplexity4.844374179840088
INFO:root:current mean train loss 16036.364065768828
INFO:root:current train perplexity4.856884956359863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.43s/it]
INFO:root:final mean train loss: 16029.647925592239
INFO:root:final train perplexity: 4.860007286071777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it]
INFO:root:eval mean loss: 22455.41638764881
INFO:root:eval perplexity: 10.216854095458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [4:43:22<8:35:36, 239.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15979.493496737638
INFO:root:current train perplexity4.831925868988037
INFO:root:current mean train loss 15995.171757403468
INFO:root:current train perplexity4.839903354644775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.07s/it]
INFO:root:final mean train loss: 16003.4017609627
INFO:root:final train perplexity: 4.847442150115967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 22455.979166666668
INFO:root:eval perplexity: 10.217451095581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [4:47:19<8:29:53, 239.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15992.671125545057
INFO:root:current train perplexity4.8173370361328125
INFO:root:current mean train loss 15988.660757211539
INFO:root:current train perplexity4.833646774291992
INFO:root:current mean train loss 15994.712283789866
INFO:root:current train perplexity4.836689472198486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.97s/it]
INFO:root:final mean train loss: 15980.413062310989
INFO:root:final train perplexity: 4.836463451385498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it]
INFO:root:eval mean loss: 22460.28466796875
INFO:root:eval perplexity: 10.222002983093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [4:51:15<8:24:12, 238.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15952.572162828947
INFO:root:current train perplexity4.819579601287842
INFO:root:current mean train loss 15964.072120392628
INFO:root:current train perplexity4.825897216796875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.95s/it]
INFO:root:final mean train loss: 15958.398122479839
INFO:root:final train perplexity: 4.825973033905029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it]
INFO:root:eval mean loss: 22470.018415178572
INFO:root:eval perplexity: 10.232307434082031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [4:55:15<8:20:56, 238.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15914.673121675532
INFO:root:current train perplexity4.794133186340332
INFO:root:current mean train loss 15928.418746014031
INFO:root:current train perplexity4.800216197967529
INFO:root:current mean train loss 15945.953188259109
INFO:root:current train perplexity4.813643455505371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.70s/it]
INFO:root:final mean train loss: 15933.37931577621
INFO:root:final train perplexity: 4.814079284667969
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it]
INFO:root:eval mean loss: 22459.893043154763
INFO:root:eval perplexity: 10.221588134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [4:59:21<8:21:41, 240.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15906.27857678346
INFO:root:current train perplexity4.794893264770508
INFO:root:current mean train loss 15913.34173798681
INFO:root:current train perplexity4.798643112182617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.57s/it]
INFO:root:final mean train loss: 15902.84388782132
INFO:root:final train perplexity: 4.799602508544922
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 22488.671409970237
INFO:root:eval perplexity: 10.252081871032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:03:20<8:16:28, 240.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15876.368010876226
INFO:root:current train perplexity4.789977550506592
INFO:root:current mean train loss 15904.855119515729
INFO:root:current train perplexity4.791364669799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it]
INFO:root:final mean train loss: 15883.622810609879
INFO:root:final train perplexity: 4.7905120849609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.13s/it]
INFO:root:eval mean loss: 22458.715518043155
INFO:root:eval perplexity: 10.220343589782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:07:22<8:13:32, 240.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15473.140299479166
INFO:root:current train perplexity4.661133289337158
INFO:root:current mean train loss 15874.783942657767
INFO:root:current train perplexity4.775558948516846
INFO:root:current mean train loss 15861.299958628386
INFO:root:current train perplexity4.775139808654785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.40s/it]
INFO:root:final mean train loss: 15860.554400044102
INFO:root:final train perplexity: 4.779623508453369
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it]
INFO:root:eval mean loss: 22446.847516741072
INFO:root:eval perplexity: 10.207797050476074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:11:20<8:08:22, 240.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15823.017258522726
INFO:root:current train perplexity4.777800559997559
INFO:root:current mean train loss 15846.268101058467
INFO:root:current train perplexity4.772578239440918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.87s/it]
INFO:root:final mean train loss: 15845.843068768902
INFO:root:final train perplexity: 4.772694110870361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 22450.000651041668
INFO:root:eval perplexity: 10.211129188537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:15:19<8:03:40, 239.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15757.442661830357
INFO:root:current train perplexity4.727297306060791
INFO:root:current mean train loss 15857.106691734813
INFO:root:current train perplexity4.765521049499512
INFO:root:current mean train loss 15854.347599637682
INFO:root:current train perplexity4.768894672393799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.72s/it]
INFO:root:final mean train loss: 15824.898469002017
INFO:root:final train perplexity: 4.762843608856201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it]
INFO:root:eval mean loss: 22463.390113467263
INFO:root:eval perplexity: 10.22529125213623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:19:17<7:58:11, 239.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15747.422735699152
INFO:root:current train perplexity4.727479934692383
INFO:root:current mean train loss 15790.677095617139
INFO:root:current train perplexity4.743034362792969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.03s/it]
INFO:root:final mean train loss: 15801.042240265877
INFO:root:final train perplexity: 4.751650810241699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 22463.59423828125
INFO:root:eval perplexity: 10.225507736206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [5:23:14<7:53:19, 238.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15888.807173295454
INFO:root:current train perplexity4.82317590713501
INFO:root:current mean train loss 15806.211245425113
INFO:root:current train perplexity4.738554954528809
INFO:root:current mean train loss 15805.652260441351
INFO:root:current train perplexity4.739963054656982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.30s/it]
INFO:root:final mean train loss: 15775.15691548009
INFO:root:final train perplexity: 4.739534854888916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 22461.17696707589
INFO:root:eval perplexity: 10.22294807434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [5:27:11<7:47:54, 237.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15761.255735367064
INFO:root:current train perplexity4.732584476470947
INFO:root:current mean train loss 15761.702280243482
INFO:root:current train perplexity4.738142490386963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.26s/it]
INFO:root:final mean train loss: 15760.53705030872
INFO:root:final train perplexity: 4.732705593109131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.05s/it]
INFO:root:eval mean loss: 22441.823381696428
INFO:root:eval perplexity: 10.202489852905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [5:31:07<7:42:49, 237.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15754.316276041667
INFO:root:current train perplexity4.697251319885254
INFO:root:current mean train loss 15718.290336277174
INFO:root:current train perplexity4.7153730392456055
INFO:root:current mean train loss 15748.757480922965
INFO:root:current train perplexity4.722289085388184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.51s/it]
INFO:root:final mean train loss: 15734.910392515121
INFO:root:final train perplexity: 4.720757484436035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.60s/it]
INFO:root:eval mean loss: 22470.8935546875
INFO:root:eval perplexity: 10.233231544494629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [5:35:11<7:42:37, 239.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15678.568942397387
INFO:root:current train perplexity4.70124626159668
INFO:root:current mean train loss 15725.23338674214
INFO:root:current train perplexity4.7114577293396


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.37s/it]
INFO:root:final mean train loss: 15720.242904170867
INFO:root:final train perplexity: 4.71393346786499
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.00s/it]
INFO:root:eval mean loss: 22437.37720889137
INFO:root:eval perplexity: 10.197798728942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [5:39:14<7:40:47, 240.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15502.905016447368
INFO:root:current train perplexity4.701220512390137
INFO:root:current mean train loss 15716.16132976628
INFO:root:current train perplexity4.701403617858887
INFO:root:current mean train loss 15708.564511094464
INFO:root:current train perplexity4.701452255249023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.34s/it]
INFO:root:final mean train loss: 15694.52700904108
INFO:root:final train perplexity: 4.701991558074951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it]
INFO:root:eval mean loss: 22456.549293154763
INFO:root:eval perplexity: 10.218050003051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [5:43:12<7:35:54, 239.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15619.303449603873
INFO:root:current train perplexity4.691589832305908
INFO:root:current mean train loss 15672.087439464547
INFO:root:current train perplexity4.690986156463623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.63s/it]
INFO:root:final mean train loss: 15679.947612147178
INFO:root:final train perplexity: 4.695235729217529
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.91s/it]
INFO:root:eval mean loss: 22452.893089657737
INFO:root:eval perplexity: 10.214187622070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [5:47:14<7:32:37, 240.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15682.266049592392
INFO:root:current train perplexity4.6724162101745605
INFO:root:current mean train loss 15662.023715383639
INFO:root:current train perplexity4.681450843811035
INFO:root:current mean train loss 15667.313599180214
INFO:root:current train perplexity4.684254169464111


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.60s/it]
INFO:root:final mean train loss: 15658.053053332913
INFO:root:final train perplexity: 4.685107231140137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it]
INFO:root:eval mean loss: 22443.35816592262
INFO:root:eval perplexity: 10.204113006591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [5:51:14<7:28:42, 240.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15641.259908854166
INFO:root:current train perplexity4.664435863494873
INFO:root:current mean train loss 15634.370625
INFO:root:current train perplexity4.671910285949707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.30s/it]
INFO:root:final mean train loss: 15639.470313287551
INFO:root:final train perplexity: 4.676527976989746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it]
INFO:root:eval mean loss: 22422.489327566964
INFO:root:eval perplexity: 10.182100296020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/89
############################# best###############
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [5:55:10<7:22:20, 239.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15584.654007523148
INFO:root:current train perplexity4.653799533843994
INFO:root:current mean train loss 15580.559939406989
INFO:root:current train perplexity4.650118827819824
INFO:root:current mean train loss 15618.710270684196
INFO:root:current train perplexity4.663256645202637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it]
INFO:root:final mean train loss: 15620.197013608871
INFO:root:final train perplexity: 4.667646884918213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 22439.493257068454
INFO:root:eval perplexity: 10.200031280517578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [5:59:12<7:20:01, 240.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15655.519246934335
INFO:root:current train perplexity4.659433841705322
INFO:root:current mean train loss 15600.697391105097
INFO:root:current train perplexity4.6553754806518555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.70s/it]
INFO:root:final mean train loss: 15599.245794480847
INFO:root:final train perplexity: 4.658010482788086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it]
INFO:root:eval mean loss: 22456.093889508928
INFO:root:eval perplexity: 10.217570304870605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:03:19<7:19:28, 241.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15608.01017515121
INFO:root:current train perplexity4.661990165710449
INFO:root:current mean train loss 15581.42350757395
INFO:root:current train perplexity4.653385162353516
INFO:root:current mean train loss 15597.661652800325
INFO:root:current train perplexity4.65396785736084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.80s/it]
INFO:root:final mean train loss: 15588.487411006805
INFO:root:final train perplexity: 4.653070449829102
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it]
INFO:root:eval mean loss: 22464.14815848214
INFO:root:eval perplexity: 10.226093292236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:07:18<7:14:01, 241.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15599.723903426206
INFO:root:current train perplexity4.6511969566345215
INFO:root:current mean train loss 15579.232934170082
INFO:root:current train perplexity4.6433515548706055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.28s/it]
INFO:root:final mean train loss: 15569.584708921371
INFO:root:final train perplexity: 4.644403457641602
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 22441.718936011905
INFO:root:eval perplexity: 10.202383041381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:11:24<7:12:24, 242.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15534.340987723213
INFO:root:current train perplexity4.603333950042725
INFO:root:current mean train loss 15533.96433738426
INFO:root:current train perplexity4.628584384918213
INFO:root:current mean train loss 15559.593882978723
INFO:root:current train perplexity4.634260177612305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.60s/it]
INFO:root:final mean train loss: 15549.490974672379
INFO:root:final train perplexity: 4.6352081298828125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.28s/it]
INFO:root:eval mean loss: 22455.84249441964
INFO:root:eval perplexity: 10.217307090759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [6:15:27<7:08:55, 242.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15564.337868175287
INFO:root:current train perplexity4.6216044425964355
INFO:root:current mean train loss 15552.159002130682
INFO:root:current train perplexity4.629144668579102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.26s/it]
INFO:root:final mean train loss: 15533.660140498992
INFO:root:final train perplexity: 4.627976417541504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it]
INFO:root:eval mean loss: 22450.075334821428
INFO:root:eval perplexity: 10.211209297180176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [6:19:26<7:02:45, 241.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15465.05413661859
INFO:root:current train perplexity4.576797008514404
INFO:root:current mean train loss 15522.413732295414
INFO:root:current train perplexity4.605875015258789
INFO:root:current mean train loss 15541.89814330544
INFO:root:current train perplexity4.621639728546143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.52s/it]
INFO:root:final mean train loss: 15519.165145381805
INFO:root:final train perplexity: 4.621364116668701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 22451.328543526786
INFO:root:eval perplexity: 10.212533950805664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [6:23:23<6:56:21, 240.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15544.44254378434
INFO:root:current train perplexity4.618824481964111
INFO:root:current mean train loss 15496.604369478076
INFO:root:current train perplexity4.61077356338501


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:34<00:00, 214.79s/it]
INFO:root:final mean train loss: 15500.818579889114
INFO:root:final train perplexity: 4.613008499145508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it]
INFO:root:eval mean loss: 22461.750162760418
INFO:root:eval perplexity: 10.223555564880371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [6:27:31<6:56:11, 242.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15474.301553415698
INFO:root:current train perplexity4.608948230743408
INFO:root:current mean train loss 15493.815422858392
INFO:root:current train perplexity4.607659816741943
INFO:root:current mean train loss 15488.921617798354
INFO:root:current train perplexity4.603838920593262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.08s/it]
INFO:root:final mean train loss: 15480.345939390121
INFO:root:final train perplexity: 4.603703498840332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it]
INFO:root:eval mean loss: 22466.944475446428
INFO:root:eval perplexity: 10.229050636291504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [6:31:30<6:50:34, 241.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15515.83904194079
INFO:root:current train perplexity4.598840713500977
INFO:root:current mean train loss 15481.895412660257
INFO:root:current train perplexity4.597609043121338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it]
INFO:root:final mean train loss: 15467.602078345513
INFO:root:final train perplexity: 4.5979204177856445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 22460.177315848214
INFO:root:eval perplexity: 10.221890449523926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [6:35:32<6:46:56, 241.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15396.426633144947
INFO:root:current train perplexity4.551224708557129
INFO:root:current mean train loss 15445.774613360969
INFO:root:current train perplexity4.579318523406982
INFO:root:current mean train loss 15461.725060096154
INFO:root:current train perplexity4.589731693267822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.54s/it]
INFO:root:final mean train loss: 15450.94968734249
INFO:root:final train perplexity: 4.590373992919922
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 22440.607607886905
INFO:root:eval perplexity: 10.201208114624023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [6:39:31<6:41:36, 240.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15385.07626065341
INFO:root:current train perplexity4.565054893493652
INFO:root:current mean train loss 15451.376231744662
INFO:root:current train perplexity4.581569671630859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.00s/it]
INFO:root:final mean train loss: 15433.578758978074
INFO:root:final train perplexity: 4.582516193389893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it]
INFO:root:eval mean loss: 22475.24879092262
INFO:root:eval perplexity: 10.237849235534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [6:43:37<6:40:08, 242.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15467.536017922794
INFO:root:current train perplexity4.56963586807251
INFO:root:current mean train loss 15442.539081901905
INFO:root:current train perplexity4.57659912109375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.61s/it]
INFO:root:final mean train loss: 15419.72710984753
INFO:root:final train perplexity: 4.576260089874268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it]
INFO:root:eval mean loss: 22450.256487165178
INFO:root:eval perplexity: 10.21139907836914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [6:47:35<6:33:45, 241.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15484.597005208334
INFO:root:current train perplexity4.512804985046387
INFO:root:current mean train loss 15436.917589502427
INFO:root:current train perplexity4.562524318695068
INFO:root:current mean train loss 15403.922505195505
INFO:root:current train perplexity4.564161777496338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.97s/it]
INFO:root:final mean train loss: 15404.29097624748
INFO:root:final train perplexity: 4.56929874420166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it]
INFO:root:eval mean loss: 22457.448683965773
INFO:root:eval perplexity: 10.219005584716797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [6:51:40<6:31:29, 242.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15371.951526988636
INFO:root:current train perplexity4.5394744873046875
INFO:root:current mean train loss 15385.021774193548
INFO:root:current train perplexity4.559871196746826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.85s/it]
INFO:root:final mean train loss: 15391.502468970513
INFO:root:final train perplexity: 4.563538551330566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 22453.965471540178
INFO:root:eval perplexity: 10.215319633483887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [6:55:44<6:28:12, 242.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15190.29296875
INFO:root:current train perplexity4.497881889343262
INFO:root:current mean train loss 15296.58519823306
INFO:root:current train perplexity4.538299560546875
INFO:root:current mean train loss 15384.31736865942
INFO:root:current train perplexity4.557793140411377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.22s/it]
INFO:root:final mean train loss: 15375.746302450856
INFO:root:final train perplexity: 4.556451797485352
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it]
INFO:root:eval mean loss: 22459.854073660714
INFO:root:eval perplexity: 10.221549034118652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [6:59:49<6:25:33, 243.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15369.472424523305
INFO:root:current train perplexity4.551150321960449
INFO:root:current mean train loss 15397.27729461478
INFO:root:current train perplexity4.552122592926025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it]
INFO:root:final mean train loss: 15357.60244455645
INFO:root:final train perplexity: 4.548304557800293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it]
INFO:root:eval mean loss: 22453.86937313988
INFO:root:eval perplexity: 10.215217590332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [7:03:50<6:20:01, 242.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15084.568803267046
INFO:root:current train perplexity4.503518104553223
INFO:root:current mean train loss 15324.805787232544
INFO:root:current train perplexity4.532604217529297
INFO:root:current mean train loss 15359.259265773104
INFO:root:current train perplexity4.542995929718018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.49s/it]
INFO:root:final mean train loss: 15347.122664913055
INFO:root:final train perplexity: 4.543605327606201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it]
INFO:root:eval mean loss: 22478.549990699405
INFO:root:eval perplexity: 10.241344451904297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [7:07:55<6:17:25, 243.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15300.44742063492
INFO:root:current train perplexity4.528188705444336
INFO:root:current mean train loss 15339.632033646472
INFO:root:current train perplexity4.536213397979736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.10s/it]
INFO:root:final mean train loss: 15334.198289440525
INFO:root:final train perplexity: 4.53781795501709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it]
INFO:root:eval mean loss: 22476.10477120536
INFO:root:eval perplexity: 10.238754272460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [7:11:57<6:12:45, 243.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15059.714453125
INFO:root:current train perplexity4.50545597076416
INFO:root:current mean train loss 15303.878422214673
INFO:root:current train perplexity4.5238423347473145
INFO:root:current mean train loss 15326.56316315407
INFO:root:current train perplexity4.5286359786987305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.70s/it]
INFO:root:final mean train loss: 15321.050576486896
INFO:root:final train perplexity: 4.5319366455078125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it]
INFO:root:eval mean loss: 22473.739560081845
INFO:root:eval perplexity: 10.236248016357422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [7:16:02<6:09:18, 243.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15236.166802705224
INFO:root:current train perplexity4.507192134857178
INFO:root:current mean train loss 15294.676395256362
INFO:root:current train perplexity4.522279739379883


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.68s/it]
INFO:root:final mean train loss: 15301.700616651966
INFO:root:final train perplexity: 4.523296356201172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.17s/it]
INFO:root:eval mean loss: 22480.0712890625
INFO:root:eval perplexity: 10.242959022521973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [7:20:03<6:04:22, 242.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15290.886872944078
INFO:root:current train perplexity4.50250768661499
INFO:root:current mean train loss 15337.800502232143
INFO:root:current train perplexity4.51874303817749
INFO:root:current mean train loss 15299.773598030823
INFO:root:current train perplexity4.517507553100586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.18s/it]
INFO:root:final mean train loss: 15293.322241998489
INFO:root:final train perplexity: 4.519559383392334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it]
INFO:root:eval mean loss: 22482.303199404763
INFO:root:eval perplexity: 10.245323181152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [7:24:07<6:00:39, 243.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15302.975544674297
INFO:root:current train perplexity4.514919757843018
INFO:root:current mean train loss 15292.986373812135
INFO:root:current train perplexity4.5153326988220215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.00s/it]
INFO:root:final mean train loss: 15276.965064264114
INFO:root:final train perplexity: 4.51227331161499
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.81s/it]
INFO:root:eval mean loss: 22480.22635323661
INFO:root:eval perplexity: 10.243123054504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [7:28:06<5:54:56, 242.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15186.95219089674
INFO:root:current train perplexity4.481618881225586
INFO:root:current mean train loss 15246.738725863821
INFO:root:current train perplexity4.5037617683410645
INFO:root:current mean train loss 15271.987225861827
INFO:root:current train perplexity4.5089569091796875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.94s/it]
INFO:root:final mean train loss: 15267.568772838962
INFO:root:final train perplexity: 4.50809383392334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it]
INFO:root:eval mean loss: 22462.433756510418
INFO:root:eval perplexity: 10.224279403686523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [7:32:07<5:50:05, 241.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15247.534231770833
INFO:root:current train perplexity4.500854969024658
INFO:root:current mean train loss 15265.821138392857
INFO:root:current train perplexity4.504537582397461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.34s/it]
INFO:root:final mean train loss: 15254.159510458669
INFO:root:final train perplexity: 4.502135276794434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it]
INFO:root:eval mean loss: 22489.714006696428
INFO:root:eval perplexity: 10.25318717956543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [7:36:04<5:44:22, 240.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15208.999855324075
INFO:root:current train perplexity4.513180732727051
INFO:root:current mean train loss 15230.22604730561
INFO:root:current train perplexity4.4956769943237305
INFO:root:current mean train loss 15243.513732103524
INFO:root:current train perplexity4.491824150085449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.23s/it]
INFO:root:final mean train loss: 15238.35013703377
INFO:root:final train perplexity: 4.495120525360107
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it]
INFO:root:eval mean loss: 22468.11793154762
INFO:root:eval perplexity: 10.230294227600098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [7:40:02<5:39:18, 239.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15202.727984078323
INFO:root:current train perplexity4.480866432189941
INFO:root:current mean train loss 15240.339014490224
INFO:root:current train perplexity4.485483169555664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.32s/it]
INFO:root:final mean train loss: 15227.936417118195
INFO:root:final train perplexity: 4.490506172180176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 22478.340308779763
INFO:root:eval perplexity: 10.241125106811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [7:44:00<5:34:48, 239.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15284.615297379032
INFO:root:current train perplexity4.4989848136901855
INFO:root:current mean train loss 15252.519561068702
INFO:root:current train perplexity4.488704204559326
INFO:root:current mean train loss 15233.174711681548
INFO:root:current train perplexity4.487215995788574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.03s/it]
INFO:root:final mean train loss: 15215.983205487652
INFO:root:final train perplexity: 4.485215187072754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it]
INFO:root:eval mean loss: 22485.059523809523
INFO:root:eval perplexity: 10.248250007629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [7:47:58<5:30:18, 238.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15222.281955948794
INFO:root:current train perplexity4.476894855499268
INFO:root:current mean train loss 15231.643576033128
INFO:root:current train perplexity4.480865955352783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.44s/it]
INFO:root:final mean train loss: 15202.846057522682
INFO:root:final train perplexity: 4.47940731048584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.80s/it]
INFO:root:eval mean loss: 22495.740792410714
INFO:root:eval perplexity: 10.259581565856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [7:51:58<5:26:47, 239.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15152.4296875
INFO:root:current train perplexity4.450808048248291
INFO:root:current mean train loss 15201.453993055555
INFO:root:current train perplexity4.463890552520752
INFO:root:current mean train loss 15202.940762134309
INFO:root:current train perplexity4.474930286407471


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.17s/it]
INFO:root:final mean train loss: 15192.540417086693
INFO:root:final train perplexity: 4.474856376647949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 22490.61739676339
INFO:root:eval perplexity: 10.254144668579102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [7:56:01<5:24:29, 240.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15134.887279992816
INFO:root:current train perplexity4.465137958526611
INFO:root:current mean train loss 15185.244192847593
INFO:root:current train perplexity4.468319416046143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.20s/it]
INFO:root:final mean train loss: 15179.554195280998
INFO:root:final train perplexity: 4.469128608703613
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.00s/it]
INFO:root:eval mean loss: 22497.77515811012
INFO:root:eval perplexity: 10.261743545532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [7:59:59<5:19:27, 239.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15142.45129707532
INFO:root:current train perplexity4.451344966888428
INFO:root:current mean train loss 15151.936994154676
INFO:root:current train perplexity4.4612932205200195
INFO:root:current mean train loss 15178.955331459205
INFO:root:current train perplexity4.464330196380615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.06s/it]
INFO:root:final mean train loss: 15169.424304592994
INFO:root:final train perplexity: 4.464665412902832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it]
INFO:root:eval mean loss: 22502.82445126488
INFO:root:eval perplexity: 10.267107963562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [8:04:00<5:16:01, 240.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15132.297615470467
INFO:root:current train perplexity4.449758529663086
INFO:root:current mean train loss 15149.573058123364
INFO:root:current train perplexity4.448707103729248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.80s/it]
INFO:root:final mean train loss: 15157.56045236895
INFO:root:final train perplexity: 4.459444046020508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it]
INFO:root:eval mean loss: 22483.72009858631
INFO:root:eval perplexity: 10.246828079223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [8:07:58<5:11:06, 239.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15130.2373046875
INFO:root:current train perplexity4.468289852142334
INFO:root:current mean train loss 15177.283612871504
INFO:root:current train perplexity4.461501121520996
INFO:root:current mean train loss 15161.696506076389
INFO:root:current train perplexity4.456188678741455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.72s/it]
INFO:root:final mean train loss: 15150.225109469506
INFO:root:final train perplexity: 4.456218242645264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it]
INFO:root:eval mean loss: 22492.984351748513
INFO:root:eval perplexity: 10.256658554077148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [8:11:57<5:07:03, 239.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15113.899424342106
INFO:root:current train perplexity4.4453935623168945
INFO:root:current mean train loss 15154.590159254807
INFO:root:current train perplexity4.448398590087891


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.47s/it]
INFO:root:final mean train loss: 15137.856382308468
INFO:root:final train perplexity: 4.450785160064697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it]
INFO:root:eval mean loss: 22524.654296875
INFO:root:eval perplexity: 10.290329933166504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [8:15:57<5:03:31, 239.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15124.819294381648
INFO:root:current train perplexity4.43451452255249
INFO:root:current mean train loss 15138.691937712585
INFO:root:current train perplexity4.44173526763916
INFO:root:current mean train loss 15137.44209023912
INFO:root:current train perplexity4.444896697998047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.89s/it]
INFO:root:final mean train loss: 15123.569906911542
INFO:root:final train perplexity: 4.444517612457275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 22494.43054780506
INFO:root:eval perplexity: 10.25819206237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [8:19:56<4:59:11, 239.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15109.165177162247
INFO:root:current train perplexity4.437711715698242
INFO:root:current mean train loss 15121.828615734925
INFO:root:current train perplexity4.437271595001221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.37s/it]
INFO:root:final mean train loss: 15113.537613407258
INFO:root:final train perplexity: 4.440122127532959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 22483.111676897322
INFO:root:eval perplexity: 10.246183395385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [8:23:53<4:54:12, 238.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15102.641907935049
INFO:root:current train perplexity4.428356170654297
INFO:root:current mean train loss 15086.483598923842
INFO:root:current train perplexity4.427475929260254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.61s/it]
INFO:root:final mean train loss: 15100.899327431956
INFO:root:final train perplexity: 4.434591293334961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.73s/it]
INFO:root:eval mean loss: 22485.107026599704
INFO:root:eval perplexity: 10.248298645019531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [8:27:50<4:49:39, 238.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14970.702473958334
INFO:root:current train perplexity4.459012985229492
INFO:root:current mean train loss 15092.11089199029
INFO:root:current train perplexity4.4331464767456055
INFO:root:current mean train loss 15087.949978833129
INFO:root:current train perplexity4.425477981567383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.27s/it]
INFO:root:final mean train loss: 15090.644381615424
INFO:root:final train perplexity: 4.430108070373535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it]
INFO:root:eval mean loss: 22491.729840959822
INFO:root:eval perplexity: 10.25532341003418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [8:31:48<4:45:56, 238.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15108.785174005681
INFO:root:current train perplexity4.430773735046387
INFO:root:current mean train loss 15092.708259828629
INFO:root:current train perplexity4.4297194480896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.34s/it]
INFO:root:final mean train loss: 15081.753118699597
INFO:root:final train perplexity: 4.426224708557129
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it]
INFO:root:eval mean loss: 22505.40564546131
INFO:root:eval perplexity: 10.26984977722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [8:35:46<4:41:35, 237.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15099.341099330357
INFO:root:current train perplexity4.3775153160095215
INFO:root:current mean train loss 15092.305481527454
INFO:root:current train perplexity4.429011344909668
INFO:root:current mean train loss 15077.857643606581
INFO:root:current train perplexity4.42061710357666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.68s/it]
INFO:root:final mean train loss: 15069.284286006805
INFO:root:final train perplexity: 4.4207844734191895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.85s/it]
INFO:root:eval mean loss: 22515.45861235119
INFO:root:eval perplexity: 10.280543327331543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [8:39:43<4:37:20, 237.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15107.240118511652
INFO:root:current train perplexity4.429839134216309
INFO:root:current mean train loss 15054.273185681997
INFO:root:current train perplexity4.417663097381592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:33<00:00, 213.01s/it]
INFO:root:final mean train loss: 15063.781206684727
INFO:root:final train perplexity: 4.418385982513428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it]
INFO:root:eval mean loss: 22508.018856956845
INFO:root:eval perplexity: 10.272626876831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [8:43:49<4:36:15, 240.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14966.358043323864
INFO:root:current train perplexity4.432547569274902
INFO:root:current mean train loss 15061.816010346283
INFO:root:current train perplexity4.411170959472656
INFO:root:current mean train loss 15056.142828050948
INFO:root:current train perplexity4.4123382568359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.76s/it]
INFO:root:final mean train loss: 15054.74847608997
INFO:root:final train perplexity: 4.4144511222839355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it]
INFO:root:eval mean loss: 22503.02420479911
INFO:root:eval perplexity: 10.267318725585938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [8:47:51<4:32:48, 240.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14953.61509486607
INFO:root:current train perplexity4.4009199142456055
INFO:root:current mean train loss 15017.946552674463
INFO:root:current train perplexity4.403619766235352


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.46s/it]
INFO:root:final mean train loss: 15048.04099593624
INFO:root:final train perplexity: 4.4115309715271
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.12s/it]
INFO:root:eval mean loss: 22511.24816313244
INFO:root:eval perplexity: 10.276061058044434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [8:51:57<4:30:38, 242.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14992.94296875
INFO:root:current train perplexity4.411197185516357
INFO:root:current mean train loss 15049.553974184782
INFO:root:current train perplexity4.412124156951904
INFO:root:current mean train loss 15041.137881540697
INFO:root:current train perplexity4.4029645919799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.85s/it]
INFO:root:final mean train loss: 15033.440339119205
INFO:root:final train perplexity: 4.405182838439941
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 22514.460984002977
INFO:root:eval perplexity: 10.27947998046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [8:55:59<4:26:24, 242.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14984.822834071829
INFO:root:current train perplexity4.385179042816162
INFO:root:current mean train loss 15059.180897969685
INFO:root:current train perplexity4.407581329345703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.21s/it]
INFO:root:final mean train loss: 15022.651477444557
INFO:root:final train perplexity: 4.4004974365234375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it]
INFO:root:eval mean loss: 22520.15062313988
INFO:root:eval perplexity: 10.285534858703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [8:59:57<4:21:13, 241.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15064.1083984375
INFO:root:current train perplexity4.39879035949707
INFO:root:current mean train loss 15051.685940782563
INFO:root:current train perplexity4.408237934112549
INFO:root:current mean train loss 15045.728502247432
INFO:root:current train perplexity4.399138450622559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.87s/it]
INFO:root:final mean train loss: 15012.737111737652
INFO:root:final train perplexity: 4.3961968421936035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]
INFO:root:eval mean loss: 22527.30836123512
INFO:root:eval perplexity: 10.293159484863281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [9:03:56<4:16:26, 240.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14996.89883637764
INFO:root:current train perplexity4.3856658935546875
INFO:root:current mean train loss 15039.454364263524
INFO:root:current train perplexity4.3964762687683105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.87s/it]
INFO:root:final mean train loss: 15006.07779029108
INFO:root:final train perplexity: 4.393311023712158
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.25s/it]
INFO:root:eval mean loss: 22524.05980282738
INFO:root:eval perplexity: 10.289697647094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [9:07:54<4:11:38, 239.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14912.926970108696
INFO:root:current train perplexity4.3653483390808105
INFO:root:current mean train loss 14994.284870426829
INFO:root:current train perplexity4.390185832977295
INFO:root:current mean train loss 15007.131314812219
INFO:root:current train perplexity4.39166259765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.41s/it]
INFO:root:final mean train loss: 14999.558511057208
INFO:root:final train perplexity: 4.390486240386963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it]
INFO:root:eval mean loss: 22531.210844494046
INFO:root:eval perplexity: 10.297314643859863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [9:11:56<4:08:21, 240.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14942.1798828125
INFO:root:current train perplexity4.369134902954102
INFO:root:current mean train loss 14991.735731026785
INFO:root:current train perplexity4.378137588500977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.14s/it]
INFO:root:final mean train loss: 14992.506024760585
INFO:root:final train perplexity: 4.38743257522583
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it]
INFO:root:eval mean loss: 22510.436965215773
INFO:root:eval perplexity: 10.275201797485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [9:16:00<4:05:21, 241.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14984.53197337963
INFO:root:current train perplexity4.381315231323242
INFO:root:current mean train loss 14947.148499015748
INFO:root:current train perplexity4.370699882507324
INFO:root:current mean train loss 14988.972965996696
INFO:root:current train perplexity4.379531383514404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.88s/it]
INFO:root:final mean train loss: 14976.97316422001
INFO:root:final train perplexity: 4.3807172775268555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 22522.05545479911
INFO:root:eval perplexity: 10.28756332397461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [9:20:04<4:02:14, 242.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14941.824799742879
INFO:root:current train perplexity4.379263401031494
INFO:root:current mean train loss 14965.407499345321
INFO:root:current train perplexity4.376265525817871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.30s/it]
INFO:root:final mean train loss: 14975.484835716987
INFO:root:final train perplexity: 4.380073070526123
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it]
INFO:root:eval mean loss: 22526.81324404762
INFO:root:eval perplexity: 10.29262924194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [9:24:06<3:58:03, 242.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14947.090631300403
INFO:root:current train perplexity4.377269744873047
INFO:root:current mean train loss 14978.681677898378
INFO:root:current train perplexity4.380539894104004
INFO:root:current mean train loss 14973.293712797618
INFO:root:current train perplexity4.3765177726745605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.83s/it]
INFO:root:final mean train loss: 14963.756619361138
INFO:root:final train perplexity: 4.375009059906006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.06s/it]
INFO:root:eval mean loss: 22531.841750372023
INFO:root:eval perplexity: 10.297987937927246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [9:28:12<3:55:20, 243.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15026.578677993222
INFO:root:current train perplexity4.366926670074463
INFO:root:current mean train loss 14977.423118382856
INFO:root:current train perplexity4.367354393005371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.59s/it]
INFO:root:final mean train loss: 14958.357039913055
INFO:root:final train perplexity: 4.372680187225342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it]
INFO:root:eval mean loss: 22524.085960751487
INFO:root:eval perplexity: 10.289724349975586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [9:32:17<3:51:39, 243.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14889.378934151786
INFO:root:current train perplexity4.3349714279174805
INFO:root:current mean train loss 14937.56673900463
INFO:root:current train perplexity4.356264114379883
INFO:root:current mean train loss 14949.887213264628
INFO:root:current train perplexity4.3681111335754395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.80s/it]
INFO:root:final mean train loss: 14949.125480405746
INFO:root:final train perplexity: 4.368700981140137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 22526.90211123512
INFO:root:eval perplexity: 10.292725563049316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [9:36:21<3:47:43, 243.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14927.680360991379
INFO:root:current train perplexity4.356929302215576
INFO:root:current mean train loss 14967.611234124332
INFO:root:current train perplexity4.369764804840088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.47s/it]
INFO:root:final mean train loss: 14943.196489887852
INFO:root:final train perplexity: 4.366146087646484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.01s/it]
INFO:root:eval mean loss: 22540.940266927082
INFO:root:eval perplexity: 10.307690620422363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [9:40:26<3:43:40, 244.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14950.98369891827
INFO:root:current train perplexity4.357226848602295
INFO:root:current mean train loss 14937.458085094424
INFO:root:current train perplexity4.360898494720459
INFO:root:current mean train loss 14944.160082701359
INFO:root:current train perplexity4.361866474151611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it]
INFO:root:final mean train loss: 14933.472144342239
INFO:root:final train perplexity: 4.3619608879089355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it]
INFO:root:eval mean loss: 22520.593215215773
INFO:root:eval perplexity: 10.286005973815918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [9:44:27<3:38:54, 243.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14975.002543355082
INFO:root:current train perplexity4.352797031402588
INFO:root:current mean train loss 14936.392930914595
INFO:root:current train perplexity4.352182388305664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it]
INFO:root:final mean train loss: 14928.384513608871
INFO:root:final train perplexity: 4.359772205352783
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.41s/it]
INFO:root:eval mean loss: 22532.58570498512
INFO:root:eval perplexity: 10.298783302307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [9:48:31<3:35:04, 243.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14912.249795603198
INFO:root:current train perplexity4.352868556976318
INFO:root:current mean train loss 14913.279706621504
INFO:root:current train perplexity4.347753047943115
INFO:root:current mean train loss 14934.403505176184
INFO:root:current train perplexity4.355710506439209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.01s/it]
INFO:root:final mean train loss: 14918.30009608115
INFO:root:final train perplexity: 4.355437755584717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it]
INFO:root:eval mean loss: 22535.23546781994
INFO:root:eval perplexity: 10.301605224609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [9:52:34<3:30:49, 243.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14926.634333881579
INFO:root:current train perplexity4.350663185119629
INFO:root:current mean train loss 14907.58329326923
INFO:root:current train perplexity4.347591876983643


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.97s/it]
INFO:root:final mean train loss: 14907.529229933216
INFO:root:final train perplexity: 4.350813865661621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 22549.283528645832
INFO:root:eval perplexity: 10.316593170166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [9:56:34<3:26:02, 242.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14895.54469331782
INFO:root:current train perplexity4.3396897315979
INFO:root:current mean train loss 14888.528512967687
INFO:root:current train perplexity4.341405868530273
INFO:root:current mean train loss 14917.150651568825
INFO:root:current train perplexity4.3503737449646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.82s/it]
INFO:root:final mean train loss: 14906.407443138862
INFO:root:final train perplexity: 4.350332260131836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.37s/it]
INFO:root:eval mean loss: 22544.19714936756
INFO:root:eval perplexity: 10.311165809631348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [10:00:33<3:21:06, 241.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14885.630109690657
INFO:root:current train perplexity4.337212562561035
INFO:root:current mean train loss 14876.572766174622
INFO:root:current train perplexity4.341857433319092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.78s/it]
INFO:root:final mean train loss: 14896.303896011845
INFO:root:final train perplexity: 4.345999240875244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.03s/it]
INFO:root:eval mean loss: 22553.53687686012
INFO:root:eval perplexity: 10.321137428283691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [10:04:37<3:17:51, 242.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14882.854721966913
INFO:root:current train perplexity4.343596458435059
INFO:root:current mean train loss 14877.583971440397
INFO:root:current train perplexity4.33843469619751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.90s/it]
INFO:root:final mean train loss: 14889.869309948337
INFO:root:final train perplexity: 4.3432416915893555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it]
INFO:root:eval mean loss: 22540.218912760418
INFO:root:eval perplexity: 10.306921005249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [10:08:34<3:12:29, 240.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14960.475260416666
INFO:root:current train perplexity4.352710723876953
INFO:root:current mean train loss 14884.717868249394
INFO:root:current train perplexity4.337708950042725
INFO:root:current mean train loss 14901.991894050185
INFO:root:current train perplexity4.3433942794799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.05s/it]
INFO:root:final mean train loss: 14889.87861485635
INFO:root:final train perplexity: 4.3432464599609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.02s/it]
INFO:root:eval mean loss: 22555.05740792411
INFO:root:eval perplexity: 10.322763442993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [10:12:36<3:08:45, 240.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14845.331622869318
INFO:root:current train perplexity4.319192886352539
INFO:root:current mean train loss 14865.580790070564
INFO:root:current train perplexity4.330148220062256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it]
INFO:root:final mean train loss: 14877.888841198337
INFO:root:final train perplexity: 4.3381123542785645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it]
INFO:root:eval mean loss: 22549.71065848214
INFO:root:eval perplexity: 10.317048072814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [10:16:41<3:05:34, 242.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14997.517020089286
INFO:root:current train perplexity4.396358489990234
INFO:root:current mean train loss 14848.445732330607
INFO:root:current train perplexity4.333374500274658
INFO:root:current mean train loss 14889.227369225544
INFO:root:current train perplexity4.337454319000244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.59s/it]
INFO:root:final mean train loss: 14871.857807774697
INFO:root:final train perplexity: 4.3355326652526855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.11s/it]
INFO:root:eval mean loss: 22552.11356026786
INFO:root:eval perplexity: 10.319616317749023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [10:20:42<3:01:22, 241.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14905.11487023305
INFO:root:current train perplexity4.335261344909668
INFO:root:current mean train loss 14859.334371314859
INFO:root:current train perplexity4.329567909240723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.30s/it]
INFO:root:final mean train loss: 14863.124299080142
INFO:root:final train perplexity: 4.33180046081543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.30s/it]
INFO:root:eval mean loss: 22544.76013764881
INFO:root:eval perplexity: 10.311765670776367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [10:24:41<2:56:45, 241.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14832.643909801136
INFO:root:current train perplexity4.280807971954346
INFO:root:current mean train loss 14865.851685670044
INFO:root:current train perplexity4.323286056518555
INFO:root:current mean train loss 14870.01139477192
INFO:root:current train perplexity4.327853679656982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.56s/it]
INFO:root:final mean train loss: 14860.998129567792
INFO:root:final train perplexity: 4.3308916091918945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 22555.98318917411
INFO:root:eval perplexity: 10.323750495910645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [10:28:39<2:51:59, 239.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14798.443033854166
INFO:root:current train perplexity4.320776462554932
INFO:root:current mean train loss 14869.802704419095
INFO:root:current train perplexity4.331836223602295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.15s/it]
INFO:root:final mean train loss: 14855.762104649697
INFO:root:final train perplexity: 4.32865571975708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
INFO:root:eval mean loss: 22545.669410342263
INFO:root:eval perplexity: 10.312734603881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [10:32:34<2:47:06, 238.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14934.863932291666
INFO:root:current train perplexity4.330310821533203
INFO:root:current mean train loss 14863.86702615489
INFO:root:current train perplexity4.33154821395874
INFO:root:current mean train loss 14864.87144349564
INFO:root:current train perplexity4.328002452850342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.93s/it]
INFO:root:final mean train loss: 14851.900441815777
INFO:root:final train perplexity: 4.327006816864014
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.96s/it]
INFO:root:eval mean loss: 22557.938639322918
INFO:root:eval perplexity: 10.325840950012207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [10:36:31<2:42:39, 238.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14825.580908931903
INFO:root:current train perplexity4.309178352355957
INFO:root:current mean train loss 14831.027162471932
INFO:root:current train perplexity4.315115928649902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.57s/it]
INFO:root:final mean train loss: 14841.632910943801
INFO:root:final train perplexity: 4.322627067565918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.92s/it]
INFO:root:eval mean loss: 22553.309151785714
INFO:root:eval perplexity: 10.320893287658691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [10:40:29<2:38:43, 238.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14820.64884868421
INFO:root:current train perplexity4.301254749298096
INFO:root:current mean train loss 14853.67467338498
INFO:root:current train perplexity4.3201141357421875
INFO:root:current mean train loss 14838.101888020834
INFO:root:current train perplexity4.321012020111084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.92s/it]
INFO:root:final mean train loss: 14835.69468639743
INFO:root:final train perplexity: 4.320096492767334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it]
INFO:root:eval mean loss: 22565.384440104168
INFO:root:eval perplexity: 10.333800315856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [10:44:27<2:34:48, 238.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14829.481225242078
INFO:root:current train perplexity4.301889896392822
INFO:root:current mean train loss 14830.398917214912
INFO:root:current train perplexity4.308727264404297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.14s/it]
INFO:root:final mean train loss: 14829.055916078629
INFO:root:final train perplexity: 4.3172688484191895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it]
INFO:root:eval mean loss: 22552.624465215773
INFO:root:eval perplexity: 10.320159912109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [10:48:27<2:31:05, 238.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14824.470405910326
INFO:root:current train perplexity4.32792854309082
INFO:root:current mean train loss 14876.432561610773
INFO:root:current train perplexity4.321932792663574
INFO:root:current mean train loss 14836.96576776205
INFO:root:current train perplexity4.313521385192871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.74s/it]
INFO:root:final mean train loss: 14825.295748802924
INFO:root:final train perplexity: 4.315668106079102
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it]
INFO:root:eval mean loss: 22551.967238653273
INFO:root:eval perplexity: 10.319461822509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [10:52:25<2:27:03, 238.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14809.917265625
INFO:root:current train perplexity4.3238749504089355
INFO:root:current mean train loss 14815.567940848214
INFO:root:current train perplexity4.313019752502441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:final mean train loss: 14821.94888404108
INFO:root:final train perplexity: 4.314242839813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 22559.51892671131
INFO:root:eval perplexity: 10.327529907226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [10:56:27<2:23:38, 239.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.768663194445
INFO:root:current train perplexity4.298202037811279
INFO:root:current mean train loss 14853.740826464074
INFO:root:current train perplexity4.325437545776367
INFO:root:current mean train loss 14830.44005971228
INFO:root:current train perplexity4.313330173492432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.34s/it]
INFO:root:final mean train loss: 14812.805857012348
INFO:root:final train perplexity: 4.310354232788086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.33s/it]
INFO:root:eval mean loss: 22564.398251488095
INFO:root:eval perplexity: 10.332746505737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [11:00:30<2:20:20, 240.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14853.094330992879
INFO:root:current train perplexity4.320463180541992
INFO:root:current mean train loss 14840.51939485859
INFO:root:current train perplexity4.314640522003174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.05s/it]
INFO:root:final mean train loss: 14811.03951140373
INFO:root:final train perplexity: 4.309603214263916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 22565.70398530506
INFO:root:eval perplexity: 10.33414077758789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [11:04:29<2:16:04, 240.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14836.577904485886
INFO:root:current train perplexity4.307901382446289
INFO:root:current mean train loss 14829.759169250954
INFO:root:current train perplexity4.30397367477417
INFO:root:current mean train loss 14816.992381966991
INFO:root:current train perplexity4.3070173263549805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.52s/it]
INFO:root:final mean train loss: 14802.762573242188
INFO:root:final train perplexity: 4.306086540222168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 22571.81701078869
INFO:root:eval perplexity: 10.340683937072754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [11:08:29<2:11:59, 239.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14799.324277579066
INFO:root:current train perplexity4.300307273864746
INFO:root:current mean train loss 14828.106637423156
INFO:root:current train perplexity4.306925296783447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.92s/it]
INFO:root:final mean train loss: 14804.573844663559
INFO:root:final train perplexity: 4.306856632232666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.35s/it]
INFO:root:eval mean loss: 22559.9501953125
INFO:root:eval perplexity: 10.327987670898438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [11:12:27<2:07:38, 239.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14946.765234375
INFO:root:current train perplexity4.339297294616699
INFO:root:current mean train loss 14793.372489872685
INFO:root:current train perplexity4.297464370727539
INFO:root:current mean train loss 14816.106407912233
INFO:root:current train perplexity4.305741310119629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.19s/it]
INFO:root:final mean train loss: 14799.042039440525
INFO:root:final train perplexity: 4.304506778717041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 22560.089797247023
INFO:root:eval perplexity: 10.32813549041748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [11:16:22<2:03:02, 238.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14792.7341954023
INFO:root:current train perplexity4.3029584884643555
INFO:root:current mean train loss 14790.355197192514
INFO:root:current train perplexity4.299912929534912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:24<00:00, 204.05s/it]
INFO:root:final mean train loss: 14789.680990895917
INFO:root:final train perplexity: 4.300534248352051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it]
INFO:root:eval mean loss: 22566.623558407737
INFO:root:eval perplexity: 10.335124015808105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [11:20:19<1:58:56, 237.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14714.501752804486
INFO:root:current train perplexity4.269582271575928
INFO:root:current mean train loss 14764.693331272481
INFO:root:current train perplexity4.297012805938721
INFO:root:current mean train loss 14795.19147162657
INFO:root:current train perplexity4.300738334655762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.59s/it]
INFO:root:final mean train loss: 14786.853862147178
INFO:root:final train perplexity: 4.299335479736328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 22579.364350818454
INFO:root:eval perplexity: 10.348761558532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [11:24:22<1:55:43, 239.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14819.719908997253
INFO:root:current train perplexity4.312457084655762
INFO:root:current mean train loss 14775.74463657559
INFO:root:current train perplexity4.295194149017334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.84s/it]
INFO:root:final mean train loss: 14779.079117313508
INFO:root:final train perplexity: 4.296039581298828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it]
INFO:root:eval mean loss: 22561.087495349704
INFO:root:eval perplexity: 10.329204559326172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [11:28:23<1:51:55, 239.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14757.44102016715
INFO:root:current train perplexity4.293835163116455
INFO:root:current mean train loss 14805.125723885489
INFO:root:current train perplexity4.300886154174805
INFO:root:current mean train loss 14795.154345100309
INFO:root:current train perplexity4.296713829040527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:final mean train loss: 14780.853236044606
INFO:root:final train perplexity: 4.2967915534973145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.87s/it]
INFO:root:eval mean loss: 22567.34119233631
INFO:root:eval perplexity: 10.335892677307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [11:32:25<1:48:12, 240.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14808.682935855262
INFO:root:current train perplexity4.295976161956787
INFO:root:current mean train loss 14798.774754607372
INFO:root:current train perplexity4.2959699630737305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.72s/it]
INFO:root:final mean train loss: 14776.849542433216
INFO:root:final train perplexity: 4.295094966888428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.95s/it]
INFO:root:eval mean loss: 22571.4677734375
INFO:root:eval perplexity: 10.340307235717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [11:36:26<1:44:18, 240.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14703.23265043218
INFO:root:current train perplexity4.272159099578857
INFO:root:current mean train loss 14763.348705888606
INFO:root:current train perplexity4.283480644226074
INFO:root:current mean train loss 14783.121734248482
INFO:root:current train perplexity4.293067932128906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.65s/it]
INFO:root:final mean train loss: 14770.997554655998
INFO:root:final train perplexity: 4.292616367340088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 22567.42406063988
INFO:root:eval perplexity: 10.335981369018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [11:40:24<1:39:57, 239.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14765.074623184975
INFO:root:current train perplexity4.286128044128418
INFO:root:current mean train loss 14775.457826240578
INFO:root:current train perplexity4.289834022521973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.26s/it]
INFO:root:final mean train loss: 14772.40912062122
INFO:root:final train perplexity: 4.293214321136475
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 22566.66868954613
INFO:root:eval perplexity: 10.335172653198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [11:44:21<1:35:35, 238.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14779.30681295956
INFO:root:current train perplexity4.277069091796875
INFO:root:current mean train loss 14760.887035647766
INFO:root:current train perplexity4.281198024749756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.34s/it]
INFO:root:final mean train loss: 14765.741399949597
INFO:root:final train perplexity: 4.290391445159912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it]
INFO:root:eval mean loss: 22580.01502046131
INFO:root:eval perplexity: 10.349454879760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [11:48:17<1:31:18, 238.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14779.004557291666
INFO:root:current train perplexity4.267416000366211
INFO:root:current mean train loss 14760.026130157767
INFO:root:current train perplexity4.287253379821777
INFO:root:current mean train loss 14788.767289485837
INFO:root:current train perplexity4.291004657745361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.26s/it]
INFO:root:final mean train loss: 14766.580298639114
INFO:root:final train perplexity: 4.290747165679932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it]
INFO:root:eval mean loss: 22580.13058035714
INFO:root:eval perplexity: 10.349583625793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [11:52:21<1:27:56, 239.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14816.67373934659
INFO:root:current train perplexity4.278865814208984
INFO:root:current mean train loss 14793.05087575605
INFO:root:current train perplexity4.28840446472168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.60s/it]
INFO:root:final mean train loss: 14760.655163180443
INFO:root:final train perplexity: 4.2882399559021
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 22575.737165178572
INFO:root:eval perplexity: 10.344879150390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [11:56:18<1:23:37, 238.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14699.268973214286
INFO:root:current train perplexity4.2762274742126465
INFO:root:current mean train loss 14732.434880622079
INFO:root:current train perplexity4.28256368637085
INFO:root:current mean train loss 14761.917638511473
INFO:root:current train perplexity4.2840118408203125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.12s/it]
INFO:root:final mean train loss: 14755.695694461945
INFO:root:final train perplexity: 4.286142826080322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 22579.180571056546
INFO:root:eval perplexity: 10.348567008972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [12:00:21<1:20:01, 240.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14731.155472060382
INFO:root:current train perplexity4.28394889831543
INFO:root:current mean train loss 14741.146048299921
INFO:root:current train perplexity4.277821063995361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.02s/it]
INFO:root:final mean train loss: 14753.876760175152
INFO:root:final train perplexity: 4.285374164581299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it]
INFO:root:eval mean loss: 22576.770833333332
INFO:root:eval perplexity: 10.345983505249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [12:04:21<1:16:04, 240.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14849.04385653409
INFO:root:current train perplexity4.269927501678467
INFO:root:current mean train loss 14782.511261261261
INFO:root:current train perplexity4.288850784301758
INFO:root:current mean train loss 14768.092430946386
INFO:root:current train perplexity4.286234378814697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.47s/it]
INFO:root:final mean train loss: 14750.295248708417
INFO:root:final train perplexity: 4.283860683441162
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 22578.819359188987
INFO:root:eval perplexity: 10.34817886352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [12:08:24<1:12:15, 240.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14701.020399305555
INFO:root:current train perplexity4.273421764373779
INFO:root:current mean train loss 14742.319845187883
INFO:root:current train perplexity4.27583122253418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.91s/it]
INFO:root:final mean train loss: 14747.347920079384
INFO:root:final train perplexity: 4.282614707946777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it]
INFO:root:eval mean loss: 22585.076032366072
INFO:root:eval perplexity: 10.35488224029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [12:12:27<1:08:27, 241.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14713.659049479167
INFO:root:current train perplexity4.29136848449707
INFO:root:current mean train loss 14762.95582540761
INFO:root:current train perplexity4.287722110748291
INFO:root:current mean train loss 14756.627525436046
INFO:root:current train perplexity4.281897068023682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.54s/it]
INFO:root:final mean train loss: 14746.36441138483
INFO:root:final train perplexity: 4.282200336456299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 22584.327287946428
INFO:root:eval perplexity: 10.354077339172363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [12:16:27<1:04:16, 241.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14767.149720149253
INFO:root:current train perplexity4.270659923553467
INFO:root:current mean train loss 14742.919372193113
INFO:root:current train perplexity4.273437976837158


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.60s/it]
INFO:root:final mean train loss: 14737.31138561618
INFO:root:final train perplexity: 4.278378009796143
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 22583.958658854168
INFO:root:eval perplexity: 10.35368537902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [12:20:31<1:00:29, 241.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14681.431846217105
INFO:root:current train perplexity4.258056640625
INFO:root:current mean train loss 14734.14078912815
INFO:root:current train perplexity4.279128551483154
INFO:root:current mean train loss 14759.608608019407
INFO:root:current train perplexity4.281428337097168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.85s/it]
INFO:root:final mean train loss: 14738.633292905746
INFO:root:final train perplexity: 4.27893590927124
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.44s/it]
INFO:root:eval mean loss: 22576.991048177082
INFO:root:eval perplexity: 10.346220970153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [12:24:36<56:39, 242.83s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14757.07479643486
INFO:root:current train perplexity4.27482795715332
INFO:root:current mean train loss 14768.716654102705
INFO:root:current train perplexity4.2799882888793945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.18s/it]
INFO:root:final mean train loss: 14737.796410345261
INFO:root:final train perplexity: 4.27858304977417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it]
INFO:root:eval mean loss: 22578.032575334822
INFO:root:eval perplexity: 10.34733772277832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [12:28:35<52:24, 241.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14788.289911684782
INFO:root:current train perplexity4.264719486236572
INFO:root:current mean train loss 14731.656043572155
INFO:root:current train perplexity4.272765636444092
INFO:root:current mean train loss 14748.794050413397
INFO:root:current train perplexity4.278446197509766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.68s/it]
INFO:root:final mean train loss: 14734.657683341733
INFO:root:final train perplexity: 4.277257919311523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it]
INFO:root:eval mean loss: 22579.316266741072
INFO:root:eval perplexity: 10.34870719909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [12:32:36<48:17, 241.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14758.517057291667
INFO:root:current train perplexity4.281424045562744
INFO:root:current mean train loss 14728.386674107143
INFO:root:current train perplexity4.273598670959473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.25s/it]
INFO:root:final mean train loss: 14735.389002646169
INFO:root:final train perplexity: 4.277566432952881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 22584.499186197918
INFO:root:eval perplexity: 10.354262351989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [12:36:35<44:08, 240.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14670.699182581018
INFO:root:current train perplexity4.256937503814697
INFO:root:current mean train loss 14719.105261134351
INFO:root:current train perplexity4.274662494659424
INFO:root:current mean train loss 14734.1709672701
INFO:root:current train perplexity4.2739973068237305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:19<00:00, 199.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:19<00:00, 199.86s/it]
INFO:root:final mean train loss: 14732.389723254788
INFO:root:final train perplexity: 4.276301383972168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 22584.773367745536
INFO:root:eval perplexity: 10.3545560836792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [12:40:28<39:43, 238.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14798.425818334652
INFO:root:current train perplexity4.281610488891602
INFO:root:current mean train loss 14740.60247905028
INFO:root:current train perplexity4.27475643157959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:21<00:00, 201.61s/it]
INFO:root:final mean train loss: 14731.547312090473
INFO:root:final train perplexity: 4.275946617126465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.12s/it]
INFO:root:eval mean loss: 22583.986235119046
INFO:root:eval perplexity: 10.35371208190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [12:44:23<35:37, 237.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14832.406596522178
INFO:root:current train perplexity4.276686668395996
INFO:root:current mean train loss 14779.988810531966
INFO:root:current train perplexity4.278944492340088
INFO:root:current mean train loss 14732.300874255952
INFO:root:current train perplexity4.272615909576416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it]
INFO:root:final mean train loss: 14726.174721994708
INFO:root:final train perplexity: 4.273680686950684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it]
INFO:root:eval mean loss: 22587.241722470237
INFO:root:eval perplexity: 10.357200622558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [12:48:25<31:50, 238.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14720.72935099774
INFO:root:current train perplexity4.27256441116333
INFO:root:current mean train loss 14724.61953018272
INFO:root:current train perplexity4.2715983390808105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:23<00:00, 203.59s/it]
INFO:root:final mean train loss: 14723.660853232106
INFO:root:final train perplexity: 4.2726216316223145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.56s/it]
INFO:root:eval mean loss: 22585.793015252977
INFO:root:eval perplexity: 10.355649948120117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [12:52:22<27:47, 238.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14738.077120535714
INFO:root:current train perplexity4.296093940734863
INFO:root:current mean train loss 14736.676142939816
INFO:root:current train perplexity4.272539138793945
INFO:root:current mean train loss 14741.768134973405
INFO:root:current train perplexity4.27284049987793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:22<00:00, 202.93s/it]
INFO:root:final mean train loss: 14725.860516948085
INFO:root:final train perplexity: 4.273548603057861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 22581.209030877977
INFO:root:eval perplexity: 10.350738525390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [12:56:17<23:44, 237.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14697.865279274425
INFO:root:current train perplexity4.2682671546936035
INFO:root:current mean train loss 14723.444226270054
INFO:root:current train perplexity4.271639823913574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.82s/it]
INFO:root:final mean train loss: 14725.897508190525
INFO:root:final train perplexity: 4.273563861846924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.84s/it]
INFO:root:eval mean loss: 22585.590192522322
INFO:root:eval perplexity: 10.355430603027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [13:00:19<19:52, 238.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14793.20287459936
INFO:root:current train perplexity4.287737846374512
INFO:root:current mean train loss 14732.360808228417
INFO:root:current train perplexity4.273296356201172
INFO:root:current mean train loss 14730.524005458943
INFO:root:current train perplexity4.270778179168701


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:32<00:00, 212.07s/it]
INFO:root:final mean train loss: 14720.003386466733
INFO:root:final train perplexity: 4.2710795402526855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 22585.883882068454
INFO:root:eval perplexity: 10.355746269226074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [13:04:24<16:02, 240.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14760.475875686812
INFO:root:current train perplexity4.277069568634033
INFO:root:current mean train loss 14743.91176681119
INFO:root:current train perplexity4.275663375854492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:26<00:00, 206.72s/it]
INFO:root:final mean train loss: 14721.225759198589
INFO:root:final train perplexity: 4.271595001220703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 22585.99402436756
INFO:root:eval perplexity: 10.355864524841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [13:08:24<12:01, 240.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14716.547510901162
INFO:root:current train perplexity4.259700298309326
INFO:root:current mean train loss 14726.552112926136
INFO:root:current train perplexity4.264003276824951
INFO:root:current mean train loss 14732.321076067386
INFO:root:current train perplexity4.271402835845947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.25s/it]
INFO:root:final mean train loss: 14720.102212229083
INFO:root:final train perplexity: 4.271122455596924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.87s/it]
INFO:root:eval mean loss: 22586.321382068454
INFO:root:eval perplexity: 10.356215476989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [13:12:24<08:00, 240.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14751.844428453947
INFO:root:current train perplexity4.28079080581665
INFO:root:current mean train loss 14737.960356570513
INFO:root:current train perplexity4.273507118225098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:25<00:00, 205.46s/it]
INFO:root:final mean train loss: 14718.456070438508
INFO:root:final train perplexity: 4.2704291343688965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it]
INFO:root:eval mean loss: 22585.840843563987
INFO:root:eval perplexity: 10.35570240020752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [13:16:23<04:00, 240.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14710.816510139628
INFO:root:current train perplexity4.262599945068359
INFO:root:current mean train loss 14716.212565104166
INFO:root:current train perplexity4.268935203552246
INFO:root:current mean train loss 14727.139498197115
INFO:root:current train perplexity4.269320011138916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.90s/it]
INFO:root:final mean train loss: 14715.039771295364
INFO:root:final train perplexity: 4.2689900398254395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it]
INFO:root:eval mean loss: 22585.9423828125
INFO:root:eval perplexity: 10.35580825805664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_topk_1/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:20:26<00:00, 240.69s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:20:26<00:00, 240.13s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.81s/it]
INFO:root:eval mean loss: 22585.9423828125
INFO:root:eval perplexity: 10.35580825805664
INFO:root:evalaution complete
INFO:root:save model final: small_topk_1/final
