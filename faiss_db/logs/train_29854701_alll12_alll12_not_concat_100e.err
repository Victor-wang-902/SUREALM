INFO:root:Output: alll12_alll12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11651.803316366793
INFO:root:current train perplexity10254.478515625
INFO:root:current mean train loss 9680.744334465295
INFO:root:current train perplexity2137.021240234375
INFO:root:current mean train loss 8518.809215941157
INFO:root:current train perplexity851.3552856445312
INFO:root:current mean train loss 7704.9892810639885
INFO:root:current train perplexity440.1866149902344
INFO:root:current mean train loss 7087.273382702906
INFO:root:current train perplexity270.1908874511719
INFO:root:current mean train loss 6610.479660518181
INFO:root:current train perplexity185.46453857421875
INFO:root:current mean train loss 6235.011952063215
INFO:root:current train perplexity137.5458526611328
INFO:root:current mean train loss 5937.594646200818
INFO:root:current train perplexity108.17549896240234
INFO:root:current mean train loss 5686.274982456636
INFO:root:current train perplexity88.78337097167969
INFO:root:current mean train loss 5471.997978935967
INFO:root:current train perplexity75.06237030029297
INFO:root:current mean train loss 5290.167668405938
INFO:root:current train perplexity64.90833282470703
INFO:root:current mean train loss 5132.35096406022
INFO:root:current train perplexity57.31254959106445
INFO:root:current mean train loss 4993.055828702367
INFO:root:current train perplexity51.327842712402344
INFO:root:current mean train loss 4869.364533888604
INFO:root:current train perplexity46.565086364746094
INFO:root:current mean train loss 4758.298501735532
INFO:root:current train perplexity42.68809509277344
INFO:root:current mean train loss 4659.246677916373
INFO:root:current train perplexity39.44207000732422
INFO:root:current mean train loss 4568.524274964133
INFO:root:current train perplexity36.711971282958984
INFO:root:current mean train loss 4487.044403873463
INFO:root:current train perplexity34.41585922241211
INFO:root:current mean train loss 4412.237093587497
INFO:root:current train perplexity32.43400192260742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.75s/it]
INFO:root:final mean train loss: 4351.912622464286
INFO:root:final train perplexity: 30.944032669067383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2808.7535824606603
INFO:root:eval perplexity: 9.694463729858398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.40s/it]
INFO:root:eval mean loss: 3110.9496814917165
INFO:root:eval perplexity: 12.733298301696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/1
  1%|          | 1/100 [09:35<15:49:11, 575.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2959.1917572021484
INFO:root:current train perplexity10.31771469116211
INFO:root:current mean train loss 3001.0090921336205
INFO:root:current train perplexity10.52360725402832
INFO:root:current mean train loss 2979.115644666884
INFO:root:current train perplexity10.378083229064941
INFO:root:current mean train loss 2962.927776095233
INFO:root:current train perplexity10.250658988952637
INFO:root:current mean train loss 2942.3471615131084
INFO:root:current train perplexity10.09410285949707
INFO:root:current mean train loss 2927.094728455063
INFO:root:current train perplexity10.003689765930176
INFO:root:current mean train loss 2915.7737212738434
INFO:root:current train perplexity9.927977561950684
INFO:root:current mean train loss 2901.7201319859682
INFO:root:current train perplexity9.831121444702148
INFO:root:current mean train loss 2888.417969049192
INFO:root:current train perplexity9.740830421447754
INFO:root:current mean train loss 2881.587802670408
INFO:root:current train perplexity9.675235748291016
INFO:root:current mean train loss 2868.8474863608053
INFO:root:current train perplexity9.582568168640137
INFO:root:current mean train loss 2857.8816793024753
INFO:root:current train perplexity9.505874633789062
INFO:root:current mean train loss 2848.160287555895
INFO:root:current train perplexity9.441771507263184
INFO:root:current mean train loss 2839.6120811392834
INFO:root:current train perplexity9.374034881591797
INFO:root:current mean train loss 2833.0437359998455
INFO:root:current train perplexity9.3152494430542
INFO:root:current mean train loss 2823.0820587882895
INFO:root:current train perplexity9.252939224243164
INFO:root:current mean train loss 2814.2642748237836
INFO:root:current train perplexity9.19464111328125
INFO:root:current mean train loss 2806.475645692198
INFO:root:current train perplexity9.131114959716797
INFO:root:current mean train loss 2796.6169892029616
INFO:root:current train perplexity9.063340187072754
INFO:root:current mean train loss 2789.391069957757
INFO:root:current train perplexity9.016050338745117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.70s/it]
INFO:root:final mean train loss: 2783.356421366281
INFO:root:final train perplexity: 8.981101036071777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 2477.878779850953
INFO:root:eval perplexity: 7.418395042419434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it]
INFO:root:eval mean loss: 2822.5688584780864
INFO:root:eval perplexity: 10.058058738708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/2
  2%|â–         | 2/100 [19:24<15:53:13, 583.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2594.8973277698865
INFO:root:current train perplexity7.790656566619873
INFO:root:current mean train loss 2606.3218727972276
INFO:root:current train perplexity7.81194543838501
INFO:root:current mean train loss 2596.733721164163
INFO:root:current train perplexity7.786067962646484
INFO:root:current mean train loss 2598.6577991565787
INFO:root:current train perplexity7.752444267272949
INFO:root:current mean train loss 2595.7625988966875
INFO:root:current train perplexity7.742791175842285
INFO:root:current mean train loss 2591.0476811679173
INFO:root:current train perplexity7.705298900604248
INFO:root:current mean train loss 2584.7751032872975
INFO:root:current train perplexity7.677339553833008
INFO:root:current mean train loss 2582.327194068149
INFO:root:current train perplexity7.652108669281006
INFO:root:current mean train loss 2578.2523508426807
INFO:root:current train perplexity7.627160549163818
INFO:root:current mean train loss 2571.8634701776864
INFO:root:current train perplexity7.593855857849121
INFO:root:current mean train loss 2565.0366527634924
INFO:root:current train perplexity7.560413360595703
INFO:root:current mean train loss 2558.692869154416
INFO:root:current train perplexity7.524622440338135
INFO:root:current mean train loss 2554.8266920351152
INFO:root:current train perplexity7.50419807434082
INFO:root:current mean train loss 2550.1801054511675
INFO:root:current train perplexity7.473325729370117
INFO:root:current mean train loss 2546.3794602089965
INFO:root:current train perplexity7.448102951049805
INFO:root:current mean train loss 2540.9160012122625
INFO:root:current train perplexity7.417215824127197
INFO:root:current mean train loss 2537.213450593592
INFO:root:current train perplexity7.3908371925354
INFO:root:current mean train loss 2533.8683686869995
INFO:root:current train perplexity7.370700359344482
INFO:root:current mean train loss 2531.1459281659168
INFO:root:current train perplexity7.355713367462158
INFO:root:current mean train loss 2527.8165824404664
INFO:root:current train perplexity7.335299968719482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.24s/it]
INFO:root:final mean train loss: 2525.455468713065
INFO:root:final train perplexity: 7.328171730041504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2327.744224602449
INFO:root:eval perplexity: 6.5701904296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2692.9516151374114
INFO:root:eval perplexity: 9.046427726745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/3
  3%|â–Ž         | 3/100 [29:04<15:40:51, 581.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2405.7997583007814
INFO:root:current train perplexity6.748597145080566
INFO:root:current mean train loss 2417.8831306966144
INFO:root:current train perplexity6.80216121673584
INFO:root:current mean train loss 2427.281544433594
INFO:root:current train perplexity6.786014080047607
INFO:root:current mean train loss 2430.0426436941966
INFO:root:current train perplexity6.76186990737915
INFO:root:current mean train loss 2429.2632215711806
INFO:root:current train perplexity6.760274887084961
INFO:root:current mean train loss 2423.3084397194602
INFO:root:current train perplexity6.744197368621826
INFO:root:current mean train loss 2418.8346014873796
INFO:root:current train perplexity6.734411239624023
INFO:root:current mean train loss 2413.368490234375
INFO:root:current train perplexity6.721119403839111
INFO:root:current mean train loss 2411.795714039522
INFO:root:current train perplexity6.700186729431152
INFO:root:current mean train loss 2407.840808233964
INFO:root:current train perplexity6.678910255432129
INFO:root:current mean train loss 2402.5379588681176
INFO:root:current train perplexity6.667321681976318
INFO:root:current mean train loss 2402.458770486583
INFO:root:current train perplexity6.664133548736572
INFO:root:current mean train loss 2402.4014154296874
INFO:root:current train perplexity6.658229827880859
INFO:root:current mean train loss 2400.5476860894096
INFO:root:current train perplexity6.645992279052734
INFO:root:current mean train loss 2399.3298282596984
INFO:root:current train perplexity6.631582260131836
INFO:root:current mean train loss 2397.656989824849
INFO:root:current train perplexity6.627014636993408
INFO:root:current mean train loss 2396.2590394915956
INFO:root:current train perplexity6.615772247314453
INFO:root:current mean train loss 2394.215372419085
INFO:root:current train perplexity6.603100776672363
INFO:root:current mean train loss 2391.327643647065
INFO:root:current train perplexity6.5926408767700195
INFO:root:current mean train loss 2389.123262595152
INFO:root:current train perplexity6.578366279602051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.81s/it]
INFO:root:final mean train loss: 2387.687393750197
INFO:root:final train perplexity: 6.573680877685547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2228.7393474173036
INFO:root:eval perplexity: 6.064628601074219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 2607.3634137092754
INFO:root:eval perplexity: 8.434864044189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/4
  4%|â–         | 4/100 [38:42<15:28:11, 580.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2347.510312208489
INFO:root:current train perplexity6.3040008544921875
INFO:root:current mean train loss 2324.6861250643246
INFO:root:current train perplexity6.214081764221191
INFO:root:current mean train loss 2321.4561520694347
INFO:root:current train perplexity6.2260918617248535
INFO:root:current mean train loss 2316.3404191768136
INFO:root:current train perplexity6.208403587341309
INFO:root:current mean train loss 2320.2228922874565
INFO:root:current train perplexity6.236981391906738
INFO:root:current mean train loss 2321.8869409308863
INFO:root:current train perplexity6.2316718101501465
INFO:root:current mean train loss 2318.603360978202
INFO:root:current train perplexity6.2252678871154785
INFO:root:current mean train loss 2320.998853143844
INFO:root:current train perplexity6.225773334503174
INFO:root:current mean train loss 2318.461998540225
INFO:root:current train perplexity6.221034049987793
INFO:root:current mean train loss 2317.16664226102
INFO:root:current train perplexity6.211418628692627
INFO:root:current mean train loss 2316.5403851381284
INFO:root:current train perplexity6.2070841789245605
INFO:root:current mean train loss 2313.6568921505127
INFO:root:current train perplexity6.19172477722168
INFO:root:current mean train loss 2314.201024754742
INFO:root:current train perplexity6.188913345336914
INFO:root:current mean train loss 2311.8972885924354
INFO:root:current train perplexity6.184633255004883
INFO:root:current mean train loss 2309.706311392963
INFO:root:current train perplexity6.172549724578857
INFO:root:current mean train loss 2309.8578684794043
INFO:root:current train perplexity6.170742034912109
INFO:root:current mean train loss 2307.2694970527377
INFO:root:current train perplexity6.165793418884277
INFO:root:current mean train loss 2308.522588534482
INFO:root:current train perplexity6.165897846221924
INFO:root:current mean train loss 2307.5358691223178
INFO:root:current train perplexity6.1653852462768555
INFO:root:current mean train loss 2307.0630035477966
INFO:root:current train perplexity6.16466760635376

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.76s/it]
INFO:root:final mean train loss: 2306.023403273528
INFO:root:final train perplexity: 6.1636481285095215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 2178.352378033577
INFO:root:eval perplexity: 5.8224639892578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it]
INFO:root:eval mean loss: 2564.5505444682235
INFO:root:eval perplexity: 8.144639015197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/5
  5%|â–Œ         | 5/100 [48:20<15:17:30, 579.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.0270167759486
INFO:root:current train perplexity6.058654308319092
INFO:root:current mean train loss 2291.0792667554774
INFO:root:current train perplexity6.059671878814697
INFO:root:current mean train loss 2279.3176742338796
INFO:root:current train perplexity6.024463653564453
INFO:root:current mean train loss 2277.898969332377
INFO:root:current train perplexity6.028634071350098
INFO:root:current mean train loss 2273.5057388179557
INFO:root:current train perplexity6.022724628448486
INFO:root:current mean train loss 2276.0461542834973
INFO:root:current train perplexity6.015530586242676
INFO:root:current mean train loss 2270.5788542094983
INFO:root:current train perplexity6.001986503601074
INFO:root:current mean train loss 2267.7439106532506
INFO:root:current train perplexity5.989264488220215
INFO:root:current mean train loss 2267.633498524109
INFO:root:current train perplexity5.983547687530518
INFO:root:current mean train loss 2264.0362335453187
INFO:root:current train perplexity5.97247838973999
INFO:root:current mean train loss 2263.1303431662245
INFO:root:current train perplexity5.964905261993408
INFO:root:current mean train loss 2262.8334912480536
INFO:root:current train perplexity5.959030628204346
INFO:root:current mean train loss 2262.172377636871
INFO:root:current train perplexity5.950562000274658
INFO:root:current mean train loss 2260.8903892384787
INFO:root:current train perplexity5.944876194000244
INFO:root:current mean train loss 2258.027787776649
INFO:root:current train perplexity5.940037727355957
INFO:root:current mean train loss 2255.980302598741
INFO:root:current train perplexity5.932028293609619
INFO:root:current mean train loss 2255.7471464252244
INFO:root:current train perplexity5.927661895751953
INFO:root:current mean train loss 2255.3306822498816
INFO:root:current train perplexity5.922086715698242
INFO:root:current mean train loss 2254.559213237398
INFO:root:current train perplexity5.919526100158691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.95s/it]
INFO:root:final mean train loss: 2254.4725763164142
INFO:root:final train perplexity: 5.918083190917969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2127.7466162282526
INFO:root:eval perplexity: 5.5889787673950195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 2520.1845802685893
INFO:root:eval perplexity: 7.85441780090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/6
  6%|â–Œ         | 6/100 [58:12<15:14:37, 583.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2251.72607421875
INFO:root:current train perplexity5.872174263000488
INFO:root:current mean train loss 2192.791215046798
INFO:root:current train perplexity5.66842794418335
INFO:root:current mean train loss 2196.061526474075
INFO:root:current train perplexity5.683505058288574
INFO:root:current mean train loss 2197.3290309969375
INFO:root:current train perplexity5.667769908905029
INFO:root:current mean train loss 2199.2788210747544
INFO:root:current train perplexity5.6760759353637695
INFO:root:current mean train loss 2205.6369918853698
INFO:root:current train perplexity5.6829023361206055
INFO:root:current mean train loss 2208.6712203700213
INFO:root:current train perplexity5.692943572998047
INFO:root:current mean train loss 2210.391395035552
INFO:root:current train perplexity5.6994948387146
INFO:root:current mean train loss 2208.874338900105
INFO:root:current train perplexity5.692744731903076
INFO:root:current mean train loss 2208.7023022108683
INFO:root:current train perplexity5.692092418670654
INFO:root:current mean train loss 2206.5693027675447
INFO:root:current train perplexity5.692229747772217
INFO:root:current mean train loss 2207.030373444241
INFO:root:current train perplexity5.69092321395874
INFO:root:current mean train loss 2205.608274639298
INFO:root:current train perplexity5.6879353523254395
INFO:root:current mean train loss 2203.9292617082415
INFO:root:current train perplexity5.68140983581543
INFO:root:current mean train loss 2204.056923887374
INFO:root:current train perplexity5.6808085441589355
INFO:root:current mean train loss 2203.513544111868
INFO:root:current train perplexity5.681594371795654
INFO:root:current mean train loss 2202.5888688649184
INFO:root:current train perplexity5.67848014831543
INFO:root:current mean train loss 2200.057167730494
INFO:root:current train perplexity5.671837329864502
INFO:root:current mean train loss 2199.394431004585
INFO:root:current train perplexity5.66792106628418
INFO:root:current mean train loss 2199.951178681656
INFO:root:current train perplexity5.664966583251953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.83s/it]
INFO:root:final mean train loss: 2198.7156389306665
INFO:root:final train perplexity: 5.663485050201416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2102.34925788176
INFO:root:eval perplexity: 5.475352764129639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 2501.534087918329
INFO:root:eval perplexity: 7.735524654388428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/7
  7%|â–‹         | 7/100 [1:07:51<15:02:39, 582.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2263.1244845920137
INFO:root:current train perplexity5.596259593963623
INFO:root:current mean train loss 2177.267391916049
INFO:root:current train perplexity5.542158126831055
INFO:root:current mean train loss 2169.030293035945
INFO:root:current train perplexity5.48885440826416
INFO:root:current mean train loss 2156.527936827462
INFO:root:current train perplexity5.464451789855957
INFO:root:current mean train loss 2166.9036692934174
INFO:root:current train perplexity5.498913288116455
INFO:root:current mean train loss 2164.705419356298
INFO:root:current train perplexity5.486555576324463
INFO:root:current mean train loss 2164.733755364773
INFO:root:current train perplexity5.484889984130859
INFO:root:current mean train loss 2166.137035486758
INFO:root:current train perplexity5.491066932678223
INFO:root:current mean train loss 2159.442341774192
INFO:root:current train perplexity5.479666233062744
INFO:root:current mean train loss 2161.032952734588
INFO:root:current train perplexity5.481125354766846
INFO:root:current mean train loss 2159.7891506352453
INFO:root:current train perplexity5.479426383972168
INFO:root:current mean train loss 2158.1930008071054
INFO:root:current train perplexity5.478476047515869
INFO:root:current mean train loss 2155.726559493342
INFO:root:current train perplexity5.472957611083984
INFO:root:current mean train loss 2156.658271847437
INFO:root:current train perplexity5.47282075881958
INFO:root:current mean train loss 2157.01562431131
INFO:root:current train perplexity5.475135326385498
INFO:root:current mean train loss 2156.4311533087325
INFO:root:current train perplexity5.474174976348877
INFO:root:current mean train loss 2154.734553805093
INFO:root:current train perplexity5.466988563537598
INFO:root:current mean train loss 2154.956802528035
INFO:root:current train perplexity5.46610164642334
INFO:root:current mean train loss 2153.450717099298
INFO:root:current train perplexity5.46218204498291
INFO:root:current mean train loss 2152.3887181446125
INFO:root:current train perplexity5.459518909454346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.72s/it]
INFO:root:final mean train loss: 2151.3589916142682
INFO:root:final train perplexity: 5.455864906311035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2060.0855440180353
INFO:root:eval perplexity: 5.291364669799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.79s/it]
INFO:root:eval mean loss: 2464.2024661666114
INFO:root:eval perplexity: 7.502922534942627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/8
  8%|â–Š         | 8/100 [1:17:31<14:51:23, 581.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2072.661296735491
INFO:root:current train perplexity5.157009124755859
INFO:root:current mean train loss 2104.571570276331
INFO:root:current train perplexity5.276301860809326
INFO:root:current mean train loss 2099.380483813996
INFO:root:current train perplexity5.27864408493042
INFO:root:current mean train loss 2111.325732786264
INFO:root:current train perplexity5.290656566619873
INFO:root:current mean train loss 2117.5792842470364
INFO:root:current train perplexity5.312297344207764
INFO:root:current mean train loss 2116.1794673171
INFO:root:current train perplexity5.302853107452393
INFO:root:current mean train loss 2117.120685823696
INFO:root:current train perplexity5.301072597503662
INFO:root:current mean train loss 2115.977048123937
INFO:root:current train perplexity5.302046775817871
INFO:root:current mean train loss 2115.2049676038546
INFO:root:current train perplexity5.304785251617432
INFO:root:current mean train loss 2117.5274387951204
INFO:root:current train perplexity5.302972793579102
INFO:root:current mean train loss 2117.655683994754
INFO:root:current train perplexity5.302058219909668
INFO:root:current mean train loss 2118.4187310710354
INFO:root:current train perplexity5.307579517364502
INFO:root:current mean train loss 2115.934825523469
INFO:root:current train perplexity5.305466175079346
INFO:root:current mean train loss 2113.8194793129683
INFO:root:current train perplexity5.3003363609313965
INFO:root:current mean train loss 2113.899078135208
INFO:root:current train perplexity5.297736167907715
INFO:root:current mean train loss 2114.4190712795194
INFO:root:current train perplexity5.298944473266602
INFO:root:current mean train loss 2115.0750512919294
INFO:root:current train perplexity5.299572467803955
INFO:root:current mean train loss 2114.7467163437727
INFO:root:current train perplexity5.299178123474121
INFO:root:current mean train loss 2114.18046875
INFO:root:current train perplexity5.297804355621338
INFO:root:current mean train loss 2114.3973344512074
INFO:root:current train perplexity5.296217441558838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.10s/it]
INFO:root:final mean train loss: 2113.403138284303
INFO:root:final train perplexity: 5.2949676513671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 2027.4421031762522
INFO:root:eval perplexity: 5.153500556945801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it]
INFO:root:eval mean loss: 2441.9657618745846
INFO:root:eval perplexity: 7.367708683013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/9
  9%|â–‰         | 9/100 [1:27:21<14:45:46, 584.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.9720717210037
INFO:root:current train perplexity5.127427101135254
INFO:root:current mean train loss 2077.7744999935753
INFO:root:current train perplexity5.184604167938232
INFO:root:current mean train loss 2088.509097629123
INFO:root:current train perplexity5.180445194244385
INFO:root:current mean train loss 2083.769479924982
INFO:root:current train perplexity5.176916122436523
INFO:root:current mean train loss 2081.499631628526
INFO:root:current train perplexity5.172351837158203
INFO:root:current mean train loss 2077.666423631751
INFO:root:current train perplexity5.15789270401001
INFO:root:current mean train loss 2078.8995007474
INFO:root:current train perplexity5.162374973297119
INFO:root:current mean train loss 2078.777919850451
INFO:root:current train perplexity5.160077095031738
INFO:root:current mean train loss 2082.5295824221043
INFO:root:current train perplexity5.165369987487793
INFO:root:current mean train loss 2080.959500737551
INFO:root:current train perplexity5.162611961364746
INFO:root:current mean train loss 2081.5179516462317
INFO:root:current train perplexity5.162364482879639
INFO:root:current mean train loss 2082.5496870676675
INFO:root:current train perplexity5.164005756378174
INFO:root:current mean train loss 2080.083418288551
INFO:root:current train perplexity5.160521030426025
INFO:root:current mean train loss 2080.6204070142035
INFO:root:current train perplexity5.156121253967285
INFO:root:current mean train loss 2081.191239454201
INFO:root:current train perplexity5.156926155090332
INFO:root:current mean train loss 2081.0432704650248
INFO:root:current train perplexity5.1578569412231445
INFO:root:current mean train loss 2082.5539521224273
INFO:root:current train perplexity5.16163969039917
INFO:root:current mean train loss 2082.6549856804277
INFO:root:current train perplexity5.161578178405762
INFO:root:current mean train loss 2081.5153094759257
INFO:root:current train perplexity5.158910274505615
INFO:root:current mean train loss 2081.782718408303
INFO:root:current train perplexity5.159117698669434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.44s/it]
INFO:root:final mean train loss: 2079.997615319818
INFO:root:final train perplexity: 5.157290458679199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2007.7863921036958
INFO:root:eval perplexity: 5.072226047515869
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2419.503266463043
INFO:root:eval perplexity: 7.23359489440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:37:01<14:34:25, 582.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2069.8541153617525
INFO:root:current train perplexity5.100705146789551
INFO:root:current mean train loss 2075.6592056906434
INFO:root:current train perplexity5.095861911773682
INFO:root:current mean train loss 2071.8998964444413
INFO:root:current train perplexity5.082468509674072
INFO:root:current mean train loss 2065.488546231898
INFO:root:current train perplexity5.066061496734619
INFO:root:current mean train loss 2063.2468183635397
INFO:root:current train perplexity5.064062595367432
INFO:root:current mean train loss 2059.428227161481
INFO:root:current train perplexity5.063995838165283
INFO:root:current mean train loss 2056.3838264682013
INFO:root:current train perplexity5.053006649017334
INFO:root:current mean train loss 2058.249999047566
INFO:root:current train perplexity5.061732292175293
INFO:root:current mean train loss 2057.3328910801297
INFO:root:current train perplexity5.062448978424072
INFO:root:current mean train loss 2056.977636063677
INFO:root:current train perplexity5.061925888061523
INFO:root:current mean train loss 2056.093611828739
INFO:root:current train perplexity5.059772491455078
INFO:root:current mean train loss 2058.0039618029564
INFO:root:current train perplexity5.061002731323242
INFO:root:current mean train loss 2057.591855745789
INFO:root:current train perplexity5.062966346740723
INFO:root:current mean train loss 2057.400569762515
INFO:root:current train perplexity5.0591607093811035
INFO:root:current mean train loss 2057.450267524278
INFO:root:current train perplexity5.060855388641357
INFO:root:current mean train loss 2056.243813159133
INFO:root:current train perplexity5.0571393966674805
INFO:root:current mean train loss 2055.5914213021692
INFO:root:current train perplexity5.055866241455078
INFO:root:current mean train loss 2055.7767745945803
INFO:root:current train perplexity5.054832935333252
INFO:root:current mean train loss 2054.9517751074272
INFO:root:current train perplexity5.0514631271362305
INFO:root:current mean train loss 2055.4075632632957
INFO:root:current train perplexity5.056452751159668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.21s/it]
INFO:root:final mean train loss: 2054.7398194098078
INFO:root:final train perplexity: 5.055573463439941
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 1986.5707648527537
INFO:root:eval perplexity: 4.985939979553223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 2402.948616623033
INFO:root:eval perplexity: 7.1363205909729
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:46:50<14:27:30, 584.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2049.151279183321
INFO:root:current train perplexity4.973481178283691
INFO:root:current mean train loss 2029.1498754357779
INFO:root:current train perplexity4.95235013961792
INFO:root:current mean train loss 2027.659173285211
INFO:root:current train perplexity4.948404312133789
INFO:root:current mean train loss 2030.6771992895888
INFO:root:current train perplexity4.960549831390381
INFO:root:current mean train loss 2025.0353461371528
INFO:root:current train perplexity4.962528228759766
INFO:root:current mean train loss 2028.0004530766719
INFO:root:current train perplexity4.960719108581543
INFO:root:current mean train loss 2028.3934150006264
INFO:root:current train perplexity4.948687553405762
INFO:root:current mean train loss 2027.9770906948254
INFO:root:current train perplexity4.943687438964844
INFO:root:current mean train loss 2027.5971331112003
INFO:root:current train perplexity4.9423298835754395
INFO:root:current mean train loss 2030.06524410596
INFO:root:current train perplexity4.948550224304199
INFO:root:current mean train loss 2032.2545117682075
INFO:root:current train perplexity4.9583516120910645
INFO:root:current mean train loss 2032.8991446020632
INFO:root:current train perplexity4.959850788116455
INFO:root:current mean train loss 2033.4113426861088
INFO:root:current train perplexity4.961872100830078
INFO:root:current mean train loss 2033.2771348389024
INFO:root:current train perplexity4.964288234710693
INFO:root:current mean train loss 2032.0772332131141
INFO:root:current train perplexity4.966053009033203
INFO:root:current mean train loss 2033.5723218112093
INFO:root:current train perplexity4.968016624450684
INFO:root:current mean train loss 2032.419721320572
INFO:root:current train perplexity4.967407703399658
INFO:root:current mean train loss 2032.6053941135044
INFO:root:current train perplexity4.9676594734191895
INFO:root:current mean train loss 2032.2003359587295
INFO:root:current train perplexity4.967994689941406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.03s/it]
INFO:root:final mean train loss: 2032.9505491501986
INFO:root:final train perplexity: 4.96943998336792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.34s/it]
INFO:root:eval mean loss: 1980.8477822161735
INFO:root:eval perplexity: 4.962915420532227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.43s/it]
INFO:root:eval mean loss: 2397.8833748026095
INFO:root:eval perplexity: 7.1068196296691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:56:27<14:14:21, 582.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2059.413126627604
INFO:root:current train perplexity4.7242631912231445
INFO:root:current mean train loss 2015.8404588421572
INFO:root:current train perplexity4.905175685882568
INFO:root:current mean train loss 2006.6908187490378
INFO:root:current train perplexity4.868945121765137
INFO:root:current mean train loss 2011.9662977161975
INFO:root:current train perplexity4.876999855041504
INFO:root:current mean train loss 2009.134786222472
INFO:root:current train perplexity4.869547367095947
INFO:root:current mean train loss 2010.8177536344433
INFO:root:current train perplexity4.878592491149902
INFO:root:current mean train loss 2014.3233106116552
INFO:root:current train perplexity4.894233226776123
INFO:root:current mean train loss 2012.1344980427075
INFO:root:current train perplexity4.884725570678711
INFO:root:current mean train loss 2012.4639777044579
INFO:root:current train perplexity4.886165618896484
INFO:root:current mean train loss 2012.8735763870864
INFO:root:current train perplexity4.889630317687988
INFO:root:current mean train loss 2011.7546121401422
INFO:root:current train perplexity4.884738445281982
INFO:root:current mean train loss 2012.0133291263528
INFO:root:current train perplexity4.890944480895996
INFO:root:current mean train loss 2011.1155898299498
INFO:root:current train perplexity4.891066074371338
INFO:root:current mean train loss 2011.223689116612
INFO:root:current train perplexity4.89081335067749
INFO:root:current mean train loss 2012.274041239058
INFO:root:current train perplexity4.889290809631348
INFO:root:current mean train loss 2012.2856111507454
INFO:root:current train perplexity4.888653755187988
INFO:root:current mean train loss 2013.4697599167089
INFO:root:current train perplexity4.893767356872559
INFO:root:current mean train loss 2013.9138015146755
INFO:root:current train perplexity4.894716262817383
INFO:root:current mean train loss 2014.0482727490858
INFO:root:current train perplexity4.894141674041748
INFO:root:current mean train loss 2015.313848290015
INFO:root:current train perplexity4.897268295288086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.17s/it]
INFO:root:final mean train loss: 2014.1605075330249
INFO:root:final train perplexity: 4.896340370178223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 1965.1841387376717
INFO:root:eval perplexity: 4.900442600250244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2388.9446489050033
INFO:root:eval perplexity: 7.055056095123291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [2:06:17<14:07:38, 584.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1976.7753540039062
INFO:root:current train perplexity4.820735454559326
INFO:root:current mean train loss 1990.0995310465494
INFO:root:current train perplexity4.793074607849121
INFO:root:current mean train loss 1990.3671164772727
INFO:root:current train perplexity4.824089527130127
INFO:root:current mean train loss 1990.1252220153808
INFO:root:current train perplexity4.807124614715576
INFO:root:current mean train loss 1991.548399716332
INFO:root:current train perplexity4.810149192810059
INFO:root:current mean train loss 1996.3125021127555
INFO:root:current train perplexity4.817025661468506
INFO:root:current mean train loss 1992.6085892215851
INFO:root:current train perplexity4.807175636291504
INFO:root:current mean train loss 1989.950900607639
INFO:root:current train perplexity4.803085803985596
INFO:root:current mean train loss 1988.8700216153773
INFO:root:current train perplexity4.807018280029297
INFO:root:current mean train loss 1988.0675387175186
INFO:root:current train perplexity4.80804967880249
INFO:root:current mean train loss 1989.5848077512255
INFO:root:current train perplexity4.81032657623291
INFO:root:current mean train loss 1990.5229705810548
INFO:root:current train perplexity4.814302921295166
INFO:root:current mean train loss 1990.5794653720543
INFO:root:current train perplexity4.810362815856934
INFO:root:current mean train loss 1992.5831370960582
INFO:root:current train perplexity4.811581611633301
INFO:root:current mean train loss 1993.2668994312555
INFO:root:current train perplexity4.817763328552246
INFO:root:current mean train loss 1992.3430294639186
INFO:root:current train perplexity4.818959712982178
INFO:root:current mean train loss 1993.0836170337818
INFO:root:current train perplexity4.82073974609375
INFO:root:current mean train loss 1994.9893203380495
INFO:root:current train perplexity4.822237491607666
INFO:root:current mean train loss 1994.0597548264723
INFO:root:current train perplexity4.820986270904541
INFO:root:current mean train loss 1994.6951983769734
INFO:root:current train perplexity4.824045181274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.86s/it]
INFO:root:final mean train loss: 1995.4562790678776
INFO:root:final train perplexity: 4.824643135070801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 1957.9386103203956
INFO:root:eval perplexity: 4.871811389923096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2378.7413425310283
INFO:root:eval perplexity: 6.996429920196533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [2:16:01<13:57:48, 584.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.2782807221283
INFO:root:current train perplexity4.689742088317871
INFO:root:current mean train loss 1989.9394308493954
INFO:root:current train perplexity4.742340087890625
INFO:root:current mean train loss 1980.6661315145373
INFO:root:current train perplexity4.741032600402832
INFO:root:current mean train loss 1976.8035356198998
INFO:root:current train perplexity4.726911544799805
INFO:root:current mean train loss 1977.8699847817147
INFO:root:current train perplexity4.732938289642334
INFO:root:current mean train loss 1981.3992910829115
INFO:root:current train perplexity4.747279167175293
INFO:root:current mean train loss 1977.9727541745365
INFO:root:current train perplexity4.743438243865967
INFO:root:current mean train loss 1976.537602293928
INFO:root:current train perplexity4.742905139923096
INFO:root:current mean train loss 1976.4356820711525
INFO:root:current train perplexity4.740107536315918
INFO:root:current mean train loss 1973.3847533788853
INFO:root:current train perplexity4.734635353088379
INFO:root:current mean train loss 1973.0366858369243
INFO:root:current train perplexity4.73789644241333
INFO:root:current mean train loss 1973.6042387064026
INFO:root:current train perplexity4.740931987762451
INFO:root:current mean train loss 1973.5503520795965
INFO:root:current train perplexity4.740647315979004
INFO:root:current mean train loss 1974.86716047471
INFO:root:current train perplexity4.744564056396484
INFO:root:current mean train loss 1973.593325174925
INFO:root:current train perplexity4.740453243255615
INFO:root:current mean train loss 1975.3372337326416
INFO:root:current train perplexity4.744461536407471
INFO:root:current mean train loss 1975.8071591069076
INFO:root:current train perplexity4.746443748474121
INFO:root:current mean train loss 1976.3121043432013
INFO:root:current train perplexity4.7489824295043945
INFO:root:current mean train loss 1976.5123282377008
INFO:root:current train perplexity4.750824451446533
INFO:root:current mean train loss 1976.8859495242723
INFO:root:current train perplexity4.753430366516113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.99s/it]
INFO:root:final mean train loss: 1977.3949335033822
INFO:root:final train perplexity: 4.756407260894775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it]
INFO:root:eval mean loss: 1943.7050439279976
INFO:root:eval perplexity: 4.816051959991455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 2368.812671850759
INFO:root:eval perplexity: 6.939850330352783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [2:25:57<13:52:53, 587.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.7990632233796
INFO:root:current train perplexity4.646176338195801
INFO:root:current mean train loss 1949.4835593483665
INFO:root:current train perplexity4.687207221984863
INFO:root:current mean train loss 1959.1879964513103
INFO:root:current train perplexity4.701962471008301
INFO:root:current mean train loss 1955.7191517285708
INFO:root:current train perplexity4.6912641525268555
INFO:root:current mean train loss 1958.1630208691836
INFO:root:current train perplexity4.687687397003174
INFO:root:current mean train loss 1960.9940035713278
INFO:root:current train perplexity4.695334434509277
INFO:root:current mean train loss 1964.2065952312691
INFO:root:current train perplexity4.70024299621582
INFO:root:current mean train loss 1961.0779747596155
INFO:root:current train perplexity4.6889238357543945
INFO:root:current mean train loss 1960.499216834611
INFO:root:current train perplexity4.689526081085205
INFO:root:current mean train loss 1959.2934704666618
INFO:root:current train perplexity4.687511444091797
INFO:root:current mean train loss 1963.0170257973716
INFO:root:current train perplexity4.693253993988037
INFO:root:current mean train loss 1960.0006540387715
INFO:root:current train perplexity4.687806606292725
INFO:root:current mean train loss 1960.9909723455255
INFO:root:current train perplexity4.690814018249512
INFO:root:current mean train loss 1961.863098054376
INFO:root:current train perplexity4.688088417053223
INFO:root:current mean train loss 1961.9159262131136
INFO:root:current train perplexity4.688397407531738
INFO:root:current mean train loss 1960.9330464759541
INFO:root:current train perplexity4.688044548034668
INFO:root:current mean train loss 1960.2673657935072
INFO:root:current train perplexity4.688073635101318
INFO:root:current mean train loss 1960.3184470651902
INFO:root:current train perplexity4.689504623413086
INFO:root:current mean train loss 1960.552389430897
INFO:root:current train perplexity4.6896772384643555
INFO:root:current mean train loss 1959.077870114189
INFO:root:current train perplexity4.686460018157959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.27s/it]
INFO:root:final mean train loss: 1958.6427438094408
INFO:root:final train perplexity: 4.686581611633301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.94s/it]
INFO:root:eval mean loss: 1932.5852223930628
INFO:root:eval perplexity: 4.77293586730957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2359.8454044423206
INFO:root:eval perplexity: 6.889142036437988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [2:35:48<13:44:35, 588.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.9089578977773
INFO:root:current train perplexity4.659998893737793
INFO:root:current mean train loss 1947.717953330592
INFO:root:current train perplexity4.623413562774658
INFO:root:current mean train loss 1945.0925045224574
INFO:root:current train perplexity4.628229141235352
INFO:root:current mean train loss 1945.3362981174191
INFO:root:current train perplexity4.626436710357666
INFO:root:current mean train loss 1944.83316305691
INFO:root:current train perplexity4.6357622146606445
INFO:root:current mean train loss 1943.0641123542853
INFO:root:current train perplexity4.6288604736328125
INFO:root:current mean train loss 1942.7699924247277
INFO:root:current train perplexity4.62222146987915
INFO:root:current mean train loss 1942.6378872051314
INFO:root:current train perplexity4.622910499572754
INFO:root:current mean train loss 1942.0080011413784
INFO:root:current train perplexity4.622203350067139
INFO:root:current mean train loss 1941.0677985555726
INFO:root:current train perplexity4.621668815612793
INFO:root:current mean train loss 1939.904464194532
INFO:root:current train perplexity4.620598793029785
INFO:root:current mean train loss 1938.4551862265491
INFO:root:current train perplexity4.614736557006836
INFO:root:current mean train loss 1937.540925248789
INFO:root:current train perplexity4.609206199645996
INFO:root:current mean train loss 1939.2207339319498
INFO:root:current train perplexity4.6138458251953125
INFO:root:current mean train loss 1939.905216759034
INFO:root:current train perplexity4.616020679473877
INFO:root:current mean train loss 1939.5368287919966
INFO:root:current train perplexity4.617500305175781
INFO:root:current mean train loss 1939.4413727190165
INFO:root:current train perplexity4.617726802825928
INFO:root:current mean train loss 1938.554436604496
INFO:root:current train perplexity4.614069938659668
INFO:root:current mean train loss 1938.2437383344886
INFO:root:current train perplexity4.613080978393555
INFO:root:current mean train loss 1939.501992390641
INFO:root:current train perplexity4.614216327667236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:46<00:00, 526.26s/it]
INFO:root:final mean train loss: 1939.2311370895777
INFO:root:final train perplexity: 4.615379810333252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it]
INFO:root:eval mean loss: 1920.7733496266899
INFO:root:eval perplexity: 4.727557182312012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 2348.317014437195
INFO:root:eval perplexity: 6.824493885040283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [2:45:54<13:41:32, 593.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1941.1435255570846
INFO:root:current train perplexity4.59523868560791
INFO:root:current mean train loss 1912.6484907434342
INFO:root:current train perplexity4.537267208099365
INFO:root:current mean train loss 1918.2032402886284
INFO:root:current train perplexity4.555507183074951
INFO:root:current mean train loss 1926.074371967119
INFO:root:current train perplexity4.562070846557617
INFO:root:current mean train loss 1920.5725375316183
INFO:root:current train perplexity4.546769142150879
INFO:root:current mean train loss 1924.7146704018521
INFO:root:current train perplexity4.556723594665527
INFO:root:current mean train loss 1920.1734782374183
INFO:root:current train perplexity4.548105716705322
INFO:root:current mean train loss 1919.8196535062064
INFO:root:current train perplexity4.54990291595459
INFO:root:current mean train loss 1921.5223792823585
INFO:root:current train perplexity4.555915355682373
INFO:root:current mean train loss 1921.1352483463672
INFO:root:current train perplexity4.554826259613037
INFO:root:current mean train loss 1920.7661207984474
INFO:root:current train perplexity4.553170680999756
INFO:root:current mean train loss 1921.6447139444576
INFO:root:current train perplexity4.555091381072998
INFO:root:current mean train loss 1922.901375812033
INFO:root:current train perplexity4.558627128601074
INFO:root:current mean train loss 1922.0819155118652
INFO:root:current train perplexity4.557849884033203
INFO:root:current mean train loss 1921.7535164945868
INFO:root:current train perplexity4.557344436645508
INFO:root:current mean train loss 1920.933590982663
INFO:root:current train perplexity4.554765701293945
INFO:root:current mean train loss 1920.940018061778
INFO:root:current train perplexity4.555187702178955
INFO:root:current mean train loss 1921.7363171332102
INFO:root:current train perplexity4.554129123687744
INFO:root:current mean train loss 1923.6815744820287
INFO:root:current train perplexity4.556558132171631

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.69s/it]
INFO:root:final mean train loss: 1922.2756397210765
INFO:root:final train perplexity: 4.554073810577393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 1905.0434427464263
INFO:root:eval perplexity: 4.667797565460205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it]
INFO:root:eval mean loss: 2342.03433032746
INFO:root:eval perplexity: 6.789518356323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:55:44<13:30:15, 592.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1805.04453125
INFO:root:current train perplexity4.207668304443359
INFO:root:current mean train loss 1874.943902297247
INFO:root:current train perplexity4.456302642822266
INFO:root:current mean train loss 1883.3951975752668
INFO:root:current train perplexity4.444761276245117
INFO:root:current mean train loss 1895.3096187403944
INFO:root:current train perplexity4.4650092124938965
INFO:root:current mean train loss 1890.7152054398148
INFO:root:current train perplexity4.461973190307617
INFO:root:current mean train loss 1893.605458839341
INFO:root:current train perplexity4.462486743927002
INFO:root:current mean train loss 1892.5117587002842
INFO:root:current train perplexity4.460006237030029
INFO:root:current mean train loss 1894.345813594304
INFO:root:current train perplexity4.46311092376709
INFO:root:current mean train loss 1896.9638051666827
INFO:root:current train perplexity4.471929550170898
INFO:root:current mean train loss 1901.5360204538588
INFO:root:current train perplexity4.480950832366943
INFO:root:current mean train loss 1901.29013671875
INFO:root:current train perplexity4.480097770690918
INFO:root:current mean train loss 1901.9551490472993
INFO:root:current train perplexity4.48172664642334
INFO:root:current mean train loss 1901.3374595800376
INFO:root:current train perplexity4.480935096740723
INFO:root:current mean train loss 1901.0070576284124
INFO:root:current train perplexity4.480101108551025
INFO:root:current mean train loss 1902.3271032584519
INFO:root:current train perplexity4.481414794921875
INFO:root:current mean train loss 1903.2602933256333
INFO:root:current train perplexity4.4823455810546875
INFO:root:current mean train loss 1904.1465426341024
INFO:root:current train perplexity4.484518527984619
INFO:root:current mean train loss 1905.1766262199872
INFO:root:current train perplexity4.4885334968566895
INFO:root:current mean train loss 1905.2873435065358
INFO:root:current train perplexity4.490637302398682
INFO:root:current mean train loss 1905.8439298054052
INFO:root:current train perplexity4.4927802085876465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.45s/it]
INFO:root:final mean train loss: 1905.3375718140326
INFO:root:final train perplexity: 4.493642807006836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 1900.4075620394226
INFO:root:eval perplexity: 4.65032958984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2330.7387050331063
INFO:root:eval perplexity: 6.727086544036865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [3:05:34<13:19:01, 591.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.946161443537
INFO:root:current train perplexity4.476439952850342
INFO:root:current mean train loss 1882.8911382956583
INFO:root:current train perplexity4.452363967895508
INFO:root:current mean train loss 1897.3274789071297
INFO:root:current train perplexity4.472148418426514
INFO:root:current mean train loss 1888.3471281632133
INFO:root:current train perplexity4.449884414672852
INFO:root:current mean train loss 1883.7983768698164
INFO:root:current train perplexity4.4342122077941895
INFO:root:current mean train loss 1888.5359665443157
INFO:root:current train perplexity4.44224214553833
INFO:root:current mean train loss 1887.9631404570061
INFO:root:current train perplexity4.439366817474365
INFO:root:current mean train loss 1891.6163867728533
INFO:root:current train perplexity4.451981067657471
INFO:root:current mean train loss 1889.74468860487
INFO:root:current train perplexity4.450902462005615
INFO:root:current mean train loss 1890.2913683314127
INFO:root:current train perplexity4.447644233703613
INFO:root:current mean train loss 1890.8508438140211
INFO:root:current train perplexity4.445258617401123
INFO:root:current mean train loss 1891.757724047982
INFO:root:current train perplexity4.444123268127441
INFO:root:current mean train loss 1892.2761054655534
INFO:root:current train perplexity4.4437079429626465
INFO:root:current mean train loss 1891.0311577547336
INFO:root:current train perplexity4.439903736114502
INFO:root:current mean train loss 1889.2385852239638
INFO:root:current train perplexity4.433708667755127
INFO:root:current mean train loss 1889.077122852461
INFO:root:current train perplexity4.43360710144043
INFO:root:current mean train loss 1890.0757833121002
INFO:root:current train perplexity4.435674667358398
INFO:root:current mean train loss 1889.7632929040994
INFO:root:current train perplexity4.4357500076293945
INFO:root:current mean train loss 1890.0551226518548
INFO:root:current train perplexity4.436197280883789
INFO:root:current mean train loss 1889.9717384362195
INFO:root:current train perplexity4.4375319480896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.84s/it]
INFO:root:final mean train loss: 1889.6427682173476
INFO:root:final train perplexity: 4.438364505767822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 1897.1994819370568
INFO:root:eval perplexity: 4.638279914855957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2336.059964660212
INFO:root:eval perplexity: 6.756425380706787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [3:15:15<13:04:48, 588.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.3760829827725
INFO:root:current train perplexity4.31061315536499
INFO:root:current mean train loss 1859.8919027863647
INFO:root:current train perplexity4.342606544494629
INFO:root:current mean train loss 1873.2885216110421
INFO:root:current train perplexity4.361591339111328
INFO:root:current mean train loss 1873.7491134598542
INFO:root:current train perplexity4.359792709350586
INFO:root:current mean train loss 1875.3101912305133
INFO:root:current train perplexity4.378433704376221
INFO:root:current mean train loss 1869.606794764248
INFO:root:current train perplexity4.369702339172363
INFO:root:current mean train loss 1873.422858630734
INFO:root:current train perplexity4.37684965133667
INFO:root:current mean train loss 1873.6215098462344
INFO:root:current train perplexity4.374040126800537
INFO:root:current mean train loss 1875.0246969047973
INFO:root:current train perplexity4.378452301025391
INFO:root:current mean train loss 1876.1002790067143
INFO:root:current train perplexity4.3812103271484375
INFO:root:current mean train loss 1877.0922817490903
INFO:root:current train perplexity4.383627414703369
INFO:root:current mean train loss 1876.9710716937486
INFO:root:current train perplexity4.386236667633057
INFO:root:current mean train loss 1875.2552940485648
INFO:root:current train perplexity4.384400367736816
INFO:root:current mean train loss 1876.1640377942085
INFO:root:current train perplexity4.382782936096191
INFO:root:current mean train loss 1877.7046439652645
INFO:root:current train perplexity4.385415077209473
INFO:root:current mean train loss 1877.1159471260255
INFO:root:current train perplexity4.386989593505859
INFO:root:current mean train loss 1877.8304384521336
INFO:root:current train perplexity4.387560844421387
INFO:root:current mean train loss 1878.6364719419387
INFO:root:current train perplexity4.389808654785156
INFO:root:current mean train loss 1876.911544758318
INFO:root:current train perplexity4.3863067626953125
INFO:root:current mean train loss 1875.1216113684163
INFO:root:current train perplexity4.3861870765686035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.72s/it]
INFO:root:final mean train loss: 1874.9779402386102
INFO:root:final train perplexity: 4.387327671051025
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 1887.280630558095
INFO:root:eval perplexity: 4.601221084594727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2329.321858291085
INFO:root:eval perplexity: 6.719295978546143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [3:25:06<12:55:53, 589.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.707512991769
INFO:root:current train perplexity4.37578821182251
INFO:root:current mean train loss 1872.5435384114583
INFO:root:current train perplexity4.34274435043335
INFO:root:current mean train loss 1866.6622443199158
INFO:root:current train perplexity4.3410444259643555
INFO:root:current mean train loss 1865.6501509419988
INFO:root:current train perplexity4.340232849121094
INFO:root:current mean train loss 1860.0025147555168
INFO:root:current train perplexity4.342846393585205
INFO:root:current mean train loss 1859.9319528264107
INFO:root:current train perplexity4.340544700622559
INFO:root:current mean train loss 1860.1303201070646
INFO:root:current train perplexity4.339632511138916
INFO:root:current mean train loss 1863.6412389038733
INFO:root:current train perplexity4.342636585235596
INFO:root:current mean train loss 1858.018498786142
INFO:root:current train perplexity4.328845024108887
INFO:root:current mean train loss 1860.2038469514089
INFO:root:current train perplexity4.333146572113037
INFO:root:current mean train loss 1859.7084943597968
INFO:root:current train perplexity4.3333048820495605
INFO:root:current mean train loss 1859.2875149736767
INFO:root:current train perplexity4.333688259124756
INFO:root:current mean train loss 1860.4723316362708
INFO:root:current train perplexity4.336221694946289
INFO:root:current mean train loss 1859.79953741113
INFO:root:current train perplexity4.332371711730957
INFO:root:current mean train loss 1859.88954942305
INFO:root:current train perplexity4.331428050994873
INFO:root:current mean train loss 1861.1882590953367
INFO:root:current train perplexity4.334654331207275
INFO:root:current mean train loss 1862.8470116214476
INFO:root:current train perplexity4.337516784667969
INFO:root:current mean train loss 1862.1539588180924
INFO:root:current train perplexity4.337993144989014
INFO:root:current mean train loss 1862.8568307284652
INFO:root:current train perplexity4.341012954711914
INFO:root:current mean train loss 1862.9087406462686
INFO:root:current train perplexity4.343382358551025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.50s/it]
INFO:root:final mean train loss: 1862.0937506463633
INFO:root:final train perplexity: 4.342973232269287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 1884.968956480635
INFO:root:eval perplexity: 4.592627048492432
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2324.8405978155474
INFO:root:eval perplexity: 6.6947174072265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:34:50<12:44:14, 587.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1867.2285591020975
INFO:root:current train perplexity4.32127046585083
INFO:root:current mean train loss 1864.3390823981665
INFO:root:current train perplexity4.320887565612793
INFO:root:current mean train loss 1868.3258302569825
INFO:root:current train perplexity4.317899227142334
INFO:root:current mean train loss 1862.078463393306
INFO:root:current train perplexity4.306763648986816
INFO:root:current mean train loss 1856.9738519196783
INFO:root:current train perplexity4.296855926513672
INFO:root:current mean train loss 1851.969116850049
INFO:root:current train perplexity4.289337635040283
INFO:root:current mean train loss 1848.8084435654253
INFO:root:current train perplexity4.280401706695557
INFO:root:current mean train loss 1850.8356830947303
INFO:root:current train perplexity4.28818416595459
INFO:root:current mean train loss 1848.082514077937
INFO:root:current train perplexity4.288222789764404
INFO:root:current mean train loss 1849.8886716240847
INFO:root:current train perplexity4.29582405090332
INFO:root:current mean train loss 1851.2784903918264
INFO:root:current train perplexity4.297265529632568
INFO:root:current mean train loss 1850.816308947577
INFO:root:current train perplexity4.296856880187988
INFO:root:current mean train loss 1851.8610979845837
INFO:root:current train perplexity4.300217151641846
INFO:root:current mean train loss 1851.3286278621176
INFO:root:current train perplexity4.296669006347656
INFO:root:current mean train loss 1850.479094982471
INFO:root:current train perplexity4.2944793701171875
INFO:root:current mean train loss 1850.6917144135161
INFO:root:current train perplexity4.293673515319824
INFO:root:current mean train loss 1850.934320626541
INFO:root:current train perplexity4.2959394454956055
INFO:root:current mean train loss 1851.0736373841123
INFO:root:current train perplexity4.299957752227783
INFO:root:current mean train loss 1851.5970068594
INFO:root:current train perplexity4.304488182067871
INFO:root:current mean train loss 1851.034853703711
INFO:root:current train perplexity4.303318977355957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.42s/it]
INFO:root:final mean train loss: 1850.2514947611337
INFO:root:final train perplexity: 4.302600860595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 1871.7935648167388
INFO:root:eval perplexity: 4.54395055770874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.11s/it]
INFO:root:eval mean loss: 2313.1181917664007
INFO:root:eval perplexity: 6.63084077835083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:44:39<12:34:47, 588.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.7656439887153
INFO:root:current train perplexity4.195193290710449
INFO:root:current mean train loss 1826.117749665913
INFO:root:current train perplexity4.223955154418945
INFO:root:current mean train loss 1828.0887678475215
INFO:root:current train perplexity4.237227916717529
INFO:root:current mean train loss 1834.18020708133
INFO:root:current train perplexity4.247249126434326
INFO:root:current mean train loss 1832.5646586515466
INFO:root:current train perplexity4.243246555328369
INFO:root:current mean train loss 1837.044203315347
INFO:root:current train perplexity4.250095844268799
INFO:root:current mean train loss 1835.7655689184216
INFO:root:current train perplexity4.2488789558410645
INFO:root:current mean train loss 1835.3573402887657
INFO:root:current train perplexity4.252945423126221
INFO:root:current mean train loss 1835.6957655317328
INFO:root:current train perplexity4.253017902374268
INFO:root:current mean train loss 1833.0071544300426
INFO:root:current train perplexity4.247673988342285
INFO:root:current mean train loss 1832.9407720443305
INFO:root:current train perplexity4.243118762969971
INFO:root:current mean train loss 1834.068365734966
INFO:root:current train perplexity4.248635292053223
INFO:root:current mean train loss 1834.364863432655
INFO:root:current train perplexity4.251870632171631
INFO:root:current mean train loss 1834.2262502985893
INFO:root:current train perplexity4.252170085906982
INFO:root:current mean train loss 1835.0460206716652
INFO:root:current train perplexity4.254683971405029
INFO:root:current mean train loss 1834.8525284677182
INFO:root:current train perplexity4.255403518676758
INFO:root:current mean train loss 1834.5414242355075
INFO:root:current train perplexity4.255192756652832
INFO:root:current mean train loss 1836.0993584148046
INFO:root:current train perplexity4.255814552307129
INFO:root:current mean train loss 1836.4987309208623
INFO:root:current train perplexity4.256387233734131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.92s/it]
INFO:root:final mean train loss: 1837.2316981020806
INFO:root:final train perplexity: 4.258646488189697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 1872.0992163259086
INFO:root:eval perplexity: 4.54507303237915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2318.2544304597463
INFO:root:eval perplexity: 6.658752918243408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:54:25<12:24:14, 587.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.5153111049108
INFO:root:current train perplexity4.167462348937988
INFO:root:current mean train loss 1810.365232093312
INFO:root:current train perplexity4.162449359893799
INFO:root:current mean train loss 1820.4417406165082
INFO:root:current train perplexity4.186961650848389
INFO:root:current mean train loss 1814.52095593381
INFO:root:current train perplexity4.179235935211182
INFO:root:current mean train loss 1807.3842206575362
INFO:root:current train perplexity4.1636786460876465
INFO:root:current mean train loss 1808.469721747103
INFO:root:current train perplexity4.169883728027344
INFO:root:current mean train loss 1814.6127766793013
INFO:root:current train perplexity4.184906959533691
INFO:root:current mean train loss 1816.3235269031227
INFO:root:current train perplexity4.1931891441345215
INFO:root:current mean train loss 1818.4502886425903
INFO:root:current train perplexity4.198576927185059
INFO:root:current mean train loss 1820.6698224152856
INFO:root:current train perplexity4.206008434295654
INFO:root:current mean train loss 1822.2314388877467
INFO:root:current train perplexity4.210847854614258
INFO:root:current mean train loss 1822.5098278180049
INFO:root:current train perplexity4.210484981536865
INFO:root:current mean train loss 1822.818338439992
INFO:root:current train perplexity4.209913730621338
INFO:root:current mean train loss 1821.2510178441205
INFO:root:current train perplexity4.206743240356445
INFO:root:current mean train loss 1822.073634512982
INFO:root:current train perplexity4.209997653961182
INFO:root:current mean train loss 1823.702291568384
INFO:root:current train perplexity4.213317394256592
INFO:root:current mean train loss 1824.774242996947
INFO:root:current train perplexity4.217199325561523
INFO:root:current mean train loss 1824.9357380970362
INFO:root:current train perplexity4.2183098793029785
INFO:root:current mean train loss 1825.7883568295604
INFO:root:current train perplexity4.22140645980835
INFO:root:current mean train loss 1825.9311271871518
INFO:root:current train perplexity4.220665454864502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.44s/it]
INFO:root:final mean train loss: 1825.9791110486499
INFO:root:final train perplexity: 4.221020698547363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 1861.1709313358822
INFO:root:eval perplexity: 4.505080699920654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2308.544136209691
INFO:root:eval perplexity: 6.606082439422607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [4:04:21<12:17:22, 589.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1799.152837117513
INFO:root:current train perplexity4.158937931060791
INFO:root:current mean train loss 1824.5667960874496
INFO:root:current train perplexity4.192051410675049
INFO:root:current mean train loss 1815.6946879795619
INFO:root:current train perplexity4.161962509155273
INFO:root:current mean train loss 1814.622919153284
INFO:root:current train perplexity4.1642889976501465
INFO:root:current mean train loss 1820.5077932105874
INFO:root:current train perplexity4.187254428863525
INFO:root:current mean train loss 1816.0884830387495
INFO:root:current train perplexity4.180134296417236
INFO:root:current mean train loss 1815.464319473658
INFO:root:current train perplexity4.177648067474365
INFO:root:current mean train loss 1810.5746466705154
INFO:root:current train perplexity4.176031589508057
INFO:root:current mean train loss 1812.3013993050288
INFO:root:current train perplexity4.177630424499512
INFO:root:current mean train loss 1811.4166151434829
INFO:root:current train perplexity4.1766676902771
INFO:root:current mean train loss 1813.9977036714554
INFO:root:current train perplexity4.179779052734375
INFO:root:current mean train loss 1813.6700312387052
INFO:root:current train perplexity4.176328659057617
INFO:root:current mean train loss 1815.5960421094708
INFO:root:current train perplexity4.1805291175842285
INFO:root:current mean train loss 1816.3716379955097
INFO:root:current train perplexity4.180994987487793
INFO:root:current mean train loss 1816.0960093294636
INFO:root:current train perplexity4.184122562408447
INFO:root:current mean train loss 1815.128296859621
INFO:root:current train perplexity4.179834842681885
INFO:root:current mean train loss 1816.1638509816137
INFO:root:current train perplexity4.182590484619141
INFO:root:current mean train loss 1816.8285855959298
INFO:root:current train perplexity4.184195041656494
INFO:root:current mean train loss 1815.5186577512507
INFO:root:current train perplexity4.1833720207214355
INFO:root:current mean train loss 1815.4643819892233
INFO:root:current train perplexity4.183210849761963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.90s/it]
INFO:root:final mean train loss: 1814.9973666546505
INFO:root:final train perplexity: 4.1846208572387695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 1866.1050579530972
INFO:root:eval perplexity: 4.5230937004089355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it]
INFO:root:eval mean loss: 2313.8463087149544
INFO:root:eval perplexity: 6.634791374206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [4:14:01<12:04:00, 587.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.4215266530107
INFO:root:current train perplexity4.174602508544922
INFO:root:current mean train loss 1788.7614088126109
INFO:root:current train perplexity4.113191604614258
INFO:root:current mean train loss 1794.3901640706042
INFO:root:current train perplexity4.128228664398193
INFO:root:current mean train loss 1791.878227166766
INFO:root:current train perplexity4.129711627960205
INFO:root:current mean train loss 1794.607041823891
INFO:root:current train perplexity4.134057521820068
INFO:root:current mean train loss 1795.4031041510225
INFO:root:current train perplexity4.128786563873291
INFO:root:current mean train loss 1799.6553279025693
INFO:root:current train perplexity4.142520904541016
INFO:root:current mean train loss 1800.1206683983849
INFO:root:current train perplexity4.138814926147461
INFO:root:current mean train loss 1802.628069465991
INFO:root:current train perplexity4.142879009246826
INFO:root:current mean train loss 1802.95252502636
INFO:root:current train perplexity4.142549991607666
INFO:root:current mean train loss 1802.3100093434798
INFO:root:current train perplexity4.142088890075684
INFO:root:current mean train loss 1802.2832721305667
INFO:root:current train perplexity4.143768787384033
INFO:root:current mean train loss 1800.475423144295
INFO:root:current train perplexity4.139227867126465
INFO:root:current mean train loss 1802.9146370770413
INFO:root:current train perplexity4.14462947845459
INFO:root:current mean train loss 1801.8725790941078
INFO:root:current train perplexity4.142171859741211
INFO:root:current mean train loss 1803.2456596518089
INFO:root:current train perplexity4.145174980163574
INFO:root:current mean train loss 1803.3327685070794
INFO:root:current train perplexity4.143990516662598
INFO:root:current mean train loss 1804.4718150796732
INFO:root:current train perplexity4.147101879119873
INFO:root:current mean train loss 1804.4866834616673
INFO:root:current train perplexity4.147860527038574
INFO:root:current mean train loss 1805.1273765033327
INFO:root:current train perplexity4.149925231933594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.74s/it]
INFO:root:final mean train loss: 1804.7519739317402
INFO:root:final train perplexity: 4.15094518661499
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 1853.219428312694
INFO:root:eval perplexity: 4.476202487945557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2303.5267437874004
INFO:root:eval perplexity: 6.5790300369262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [4:23:55<11:56:55, 589.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.8185045965786
INFO:root:current train perplexity4.046927452087402
INFO:root:current mean train loss 1786.8508092180084
INFO:root:current train perplexity4.089296340942383
INFO:root:current mean train loss 1789.0720692715904
INFO:root:current train perplexity4.108138561248779
INFO:root:current mean train loss 1784.1876466207664
INFO:root:current train perplexity4.098053455352783
INFO:root:current mean train loss 1787.3223828977893
INFO:root:current train perplexity4.10587215423584
INFO:root:current mean train loss 1788.4252074320257
INFO:root:current train perplexity4.106258392333984
INFO:root:current mean train loss 1787.7058361482475
INFO:root:current train perplexity4.103829860687256
INFO:root:current mean train loss 1789.7152928978912
INFO:root:current train perplexity4.103708744049072
INFO:root:current mean train loss 1790.1548868815105
INFO:root:current train perplexity4.106998920440674
INFO:root:current mean train loss 1792.0901454853863
INFO:root:current train perplexity4.106821060180664
INFO:root:current mean train loss 1790.9149588745347
INFO:root:current train perplexity4.104302406311035
INFO:root:current mean train loss 1789.4669080875904
INFO:root:current train perplexity4.100741863250732
INFO:root:current mean train loss 1789.6450148735591
INFO:root:current train perplexity4.103185176849365
INFO:root:current mean train loss 1790.2982383581957
INFO:root:current train perplexity4.1070146560668945
INFO:root:current mean train loss 1791.5101629814494
INFO:root:current train perplexity4.112086772918701
INFO:root:current mean train loss 1792.9697326738508
INFO:root:current train perplexity4.114175796508789
INFO:root:current mean train loss 1793.0937700996353
INFO:root:current train perplexity4.115714073181152
INFO:root:current mean train loss 1794.0262831686841
INFO:root:current train perplexity4.117974281311035
INFO:root:current mean train loss 1794.1347642453034
INFO:root:current train perplexity4.118409156799316
INFO:root:current mean train loss 1795.7657902749736
INFO:root:current train perplexity4.119365215301514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.59s/it]
INFO:root:final mean train loss: 1794.9125635836742
INFO:root:final train perplexity: 4.118858337402344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it]
INFO:root:eval mean loss: 1851.8874663224458
INFO:root:eval perplexity: 4.471383094787598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 2301.975108045213
INFO:root:eval perplexity: 6.570687294006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:33:44<11:46:47, 588.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.8088525390624
INFO:root:current train perplexity4.100346088409424
INFO:root:current mean train loss 1781.993159877232
INFO:root:current train perplexity4.068380832672119
INFO:root:current mean train loss 1778.2919074041192
INFO:root:current train perplexity4.056717872619629
INFO:root:current mean train loss 1783.8118092447917
INFO:root:current train perplexity4.071890830993652
INFO:root:current mean train loss 1784.68802760074
INFO:root:current train perplexity4.078103065490723
INFO:root:current mean train loss 1786.3722787873642
INFO:root:current train perplexity4.080811023712158
INFO:root:current mean train loss 1783.6982438151042
INFO:root:current train perplexity4.079325199127197
INFO:root:current mean train loss 1786.8466831527219
INFO:root:current train perplexity4.087456703186035
INFO:root:current mean train loss 1788.4147003348214
INFO:root:current train perplexity4.087990760803223
INFO:root:current mean train loss 1789.8333869190706
INFO:root:current train perplexity4.095362186431885
INFO:root:current mean train loss 1789.7914578034156
INFO:root:current train perplexity4.090472221374512
INFO:root:current mean train loss 1786.2590465009973
INFO:root:current train perplexity4.085235595703125
INFO:root:current mean train loss 1785.821090782016
INFO:root:current train perplexity4.0858612060546875
INFO:root:current mean train loss 1785.0171510120738
INFO:root:current train perplexity4.084989547729492
INFO:root:current mean train loss 1786.2208445610434
INFO:root:current train perplexity4.088092803955078
INFO:root:current mean train loss 1786.6854918464783
INFO:root:current train perplexity4.0882978439331055
INFO:root:current mean train loss 1787.0777544163946
INFO:root:current train perplexity4.088466167449951
INFO:root:current mean train loss 1787.0225758555237
INFO:root:current train perplexity4.089141845703125
INFO:root:current mean train loss 1786.5358329427083
INFO:root:current train perplexity4.0887017250061035
INFO:root:current mean train loss 1786.7440619437302
INFO:root:current train perplexity4.090550899505615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.48s/it]
INFO:root:final mean train loss: 1786.1669430331156
INFO:root:final train perplexity: 4.090546607971191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 1848.1389220758533
INFO:root:eval perplexity: 4.45784854888916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2298.771493032469
INFO:root:eval perplexity: 6.553494453430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:43:34<11:37:16, 589.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1777.4129651940386
INFO:root:current train perplexity4.044271469116211
INFO:root:current mean train loss 1779.232630411784
INFO:root:current train perplexity4.053480625152588
INFO:root:current mean train loss 1774.698808225867
INFO:root:current train perplexity4.051806449890137
INFO:root:current mean train loss 1773.0420706612724
INFO:root:current train perplexity4.054327964782715
INFO:root:current mean train loss 1773.2337852416
INFO:root:current train perplexity4.054198265075684
INFO:root:current mean train loss 1775.5459827732395
INFO:root:current train perplexity4.050090789794922
INFO:root:current mean train loss 1772.2004396295272
INFO:root:current train perplexity4.046082496643066
INFO:root:current mean train loss 1773.2882308189314
INFO:root:current train perplexity4.048853874206543
INFO:root:current mean train loss 1774.7977455036523
INFO:root:current train perplexity4.051647663116455
INFO:root:current mean train loss 1777.263319200085
INFO:root:current train perplexity4.0614423751831055
INFO:root:current mean train loss 1777.5789688725174
INFO:root:current train perplexity4.0601396560668945
INFO:root:current mean train loss 1778.7156085327968
INFO:root:current train perplexity4.0619282722473145
INFO:root:current mean train loss 1778.6657354868603
INFO:root:current train perplexity4.062838077545166
INFO:root:current mean train loss 1778.4266379345422
INFO:root:current train perplexity4.0615925788879395
INFO:root:current mean train loss 1777.038836931735
INFO:root:current train perplexity4.059575080871582
INFO:root:current mean train loss 1777.3087152835712
INFO:root:current train perplexity4.0631422996521
INFO:root:current mean train loss 1777.803921313996
INFO:root:current train perplexity4.063543796539307
INFO:root:current mean train loss 1779.050032547542
INFO:root:current train perplexity4.0651044845581055
INFO:root:current mean train loss 1778.5047880338059
INFO:root:current train perplexity4.06351375579834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it]
INFO:root:final mean train loss: 1777.7594210210618
INFO:root:final train perplexity: 4.063513278961182
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 1850.4828032365083
INFO:root:eval perplexity: 4.466306209564209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2302.446337111453
INFO:root:eval perplexity: 6.573219299316406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:53:20<11:26:36, 588.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.6174180772568
INFO:root:current train perplexity4.073299407958984
INFO:root:current mean train loss 1757.7652072731507
INFO:root:current train perplexity4.001067161560059
INFO:root:current mean train loss 1753.8860850356982
INFO:root:current train perplexity3.9939239025115967
INFO:root:current mean train loss 1765.4696104179309
INFO:root:current train perplexity4.020757675170898
INFO:root:current mean train loss 1763.792547622345
INFO:root:current train perplexity4.013296127319336
INFO:root:current mean train loss 1763.9375304576222
INFO:root:current train perplexity4.010157585144043
INFO:root:current mean train loss 1763.6501134111377
INFO:root:current train perplexity4.017482280731201
INFO:root:current mean train loss 1764.6247995911936
INFO:root:current train perplexity4.015982627868652
INFO:root:current mean train loss 1763.880672572717
INFO:root:current train perplexity4.018784523010254
INFO:root:current mean train loss 1766.7272174360992
INFO:root:current train perplexity4.024438381195068
INFO:root:current mean train loss 1766.6857133455153
INFO:root:current train perplexity4.024726390838623
INFO:root:current mean train loss 1766.2247399208889
INFO:root:current train perplexity4.030115127563477
INFO:root:current mean train loss 1766.4856981856453
INFO:root:current train perplexity4.030830383300781
INFO:root:current mean train loss 1766.6499885110295
INFO:root:current train perplexity4.033078670501709
INFO:root:current mean train loss 1767.5187022288358
INFO:root:current train perplexity4.03413724899292
INFO:root:current mean train loss 1767.1186037259515
INFO:root:current train perplexity4.033071517944336
INFO:root:current mean train loss 1768.02824573505
INFO:root:current train perplexity4.03461217880249
INFO:root:current mean train loss 1768.3973676526386
INFO:root:current train perplexity4.032591819763184
INFO:root:current mean train loss 1768.3274320535993
INFO:root:current train perplexity4.031932353973389
INFO:root:current mean train loss 1768.9560298130361
INFO:root:current train perplexity4.033163070678711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.26s/it]
INFO:root:final mean train loss: 1768.532141735021
INFO:root:final train perplexity: 4.034050464630127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 1836.2062165821699
INFO:root:eval perplexity: 4.415034770965576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2290.198209721991
INFO:root:eval perplexity: 6.507705211639404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [5:03:09<11:16:53, 588.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1769.9566040039062
INFO:root:current train perplexity4.033344268798828
INFO:root:current mean train loss 1777.0548434787327
INFO:root:current train perplexity4.020873546600342
INFO:root:current mean train loss 1769.1817464912888
INFO:root:current train perplexity4.012118816375732
INFO:root:current mean train loss 1762.804006752061
INFO:root:current train perplexity4.007733345031738
INFO:root:current mean train loss 1763.9405835648658
INFO:root:current train perplexity3.9999022483825684
INFO:root:current mean train loss 1762.3052662896566
INFO:root:current train perplexity3.9962427616119385
INFO:root:current mean train loss 1758.7213343416158
INFO:root:current train perplexity3.993237018585205
INFO:root:current mean train loss 1757.3041965284951
INFO:root:current train perplexity3.9925711154937744
INFO:root:current mean train loss 1759.1298071466404
INFO:root:current train perplexity3.9934308528900146
INFO:root:current mean train loss 1758.7199311555075
INFO:root:current train perplexity3.998425245285034
INFO:root:current mean train loss 1759.0490629854257
INFO:root:current train perplexity4.000101089477539
INFO:root:current mean train loss 1758.9789426542725
INFO:root:current train perplexity4.004388809204102
INFO:root:current mean train loss 1758.7815836522163
INFO:root:current train perplexity4.004538536071777
INFO:root:current mean train loss 1758.9072231563148
INFO:root:current train perplexity4.003840446472168
INFO:root:current mean train loss 1758.0523217670714
INFO:root:current train perplexity4.002724647521973
INFO:root:current mean train loss 1758.7748885848418
INFO:root:current train perplexity4.0053324699401855
INFO:root:current mean train loss 1759.959578660728
INFO:root:current train perplexity4.007136344909668
INFO:root:current mean train loss 1759.4316857471665
INFO:root:current train perplexity4.003297328948975
INFO:root:current mean train loss 1760.69800439774
INFO:root:current train perplexity4.008693218231201
INFO:root:current mean train loss 1760.4025749610591
INFO:root:current train perplexity4.008436679840088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.11s/it]
INFO:root:final mean train loss: 1760.9038042538825
INFO:root:final train perplexity: 4.009853363037109
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 1853.67379046501
INFO:root:eval perplexity: 4.477848529815674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2312.7138689189937
INFO:root:eval perplexity: 6.628648281097412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [5:13:05<11:09:41, 590.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.655023619186
INFO:root:current train perplexity3.989828586578369
INFO:root:current mean train loss 1762.3282692649148
INFO:root:current train perplexity4.002133846282959
INFO:root:current mean train loss 1766.2314186881108
INFO:root:current train perplexity3.989363431930542
INFO:root:current mean train loss 1755.6670078466655
INFO:root:current train perplexity3.9722673892974854
INFO:root:current mean train loss 1751.6249426848194
INFO:root:current train perplexity3.9782612323760986
INFO:root:current mean train loss 1749.9096387438133
INFO:root:current train perplexity3.9753029346466064
INFO:root:current mean train loss 1751.911017766451
INFO:root:current train perplexity3.9831137657165527
INFO:root:current mean train loss 1751.968428476983
INFO:root:current train perplexity3.985537052154541
INFO:root:current mean train loss 1753.5777167957165
INFO:root:current train perplexity3.990539789199829
INFO:root:current mean train loss 1754.0025276192173
INFO:root:current train perplexity3.987967014312744
INFO:root:current mean train loss 1752.9454758846177
INFO:root:current train perplexity3.986940860748291
INFO:root:current mean train loss 1751.9277299962748
INFO:root:current train perplexity3.9850196838378906
INFO:root:current mean train loss 1752.1951510489994
INFO:root:current train perplexity3.9838526248931885
INFO:root:current mean train loss 1752.5917971476813
INFO:root:current train perplexity3.983133316040039
INFO:root:current mean train loss 1753.2019006592982
INFO:root:current train perplexity3.985212564468384
INFO:root:current mean train loss 1752.4529461270404
INFO:root:current train perplexity3.984215497970581
INFO:root:current mean train loss 1753.332949860678
INFO:root:current train perplexity3.9857869148254395
INFO:root:current mean train loss 1752.583796822334
INFO:root:current train perplexity3.9822545051574707
INFO:root:current mean train loss 1754.0273541488275
INFO:root:current train perplexity3.985502004623413
INFO:root:current mean train loss 1753.1150382960266
INFO:root:current train perplexity3.982604742050171

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.25s/it]
INFO:root:final mean train loss: 1752.6895893845244
INFO:root:final train perplexity: 3.9839608669281006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 1828.391217603751
INFO:root:eval perplexity: 4.387218475341797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.26s/it]
INFO:root:eval mean loss: 2284.832245522357
INFO:root:eval perplexity: 6.479209899902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [5:22:45<10:55:54, 587.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1728.909619140625
INFO:root:current train perplexity3.9231274127960205
INFO:root:current mean train loss 1738.3727195739746
INFO:root:current train perplexity3.9602296352386475
INFO:root:current mean train loss 1743.2123629056491
INFO:root:current train perplexity3.964999198913574
INFO:root:current mean train loss 1737.0760904947917
INFO:root:current train perplexity3.9508144855499268
INFO:root:current mean train loss 1739.1953676970109
INFO:root:current train perplexity3.9578638076782227
INFO:root:current mean train loss 1735.9696014404296
INFO:root:current train perplexity3.9466230869293213
INFO:root:current mean train loss 1734.6176497025924
INFO:root:current train perplexity3.9463837146759033
INFO:root:current mean train loss 1738.1550174110814
INFO:root:current train perplexity3.946545124053955
INFO:root:current mean train loss 1735.7371316599292
INFO:root:current train perplexity3.9395511150360107
INFO:root:current mean train loss 1737.5398085276286
INFO:root:current train perplexity3.9432485103607178
INFO:root:current mean train loss 1739.1344924638856
INFO:root:current train perplexity3.945136308670044
INFO:root:current mean train loss 1740.1866128855738
INFO:root:current train perplexity3.9461286067962646
INFO:root:current mean train loss 1741.0582878960504
INFO:root:current train perplexity3.9492976665496826
INFO:root:current mean train loss 1743.2266967773437
INFO:root:current train perplexity3.953266143798828
INFO:root:current mean train loss 1744.8452506287458
INFO:root:current train perplexity3.9550163745880127
INFO:root:current mean train loss 1745.869532815004
INFO:root:current train perplexity3.956695079803467
INFO:root:current mean train loss 1746.3258678758
INFO:root:current train perplexity3.958566665649414
INFO:root:current mean train loss 1745.6854017084295
INFO:root:current train perplexity3.957252264022827
INFO:root:current mean train loss 1745.234401842343
INFO:root:current train perplexity3.958106279373169
INFO:root:current mean train loss 1744.7168602768256
INFO:root:current train perplexity3.957765579223633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.39s/it]
INFO:root:final mean train loss: 1744.360890906445
INFO:root:final train perplexity: 3.9578773975372314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 1851.0492155467364
INFO:root:eval perplexity: 4.468352794647217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2305.0506280127993
INFO:root:eval perplexity: 6.5872344970703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [5:32:39<10:48:26, 589.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.4946320769075
INFO:root:current train perplexity3.903277635574341
INFO:root:current mean train loss 1732.2740044028071
INFO:root:current train perplexity3.9286141395568848
INFO:root:current mean train loss 1731.204535198556
INFO:root:current train perplexity3.923715591430664
INFO:root:current mean train loss 1730.6041842594702
INFO:root:current train perplexity3.921485662460327
INFO:root:current mean train loss 1731.5614420572917
INFO:root:current train perplexity3.919907808303833
INFO:root:current mean train loss 1733.1662917112353
INFO:root:current train perplexity3.929136276245117
INFO:root:current mean train loss 1731.057360064508
INFO:root:current train perplexity3.923816204071045
INFO:root:current mean train loss 1731.582600597249
INFO:root:current train perplexity3.9208667278289795
INFO:root:current mean train loss 1734.8229778642121
INFO:root:current train perplexity3.928539752960205
INFO:root:current mean train loss 1735.5783608943193
INFO:root:current train perplexity3.928799629211426
INFO:root:current mean train loss 1733.975753231633
INFO:root:current train perplexity3.9256656169891357
INFO:root:current mean train loss 1734.3138886146253
INFO:root:current train perplexity3.9314541816711426
INFO:root:current mean train loss 1734.509765625
INFO:root:current train perplexity3.9310572147369385
INFO:root:current mean train loss 1733.9707431945578
INFO:root:current train perplexity3.9294848442077637
INFO:root:current mean train loss 1735.081876699232
INFO:root:current train perplexity3.9306068420410156
INFO:root:current mean train loss 1736.4362446960952
INFO:root:current train perplexity3.9323348999023438
INFO:root:current mean train loss 1736.0823177549196
INFO:root:current train perplexity3.9308207035064697
INFO:root:current mean train loss 1736.6642565622583
INFO:root:current train perplexity3.932497978210449
INFO:root:current mean train loss 1737.3733788125999
INFO:root:current train perplexity3.933366298675537
INFO:root:current mean train loss 1737.1330854756457
INFO:root:current train perplexity3.9339497089385986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.15s/it]
INFO:root:final mean train loss: 1736.54169698418
INFO:root:final train perplexity: 3.9335458278656006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 1831.0973805096132
INFO:root:eval perplexity: 4.3968305587768555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2290.2812283563276
INFO:root:eval perplexity: 6.508148193359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:42:30<10:39:01, 589.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.2806578291224
INFO:root:current train perplexity3.9019405841827393
INFO:root:current mean train loss 1732.8086516390142
INFO:root:current train perplexity3.8928751945495605
INFO:root:current mean train loss 1731.644295828683
INFO:root:current train perplexity3.906001567840576
INFO:root:current mean train loss 1725.6349546171082
INFO:root:current train perplexity3.8966026306152344
INFO:root:current mean train loss 1727.1027525619938
INFO:root:current train perplexity3.9037258625030518
INFO:root:current mean train loss 1725.7959393331098
INFO:root:current train perplexity3.9009792804718018
INFO:root:current mean train loss 1730.8066548723996
INFO:root:current train perplexity3.91483211517334
INFO:root:current mean train loss 1734.1605547465365
INFO:root:current train perplexity3.9175477027893066
INFO:root:current mean train loss 1732.9675848702723
INFO:root:current train perplexity3.9109997749328613
INFO:root:current mean train loss 1730.877932880486
INFO:root:current train perplexity3.905810832977295
INFO:root:current mean train loss 1729.7300831238574
INFO:root:current train perplexity3.9075684547424316
INFO:root:current mean train loss 1729.080596668237
INFO:root:current train perplexity3.9079549312591553
INFO:root:current mean train loss 1729.4914989441957
INFO:root:current train perplexity3.90929913520813
INFO:root:current mean train loss 1729.9035606001166
INFO:root:current train perplexity3.9091622829437256
INFO:root:current mean train loss 1730.624977530565
INFO:root:current train perplexity3.9101810455322266
INFO:root:current mean train loss 1730.9576495659994
INFO:root:current train perplexity3.910226821899414
INFO:root:current mean train loss 1731.7390365150209
INFO:root:current train perplexity3.910794973373413
INFO:root:current mean train loss 1731.5236679638508
INFO:root:current train perplexity3.910341501235962
INFO:root:current mean train loss 1730.3603579431551
INFO:root:current train perplexity3.910740375518799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.60s/it]
INFO:root:final mean train loss: 1728.922982281768
INFO:root:final train perplexity: 3.9099814891815186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it]
INFO:root:eval mean loss: 1824.2797375401706
INFO:root:eval perplexity: 4.372654438018799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it]
INFO:root:eval mean loss: 2285.3688293889904
INFO:root:eval perplexity: 6.482053756713867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:52:16<10:28:07, 588.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.3760764382102
INFO:root:current train perplexity3.9268035888671875
INFO:root:current mean train loss 1716.1532895199887
INFO:root:current train perplexity3.8704307079315186
INFO:root:current mean train loss 1719.1796701440314
INFO:root:current train perplexity3.88222336769104
INFO:root:current mean train loss 1720.1899794796273
INFO:root:current train perplexity3.8814051151275635
INFO:root:current mean train loss 1723.6142242505894
INFO:root:current train perplexity3.8822810649871826
INFO:root:current mean train loss 1724.2056896709882
INFO:root:current train perplexity3.885425329208374
INFO:root:current mean train loss 1722.4170990739437
INFO:root:current train perplexity3.879493236541748
INFO:root:current mean train loss 1720.568351820719
INFO:root:current train perplexity3.879470109939575
INFO:root:current mean train loss 1720.9470044758111
INFO:root:current train perplexity3.880657434463501
INFO:root:current mean train loss 1723.7618262147537
INFO:root:current train perplexity3.885249376296997
INFO:root:current mean train loss 1724.3228143980666
INFO:root:current train perplexity3.8882851600646973
INFO:root:current mean train loss 1722.3820621686193
INFO:root:current train perplexity3.8863911628723145
INFO:root:current mean train loss 1723.130425324822
INFO:root:current train perplexity3.888762950897217
INFO:root:current mean train loss 1723.4470869423687
INFO:root:current train perplexity3.8895933628082275
INFO:root:current mean train loss 1722.936687466779
INFO:root:current train perplexity3.8896405696868896
INFO:root:current mean train loss 1722.8703022722689
INFO:root:current train perplexity3.8894991874694824
INFO:root:current mean train loss 1721.9114543173641
INFO:root:current train perplexity3.887606143951416
INFO:root:current mean train loss 1722.6487125327615
INFO:root:current train perplexity3.8886518478393555
INFO:root:current mean train loss 1723.8023546156733
INFO:root:current train perplexity3.8910810947418213
INFO:root:current mean train loss 1723.2319360849808
INFO:root:current train perplexity3.890378952026367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.07s/it]
INFO:root:final mean train loss: 1723.066641680111
INFO:root:final train perplexity: 3.8919639587402344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 1823.4200205701463
INFO:root:eval perplexity: 4.369615077972412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 2285.1189337114915
INFO:root:eval perplexity: 6.480729579925537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [6:02:08<10:19:14, 589.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1678.2191641671318
INFO:root:current train perplexity3.8521244525909424
INFO:root:current mean train loss 1728.4879369735718
INFO:root:current train perplexity3.882256507873535
INFO:root:current mean train loss 1721.2889570269667
INFO:root:current train perplexity3.8806445598602295
INFO:root:current mean train loss 1713.2955467410204
INFO:root:current train perplexity3.8712151050567627
INFO:root:current mean train loss 1710.0427622572283
INFO:root:current train perplexity3.8650319576263428
INFO:root:current mean train loss 1711.2534921819513
INFO:root:current train perplexity3.8591325283050537
INFO:root:current mean train loss 1713.4404361020229
INFO:root:current train perplexity3.86336350440979
INFO:root:current mean train loss 1711.9763549133972
INFO:root:current train perplexity3.8606560230255127
INFO:root:current mean train loss 1714.1941385315235
INFO:root:current train perplexity3.863556385040283
INFO:root:current mean train loss 1716.6237992911504
INFO:root:current train perplexity3.865708351135254
INFO:root:current mean train loss 1718.8281498177969
INFO:root:current train perplexity3.868492841720581
INFO:root:current mean train loss 1719.0134736189605
INFO:root:current train perplexity3.8724138736724854
INFO:root:current mean train loss 1718.063169895632
INFO:root:current train perplexity3.8742740154266357
INFO:root:current mean train loss 1717.8765760674535
INFO:root:current train perplexity3.8714311122894287
INFO:root:current mean train loss 1718.1342912775463
INFO:root:current train perplexity3.871368408203125
INFO:root:current mean train loss 1718.4466646204444
INFO:root:current train perplexity3.871140241622925
INFO:root:current mean train loss 1717.6603018645865
INFO:root:current train perplexity3.8702847957611084
INFO:root:current mean train loss 1718.192773607042
INFO:root:current train perplexity3.8698225021362305
INFO:root:current mean train loss 1717.050149529455
INFO:root:current train perplexity3.870272397994995
INFO:root:current mean train loss 1716.3358798838256
INFO:root:current train perplexity3.8694751262664795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.47s/it]
INFO:root:final mean train loss: 1715.9040815129283
INFO:root:final train perplexity: 3.8700413703918457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 1818.816615760749
INFO:root:eval perplexity: 4.353377819061279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.72s/it]
INFO:root:eval mean loss: 2281.4891725364305
INFO:root:eval perplexity: 6.461519718170166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [6:11:52<10:07:44, 588.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.6158311631943
INFO:root:current train perplexity3.8308491706848145
INFO:root:current mean train loss 1711.0847479458514
INFO:root:current train perplexity3.8564953804016113
INFO:root:current mean train loss 1713.741733597736
INFO:root:current train perplexity3.8564279079437256
INFO:root:current mean train loss 1716.868358667346
INFO:root:current train perplexity3.8583664894104004
INFO:root:current mean train loss 1714.185079716029
INFO:root:current train perplexity3.8621528148651123
INFO:root:current mean train loss 1711.2447359697535
INFO:root:current train perplexity3.859196901321411
INFO:root:current mean train loss 1710.8845358678536
INFO:root:current train perplexity3.852334976196289
INFO:root:current mean train loss 1711.3813619114408
INFO:root:current train perplexity3.8563783168792725
INFO:root:current mean train loss 1710.671490731324
INFO:root:current train perplexity3.8535332679748535
INFO:root:current mean train loss 1708.1045534164186
INFO:root:current train perplexity3.846843957901001
INFO:root:current mean train loss 1707.7700760690789
INFO:root:current train perplexity3.847391128540039
INFO:root:current mean train loss 1707.5918966634824
INFO:root:current train perplexity3.8466758728027344
INFO:root:current mean train loss 1706.2100830078125
INFO:root:current train perplexity3.845201253890991
INFO:root:current mean train loss 1707.933138777155
INFO:root:current train perplexity3.8476126194000244
INFO:root:current mean train loss 1708.982621495864
INFO:root:current train perplexity3.849940299987793
INFO:root:current mean train loss 1709.7665204983314
INFO:root:current train perplexity3.852074146270752
INFO:root:current mean train loss 1710.7551372678809
INFO:root:current train perplexity3.8528547286987305
INFO:root:current mean train loss 1711.1941358681054
INFO:root:current train perplexity3.8534095287323
INFO:root:current mean train loss 1711.4134614112254
INFO:root:current train perplexity3.8540444374084473
INFO:root:current mean train loss 1711.1642979795952
INFO:root:current train perplexity3.853426218032837

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.51s/it]
INFO:root:final mean train loss: 1711.0882983878594
INFO:root:final train perplexity: 3.8553707599639893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it]
INFO:root:eval mean loss: 1830.6844404504654
INFO:root:eval perplexity: 4.395362854003906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it]
INFO:root:eval mean loss: 2292.0367704350897
INFO:root:eval perplexity: 6.51749849319458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [6:21:45<9:59:23, 589.57s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.0233626827116
INFO:root:current train perplexity3.838531255722046
INFO:root:current mean train loss 1710.0973736798321
INFO:root:current train perplexity3.8231112957000732
INFO:root:current mean train loss 1698.8681072205989
INFO:root:current train perplexity3.809471368789673
INFO:root:current mean train loss 1696.9301751068283
INFO:root:current train perplexity3.8059322834014893
INFO:root:current mean train loss 1698.7119275377943
INFO:root:current train perplexity3.8072776794433594
INFO:root:current mean train loss 1697.8657710934024
INFO:root:current train perplexity3.8123743534088135
INFO:root:current mean train loss 1701.0915387202606
INFO:root:current train perplexity3.82173752784729
INFO:root:current mean train loss 1703.9097746601255
INFO:root:current train perplexity3.82434344291687
INFO:root:current mean train loss 1705.412406903685
INFO:root:current train perplexity3.826810121536255
INFO:root:current mean train loss 1707.093183806929
INFO:root:current train perplexity3.829552412033081
INFO:root:current mean train loss 1710.3898034966824
INFO:root:current train perplexity3.8395729064941406
INFO:root:current mean train loss 1708.5852822912746
INFO:root:current train perplexity3.8350212574005127
INFO:root:current mean train loss 1707.030427331214
INFO:root:current train perplexity3.8318068981170654
INFO:root:current mean train loss 1707.9600536105565
INFO:root:current train perplexity3.83382511138916
INFO:root:current mean train loss 1708.524358371051
INFO:root:current train perplexity3.8367109298706055
INFO:root:current mean train loss 1709.7903408778309
INFO:root:current train perplexity3.840731382369995
INFO:root:current mean train loss 1718.8406633544628
INFO:root:current train perplexity3.870565414428711
INFO:root:current mean train loss 1733.9145638057782
INFO:root:current train perplexity3.9175667762756348
INFO:root:current mean train loss 1748.1884763658238
INFO:root:current train perplexity3.9646801948547363
INFO:root:current mean train loss 1765.044991185055
INFO:root:current train perplexity4.020228385925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.78s/it]
INFO:root:final mean train loss: 1767.2415444609258
INFO:root:final train perplexity: 4.029946327209473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2010.3515027634642
INFO:root:eval perplexity: 5.082760334014893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2463.3191268596242
INFO:root:eval perplexity: 7.49750280380249
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [6:31:31<9:48:24, 588.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2080.1157890995846
INFO:root:current train perplexity5.176929473876953
INFO:root:current mean train loss 2981.6211230741533
INFO:root:current train perplexity10.604604721069336
INFO:root:current mean train loss 3768.694058982275
INFO:root:current train perplexity19.691112518310547
INFO:root:current mean train loss 3869.727536807903
INFO:root:current train perplexity21.278873443603516
INFO:root:current mean train loss 3786.876370806286
INFO:root:current train perplexity19.95223045349121
INFO:root:current mean train loss 3626.4083901308154
INFO:root:current train perplexity17.55703353881836
INFO:root:current mean train loss 3463.4591319740084
INFO:root:current train perplexity15.43795394897461
INFO:root:current mean train loss 3327.468719129844
INFO:root:current train perplexity13.824596405029297
INFO:root:current mean train loss 3211.9641432691624
INFO:root:current train perplexity12.58352279663086
INFO:root:current mean train loss 3111.9972538543793
INFO:root:current train perplexity11.642887115478516
INFO:root:current mean train loss 3026.3371609183127
INFO:root:current train perplexity10.888017654418945
INFO:root:current mean train loss 2953.8996860546213
INFO:root:current train perplexity10.256524085998535
INFO:root:current mean train loss 2888.1041679710406
INFO:root:current train perplexity9.737630844116211
INFO:root:current mean train loss 2833.470592385362
INFO:root:current train perplexity9.327588081359863
INFO:root:current mean train loss 2783.2183057928182
INFO:root:current train perplexity8.964972496032715
INFO:root:current mean train loss 2738.7819191834233
INFO:root:current train perplexity8.656466484069824
INFO:root:current mean train loss 2695.376072241196
INFO:root:current train perplexity8.3713960647583
INFO:root:current mean train loss 2658.7051520945315
INFO:root:current train perplexity8.130997657775879
INFO:root:current mean train loss 2625.7900004729495
INFO:root:current train perplexity7.926854133605957
INFO:root:current mean train loss 2595.7826788826624
INFO:root:current train perplexity7.742342472076416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.21s/it]
INFO:root:final mean train loss: 2594.2613962763076
INFO:root:final train perplexity: 7.736819744110107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it]
INFO:root:eval mean loss: 1977.1261107532691
INFO:root:eval perplexity: 4.948000431060791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.27s/it]
INFO:root:eval mean loss: 2442.4110791361923
INFO:root:eval perplexity: 7.3703932762146
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:41:30<9:41:44, 591.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2040.5448519388835
INFO:root:current train perplexity4.981678009033203
INFO:root:current mean train loss 2050.91332322724
INFO:root:current train perplexity5.022850513458252
INFO:root:current mean train loss 2054.3342235668288
INFO:root:current train perplexity5.006465435028076
INFO:root:current mean train loss 2044.064501213305
INFO:root:current train perplexity4.969746112823486
INFO:root:current mean train loss 2035.7049639301915
INFO:root:current train perplexity4.963663578033447
INFO:root:current mean train loss 2035.1539296399826
INFO:root:current train perplexity4.952779293060303
INFO:root:current mean train loss 2033.5471887698118
INFO:root:current train perplexity4.944038391113281
INFO:root:current mean train loss 2027.6835494305021
INFO:root:current train perplexity4.920821189880371
INFO:root:current mean train loss 2024.3824036461967
INFO:root:current train perplexity4.914616107940674
INFO:root:current mean train loss 2019.7799580891926
INFO:root:current train perplexity4.900452613830566
INFO:root:current mean train loss 2015.1925053283246
INFO:root:current train perplexity4.884601593017578
INFO:root:current mean train loss 2010.3209844991115
INFO:root:current train perplexity4.865809440612793
INFO:root:current mean train loss 2008.4124959309895
INFO:root:current train perplexity4.85703182220459
INFO:root:current mean train loss 2006.9890815275787
INFO:root:current train perplexity4.852032661437988
INFO:root:current mean train loss 2004.0477336536753
INFO:root:current train perplexity4.84587287902832
INFO:root:current mean train loss 2002.216616599482
INFO:root:current train perplexity4.839469909667969
INFO:root:current mean train loss 2000.713617720694
INFO:root:current train perplexity4.837789058685303
INFO:root:current mean train loss 1998.8155300760588
INFO:root:current train perplexity4.835323333740234
INFO:root:current mean train loss 1998.708784272399
INFO:root:current train perplexity4.833623886108398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.35s/it]
INFO:root:final mean train loss: 1998.8678230289493
INFO:root:final train perplexity: 4.837641716003418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it]
INFO:root:eval mean loss: 1924.2374968833112
INFO:root:eval perplexity: 4.740821361541748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2386.112880409187
INFO:root:eval perplexity: 7.038736343383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:51:16<9:30:15, 589.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.403817983774
INFO:root:current train perplexity4.631889343261719
INFO:root:current mean train loss 1983.2313815766731
INFO:root:current train perplexity4.722255229949951
INFO:root:current mean train loss 1961.7081212863116
INFO:root:current train perplexity4.711406707763672
INFO:root:current mean train loss 1955.4211772882138
INFO:root:current train perplexity4.686542510986328
INFO:root:current mean train loss 1958.8875017143046
INFO:root:current train perplexity4.687500476837158
INFO:root:current mean train loss 1956.1080988536337
INFO:root:current train perplexity4.682713508605957
INFO:root:current mean train loss 1959.6066703360777
INFO:root:current train perplexity4.6931281089782715
INFO:root:current mean train loss 1960.8040437631487
INFO:root:current train perplexity4.695620536804199
INFO:root:current mean train loss 1959.223166002412
INFO:root:current train perplexity4.690453052520752
INFO:root:current mean train loss 1952.6685820430157
INFO:root:current train perplexity4.669675350189209
INFO:root:current mean train loss 1961.276546617604
INFO:root:current train perplexity4.698788166046143
INFO:root:current mean train loss 2078.510194351731
INFO:root:current train perplexity5.150970935821533
INFO:root:current mean train loss 2422.9338220909226
INFO:root:current train perplexity6.74921989440918
INFO:root:current mean train loss 2648.269885002886
INFO:root:current train perplexity8.06740951538086
INFO:root:current mean train loss 2743.1457793390337
INFO:root:current train perplexity8.698877334594727
INFO:root:current mean train loss 2740.3613180398784
INFO:root:current train perplexity8.677764892578125
INFO:root:current mean train loss 2709.977679068748
INFO:root:current train perplexity8.471885681152344
INFO:root:current mean train loss 2674.709284669394
INFO:root:current train perplexity8.236710548400879
INFO:root:current mean train loss 2639.5188104763124
INFO:root:current train perplexity8.012153625488281
INFO:root:current mean train loss 2606.4052486150476
INFO:root:current train perplexity7.803123950958252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.73s/it]
INFO:root:final mean train loss: 2582.1765254910883
INFO:root:final train perplexity: 7.663430213928223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 1953.1930741113974
INFO:root:eval perplexity: 4.853149890899658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 2408.8865754688886
INFO:root:eval perplexity: 7.171060562133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [7:00:57<9:17:44, 587.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.670255533854
INFO:root:current train perplexity4.64613151550293
INFO:root:current mean train loss 1934.3007774939904
INFO:root:current train perplexity4.592561721801758
INFO:root:current mean train loss 1935.6120467476223
INFO:root:current train perplexity4.584856986999512
INFO:root:current mean train loss 1934.7445234818892
INFO:root:current train perplexity4.585608959197998
INFO:root:current mean train loss 1930.9512195675873
INFO:root:current train perplexity4.570686340332031
INFO:root:current mean train loss 1929.1884597490418
INFO:root:current train perplexity4.563849449157715
INFO:root:current mean train loss 1924.5316278366815
INFO:root:current train perplexity4.549242973327637
INFO:root:current mean train loss 1922.8099099355202
INFO:root:current train perplexity4.548829555511475
INFO:root:current mean train loss 1936.3408219302994
INFO:root:current train perplexity4.597973823547363
INFO:root:current mean train loss 2009.9972817697833
INFO:root:current train perplexity4.875763416290283
INFO:root:current mean train loss 2155.2663189045434
INFO:root:current train perplexity5.477340221405029
INFO:root:current mean train loss 2297.6237294965085
INFO:root:current train perplexity6.127283096313477
INFO:root:current mean train loss 2420.148168052115
INFO:root:current train perplexity6.746242046356201
INFO:root:current mean train loss 2526.7311768495947
INFO:root:current train perplexity7.346873760223389
INFO:root:current mean train loss 2618.438131265707
INFO:root:current train perplexity7.891997814178467
INFO:root:current mean train loss 2752.8089886035796
INFO:root:current train perplexity8.758180618286133
INFO:root:current mean train loss 2836.2266247333923
INFO:root:current train perplexity9.358004570007324
INFO:root:current mean train loss 2924.39700010443
INFO:root:current train perplexity10.01705265045166
INFO:root:current mean train loss 3005.6006209576717
INFO:root:current train perplexity10.676250457763672
INFO:root:current mean train loss 3054.0512087490893
INFO:root:current train perplexity11.104697227478027

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.74s/it]
INFO:root:final mean train loss: 3076.1053821373275
INFO:root:final train perplexity: 11.313557624816895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2607.2296419617132
INFO:root:eval perplexity: 8.236491203308105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 3033.568806100399
INFO:root:eval perplexity: 11.952444076538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [7:10:52<9:10:11, 589.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4070.009957820811
INFO:root:current train perplexity25.242551803588867
INFO:root:current mean train loss 4113.499928584715
INFO:root:current train perplexity25.557695388793945
INFO:root:current mean train loss 4127.50882761102
INFO:root:current train perplexity25.913637161254883
INFO:root:current mean train loss 4146.634030388824
INFO:root:current train perplexity26.4149227142334
INFO:root:current mean train loss 4167.58190617572
INFO:root:current train perplexity26.836278915405273
INFO:root:current mean train loss 4190.660917683101
INFO:root:current train perplexity27.46938705444336
INFO:root:current mean train loss 4233.708814193514
INFO:root:current train perplexity28.281251907348633
INFO:root:current mean train loss 4291.971176698983
INFO:root:current train perplexity29.619007110595703
INFO:root:current mean train loss 4381.058738159036
INFO:root:current train perplexity31.760498046875
INFO:root:current mean train loss 4458.661783510428
INFO:root:current train perplexity33.816768646240234
INFO:root:current mean train loss 4563.787678570096
INFO:root:current train perplexity36.7196159362793
INFO:root:current mean train loss 4684.249373152449
INFO:root:current train perplexity40.30405807495117
INFO:root:current mean train loss 4814.158333711846
INFO:root:current train perplexity44.646629333496094
INFO:root:current mean train loss 4949.059066262702
INFO:root:current train perplexity49.59994888305664
INFO:root:current mean train loss 5076.797629018281
INFO:root:current train perplexity54.745025634765625
INFO:root:current mean train loss 5206.403091953428
INFO:root:current train perplexity60.620426177978516
INFO:root:current mean train loss 5313.346336823343
INFO:root:current train perplexity65.98011779785156
INFO:root:current mean train loss 5427.769370958474
INFO:root:current train perplexity72.07447052001953
INFO:root:current mean train loss 5529.9198778583095
INFO:root:current train perplexity78.19425201416016
INFO:root:current mean train loss 5632.366529310919
INFO:root:current train perplexity84.79443359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.35s/it]
INFO:root:final mean train loss: 5664.386197596563
INFO:root:final train perplexity: 87.11901092529297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 7642.696723667443
INFO:root:eval perplexity: 483.4580078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it]
INFO:root:eval mean loss: 7998.372366397939
INFO:root:eval perplexity: 693.1793823242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [7:20:27<8:56:30, 585.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7608.964797973633
INFO:root:current train perplexity388.5448303222656
INFO:root:current mean train loss 7675.0370498285065
INFO:root:current train perplexity410.2825927734375
INFO:root:current mean train loss 7673.7306426077175
INFO:root:current train perplexity418.94244384765625
INFO:root:current mean train loss 7681.907879839887
INFO:root:current train perplexity422.8843078613281
INFO:root:current mean train loss 7686.240400643184
INFO:root:current train perplexity430.0801086425781
INFO:root:current mean train loss 7700.811641179078
INFO:root:current train perplexity433.8552551269531
INFO:root:current mean train loss 7704.824457007719
INFO:root:current train perplexity431.5614929199219
INFO:root:current mean train loss 7690.55871070742
INFO:root:current train perplexity431.29302978515625
INFO:root:current mean train loss 7692.5139567057295
INFO:root:current train perplexity429.2392883300781
INFO:root:current mean train loss 7681.478077488816
INFO:root:current train perplexity423.9826965332031
INFO:root:current mean train loss 7655.3512724682805
INFO:root:current train perplexity416.7467956542969
INFO:root:current mean train loss 7633.644562711421
INFO:root:current train perplexity409.3124084472656
INFO:root:current mean train loss 7601.3418613868425
INFO:root:current train perplexity399.938232421875
INFO:root:current mean train loss 7568.893938081355
INFO:root:current train perplexity391.2642822265625
INFO:root:current mean train loss 7543.120785238964
INFO:root:current train perplexity384.20770263671875
INFO:root:current mean train loss 7507.209186992986
INFO:root:current train perplexity374.0524597167969
INFO:root:current mean train loss 7463.050783597506
INFO:root:current train perplexity360.674072265625
INFO:root:current mean train loss 7398.000917880173
INFO:root:current train perplexity341.88226318359375
INFO:root:current mean train loss 7313.9856389254455
INFO:root:current train perplexity319.5425720214844
INFO:root:current mean train loss 7220.35045218225
INFO:root:current train perplexity296.7755126953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.77s/it]
INFO:root:final mean train loss: 7200.012519871052
INFO:root:final train perplexity: 292.47021484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.36s/it]
INFO:root:eval mean loss: 4416.853346804355
INFO:root:eval perplexity: 35.59095764160156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.59s/it]
INFO:root:eval mean loss: 4711.757835875166
INFO:root:eval perplexity: 47.153358459472656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [7:30:15<8:47:29, 586.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5006.912796585648
INFO:root:current train perplexity52.08435821533203
INFO:root:current mean train loss 4849.183191794717
INFO:root:current train perplexity45.81035232543945
INFO:root:current mean train loss 4748.649516584186
INFO:root:current train perplexity42.741153717041016
INFO:root:current mean train loss 4898.593803826279
INFO:root:current train perplexity47.75851058959961
INFO:root:current mean train loss 4970.951906834719
INFO:root:current train perplexity51.0833854675293
INFO:root:current mean train loss 5019.470986344933
INFO:root:current train perplexity52.71824264526367
INFO:root:current mean train loss 5036.490460231966
INFO:root:current train perplexity53.32904815673828
INFO:root:current mean train loss 4961.2207018746
INFO:root:current train perplexity50.275020599365234
INFO:root:current mean train loss 4885.536637720807
INFO:root:current train perplexity47.523380279541016
INFO:root:current mean train loss 4811.902341261309
INFO:root:current train perplexity44.76449966430664
INFO:root:current mean train loss 4759.257170416931
INFO:root:current train perplexity42.92665100097656
INFO:root:current mean train loss 4663.069043630266
INFO:root:current train perplexity39.73451614379883
INFO:root:current mean train loss 4569.689137324051
INFO:root:current train perplexity36.843685150146484
INFO:root:current mean train loss 4467.14663817829
INFO:root:current train perplexity33.906890869140625
INFO:root:current mean train loss 4371.741289570234
INFO:root:current train perplexity31.38098907470703
INFO:root:current mean train loss 4288.398042335004
INFO:root:current train perplexity29.349775314331055
INFO:root:current mean train loss 4211.08514712922
INFO:root:current train perplexity27.592302322387695
INFO:root:current mean train loss 4143.727527273565
INFO:root:current train perplexity26.162368774414062
INFO:root:current mean train loss 4079.5294705380284
INFO:root:current train perplexity24.934463500976562
INFO:root:current mean train loss 4023.1676127064534
INFO:root:current train perplexity23.85861587524414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.66s/it]
INFO:root:final mean train loss: 4021.6162889935545
INFO:root:final train perplexity: 23.847713470458984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 2500.1444641546154
INFO:root:eval perplexity: 7.553190231323242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 2893.9917979138963
INFO:root:eval perplexity: 10.663065910339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [7:40:01<8:37:35, 585.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3033.494875538106
INFO:root:current train perplexity10.814506530761719
INFO:root:current mean train loss 2978.885504212042
INFO:root:current train perplexity10.45189380645752
INFO:root:current mean train loss 2989.2613533583262
INFO:root:current train perplexity10.557777404785156
INFO:root:current mean train loss 2974.890163709171
INFO:root:current train perplexity10.494307518005371
INFO:root:current mean train loss 2992.1384022417797
INFO:root:current train perplexity10.651556015014648
INFO:root:current mean train loss 3002.806132338916
INFO:root:current train perplexity10.727823257446289
INFO:root:current mean train loss 3012.973475765021
INFO:root:current train perplexity10.79963207244873
INFO:root:current mean train loss 3023.209057494811
INFO:root:current train perplexity10.883001327514648
INFO:root:current mean train loss 3030.8298421405207
INFO:root:current train perplexity10.931119918823242
INFO:root:current mean train loss 3034.372632716605
INFO:root:current train perplexity10.937253952026367
INFO:root:current mean train loss 3036.164064723503
INFO:root:current train perplexity10.947624206542969
INFO:root:current mean train loss 3041.296440315565
INFO:root:current train perplexity10.970638275146484
INFO:root:current mean train loss 3041.260219109628
INFO:root:current train perplexity10.960851669311523
INFO:root:current mean train loss 3046.3730257440875
INFO:root:current train perplexity11.019351959228516
INFO:root:current mean train loss 3072.735699356955
INFO:root:current train perplexity11.260396003723145
INFO:root:current mean train loss 3084.8992571586064
INFO:root:current train perplexity11.370203018188477
INFO:root:current mean train loss 3119.0009015086684
INFO:root:current train perplexity11.69359016418457
INFO:root:current mean train loss 3150.2753589871995
INFO:root:current train perplexity11.97125244140625
INFO:root:current mean train loss 3165.9858592669502
INFO:root:current train perplexity12.13294792175293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.12s/it]
INFO:root:final mean train loss: 3168.0901436009794
INFO:root:final train perplexity: 12.16479778289795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2641.7713159872287
INFO:root:eval perplexity: 8.469823837280273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 3009.0784141594636
INFO:root:eval perplexity: 11.715432167053223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:49:51<8:28:57, 587.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.938411458333
INFO:root:current train perplexity14.936488151550293
INFO:root:current mean train loss 3323.2002611243206
INFO:root:current train perplexity13.623215675354004
INFO:root:current mean train loss 3260.7085051780523
INFO:root:current train perplexity13.144658088684082
INFO:root:current mean train loss 3277.3291674417164
INFO:root:current train perplexity13.26372241973877
INFO:root:current mean train loss 3321.4372617422814
INFO:root:current train perplexity13.709603309631348
INFO:root:current mean train loss 3314.9309029884707
INFO:root:current train perplexity13.65151309967041
INFO:root:current mean train loss 3302.9844996506604
INFO:root:current train perplexity13.529157638549805
INFO:root:current mean train loss 3296.9462887210448
INFO:root:current train perplexity13.458534240722656
INFO:root:current mean train loss 3294.896138084739
INFO:root:current train perplexity13.472326278686523
INFO:root:current mean train loss 3304.864852821892
INFO:root:current train perplexity13.58411693572998
INFO:root:current mean train loss 3309.4236542199046
INFO:root:current train perplexity13.648909568786621
INFO:root:current mean train loss 3320.9559204648963
INFO:root:current train perplexity13.756083488464355
INFO:root:current mean train loss 3340.1586859809026
INFO:root:current train perplexity13.950474739074707
INFO:root:current mean train loss 3355.3794984998813
INFO:root:current train perplexity14.122499465942383
INFO:root:current mean train loss 3364.8787649417513
INFO:root:current train perplexity14.209640502929688
INFO:root:current mean train loss 3375.025688428218
INFO:root:current train perplexity14.331622123718262
INFO:root:current mean train loss 3384.5199093278347
INFO:root:current train perplexity14.43712329864502
INFO:root:current mean train loss 3395.108165400647
INFO:root:current train perplexity14.556985855102539
INFO:root:current mean train loss 3408.7370136019285
INFO:root:current train perplexity14.719711303710938
INFO:root:current mean train loss 3429.2011094055974
INFO:root:current train perplexity14.938002586364746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.59s/it]
INFO:root:final mean train loss: 3439.536219055822
INFO:root:final train perplexity: 15.068782806396484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2840.733500595634
INFO:root:eval perplexity: 9.948471069335938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it]
INFO:root:eval mean loss: 3180.2104669665614
INFO:root:eval perplexity: 13.47536849975586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [7:59:46<8:21:08, 589.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3697.9865951538086
INFO:root:current train perplexity18.905071258544922
INFO:root:current mean train loss 3652.0742205995502
INFO:root:current train perplexity17.745454788208008
INFO:root:current mean train loss 3696.5659926842
INFO:root:current train perplexity18.256317138671875
INFO:root:current mean train loss 3727.5645597526827
INFO:root:current train perplexity18.750587463378906
INFO:root:current mean train loss 3756.0784103958695
INFO:root:current train perplexity19.161075592041016
INFO:root:current mean train loss 3779.321142210996
INFO:root:current train perplexity19.441598892211914
INFO:root:current mean train loss 3792.51758816876
INFO:root:current train perplexity19.659711837768555
INFO:root:current mean train loss 3796.9964739690063
INFO:root:current train perplexity19.7549991607666
INFO:root:current mean train loss 3798.4972566457895
INFO:root:current train perplexity19.800992965698242
INFO:root:current mean train loss 3797.961379153534
INFO:root:current train perplexity19.804903030395508
INFO:root:current mean train loss 3802.4977800236193
INFO:root:current train perplexity19.922027587890625
INFO:root:current mean train loss 3810.288228712318
INFO:root:current train perplexity20.07274627685547
INFO:root:current mean train loss 3817.1142159994547
INFO:root:current train perplexity20.184404373168945
INFO:root:current mean train loss 3824.519500824066
INFO:root:current train perplexity20.33095359802246
INFO:root:current mean train loss 3841.822296142578
INFO:root:current train perplexity20.622848510742188
INFO:root:current mean train loss 3861.638710759016
INFO:root:current train perplexity20.95559310913086
INFO:root:current mean train loss 3882.3888705384497
INFO:root:current train perplexity21.36295509338379
INFO:root:current mean train loss 3912.158753428118
INFO:root:current train perplexity21.858612060546875
INFO:root:current mean train loss 3938.6999009311457
INFO:root:current train perplexity22.310964584350586
INFO:root:current mean train loss 3959.585737587749
INFO:root:current train perplexity22.68220329284668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:44<00:00, 524.16s/it]
INFO:root:final mean train loss: 3968.0728456898282
INFO:root:final train perplexity: 22.861648559570312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it]
INFO:root:eval mean loss: 3015.169417144559
INFO:root:eval perplexity: 11.455750465393066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 3366.641640953984
INFO:root:eval perplexity: 15.694842338562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [8:09:49<8:14:41, 593.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4347.5664261798465
INFO:root:current train perplexity31.426698684692383
INFO:root:current mean train loss 4353.536183606858
INFO:root:current train perplexity30.730819702148438
INFO:root:current mean train loss 4323.9805069888935
INFO:root:current train perplexity30.127910614013672
INFO:root:current mean train loss 4329.444565387715
INFO:root:current train perplexity30.448837280273438
INFO:root:current mean train loss 4356.00666955213
INFO:root:current train perplexity31.087238311767578
INFO:root:current mean train loss 4343.235648622495
INFO:root:current train perplexity30.844520568847656
INFO:root:current mean train loss 4362.239813053737
INFO:root:current train perplexity31.191436767578125
INFO:root:current mean train loss 4348.689815913405
INFO:root:current train perplexity30.806598663330078
INFO:root:current mean train loss 4348.38429862338
INFO:root:current train perplexity30.769302368164062
INFO:root:current mean train loss 4361.299573409921
INFO:root:current train perplexity31.12702751159668
INFO:root:current mean train loss 4406.82978929896
INFO:root:current train perplexity32.33338165283203
INFO:root:current mean train loss 4459.046375457259
INFO:root:current train perplexity33.7080078125
INFO:root:current mean train loss 4544.300400281162
INFO:root:current train perplexity36.00845718383789
INFO:root:current mean train loss 4618.221286420207
INFO:root:current train perplexity38.22637176513672
INFO:root:current mean train loss 4639.27256843351
INFO:root:current train perplexity38.88198471069336
INFO:root:current mean train loss 4593.659122316817
INFO:root:current train perplexity37.5251350402832
INFO:root:current mean train loss 4547.889579444455
INFO:root:current train perplexity36.18598556518555
INFO:root:current mean train loss 4511.91072465516
INFO:root:current train perplexity35.15034484863281
INFO:root:current mean train loss 4481.392487017898
INFO:root:current train perplexity34.27682876586914
INFO:root:current mean train loss 4452.678403037215
INFO:root:current train perplexity33.48646545410156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 514.00s/it]
INFO:root:final mean train loss: 4439.07835430505
INFO:root:final train perplexity: 33.14606857299805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 2831.3707015666555
INFO:root:eval perplexity: 9.873418807983398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.83s/it]
INFO:root:eval mean loss: 3207.1469895383143
INFO:root:eval perplexity: 13.775516510009766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [8:19:42<8:04:41, 593.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3620.9518488103695
INFO:root:current train perplexity17.60198974609375
INFO:root:current mean train loss 3976.2130126953125
INFO:root:current train perplexity22.850582122802734
INFO:root:current mean train loss 4042.6669306934327
INFO:root:current train perplexity24.218975067138672
INFO:root:current mean train loss 4007.711884712261
INFO:root:current train perplexity23.65498161315918
INFO:root:current mean train loss 4034.9747120607562
INFO:root:current train perplexity23.95518684387207
INFO:root:current mean train loss 4056.3410109664865
INFO:root:current train perplexity24.385345458984375
INFO:root:current mean train loss 4082.3024000563064
INFO:root:current train perplexity24.959741592407227
INFO:root:current mean train loss 4116.357080843057
INFO:root:current train perplexity25.591218948364258
INFO:root:current mean train loss 4141.95904611495
INFO:root:current train perplexity26.111961364746094
INFO:root:current mean train loss 4162.586900162154
INFO:root:current train perplexity26.543710708618164
INFO:root:current mean train loss 4185.335861234683
INFO:root:current train perplexity26.932891845703125
INFO:root:current mean train loss 4199.331415035713
INFO:root:current train perplexity27.26300811767578
INFO:root:current mean train loss 4210.2579588686685
INFO:root:current train perplexity27.52593231201172
INFO:root:current mean train loss 4224.961083877139
INFO:root:current train perplexity27.843647003173828
INFO:root:current mean train loss 4235.719537878102
INFO:root:current train perplexity28.08313751220703
INFO:root:current mean train loss 4244.118762721504
INFO:root:current train perplexity28.26565933227539
INFO:root:current mean train loss 4247.573740433673
INFO:root:current train perplexity28.418914794921875
INFO:root:current mean train loss 4252.027340708611
INFO:root:current train perplexity28.489721298217773
INFO:root:current mean train loss 4253.463979445087
INFO:root:current train perplexity28.539409637451172
INFO:root:current mean train loss 4248.485286739811
INFO:root:current train perplexity28.495351791381836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.61s/it]
INFO:root:final mean train loss: 4246.256860129953
INFO:root:final train perplexity: 28.470083236694336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.60s/it]
INFO:root:eval mean loss: 2941.7820992977063
INFO:root:eval perplexity: 10.795620918273926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 3311.712788466866
INFO:root:eval perplexity: 15.00539493560791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [8:29:34<7:54:27, 593.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4059.2757024190514
INFO:root:current train perplexity25.384559631347656
INFO:root:current mean train loss 4027.1944720158813
INFO:root:current train perplexity24.4703426361084
INFO:root:current mean train loss 3963.7873207334915
INFO:root:current train perplexity23.146940231323242
INFO:root:current mean train loss 3916.2950538256773
INFO:root:current train perplexity22.10087776184082
INFO:root:current mean train loss 3864.044945631955
INFO:root:current train perplexity21.208694458007812
INFO:root:current mean train loss 3828.9285564128163
INFO:root:current train perplexity20.553043365478516
INFO:root:current mean train loss 3798.1036546743458
INFO:root:current train perplexity20.065879821777344
INFO:root:current mean train loss 3780.2986606875597
INFO:root:current train perplexity19.6990909576416
INFO:root:current mean train loss 3764.7673630158197
INFO:root:current train perplexity19.452909469604492
INFO:root:current mean train loss 3754.092445101888
INFO:root:current train perplexity19.291730880737305
INFO:root:current mean train loss 3749.0092604365045
INFO:root:current train perplexity19.19253158569336
INFO:root:current mean train loss 3741.054836914888
INFO:root:current train perplexity19.07423210144043
INFO:root:current mean train loss 3737.287498706036
INFO:root:current train perplexity18.995677947998047
INFO:root:current mean train loss 3735.1563117854075
INFO:root:current train perplexity18.99143409729004
INFO:root:current mean train loss 3734.9137730871753
INFO:root:current train perplexity18.983905792236328
INFO:root:current mean train loss 3733.1064905008784
INFO:root:current train perplexity18.952499389648438
INFO:root:current mean train loss 3730.7439138919062
INFO:root:current train perplexity18.93097496032715
INFO:root:current mean train loss 3729.3404434897293
INFO:root:current train perplexity18.90308380126953
INFO:root:current mean train loss 3730.196863175451
INFO:root:current train perplexity18.896968841552734
INFO:root:current mean train loss 3726.892345126446
INFO:root:current train perplexity18.901691436767578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.51s/it]
INFO:root:final mean train loss: 3726.892345126446
INFO:root:final train perplexity: 18.901691436767578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 2842.91264786957
INFO:root:eval perplexity: 9.966014862060547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 3217.384898950022
INFO:root:eval perplexity: 13.89134693145752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [8:39:32<7:45:32, 594.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.7261938476563
INFO:root:current train perplexity18.82347297668457
INFO:root:current mean train loss 3698.9561865234373
INFO:root:current train perplexity18.772375106811523
INFO:root:current mean train loss 3718.501417643229
INFO:root:current train perplexity18.89987564086914
INFO:root:current mean train loss 3720.5580480957033
INFO:root:current train perplexity19.02140235900879
INFO:root:current mean train loss 3724.4604877929687
INFO:root:current train perplexity19.0082950592041
INFO:root:current mean train loss 3731.521307779948
INFO:root:current train perplexity19.008014678955078
INFO:root:current mean train loss 3729.420438406808
INFO:root:current train perplexity18.96683692932129
INFO:root:current mean train loss 3729.115718688965
INFO:root:current train perplexity18.96843719482422
INFO:root:current mean train loss 3729.4804440646703
INFO:root:current train perplexity18.96161460876465
INFO:root:current mean train loss 3729.9811684570313
INFO:root:current train perplexity18.948680877685547
INFO:root:current mean train loss 3728.959530806108
INFO:root:current train perplexity18.95357322692871
INFO:root:current mean train loss 3730.3990887451173
INFO:root:current train perplexity18.960308074951172
INFO:root:current mean train loss 3726.8362751652644
INFO:root:current train perplexity18.906225204467773
INFO:root:current mean train loss 3725.7214120047433
INFO:root:current train perplexity18.8798885345459
INFO:root:current mean train loss 3725.2077221679688
INFO:root:current train perplexity18.878780364990234
INFO:root:current mean train loss 3726.3517359924317
INFO:root:current train perplexity18.894189834594727
INFO:root:current mean train loss 3729.1655985753678
INFO:root:current train perplexity18.906654357910156
INFO:root:current mean train loss 3732.3400073242187
INFO:root:current train perplexity18.947410583496094
INFO:root:current mean train loss 3738.449801603618
INFO:root:current train perplexity19.0389461517334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.84s/it]
INFO:root:final mean train loss: 3740.2535389925697
INFO:root:final train perplexity: 19.101919174194336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 2877.4565637466753
INFO:root:eval perplexity: 10.24836254119873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 3240.076379221382
INFO:root:eval perplexity: 14.15153980255127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [8:49:21<7:34:33, 592.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.611127068015
INFO:root:current train perplexity20.459213256835938
INFO:root:current mean train loss 3788.516390808627
INFO:root:current train perplexity19.664474487304688
INFO:root:current mean train loss 3750.1377875684043
INFO:root:current train perplexity19.119155883789062
INFO:root:current mean train loss 3707.707357797713
INFO:root:current train perplexity18.570354461669922
INFO:root:current mean train loss 3674.2327913060176
INFO:root:current train perplexity18.1578311920166
INFO:root:current mean train loss 3646.146507041828
INFO:root:current train perplexity17.690914154052734
INFO:root:current mean train loss 3609.61832708671
INFO:root:current train perplexity17.143653869628906
INFO:root:current mean train loss 3577.557120393676
INFO:root:current train perplexity16.717628479003906
INFO:root:current mean train loss 3554.6386892068926
INFO:root:current train perplexity16.40379524230957
INFO:root:current mean train loss 3534.855832697911
INFO:root:current train perplexity16.14375877380371
INFO:root:current mean train loss 3515.5755462796524
INFO:root:current train perplexity15.935900688171387
INFO:root:current mean train loss 3498.4559259508587
INFO:root:current train perplexity15.722755432128906
INFO:root:current mean train loss 3480.71506762916
INFO:root:current train perplexity15.52010440826416
INFO:root:current mean train loss 3463.4901574438236
INFO:root:current train perplexity15.317307472229004
INFO:root:current mean train loss 3443.7117453866554
INFO:root:current train perplexity15.087048530578613
INFO:root:current mean train loss 3423.647702825014
INFO:root:current train perplexity14.860328674316406
INFO:root:current mean train loss 3403.267589297793
INFO:root:current train perplexity14.642251968383789
INFO:root:current mean train loss 3389.6941923253676
INFO:root:current train perplexity14.494226455688477
INFO:root:current mean train loss 3380.608220001204
INFO:root:current train perplexity14.391861915588379
INFO:root:current mean train loss 3374.1278439772022
INFO:root:current train perplexity14.302051544189453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.17s/it]
INFO:root:final mean train loss: 3367.781099428147
INFO:root:final train perplexity: 14.239712715148926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it]
INFO:root:eval mean loss: 2605.611369680851
INFO:root:eval perplexity: 8.225716590881348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 3015.2381505222183
INFO:root:eval perplexity: 11.774600982666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:59:19<7:25:46, 594.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3117.4810072954965
INFO:root:current train perplexity11.952125549316406
INFO:root:current mean train loss 3123.1452418085355
INFO:root:current train perplexity11.863906860351562
INFO:root:current mean train loss 3105.9263853415464
INFO:root:current train perplexity11.587932586669922
INFO:root:current mean train loss 3093.0459408331776
INFO:root:current train perplexity11.424062728881836
INFO:root:current mean train loss 3071.5816042851743
INFO:root:current train perplexity11.272687911987305
INFO:root:current mean train loss 3063.6002512728232
INFO:root:current train perplexity11.174994468688965
INFO:root:current mean train loss 3053.430815783961
INFO:root:current train perplexity11.110613822937012
INFO:root:current mean train loss 3047.0848804442694
INFO:root:current train perplexity11.070371627807617
INFO:root:current mean train loss 3045.9412601754534
INFO:root:current train perplexity11.056877136230469
INFO:root:current mean train loss 3044.1186489456472
INFO:root:current train perplexity11.031524658203125
INFO:root:current mean train loss 3036.070531612669
INFO:root:current train perplexity10.962911605834961
INFO:root:current mean train loss 3033.983717284295
INFO:root:current train perplexity10.938667297363281
INFO:root:current mean train loss 3035.7540955875834
INFO:root:current train perplexity10.958450317382812
INFO:root:current mean train loss 3040.27827089873
INFO:root:current train perplexity10.997664451599121
INFO:root:current mean train loss 3043.15165440175
INFO:root:current train perplexity11.021926879882812
INFO:root:current mean train loss 3043.046608896268
INFO:root:current train perplexity11.01526165008545
INFO:root:current mean train loss 3038.5317577049227
INFO:root:current train perplexity10.9801025390625
INFO:root:current mean train loss 3035.4213743286837
INFO:root:current train perplexity10.947550773620605
INFO:root:current mean train loss 3028.7895640931706
INFO:root:current train perplexity10.902811050415039
INFO:root:current mean train loss 3025.7353383077093
INFO:root:current train perplexity10.875883102416992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.76s/it]
INFO:root:final mean train loss: 3024.74599316357
INFO:root:final train perplexity: 10.864457130432129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 2499.626460947889
INFO:root:eval perplexity: 7.550026893615723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 2912.8840674001276
INFO:root:eval perplexity: 10.829097747802734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [9:09:11<7:15:17, 593.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2975.8799067478553
INFO:root:current train perplexity10.524209022521973
INFO:root:current mean train loss 2953.6815031948468
INFO:root:current train perplexity10.392694473266602
INFO:root:current mean train loss 2962.1966392243526
INFO:root:current train perplexity10.361233711242676
INFO:root:current mean train loss 2985.2681394397705
INFO:root:current train perplexity10.489811897277832
INFO:root:current mean train loss 3019.0936298243487
INFO:root:current train perplexity10.770909309387207
INFO:root:current mean train loss 3023.9114775337453
INFO:root:current train perplexity10.822216033935547
INFO:root:current mean train loss 3031.1524813838087
INFO:root:current train perplexity10.879262924194336
INFO:root:current mean train loss 3032.6300603102113
INFO:root:current train perplexity10.88509464263916
INFO:root:current mean train loss 3029.8403914168075
INFO:root:current train perplexity10.88101863861084
INFO:root:current mean train loss 3025.993048281825
INFO:root:current train perplexity10.851789474487305
INFO:root:current mean train loss 3022.643819269966
INFO:root:current train perplexity10.828402519226074
INFO:root:current mean train loss 3022.5516417873723
INFO:root:current train perplexity10.810227394104004
INFO:root:current mean train loss 3016.3019393079285
INFO:root:current train perplexity10.763967514038086
INFO:root:current mean train loss 3014.982231044134
INFO:root:current train perplexity10.752409934997559
INFO:root:current mean train loss 3011.508908524832
INFO:root:current train perplexity10.717021942138672
INFO:root:current mean train loss 3009.1254827719517
INFO:root:current train perplexity10.692245483398438
INFO:root:current mean train loss 3005.760937973198
INFO:root:current train perplexity10.66821002960205
INFO:root:current mean train loss 3003.1032136212343
INFO:root:current train perplexity10.648808479309082
INFO:root:current mean train loss 2997.1648011210154
INFO:root:current train perplexity10.610742568969727
INFO:root:current mean train loss 2991.740082584852
INFO:root:current train perplexity10.578274726867676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.46s/it]
INFO:root:final mean train loss: 2989.294733875638
INFO:root:final train perplexity: 10.564903259277344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 2439.1613938351893
INFO:root:eval perplexity: 7.189708709716797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.67s/it]
INFO:root:eval mean loss: 2856.372306661403
INFO:root:eval perplexity: 10.340001106262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [9:18:47<7:01:41, 588.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2885.16603716682
INFO:root:current train perplexity9.766536712646484
INFO:root:current mean train loss 2871.5598914736793
INFO:root:current train perplexity9.593355178833008
INFO:root:current mean train loss 2880.107724317864
INFO:root:current train perplexity9.709102630615234
INFO:root:current mean train loss 2873.9539901069975
INFO:root:current train perplexity9.668597221374512
INFO:root:current mean train loss 2865.435543744992
INFO:root:current train perplexity9.587118148803711
INFO:root:current mean train loss 2858.6100407989934
INFO:root:current train perplexity9.508136749267578
INFO:root:current mean train loss 2850.0164148022313
INFO:root:current train perplexity9.442431449890137
INFO:root:current mean train loss 2836.7124236424766
INFO:root:current train perplexity9.374980926513672
INFO:root:current mean train loss 2825.073713311402
INFO:root:current train perplexity9.293365478515625
INFO:root:current mean train loss 2818.402237569005
INFO:root:current train perplexity9.245183944702148
INFO:root:current mean train loss 2815.157588887304
INFO:root:current train perplexity9.20788860321045
INFO:root:current mean train loss 2807.950842452376
INFO:root:current train perplexity9.166688919067383
INFO:root:current mean train loss 2801.453636193501
INFO:root:current train perplexity9.11864948272705
INFO:root:current mean train loss 2795.024374800119
INFO:root:current train perplexity9.077176094055176
INFO:root:current mean train loss 2790.47797761756
INFO:root:current train perplexity9.039556503295898
INFO:root:current mean train loss 2786.2812199495274
INFO:root:current train perplexity9.004995346069336
INFO:root:current mean train loss 2783.4790406444376
INFO:root:current train perplexity8.982634544372559
INFO:root:current mean train loss 2781.513372084674
INFO:root:current train perplexity8.960897445678711
INFO:root:current mean train loss 2779.2363244655044
INFO:root:current train perplexity8.943374633789062
INFO:root:current mean train loss 2776.3498832888718
INFO:root:current train perplexity8.92374038696289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.80s/it]
INFO:root:final mean train loss: 2774.935339115391
INFO:root:final train perplexity: 8.921649932861328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it]
INFO:root:eval mean loss: 2340.0955944737643
INFO:root:eval perplexity: 6.636149883270264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 2762.7869448830897
INFO:root:eval perplexity: 9.578137397766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [9:28:41<6:53:02, 590.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2721.9818215762866
INFO:root:current train perplexity8.544943809509277
INFO:root:current mean train loss 2718.6139001794763
INFO:root:current train perplexity8.579042434692383
INFO:root:current mean train loss 2727.0778508771928
INFO:root:current train perplexity8.62503719329834
INFO:root:current mean train loss 2726.9011782163147
INFO:root:current train perplexity8.636507034301758
INFO:root:current mean train loss 2728.87077863241
INFO:root:current train perplexity8.633227348327637
INFO:root:current mean train loss 2732.1136773003473
INFO:root:current train perplexity8.644298553466797
INFO:root:current mean train loss 2734.55104178547
INFO:root:current train perplexity8.663566589355469
INFO:root:current mean train loss 2742.7193200761344
INFO:root:current train perplexity8.729068756103516
INFO:root:current mean train loss 2750.534174721928
INFO:root:current train perplexity8.757092475891113
INFO:root:current mean train loss 2753.0178787773634
INFO:root:current train perplexity8.77110481262207
INFO:root:current mean train loss 2753.922777532762
INFO:root:current train perplexity8.784993171691895
INFO:root:current mean train loss 2757.524304662777
INFO:root:current train perplexity8.8038969039917
INFO:root:current mean train loss 2760.265250334387
INFO:root:current train perplexity8.808804512023926
INFO:root:current mean train loss 2761.4323088828405
INFO:root:current train perplexity8.82300853729248
INFO:root:current mean train loss 2761.5189385719173
INFO:root:current train perplexity8.82597541809082
INFO:root:current mean train loss 2764.816382375049
INFO:root:current train perplexity8.842519760131836
INFO:root:current mean train loss 2766.50797028584
INFO:root:current train perplexity8.859845161437988
INFO:root:current mean train loss 2768.2438004694063
INFO:root:current train perplexity8.867237091064453
INFO:root:current mean train loss 2768.4872069017324
INFO:root:current train perplexity8.875151634216309

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.15s/it]
INFO:root:final mean train loss: 2768.7899367524346
INFO:root:final train perplexity: 8.878517150878906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.63s/it]
INFO:root:eval mean loss: 2361.7701416015625
INFO:root:eval perplexity: 6.753500938415527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2783.724971257203
INFO:root:eval perplexity: 9.743562698364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [9:38:30<6:42:57, 589.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2893.8992919921875
INFO:root:current train perplexity9.31928539276123
INFO:root:current mean train loss 2785.476710899203
INFO:root:current train perplexity9.026063919067383
INFO:root:current mean train loss 2781.5779666711787
INFO:root:current train perplexity8.998069763183594
INFO:root:current mean train loss 2776.515646827142
INFO:root:current train perplexity8.935174942016602
INFO:root:current mean train loss 2775.079913542638
INFO:root:current train perplexity8.921757698059082
INFO:root:current mean train loss 2772.7848279732634
INFO:root:current train perplexity8.918129920959473
INFO:root:current mean train loss 2776.939560189992
INFO:root:current train perplexity8.94564151763916
INFO:root:current mean train loss 2777.252490790821
INFO:root:current train perplexity8.944047927856445
INFO:root:current mean train loss 2777.248025565968
INFO:root:current train perplexity8.931292533874512
INFO:root:current mean train loss 2779.795138678371
INFO:root:current train perplexity8.942312240600586
INFO:root:current mean train loss 2781.76014816071
INFO:root:current train perplexity8.967544555664062
INFO:root:current mean train loss 2785.784840329373
INFO:root:current train perplexity8.980755805969238
INFO:root:current mean train loss 2786.7066477745425
INFO:root:current train perplexity8.982306480407715
INFO:root:current mean train loss 2784.745410831293
INFO:root:current train perplexity8.983872413635254
INFO:root:current mean train loss 2783.4786531935406
INFO:root:current train perplexity8.984345436096191
INFO:root:current mean train loss 2783.852671535609
INFO:root:current train perplexity8.986863136291504
INFO:root:current mean train loss 2783.966969541247
INFO:root:current train perplexity8.99652099609375
INFO:root:current mean train loss 2786.3155177617327
INFO:root:current train perplexity9.008673667907715
INFO:root:current mean train loss 2790.4686143813733
INFO:root:current train perplexity9.03249454498291
INFO:root:current mean train loss 2827.3959515528472
INFO:root:current train perplexity9.300087928771973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.95s/it]
INFO:root:final mean train loss: 2998.6286192647267
INFO:root:final train perplexity: 10.642963409423828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 6602.621072972074
INFO:root:eval perplexity: 208.47357177734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 6715.89682201629
INFO:root:eval perplexity: 242.85012817382812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [9:48:24<6:34:04, 591.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6741.482010690789
INFO:root:current train perplexity209.42279052734375
INFO:root:current mean train loss 6687.5343356092435
INFO:root:current train perplexity196.5685272216797
INFO:root:current mean train loss 6796.207020102026
INFO:root:current train perplexity210.03793334960938
INFO:root:current mean train loss 6806.457697088068
INFO:root:current train perplexity213.39295959472656
INFO:root:current mean train loss 6806.3214615341585
INFO:root:current train perplexity214.72938537597656
INFO:root:current mean train loss 6817.430421333092
INFO:root:current train perplexity215.50743103027344
INFO:root:current mean train loss 6806.947241960319
INFO:root:current train perplexity215.57464599609375
INFO:root:current mean train loss 6805.443011669854
INFO:root:current train perplexity215.3134002685547
INFO:root:current mean train loss 6802.632021949405
INFO:root:current train perplexity214.77096557617188
INFO:root:current mean train loss 6798.001461124524
INFO:root:current train perplexity214.1458282470703
INFO:root:current mean train loss 6795.297763873129
INFO:root:current train perplexity213.6279296875
INFO:root:current mean train loss 6792.399138286137
INFO:root:current train perplexity213.10986328125
INFO:root:current mean train loss 6792.8047716173605
INFO:root:current train perplexity212.8394317626953
INFO:root:current mean train loss 6788.704269999171
INFO:root:current train perplexity212.173583984375
INFO:root:current mean train loss 6787.6647847708555
INFO:root:current train perplexity211.6204833984375
INFO:root:current mean train loss 6785.555070988829
INFO:root:current train perplexity211.02777099609375
INFO:root:current mean train loss 6783.02453892256
INFO:root:current train perplexity210.5101776123047
INFO:root:current mean train loss 6778.680843581843
INFO:root:current train perplexity209.73098754882812
INFO:root:current mean train loss 6771.656461525907
INFO:root:current train perplexity208.84559631347656
INFO:root:current mean train loss 6769.400097758028
INFO:root:current train perplexity208.16424560546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.55s/it]
INFO:root:final mean train loss: 6766.895068039271
INFO:root:final train perplexity: 207.84249877929688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 6498.098942749889
INFO:root:eval perplexity: 191.57530212402344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 6602.550812416888
INFO:root:eval perplexity: 221.35049438476562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [9:58:17<6:24:37, 591.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6656.407497829861
INFO:root:current train perplexity192.77426147460938
INFO:root:current mean train loss 6659.017423741958
INFO:root:current train perplexity193.43917846679688
INFO:root:current mean train loss 6656.959830591234
INFO:root:current train perplexity193.60214233398438
INFO:root:current mean train loss 6676.863103957403
INFO:root:current train perplexity194.30418395996094
INFO:root:current mean train loss 6668.607625698824
INFO:root:current train perplexity193.988037109375
INFO:root:current mean train loss 6669.905032940765
INFO:root:current train perplexity193.7383575439453
INFO:root:current mean train loss 6670.001953892738
INFO:root:current train perplexity193.53494262695312
INFO:root:current mean train loss 6677.34260559082
INFO:root:current train perplexity193.6448974609375
INFO:root:current mean train loss 6673.335272830069
INFO:root:current train perplexity193.54510498046875
INFO:root:current mean train loss 6675.081400031718
INFO:root:current train perplexity193.45762634277344
INFO:root:current mean train loss 6674.212286400519
INFO:root:current train perplexity193.21949768066406
INFO:root:current mean train loss 6672.101406043684
INFO:root:current train perplexity193.0355987548828
INFO:root:current mean train loss 6667.61139054283
INFO:root:current train perplexity192.94163513183594
INFO:root:current mean train loss 6670.0845212650875
INFO:root:current train perplexity192.97991943359375
INFO:root:current mean train loss 6664.231184510468
INFO:root:current train perplexity192.6165008544922
INFO:root:current mean train loss 6664.087596257527
INFO:root:current train perplexity192.51467895507812
INFO:root:current mean train loss 6665.605440993181
INFO:root:current train perplexity192.4451904296875
INFO:root:current mean train loss 6666.187901369438
INFO:root:current train perplexity192.38510131835938
INFO:root:current mean train loss 6669.688993566177
INFO:root:current train perplexity192.39244079589844
INFO:root:current mean train loss 6671.025863773567
INFO:root:current train perplexity192.33079528808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.50s/it]
INFO:root:final mean train loss: 6667.893485988323
INFO:root:final train perplexity: 192.23178100585938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 6465.014300407247
INFO:root:eval perplexity: 186.517333984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 6569.503661243628
INFO:root:eval perplexity: 215.4482421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [10:08:05<6:13:52, 590.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6687.523428287146
INFO:root:current train perplexity191.221923828125
INFO:root:current mean train loss 6666.23078150531
INFO:root:current train perplexity191.35134887695312
INFO:root:current mean train loss 6673.053450392169
INFO:root:current train perplexity190.84844970703125
INFO:root:current mean train loss 6662.6092366767
INFO:root:current train perplexity190.07167053222656
INFO:root:current mean train loss 6660.5377291580435
INFO:root:current train perplexity189.85653686523438
INFO:root:current mean train loss 6656.376445418457
INFO:root:current train perplexity189.47100830078125
INFO:root:current mean train loss 6656.846821012395
INFO:root:current train perplexity188.8371124267578
INFO:root:current mean train loss 6661.608150730412
INFO:root:current train perplexity188.59405517578125
INFO:root:current mean train loss 6657.976402792534
INFO:root:current train perplexity188.37681579589844
INFO:root:current mean train loss 6649.546417460487
INFO:root:current train perplexity187.77828979492188
INFO:root:current mean train loss 6644.066664069919
INFO:root:current train perplexity187.31004333496094
INFO:root:current mean train loss 6639.411539360635
INFO:root:current train perplexity187.04620361328125
INFO:root:current mean train loss 6637.2379613147195
INFO:root:current train perplexity186.79226684570312
INFO:root:current mean train loss 6633.470961520695
INFO:root:current train perplexity186.5946502685547
INFO:root:current mean train loss 6629.711339752344
INFO:root:current train perplexity186.2201690673828
INFO:root:current mean train loss 6567.866485733258
INFO:root:current train perplexity177.96591186523438
INFO:root:current mean train loss 6430.397596669644
INFO:root:current train perplexity159.30609130859375
INFO:root:current mean train loss 6285.086182476246
INFO:root:current train perplexity142.10745239257812
INFO:root:current mean train loss 6141.485055115438
INFO:root:current train perplexity126.93584442138672
INFO:root:current mean train loss 6006.031834162386
INFO:root:current train perplexity114.01799011230469

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.57s/it]
INFO:root:final mean train loss: 5966.893528463621
INFO:root:final train perplexity: 110.59242248535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2658.547948093279
INFO:root:eval perplexity: 8.585522651672363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it]
INFO:root:eval mean loss: 3045.1339072369515
INFO:root:eval perplexity: 12.066030502319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [10:17:47<6:02:37, 588.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.0419154575893
INFO:root:current train perplexity16.109216690063477
INFO:root:current mean train loss 3634.429137465533
INFO:root:current train perplexity17.271543502807617
INFO:root:current mean train loss 3592.6746428313077
INFO:root:current train perplexity16.852441787719727
INFO:root:current mean train loss 3553.768309227196
INFO:root:current train perplexity16.490947723388672
INFO:root:current mean train loss 3530.8603468874667
INFO:root:current train perplexity16.171039581298828
INFO:root:current mean train loss 3512.33416041324
INFO:root:current train perplexity15.961122512817383
INFO:root:current mean train loss 3493.5323282270288
INFO:root:current train perplexity15.71975326538086
INFO:root:current mean train loss 3479.749224140118
INFO:root:current train perplexity15.543434143066406
INFO:root:current mean train loss 3459.5447313330637
INFO:root:current train perplexity15.328420639038086
INFO:root:current mean train loss 3441.9468916116302
INFO:root:current train perplexity15.111236572265625
INFO:root:current mean train loss 3423.3658267012265
INFO:root:current train perplexity14.920016288757324
INFO:root:current mean train loss 3406.5353252704326
INFO:root:current train perplexity14.733173370361328
INFO:root:current mean train loss 3388.1345987635336
INFO:root:current train perplexity14.529752731323242
INFO:root:current mean train loss 3373.756738459455
INFO:root:current train perplexity14.345580101013184
INFO:root:current mean train loss 3359.124902841996
INFO:root:current train perplexity14.168314933776855
INFO:root:current mean train loss 3344.518847967257
INFO:root:current train perplexity14.01028823852539
INFO:root:current mean train loss 3332.976954879304
INFO:root:current train perplexity13.87025260925293
INFO:root:current mean train loss 3320.766099901792
INFO:root:current train perplexity13.721928596496582
INFO:root:current mean train loss 3311.1368033506014
INFO:root:current train perplexity13.607345581054688
INFO:root:current mean train loss 3302.2020805242705
INFO:root:current train perplexity13.508913040161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.74s/it]
INFO:root:final mean train loss: 3299.801401943374
INFO:root:final train perplexity: 13.496383666992188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it]
INFO:root:eval mean loss: 2515.4554755028257
INFO:root:eval perplexity: 7.647301197052002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.00s/it]
INFO:root:eval mean loss: 2924.153090456699
INFO:root:eval perplexity: 10.929360389709473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [10:27:20<5:50:10, 583.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3160.9793266208694
INFO:root:current train perplexity11.901639938354492
INFO:root:current mean train loss 3142.005493816845
INFO:root:current train perplexity11.892486572265625
INFO:root:current mean train loss 3138.0694584331445
INFO:root:current train perplexity11.889974594116211
INFO:root:current mean train loss 3130.7369659187257
INFO:root:current train perplexity11.814850807189941
INFO:root:current mean train loss 3127.557033656314
INFO:root:current train perplexity11.814066886901855
INFO:root:current mean train loss 3136.209154899116
INFO:root:current train perplexity11.836444854736328
INFO:root:current mean train loss 3136.2804479251954
INFO:root:current train perplexity11.87402629852295
INFO:root:current mean train loss 3137.130189927136
INFO:root:current train perplexity11.890411376953125
INFO:root:current mean train loss 3134.8553278255354
INFO:root:current train perplexity11.865069389343262
INFO:root:current mean train loss 3128.605191958349
INFO:root:current train perplexity11.822599411010742
INFO:root:current mean train loss 3122.9073664885436
INFO:root:current train perplexity11.7789306640625
INFO:root:current mean train loss 3118.0961144824137
INFO:root:current train perplexity11.727256774902344
INFO:root:current mean train loss 3109.9109721387554
INFO:root:current train perplexity11.650101661682129
INFO:root:current mean train loss 3099.7413098610987
INFO:root:current train perplexity11.565095901489258
INFO:root:current mean train loss 3094.725903303894
INFO:root:current train perplexity11.504450798034668
INFO:root:current mean train loss 3088.8249507103615
INFO:root:current train perplexity11.445040702819824
INFO:root:current mean train loss 3081.2107295390765
INFO:root:current train perplexity11.365744590759277
INFO:root:current mean train loss 3071.9406790196995
INFO:root:current train perplexity11.2933988571167
INFO:root:current mean train loss 3065.1260343954937
INFO:root:current train perplexity11.219470024108887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.74s/it]
INFO:root:final mean train loss: 3058.4478215589347
INFO:root:final train perplexity: 11.157098770141602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.96s/it]
INFO:root:eval mean loss: 2435.149027939384
INFO:root:eval perplexity: 7.166415214538574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.06s/it]
INFO:root:eval mean loss: 2852.320629796238
INFO:root:eval perplexity: 10.305790901184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [10:36:51<5:38:04, 579.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2828.4430541992188
INFO:root:current train perplexity9.773002624511719
INFO:root:current mean train loss 2905.0632746769834
INFO:root:current train perplexity9.967616081237793
INFO:root:current mean train loss 2906.488917930453
INFO:root:current train perplexity9.98450756072998
INFO:root:current mean train loss 2899.170375623201
INFO:root:current train perplexity9.949257850646973
INFO:root:current mean train loss 2901.8899336711015
INFO:root:current train perplexity9.9363431930542
INFO:root:current mean train loss 2901.6651843843006
INFO:root:current train perplexity9.912419319152832
INFO:root:current mean train loss 2904.0341416921046
INFO:root:current train perplexity9.898962020874023
INFO:root:current mean train loss 2901.675070329146
INFO:root:current train perplexity9.8770751953125
INFO:root:current mean train loss 2899.629255456118
INFO:root:current train perplexity9.854334831237793
INFO:root:current mean train loss 2899.441667674917
INFO:root:current train perplexity9.854783058166504
INFO:root:current mean train loss 2895.542921818585
INFO:root:current train perplexity9.823266983032227
INFO:root:current mean train loss 2893.7225702258124
INFO:root:current train perplexity9.796634674072266
INFO:root:current mean train loss 2890.527012821844
INFO:root:current train perplexity9.764808654785156
INFO:root:current mean train loss 2887.2520139729318
INFO:root:current train perplexity9.739108085632324
INFO:root:current mean train loss 2885.373459688279
INFO:root:current train perplexity9.725329399108887
INFO:root:current mean train loss 2882.6852321218935
INFO:root:current train perplexity9.698966979980469
INFO:root:current mean train loss 2879.526907371464
INFO:root:current train perplexity9.675889015197754
INFO:root:current mean train loss 2876.3421751210385
INFO:root:current train perplexity9.655926704406738
INFO:root:current mean train loss 2873.639411469521
INFO:root:current train perplexity9.637941360473633
INFO:root:current mean train loss 2871.5737614992286
INFO:root:current train perplexity9.623197555541992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.92s/it]
INFO:root:final mean train loss: 2868.6768011496156
INFO:root:final train perplexity: 9.606223106384277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2385.689374774906
INFO:root:eval perplexity: 6.885415077209473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 2811.4980434120125
INFO:root:eval perplexity: 9.96740436553955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [10:46:34<5:29:04, 580.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2880.6520066034227
INFO:root:current train perplexity9.63115119934082
INFO:root:current mean train loss 2849.6868765334452
INFO:root:current train perplexity9.448169708251953
INFO:root:current mean train loss 2850.5042630709136
INFO:root:current train perplexity9.39189338684082
INFO:root:current mean train loss 2834.5076390917056
INFO:root:current train perplexity9.32854175567627
INFO:root:current mean train loss 2827.4835683500964
INFO:root:current train perplexity9.295222282409668
INFO:root:current mean train loss 2827.166193693018
INFO:root:current train perplexity9.299843788146973
INFO:root:current mean train loss 2828.433417622786
INFO:root:current train perplexity9.316244125366211
INFO:root:current mean train loss 2827.7075527154125
INFO:root:current train perplexity9.29662036895752
INFO:root:current mean train loss 2824.2004522400275
INFO:root:current train perplexity9.272173881530762
INFO:root:current mean train loss 2856.9238745143693
INFO:root:current train perplexity9.530839920043945
INFO:root:current mean train loss 3164.840002764217
INFO:root:current train perplexity12.169845581054688
INFO:root:current mean train loss 3471.231804009743
INFO:root:current train perplexity15.466915130615234
INFO:root:current mean train loss 3656.0138020433433
INFO:root:current train perplexity17.92108154296875
INFO:root:current mean train loss 3746.0110796597037
INFO:root:current train perplexity19.257076263427734
INFO:root:current mean train loss 3815.5415884362906
INFO:root:current train perplexity20.316980361938477
INFO:root:current mean train loss 3820.617355236327
INFO:root:current train perplexity20.338773727416992
INFO:root:current mean train loss 3807.0863937010813
INFO:root:current train perplexity20.10306167602539
INFO:root:current mean train loss 3789.2983963039296
INFO:root:current train perplexity19.841445922851562
INFO:root:current mean train loss 3773.1910868963655
INFO:root:current train perplexity19.595413208007812
INFO:root:current mean train loss 3761.8253748912107
INFO:root:current train perplexity19.416099548339844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.45s/it]
INFO:root:final mean train loss: 3754.363805296682
INFO:root:final train perplexity: 19.31568145751953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.26s/it]
INFO:root:eval mean loss: 2666.408320866578
INFO:root:eval perplexity: 8.640275955200195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.94s/it]
INFO:root:eval mean loss: 3062.951810363337
INFO:root:eval perplexity: 12.243143081665039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [10:56:05<5:17:47, 577.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3517.4284346731088
INFO:root:current train perplexity16.484785079956055
INFO:root:current mean train loss 3494.4425915704255
INFO:root:current train perplexity15.779935836791992
INFO:root:current mean train loss 3437.32890666032
INFO:root:current train perplexity15.038064956665039
INFO:root:current mean train loss 3397.142913276627
INFO:root:current train perplexity14.554734230041504
INFO:root:current mean train loss 3362.1050189292596
INFO:root:current train perplexity14.1856107711792
INFO:root:current mean train loss 3342.267899864225
INFO:root:current train perplexity13.946660041809082
INFO:root:current mean train loss 3320.3260111554664
INFO:root:current train perplexity13.710679054260254
INFO:root:current mean train loss 3301.069027949801
INFO:root:current train perplexity13.544965744018555
INFO:root:current mean train loss 3286.2753154599864
INFO:root:current train perplexity13.382866859436035
INFO:root:current mean train loss 3271.412885783832
INFO:root:current train perplexity13.219331741333008
INFO:root:current mean train loss 3258.2803294157934
INFO:root:current train perplexity13.090009689331055
INFO:root:current mean train loss 3248.736469717981
INFO:root:current train perplexity12.981821060180664
INFO:root:current mean train loss 3243.4324558732583
INFO:root:current train perplexity12.909825325012207
INFO:root:current mean train loss 3239.7814477940487
INFO:root:current train perplexity12.869606971740723
INFO:root:current mean train loss 3236.012779861896
INFO:root:current train perplexity12.819145202636719
INFO:root:current mean train loss 3233.29699421301
INFO:root:current train perplexity12.789375305175781
INFO:root:current mean train loss 3230.484825572106
INFO:root:current train perplexity12.760427474975586
INFO:root:current mean train loss 3225.5943385783767
INFO:root:current train perplexity12.725173950195312
INFO:root:current mean train loss 3220.812240451153
INFO:root:current train perplexity12.68536376953125
INFO:root:current mean train loss 3219.4545829150943
INFO:root:current train perplexity12.658771514892578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.56s/it]
INFO:root:final mean train loss: 3216.419259937496
INFO:root:final train perplexity: 12.637414932250977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2488.971953696393
INFO:root:eval perplexity: 7.485249996185303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2898.4978767557345
INFO:root:eval perplexity: 10.702434539794922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [11:05:47<5:08:53, 579.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3142.3439719460225
INFO:root:current train perplexity11.787161827087402
INFO:root:current mean train loss 3104.264013671875
INFO:root:current train perplexity11.48058032989502
INFO:root:current mean train loss 3097.5742828967523
INFO:root:current train perplexity11.437675476074219
INFO:root:current mean train loss 3092.6758073833626
INFO:root:current train perplexity11.419639587402344
INFO:root:current mean train loss 3099.061875429258
INFO:root:current train perplexity11.435990333557129
INFO:root:current mean train loss 3101.1287443693695
INFO:root:current train perplexity11.440410614013672
INFO:root:current mean train loss 3094.9538969316554
INFO:root:current train perplexity11.422450065612793
INFO:root:current mean train loss 3092.133574024731
INFO:root:current train perplexity11.40162467956543
INFO:root:current mean train loss 3098.9953678956504
INFO:root:current train perplexity11.471816062927246
INFO:root:current mean train loss 3094.621795494519
INFO:root:current train perplexity11.433631896972656
INFO:root:current mean train loss 3086.7847559056577
INFO:root:current train perplexity11.354177474975586
INFO:root:current mean train loss 3080.7946398978625
INFO:root:current train perplexity11.312411308288574
INFO:root:current mean train loss 3079.472103188807
INFO:root:current train perplexity11.313352584838867
INFO:root:current mean train loss 3075.7344883316996
INFO:root:current train perplexity11.291939735412598
INFO:root:current mean train loss 3072.591209091763
INFO:root:current train perplexity11.257610321044922
INFO:root:current mean train loss 3070.689289527231
INFO:root:current train perplexity11.236766815185547
INFO:root:current mean train loss 3068.3832307106777
INFO:root:current train perplexity11.223799705505371
INFO:root:current mean train loss 3078.7458789618945
INFO:root:current train perplexity11.308964729309082
INFO:root:current mean train loss 3078.6842691837937
INFO:root:current train perplexity11.327414512634277
INFO:root:current mean train loss 3079.1668493246484
INFO:root:current train perplexity11.335451126098633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.09s/it]
INFO:root:final mean train loss: 3078.2697944737297
INFO:root:final train perplexity: 11.332884788513184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 2467.8604485261526
INFO:root:eval perplexity: 7.358534812927246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.49s/it]
INFO:root:eval mean loss: 2882.5247724817154
INFO:root:eval perplexity: 10.563535690307617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [11:15:21<4:58:21, 577.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3053.3322177463106
INFO:root:current train perplexity10.94654369354248
INFO:root:current mean train loss 3065.80314032976
INFO:root:current train perplexity11.099136352539062
INFO:root:current mean train loss 3063.9032978731043
INFO:root:current train perplexity11.137415885925293
INFO:root:current mean train loss 3058.6837775117606
INFO:root:current train perplexity11.103053092956543
INFO:root:current mean train loss 3049.006519382283
INFO:root:current train perplexity11.06261157989502
INFO:root:current mean train loss 3044.4466411884014
INFO:root:current train perplexity11.036576271057129
INFO:root:current mean train loss 3043.622247968401
INFO:root:current train perplexity11.024672508239746
INFO:root:current mean train loss 3044.047604575676
INFO:root:current train perplexity11.020278930664062
INFO:root:current mean train loss 3041.2770984894637
INFO:root:current train perplexity11.006207466125488
INFO:root:current mean train loss 3041.5456264166182
INFO:root:current train perplexity10.993972778320312
INFO:root:current mean train loss 3036.2502958383134
INFO:root:current train perplexity10.979092597961426
INFO:root:current mean train loss 3035.2799920091857
INFO:root:current train perplexity10.96427059173584
INFO:root:current mean train loss 3031.805763868416
INFO:root:current train perplexity10.949753761291504
INFO:root:current mean train loss 3030.0786673765488
INFO:root:current train perplexity10.928471565246582
INFO:root:current mean train loss 3029.580489117166
INFO:root:current train perplexity10.920465469360352
INFO:root:current mean train loss 3028.0389627937143
INFO:root:current train perplexity10.905013084411621
INFO:root:current mean train loss 3027.2976969303695
INFO:root:current train perplexity10.889697074890137
INFO:root:current mean train loss 3029.627828145942
INFO:root:current train perplexity10.899139404296875
INFO:root:current mean train loss 3028.166946932801
INFO:root:current train perplexity10.883517265319824
INFO:root:current mean train loss 3025.9752498108282
INFO:root:current train perplexity10.868141174316406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.34s/it]
INFO:root:final mean train loss: 3025.0045686799713
INFO:root:final train perplexity: 10.866671562194824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.05s/it]
INFO:root:eval mean loss: 2457.8276609596633
INFO:root:eval perplexity: 7.299069404602051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.22s/it]
INFO:root:eval mean loss: 2869.980227206616
INFO:root:eval perplexity: 10.455714225769043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [11:24:49<4:47:18, 574.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2947.935437148876
INFO:root:current train perplexity10.438361167907715
INFO:root:current mean train loss 2957.9218866257443
INFO:root:current train perplexity10.436935424804688
INFO:root:current mean train loss 2977.465083666739
INFO:root:current train perplexity10.4473295211792
INFO:root:current mean train loss 2967.0242169926896
INFO:root:current train perplexity10.4021635055542
INFO:root:current mean train loss 2961.152324278662
INFO:root:current train perplexity10.354524612426758
INFO:root:current mean train loss 2960.2990498826134
INFO:root:current train perplexity10.350743293762207
INFO:root:current mean train loss 2959.003215285967
INFO:root:current train perplexity10.333515167236328
INFO:root:current mean train loss 2956.6411980651933
INFO:root:current train perplexity10.290833473205566
INFO:root:current mean train loss 2952.6063313435916
INFO:root:current train perplexity10.261222839355469
INFO:root:current mean train loss 2952.4706179596656
INFO:root:current train perplexity10.25922679901123
INFO:root:current mean train loss 2947.076662622317
INFO:root:current train perplexity10.225261688232422
INFO:root:current mean train loss 2944.2011205418157
INFO:root:current train perplexity10.2005615234375
INFO:root:current mean train loss 2940.9604721365276
INFO:root:current train perplexity10.175959587097168
INFO:root:current mean train loss 2938.5320173995456
INFO:root:current train perplexity10.16109848022461
INFO:root:current mean train loss 2937.8101315572007
INFO:root:current train perplexity10.149578094482422
INFO:root:current mean train loss 2936.0599259988103
INFO:root:current train perplexity10.136442184448242
INFO:root:current mean train loss 2933.218799001582
INFO:root:current train perplexity10.112607955932617
INFO:root:current mean train loss 2931.1657572917393
INFO:root:current train perplexity10.084759712219238
INFO:root:current mean train loss 2928.381350628846
INFO:root:current train perplexity10.063868522644043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.06s/it]
INFO:root:final mean train loss: 2925.3370075081552
INFO:root:final train perplexity: 10.045218467712402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2415.644195773077
INFO:root:eval perplexity: 7.054255485534668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it]
INFO:root:eval mean loss: 2834.8419799804688
INFO:root:eval perplexity: 10.159523963928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [11:34:31<4:38:53, 577.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2878.532958984375
INFO:root:current train perplexity9.162397384643555
INFO:root:current mean train loss 2834.309330778302
INFO:root:current train perplexity9.409761428833008
INFO:root:current mean train loss 2858.015730478231
INFO:root:current train perplexity9.453038215637207
INFO:root:current mean train loss 2858.8587239583335
INFO:root:current train perplexity9.465645790100098
INFO:root:current mean train loss 2868.767463871998
INFO:root:current train perplexity9.52707290649414
INFO:root:current mean train loss 2869.448688492002
INFO:root:current train perplexity9.578869819641113
INFO:root:current mean train loss 2869.6574034234477
INFO:root:current train perplexity9.575116157531738
INFO:root:current mean train loss 2863.538216653019
INFO:root:current train perplexity9.54629898071289
INFO:root:current mean train loss 2861.5656102182847
INFO:root:current train perplexity9.563765525817871
INFO:root:current mean train loss 2862.0149227588645
INFO:root:current train perplexity9.579706192016602
INFO:root:current mean train loss 2863.0415289027555
INFO:root:current train perplexity9.570608139038086
INFO:root:current mean train loss 2862.4927000628672
INFO:root:current train perplexity9.558246612548828
INFO:root:current mean train loss 2859.5996848844966
INFO:root:current train perplexity9.533027648925781
INFO:root:current mean train loss 2855.8657587352245
INFO:root:current train perplexity9.509941101074219
INFO:root:current mean train loss 2853.2924037189946
INFO:root:current train perplexity9.488260269165039
INFO:root:current mean train loss 2849.9603427111865
INFO:root:current train perplexity9.45999813079834
INFO:root:current mean train loss 2845.7733640753913
INFO:root:current train perplexity9.428351402282715
INFO:root:current mean train loss 2843.653015065165
INFO:root:current train perplexity9.403011322021484
INFO:root:current mean train loss 2838.879849692648
INFO:root:current train perplexity9.369467735290527
INFO:root:current mean train loss 2835.045039334052
INFO:root:current train perplexity9.34163761138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.21s/it]
INFO:root:final mean train loss: 2830.9757784921835
INFO:root:final train perplexity: 9.324801445007324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it]
INFO:root:eval mean loss: 2353.9518025716147
INFO:root:eval perplexity: 6.71093225479126
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it]
INFO:root:eval mean loss: 2782.0124741141676
INFO:root:eval perplexity: 9.729926109313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [11:44:01<4:28:09, 574.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2821.849322775136
INFO:root:current train perplexity8.957625389099121
INFO:root:current mean train loss 2783.095719004065
INFO:root:current train perplexity8.87709903717041
INFO:root:current mean train loss 2771.083866136491
INFO:root:current train perplexity8.832385063171387
INFO:root:current mean train loss 2761.6535130550988
INFO:root:current train perplexity8.776229858398438
INFO:root:current mean train loss 2754.7476803754803
INFO:root:current train perplexity8.719599723815918
INFO:root:current mean train loss 2751.518129892149
INFO:root:current train perplexity8.715068817138672
INFO:root:current mean train loss 2754.6956651911114
INFO:root:current train perplexity8.745381355285645
INFO:root:current mean train loss 2754.711787433545
INFO:root:current train perplexity8.76533317565918
INFO:root:current mean train loss 2756.3667641844813
INFO:root:current train perplexity8.78506851196289
INFO:root:current mean train loss 2767.4273698833626
INFO:root:current train perplexity8.86374568939209
INFO:root:current mean train loss 2774.2811161164313
INFO:root:current train perplexity8.928277969360352
INFO:root:current mean train loss 2780.8053718763913
INFO:root:current train perplexity8.969761848449707
INFO:root:current mean train loss 2787.217535085982
INFO:root:current train perplexity9.014102935791016
INFO:root:current mean train loss 2792.357466901691
INFO:root:current train perplexity9.049386978149414
INFO:root:current mean train loss 2799.413938628228
INFO:root:current train perplexity9.10034465789795
INFO:root:current mean train loss 2805.7874450483214
INFO:root:current train perplexity9.13523006439209
INFO:root:current mean train loss 2807.3941706800197
INFO:root:current train perplexity9.155047416687012
INFO:root:current mean train loss 2811.690841453406
INFO:root:current train perplexity9.185013771057129
INFO:root:current mean train loss 2814.0436322018136
INFO:root:current train perplexity9.20528507232666
INFO:root:current mean train loss 2818.7755326912297
INFO:root:current train perplexity9.234833717346191

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.07s/it]
INFO:root:final mean train loss: 2821.0871146813342
INFO:root:final train perplexity: 9.252363204956055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 2409.0834030259584
INFO:root:eval perplexity: 7.016924858093262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.53s/it]
INFO:root:eval mean loss: 2829.1614535717254
INFO:root:eval perplexity: 10.112436294555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [11:53:41<4:19:22, 576.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2915.0309326171873
INFO:root:current train perplexity9.950337409973145
INFO:root:current mean train loss 2911.7230486188614
INFO:root:current train perplexity9.892914772033691
INFO:root:current mean train loss 2907.211410522461
INFO:root:current train perplexity9.785737991333008
INFO:root:current mean train loss 2895.07118063534
INFO:root:current train perplexity9.764619827270508
INFO:root:current mean train loss 2897.10810546875
INFO:root:current train perplexity9.780109405517578
INFO:root:current mean train loss 2901.0480545609084
INFO:root:current train perplexity9.790790557861328
INFO:root:current mean train loss 2899.5986568450926
INFO:root:current train perplexity9.7978515625
INFO:root:current mean train loss 2900.1614696605784
INFO:root:current train perplexity9.811262130737305
INFO:root:current mean train loss 2905.1194164457775
INFO:root:current train perplexity9.84776782989502
INFO:root:current mean train loss 2905.702986826795
INFO:root:current train perplexity9.852516174316406
INFO:root:current mean train loss 2907.2865847074067
INFO:root:current train perplexity9.878716468811035
INFO:root:current mean train loss 2913.0101641738624
INFO:root:current train perplexity9.92540454864502
INFO:root:current mean train loss 2915.6087469285535
INFO:root:current train perplexity9.94653034210205
INFO:root:current mean train loss 2913.37967656833
INFO:root:current train perplexity9.93249225616455
INFO:root:current mean train loss 2911.5390942043728
INFO:root:current train perplexity9.91904067993164
INFO:root:current mean train loss 2909.9685478705865
INFO:root:current train perplexity9.9092435836792
INFO:root:current mean train loss 2912.523017101753
INFO:root:current train perplexity9.938791275024414
INFO:root:current mean train loss 2918.290688560749
INFO:root:current train perplexity9.972981452941895
INFO:root:current mean train loss 2920.1638902747113
INFO:root:current train perplexity9.987377166748047
INFO:root:current mean train loss 2921.952849020417
INFO:root:current train perplexity10.00549030303955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.07s/it]
INFO:root:final mean train loss: 2921.754130691936
INFO:root:final train perplexity: 10.016875267028809
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it]
INFO:root:eval mean loss: 2417.1702932804187
INFO:root:eval perplexity: 7.062967777252197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.39s/it]
INFO:root:eval mean loss: 2837.564780810201
INFO:root:eval perplexity: 10.182172775268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [12:03:13<4:09:10, 575.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2898.581418756853
INFO:root:current train perplexity10.125239372253418
INFO:root:current mean train loss 2964.19388497711
INFO:root:current train perplexity10.381319999694824
INFO:root:current mean train loss 2967.2838377006324
INFO:root:current train perplexity10.351944923400879
INFO:root:current mean train loss 2954.9048699557948
INFO:root:current train perplexity10.308609962463379
INFO:root:current mean train loss 2955.485016069475
INFO:root:current train perplexity10.273893356323242
INFO:root:current mean train loss 2946.020222470405
INFO:root:current train perplexity10.252333641052246
INFO:root:current mean train loss 2948.8430015993627
INFO:root:current train perplexity10.255372047424316
INFO:root:current mean train loss 2949.5864177184817
INFO:root:current train perplexity10.258512496948242
INFO:root:current mean train loss 2946.9571782471558
INFO:root:current train perplexity10.249068260192871
INFO:root:current mean train loss 2950.1882436467313
INFO:root:current train perplexity10.256791114807129
INFO:root:current mean train loss 2949.9633424121926
INFO:root:current train perplexity10.248018264770508
INFO:root:current mean train loss 2948.9873344401603
INFO:root:current train perplexity10.24519157409668
INFO:root:current mean train loss 2947.271943328299
INFO:root:current train perplexity10.225568771362305
INFO:root:current mean train loss 2945.557433497317
INFO:root:current train perplexity10.207738876342773
INFO:root:current mean train loss 2946.9062218492622
INFO:root:current train perplexity10.214871406555176
INFO:root:current mean train loss 2948.357973661037
INFO:root:current train perplexity10.231640815734863
INFO:root:current mean train loss 2949.366304939744
INFO:root:current train perplexity10.240424156188965
INFO:root:current mean train loss 2950.718577837089
INFO:root:current train perplexity10.245672225952148
INFO:root:current mean train loss 2952.5441928713567
INFO:root:current train perplexity10.254624366760254
INFO:root:current mean train loss 2951.5829077610024
INFO:root:current train perplexity10.24907112121582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.41s/it]
INFO:root:final mean train loss: 2950.43615230189
INFO:root:final train perplexity: 10.246039390563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it]
INFO:root:eval mean loss: 2396.972991726923
INFO:root:eval perplexity: 6.948536396026611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.14s/it]
INFO:root:eval mean loss: 2816.4844970703125
INFO:root:eval perplexity: 10.008135795593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [12:12:51<4:00:01, 576.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2941.6095333614867
INFO:root:current train perplexity10.133366584777832
INFO:root:current mean train loss 2921.3388573657508
INFO:root:current train perplexity10.02661418914795
INFO:root:current mean train loss 2921.1842201399977
INFO:root:current train perplexity10.075394630432129
INFO:root:current mean train loss 2920.383337989848
INFO:root:current train perplexity10.054917335510254
INFO:root:current mean train loss 2917.6777034711236
INFO:root:current train perplexity10.013558387756348
INFO:root:current mean train loss 2922.883871151595
INFO:root:current train perplexity10.019414901733398
INFO:root:current mean train loss 2924.5853934358774
INFO:root:current train perplexity10.033685684204102
INFO:root:current mean train loss 2926.3954065603803
INFO:root:current train perplexity10.03249740600586
INFO:root:current mean train loss 2924.719266773634
INFO:root:current train perplexity10.038665771484375
INFO:root:current mean train loss 2925.4055499129718
INFO:root:current train perplexity10.026372909545898
INFO:root:current mean train loss 2925.534606592615
INFO:root:current train perplexity10.014544486999512
INFO:root:current mean train loss 2923.4795836882454
INFO:root:current train perplexity10.014126777648926
INFO:root:current mean train loss 2919.649987237233
INFO:root:current train perplexity9.99670124053955
INFO:root:current mean train loss 2920.1134429443005
INFO:root:current train perplexity9.987800598144531
INFO:root:current mean train loss 2917.0528090747434
INFO:root:current train perplexity9.967233657836914
INFO:root:current mean train loss 2915.2985444317324
INFO:root:current train perplexity9.959579467773438
INFO:root:current mean train loss 2915.1928277784777
INFO:root:current train perplexity9.951874732971191
INFO:root:current mean train loss 2914.36495775569
INFO:root:current train perplexity9.9412841796875
INFO:root:current mean train loss 2912.6950467332576
INFO:root:current train perplexity9.933135986328125
INFO:root:current mean train loss 2910.365259729016
INFO:root:current train perplexity9.92180347442627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.70s/it]
INFO:root:final mean train loss: 2909.5816660855553
INFO:root:final train perplexity: 9.921172142028809
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it]
INFO:root:eval mean loss: 2391.4588285405584
INFO:root:eval perplexity: 6.917617321014404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it]
INFO:root:eval mean loss: 2811.455188940603
INFO:root:eval perplexity: 9.967057228088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [12:22:21<3:49:40, 574.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2858.492410177713
INFO:root:current train perplexity9.872498512268066
INFO:root:current mean train loss 2880.0306671302355
INFO:root:current train perplexity9.804352760314941
INFO:root:current mean train loss 2875.6202287706724
INFO:root:current train perplexity9.821508407592773
INFO:root:current mean train loss 2874.91700280231
INFO:root:current train perplexity9.751334190368652
INFO:root:current mean train loss 2873.3273821362654
INFO:root:current train perplexity9.746848106384277
INFO:root:current mean train loss 2869.872502412489
INFO:root:current train perplexity9.705647468566895
INFO:root:current mean train loss 2876.2140540911046
INFO:root:current train perplexity9.713106155395508
INFO:root:current mean train loss 2875.064317628496
INFO:root:current train perplexity9.713104248046875
INFO:root:current mean train loss 2882.219271710157
INFO:root:current train perplexity9.758644104003906
INFO:root:current mean train loss 2886.8974153612985
INFO:root:current train perplexity9.77994155883789
INFO:root:current mean train loss 2884.309289472459
INFO:root:current train perplexity9.763619422912598
INFO:root:current mean train loss 2883.9702054143054
INFO:root:current train perplexity9.747333526611328
INFO:root:current mean train loss 2882.4138879517454
INFO:root:current train perplexity9.734929084777832
INFO:root:current mean train loss 2881.8703771244273
INFO:root:current train perplexity9.714609146118164
INFO:root:current mean train loss 2880.6470031124245
INFO:root:current train perplexity9.700898170471191
INFO:root:current mean train loss 2879.5853519307825
INFO:root:current train perplexity9.693492889404297
INFO:root:current mean train loss 2877.2720348825123
INFO:root:current train perplexity9.678934097290039
INFO:root:current mean train loss 2875.4289060046326
INFO:root:current train perplexity9.652366638183594
INFO:root:current mean train loss 2873.5771205504693
INFO:root:current train perplexity9.644006729125977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.71s/it]
INFO:root:final mean train loss: 2871.504631962009
INFO:root:final train perplexity: 9.627668380737305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it]
INFO:root:eval mean loss: 2377.546435200576
INFO:root:eval perplexity: 6.840219497680664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it]
INFO:root:eval mean loss: 2799.9215992596132
INFO:root:eval perplexity: 9.873482704162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [12:31:52<3:39:45, 573.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2727.8525390625
INFO:root:current train perplexity8.936702728271484
INFO:root:current mean train loss 2843.2100694444443
INFO:root:current train perplexity9.351202011108398
INFO:root:current mean train loss 2847.6730076716494
INFO:root:current train perplexity9.464237213134766
INFO:root:current mean train loss 2838.9158325195312
INFO:root:current train perplexity9.443275451660156
INFO:root:current mean train loss 2841.246420467601
INFO:root:current train perplexity9.434803009033203
INFO:root:current mean train loss 2840.3083952655943
INFO:root:current train perplexity9.42486572265625
INFO:root:current mean train loss 2838.3033937153064
INFO:root:current train perplexity9.423126220703125
INFO:root:current mean train loss 2835.766161902476
INFO:root:current train perplexity9.407312393188477
INFO:root:current mean train loss 2842.852205182066
INFO:root:current train perplexity9.426153182983398
INFO:root:current mean train loss 2843.74325198539
INFO:root:current train perplexity9.423809051513672
INFO:root:current mean train loss 2843.7386719234405
INFO:root:current train perplexity9.42409896850586
INFO:root:current mean train loss 2844.6356890847105
INFO:root:current train perplexity9.425432205200195
INFO:root:current mean train loss 2843.3998439359348
INFO:root:current train perplexity9.414671897888184
INFO:root:current mean train loss 2845.687056888499
INFO:root:current train perplexity9.424324035644531
INFO:root:current mean train loss 2844.9670691056685
INFO:root:current train perplexity9.422539710998535
INFO:root:current mean train loss 2844.997802734375
INFO:root:current train perplexity9.421092987060547
INFO:root:current mean train loss 2846.566123089387
INFO:root:current train perplexity9.422688484191895
INFO:root:current mean train loss 2844.9297443899113
INFO:root:current train perplexity9.414323806762695
INFO:root:current mean train loss 2843.0365346722897
INFO:root:current train perplexity9.40738582611084
INFO:root:current mean train loss 2842.100986952552
INFO:root:current train perplexity9.403879165649414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.82s/it]
INFO:root:final mean train loss: 2841.8067571550564
INFO:root:final train perplexity: 9.40479564666748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it]
INFO:root:eval mean loss: 2380.340082696144
INFO:root:eval perplexity: 6.855692386627197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.43s/it]
INFO:root:eval mean loss: 2803.507176608904
INFO:root:eval perplexity: 9.902482032775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [12:41:23<3:29:53, 572.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2858.339775390625
INFO:root:current train perplexity9.558354377746582
INFO:root:current mean train loss 2813.396791015625
INFO:root:current train perplexity9.38524341583252
INFO:root:current mean train loss 2825.4474869791666
INFO:root:current train perplexity9.373364448547363
INFO:root:current mean train loss 2830.410419170673
INFO:root:current train perplexity9.384181022644043
INFO:root:current mean train loss 2835.519676585478
INFO:root:current train perplexity9.421976089477539
INFO:root:current mean train loss 2835.041691313244
INFO:root:current train perplexity9.394944190979004
INFO:root:current mean train loss 2835.5401765625
INFO:root:current train perplexity9.444479942321777
INFO:root:current mean train loss 2853.307965382543
INFO:root:current train perplexity9.561463356018066
INFO:root:current mean train loss 2880.322936789773
INFO:root:current train perplexity9.732385635375977
INFO:root:current mean train loss 2887.469956714527
INFO:root:current train perplexity9.786062240600586
INFO:root:current mean train loss 2886.4386304306404
INFO:root:current train perplexity9.796359062194824
INFO:root:current mean train loss 2891.930697048611
INFO:root:current train perplexity9.817166328430176
INFO:root:current mean train loss 2894.4966047512753
INFO:root:current train perplexity9.821393966674805
INFO:root:current mean train loss 2894.9570376989977
INFO:root:current train perplexity9.819588661193848
INFO:root:current mean train loss 2895.0969423314145
INFO:root:current train perplexity9.813725471496582
INFO:root:current mean train loss 2894.715673347848
INFO:root:current train perplexity9.804908752441406
INFO:root:current mean train loss 2892.1354271334135
INFO:root:current train perplexity9.7915678024292
INFO:root:current mean train loss 2891.5614591825183
INFO:root:current train perplexity9.775850296020508
INFO:root:current mean train loss 2891.707210509418
INFO:root:current train perplexity9.769461631774902
INFO:root:current mean train loss 2889.7757700892857
INFO:root:current train perplexity9.758564949035645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.74s/it]
INFO:root:final mean train loss: 2887.637143872329
INFO:root:final train perplexity: 9.750947952270508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2379.741550743157
INFO:root:eval perplexity: 6.85237455368042
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2798.8511248649434
INFO:root:eval perplexity: 9.86484432220459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [12:51:05<3:21:20, 575.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2823.0924014136904
INFO:root:current train perplexity9.196188926696777
INFO:root:current mean train loss 2861.39394324934
INFO:root:current train perplexity9.424859046936035
INFO:root:current mean train loss 2853.6453474060563
INFO:root:current train perplexity9.406289100646973
INFO:root:current mean train loss 2846.3381647478072
INFO:root:current train perplexity9.39041805267334
INFO:root:current mean train loss 2841.0619255514707
INFO:root:current train perplexity9.395485877990723
INFO:root:current mean train loss 2841.8525566298144
INFO:root:current train perplexity9.399787902832031
INFO:root:current mean train loss 2844.4542837172653
INFO:root:current train perplexity9.402836799621582
INFO:root:current mean train loss 2847.6658560452115
INFO:root:current train perplexity9.428324699401855
INFO:root:current mean train loss 2844.1829027914378
INFO:root:current train perplexity9.418251991271973
INFO:root:current mean train loss 2841.1917615756865
INFO:root:current train perplexity9.405755996704102
INFO:root:current mean train loss 2842.88632536026
INFO:root:current train perplexity9.402390480041504
INFO:root:current mean train loss 2837.9360298116653
INFO:root:current train perplexity9.384957313537598
INFO:root:current mean train loss 2834.882879137417
INFO:root:current train perplexity9.36414623260498
INFO:root:current mean train loss 2832.088319053593
INFO:root:current train perplexity9.346433639526367
INFO:root:current mean train loss 2831.6093734762376
INFO:root:current train perplexity9.3427734375
INFO:root:current mean train loss 2831.976418897181
INFO:root:current train perplexity9.335583686828613
INFO:root:current mean train loss 2829.980863359756
INFO:root:current train perplexity9.315791130065918
INFO:root:current mean train loss 2827.6720021156984
INFO:root:current train perplexity9.302607536315918
INFO:root:current mean train loss 2828.1955844742465
INFO:root:current train perplexity9.298185348510742
INFO:root:current mean train loss 2826.4709661230368
INFO:root:current train perplexity9.288992881774902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.31s/it]
INFO:root:final mean train loss: 2825.89647434098
INFO:root:final train perplexity: 9.287524223327637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it]
INFO:root:eval mean loss: 2363.650823065575
INFO:root:eval perplexity: 6.763781547546387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it]
INFO:root:eval mean loss: 2785.404274798454
INFO:root:eval perplexity: 9.756952285766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [13:00:34<3:11:08, 573.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2812.2852845272773
INFO:root:current train perplexity9.127029418945312
INFO:root:current mean train loss 2794.8490903842376
INFO:root:current train perplexity9.04287338256836
INFO:root:current mean train loss 2788.075662855936
INFO:root:current train perplexity9.040860176086426
INFO:root:current mean train loss 2797.9919243177665
INFO:root:current train perplexity9.075174331665039
INFO:root:current mean train loss 2798.7044909109477
INFO:root:current train perplexity9.09235668182373
INFO:root:current mean train loss 2803.7394988959077
INFO:root:current train perplexity9.096667289733887
INFO:root:current mean train loss 2806.607490412201
INFO:root:current train perplexity9.113463401794434
INFO:root:current mean train loss 2803.4358852622695
INFO:root:current train perplexity9.104264259338379
INFO:root:current mean train loss 2799.6934423657594
INFO:root:current train perplexity9.09562873840332
INFO:root:current mean train loss 2801.9962014366365
INFO:root:current train perplexity9.109670639038086
INFO:root:current mean train loss 2804.6922576299135
INFO:root:current train perplexity9.126849174499512
INFO:root:current mean train loss 2804.27027841721
INFO:root:current train perplexity9.124899864196777
INFO:root:current mean train loss 2807.167787438257
INFO:root:current train perplexity9.13668155670166
INFO:root:current mean train loss 2807.6304539111366
INFO:root:current train perplexity9.139134407043457
INFO:root:current mean train loss 2807.77809541531
INFO:root:current train perplexity9.137084007263184
INFO:root:current mean train loss 2808.3447596052656
INFO:root:current train perplexity9.149629592895508
INFO:root:current mean train loss 2810.1318728749907
INFO:root:current train perplexity9.155062675476074
INFO:root:current mean train loss 2809.7157109419413
INFO:root:current train perplexity9.161083221435547
INFO:root:current mean train loss 2807.981776655586
INFO:root:current train perplexity9.15372085571289
INFO:root:current mean train loss 2806.8040247435715
INFO:root:current train perplexity9.147611618041992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.00s/it]
INFO:root:final mean train loss: 2806.5426804720005
INFO:root:final train perplexity: 9.146838188171387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2359.561196185173
INFO:root:eval perplexity: 6.741446018218994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it]
INFO:root:eval mean loss: 2783.80315859098
INFO:root:eval perplexity: 9.744182586669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [13:10:15<3:02:21, 575.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2795.0498560855262
INFO:root:current train perplexity9.134272575378418
INFO:root:current mean train loss 2802.777977683327
INFO:root:current train perplexity9.10441780090332
INFO:root:current mean train loss 2792.2825777357903
INFO:root:current train perplexity9.046060562133789
INFO:root:current mean train loss 2791.6405321486454
INFO:root:current train perplexity9.04844856262207
INFO:root:current mean train loss 2791.8321522945116
INFO:root:current train perplexity9.017851829528809
INFO:root:current mean train loss 2796.9385384453667
INFO:root:current train perplexity9.028711318969727
INFO:root:current mean train loss 2795.227134208002
INFO:root:current train perplexity9.027094841003418
INFO:root:current mean train loss 2796.9672703693823
INFO:root:current train perplexity9.03883171081543
INFO:root:current mean train loss 2794.768296054509
INFO:root:current train perplexity9.02517318725586
INFO:root:current mean train loss 2793.673550465068
INFO:root:current train perplexity9.012985229492188
INFO:root:current mean train loss 2790.910058003819
INFO:root:current train perplexity9.005456924438477
INFO:root:current mean train loss 2792.0009921326928
INFO:root:current train perplexity9.016194343566895
INFO:root:current mean train loss 2793.616807895768
INFO:root:current train perplexity9.026223182678223
INFO:root:current mean train loss 2792.7160522106083
INFO:root:current train perplexity9.023490905761719
INFO:root:current mean train loss 2790.303870224371
INFO:root:current train perplexity9.021313667297363
INFO:root:current mean train loss 2791.3456393014358
INFO:root:current train perplexity9.028961181640625
INFO:root:current mean train loss 2790.740280843293
INFO:root:current train perplexity9.029608726501465
INFO:root:current mean train loss 2790.9027396537163
INFO:root:current train perplexity9.035606384277344
INFO:root:current mean train loss 2792.411283773654
INFO:root:current train perplexity9.043108940124512
INFO:root:current mean train loss 2793.9832071775368
INFO:root:current train perplexity9.05226993560791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.76s/it]
INFO:root:final mean train loss: 2793.509963596823
INFO:root:final train perplexity: 9.053306579589844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2359.4830062541555
INFO:root:eval perplexity: 6.7410197257995605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.89s/it]
INFO:root:eval mean loss: 2778.1545626592974
INFO:root:eval perplexity: 9.699272155761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [13:19:46<2:52:17, 574.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2788.386288222446
INFO:root:current train perplexity9.015873908996582
INFO:root:current mean train loss 2797.5077947903173
INFO:root:current train perplexity9.103300094604492
INFO:root:current mean train loss 2803.4614457791167
INFO:root:current train perplexity9.140313148498535
INFO:root:current mean train loss 2800.9350666696487
INFO:root:current train perplexity9.092187881469727
INFO:root:current mean train loss 2799.8887060447832
INFO:root:current train perplexity9.07791805267334
INFO:root:current mean train loss 2802.815899030354
INFO:root:current train perplexity9.087613105773926
INFO:root:current mean train loss 2796.0266994019435
INFO:root:current train perplexity9.073036193847656
INFO:root:current mean train loss 2794.8051265221075
INFO:root:current train perplexity9.068557739257812
INFO:root:current mean train loss 2792.0842416385253
INFO:root:current train perplexity9.041604042053223
INFO:root:current mean train loss 2793.8646116074237
INFO:root:current train perplexity9.043009757995605
INFO:root:current mean train loss 2792.4383986072594
INFO:root:current train perplexity9.026920318603516
INFO:root:current mean train loss 2789.0591667539816
INFO:root:current train perplexity9.011968612670898
INFO:root:current mean train loss 2784.2553167143997
INFO:root:current train perplexity8.986268997192383
INFO:root:current mean train loss 2783.0224002966843
INFO:root:current train perplexity8.979801177978516
INFO:root:current mean train loss 2781.598927154848
INFO:root:current train perplexity8.966727256774902
INFO:root:current mean train loss 2781.729177241496
INFO:root:current train perplexity8.95295524597168
INFO:root:current mean train loss 2779.3414181902504
INFO:root:current train perplexity8.94659423828125
INFO:root:current mean train loss 2777.7411518426693
INFO:root:current train perplexity8.937943458557129
INFO:root:current mean train loss 2777.738296726426
INFO:root:current train perplexity8.933995246887207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.21s/it]
INFO:root:final mean train loss: 2775.5229179470816
INFO:root:final train perplexity: 8.925786018371582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 2342.2906156499334
INFO:root:eval perplexity: 6.647940635681152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.30s/it]
INFO:root:eval mean loss: 2766.567571978197
INFO:root:eval perplexity: 9.607796669006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [13:29:13<2:42:05, 572.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2706.95615234375
INFO:root:current train perplexity8.598798751831055
INFO:root:current mean train loss 2750.9601606889205
INFO:root:current train perplexity8.771740913391113
INFO:root:current mean train loss 2759.628404017857
INFO:root:current train perplexity8.79686450958252
INFO:root:current mean train loss 2760.8329715851814
INFO:root:current train perplexity8.792563438415527
INFO:root:current mean train loss 2759.8640744092986
INFO:root:current train perplexity8.806979179382324
INFO:root:current mean train loss 2763.151079005821
INFO:root:current train perplexity8.827648162841797
INFO:root:current mean train loss 2759.123851338371
INFO:root:current train perplexity8.82433795928955
INFO:root:current mean train loss 2756.8690281827685
INFO:root:current train perplexity8.820611000061035
INFO:root:current mean train loss 2754.716155779803
INFO:root:current train perplexity8.810108184814453
INFO:root:current mean train loss 2756.4199143629808
INFO:root:current train perplexity8.825663566589355
INFO:root:current mean train loss 2759.8885696260054
INFO:root:current train perplexity8.825675964355469
INFO:root:current mean train loss 2759.075653241132
INFO:root:current train perplexity8.820836067199707
INFO:root:current mean train loss 2760.7611372514207
INFO:root:current train perplexity8.827067375183105
INFO:root:current mean train loss 2762.3928735165196
INFO:root:current train perplexity8.845704078674316
INFO:root:current mean train loss 2761.8508084344526
INFO:root:current train perplexity8.845492362976074
INFO:root:current mean train loss 2762.5038679312397
INFO:root:current train perplexity8.84345817565918
INFO:root:current mean train loss 2763.3459736510094
INFO:root:current train perplexity8.84807014465332
INFO:root:current mean train loss 2760.3877234386423
INFO:root:current train perplexity8.834077835083008
INFO:root:current mean train loss 2762.498324466937
INFO:root:current train perplexity8.840339660644531
INFO:root:current mean train loss 2764.5363245459753
INFO:root:current train perplexity8.845284461975098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.19s/it]
INFO:root:final mean train loss: 2764.447714262639
INFO:root:final train perplexity: 8.848162651062012
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 2342.6614007611647
INFO:root:eval perplexity: 6.6499342918396
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.35s/it]
INFO:root:eval mean loss: 2766.5891736619014
INFO:root:eval perplexity: 9.607966423034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [13:38:42<2:32:19, 571.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2732.8746473524307
INFO:root:current train perplexity8.78042221069336
INFO:root:current mean train loss 2759.4501337967517
INFO:root:current train perplexity8.816764831542969
INFO:root:current mean train loss 2765.898595599876
INFO:root:current train perplexity8.814058303833008
INFO:root:current mean train loss 2751.8963231077983
INFO:root:current train perplexity8.773650169372559
INFO:root:current mean train loss 2753.797976777481
INFO:root:current train perplexity8.77227783203125
INFO:root:current mean train loss 2751.6658266129034
INFO:root:current train perplexity8.744190216064453
INFO:root:current mean train loss 2752.1632860782993
INFO:root:current train perplexity8.743331909179688
INFO:root:current mean train loss 2757.114317924153
INFO:root:current train perplexity8.767155647277832
INFO:root:current mean train loss 2757.7801692275357
INFO:root:current train perplexity8.773418426513672
INFO:root:current mean train loss 2755.0700333316477
INFO:root:current train perplexity8.760293960571289
INFO:root:current mean train loss 2753.8744344590586
INFO:root:current train perplexity8.75212287902832
INFO:root:current mean train loss 2757.5782159840837
INFO:root:current train perplexity8.761810302734375
INFO:root:current mean train loss 2756.7775055155485
INFO:root:current train perplexity8.764082908630371
INFO:root:current mean train loss 2756.0486248277953
INFO:root:current train perplexity8.76220703125
INFO:root:current mean train loss 2756.153914325289
INFO:root:current train perplexity8.760015487670898
INFO:root:current mean train loss 2753.3188204762196
INFO:root:current train perplexity8.750029563903809
INFO:root:current mean train loss 2751.679488075974
INFO:root:current train perplexity8.742565155029297
INFO:root:current mean train loss 2751.7412178644777
INFO:root:current train perplexity8.749157905578613
INFO:root:current mean train loss 2751.5377260739515
INFO:root:current train perplexity8.750768661499023
INFO:root:current mean train loss 2751.9268758919306
INFO:root:current train perplexity8.752337455749512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.63s/it]
INFO:root:final mean train loss: 2750.868519746951
INFO:root:final train perplexity: 8.75390911102295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.07s/it]
INFO:root:eval mean loss: 2344.944466232408
INFO:root:eval perplexity: 6.662224769592285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.83s/it]
INFO:root:eval mean loss: 2771.5307418065713
INFO:root:eval perplexity: 9.64687442779541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [13:48:23<2:23:31, 574.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2737.478826349432
INFO:root:current train perplexity8.687780380249023
INFO:root:current mean train loss 2756.2754024929473
INFO:root:current train perplexity8.843331336975098
INFO:root:current mean train loss 2753.7674350425846
INFO:root:current train perplexity8.82077693939209
INFO:root:current mean train loss 2751.465824570767
INFO:root:current train perplexity8.768669128417969
INFO:root:current mean train loss 2751.7135587125213
INFO:root:current train perplexity8.760392189025879
INFO:root:current mean train loss 2753.1270536534926
INFO:root:current train perplexity8.764808654785156
INFO:root:current mean train loss 2752.0849613166
INFO:root:current train perplexity8.744013786315918
INFO:root:current mean train loss 2753.8814910560527
INFO:root:current train perplexity8.740403175354004
INFO:root:current mean train loss 2753.938642312
INFO:root:current train perplexity8.734728813171387
INFO:root:current mean train loss 2750.586542420468
INFO:root:current train perplexity8.709898948669434
INFO:root:current mean train loss 2747.639951742472
INFO:root:current train perplexity8.700623512268066
INFO:root:current mean train loss 2743.9304935482
INFO:root:current train perplexity8.682673454284668
INFO:root:current mean train loss 2745.2608524825414
INFO:root:current train perplexity8.685173034667969
INFO:root:current mean train loss 2744.021405356271
INFO:root:current train perplexity8.676825523376465
INFO:root:current mean train loss 2744.4407773004673
INFO:root:current train perplexity8.677915573120117
INFO:root:current mean train loss 2743.237151625243
INFO:root:current train perplexity8.672500610351562
INFO:root:current mean train loss 2741.5478735410966
INFO:root:current train perplexity8.668120384216309
INFO:root:current mean train loss 2740.3736555466958
INFO:root:current train perplexity8.669124603271484
INFO:root:current mean train loss 2739.2316519846886
INFO:root:current train perplexity8.668201446533203
INFO:root:current mean train loss 2738.3865723158597
INFO:root:current train perplexity8.66624641418457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.05s/it]
INFO:root:final mean train loss: 2738.612198930164
INFO:root:final train perplexity: 8.66970157623291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 2338.3542536742298
INFO:root:eval perplexity: 6.626810073852539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.20s/it]
INFO:root:eval mean loss: 2762.6076313857493
INFO:root:eval perplexity: 9.576732635498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [13:57:55<2:13:48, 573.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2750.5485919889857
INFO:root:current train perplexity8.730487823486328
INFO:root:current mean train loss 2736.198509074146
INFO:root:current train perplexity8.701004981994629
INFO:root:current mean train loss 2743.594579703963
INFO:root:current train perplexity8.748442649841309
INFO:root:current mean train loss 2742.3509639835092
INFO:root:current train perplexity8.73033332824707
INFO:root:current mean train loss 2738.1084122068196
INFO:root:current train perplexity8.699795722961426
INFO:root:current mean train loss 2733.6369726823614
INFO:root:current train perplexity8.688273429870605
INFO:root:current mean train loss 2734.4088829144407
INFO:root:current train perplexity8.672298431396484
INFO:root:current mean train loss 2736.9789354121326
INFO:root:current train perplexity8.68565559387207
INFO:root:current mean train loss 2736.1063836393455
INFO:root:current train perplexity8.677108764648438
INFO:root:current mean train loss 2735.8900951818173
INFO:root:current train perplexity8.6800537109375
INFO:root:current mean train loss 2734.416231347748
INFO:root:current train perplexity8.664705276489258
INFO:root:current mean train loss 2736.2055034259597
INFO:root:current train perplexity8.6665620803833
INFO:root:current mean train loss 2736.1006882597208
INFO:root:current train perplexity8.667169570922852
INFO:root:current mean train loss 2738.0532247191577
INFO:root:current train perplexity8.667243957519531
INFO:root:current mean train loss 2739.1249576388445
INFO:root:current train perplexity8.670125007629395
INFO:root:current mean train loss 2737.0613483475386
INFO:root:current train perplexity8.651692390441895
INFO:root:current mean train loss 2735.434812027887
INFO:root:current train perplexity8.646159172058105
INFO:root:current mean train loss 2734.2167037799236
INFO:root:current train perplexity8.638137817382812
INFO:root:current mean train loss 2734.9508723075
INFO:root:current train perplexity8.649182319641113
INFO:root:current mean train loss 2737.3775201512503
INFO:root:current train perplexity8.654340744018555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.57s/it]
INFO:root:final mean train loss: 2736.0797601142917
INFO:root:final train perplexity: 8.6524019241333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it]
INFO:root:eval mean loss: 2339.27640484749
INFO:root:eval perplexity: 6.631755352020264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it]
INFO:root:eval mean loss: 2765.0433908016125
INFO:root:eval perplexity: 9.59582805633545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [14:07:24<2:03:55, 572.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2724.1428754757612
INFO:root:current train perplexity8.537187576293945
INFO:root:current mean train loss 2747.406997509217
INFO:root:current train perplexity8.646444320678711
INFO:root:current mean train loss 2735.6046485077563
INFO:root:current train perplexity8.604731559753418
INFO:root:current mean train loss 2734.651297433036
INFO:root:current train perplexity8.587886810302734
INFO:root:current mean train loss 2733.5559475312175
INFO:root:current train perplexity8.5949068069458
INFO:root:current mean train loss 2733.776334663576
INFO:root:current train perplexity8.594430923461914
INFO:root:current mean train loss 2734.520537339832
INFO:root:current train perplexity8.601150512695312
INFO:root:current mean train loss 2735.3289054341058
INFO:root:current train perplexity8.61100959777832
INFO:root:current mean train loss 2733.8598360309297
INFO:root:current train perplexity8.624814987182617
INFO:root:current mean train loss 2733.981164226259
INFO:root:current train perplexity8.629043579101562
INFO:root:current mean train loss 2730.906072896133
INFO:root:current train perplexity8.622212409973145
INFO:root:current mean train loss 2732.4680465931397
INFO:root:current train perplexity8.618112564086914
INFO:root:current mean train loss 2732.5293539939726
INFO:root:current train perplexity8.622979164123535
INFO:root:current mean train loss 2731.1896161216437
INFO:root:current train perplexity8.61038589477539
INFO:root:current mean train loss 2733.0622669266427
INFO:root:current train perplexity8.615519523620605
INFO:root:current mean train loss 2730.146314342968
INFO:root:current train perplexity8.600133895874023
INFO:root:current mean train loss 2731.8439018967892
INFO:root:current train perplexity8.610223770141602
INFO:root:current mean train loss 2731.6251529654983
INFO:root:current train perplexity8.610106468200684
INFO:root:current mean train loss 2731.349530074797
INFO:root:current train perplexity8.613030433654785
INFO:root:current mean train loss 2730.507217700368
INFO:root:current train perplexity8.609787940979004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.88s/it]
INFO:root:final mean train loss: 2729.863181217596
INFO:root:final train perplexity: 8.610086441040039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 2334.1713321766956
INFO:root:eval perplexity: 6.604430675506592
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.27s/it]
INFO:root:eval mean loss: 2759.3349068283187
INFO:root:eval perplexity: 9.551135063171387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [14:16:55<1:54:20, 571.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2744.513353207237
INFO:root:current train perplexity8.705833435058594
INFO:root:current mean train loss 2731.144037960737
INFO:root:current train perplexity8.625908851623535
INFO:root:current mean train loss 2738.2458694716634
INFO:root:current train perplexity8.648327827453613
INFO:root:current mean train loss 2733.6907177116295
INFO:root:current train perplexity8.664960861206055
INFO:root:current mean train loss 2746.4132250236744
INFO:root:current train perplexity8.72741413116455
INFO:root:current mean train loss 2748.33895417542
INFO:root:current train perplexity8.73215103149414
INFO:root:current mean train loss 2746.6290650292267
INFO:root:current train perplexity8.727357864379883
INFO:root:current mean train loss 2746.1521640993515
INFO:root:current train perplexity8.717174530029297
INFO:root:current mean train loss 2750.46493076772
INFO:root:current train perplexity8.717409133911133
INFO:root:current mean train loss 2748.218233010757
INFO:root:current train perplexity8.724813461303711
INFO:root:current mean train loss 2747.130474323987
INFO:root:current train perplexity8.704947471618652
INFO:root:current mean train loss 2744.5290780677956
INFO:root:current train perplexity8.699686050415039
INFO:root:current mean train loss 2743.867815101653
INFO:root:current train perplexity8.692530632019043
INFO:root:current mean train loss 2743.369683159722
INFO:root:current train perplexity8.681748390197754
INFO:root:current mean train loss 2741.2081169000835
INFO:root:current train perplexity8.672999382019043
INFO:root:current mean train loss 2738.014320416585
INFO:root:current train perplexity8.663395881652832
INFO:root:current mean train loss 2736.843263447179
INFO:root:current train perplexity8.650654792785645
INFO:root:current mean train loss 2733.96985250914
INFO:root:current train perplexity8.633177757263184
INFO:root:current mean train loss 2732.4010849119804
INFO:root:current train perplexity8.62441635131836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.88s/it]
INFO:root:final mean train loss: 2731.0865956824414
INFO:root:final train perplexity: 8.61839771270752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.11s/it]
INFO:root:eval mean loss: 2330.411072643091
INFO:root:eval perplexity: 6.584376811981201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2758.999326448914
INFO:root:eval perplexity: 9.548514366149902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [14:26:28<1:44:54, 572.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2808.2326049804688
INFO:root:current train perplexity8.65830135345459
INFO:root:current mean train loss 2727.733193533761
INFO:root:current train perplexity8.530745506286621
INFO:root:current mean train loss 2726.3666485480544
INFO:root:current train perplexity8.522302627563477
INFO:root:current mean train loss 2717.759451841697
INFO:root:current train perplexity8.507436752319336
INFO:root:current mean train loss 2715.6841981758193
INFO:root:current train perplexity8.505901336669922
INFO:root:current mean train loss 2721.313238143921
INFO:root:current train perplexity8.545764923095703
INFO:root:current mean train loss 2727.577211467269
INFO:root:current train perplexity8.567893981933594
INFO:root:current mean train loss 2725.828726436315
INFO:root:current train perplexity8.570611000061035
INFO:root:current mean train loss 2723.261366069023
INFO:root:current train perplexity8.576254844665527
INFO:root:current mean train loss 2723.9124365020216
INFO:root:current train perplexity8.581625938415527
INFO:root:current mean train loss 2724.2753681891522
INFO:root:current train perplexity8.573963165283203
INFO:root:current mean train loss 2724.725499873539
INFO:root:current train perplexity8.567634582519531
INFO:root:current mean train loss 2724.160894916396
INFO:root:current train perplexity8.558788299560547
INFO:root:current mean train loss 2725.000518798828
INFO:root:current train perplexity8.56544303894043
INFO:root:current mean train loss 2723.476228967942
INFO:root:current train perplexity8.555169105529785
INFO:root:current mean train loss 2722.5962159494875
INFO:root:current train perplexity8.550507545471191
INFO:root:current mean train loss 2721.2500790579443
INFO:root:current train perplexity8.548566818237305
INFO:root:current mean train loss 2721.24105578271
INFO:root:current train perplexity8.54957389831543
INFO:root:current mean train loss 2720.9310836286736
INFO:root:current train perplexity8.544024467468262
INFO:root:current mean train loss 2721.0301357891767
INFO:root:current train perplexity8.547082901000977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.31s/it]
INFO:root:final mean train loss: 2720.747885715102
INFO:root:final train perplexity: 8.54841136932373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it]
INFO:root:eval mean loss: 2330.4005958070147
INFO:root:eval perplexity: 6.584320545196533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it]
INFO:root:eval mean loss: 2757.5608087634364
INFO:root:eval perplexity: 9.537283897399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [14:36:08<1:35:45, 574.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2656.5257526266164
INFO:root:current train perplexity8.399365425109863
INFO:root:current mean train loss 2722.3031791273015
INFO:root:current train perplexity8.599028587341309
INFO:root:current mean train loss 2714.106446378616
INFO:root:current train perplexity8.568727493286133
INFO:root:current mean train loss 2712.6325127042173
INFO:root:current train perplexity8.561216354370117
INFO:root:current mean train loss 2721.177358204946
INFO:root:current train perplexity8.567584991455078
INFO:root:current mean train loss 2726.2198670933512
INFO:root:current train perplexity8.56662368774414
INFO:root:current mean train loss 2726.4049491457795
INFO:root:current train perplexity8.566106796264648
INFO:root:current mean train loss 2726.888580615301
INFO:root:current train perplexity8.577068328857422
INFO:root:current mean train loss 2726.6429637729475
INFO:root:current train perplexity8.574825286865234
INFO:root:current mean train loss 2727.8937989595247
INFO:root:current train perplexity8.57839584350586
INFO:root:current mean train loss 2727.292523294195
INFO:root:current train perplexity8.579387664794922
INFO:root:current mean train loss 2724.878730334678
INFO:root:current train perplexity8.571349143981934
INFO:root:current mean train loss 2725.79168298906
INFO:root:current train perplexity8.577385902404785
INFO:root:current mean train loss 2724.718773422069
INFO:root:current train perplexity8.575613021850586
INFO:root:current mean train loss 2726.9246194037296
INFO:root:current train perplexity8.58924674987793
INFO:root:current mean train loss 2728.7167583138744
INFO:root:current train perplexity8.595827102661133
INFO:root:current mean train loss 2730.368989329751
INFO:root:current train perplexity8.60001277923584
INFO:root:current mean train loss 2729.713943084311
INFO:root:current train perplexity8.59564208984375
INFO:root:current mean train loss 2729.214901347966
INFO:root:current train perplexity8.598878860473633
INFO:root:current mean train loss 2728.6214884376823
INFO:root:current train perplexity8.596390724182129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.70s/it]
INFO:root:final mean train loss: 2727.8354213327934
INFO:root:final train perplexity: 8.59632682800293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2330.436082339456
INFO:root:eval perplexity: 6.584510326385498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.45s/it]
INFO:root:eval mean loss: 2758.0505470654643
INFO:root:eval perplexity: 9.541109085083008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [14:45:39<1:26:02, 573.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2715.1941661005435
INFO:root:current train perplexity8.547688484191895
INFO:root:current mean train loss 2715.855711218429
INFO:root:current train perplexity8.58631420135498
INFO:root:current mean train loss 2723.0837164157774
INFO:root:current train perplexity8.595324516296387
INFO:root:current mean train loss 2721.287460768154
INFO:root:current train perplexity8.602444648742676
INFO:root:current mean train loss 2724.8558283921316
INFO:root:current train perplexity8.59853458404541
INFO:root:current mean train loss 2726.4313271770548
INFO:root:current train perplexity8.620529174804688
INFO:root:current mean train loss 2727.20996207128
INFO:root:current train perplexity8.61080265045166
INFO:root:current mean train loss 2726.8560944830765
INFO:root:current train perplexity8.594986915588379
INFO:root:current mean train loss 2722.564154730903
INFO:root:current train perplexity8.578322410583496
INFO:root:current mean train loss 2723.0444779829545
INFO:root:current train perplexity8.584465980529785
INFO:root:current mean train loss 2727.006067337999
INFO:root:current train perplexity8.590970993041992
INFO:root:current mean train loss 2722.8173898427276
INFO:root:current train perplexity8.570676803588867
INFO:root:current mean train loss 2724.020238787558
INFO:root:current train perplexity8.572139739990234
INFO:root:current mean train loss 2724.0835798923895
INFO:root:current train perplexity8.568157196044922
INFO:root:current mean train loss 2725.9019500183695
INFO:root:current train perplexity8.573531150817871
INFO:root:current mean train loss 2723.8192086559066
INFO:root:current train perplexity8.562026977539062
INFO:root:current mean train loss 2723.8831281325943
INFO:root:current train perplexity8.56299877166748
INFO:root:current mean train loss 2722.2774763074526
INFO:root:current train perplexity8.556035995483398
INFO:root:current mean train loss 2721.2556157633903
INFO:root:current train perplexity8.551165580749512
INFO:root:current mean train loss 2721.5561891028474
INFO:root:current train perplexity8.551593780517578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.95s/it]
INFO:root:final mean train loss: 2721.426095690321
INFO:root:final train perplexity: 8.552984237670898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 2328.5823126177415
INFO:root:eval perplexity: 6.574644565582275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.82s/it]
INFO:root:eval mean loss: 2755.904330639129
INFO:root:eval perplexity: 9.524374961853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [14:55:22<1:16:51, 576.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2707.2990993923613
INFO:root:current train perplexity8.578851699829102
INFO:root:current mean train loss 2711.717638635928
INFO:root:current train perplexity8.605107307434082
INFO:root:current mean train loss 2723.9320323639495
INFO:root:current train perplexity8.63261604309082
INFO:root:current mean train loss 2720.883476320377
INFO:root:current train perplexity8.596662521362305
INFO:root:current mean train loss 2721.06622116715
INFO:root:current train perplexity8.583549499511719
INFO:root:current mean train loss 2716.7928226125387
INFO:root:current train perplexity8.560009956359863
INFO:root:current mean train loss 2720.0858929434153
INFO:root:current train perplexity8.576955795288086
INFO:root:current mean train loss 2724.966425064507
INFO:root:current train perplexity8.596365928649902
INFO:root:current mean train loss 2726.8344239978637
INFO:root:current train perplexity8.599376678466797
INFO:root:current mean train loss 2727.1584259698698
INFO:root:current train perplexity8.593042373657227
INFO:root:current mean train loss 2729.1828514522576
INFO:root:current train perplexity8.592509269714355
INFO:root:current mean train loss 2728.0488747279396
INFO:root:current train perplexity8.58339786529541
INFO:root:current mean train loss 2726.979327687364
INFO:root:current train perplexity8.576417922973633
INFO:root:current mean train loss 2726.5494165343566
INFO:root:current train perplexity8.569652557373047
INFO:root:current mean train loss 2723.878719348086
INFO:root:current train perplexity8.559948921203613
INFO:root:current mean train loss 2724.052452433971
INFO:root:current train perplexity8.557973861694336
INFO:root:current mean train loss 2722.6740759358086
INFO:root:current train perplexity8.55809211730957
INFO:root:current mean train loss 2721.811115613257
INFO:root:current train perplexity8.55186939239502
INFO:root:current mean train loss 2722.3529574956806
INFO:root:current train perplexity8.553400993347168
INFO:root:current mean train loss 2721.729630239509
INFO:root:current train perplexity8.548319816589355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.92s/it]
INFO:root:final mean train loss: 2720.8058583408188
INFO:root:final train perplexity: 8.54880142211914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.91s/it]
INFO:root:eval mean loss: 2328.6261458160184
INFO:root:eval perplexity: 6.574877738952637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it]
INFO:root:eval mean loss: 2755.222486563608
INFO:root:eval perplexity: 9.519064903259277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [15:04:52<1:07:00, 574.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2702.9192443847655
INFO:root:current train perplexity8.445358276367188
INFO:root:current mean train loss 2734.205726453993
INFO:root:current train perplexity8.58229923248291
INFO:root:current mean train loss 2726.4336844308036
INFO:root:current train perplexity8.544416427612305
INFO:root:current mean train loss 2724.6305831106088
INFO:root:current train perplexity8.52431869506836
INFO:root:current mean train loss 2720.261541748047
INFO:root:current train perplexity8.528721809387207
INFO:root:current mean train loss 2720.3411760001345
INFO:root:current train perplexity8.534600257873535
INFO:root:current mean train loss 2721.0857741411996
INFO:root:current train perplexity8.53386402130127
INFO:root:current mean train loss 2721.1855215219352
INFO:root:current train perplexity8.53170394897461
INFO:root:current mean train loss 2719.406931096857
INFO:root:current train perplexity8.534036636352539
INFO:root:current mean train loss 2721.2424448441484
INFO:root:current train perplexity8.539692878723145
INFO:root:current mean train loss 2720.3316182454428
INFO:root:current train perplexity8.537476539611816
INFO:root:current mean train loss 2720.7023689916577
INFO:root:current train perplexity8.536992073059082
INFO:root:current mean train loss 2720.2388677597046
INFO:root:current train perplexity8.538827896118164
INFO:root:current mean train loss 2721.1125735960145
INFO:root:current train perplexity8.538074493408203
INFO:root:current mean train loss 2721.136354518581
INFO:root:current train perplexity8.545668601989746
INFO:root:current mean train loss 2722.364636230469
INFO:root:current train perplexity8.550509452819824
INFO:root:current mean train loss 2722.153788829985
INFO:root:current train perplexity8.549346923828125
INFO:root:current mean train loss 2721.7777334148964
INFO:root:current train perplexity8.54723834991455
INFO:root:current mean train loss 2721.3447888962764
INFO:root:current train perplexity8.545587539672852
INFO:root:current mean train loss 2721.3021068842722
INFO:root:current train perplexity8.547325134277344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.83s/it]
INFO:root:final mean train loss: 2720.6383131741877
INFO:root:final train perplexity: 8.547672271728516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 2327.3239750422485
INFO:root:eval perplexity: 6.567957401275635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.82s/it]
INFO:root:eval mean loss: 2754.29535994293
INFO:root:eval perplexity: 9.511850357055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [15:14:34<57:39, 576.55s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2702.5284033706507
INFO:root:current train perplexity8.493172645568848
INFO:root:current mean train loss 2714.843989183455
INFO:root:current train perplexity8.544122695922852
INFO:root:current mean train loss 2713.8078818786826
INFO:root:current train perplexity8.549654960632324
INFO:root:current mean train loss 2712.7459504634367
INFO:root:current train perplexity8.529043197631836
INFO:root:current mean train loss 2712.177882234815
INFO:root:current train perplexity8.548197746276855
INFO:root:current mean train loss 2713.2643409102807
INFO:root:current train perplexity8.5564603805542
INFO:root:current mean train loss 2713.673953522911
INFO:root:current train perplexity8.551899909973145
INFO:root:current mean train loss 2717.0324801991846
INFO:root:current train perplexity8.552749633789062
INFO:root:current mean train loss 2720.7320939045953
INFO:root:current train perplexity8.564152717590332
INFO:root:current mean train loss 2718.8136408737932
INFO:root:current train perplexity8.551018714904785
INFO:root:current mean train loss 2720.245239814195
INFO:root:current train perplexity8.551812171936035
INFO:root:current mean train loss 2720.1749121746425
INFO:root:current train perplexity8.544320106506348
INFO:root:current mean train loss 2719.4243184768334
INFO:root:current train perplexity8.538795471191406
INFO:root:current mean train loss 2720.0609074062163
INFO:root:current train perplexity8.535001754760742
INFO:root:current mean train loss 2718.8793614246724
INFO:root:current train perplexity8.523219108581543
INFO:root:current mean train loss 2719.91440096421
INFO:root:current train perplexity8.527060508728027
INFO:root:current mean train loss 2718.1155718846676
INFO:root:current train perplexity8.526679039001465
INFO:root:current mean train loss 2718.5497609405434
INFO:root:current train perplexity8.529783248901367
INFO:root:current mean train loss 2719.175745085785
INFO:root:current train perplexity8.531933784484863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.67s/it]
INFO:root:final mean train loss: 2717.7057830918275
INFO:root:final train perplexity: 8.52792739868164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 2327.5331234762853
INFO:root:eval perplexity: 6.569069862365723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.21s/it]
INFO:root:eval mean loss: 2754.444526834691
INFO:root:eval perplexity: 9.513011932373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [15:24:11<48:03, 576.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2814.907244001116
INFO:root:current train perplexity8.896060943603516
INFO:root:current mean train loss 2714.8572162828946
INFO:root:current train perplexity8.607943534851074
INFO:root:current mean train loss 2729.036763699255
INFO:root:current train perplexity8.570026397705078
INFO:root:current mean train loss 2724.2301795133358
INFO:root:current train perplexity8.567001342773438
INFO:root:current mean train loss 2729.0284506387757
INFO:root:current train perplexity8.572043418884277
INFO:root:current mean train loss 2723.7785145800403
INFO:root:current train perplexity8.538506507873535
INFO:root:current mean train loss 2721.7604165341254
INFO:root:current train perplexity8.546039581298828
INFO:root:current mean train loss 2719.904738653274
INFO:root:current train perplexity8.531365394592285
INFO:root:current mean train loss 2719.5000482882565
INFO:root:current train perplexity8.524682998657227
INFO:root:current mean train loss 2718.1453988306894
INFO:root:current train perplexity8.51665210723877
INFO:root:current mean train loss 2714.852924535025
INFO:root:current train perplexity8.503816604614258
INFO:root:current mean train loss 2716.9542082918397
INFO:root:current train perplexity8.505521774291992
INFO:root:current mean train loss 2714.5425892661783
INFO:root:current train perplexity8.496378898620605
INFO:root:current mean train loss 2714.2829357594296
INFO:root:current train perplexity8.496432304382324
INFO:root:current mean train loss 2715.831500149178
INFO:root:current train perplexity8.494232177734375
INFO:root:current mean train loss 2714.503406035853
INFO:root:current train perplexity8.492932319641113
INFO:root:current mean train loss 2713.7818021147964
INFO:root:current train perplexity8.492239952087402
INFO:root:current mean train loss 2712.2250819879487
INFO:root:current train perplexity8.487845420837402
INFO:root:current mean train loss 2711.564094047168
INFO:root:current train perplexity8.482481956481934
INFO:root:current mean train loss 2712.5101172946465
INFO:root:current train perplexity8.488375663757324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.28s/it]
INFO:root:final mean train loss: 2711.3920472453356
INFO:root:final train perplexity: 8.48556900024414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 2324.101321389489
INFO:root:eval perplexity: 6.5508623123168945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it]
INFO:root:eval mean loss: 2752.274544357408
INFO:root:eval perplexity: 9.496143341064453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [15:33:45<38:24, 576.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2731.036361202117
INFO:root:current train perplexity8.428631782531738
INFO:root:current mean train loss 2709.793369438812
INFO:root:current train perplexity8.41235637664795
INFO:root:current mean train loss 2713.0411857836175
INFO:root:current train perplexity8.439437866210938
INFO:root:current mean train loss 2712.3787513571565
INFO:root:current train perplexity8.44979476928711
INFO:root:current mean train loss 2711.3391447487675
INFO:root:current train perplexity8.417267799377441
INFO:root:current mean train loss 2705.4933006157307
INFO:root:current train perplexity8.414310455322266
INFO:root:current mean train loss 2710.406878729819
INFO:root:current train perplexity8.44490909576416
INFO:root:current mean train loss 2712.440232638295
INFO:root:current train perplexity8.442219734191895
INFO:root:current mean train loss 2714.378372137297
INFO:root:current train perplexity8.458324432373047
INFO:root:current mean train loss 2713.3625889500536
INFO:root:current train perplexity8.469914436340332
INFO:root:current mean train loss 2715.5942946396094
INFO:root:current train perplexity8.482111930847168
INFO:root:current mean train loss 2714.6357281564296
INFO:root:current train perplexity8.48451042175293
INFO:root:current mean train loss 2713.282079998794
INFO:root:current train perplexity8.486350059509277
INFO:root:current mean train loss 2711.4600810818347
INFO:root:current train perplexity8.482534408569336
INFO:root:current mean train loss 2709.558499062336
INFO:root:current train perplexity8.468147277832031
INFO:root:current mean train loss 2709.3099209756183
INFO:root:current train perplexity8.468607902526855
INFO:root:current mean train loss 2711.026398621915
INFO:root:current train perplexity8.474889755249023
INFO:root:current mean train loss 2712.5616711066127
INFO:root:current train perplexity8.480219841003418
INFO:root:current mean train loss 2711.463115831726
INFO:root:current train perplexity8.477829933166504
INFO:root:current mean train loss 2711.2171918492686
INFO:root:current train perplexity8.481853485107422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.37s/it]
INFO:root:final mean train loss: 2710.838541112641
INFO:root:final train perplexity: 8.481863021850586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2326.8484246003713
INFO:root:eval perplexity: 6.565433502197266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it]
INFO:root:eval mean loss: 2753.6922451587434
INFO:root:eval perplexity: 9.507159233093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [15:43:28<28:53, 577.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2750.728673299154
INFO:root:current train perplexity8.60341739654541
INFO:root:current mean train loss 2742.6447737410263
INFO:root:current train perplexity8.574020385742188
INFO:root:current mean train loss 2733.695276075794
INFO:root:current train perplexity8.5803861618042
INFO:root:current mean train loss 2724.410416526356
INFO:root:current train perplexity8.57776165008545
INFO:root:current mean train loss 2723.30402810233
INFO:root:current train perplexity8.582015037536621
INFO:root:current mean train loss 2723.922254130788
INFO:root:current train perplexity8.565346717834473
INFO:root:current mean train loss 2717.6737964771414
INFO:root:current train perplexity8.545022964477539
INFO:root:current mean train loss 2718.7709657393675
INFO:root:current train perplexity8.553190231323242
INFO:root:current mean train loss 2721.8282571468712
INFO:root:current train perplexity8.553516387939453
INFO:root:current mean train loss 2721.7942847400777
INFO:root:current train perplexity8.547099113464355
INFO:root:current mean train loss 2720.2179896230914
INFO:root:current train perplexity8.540413856506348
INFO:root:current mean train loss 2721.3951839221063
INFO:root:current train perplexity8.548232078552246
INFO:root:current mean train loss 2722.91465817965
INFO:root:current train perplexity8.552125930786133
INFO:root:current mean train loss 2722.1842964693064
INFO:root:current train perplexity8.540648460388184
INFO:root:current mean train loss 2719.8587993811507
INFO:root:current train perplexity8.53813362121582
INFO:root:current mean train loss 2717.9456675132733
INFO:root:current train perplexity8.533916473388672
INFO:root:current mean train loss 2718.3235642516497
INFO:root:current train perplexity8.53972339630127
INFO:root:current mean train loss 2719.6375803652836
INFO:root:current train perplexity8.540617942810059
INFO:root:current mean train loss 2720.2095733246247
INFO:root:current train perplexity8.54093074798584
INFO:root:current mean train loss 2720.744636175324
INFO:root:current train perplexity8.538763046264648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.62s/it]
INFO:root:final mean train loss: 2719.156986238496
INFO:root:final train perplexity: 8.537693977355957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 2325.7180625969636
INFO:root:eval perplexity: 6.5594329833984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.69s/it]
INFO:root:eval mean loss: 2753.0109482352614
INFO:root:eval perplexity: 9.501866340637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [15:52:58<19:11, 575.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2685.9052959735577
INFO:root:current train perplexity8.42718505859375
INFO:root:current mean train loss 2716.870204486269
INFO:root:current train perplexity8.486373901367188
INFO:root:current mean train loss 2713.9544977152123
INFO:root:current train perplexity8.472447395324707
INFO:root:current mean train loss 2712.3952329034673
INFO:root:current train perplexity8.448862075805664
INFO:root:current mean train loss 2715.161856833837
INFO:root:current train perplexity8.47989559173584
INFO:root:current mean train loss 2712.6404348727874
INFO:root:current train perplexity8.504261016845703
INFO:root:current mean train loss 2714.3819556214758
INFO:root:current train perplexity8.523459434509277
INFO:root:current mean train loss 2715.575194993362
INFO:root:current train perplexity8.531210899353027
INFO:root:current mean train loss 2717.160658078938
INFO:root:current train perplexity8.53840446472168
INFO:root:current mean train loss 2716.733118624514
INFO:root:current train perplexity8.533493995666504
INFO:root:current mean train loss 2719.485763506822
INFO:root:current train perplexity8.541729927062988
INFO:root:current mean train loss 2718.6403833741283
INFO:root:current train perplexity8.537693977355957
INFO:root:current mean train loss 2718.0849258121293
INFO:root:current train perplexity8.535612106323242
INFO:root:current mean train loss 2717.1892597799338
INFO:root:current train perplexity8.538243293762207
INFO:root:current mean train loss 2718.7657469869882
INFO:root:current train perplexity8.539314270019531
INFO:root:current mean train loss 2718.324012829473
INFO:root:current train perplexity8.541805267333984
INFO:root:current mean train loss 2719.316131756757
INFO:root:current train perplexity8.539834022521973
INFO:root:current mean train loss 2718.964710268015
INFO:root:current train perplexity8.538752555847168
INFO:root:current mean train loss 2718.9297118486093
INFO:root:current train perplexity8.536086082458496
INFO:root:current mean train loss 2718.788649013995
INFO:root:current train perplexity8.530900001525879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.56s/it]
INFO:root:final mean train loss: 2717.962540234572
INFO:root:final train perplexity: 8.529653549194336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2326.8602169388573
INFO:root:eval perplexity: 6.565494537353516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it]
INFO:root:eval mean loss: 2754.010643925227
INFO:root:eval perplexity: 9.509634971618652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [16:02:33<09:35, 575.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2701.862072456174
INFO:root:current train perplexity8.511981010437012
INFO:root:current mean train loss 2704.6298707396118
INFO:root:current train perplexity8.523774147033691
INFO:root:current mean train loss 2717.54450891373
INFO:root:current train perplexity8.533411979675293
INFO:root:current mean train loss 2719.9395215099394
INFO:root:current train perplexity8.513731002807617
INFO:root:current mean train loss 2718.32911371888
INFO:root:current train perplexity8.522613525390625
INFO:root:current mean train loss 2718.488798475757
INFO:root:current train perplexity8.531219482421875
INFO:root:current mean train loss 2714.2277205570704
INFO:root:current train perplexity8.51940631866455
INFO:root:current mean train loss 2713.0102564038525
INFO:root:current train perplexity8.514447212219238
INFO:root:current mean train loss 2717.783818182221
INFO:root:current train perplexity8.53411865234375
INFO:root:current mean train loss 2719.9653705666847
INFO:root:current train perplexity8.530524253845215
INFO:root:current mean train loss 2719.3256621581127
INFO:root:current train perplexity8.53091049194336
INFO:root:current mean train loss 2719.151150517859
INFO:root:current train perplexity8.520795822143555
INFO:root:current mean train loss 2720.2397064827906
INFO:root:current train perplexity8.524347305297852
INFO:root:current mean train loss 2721.831015999514
INFO:root:current train perplexity8.535775184631348
INFO:root:current mean train loss 2721.810964648701
INFO:root:current train perplexity8.539304733276367
INFO:root:current mean train loss 2721.185910925401
INFO:root:current train perplexity8.540578842163086
INFO:root:current mean train loss 2722.49389285565
INFO:root:current train perplexity8.545960426330566
INFO:root:current mean train loss 2721.831285401761
INFO:root:current train perplexity8.542112350463867
INFO:root:current mean train loss 2719.559130418313
INFO:root:current train perplexity8.536330223083496
INFO:root:current mean train loss 2719.649789019141
INFO:root:current train perplexity8.535308837890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.16s/it]
INFO:root:final mean train loss: 2718.793837862308
INFO:root:final train perplexity: 8.535249710083008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2326.659723809425
INFO:root:eval perplexity: 6.564430236816406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2754.0973346250275
INFO:root:eval perplexity: 9.510311126708984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [16:12:13<00:00, 576.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [16:12:13<00:00, 583.34s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.72s/it]
INFO:root:eval mean loss: 2326.659723809425
INFO:root:eval perplexity: 6.564430236816406
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.64s/it]
INFO:root:eval mean loss: 2754.0973346250275
INFO:root:eval perplexity: 9.510311126708984
INFO:root:evalaution complete
INFO:root:save model final: alll12_alll12_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14683b600f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14683b5f88e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14683b51de09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14683b601a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14683b51b948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14683b601a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14683b4d6b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14683af3b46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x146937757a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x146937757be0]
python(+0x24a989) [0x55add891f989]
python(+0x24a9bd) [0x55add891f9bd]
python(+0x24aa14) [0x55add891fa14]
python(+0x108f75) [0x55add87ddf75]
python(Py_RunMain+0x313) [0x55add8922983]
python(Py_BytesMain+0x39) [0x55add8922bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x1469377350b3]
python(+0x1d6e13) [0x55add88abe13]
/opt/slurm/data/slurmd/job29854701/slurm_script: line 244: 2485467 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L12-v1 --data_config data_config.json --data_folder fast_processed_data_allminil12_final --output alll12_alll12_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
