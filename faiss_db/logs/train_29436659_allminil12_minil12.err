INFO:root:Output: allminil12_minilml12
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11418.584847498421
INFO:root:current train perplexity8523.7734375
INFO:root:current mean train loss 9455.030462370445
INFO:root:current train perplexity1787.194580078125
INFO:root:current mean train loss 8301.525733565008
INFO:root:current train perplexity716.7615966796875
INFO:root:current mean train loss 7520.970044740759
INFO:root:current train perplexity380.6258239746094
INFO:root:current mean train loss 6938.2023583299415
INFO:root:current train perplexity240.1726531982422
INFO:root:current mean train loss 6488.896933120956
INFO:root:current train perplexity168.4775390625
INFO:root:current mean train loss 6134.322062349115
INFO:root:current train perplexity127.03205871582031
INFO:root:current mean train loss 5853.233134435623
INFO:root:current train perplexity101.21110534667969
INFO:root:current mean train loss 5614.823544987052
INFO:root:current train perplexity83.91695404052734
INFO:root:current mean train loss 5410.897037418277
INFO:root:current train perplexity71.5288314819336
INFO:root:current mean train loss 5237.30041803806
INFO:root:current train perplexity62.25714111328125
INFO:root:current mean train loss 5086.471686406967
INFO:root:current train perplexity55.27543640136719
INFO:root:current mean train loss 4952.682294109953
INFO:root:current train perplexity49.719139099121094
INFO:root:current mean train loss 4834.379982981705
INFO:root:current train perplexity45.29768753051758
INFO:root:current mean train loss 4727.389489640229
INFO:root:current train perplexity41.65977478027344
INFO:root:current mean train loss 4631.886647752257
INFO:root:current train perplexity38.600040435791016
INFO:root:current mean train loss 4544.1735441804
INFO:root:current train perplexity36.013641357421875
INFO:root:current mean train loss 4465.866691076206
INFO:root:current train perplexity33.84584426879883
INFO:root:current mean train loss 4393.416895636889
INFO:root:current train perplexity31.956214904785156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.28s/it]
INFO:root:final mean train loss: 4334.970245561393
INFO:root:final train perplexity: 30.533309936523438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 2830.700719089373
INFO:root:eval perplexity: 9.868071556091309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 3125.1632690429688
INFO:root:eval perplexity: 12.882174491882324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/1
  0%|          | 1/200 [10:41<35:26:24, 641.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2987.8152465820312
INFO:root:current train perplexity10.553285598754883
INFO:root:current mean train loss 3024.5263671875
INFO:root:current train perplexity10.719508171081543
INFO:root:current mean train loss 3003.568913212529
INFO:root:current train perplexity10.57931900024414
INFO:root:current mean train loss 2987.209977162035
INFO:root:current train perplexity10.4480562210083
INFO:root:current mean train loss 2966.2467316847583
INFO:root:current train perplexity10.285451889038086
INFO:root:current mean train loss 2951.208076891049
INFO:root:current train perplexity10.195287704467773
INFO:root:current mean train loss 2939.4974060058594
INFO:root:current train perplexity10.115129470825195
INFO:root:current mean train loss 2925.2977219906597
INFO:root:current train perplexity10.015401840209961
INFO:root:current mean train loss 2911.1497440712124
INFO:root:current train perplexity9.916900634765625
INFO:root:current mean train loss 2904.562372066048
INFO:root:current train perplexity9.851902961730957
INFO:root:current mean train loss 2891.4894245778482
INFO:root:current train perplexity9.755019187927246
INFO:root:current mean train loss 2880.4349290854616
INFO:root:current train perplexity9.676315307617188
INFO:root:current mean train loss 2870.48530960083
INFO:root:current train perplexity9.609402656555176
INFO:root:current mean train loss 2861.947171938818
INFO:root:current train perplexity9.540504455566406
INFO:root:current mean train loss 2855.6057980639785
INFO:root:current train perplexity9.482285499572754
INFO:root:current mean train loss 2845.5760206559717
INFO:root:current train perplexity9.418437004089355
INFO:root:current mean train loss 2836.5256235859183
INFO:root:current train perplexity9.357428550720215
INFO:root:current mean train loss 2828.6822403060805
INFO:root:current train perplexity9.292317390441895
INFO:root:current mean train loss 2818.9615974594317
INFO:root:current train perplexity9.224372863769531
INFO:root:current mean train loss 2811.71917074757
INFO:root:current train perplexity9.176155090332031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.80s/it]
INFO:root:final mean train loss: 2805.7790667081326
INFO:root:final train perplexity: 9.141332626342773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2505.2546564196864
INFO:root:eval perplexity: 7.584470272064209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2842.5450603945037
INFO:root:eval perplexity: 10.22372817993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/2
  1%|          | 2/200 [21:19<35:10:19, 639.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2616.3889382102275
INFO:root:current train perplexity7.924252033233643
INFO:root:current mean train loss 2631.2785626174814
INFO:root:current train perplexity7.967237949371338
INFO:root:current mean train loss 2621.6346891345897
INFO:root:current train perplexity7.940821170806885
INFO:root:current mean train loss 2624.5311869486673
INFO:root:current train perplexity7.912145137786865
INFO:root:current mean train loss 2622.585423846168
INFO:root:current train perplexity7.908294200897217
INFO:root:current mean train loss 2619.111780220304
INFO:root:current train perplexity7.8776092529296875
INFO:root:current mean train loss 2612.9470793376036
INFO:root:current train perplexity7.849804878234863
INFO:root:current mean train loss 2610.9699423921384
INFO:root:current train perplexity7.826794624328613
INFO:root:current mean train loss 2607.3523057660564
INFO:root:current train perplexity7.804084300994873
INFO:root:current mean train loss 2601.322741869306
INFO:root:current train perplexity7.772261619567871
INFO:root:current mean train loss 2594.519005626815
INFO:root:current train perplexity7.738262176513672
INFO:root:current mean train loss 2588.420403045358
INFO:root:current train perplexity7.703140735626221
INFO:root:current mean train loss 2584.7413487492395
INFO:root:current train perplexity7.6833953857421875
INFO:root:current mean train loss 2580.719162639781
INFO:root:current train perplexity7.655513763427734
INFO:root:current mean train loss 2577.050823161091
INFO:root:current train perplexity7.630438327789307
INFO:root:current mean train loss 2571.8688520517367
INFO:root:current train perplexity7.600497722625732
INFO:root:current mean train loss 2568.524449495034
INFO:root:current train perplexity7.57554817199707
INFO:root:current mean train loss 2565.402186530763
INFO:root:current train perplexity7.556223392486572
INFO:root:current mean train loss 2562.93998216295
INFO:root:current train perplexity7.542418479919434
INFO:root:current mean train loss 2560.046434460683
INFO:root:current train perplexity7.524053573608398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.99s/it]
INFO:root:final mean train loss: 2557.7489926582984
INFO:root:final train perplexity: 7.517205715179443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2361.5562657565933
INFO:root:eval perplexity: 6.75233268737793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2719.223164010555
INFO:root:eval perplexity: 9.242897987365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/3
  2%|â–         | 3/200 [32:01<35:02:58, 640.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2439.7865966796876
INFO:root:current train perplexity6.933104991912842
INFO:root:current mean train loss 2453.582049153646
INFO:root:current train perplexity6.997463226318359
INFO:root:current mean train loss 2464.7553759765624
INFO:root:current train perplexity6.989624977111816
INFO:root:current mean train loss 2468.635237862723
INFO:root:current train perplexity6.970269203186035
INFO:root:current mean train loss 2467.7266981336807
INFO:root:current train perplexity6.967957019805908
INFO:root:current mean train loss 2461.468640802557
INFO:root:current train perplexity6.94998025894165
INFO:root:current mean train loss 2457.1327490234376
INFO:root:current train perplexity6.940876007080078
INFO:root:current mean train loss 2452.0380143229168
INFO:root:current train perplexity6.92946720123291
INFO:root:current mean train loss 2450.6460403262868
INFO:root:current train perplexity6.908660411834717
INFO:root:current mean train loss 2447.055707236842
INFO:root:current train perplexity6.888696670532227
INFO:root:current mean train loss 2441.439064360119
INFO:root:current train perplexity6.875315189361572
INFO:root:current mean train loss 2441.216473547894
INFO:root:current train perplexity6.871201992034912
INFO:root:current mean train loss 2441.126359375
INFO:root:current train perplexity6.864844799041748
INFO:root:current mean train loss 2439.1114518229165
INFO:root:current train perplexity6.851312637329102
INFO:root:current mean train loss 2437.897886247306
INFO:root:current train perplexity6.836349010467529
INFO:root:current mean train loss 2435.9751010427167
INFO:root:current train perplexity6.830364227294922
INFO:root:current mean train loss 2434.3947802734374
INFO:root:current train perplexity6.817729949951172
INFO:root:current mean train loss 2432.7122495814733
INFO:root:current train perplexity6.806577205657959
INFO:root:current mean train loss 2430.043857553843
INFO:root:current train perplexity6.797048091888428
INFO:root:current mean train loss 2428.0378649589343
INFO:root:current train perplexity6.783343315124512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.18s/it]
INFO:root:final mean train loss: 2426.669096346041
INFO:root:final train perplexity: 6.778914928436279
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2274.3690358696253
INFO:root:eval perplexity: 6.292611122131348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2640.6005902662346
INFO:root:eval perplexity: 8.667285919189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/4
  2%|â–         | 4/200 [42:29<34:36:05, 635.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2380.246920913013
INFO:root:current train perplexity6.467958450317383
INFO:root:current mean train loss 2360.791585773765
INFO:root:current train perplexity6.392920017242432
INFO:root:current mean train loss 2359.0410041951955
INFO:root:current train perplexity6.41318941116333
INFO:root:current mean train loss 2354.2021946712152
INFO:root:current train perplexity6.396487712860107
INFO:root:current mean train loss 2356.19700344829
INFO:root:current train perplexity6.416530609130859
INFO:root:current mean train loss 2358.1959908836943
INFO:root:current train perplexity6.412544250488281
INFO:root:current mean train loss 2355.2414235997235
INFO:root:current train perplexity6.407773494720459
INFO:root:current mean train loss 2358.2766356785264
INFO:root:current train perplexity6.411342620849609
INFO:root:current mean train loss 2356.088855642211
INFO:root:current train perplexity6.408352851867676
INFO:root:current mean train loss 2354.724926732565
INFO:root:current train perplexity6.398046493530273
INFO:root:current mean train loss 2354.371806036566
INFO:root:current train perplexity6.394937515258789
INFO:root:current mean train loss 2351.9502368394187
INFO:root:current train perplexity6.381415843963623
INFO:root:current mean train loss 2352.4165696141845
INFO:root:current train perplexity6.378030776977539
INFO:root:current mean train loss 2349.7336903525343
INFO:root:current train perplexity6.371836185455322
INFO:root:current mean train loss 2347.5332748527503
INFO:root:current train perplexity6.359316349029541
INFO:root:current mean train loss 2346.96585162856
INFO:root:current train perplexity6.353809833526611
INFO:root:current mean train loss 2343.8436517286386
INFO:root:current train perplexity6.346169471740723
INFO:root:current mean train loss 2344.2010314975946
INFO:root:current train perplexity6.341701507568359
INFO:root:current mean train loss 2342.7876764429275
INFO:root:current train perplexity6.339109897613525
INFO:root:current mean train loss 2341.226659994896
INFO:root:current train perplexity6.332961559295654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.41s/it]
INFO:root:final mean train loss: 2340.0463921358896
INFO:root:final train perplexity: 6.331273078918457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2220.71210106383
INFO:root:eval perplexity: 6.025387287139893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2597.819558001579
INFO:root:eval perplexity: 8.369282722473145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/5
  2%|â–Ž         | 5/200 [53:03<34:24:27, 635.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2288.8177751813614
INFO:root:current train perplexity6.134954452514648
INFO:root:current mean train loss 2306.360163813052
INFO:root:current train perplexity6.132927417755127
INFO:root:current mean train loss 2297.0256897832305
INFO:root:current train perplexity6.10910701751709
INFO:root:current mean train loss 2296.0401442845664
INFO:root:current train perplexity6.115509033203125
INFO:root:current mean train loss 2290.733961373321
INFO:root:current train perplexity6.105231761932373
INFO:root:current mean train loss 2294.7392538410345
INFO:root:current train perplexity6.104836940765381
INFO:root:current mean train loss 2290.1255523503173
INFO:root:current train perplexity6.095301628112793
INFO:root:current mean train loss 2287.435074008241
INFO:root:current train perplexity6.083078861236572
INFO:root:current mean train loss 2287.0777880638434
INFO:root:current train perplexity6.076045513153076
INFO:root:current mean train loss 2284.4302801116696
INFO:root:current train perplexity6.069402694702148
INFO:root:current mean train loss 2283.975629855786
INFO:root:current train perplexity6.063836097717285
INFO:root:current mean train loss 2283.5273263261124
INFO:root:current train perplexity6.057098388671875
INFO:root:current mean train loss 2283.0390049824464
INFO:root:current train perplexity6.049264907836914
INFO:root:current mean train loss 2282.009288809892
INFO:root:current train perplexity6.04469108581543
INFO:root:current mean train loss 2279.396487007244
INFO:root:current train perplexity6.041041851043701
INFO:root:current mean train loss 2277.7474920870077
INFO:root:current train perplexity6.034810543060303
INFO:root:current mean train loss 2277.5144796847167
INFO:root:current train perplexity6.030335426330566
INFO:root:current mean train loss 2277.3480867120716
INFO:root:current train perplexity6.025817394256592
INFO:root:current mean train loss 2276.384781110565
INFO:root:current train perplexity6.022311210632324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.42s/it]
INFO:root:final mean train loss: 2276.469912745889
INFO:root:final train perplexity: 6.021649360656738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2176.1467289484985
INFO:root:eval perplexity: 5.812086582183838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2557.940585954815
INFO:root:eval perplexity: 8.100728034973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/6
  3%|â–Ž         | 6/200 [1:03:26<33:59:55, 630.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2297.537109375
INFO:root:current train perplexity6.087514400482178
INFO:root:current mean train loss 2216.189297213413
INFO:root:current train perplexity5.774342060089111
INFO:root:current mean train loss 2222.739393243742
INFO:root:current train perplexity5.80474853515625
INFO:root:current mean train loss 2225.415725657314
INFO:root:current train perplexity5.794854164123535
INFO:root:current mean train loss 2227.9885022551043
INFO:root:current train perplexity5.8061957359313965
INFO:root:current mean train loss 2233.5570204805235
INFO:root:current train perplexity5.809275150299072
INFO:root:current mean train loss 2234.730967796186
INFO:root:current train perplexity5.81097412109375
INFO:root:current mean train loss 2236.3974450909973
INFO:root:current train perplexity5.817401885986328
INFO:root:current mean train loss 2235.0964072009597
INFO:root:current train perplexity5.811501502990723
INFO:root:current mean train loss 2235.31758752753
INFO:root:current train perplexity5.81263542175293
INFO:root:current mean train loss 2232.8044645783903
INFO:root:current train perplexity5.811152935028076
INFO:root:current mean train loss 2233.242284402319
INFO:root:current train perplexity5.809671878814697
INFO:root:current mean train loss 2232.253621656432
INFO:root:current train perplexity5.808648586273193
INFO:root:current mean train loss 2230.63572426634
INFO:root:current train perplexity5.802276134490967
INFO:root:current mean train loss 2231.0301575534772
INFO:root:current train perplexity5.802868843078613
INFO:root:current mean train loss 2230.314966292003
INFO:root:current train perplexity5.802923202514648
INFO:root:current mean train loss 2229.579908019524
INFO:root:current train perplexity5.800622463226318
INFO:root:current mean train loss 2227.134993188175
INFO:root:current train perplexity5.794292449951172
INFO:root:current mean train loss 2226.7515436709423
INFO:root:current train perplexity5.791554927825928
INFO:root:current mean train loss 2227.530755490018
INFO:root:current train perplexity5.789482593536377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.43s/it]
INFO:root:final mean train loss: 2225.9780283594637
INFO:root:final train perplexity: 5.786573886871338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2144.885125775709
INFO:root:eval perplexity: 5.666984558105469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 2531.9822080355166
INFO:root:eval perplexity: 7.930568695068359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/7
  4%|â–Ž         | 7/200 [1:14:00<33:53:24, 632.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2283.953843858507
INFO:root:current train perplexity5.685667514801025
INFO:root:current mean train loss 2201.5136749784824
INFO:root:current train perplexity5.648858547210693
INFO:root:current mean train loss 2198.0035210005735
INFO:root:current train perplexity5.615124225616455
INFO:root:current mean train loss 2186.2430669436667
INFO:root:current train perplexity5.5938310623168945
INFO:root:current mean train loss 2196.3852994635913
INFO:root:current train perplexity5.627930164337158
INFO:root:current mean train loss 2194.4997676422236
INFO:root:current train perplexity5.6166229248046875
INFO:root:current mean train loss 2195.3973914087783
INFO:root:current train perplexity5.61873197555542
INFO:root:current mean train loss 2196.326686508476
INFO:root:current train perplexity5.6229658126831055
INFO:root:current mean train loss 2191.1611338571115
INFO:root:current train perplexity5.618303298950195
INFO:root:current mean train loss 2192.490335169441
INFO:root:current train perplexity5.6185622215271
INFO:root:current mean train loss 2191.3032082668224
INFO:root:current train perplexity5.617125034332275
INFO:root:current mean train loss 2190.0347101146717
INFO:root:current train perplexity5.617691993713379
INFO:root:current mean train loss 2188.056051821153
INFO:root:current train perplexity5.614269256591797
INFO:root:current mean train loss 2189.4271609779553
INFO:root:current train perplexity5.616008758544922
INFO:root:current mean train loss 2189.591300243383
INFO:root:current train perplexity5.617542266845703
INFO:root:current mean train loss 2188.8791707356772
INFO:root:current train perplexity5.616014003753662
INFO:root:current mean train loss 2187.3908620487773
INFO:root:current train perplexity5.609565258026123
INFO:root:current mean train loss 2188.010428414217
INFO:root:current train perplexity5.610382556915283
INFO:root:current mean train loss 2186.937728025732
INFO:root:current train perplexity5.608315467834473
INFO:root:current mean train loss 2185.7464809000057
INFO:root:current train perplexity5.605041980743408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.97s/it]
INFO:root:final mean train loss: 2184.8464011972865
INFO:root:final train perplexity: 5.6018757820129395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2123.163833942819
INFO:root:eval perplexity: 5.568302631378174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 2513.9535509474736
INFO:root:eval perplexity: 7.8144941329956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/8
  4%|â–         | 8/200 [1:24:21<33:31:21, 628.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.495556640625
INFO:root:current train perplexity5.280224323272705
INFO:root:current mean train loss 2138.4202275028933
INFO:root:current train perplexity5.419349193572998
INFO:root:current mean train loss 2133.378281873338
INFO:root:current train perplexity5.422792911529541
INFO:root:current mean train loss 2145.687196828358
INFO:root:current train perplexity5.43606424331665
INFO:root:current mean train loss 2152.6602308952947
INFO:root:current train perplexity5.4613213539123535
INFO:root:current mean train loss 2150.6363331447137
INFO:root:current train perplexity5.448869705200195
INFO:root:current mean train loss 2150.4108112004797
INFO:root:current train perplexity5.44194221496582
INFO:root:current mean train loss 2149.4221455476722
INFO:root:current train perplexity5.443698406219482
INFO:root:current mean train loss 2147.9960896566245
INFO:root:current train perplexity5.443798065185547
INFO:root:current mean train loss 2151.0526074740974
INFO:root:current train perplexity5.444902420043945
INFO:root:current mean train loss 2151.836846717429
INFO:root:current train perplexity5.446755409240723
INFO:root:current mean train loss 2152.2459878123277
INFO:root:current train perplexity5.450944900512695
INFO:root:current mean train loss 2149.686875415138
INFO:root:current train perplexity5.4485859870910645
INFO:root:current mean train loss 2148.1211674493798
INFO:root:current train perplexity5.445740699768066
INFO:root:current mean train loss 2148.593779007649
INFO:root:current train perplexity5.444708347320557
INFO:root:current mean train loss 2149.578090963457
INFO:root:current train perplexity5.447927474975586
INFO:root:current mean train loss 2150.407970258147
INFO:root:current train perplexity5.449283599853516
INFO:root:current mean train loss 2150.3088696218706
INFO:root:current train perplexity5.449880599975586
INFO:root:current mean train loss 2149.6557154185116
INFO:root:current train perplexity5.4481120109558105
INFO:root:current mean train loss 2150.3302033495843
INFO:root:current train perplexity5.448402404785156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.16s/it]
INFO:root:final mean train loss: 2149.315939360295
INFO:root:final train perplexity: 5.447080612182617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it]
INFO:root:eval mean loss: 2097.7219454717974
INFO:root:eval perplexity: 5.454899787902832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2494.0129234368073
INFO:root:eval perplexity: 7.6880879402160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/9
  4%|â–         | 9/200 [1:34:56<33:27:17, 630.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2087.581456111028
INFO:root:current train perplexity5.313742637634277
INFO:root:current mean train loss 2122.426727294922
INFO:root:current train perplexity5.371246337890625
INFO:root:current mean train loss 2133.2737421913753
INFO:root:current train perplexity5.366346836090088
INFO:root:current mean train loss 2126.2839258367367
INFO:root:current train perplexity5.35352897644043
INFO:root:current mean train loss 2124.0378523294903
INFO:root:current train perplexity5.349008560180664
INFO:root:current mean train loss 2120.9715200230694
INFO:root:current train perplexity5.337310791015625
INFO:root:current mean train loss 2120.7804499901144
INFO:root:current train perplexity5.335934162139893
INFO:root:current mean train loss 2120.235529635815
INFO:root:current train perplexity5.331738471984863
INFO:root:current mean train loss 2123.1562249268723
INFO:root:current train perplexity5.333507061004639
INFO:root:current mean train loss 2121.1919674913424
INFO:root:current train perplexity5.329074382781982
INFO:root:current mean train loss 2121.349774030678
INFO:root:current train perplexity5.327086448669434
INFO:root:current mean train loss 2122.656057357788
INFO:root:current train perplexity5.329883575439453
INFO:root:current mean train loss 2120.6570999096757
INFO:root:current train perplexity5.328381061553955
INFO:root:current mean train loss 2121.483817377034
INFO:root:current train perplexity5.32492208480835
INFO:root:current mean train loss 2121.8575782460616
INFO:root:current train perplexity5.324893474578857
INFO:root:current mean train loss 2121.1594552108922
INFO:root:current train perplexity5.3235764503479
INFO:root:current mean train loss 2122.073995373151
INFO:root:current train perplexity5.3249311447143555
INFO:root:current mean train loss 2122.214536692998
INFO:root:current train perplexity5.3250250816345215
INFO:root:current mean train loss 2121.081815320009
INFO:root:current train perplexity5.322340488433838
INFO:root:current mean train loss 2121.3158890145723
INFO:root:current train perplexity5.322397708892822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.10s/it]
INFO:root:final mean train loss: 2119.4410527816517
INFO:root:final train perplexity: 5.320241451263428
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2082.8199371987203
INFO:root:eval perplexity: 5.389553070068359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2482.115773735317
INFO:root:eval perplexity: 7.613648891448975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/10
  5%|â–Œ         | 10/200 [1:45:18<33:08:22, 627.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2101.6389036316805
INFO:root:current train perplexity5.229938983917236
INFO:root:current mean train loss 2111.168303901627
INFO:root:current train perplexity5.23982048034668
INFO:root:current mean train loss 2108.0421959405494
INFO:root:current train perplexity5.228672981262207
INFO:root:current mean train loss 2103.008232302782
INFO:root:current train perplexity5.217600345611572
INFO:root:current mean train loss 2100.8991204690833
INFO:root:current train perplexity5.216214656829834
INFO:root:current mean train loss 2096.566487344162
INFO:root:current train perplexity5.214320659637451
INFO:root:current mean train loss 2094.166635282371
INFO:root:current train perplexity5.205668926239014
INFO:root:current mean train loss 2096.1425354242015
INFO:root:current train perplexity5.215133190155029
INFO:root:current mean train loss 2094.810714317822
INFO:root:current train perplexity5.2142486572265625
INFO:root:current mean train loss 2094.576459855118
INFO:root:current train perplexity5.214224815368652
INFO:root:current mean train loss 2093.3727548882935
INFO:root:current train perplexity5.210719108581543
INFO:root:current mean train loss 2095.049208746291
INFO:root:current train perplexity5.2109055519104
INFO:root:current mean train loss 2094.7561349710954
INFO:root:current train perplexity5.2134833335876465
INFO:root:current mean train loss 2094.6895053771573
INFO:root:current train perplexity5.210019588470459
INFO:root:current mean train loss 2095.288195709374
INFO:root:current train perplexity5.214048862457275
INFO:root:current mean train loss 2094.484759338651
INFO:root:current train perplexity5.2118964195251465
INFO:root:current mean train loss 2093.4793642660043
INFO:root:current train perplexity5.2091593742370605
INFO:root:current mean train loss 2093.5878205846566
INFO:root:current train perplexity5.207744598388672
INFO:root:current mean train loss 2092.9788036560744
INFO:root:current train perplexity5.205158710479736
INFO:root:current mean train loss 2093.542757033333
INFO:root:current train perplexity5.2108049392700195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.69s/it]
INFO:root:final mean train loss: 2092.912404609099
INFO:root:final train perplexity: 5.210086822509766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2069.0889836304577
INFO:root:eval perplexity: 5.330033779144287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2470.612589085356
INFO:root:eval perplexity: 7.542356967926025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/11
  6%|â–Œ         | 11/200 [1:55:50<33:01:39, 629.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2073.273264330487
INFO:root:current train perplexity5.068289279937744
INFO:root:current mean train loss 2058.968832692792
INFO:root:current train perplexity5.07016134262085
INFO:root:current mean train loss 2059.4484590116913
INFO:root:current train perplexity5.0740275382995605
INFO:root:current mean train loss 2062.760941737674
INFO:root:current train perplexity5.087668418884277
INFO:root:current mean train loss 2058.338672025704
INFO:root:current train perplexity5.095003128051758
INFO:root:current mean train loss 2063.0588972592923
INFO:root:current train perplexity5.099981784820557
INFO:root:current mean train loss 2064.834986383644
INFO:root:current train perplexity5.092921257019043
INFO:root:current mean train loss 2065.1905477198634
INFO:root:current train perplexity5.090808868408203
INFO:root:current mean train loss 2065.731804083486
INFO:root:current train perplexity5.093109607696533
INFO:root:current mean train loss 2067.629506821081
INFO:root:current train perplexity5.09716272354126
INFO:root:current mean train loss 2068.948346835254
INFO:root:current train perplexity5.103781700134277
INFO:root:current mean train loss 2069.683136964126
INFO:root:current train perplexity5.1056694984436035
INFO:root:current mean train loss 2069.704667110651
INFO:root:current train perplexity5.105775833129883
INFO:root:current mean train loss 2069.448216998388
INFO:root:current train perplexity5.107824802398682
INFO:root:current mean train loss 2068.1899193087306
INFO:root:current train perplexity5.109524250030518
INFO:root:current mean train loss 2069.882038977528
INFO:root:current train perplexity5.112267017364502
INFO:root:current mean train loss 2069.048018667056
INFO:root:current train perplexity5.1129961013793945
INFO:root:current mean train loss 2069.447242113137
INFO:root:current train perplexity5.114107131958008
INFO:root:current mean train loss 2069.199953372506
INFO:root:current train perplexity5.115124225616455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.16s/it]
INFO:root:final mean train loss: 2069.5193290614266
INFO:root:final train perplexity: 5.114846706390381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2055.6292447570368
INFO:root:eval perplexity: 5.272329330444336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it]
INFO:root:eval mean loss: 2459.883301646997
INFO:root:eval perplexity: 7.47646427154541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/12
  6%|â–Œ         | 12/200 [2:06:13<32:44:58, 627.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2095.6407063802085
INFO:root:current train perplexity4.855079650878906
INFO:root:current mean train loss 2050.2584832941443
INFO:root:current train perplexity5.040186882019043
INFO:root:current mean train loss 2041.061717667603
INFO:root:current train perplexity5.002757549285889
INFO:root:current mean train loss 2045.5174020697968
INFO:root:current train perplexity5.007584095001221
INFO:root:current mean train loss 2044.4176888667027
INFO:root:current train perplexity5.006817817687988
INFO:root:current mean train loss 2044.8843899493663
INFO:root:current train perplexity5.011358261108398
INFO:root:current mean train loss 2048.673376080211
INFO:root:current train perplexity5.0285844802856445
INFO:root:current mean train loss 2046.0400527802165
INFO:root:current train perplexity5.017038345336914
INFO:root:current mean train loss 2046.0901710443745
INFO:root:current train perplexity5.017416000366211
INFO:root:current mean train loss 2046.7775693705444
INFO:root:current train perplexity5.022106647491455
INFO:root:current mean train loss 2045.587945514044
INFO:root:current train perplexity5.0167927742004395
INFO:root:current mean train loss 2045.6730293004164
INFO:root:current train perplexity5.022569179534912
INFO:root:current mean train loss 2044.4066458406394
INFO:root:current train perplexity5.021293640136719
INFO:root:current mean train loss 2044.971600805533
INFO:root:current train perplexity5.022833824157715
INFO:root:current mean train loss 2046.2146413725611
INFO:root:current train perplexity5.021935939788818
INFO:root:current mean train loss 2046.011074611844
INFO:root:current train perplexity5.020418643951416
INFO:root:current mean train loss 2047.2037905611548
INFO:root:current train perplexity5.025712966918945
INFO:root:current mean train loss 2047.7891716679894
INFO:root:current train perplexity5.027235507965088
INFO:root:current mean train loss 2047.828106516808
INFO:root:current train perplexity5.026247978210449
INFO:root:current mean train loss 2048.8191374690045
INFO:root:current train perplexity5.028339862823486

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.17s/it]
INFO:root:final mean train loss: 2047.65271063808
INFO:root:final train perplexity: 5.027395725250244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2046.6965016033632
INFO:root:eval perplexity: 5.234376907348633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2454.797545953845
INFO:root:eval perplexity: 7.4454345703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/13
  6%|â–‹         | 13/200 [2:16:44<32:38:41, 628.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.9417724609375
INFO:root:current train perplexity4.863759517669678
INFO:root:current mean train loss 2012.5285115559896
INFO:root:current train perplexity4.878483772277832
INFO:root:current mean train loss 2014.1546930486506
INFO:root:current train perplexity4.915673732757568
INFO:root:current mean train loss 2017.7278064727784
INFO:root:current train perplexity4.912957191467285
INFO:root:current mean train loss 2019.1226719447545
INFO:root:current train perplexity4.915903568267822
INFO:root:current mean train loss 2024.4884521484375
INFO:root:current train perplexity4.925107955932617
INFO:root:current mean train loss 2021.4897330991682
INFO:root:current train perplexity4.91782808303833
INFO:root:current mean train loss 2020.3999286227756
INFO:root:current train perplexity4.91981315612793
INFO:root:current mean train loss 2019.5640849788015
INFO:root:current train perplexity4.924918174743652
INFO:root:current mean train loss 2019.6278118631114
INFO:root:current train perplexity4.9294114112854
INFO:root:current mean train loss 2021.423186896829
INFO:root:current train perplexity4.932772159576416
INFO:root:current mean train loss 2022.3394523620605
INFO:root:current train perplexity4.936771869659424
INFO:root:current mean train loss 2022.7983446465164
INFO:root:current train perplexity4.934229373931885
INFO:root:current mean train loss 2025.0240108605587
INFO:root:current train perplexity4.936237335205078
INFO:root:current mean train loss 2025.5536883287027
INFO:root:current train perplexity4.9420390129089355
INFO:root:current mean train loss 2024.6275710256475
INFO:root:current train perplexity4.943335056304932
INFO:root:current mean train loss 2025.2794405713494
INFO:root:current train perplexity4.944798946380615
INFO:root:current mean train loss 2027.1248044036156
INFO:root:current train perplexity4.946003437042236
INFO:root:current mean train loss 2026.4924961635045
INFO:root:current train perplexity4.945918083190918
INFO:root:current mean train loss 2027.124412091573
INFO:root:current train perplexity4.949052810668945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.19s/it]
INFO:root:final mean train loss: 2028.011309048051
INFO:root:final train perplexity: 4.950119972229004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2037.182691641733
INFO:root:eval perplexity: 5.194258689880371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2449.334299073997
INFO:root:eval perplexity: 7.412240982055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/14
  7%|â–‹         | 14/200 [2:27:06<32:22:21, 626.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.5538066142315
INFO:root:current train perplexity4.796643257141113
INFO:root:current mean train loss 2018.7199074404084
INFO:root:current train perplexity4.850311279296875
INFO:root:current mean train loss 2007.9719088912514
INFO:root:current train perplexity4.843849182128906
INFO:root:current mean train loss 2006.0796662735302
INFO:root:current train perplexity4.836907386779785
INFO:root:current mean train loss 2007.6940658185247
INFO:root:current train perplexity4.845192909240723
INFO:root:current mean train loss 2010.510742869457
INFO:root:current train perplexity4.857170104980469
INFO:root:current mean train loss 2007.7715589202928
INFO:root:current train perplexity4.856000900268555
INFO:root:current mean train loss 2006.8133283224327
INFO:root:current train perplexity4.857353687286377
INFO:root:current mean train loss 2007.1915335706485
INFO:root:current train perplexity4.85628604888916
INFO:root:current mean train loss 2004.9355894758455
INFO:root:current train perplexity4.853813648223877
INFO:root:current mean train loss 2004.226510234601
INFO:root:current train perplexity4.855849742889404
INFO:root:current mean train loss 2004.9408574167217
INFO:root:current train perplexity4.859538555145264
INFO:root:current mean train loss 2005.5560958973322
INFO:root:current train perplexity4.861809730529785
INFO:root:current mean train loss 2006.8817364186962
INFO:root:current train perplexity4.865844249725342
INFO:root:current mean train loss 2005.9240435531924
INFO:root:current train perplexity4.862850189208984
INFO:root:current mean train loss 2007.843930365439
INFO:root:current train perplexity4.86759614944458
INFO:root:current mean train loss 2008.216576596623
INFO:root:current train perplexity4.869259357452393
INFO:root:current mean train loss 2008.6324564088811
INFO:root:current train perplexity4.8715314865112305
INFO:root:current mean train loss 2008.6910710716352
INFO:root:current train perplexity4.872895240783691
INFO:root:current mean train loss 2009.228975988259
INFO:root:current train perplexity4.876221179962158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.26s/it]
INFO:root:final mean train loss: 2009.7334078867148
INFO:root:final train perplexity: 4.879275321960449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 2027.644623884918
INFO:root:eval perplexity: 5.154344081878662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2440.746113229305
INFO:root:eval perplexity: 7.3603620529174805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/15
  8%|â–Š         | 15/200 [2:37:42<32:20:05, 629.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1963.8600260416667
INFO:root:current train perplexity4.762293338775635
INFO:root:current mean train loss 1981.1510509144175
INFO:root:current train perplexity4.806317329406738
INFO:root:current mean train loss 1989.5992407611036
INFO:root:current train perplexity4.816310882568359
INFO:root:current mean train loss 1986.5711459574727
INFO:root:current train perplexity4.807060241699219
INFO:root:current mean train loss 1987.6910881681065
INFO:root:current train perplexity4.798177719116211
INFO:root:current mean train loss 1992.5064952864113
INFO:root:current train perplexity4.813488006591797
INFO:root:current mean train loss 1996.1503977177704
INFO:root:current train perplexity4.820045471191406
INFO:root:current mean train loss 1993.2754037386542
INFO:root:current train perplexity4.809401988983154
INFO:root:current mean train loss 1993.3662685421089
INFO:root:current train perplexity4.812604904174805
INFO:root:current mean train loss 1993.0246942868023
INFO:root:current train perplexity4.813858509063721
INFO:root:current mean train loss 1996.0453942894258
INFO:root:current train perplexity4.8169474601745605
INFO:root:current mean train loss 1993.4101090720455
INFO:root:current train perplexity4.812899112701416
INFO:root:current mean train loss 1994.5544242798046
INFO:root:current train perplexity4.816560745239258
INFO:root:current mean train loss 1995.9043115703182
INFO:root:current train perplexity4.8154683113098145
INFO:root:current mean train loss 1995.9811259483538
INFO:root:current train perplexity4.815879821777344
INFO:root:current mean train loss 1995.1052931855545
INFO:root:current train perplexity4.815981388092041
INFO:root:current mean train loss 1993.7469288319746
INFO:root:current train perplexity4.813426971435547
INFO:root:current mean train loss 1993.9235161288707
INFO:root:current train perplexity4.815392971038818
INFO:root:current mean train loss 1994.466008882821
INFO:root:current train perplexity4.816730976104736
INFO:root:current mean train loss 1993.2206656417925
INFO:root:current train perplexity4.814335823059082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.44s/it]
INFO:root:final mean train loss: 1992.7793319017312
INFO:root:final train perplexity: 4.814468860626221
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2024.8325779691656
INFO:root:eval perplexity: 5.142634868621826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 2439.785535447141
INFO:root:eval perplexity: 7.354583740234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/16
  8%|â–Š         | 16/200 [2:48:01<32:00:14, 626.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1998.6722532460387
INFO:root:current train perplexity4.754599094390869
INFO:root:current mean train loss 1981.0039769222863
INFO:root:current train perplexity4.745988845825195
INFO:root:current mean train loss 1978.970745016288
INFO:root:current train perplexity4.753402233123779
INFO:root:current mean train loss 1978.9401180956243
INFO:root:current train perplexity4.750485420227051
INFO:root:current mean train loss 1977.2203239554306
INFO:root:current train perplexity4.75569486618042
INFO:root:current mean train loss 1976.185034650011
INFO:root:current train perplexity4.751356601715088
INFO:root:current mean train loss 1976.0522071622345
INFO:root:current train perplexity4.745047092437744
INFO:root:current mean train loss 1976.8694523713623
INFO:root:current train perplexity4.749327659606934
INFO:root:current mean train loss 1976.4197455667875
INFO:root:current train perplexity4.749303340911865
INFO:root:current mean train loss 1975.876761785128
INFO:root:current train perplexity4.7502946853637695
INFO:root:current mean train loss 1975.475576021424
INFO:root:current train perplexity4.752109527587891
INFO:root:current mean train loss 1975.101132699916
INFO:root:current train perplexity4.750096797943115
INFO:root:current mean train loss 1974.871480610125
INFO:root:current train perplexity4.746923923492432
INFO:root:current mean train loss 1976.2480204308843
INFO:root:current train perplexity4.7505364418029785
INFO:root:current mean train loss 1977.0729192945116
INFO:root:current train perplexity4.753294944763184
INFO:root:current mean train loss 1976.743057144136
INFO:root:current train perplexity4.755019664764404
INFO:root:current mean train loss 1976.6845265542013
INFO:root:current train perplexity4.7554030418396
INFO:root:current mean train loss 1975.8906999929418
INFO:root:current train perplexity4.75197696685791
INFO:root:current mean train loss 1976.1825024244429
INFO:root:current train perplexity4.7532196044921875
INFO:root:current mean train loss 1977.30364157233
INFO:root:current train perplexity4.753806114196777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.07s/it]
INFO:root:final mean train loss: 1977.0527582596603
INFO:root:final train perplexity: 4.755123615264893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2016.9703559604943
INFO:root:eval perplexity: 5.110039234161377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2434.6711572958225
INFO:root:eval perplexity: 7.323885917663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/17
  8%|â–Š         | 17/200 [2:58:32<31:54:09, 627.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.7977170077238
INFO:root:current train perplexity4.710948944091797
INFO:root:current mean train loss 1947.8193872330037
INFO:root:current train perplexity4.66521692276001
INFO:root:current mean train loss 1951.5007175869412
INFO:root:current train perplexity4.677007675170898
INFO:root:current mean train loss 1960.0572270658827
INFO:root:current train perplexity4.685889720916748
INFO:root:current mean train loss 1955.163179241243
INFO:root:current train perplexity4.672492504119873
INFO:root:current mean train loss 1959.6877923044217
INFO:root:current train perplexity4.684041500091553
INFO:root:current mean train loss 1956.5318819977517
INFO:root:current train perplexity4.68043851852417
INFO:root:current mean train loss 1956.394636434952
INFO:root:current train perplexity4.6831464767456055
INFO:root:current mean train loss 1958.0115432051925
INFO:root:current train perplexity4.689017295837402
INFO:root:current mean train loss 1957.6654836060065
INFO:root:current train perplexity4.688053607940674
INFO:root:current mean train loss 1957.779889050652
INFO:root:current train perplexity4.688131809234619
INFO:root:current mean train loss 1959.0516244393807
INFO:root:current train perplexity4.691539764404297
INFO:root:current mean train loss 1960.1905855925186
INFO:root:current train perplexity4.694726467132568
INFO:root:current mean train loss 1959.904800986694
INFO:root:current train perplexity4.695946216583252
INFO:root:current mean train loss 1959.7380232452065
INFO:root:current train perplexity4.696038722991943
INFO:root:current mean train loss 1959.2220307549542
INFO:root:current train perplexity4.694515705108643
INFO:root:current mean train loss 1959.3486305706874
INFO:root:current train perplexity4.6954026222229
INFO:root:current mean train loss 1960.2489318847656
INFO:root:current train perplexity4.694616794586182
INFO:root:current mean train loss 1962.4361276788227
INFO:root:current train perplexity4.697922706604004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.95s/it]
INFO:root:final mean train loss: 1961.5894239216939
INFO:root:final train perplexity: 4.69748592376709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2012.3518005803967
INFO:root:eval perplexity: 5.090989112854004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2434.1974946150544
INFO:root:eval perplexity: 7.321048259735107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/18
  9%|â–‰         | 18/200 [3:08:55<31:39:17, 626.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.41162109375
INFO:root:current train perplexity4.425361156463623
INFO:root:current mean train loss 1917.9018636067708
INFO:root:current train perplexity4.61151647567749
INFO:root:current mean train loss 1927.459902581936
INFO:root:current train perplexity4.602626800537109
INFO:root:current mean train loss 1937.7652139632428
INFO:root:current train perplexity4.617199420928955
INFO:root:current mean train loss 1933.692172429591
INFO:root:current train perplexity4.616267681121826
INFO:root:current mean train loss 1936.0564851968595
INFO:root:current train perplexity4.614655017852783
INFO:root:current mean train loss 1934.7963108535641
INFO:root:current train perplexity4.611515045166016
INFO:root:current mean train loss 1937.0324523492907
INFO:root:current train perplexity4.616113185882568
INFO:root:current mean train loss 1939.5770615477
INFO:root:current train perplexity4.6249566078186035
INFO:root:current mean train loss 1943.9104532652798
INFO:root:current train perplexity4.6332478523254395
INFO:root:current mean train loss 1943.9399346043222
INFO:root:current train perplexity4.633371829986572
INFO:root:current mean train loss 1944.4609035854426
INFO:root:current train perplexity4.634514808654785
INFO:root:current mean train loss 1944.5687238637838
INFO:root:current train perplexity4.636381149291992
INFO:root:current mean train loss 1944.1813035986888
INFO:root:current train perplexity4.635316848754883
INFO:root:current mean train loss 1945.0014585881895
INFO:root:current train perplexity4.634769439697266
INFO:root:current mean train loss 1946.1799709788984
INFO:root:current train perplexity4.6365742683410645
INFO:root:current mean train loss 1947.0357408945433
INFO:root:current train perplexity4.6386871337890625
INFO:root:current mean train loss 1947.9067723607038
INFO:root:current train perplexity4.64226770401001
INFO:root:current mean train loss 1948.088457423498
INFO:root:current train perplexity4.644743919372559
INFO:root:current mean train loss 1948.982294101665
INFO:root:current train perplexity4.648199081420898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.51s/it]
INFO:root:final mean train loss: 1948.239886600804
INFO:root:final train perplexity: 4.648289203643799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2010.0262130845524
INFO:root:eval perplexity: 5.081421852111816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it]
INFO:root:eval mean loss: 2431.8331125678747
INFO:root:eval perplexity: 7.3069071769714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/19
 10%|â–‰         | 19/200 [3:19:18<31:26:31, 625.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1907.3836669921875
INFO:root:current train perplexity4.609034061431885
INFO:root:current mean train loss 1919.1855989049693
INFO:root:current train perplexity4.582398414611816
INFO:root:current mean train loss 1937.5586404886333
INFO:root:current train perplexity4.6164679527282715
INFO:root:current mean train loss 1927.8620779854912
INFO:root:current train perplexity4.591091156005859
INFO:root:current mean train loss 1924.8841144869114
INFO:root:current train perplexity4.580613136291504
INFO:root:current mean train loss 1930.8425599313787
INFO:root:current train perplexity4.5931396484375
INFO:root:current mean train loss 1929.5817511947976
INFO:root:current train perplexity4.587654113769531
INFO:root:current mean train loss 1932.223593418618
INFO:root:current train perplexity4.5970139503479
INFO:root:current mean train loss 1930.5184289045867
INFO:root:current train perplexity4.596625804901123
INFO:root:current mean train loss 1931.7729420692956
INFO:root:current train perplexity4.595713138580322
INFO:root:current mean train loss 1932.8666076062943
INFO:root:current train perplexity4.595087051391602
INFO:root:current mean train loss 1934.3823321609361
INFO:root:current train perplexity4.5960211753845215
INFO:root:current mean train loss 1934.408310810595
INFO:root:current train perplexity4.593754291534424
INFO:root:current mean train loss 1933.8512660039535
INFO:root:current train perplexity4.592324256896973
INFO:root:current mean train loss 1933.0816557678995
INFO:root:current train perplexity4.5896172523498535
INFO:root:current mean train loss 1933.0487747092127
INFO:root:current train perplexity4.589989185333252
INFO:root:current mean train loss 1934.356671315674
INFO:root:current train perplexity4.593214988708496
INFO:root:current mean train loss 1934.0116522564151
INFO:root:current train perplexity4.593203067779541
INFO:root:current mean train loss 1934.6271729453597
INFO:root:current train perplexity4.594825267791748
INFO:root:current mean train loss 1934.7989393982505
INFO:root:current train perplexity4.597170829772949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.50s/it]
INFO:root:final mean train loss: 1934.2553121823587
INFO:root:final train perplexity: 4.597304344177246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2006.2275009696366
INFO:root:eval perplexity: 5.065835952758789
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2430.9479880907857
INFO:root:eval perplexity: 7.301620006561279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/20
 10%|â–ˆ         | 20/200 [3:29:52<31:23:37, 627.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1880.8892759665464
INFO:root:current train perplexity4.458749771118164
INFO:root:current mean train loss 1907.757624564411
INFO:root:current train perplexity4.509864330291748
INFO:root:current mean train loss 1917.6060116819756
INFO:root:current train perplexity4.516244888305664
INFO:root:current mean train loss 1916.4269166119332
INFO:root:current train perplexity4.508485794067383
INFO:root:current mean train loss 1918.6881173031747
INFO:root:current train perplexity4.53057336807251
INFO:root:current mean train loss 1913.9359801226954
INFO:root:current train perplexity4.5251946449279785
INFO:root:current mean train loss 1917.319781427279
INFO:root:current train perplexity4.530905723571777
INFO:root:current mean train loss 1916.7323883428303
INFO:root:current train perplexity4.525110721588135
INFO:root:current mean train loss 1918.4993035153923
INFO:root:current train perplexity4.530961990356445
INFO:root:current mean train loss 1919.961105070429
INFO:root:current train perplexity4.5351715087890625
INFO:root:current mean train loss 1921.1878840691545
INFO:root:current train perplexity4.538487911224365
INFO:root:current mean train loss 1921.5313368103189
INFO:root:current train perplexity4.542925834655762
INFO:root:current mean train loss 1920.1404150469443
INFO:root:current train perplexity4.542287349700928
INFO:root:current mean train loss 1921.5066846942973
INFO:root:current train perplexity4.542130470275879
INFO:root:current mean train loss 1922.813591167776
INFO:root:current train perplexity4.543955326080322
INFO:root:current mean train loss 1922.5946531934037
INFO:root:current train perplexity4.546999454498291
INFO:root:current mean train loss 1923.370263463335
INFO:root:current train perplexity4.547763824462891
INFO:root:current mean train loss 1924.433027200551
INFO:root:current train perplexity4.550999641418457
INFO:root:current mean train loss 1923.1216612209632
INFO:root:current train perplexity4.548913955688477
INFO:root:current mean train loss 1921.8073977253498
INFO:root:current train perplexity4.5506510734558105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.74s/it]
INFO:root:final mean train loss: 1921.7890089134105
INFO:root:final train perplexity: 4.552326679229736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 2001.3079872942985
INFO:root:eval perplexity: 5.045719623565674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2428.5746996724015
INFO:root:eval perplexity: 7.287461757659912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/21
 10%|â–ˆ         | 21/200 [3:40:14<31:07:54, 626.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1912.0237928118024
INFO:root:current train perplexity4.509885787963867
INFO:root:current mean train loss 1914.389642177484
INFO:root:current train perplexity4.487623691558838
INFO:root:current mean train loss 1907.3219537734985
INFO:root:current train perplexity4.482108116149902
INFO:root:current mean train loss 1907.2956320087562
INFO:root:current train perplexity4.484807968139648
INFO:root:current mean train loss 1902.5719243099816
INFO:root:current train perplexity4.491288185119629
INFO:root:current mean train loss 1901.9392553096195
INFO:root:current train perplexity4.486868381500244
INFO:root:current mean train loss 1902.6604647752715
INFO:root:current train perplexity4.4877400398254395
INFO:root:current mean train loss 1906.3937576536148
INFO:root:current train perplexity4.491421222686768
INFO:root:current mean train loss 1902.3296946587964
INFO:root:current train perplexity4.482792377471924
INFO:root:current mean train loss 1904.6640742473523
INFO:root:current train perplexity4.487695693969727
INFO:root:current mean train loss 1904.3863072250829
INFO:root:current train perplexity4.48867654800415
INFO:root:current mean train loss 1904.7067375843087
INFO:root:current train perplexity4.4917449951171875
INFO:root:current mean train loss 1905.6843629095965
INFO:root:current train perplexity4.493597984313965
INFO:root:current mean train loss 1905.7772527373997
INFO:root:current train perplexity4.492280006408691
INFO:root:current mean train loss 1906.1815888960282
INFO:root:current train perplexity4.4923810958862305
INFO:root:current mean train loss 1907.5900798101352
INFO:root:current train perplexity4.496085166931152
INFO:root:current mean train loss 1909.6193412006764
INFO:root:current train perplexity4.5002946853637695
INFO:root:current mean train loss 1909.070230818555
INFO:root:current train perplexity4.501374244689941
INFO:root:current mean train loss 1909.6604208452948
INFO:root:current train perplexity4.504123210906982
INFO:root:current mean train loss 1909.8397705452574
INFO:root:current train perplexity4.507091999053955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.19s/it]
INFO:root:final mean train loss: 1908.9738755372816
INFO:root:final train perplexity: 4.506548881530762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 1997.9754941683289
INFO:root:eval perplexity: 5.032139778137207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2424.926017598903
INFO:root:eval perplexity: 7.265748023986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/22
 11%|â–ˆ         | 22/200 [3:50:48<31:04:35, 628.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1899.8223575957834
INFO:root:current train perplexity4.433089733123779
INFO:root:current mean train loss 1897.5332546344382
INFO:root:current train perplexity4.434955596923828
INFO:root:current mean train loss 1903.4628293662718
INFO:root:current train perplexity4.438333034515381
INFO:root:current mean train loss 1899.0623769478887
INFO:root:current train perplexity4.433495044708252
INFO:root:current mean train loss 1895.5686117740815
INFO:root:current train perplexity4.429044246673584
INFO:root:current mean train loss 1892.784546324512
INFO:root:current train perplexity4.4292216300964355
INFO:root:current mean train loss 1890.4431337353733
INFO:root:current train perplexity4.422882080078125
INFO:root:current mean train loss 1892.2970570790044
INFO:root:current train perplexity4.4303436279296875
INFO:root:current mean train loss 1890.3464447755584
INFO:root:current train perplexity4.4334001541137695
INFO:root:current mean train loss 1892.1306102160681
INFO:root:current train perplexity4.441216945648193
INFO:root:current mean train loss 1894.0464780723948
INFO:root:current train perplexity4.4444708824157715
INFO:root:current mean train loss 1894.0517145207268
INFO:root:current train perplexity4.445712089538574
INFO:root:current mean train loss 1895.126533214632
INFO:root:current train perplexity4.449289798736572
INFO:root:current mean train loss 1895.4646718024512
INFO:root:current train perplexity4.4486260414123535
INFO:root:current mean train loss 1895.5530960279827
INFO:root:current train perplexity4.449660778045654
INFO:root:current mean train loss 1896.1963969313713
INFO:root:current train perplexity4.4502973556518555
INFO:root:current mean train loss 1896.7225312610906
INFO:root:current train perplexity4.453675270080566
INFO:root:current mean train loss 1897.389832816686
INFO:root:current train perplexity4.4597883224487305
INFO:root:current mean train loss 1897.8642848595794
INFO:root:current train perplexity4.464385986328125
INFO:root:current mean train loss 1897.8227304573659
INFO:root:current train perplexity4.465025424957275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.36s/it]
INFO:root:final mean train loss: 1897.161345281327
INFO:root:final train perplexity: 4.4647603034973145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 1996.937903438054
INFO:root:eval perplexity: 5.027919292449951
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it]
INFO:root:eval mean loss: 2426.4376493413397
INFO:root:eval perplexity: 7.2747344970703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/23
 12%|â–ˆâ–        | 23/200 [4:01:11<30:49:18, 626.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.1083455403646
INFO:root:current train perplexity4.337846755981445
INFO:root:current mean train loss 1870.3742765727795
INFO:root:current train perplexity4.374050140380859
INFO:root:current mean train loss 1870.9027975148167
INFO:root:current train perplexity4.382966995239258
INFO:root:current mean train loss 1876.6000701121795
INFO:root:current train perplexity4.391716957092285
INFO:root:current mean train loss 1876.9249838069993
INFO:root:current train perplexity4.394330978393555
INFO:root:current mean train loss 1880.3408869339248
INFO:root:current train perplexity4.397533893585205
INFO:root:current mean train loss 1880.6928434952445
INFO:root:current train perplexity4.402002811431885
INFO:root:current mean train loss 1880.8955771917028
INFO:root:current train perplexity4.408477783203125
INFO:root:current mean train loss 1881.4083977517116
INFO:root:current train perplexity4.4091315269470215
INFO:root:current mean train loss 1879.349422940341
INFO:root:current train perplexity4.405875205993652
INFO:root:current mean train loss 1879.4997601150374
INFO:root:current train perplexity4.401788234710693
INFO:root:current mean train loss 1880.5822790835084
INFO:root:current train perplexity4.407400131225586
INFO:root:current mean train loss 1881.3794730726138
INFO:root:current train perplexity4.412558078765869
INFO:root:current mean train loss 1881.91957647749
INFO:root:current train perplexity4.41525411605835
INFO:root:current mean train loss 1882.9915084941276
INFO:root:current train perplexity4.418736457824707
INFO:root:current mean train loss 1882.6415462853774
INFO:root:current train perplexity4.418976306915283
INFO:root:current mean train loss 1882.7394754443649
INFO:root:current train perplexity4.420205116271973
INFO:root:current mean train loss 1884.2024893478308
INFO:root:current train perplexity4.42039680480957
INFO:root:current mean train loss 1885.0769646861565
INFO:root:current train perplexity4.42262601852417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.38s/it]
INFO:root:final mean train loss: 1885.7376872421935
INFO:root:final train perplexity: 4.424715995788574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 1992.2603478397884
INFO:root:eval perplexity: 5.008934020996094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 2424.9544950444647
INFO:root:eval perplexity: 7.265915870666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/24
 12%|â–ˆâ–        | 24/200 [4:11:42<30:42:03, 627.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.4625941685267
INFO:root:current train perplexity4.3038787841796875
INFO:root:current mean train loss 1860.547419182608
INFO:root:current train perplexity4.330289363861084
INFO:root:current mean train loss 1863.222259963768
INFO:root:current train perplexity4.330256462097168
INFO:root:current mean train loss 1860.7825363109478
INFO:root:current train perplexity4.3344292640686035
INFO:root:current mean train loss 1854.8575031552327
INFO:root:current train perplexity4.322635173797607
INFO:root:current mean train loss 1856.5084700424525
INFO:root:current train perplexity4.331082344055176
INFO:root:current mean train loss 1862.4698249025046
INFO:root:current train perplexity4.345918655395508
INFO:root:current mean train loss 1863.7534369613022
INFO:root:current train perplexity4.353124618530273
INFO:root:current mean train loss 1865.8907373893956
INFO:root:current train perplexity4.35870885848999
INFO:root:current mean train loss 1868.094061164898
INFO:root:current train perplexity4.366369724273682
INFO:root:current mean train loss 1869.7520351921316
INFO:root:current train perplexity4.3717169761657715
INFO:root:current mean train loss 1870.2290663197973
INFO:root:current train perplexity4.37199068069458
INFO:root:current mean train loss 1870.8753997878587
INFO:root:current train perplexity4.372518539428711
INFO:root:current mean train loss 1869.895525277801
INFO:root:current train perplexity4.371307373046875
INFO:root:current mean train loss 1870.99420118298
INFO:root:current train perplexity4.375655174255371
INFO:root:current mean train loss 1872.51422722607
INFO:root:current train perplexity4.378672122955322
INFO:root:current mean train loss 1873.4212511272704
INFO:root:current train perplexity4.382144927978516
INFO:root:current mean train loss 1873.5824808434709
INFO:root:current train perplexity4.38331413269043
INFO:root:current mean train loss 1874.0744367471768
INFO:root:current train perplexity4.38529109954834
INFO:root:current mean train loss 1874.4637698897154
INFO:root:current train perplexity4.385340690612793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.88s/it]
INFO:root:final mean train loss: 1875.006181048433
INFO:root:final train perplexity: 4.387425899505615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 1992.2192958534188
INFO:root:eval perplexity: 5.008768081665039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 2426.6315363890735
INFO:root:eval perplexity: 7.275887966156006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/25
 12%|â–ˆâ–Ž        | 25/200 [4:22:04<30:26:58, 626.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1853.6027119954426
INFO:root:current train perplexity4.342255592346191
INFO:root:current mean train loss 1869.2204196068549
INFO:root:current train perplexity4.34169864654541
INFO:root:current mean train loss 1862.4962561471123
INFO:root:current train perplexity4.317787170410156
INFO:root:current mean train loss 1859.5312910668645
INFO:root:current train perplexity4.313931465148926
INFO:root:current mean train loss 1865.8416854570496
INFO:root:current train perplexity4.339268207550049
INFO:root:current mean train loss 1862.1348173418119
INFO:root:current train perplexity4.334512710571289
INFO:root:current mean train loss 1862.1461162078074
INFO:root:current train perplexity4.334092140197754
INFO:root:current mean train loss 1858.296522783311
INFO:root:current train perplexity4.336361408233643
INFO:root:current mean train loss 1859.8101339988339
INFO:root:current train perplexity4.337179660797119
INFO:root:current mean train loss 1859.3404251693132
INFO:root:current train perplexity4.337654113769531
INFO:root:current mean train loss 1862.031022310257
INFO:root:current train perplexity4.34111213684082
INFO:root:current mean train loss 1861.886905547987
INFO:root:current train perplexity4.338089942932129
INFO:root:current mean train loss 1863.9882488375397
INFO:root:current train perplexity4.3429951667785645
INFO:root:current mean train loss 1864.8378432351658
INFO:root:current train perplexity4.343674182891846
INFO:root:current mean train loss 1864.6998140142205
INFO:root:current train perplexity4.347506999969482
INFO:root:current mean train loss 1864.4431485554053
INFO:root:current train perplexity4.345454692840576
INFO:root:current mean train loss 1865.2398596702537
INFO:root:current train perplexity4.347482681274414
INFO:root:current mean train loss 1865.914846681387
INFO:root:current train perplexity4.3491692543029785
INFO:root:current mean train loss 1864.8177927920692
INFO:root:current train perplexity4.349142551422119
INFO:root:current mean train loss 1864.847619387811
INFO:root:current train perplexity4.3492631912231445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.62s/it]
INFO:root:final mean train loss: 1864.115014980853
INFO:root:final train perplexity: 4.349902153015137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 1989.131970994016
INFO:root:eval perplexity: 4.996277332305908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2423.6619427187225
INFO:root:eval perplexity: 7.258238792419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/26
 13%|â–ˆâ–Ž        | 26/200 [4:32:34<30:19:26, 627.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1822.8041247856327
INFO:root:current train perplexity4.283905982971191
INFO:root:current mean train loss 1831.4018961588542
INFO:root:current train perplexity4.254217147827148
INFO:root:current mean train loss 1835.5973609512773
INFO:root:current train perplexity4.264856338500977
INFO:root:current mean train loss 1835.6747219947076
INFO:root:current train perplexity4.27537202835083
INFO:root:current mean train loss 1839.769726396418
INFO:root:current train perplexity4.28438138961792
INFO:root:current mean train loss 1841.2310454814578
INFO:root:current train perplexity4.2809624671936035
INFO:root:current mean train loss 1846.0311677310842
INFO:root:current train perplexity4.297057628631592
INFO:root:current mean train loss 1847.471942608173
INFO:root:current train perplexity4.296379089355469
INFO:root:current mean train loss 1849.4541552676314
INFO:root:current train perplexity4.298705577850342
INFO:root:current mean train loss 1850.3627535326448
INFO:root:current train perplexity4.3003058433532715
INFO:root:current mean train loss 1850.5187969519243
INFO:root:current train perplexity4.302580833435059
INFO:root:current mean train loss 1850.5546011628026
INFO:root:current train perplexity4.304586887359619
INFO:root:current mean train loss 1849.1275535417506
INFO:root:current train perplexity4.3012003898620605
INFO:root:current mean train loss 1851.158450997827
INFO:root:current train perplexity4.305354595184326
INFO:root:current mean train loss 1850.859948162897
INFO:root:current train perplexity4.305352210998535
INFO:root:current mean train loss 1852.1711477270999
INFO:root:current train perplexity4.308220386505127
INFO:root:current mean train loss 1852.3015327895291
INFO:root:current train perplexity4.307096481323242
INFO:root:current mean train loss 1853.1352643533933
INFO:root:current train perplexity4.3092756271362305
INFO:root:current mean train loss 1853.083045341993
INFO:root:current train perplexity4.309855937957764
INFO:root:current mean train loss 1853.6421585829833
INFO:root:current train perplexity4.3117218017578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it]
INFO:root:final mean train loss: 1853.1834423163293
INFO:root:final train perplexity: 4.312561511993408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 1989.2864137473682
INFO:root:eval perplexity: 4.996901512145996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 2425.2744032406636
INFO:root:eval perplexity: 7.267817497253418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/27
 14%|â–ˆâ–Ž        | 27/200 [4:42:56<30:04:29, 625.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1830.6511777680496
INFO:root:current train perplexity4.198219299316406
INFO:root:current mean train loss 1829.3494417214695
INFO:root:current train perplexity4.228594779968262
INFO:root:current mean train loss 1830.3831484299299
INFO:root:current train perplexity4.244383811950684
INFO:root:current mean train loss 1827.9073632948891
INFO:root:current train perplexity4.2421722412109375
INFO:root:current mean train loss 1829.922819845541
INFO:root:current train perplexity4.24644660949707
INFO:root:current mean train loss 1831.9227174601674
INFO:root:current train perplexity4.249778747558594
INFO:root:current mean train loss 1832.9614302336627
INFO:root:current train perplexity4.253163814544678
INFO:root:current mean train loss 1835.313470926008
INFO:root:current train perplexity4.254014492034912
INFO:root:current mean train loss 1835.7763976339415
INFO:root:current train perplexity4.257553577423096
INFO:root:current mean train loss 1838.4035738823559
INFO:root:current train perplexity4.259521007537842
INFO:root:current mean train loss 1837.5813727856585
INFO:root:current train perplexity4.258127212524414
INFO:root:current mean train loss 1836.8060028655952
INFO:root:current train perplexity4.2567219734191895
INFO:root:current mean train loss 1837.1648258761115
INFO:root:current train perplexity4.25991678237915
INFO:root:current mean train loss 1837.7356561989427
INFO:root:current train perplexity4.2636613845825195
INFO:root:current mean train loss 1838.980943132984
INFO:root:current train perplexity4.269071102142334
INFO:root:current mean train loss 1840.301351877783
INFO:root:current train perplexity4.270699977874756
INFO:root:current mean train loss 1840.7798506825336
INFO:root:current train perplexity4.273521900177002
INFO:root:current mean train loss 1841.986495190513
INFO:root:current train perplexity4.276772975921631
INFO:root:current mean train loss 1842.5149890911978
INFO:root:current train perplexity4.27864408493042
INFO:root:current mean train loss 1844.1206757308757
INFO:root:current train perplexity4.279429912567139

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.83s/it]
INFO:root:final mean train loss: 1843.3317127776038
INFO:root:final train perplexity: 4.279183864593506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 1990.6603445499502
INFO:root:eval perplexity: 5.002457618713379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it]
INFO:root:eval mean loss: 2429.471058514101
INFO:root:eval perplexity: 7.29280424118042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/28
 14%|â–ˆâ–        | 28/200 [4:53:28<29:59:31, 627.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.6396256510416
INFO:root:current train perplexity4.231298446655273
INFO:root:current mean train loss 1826.105991908482
INFO:root:current train perplexity4.212188243865967
INFO:root:current mean train loss 1824.5915709339488
INFO:root:current train perplexity4.207355976104736
INFO:root:current mean train loss 1826.295760091146
INFO:root:current train perplexity4.210360050201416
INFO:root:current mean train loss 1829.3869695723683
INFO:root:current train perplexity4.224231243133545
INFO:root:current mean train loss 1830.3960423743206
INFO:root:current train perplexity4.224719524383545
INFO:root:current mean train loss 1828.270630606192
INFO:root:current train perplexity4.225189685821533
INFO:root:current mean train loss 1831.2071646610384
INFO:root:current train perplexity4.232852458953857
INFO:root:current mean train loss 1832.9941240234375
INFO:root:current train perplexity4.234019756317139
INFO:root:current mean train loss 1834.114366861979
INFO:root:current train perplexity4.240729331970215
INFO:root:current mean train loss 1834.6714953897165
INFO:root:current train perplexity4.237541675567627
INFO:root:current mean train loss 1831.82688061004
INFO:root:current train perplexity4.234570026397705
INFO:root:current mean train loss 1831.9942407705269
INFO:root:current train perplexity4.237294673919678
INFO:root:current mean train loss 1831.826140181108
INFO:root:current train perplexity4.238560676574707
INFO:root:current mean train loss 1833.0340277409957
INFO:root:current train perplexity4.24177360534668
INFO:root:current mean train loss 1833.4203654358878
INFO:root:current train perplexity4.2416887283325195
INFO:root:current mean train loss 1834.1330279996503
INFO:root:current train perplexity4.242905139923096
INFO:root:current mean train loss 1834.1541761113556
INFO:root:current train perplexity4.243885040283203
INFO:root:current mean train loss 1833.9231759765626
INFO:root:current train perplexity4.244314193725586
INFO:root:current mean train loss 1834.3429456339004
INFO:root:current train perplexity4.246973991394043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.30s/it]
INFO:root:final mean train loss: 1833.7589418812347
INFO:root:final train perplexity: 4.246999740600586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.61s/it]
INFO:root:eval mean loss: 1988.7594089372783
INFO:root:eval perplexity: 4.994771957397461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2429.7117660197805
INFO:root:eval perplexity: 7.294240951538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/29
 14%|â–ˆâ–        | 29/200 [5:03:58<29:50:31, 628.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1816.2397049613621
INFO:root:current train perplexity4.169619083404541
INFO:root:current mean train loss 1817.4576587677002
INFO:root:current train perplexity4.177213668823242
INFO:root:current mean train loss 1815.75266213613
INFO:root:current train perplexity4.185093879699707
INFO:root:current mean train loss 1815.4133026745856
INFO:root:current train perplexity4.1922454833984375
INFO:root:current mean train loss 1816.2248299451378
INFO:root:current train perplexity4.194143772125244
INFO:root:current mean train loss 1818.4866662927575
INFO:root:current train perplexity4.18943977355957
INFO:root:current mean train loss 1816.2004292217982
INFO:root:current train perplexity4.188958644866943
INFO:root:current mean train loss 1817.3674149946733
INFO:root:current train perplexity4.192071914672852
INFO:root:current mean train loss 1818.8918810104576
INFO:root:current train perplexity4.194962501525879
INFO:root:current mean train loss 1820.6098830930648
INFO:root:current train perplexity4.20267391204834
INFO:root:current mean train loss 1821.117955581609
INFO:root:current train perplexity4.201904773712158
INFO:root:current mean train loss 1822.263744789482
INFO:root:current train perplexity4.203740119934082
INFO:root:current mean train loss 1822.948779977143
INFO:root:current train perplexity4.207143783569336
INFO:root:current mean train loss 1823.3413758551937
INFO:root:current train perplexity4.2079362869262695
INFO:root:current mean train loss 1822.55993194171
INFO:root:current train perplexity4.207921504974365
INFO:root:current mean train loss 1822.856321248577
INFO:root:current train perplexity4.2117791175842285
INFO:root:current mean train loss 1823.7119874345494
INFO:root:current train perplexity4.21336030960083
INFO:root:current mean train loss 1824.4556712423052
INFO:root:current train perplexity4.213244915008545
INFO:root:current mean train loss 1824.5295190790996
INFO:root:current train perplexity4.213656425476074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.91s/it]
INFO:root:final mean train loss: 1824.137048210571
INFO:root:final train perplexity: 4.214893817901611
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 1988.6914032198858
INFO:root:eval perplexity: 4.994496822357178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2429.388429032995
INFO:root:eval perplexity: 7.29231071472168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/30
 15%|â–ˆâ–Œ        | 30/200 [5:14:33<29:46:03, 630.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1834.602511935764
INFO:root:current train perplexity4.140034198760986
INFO:root:current mean train loss 1793.8536197767346
INFO:root:current train perplexity4.116602420806885
INFO:root:current mean train loss 1791.303144975142
INFO:root:current train perplexity4.113675117492676
INFO:root:current mean train loss 1800.9194134462227
INFO:root:current train perplexity4.1346821784973145
INFO:root:current mean train loss 1801.5430293374657
INFO:root:current train perplexity4.134451389312744
INFO:root:current mean train loss 1802.946008468658
INFO:root:current train perplexity4.135232925415039
INFO:root:current mean train loss 1803.5437512828407
INFO:root:current train perplexity4.145866870880127
INFO:root:current mean train loss 1804.9809899162
INFO:root:current train perplexity4.14572286605835
INFO:root:current mean train loss 1805.3266157944802
INFO:root:current train perplexity4.152304172515869
INFO:root:current mean train loss 1808.6203508534447
INFO:root:current train perplexity4.159529685974121
INFO:root:current mean train loss 1809.2145694849867
INFO:root:current train perplexity4.161922931671143
INFO:root:current mean train loss 1808.7489690617251
INFO:root:current train perplexity4.16765022277832
INFO:root:current mean train loss 1810.0051626957973
INFO:root:current train perplexity4.171661853790283
INFO:root:current mean train loss 1810.6085477381648
INFO:root:current train perplexity4.175479888916016
INFO:root:current mean train loss 1811.6393601124469
INFO:root:current train perplexity4.177066326141357
INFO:root:current mean train loss 1811.6339210019828
INFO:root:current train perplexity4.1772685050964355
INFO:root:current mean train loss 1813.0195416438053
INFO:root:current train perplexity4.180398941040039
INFO:root:current mean train loss 1813.6463370192043
INFO:root:current train perplexity4.179069995880127
INFO:root:current mean train loss 1814.1820980681446
INFO:root:current train perplexity4.180370330810547
INFO:root:current mean train loss 1815.0512876275823
INFO:root:current train perplexity4.182420253753662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.44s/it]
INFO:root:final mean train loss: 1815.0061768316825
INFO:root:final train perplexity: 4.18464994430542
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 1986.774438303413
INFO:root:eval perplexity: 4.986759185791016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.92s/it]
INFO:root:eval mean loss: 2428.035261438248
INFO:root:eval perplexity: 7.284246921539307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/31
 16%|â–ˆâ–Œ        | 31/200 [5:25:00<29:32:41, 629.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.9451669546274
INFO:root:current train perplexity4.107067108154297
INFO:root:current mean train loss 1814.7459639291915
INFO:root:current train perplexity4.1413116455078125
INFO:root:current mean train loss 1805.7963521501658
INFO:root:current train perplexity4.129155158996582
INFO:root:current mean train loss 1801.20050086273
INFO:root:current train perplexity4.130768299102783
INFO:root:current mean train loss 1804.345382188967
INFO:root:current train perplexity4.128952503204346
INFO:root:current mean train loss 1804.276616897873
INFO:root:current train perplexity4.130292892456055
INFO:root:current mean train loss 1801.4589141748204
INFO:root:current train perplexity4.129880905151367
INFO:root:current mean train loss 1799.992235588305
INFO:root:current train perplexity4.129126071929932
INFO:root:current mean train loss 1802.121775038306
INFO:root:current train perplexity4.130879878997803
INFO:root:current mean train loss 1802.1120766295728
INFO:root:current train perplexity4.137510776519775
INFO:root:current mean train loss 1801.9024452373067
INFO:root:current train perplexity4.1375041007995605
INFO:root:current mean train loss 1801.5353011949449
INFO:root:current train perplexity4.141082286834717
INFO:root:current mean train loss 1801.7609783626885
INFO:root:current train perplexity4.142638683319092
INFO:root:current mean train loss 1802.611894472332
INFO:root:current train perplexity4.144258499145508
INFO:root:current mean train loss 1802.0794947384784
INFO:root:current train perplexity4.144198894500732
INFO:root:current mean train loss 1802.8931422402318
INFO:root:current train perplexity4.147205829620361
INFO:root:current mean train loss 1804.138140651426
INFO:root:current train perplexity4.1492204666137695
INFO:root:current mean train loss 1804.2261510961716
INFO:root:current train perplexity4.1472015380859375
INFO:root:current mean train loss 1805.219605561807
INFO:root:current train perplexity4.15193510055542
INFO:root:current mean train loss 1804.8865599825374
INFO:root:current train perplexity4.1515631675720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.92s/it]
INFO:root:final mean train loss: 1805.286847505555
INFO:root:final train perplexity: 4.152696132659912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 1985.7322063040226
INFO:root:eval perplexity: 4.9825592041015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2430.727919125388
INFO:root:eval perplexity: 7.300303936004639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/32
 16%|â–ˆâ–Œ        | 32/200 [5:35:27<29:19:44, 628.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.5060808048693
INFO:root:current train perplexity4.088033676147461
INFO:root:current mean train loss 1796.4415778313482
INFO:root:current train perplexity4.111024856567383
INFO:root:current mean train loss 1799.050295480485
INFO:root:current train perplexity4.093258857727051
INFO:root:current mean train loss 1790.6918785161945
INFO:root:current train perplexity4.083090782165527
INFO:root:current mean train loss 1788.4943850411787
INFO:root:current train perplexity4.095585346221924
INFO:root:current mean train loss 1789.3352005819809
INFO:root:current train perplexity4.100852012634277
INFO:root:current mean train loss 1791.5229617485177
INFO:root:current train perplexity4.109549045562744
INFO:root:current mean train loss 1792.3397757323562
INFO:root:current train perplexity4.114567756652832
INFO:root:current mean train loss 1793.6356835416204
INFO:root:current train perplexity4.118711471557617
INFO:root:current mean train loss 1793.9286614880202
INFO:root:current train perplexity4.115535736083984
INFO:root:current mean train loss 1793.459919155044
INFO:root:current train perplexity4.116440773010254
INFO:root:current mean train loss 1792.3422384854482
INFO:root:current train perplexity4.114162921905518
INFO:root:current mean train loss 1793.468932761747
INFO:root:current train perplexity4.115699768066406
INFO:root:current mean train loss 1794.16005699402
INFO:root:current train perplexity4.1158647537231445
INFO:root:current mean train loss 1795.096780524515
INFO:root:current train perplexity4.119079113006592
INFO:root:current mean train loss 1794.8563414380214
INFO:root:current train perplexity4.119733810424805
INFO:root:current mean train loss 1795.6973132495102
INFO:root:current train perplexity4.121201515197754
INFO:root:current mean train loss 1795.7137528910284
INFO:root:current train perplexity4.120005130767822
INFO:root:current mean train loss 1797.0691017982952
INFO:root:current train perplexity4.123046398162842
INFO:root:current mean train loss 1796.5783545022396
INFO:root:current train perplexity4.12141752243042

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.99s/it]
INFO:root:final mean train loss: 1796.2037964174979
INFO:root:final train perplexity: 4.123054504394531
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 1986.3898843535294
INFO:root:eval perplexity: 4.985209941864014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2431.67677036583
INFO:root:eval perplexity: 7.305972576141357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/33
 16%|â–ˆâ–‹        | 33/200 [5:46:01<29:13:56, 630.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1769.6348815917968
INFO:root:current train perplexity4.051497936248779
INFO:root:current mean train loss 1777.4176872253418
INFO:root:current train perplexity4.084563255310059
INFO:root:current mean train loss 1780.3220956655648
INFO:root:current train perplexity4.082993030548096
INFO:root:current mean train loss 1777.0022132025824
INFO:root:current train perplexity4.077569007873535
INFO:root:current mean train loss 1778.7279830269192
INFO:root:current train perplexity4.083582401275635
INFO:root:current mean train loss 1776.0243719918387
INFO:root:current train perplexity4.073639869689941
INFO:root:current mean train loss 1774.9741268273556
INFO:root:current train perplexity4.074460506439209
INFO:root:current mean train loss 1778.483302869295
INFO:root:current train perplexity4.07427453994751
INFO:root:current mean train loss 1777.402875181686
INFO:root:current train perplexity4.071367263793945
INFO:root:current mean train loss 1779.293811670939
INFO:root:current train perplexity4.0754241943359375
INFO:root:current mean train loss 1780.6857006144974
INFO:root:current train perplexity4.076645851135254
INFO:root:current mean train loss 1781.7396208664466
INFO:root:current train perplexity4.0776214599609375
INFO:root:current mean train loss 1782.5092476012214
INFO:root:current train perplexity4.0805792808532715
INFO:root:current mean train loss 1784.478833725873
INFO:root:current train perplexity4.083970546722412
INFO:root:current mean train loss 1786.3777682369703
INFO:root:current train perplexity4.086600303649902
INFO:root:current mean train loss 1787.5741147554838
INFO:root:current train perplexity4.088852405548096
INFO:root:current mean train loss 1788.4143586308123
INFO:root:current train perplexity4.092034816741943
INFO:root:current mean train loss 1788.521360501376
INFO:root:current train perplexity4.093103885650635
INFO:root:current mean train loss 1788.2869693222867
INFO:root:current train perplexity4.094743728637695
INFO:root:current mean train loss 1788.2723203075175
INFO:root:current train perplexity4.0960469245910645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.03s/it]
INFO:root:final mean train loss: 1787.9583126804891
INFO:root:final train perplexity: 4.096330165863037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 1986.0561345959386
INFO:root:eval perplexity: 4.9838643074035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2433.0229024684177
INFO:root:eval perplexity: 7.314020156860352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/34
 17%|â–ˆâ–‹        | 34/200 [5:56:36<29:07:52, 631.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1771.9683251318993
INFO:root:current train perplexity4.0198259353637695
INFO:root:current mean train loss 1770.8359685348253
INFO:root:current train perplexity4.050117015838623
INFO:root:current mean train loss 1770.8500782660199
INFO:root:current train perplexity4.048494815826416
INFO:root:current mean train loss 1771.4633912104193
INFO:root:current train perplexity4.050064563751221
INFO:root:current mean train loss 1772.58049961306
INFO:root:current train perplexity4.048833847045898
INFO:root:current mean train loss 1772.5509208798203
INFO:root:current train perplexity4.05323600769043
INFO:root:current mean train loss 1771.3238453266363
INFO:root:current train perplexity4.050597667694092
INFO:root:current mean train loss 1772.2503047830196
INFO:root:current train perplexity4.048724174499512
INFO:root:current mean train loss 1775.1899422413946
INFO:root:current train perplexity4.055627346038818
INFO:root:current mean train loss 1776.5819101792397
INFO:root:current train perplexity4.057882785797119
INFO:root:current mean train loss 1775.597386267192
INFO:root:current train perplexity4.056666374206543
INFO:root:current mean train loss 1775.5639869346392
INFO:root:current train perplexity4.061574935913086
INFO:root:current mean train loss 1775.874908710142
INFO:root:current train perplexity4.061508655548096
INFO:root:current mean train loss 1775.6794332533361
INFO:root:current train perplexity4.060988426208496
INFO:root:current mean train loss 1776.7334976971108
INFO:root:current train perplexity4.061906337738037
INFO:root:current mean train loss 1777.68654155066
INFO:root:current train perplexity4.062345504760742
INFO:root:current mean train loss 1777.704717737333
INFO:root:current train perplexity4.061962127685547
INFO:root:current mean train loss 1778.3072865603676
INFO:root:current train perplexity4.06375789642334
INFO:root:current mean train loss 1779.1107069776613
INFO:root:current train perplexity4.064925193786621
INFO:root:current mean train loss 1779.231019270438
INFO:root:current train perplexity4.06671667098999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.53s/it]
INFO:root:final mean train loss: 1778.695814231761
INFO:root:final train perplexity: 4.066515922546387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it]
INFO:root:eval mean loss: 1987.045069484846
INFO:root:eval perplexity: 4.987852573394775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.58s/it]
INFO:root:eval mean loss: 2438.471785741495
INFO:root:eval perplexity: 7.346685886383057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/35
 18%|â–ˆâ–Š        | 35/200 [6:07:18<29:05:48, 634.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1776.63630578873
INFO:root:current train perplexity4.004922389984131
INFO:root:current mean train loss 1769.654800257732
INFO:root:current train perplexity4.007023811340332
INFO:root:current mean train loss 1768.473486245084
INFO:root:current train perplexity4.020847797393799
INFO:root:current mean train loss 1764.739615658213
INFO:root:current train perplexity4.018571376800537
INFO:root:current mean train loss 1766.0546111442782
INFO:root:current train perplexity4.025493144989014
INFO:root:current mean train loss 1765.5028030960648
INFO:root:current train perplexity4.025087356567383
INFO:root:current mean train loss 1769.0467560957763
INFO:root:current train perplexity4.034673690795898
INFO:root:current mean train loss 1772.4980965333261
INFO:root:current train perplexity4.037608623504639
INFO:root:current mean train loss 1771.749485638851
INFO:root:current train perplexity4.032204627990723
INFO:root:current mean train loss 1769.4224230883347
INFO:root:current train perplexity4.026130199432373
INFO:root:current mean train loss 1768.5924868958523
INFO:root:current train perplexity4.029073238372803
INFO:root:current mean train loss 1768.3747990031538
INFO:root:current train perplexity4.0308990478515625
INFO:root:current mean train loss 1769.1259101502126
INFO:root:current train perplexity4.033369064331055
INFO:root:current mean train loss 1769.8159706849108
INFO:root:current train perplexity4.034079074859619
INFO:root:current mean train loss 1770.5431312652956
INFO:root:current train perplexity4.035118579864502
INFO:root:current mean train loss 1771.259680237046
INFO:root:current train perplexity4.036362648010254
INFO:root:current mean train loss 1772.2377299159027
INFO:root:current train perplexity4.037531852722168
INFO:root:current mean train loss 1772.6037788858914
INFO:root:current train perplexity4.038916110992432
INFO:root:current mean train loss 1771.961411408663
INFO:root:current train perplexity4.041085243225098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.88s/it]
INFO:root:final mean train loss: 1770.7269366211922
INFO:root:final train perplexity: 4.041038990020752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 1989.698560782358
INFO:root:eval perplexity: 4.998567581176758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.22s/it]
INFO:root:eval mean loss: 2440.154967828845
INFO:root:eval perplexity: 7.356804847717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/36
 18%|â–ˆâ–Š        | 36/200 [6:17:55<28:56:57, 635.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.2227006392045
INFO:root:current train perplexity3.993914842605591
INFO:root:current mean train loss 1744.5427213101773
INFO:root:current train perplexity3.958059549331665
INFO:root:current mean train loss 1752.1338793135367
INFO:root:current train perplexity3.9844868183135986
INFO:root:current mean train loss 1754.3054850783763
INFO:root:current train perplexity3.987217903137207
INFO:root:current mean train loss 1758.6893574884048
INFO:root:current train perplexity3.990936040878296
INFO:root:current mean train loss 1759.0799402882674
INFO:root:current train perplexity3.9935641288757324
INFO:root:current mean train loss 1759.2908855631777
INFO:root:current train perplexity3.9937384128570557
INFO:root:current mean train loss 1757.0351701567445
INFO:root:current train perplexity3.9925577640533447
INFO:root:current mean train loss 1757.4726931269747
INFO:root:current train perplexity3.9939653873443604
INFO:root:current mean train loss 1759.7624450080611
INFO:root:current train perplexity3.9969513416290283
INFO:root:current mean train loss 1760.4708414955026
INFO:root:current train perplexity4.000567436218262
INFO:root:current mean train loss 1759.629516052191
INFO:root:current train perplexity4.002172946929932
INFO:root:current mean train loss 1759.8361210590745
INFO:root:current train perplexity4.002906322479248
INFO:root:current mean train loss 1760.1721467949978
INFO:root:current train perplexity4.003819942474365
INFO:root:current mean train loss 1760.4037745940102
INFO:root:current train perplexity4.006246566772461
INFO:root:current mean train loss 1761.1755199823688
INFO:root:current train perplexity4.008749485015869
INFO:root:current mean train loss 1760.5662233339638
INFO:root:current train perplexity4.007926940917969
INFO:root:current mean train loss 1761.2529647176132
INFO:root:current train perplexity4.008817672729492
INFO:root:current mean train loss 1762.6129245431564
INFO:root:current train perplexity4.011948585510254
INFO:root:current mean train loss 1762.720631773593
INFO:root:current train perplexity4.013394832611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.04s/it]
INFO:root:final mean train loss: 1762.2978057938276
INFO:root:final train perplexity: 4.014264106750488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 1990.4540227795324
INFO:root:eval perplexity: 5.001622200012207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2443.6242342468695
INFO:root:eval perplexity: 7.377707004547119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/37
 18%|â–ˆâ–Š        | 37/200 [6:28:46<28:58:42, 640.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.1522783551898
INFO:root:current train perplexity3.9617953300476074
INFO:root:current mean train loss 1758.6332473754883
INFO:root:current train perplexity3.975191593170166
INFO:root:current mean train loss 1753.38329114412
INFO:root:current train perplexity3.980011463165283
INFO:root:current mean train loss 1746.8550530410394
INFO:root:current train perplexity3.9752256870269775
INFO:root:current mean train loss 1744.6703146105615
INFO:root:current train perplexity3.9723048210144043
INFO:root:current mean train loss 1746.4588216145833
INFO:root:current train perplexity3.9678518772125244
INFO:root:current mean train loss 1748.243439109462
INFO:root:current train perplexity3.970890760421753
INFO:root:current mean train loss 1748.0669584169493
INFO:root:current train perplexity3.972177505493164
INFO:root:current mean train loss 1750.003079769116
INFO:root:current train perplexity3.974195718765259
INFO:root:current mean train loss 1751.729938901704
INFO:root:current train perplexity3.9740960597991943
INFO:root:current mean train loss 1753.5887237430084
INFO:root:current train perplexity3.9757940769195557
INFO:root:current mean train loss 1754.0120112642328
INFO:root:current train perplexity3.980639696121216
INFO:root:current mean train loss 1753.414572252901
INFO:root:current train perplexity3.9837605953216553
INFO:root:current mean train loss 1753.4619489922582
INFO:root:current train perplexity3.981522560119629
INFO:root:current mean train loss 1754.3113360578607
INFO:root:current train perplexity3.9832956790924072
INFO:root:current mean train loss 1754.5111872488292
INFO:root:current train perplexity3.9826831817626953
INFO:root:current mean train loss 1753.872612655602
INFO:root:current train perplexity3.982300043106079
INFO:root:current mean train loss 1754.6616515406856
INFO:root:current train perplexity3.9825830459594727
INFO:root:current mean train loss 1754.0287559058524
INFO:root:current train perplexity3.9847328662872314
INFO:root:current mean train loss 1754.0376666690304
INFO:root:current train perplexity3.9862146377563477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 552.00s/it]
INFO:root:final mean train loss: 1753.7980826835228
INFO:root:final train perplexity: 3.9874446392059326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.77s/it]
INFO:root:eval mean loss: 1989.5478290530807
INFO:root:eval perplexity: 4.997957229614258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2447.4918433656085
INFO:root:eval perplexity: 7.40108060836792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/38
 19%|â–ˆâ–‰        | 38/200 [6:39:15<28:39:25, 636.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.7941840277779
INFO:root:current train perplexity3.929334878921509
INFO:root:current mean train loss 1737.369324993265
INFO:root:current train perplexity3.937291145324707
INFO:root:current mean train loss 1741.6876629264987
INFO:root:current train perplexity3.9422497749328613
INFO:root:current mean train loss 1745.6283645408741
INFO:root:current train perplexity3.946631669998169
INFO:root:current mean train loss 1742.975205187851
INFO:root:current train perplexity3.950803279876709
INFO:root:current mean train loss 1740.8156149207998
INFO:root:current train perplexity3.9503157138824463
INFO:root:current mean train loss 1741.5413521226988
INFO:root:current train perplexity3.9465670585632324
INFO:root:current mean train loss 1741.5846371644295
INFO:root:current train perplexity3.9493424892425537
INFO:root:current mean train loss 1741.8611680612057
INFO:root:current train perplexity3.9494869709014893
INFO:root:current mean train loss 1740.3572379298942
INFO:root:current train perplexity3.9459593296051025
INFO:root:current mean train loss 1740.1321637167314
INFO:root:current train perplexity3.9468913078308105
INFO:root:current mean train loss 1740.4193891367017
INFO:root:current train perplexity3.947603225708008
INFO:root:current mean train loss 1739.778594750094
INFO:root:current train perplexity3.948453664779663
INFO:root:current mean train loss 1741.463123965352
INFO:root:current train perplexity3.950751781463623
INFO:root:current mean train loss 1742.2708700529845
INFO:root:current train perplexity3.9523708820343018
INFO:root:current mean train loss 1743.4151798581613
INFO:root:current train perplexity3.955681324005127
INFO:root:current mean train loss 1744.665477254108
INFO:root:current train perplexity3.957254648208618
INFO:root:current mean train loss 1745.6620955939961
INFO:root:current train perplexity3.959547996520996
INFO:root:current mean train loss 1746.1300484840785
INFO:root:current train perplexity3.9609761238098145
INFO:root:current mean train loss 1746.3967440803744
INFO:root:current train perplexity3.961954116821289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.96s/it]
INFO:root:final mean train loss: 1746.275296902332
INFO:root:final train perplexity: 3.963857412338257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 1990.7124391379932
INFO:root:eval perplexity: 5.002668380737305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2446.4442450340757
INFO:root:eval perplexity: 7.394741535186768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/39
 20%|â–ˆâ–‰        | 39/200 [6:49:51<28:28:23, 636.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.1061125724545
INFO:root:current train perplexity3.887428045272827
INFO:root:current mean train loss 1732.556180977527
INFO:root:current train perplexity3.8910412788391113
INFO:root:current mean train loss 1726.426248564975
INFO:root:current train perplexity3.8930251598358154
INFO:root:current mean train loss 1726.244665999439
INFO:root:current train perplexity3.8948299884796143
INFO:root:current mean train loss 1727.7062132203735
INFO:root:current train perplexity3.8951549530029297
INFO:root:current mean train loss 1727.5914638967276
INFO:root:current train perplexity3.9027514457702637
INFO:root:current mean train loss 1730.9412118963605
INFO:root:current train perplexity3.912713050842285
INFO:root:current mean train loss 1734.1923541371905
INFO:root:current train perplexity3.9166100025177
INFO:root:current mean train loss 1735.2223997890535
INFO:root:current train perplexity3.917642593383789
INFO:root:current mean train loss 1737.1755789838064
INFO:root:current train perplexity3.9212472438812256
INFO:root:current mean train loss 1740.1809464794094
INFO:root:current train perplexity3.9306087493896484
INFO:root:current mean train loss 1739.2941962814987
INFO:root:current train perplexity3.928800582885742
INFO:root:current mean train loss 1738.470965740609
INFO:root:current train perplexity3.927795648574829
INFO:root:current mean train loss 1739.4060072037616
INFO:root:current train perplexity3.929866075515747
INFO:root:current mean train loss 1740.563799773293
INFO:root:current train perplexity3.9346845149993896
INFO:root:current mean train loss 1741.3730031109956
INFO:root:current train perplexity3.9373958110809326
INFO:root:current mean train loss 1740.482760028862
INFO:root:current train perplexity3.9370882511138916
INFO:root:current mean train loss 1740.5084396864581
INFO:root:current train perplexity3.937962770462036
INFO:root:current mean train loss 1739.9782866284363
INFO:root:current train perplexity3.939115524291992
INFO:root:current mean train loss 1739.396109764729
INFO:root:current train perplexity3.939762592315674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.09s/it]
INFO:root:final mean train loss: 1738.6581957072124
INFO:root:final train perplexity: 3.940117120742798
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 1991.9561490539118
INFO:root:eval perplexity: 5.007702350616455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2448.316450835965
INFO:root:eval perplexity: 7.406072616577148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/40
 20%|â–ˆâ–ˆ        | 40/200 [7:00:14<28:06:35, 632.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.9608756922469
INFO:root:current train perplexity3.9005255699157715
INFO:root:current mean train loss 1717.758326013661
INFO:root:current train perplexity3.8976542949676514
INFO:root:current mean train loss 1719.7289728417618
INFO:root:current train perplexity3.8958380222320557
INFO:root:current mean train loss 1722.3228357159053
INFO:root:current train perplexity3.89976167678833
INFO:root:current mean train loss 1721.3137915497782
INFO:root:current train perplexity3.8985884189605713
INFO:root:current mean train loss 1721.7847714860616
INFO:root:current train perplexity3.8981070518493652
INFO:root:current mean train loss 1720.4483250658711
INFO:root:current train perplexity3.894244909286499
INFO:root:current mean train loss 1723.0410468085586
INFO:root:current train perplexity3.8963372707366943
INFO:root:current mean train loss 1726.8462450116433
INFO:root:current train perplexity3.9019880294799805
INFO:root:current mean train loss 1727.593734413903
INFO:root:current train perplexity3.9067254066467285
INFO:root:current mean train loss 1728.3078310085293
INFO:root:current train perplexity3.91011905670166
INFO:root:current mean train loss 1730.870010233613
INFO:root:current train perplexity3.9120707511901855
INFO:root:current mean train loss 1730.1228289809237
INFO:root:current train perplexity3.9096176624298096
INFO:root:current mean train loss 1730.6368485216303
INFO:root:current train perplexity3.9112813472747803
INFO:root:current mean train loss 1730.5610008213953
INFO:root:current train perplexity3.9109277725219727
INFO:root:current mean train loss 1731.3123224220976
INFO:root:current train perplexity3.9132447242736816
INFO:root:current mean train loss 1730.6148129815924
INFO:root:current train perplexity3.912902355194092
INFO:root:current mean train loss 1731.5251356428296
INFO:root:current train perplexity3.9151289463043213
INFO:root:current mean train loss 1731.6069625683958
INFO:root:current train perplexity3.916717529296875
INFO:root:current mean train loss 1731.6670923604092
INFO:root:current train perplexity3.917182445526123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.46s/it]
INFO:root:final mean train loss: 1731.3017285414796
INFO:root:final train perplexity: 3.917323589324951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 1992.9119526748116
INFO:root:eval perplexity: 5.011575698852539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it]
INFO:root:eval mean loss: 2450.1529774767287
INFO:root:eval perplexity: 7.417206764221191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/41
 20%|â–ˆâ–ˆ        | 41/200 [7:10:54<28:02:06, 634.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.6072095235188
INFO:root:current train perplexity3.85463547706604
INFO:root:current mean train loss 1723.8082406180245
INFO:root:current train perplexity3.8828799724578857
INFO:root:current mean train loss 1731.035591744088
INFO:root:current train perplexity3.8854684829711914
INFO:root:current mean train loss 1727.9629880346433
INFO:root:current train perplexity3.878382682800293
INFO:root:current mean train loss 1722.724389353106
INFO:root:current train perplexity3.8799479007720947
INFO:root:current mean train loss 1724.036521553193
INFO:root:current train perplexity3.878164768218994
INFO:root:current mean train loss 1725.5648526597297
INFO:root:current train perplexity3.881169080734253
INFO:root:current mean train loss 1724.1771977870308
INFO:root:current train perplexity3.8766136169433594
INFO:root:current mean train loss 1723.6928255898613
INFO:root:current train perplexity3.8795371055603027
INFO:root:current mean train loss 1723.3025299439948
INFO:root:current train perplexity3.8807754516601562
INFO:root:current mean train loss 1723.9341157787908
INFO:root:current train perplexity3.8839333057403564
INFO:root:current mean train loss 1724.1103449282439
INFO:root:current train perplexity3.884403705596924
INFO:root:current mean train loss 1724.9886369116512
INFO:root:current train perplexity3.8860766887664795
INFO:root:current mean train loss 1725.789746128727
INFO:root:current train perplexity3.888829231262207
INFO:root:current mean train loss 1725.130514869078
INFO:root:current train perplexity3.8903088569641113
INFO:root:current mean train loss 1725.08550482346
INFO:root:current train perplexity3.8905723094940186
INFO:root:current mean train loss 1724.0207998887547
INFO:root:current train perplexity3.8901126384735107
INFO:root:current mean train loss 1723.4992773654997
INFO:root:current train perplexity3.891822338104248
INFO:root:current mean train loss 1723.8077061649112
INFO:root:current train perplexity3.8918707370758057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.14s/it]
INFO:root:final mean train loss: 1723.6650789215657
INFO:root:final train perplexity: 3.893801689147949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 1994.2546789291057
INFO:root:eval perplexity: 5.017019748687744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 2455.9186145971853
INFO:root:eval perplexity: 7.452262878417969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/42
 21%|â–ˆâ–ˆ        | 42/200 [7:21:18<27:43:16, 631.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1687.6785513070913
INFO:root:current train perplexity3.8331730365753174
INFO:root:current mean train loss 1708.1071852962527
INFO:root:current train perplexity3.8073947429656982
INFO:root:current mean train loss 1697.5976487996993
INFO:root:current train perplexity3.8240396976470947
INFO:root:current mean train loss 1699.2283034644568
INFO:root:current train perplexity3.827892303466797
INFO:root:current mean train loss 1704.0026178613991
INFO:root:current train perplexity3.8338959217071533
INFO:root:current mean train loss 1704.7101398787768
INFO:root:current train perplexity3.8399500846862793
INFO:root:current mean train loss 1708.1299389688265
INFO:root:current train perplexity3.848518133163452
INFO:root:current mean train loss 1710.0280510045034
INFO:root:current train perplexity3.8528952598571777
INFO:root:current mean train loss 1708.7375018318055
INFO:root:current train perplexity3.84946346282959
INFO:root:current mean train loss 1708.0445464385953
INFO:root:current train perplexity3.8498222827911377
INFO:root:current mean train loss 1708.8313338947203
INFO:root:current train perplexity3.8502721786499023
INFO:root:current mean train loss 1710.2887164695994
INFO:root:current train perplexity3.8527719974517822
INFO:root:current mean train loss 1711.5399564411262
INFO:root:current train perplexity3.852811574935913
INFO:root:current mean train loss 1710.388686099492
INFO:root:current train perplexity3.851372003555298
INFO:root:current mean train loss 1710.7206611390327
INFO:root:current train perplexity3.8537344932556152
INFO:root:current mean train loss 1710.6652815088246
INFO:root:current train perplexity3.8530025482177734
INFO:root:current mean train loss 1712.2425624897076
INFO:root:current train perplexity3.8576669692993164
INFO:root:current mean train loss 1713.825879989419
INFO:root:current train perplexity3.8616349697113037
INFO:root:current mean train loss 1714.9940030686578
INFO:root:current train perplexity3.8654463291168213
INFO:root:current mean train loss 1716.6731198236573
INFO:root:current train perplexity3.8697285652160645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.12s/it]
INFO:root:final mean train loss: 1715.7824432480775
INFO:root:final train perplexity: 3.8696694374084473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.96s/it]
INFO:root:eval mean loss: 1996.2372596686614
INFO:root:eval perplexity: 5.025069713592529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2457.519964556322
INFO:root:eval perplexity: 7.462027549743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:31:53<27:35:20, 632.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1703.5921142578125
INFO:root:current train perplexity3.7960216999053955
INFO:root:current mean train loss 1695.0140869140625
INFO:root:current train perplexity3.8032431602478027
INFO:root:current mean train loss 1697.0589212168818
INFO:root:current train perplexity3.8003289699554443
INFO:root:current mean train loss 1700.8771654533618
INFO:root:current train perplexity3.8145992755889893
INFO:root:current mean train loss 1700.5873847429143
INFO:root:current train perplexity3.8128087520599365
INFO:root:current mean train loss 1701.9053351636203
INFO:root:current train perplexity3.8163976669311523
INFO:root:current mean train loss 1701.0735725523934
INFO:root:current train perplexity3.8154478073120117
INFO:root:current mean train loss 1702.6999005043344
INFO:root:current train perplexity3.8246164321899414
INFO:root:current mean train loss 1703.4386651096574
INFO:root:current train perplexity3.8271303176879883
INFO:root:current mean train loss 1702.194162545153
INFO:root:current train perplexity3.825413465499878
INFO:root:current mean train loss 1701.0275452252731
INFO:root:current train perplexity3.8274588584899902
INFO:root:current mean train loss 1700.829496400546
INFO:root:current train perplexity3.826305627822876
INFO:root:current mean train loss 1701.2124083976435
INFO:root:current train perplexity3.8262951374053955
INFO:root:current mean train loss 1701.950569049577
INFO:root:current train perplexity3.8316662311553955
INFO:root:current mean train loss 1703.6015345860194
INFO:root:current train perplexity3.8346481323242188
INFO:root:current mean train loss 1705.7138376672283
INFO:root:current train perplexity3.8365845680236816
INFO:root:current mean train loss 1705.9610373280532
INFO:root:current train perplexity3.838456630706787
INFO:root:current mean train loss 1708.233992207257
INFO:root:current train perplexity3.8420612812042236
INFO:root:current mean train loss 1708.9555643383922
INFO:root:current train perplexity3.843696355819702
INFO:root:current mean train loss 1708.5075313587881
INFO:root:current train perplexity3.8448634147644043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.75s/it]
INFO:root:final mean train loss: 1708.102620104137
INFO:root:final train perplexity: 3.8463029861450195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 1998.9386648624502
INFO:root:eval perplexity: 5.036061763763428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2461.454510627909
INFO:root:eval perplexity: 7.486078262329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:42:22<27:21:19, 631.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.4772481715424
INFO:root:current train perplexity3.759594202041626
INFO:root:current mean train loss 1689.3871929142751
INFO:root:current train perplexity3.7849462032318115
INFO:root:current mean train loss 1691.4046709933261
INFO:root:current train perplexity3.7953104972839355
INFO:root:current mean train loss 1690.8840659193759
INFO:root:current train perplexity3.800067186355591
INFO:root:current mean train loss 1691.8759533500245
INFO:root:current train perplexity3.801943063735962
INFO:root:current mean train loss 1690.0792062260768
INFO:root:current train perplexity3.804370880126953
INFO:root:current mean train loss 1693.5961795199598
INFO:root:current train perplexity3.8074841499328613
INFO:root:current mean train loss 1694.3448636669073
INFO:root:current train perplexity3.810070514678955
INFO:root:current mean train loss 1695.1993351996016
INFO:root:current train perplexity3.8118667602539062
INFO:root:current mean train loss 1695.47123265493
INFO:root:current train perplexity3.8148269653320312
INFO:root:current mean train loss 1696.2332076953498
INFO:root:current train perplexity3.8161823749542236
INFO:root:current mean train loss 1697.4201977304926
INFO:root:current train perplexity3.817037343978882
INFO:root:current mean train loss 1697.298583984375
INFO:root:current train perplexity3.816418170928955
INFO:root:current mean train loss 1698.3651310638224
INFO:root:current train perplexity3.818009853363037
INFO:root:current mean train loss 1699.2264888528798
INFO:root:current train perplexity3.8179616928100586
INFO:root:current mean train loss 1700.399885220765
INFO:root:current train perplexity3.821197271347046
INFO:root:current mean train loss 1700.8865688117837
INFO:root:current train perplexity3.823164224624634
INFO:root:current mean train loss 1701.721147874593
INFO:root:current train perplexity3.8234376907348633
INFO:root:current mean train loss 1701.560996823396
INFO:root:current train perplexity3.8241195678710938
INFO:root:current mean train loss 1702.0478128786876
INFO:root:current train perplexity3.8259060382843018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.47s/it]
INFO:root:final mean train loss: 1701.514548897563
INFO:root:final train perplexity: 3.82637095451355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 1998.2573774621842
INFO:root:eval perplexity: 5.033287048339844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2463.311354616855
INFO:root:eval perplexity: 7.497456073760986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:52:46<27:05:29, 629.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1705.6254978179932
INFO:root:current train perplexity3.8058273792266846
INFO:root:current mean train loss 1690.7428052948742
INFO:root:current train perplexity3.763909101486206
INFO:root:current mean train loss 1685.2263951157079
INFO:root:current train perplexity3.7657437324523926
INFO:root:current mean train loss 1681.9695836999915
INFO:root:current train perplexity3.7585177421569824
INFO:root:current mean train loss 1679.6783002656082
INFO:root:current train perplexity3.76279878616333
INFO:root:current mean train loss 1683.59309917477
INFO:root:current train perplexity3.7721645832061768
INFO:root:current mean train loss 1686.449114696089
INFO:root:current train perplexity3.773669958114624
INFO:root:current mean train loss 1685.4508612667703
INFO:root:current train perplexity3.7794852256774902
INFO:root:current mean train loss 1688.6400667826335
INFO:root:current train perplexity3.7837562561035156
INFO:root:current mean train loss 1690.2047667443999
INFO:root:current train perplexity3.7854037284851074
INFO:root:current mean train loss 1690.4319016306024
INFO:root:current train perplexity3.788893699645996
INFO:root:current mean train loss 1691.4769676182277
INFO:root:current train perplexity3.7912633419036865
INFO:root:current mean train loss 1690.8439106035837
INFO:root:current train perplexity3.7912967205047607
INFO:root:current mean train loss 1690.9157035581527
INFO:root:current train perplexity3.794602394104004
INFO:root:current mean train loss 1690.725378484674
INFO:root:current train perplexity3.7958426475524902
INFO:root:current mean train loss 1690.7323860500169
INFO:root:current train perplexity3.797184467315674
INFO:root:current mean train loss 1692.090213262118
INFO:root:current train perplexity3.799900531768799
INFO:root:current mean train loss 1692.914268787756
INFO:root:current train perplexity3.800468683242798
INFO:root:current mean train loss 1693.7141400775172
INFO:root:current train perplexity3.8017070293426514
INFO:root:current mean train loss 1694.4897402512809
INFO:root:current train perplexity3.803955078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.39s/it]
INFO:root:final mean train loss: 1694.2235378278847
INFO:root:final train perplexity: 3.804431200027466
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.43s/it]
INFO:root:eval mean loss: 2001.2377501142787
INFO:root:eval perplexity: 5.0454325675964355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 2465.2500238080397
INFO:root:eval perplexity: 7.509352684020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [8:03:23<27:01:02, 631.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.7003565658758
INFO:root:current train perplexity3.7366795539855957
INFO:root:current mean train loss 1673.523757175846
INFO:root:current train perplexity3.743025779724121
INFO:root:current mean train loss 1667.9550759529304
INFO:root:current train perplexity3.7396583557128906
INFO:root:current mean train loss 1672.268800109703
INFO:root:current train perplexity3.7427420616149902
INFO:root:current mean train loss 1672.9397330492302
INFO:root:current train perplexity3.7575936317443848
INFO:root:current mean train loss 1675.337109879249
INFO:root:current train perplexity3.7560808658599854
INFO:root:current mean train loss 1676.0179843090355
INFO:root:current train perplexity3.75569486618042
INFO:root:current mean train loss 1677.146649896717
INFO:root:current train perplexity3.7596218585968018
INFO:root:current mean train loss 1677.4003174659479
INFO:root:current train perplexity3.764864921569824
INFO:root:current mean train loss 1679.345007411323
INFO:root:current train perplexity3.7685375213623047
INFO:root:current mean train loss 1680.4948049539994
INFO:root:current train perplexity3.7715189456939697
INFO:root:current mean train loss 1682.0569391339436
INFO:root:current train perplexity3.774418592453003
INFO:root:current mean train loss 1682.857236816025
INFO:root:current train perplexity3.7743048667907715
INFO:root:current mean train loss 1684.1101558610721
INFO:root:current train perplexity3.7750017642974854
INFO:root:current mean train loss 1684.955798348086
INFO:root:current train perplexity3.774374485015869
INFO:root:current mean train loss 1686.1922261517384
INFO:root:current train perplexity3.776245355606079
INFO:root:current mean train loss 1687.3930088204334
INFO:root:current train perplexity3.778571128845215
INFO:root:current mean train loss 1687.7796040727208
INFO:root:current train perplexity3.7794907093048096
INFO:root:current mean train loss 1687.1320304323042
INFO:root:current train perplexity3.7814748287200928
INFO:root:current mean train loss 1687.7297909855542
INFO:root:current train perplexity3.783781051635742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.94s/it]
INFO:root:final mean train loss: 1687.3739458739126
INFO:root:final train perplexity: 3.783935308456421
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it]
INFO:root:eval mean loss: 2001.9898452217697
INFO:root:eval perplexity: 5.04850435256958
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.65s/it]
INFO:root:eval mean loss: 2469.867840706034
INFO:root:eval perplexity: 7.537765979766846
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [8:13:57<26:52:00, 632.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.4840224908323
INFO:root:current train perplexity3.7277917861938477
INFO:root:current mean train loss 1667.760680535827
INFO:root:current train perplexity3.720550060272217
INFO:root:current mean train loss 1664.5998150102243
INFO:root:current train perplexity3.7152369022369385
INFO:root:current mean train loss 1665.8477154449004
INFO:root:current train perplexity3.7299489974975586
INFO:root:current mean train loss 1666.4705384036145
INFO:root:current train perplexity3.7343709468841553
INFO:root:current mean train loss 1668.7989465209553
INFO:root:current train perplexity3.7385499477386475
INFO:root:current mean train loss 1671.1061035855794
INFO:root:current train perplexity3.742541551589966
INFO:root:current mean train loss 1672.0506227727521
INFO:root:current train perplexity3.7445199489593506
INFO:root:current mean train loss 1675.111420425381
INFO:root:current train perplexity3.7502505779266357
INFO:root:current mean train loss 1675.7490041117392
INFO:root:current train perplexity3.747509717941284
INFO:root:current mean train loss 1676.4581894726919
INFO:root:current train perplexity3.7486445903778076
INFO:root:current mean train loss 1679.129804149494
INFO:root:current train perplexity3.752513885498047
INFO:root:current mean train loss 1679.5867203299547
INFO:root:current train perplexity3.7520740032196045
INFO:root:current mean train loss 1679.6685406817217
INFO:root:current train perplexity3.7550008296966553
INFO:root:current mean train loss 1680.0004280609824
INFO:root:current train perplexity3.7577757835388184
INFO:root:current mean train loss 1680.6759267718683
INFO:root:current train perplexity3.760021686553955
INFO:root:current mean train loss 1680.544412817354
INFO:root:current train perplexity3.7620060443878174
INFO:root:current mean train loss 1681.441944160504
INFO:root:current train perplexity3.7622792720794678
INFO:root:current mean train loss 1681.354168617562
INFO:root:current train perplexity3.764089822769165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.76s/it]
INFO:root:final mean train loss: 1680.9277908856136
INFO:root:final train perplexity: 3.7647476196289062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2003.5240751225897
INFO:root:eval perplexity: 5.054770469665527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2473.2635091145835
INFO:root:eval perplexity: 7.558728218078613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/48
 24%|â–ˆâ–ˆâ–       | 48/200 [8:24:40<26:49:56, 635.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1647.673494466146
INFO:root:current train perplexity3.6762425899505615
INFO:root:current mean train loss 1668.1491773522418
INFO:root:current train perplexity3.710010051727295
INFO:root:current mean train loss 1657.6695119458575
INFO:root:current train perplexity3.704644203186035
INFO:root:current mean train loss 1664.026818266369
INFO:root:current train perplexity3.7155299186706543
INFO:root:current mean train loss 1665.3080289909637
INFO:root:current train perplexity3.716066837310791
INFO:root:current mean train loss 1664.6056484185376
INFO:root:current train perplexity3.7156567573547363
INFO:root:current mean train loss 1664.3644582856962
INFO:root:current train perplexity3.7157297134399414
INFO:root:current mean train loss 1665.0455556162588
INFO:root:current train perplexity3.7168405055999756
INFO:root:current mean train loss 1663.2044683725555
INFO:root:current train perplexity3.7163991928100586
INFO:root:current mean train loss 1663.4827183124146
INFO:root:current train perplexity3.7179548740386963
INFO:root:current mean train loss 1663.845843596059
INFO:root:current train perplexity3.7211899757385254
INFO:root:current mean train loss 1665.422922177165
INFO:root:current train perplexity3.723426103591919
INFO:root:current mean train loss 1666.36100039384
INFO:root:current train perplexity3.724091053009033
INFO:root:current mean train loss 1666.9775235600346
INFO:root:current train perplexity3.726357936859131
INFO:root:current mean train loss 1669.4678693683745
INFO:root:current train perplexity3.731198787689209
INFO:root:current mean train loss 1670.098463928424
INFO:root:current train perplexity3.734060764312744
INFO:root:current mean train loss 1670.294823538482
INFO:root:current train perplexity3.734353542327881
INFO:root:current mean train loss 1670.797788641126
INFO:root:current train perplexity3.735680341720581
INFO:root:current mean train loss 1671.3972515684186
INFO:root:current train perplexity3.7381184101104736
INFO:root:current mean train loss 1672.646019487904
INFO:root:current train perplexity3.7392055988311768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.75s/it]
INFO:root:final mean train loss: 1672.8774628285742
INFO:root:final train perplexity: 3.7409207820892334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 2008.0710081276318
INFO:root:eval perplexity: 5.073392868041992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2479.046428274601
INFO:root:eval perplexity: 7.59456205368042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:35:16<26:39:29, 635.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1650.8948020935059
INFO:root:current train perplexity3.714528799057007
INFO:root:current mean train loss 1654.9808636289654
INFO:root:current train perplexity3.6816177368164062
INFO:root:current mean train loss 1659.1173248291016
INFO:root:current train perplexity3.6826109886169434
INFO:root:current mean train loss 1657.6773494122976
INFO:root:current train perplexity3.682304620742798
INFO:root:current mean train loss 1660.8416278980396
INFO:root:current train perplexity3.6902284622192383
INFO:root:current mean train loss 1661.2733753175664
INFO:root:current train perplexity3.6854195594787598
INFO:root:current mean train loss 1664.1239403833317
INFO:root:current train perplexity3.6949658393859863
INFO:root:current mean train loss 1665.1484830262232
INFO:root:current train perplexity3.7000784873962402
INFO:root:current mean train loss 1665.109891451322
INFO:root:current train perplexity3.7018251419067383
INFO:root:current mean train loss 1665.8426876477417
INFO:root:current train perplexity3.704963207244873
INFO:root:current mean train loss 1665.6555134381435
INFO:root:current train perplexity3.708200693130493
INFO:root:current mean train loss 1665.104736543797
INFO:root:current train perplexity3.7088749408721924
INFO:root:current mean train loss 1665.4443028437627
INFO:root:current train perplexity3.7101478576660156
INFO:root:current mean train loss 1665.3011965823246
INFO:root:current train perplexity3.712000608444214
INFO:root:current mean train loss 1665.6144904450998
INFO:root:current train perplexity3.7139265537261963
INFO:root:current mean train loss 1665.7647967226512
INFO:root:current train perplexity3.7149999141693115
INFO:root:current mean train loss 1664.9838272543514
INFO:root:current train perplexity3.7173421382904053
INFO:root:current mean train loss 1665.2464405791038
INFO:root:current train perplexity3.7172582149505615
INFO:root:current mean train loss 1666.2213990990251
INFO:root:current train perplexity3.7194182872772217
INFO:root:current mean train loss 1666.7534252980233
INFO:root:current train perplexity3.721036672592163

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.53s/it]
INFO:root:final mean train loss: 1666.3358870528891
INFO:root:final train perplexity: 3.7216708660125732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 2010.067568948083
INFO:root:eval perplexity: 5.081592082977295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 2484.9453159629875
INFO:root:eval perplexity: 7.631287574768066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:45:57<26:33:05, 637.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1632.082442303093
INFO:root:current train perplexity3.6482784748077393
INFO:root:current mean train loss 1648.138199979027
INFO:root:current train perplexity3.6572763919830322
INFO:root:current mean train loss 1647.9129619062187
INFO:root:current train perplexity3.6614253520965576
INFO:root:current mean train loss 1647.4633086021445
INFO:root:current train perplexity3.668903350830078
INFO:root:current mean train loss 1648.702203355547
INFO:root:current train perplexity3.672201156616211
INFO:root:current mean train loss 1648.8226038198002
INFO:root:current train perplexity3.675670862197876
INFO:root:current mean train loss 1651.1057463706184
INFO:root:current train perplexity3.67698335647583
INFO:root:current mean train loss 1652.3725520746411
INFO:root:current train perplexity3.678241491317749
INFO:root:current mean train loss 1652.064948882877
INFO:root:current train perplexity3.675995111465454
INFO:root:current mean train loss 1652.2660762356757
INFO:root:current train perplexity3.678502082824707
INFO:root:current mean train loss 1653.1428821952827
INFO:root:current train perplexity3.6839897632598877
INFO:root:current mean train loss 1653.067147277354
INFO:root:current train perplexity3.684380054473877
INFO:root:current mean train loss 1655.375095193342
INFO:root:current train perplexity3.689429759979248
INFO:root:current mean train loss 1655.647254078542
INFO:root:current train perplexity3.6921751499176025
INFO:root:current mean train loss 1655.7015660551187
INFO:root:current train perplexity3.692856550216675
INFO:root:current mean train loss 1656.6509351736504
INFO:root:current train perplexity3.6962509155273438
INFO:root:current mean train loss 1657.380853674931
INFO:root:current train perplexity3.6980831623077393
INFO:root:current mean train loss 1658.1767087470741
INFO:root:current train perplexity3.699526309967041
INFO:root:current mean train loss 1658.856692357989
INFO:root:current train perplexity3.7000210285186768
INFO:root:current mean train loss 1660.29668127836
INFO:root:current train perplexity3.703284740447998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.70s/it]
INFO:root:final mean train loss: 1659.998050383829
INFO:root:final train perplexity: 3.703115224838257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2008.8259000304743
INFO:root:eval perplexity: 5.076491355895996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2482.1418141033632
INFO:root:eval perplexity: 7.613810062408447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [8:56:33<26:21:46, 636.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1622.183310768821
INFO:root:current train perplexity3.6141865253448486
INFO:root:current mean train loss 1634.3516022096198
INFO:root:current train perplexity3.618683099746704
INFO:root:current mean train loss 1637.5467006138392
INFO:root:current train perplexity3.636422872543335
INFO:root:current mean train loss 1634.6409661965292
INFO:root:current train perplexity3.6340181827545166
INFO:root:current mean train loss 1642.0728317064277
INFO:root:current train perplexity3.642169952392578
INFO:root:current mean train loss 1643.1350977597726
INFO:root:current train perplexity3.646662712097168
INFO:root:current mean train loss 1643.4335547094947
INFO:root:current train perplexity3.6516921520233154
INFO:root:current mean train loss 1645.5360067581694
INFO:root:current train perplexity3.655038833618164
INFO:root:current mean train loss 1645.5533589634003
INFO:root:current train perplexity3.6550583839416504
INFO:root:current mean train loss 1647.6480958042184
INFO:root:current train perplexity3.661313533782959
INFO:root:current mean train loss 1650.8322522591025
INFO:root:current train perplexity3.665642023086548
INFO:root:current mean train loss 1651.6334341582467
INFO:root:current train perplexity3.6696417331695557
INFO:root:current mean train loss 1652.42880745597
INFO:root:current train perplexity3.6733767986297607
INFO:root:current mean train loss 1653.254349938947
INFO:root:current train perplexity3.675619602203369
INFO:root:current mean train loss 1654.0560885607626
INFO:root:current train perplexity3.678074836730957
INFO:root:current mean train loss 1654.4158086667117
INFO:root:current train perplexity3.6789231300354004
INFO:root:current mean train loss 1653.0716049359196
INFO:root:current train perplexity3.6788768768310547
INFO:root:current mean train loss 1654.2970850632387
INFO:root:current train perplexity3.6809685230255127
INFO:root:current mean train loss 1654.0876441293208
INFO:root:current train perplexity3.6812357902526855
INFO:root:current mean train loss 1653.8608080533127
INFO:root:current train perplexity3.683986186981201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.01s/it]
INFO:root:final mean train loss: 1653.3987813652373
INFO:root:final train perplexity: 3.6838912963867188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2014.876444498698
INFO:root:eval perplexity: 5.10139274597168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2490.092000758394
INFO:root:eval perplexity: 7.66347599029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [9:07:19<26:17:49, 639.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.917501058923
INFO:root:current train perplexity3.6005043983459473
INFO:root:current mean train loss 1624.6015691705088
INFO:root:current train perplexity3.632354259490967
INFO:root:current mean train loss 1626.37986383337
INFO:root:current train perplexity3.629650592803955
INFO:root:current mean train loss 1630.6271210912003
INFO:root:current train perplexity3.628871440887451
INFO:root:current mean train loss 1631.5323251285909
INFO:root:current train perplexity3.6316134929656982
INFO:root:current mean train loss 1634.7888686113047
INFO:root:current train perplexity3.6353142261505127
INFO:root:current mean train loss 1635.3674078699785
INFO:root:current train perplexity3.6375210285186768
INFO:root:current mean train loss 1637.8848892543203
INFO:root:current train perplexity3.6378345489501953
INFO:root:current mean train loss 1639.7698382920885
INFO:root:current train perplexity3.642720937728882
INFO:root:current mean train loss 1641.6615324282332
INFO:root:current train perplexity3.648310661315918
INFO:root:current mean train loss 1642.3044710872575
INFO:root:current train perplexity3.6483254432678223
INFO:root:current mean train loss 1643.209057637825
INFO:root:current train perplexity3.651064157485962
INFO:root:current mean train loss 1644.0443204670146
INFO:root:current train perplexity3.6516082286834717
INFO:root:current mean train loss 1644.0345962976771
INFO:root:current train perplexity3.6539204120635986
INFO:root:current mean train loss 1645.2664612186816
INFO:root:current train perplexity3.6571390628814697
INFO:root:current mean train loss 1646.0818154870599
INFO:root:current train perplexity3.659116744995117
INFO:root:current mean train loss 1646.100554603944
INFO:root:current train perplexity3.660342216491699
INFO:root:current mean train loss 1647.333253185467
INFO:root:current train perplexity3.6633048057556152
INFO:root:current mean train loss 1647.6464462563895
INFO:root:current train perplexity3.6625940799713135
INFO:root:current mean train loss 1646.8463631234142
INFO:root:current train perplexity3.6649038791656494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.31s/it]
INFO:root:final mean train loss: 1646.8463631234142
INFO:root:final train perplexity: 3.6649038791656494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 2013.4156892384199
INFO:root:eval perplexity: 5.095371246337891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.86s/it]
INFO:root:eval mean loss: 2490.943523434037
INFO:root:eval perplexity: 7.668816566467285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [9:18:00<26:08:30, 640.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.4570166015626
INFO:root:current train perplexity3.592846632003784
INFO:root:current mean train loss 1614.375888671875
INFO:root:current train perplexity3.595968723297119
INFO:root:current mean train loss 1621.7341731770832
INFO:root:current train perplexity3.6032679080963135
INFO:root:current mean train loss 1621.8505493164062
INFO:root:current train perplexity3.6111233234405518
INFO:root:current mean train loss 1625.5406896972656
INFO:root:current train perplexity3.6157193183898926
INFO:root:current mean train loss 1628.0514621988932
INFO:root:current train perplexity3.614067316055298
INFO:root:current mean train loss 1629.1599285016741
INFO:root:current train perplexity3.616422414779663
INFO:root:current mean train loss 1628.9493676757813
INFO:root:current train perplexity3.6163363456726074
INFO:root:current mean train loss 1630.6288342285156
INFO:root:current train perplexity3.6201069355010986
INFO:root:current mean train loss 1632.266663696289
INFO:root:current train perplexity3.6230788230895996
INFO:root:current mean train loss 1632.27770341353
INFO:root:current train perplexity3.62479829788208
INFO:root:current mean train loss 1634.4235196940103
INFO:root:current train perplexity3.629697799682617
INFO:root:current mean train loss 1634.9090397761418
INFO:root:current train perplexity3.6310155391693115
INFO:root:current mean train loss 1636.362180001395
INFO:root:current train perplexity3.634357452392578
INFO:root:current mean train loss 1637.086490641276
INFO:root:current train perplexity3.6369874477386475
INFO:root:current mean train loss 1638.382049331665
INFO:root:current train perplexity3.6405677795410156
INFO:root:current mean train loss 1639.7079863424863
INFO:root:current train perplexity3.6418774127960205
INFO:root:current mean train loss 1640.0869354926215
INFO:root:current train perplexity3.6424074172973633
INFO:root:current mean train loss 1640.7802094469573
INFO:root:current train perplexity3.644404888153076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:39<00:00, 579.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:39<00:00, 579.72s/it]
INFO:root:final mean train loss: 1640.3275208042778
INFO:root:final train perplexity: 3.6461100578308105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.56s/it]
INFO:root:eval mean loss: 2016.6675042767897
INFO:root:eval perplexity: 5.108788967132568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2495.244354897357
INFO:root:eval perplexity: 7.695834636688232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [9:28:58<26:10:27, 645.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1600.7140826056984
INFO:root:current train perplexity3.590693950653076
INFO:root:current mean train loss 1623.197292751736
INFO:root:current train perplexity3.583280086517334
INFO:root:current mean train loss 1623.9089833624353
INFO:root:current train perplexity3.588475227355957
INFO:root:current mean train loss 1622.4597826455295
INFO:root:current train perplexity3.5910744667053223
INFO:root:current mean train loss 1620.868196848771
INFO:root:current train perplexity3.5927696228027344
INFO:root:current mean train loss 1625.7068839156188
INFO:root:current train perplexity3.6002631187438965
INFO:root:current mean train loss 1627.9812700219054
INFO:root:current train perplexity3.6024293899536133
INFO:root:current mean train loss 1628.6459443372996
INFO:root:current train perplexity3.6044390201568604
INFO:root:current mean train loss 1629.684261027865
INFO:root:current train perplexity3.605884313583374
INFO:root:current mean train loss 1631.0504606989505
INFO:root:current train perplexity3.6090807914733887
INFO:root:current mean train loss 1630.3377331458948
INFO:root:current train perplexity3.610760450363159
INFO:root:current mean train loss 1631.4830765958973
INFO:root:current train perplexity3.614046096801758
INFO:root:current mean train loss 1631.3370737469186
INFO:root:current train perplexity3.6153221130371094
INFO:root:current mean train loss 1631.8202709757024
INFO:root:current train perplexity3.6174094676971436
INFO:root:current mean train loss 1631.9089876658159
INFO:root:current train perplexity3.6184122562408447
INFO:root:current mean train loss 1632.235025263807
INFO:root:current train perplexity3.620497465133667
INFO:root:current mean train loss 1631.734204161956
INFO:root:current train perplexity3.6212921142578125
INFO:root:current mean train loss 1631.82537767147
INFO:root:current train perplexity3.622499704360962
INFO:root:current mean train loss 1632.5102555858084
INFO:root:current train perplexity3.6245968341827393
INFO:root:current mean train loss 1634.194791106302
INFO:root:current train perplexity3.627398729324341

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.80s/it]
INFO:root:final mean train loss: 1634.0621791883846
INFO:root:final train perplexity: 3.628138780593872
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2021.67866072418
INFO:root:eval perplexity: 5.12953519821167
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2503.012599647468
INFO:root:eval perplexity: 7.744884967803955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:39:39<25:56:17, 643.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.4806482651654
INFO:root:current train perplexity3.5767953395843506
INFO:root:current mean train loss 1613.2367827002681
INFO:root:current train perplexity3.588261604309082
INFO:root:current mean train loss 1616.7091408754006
INFO:root:current train perplexity3.5796499252319336
INFO:root:current mean train loss 1618.1311243479838
INFO:root:current train perplexity3.5760228633880615
INFO:root:current mean train loss 1617.4198774346557
INFO:root:current train perplexity3.5807337760925293
INFO:root:current mean train loss 1618.4815063476562
INFO:root:current train perplexity3.5791735649108887
INFO:root:current mean train loss 1618.8493958482231
INFO:root:current train perplexity3.58445405960083
INFO:root:current mean train loss 1619.0317005292595
INFO:root:current train perplexity3.5875918865203857
INFO:root:current mean train loss 1621.087006273887
INFO:root:current train perplexity3.592806816101074
INFO:root:current mean train loss 1623.254491377183
INFO:root:current train perplexity3.5973103046417236
INFO:root:current mean train loss 1624.5088385281294
INFO:root:current train perplexity3.6010794639587402
INFO:root:current mean train loss 1625.1931623832259
INFO:root:current train perplexity3.6019270420074463
INFO:root:current mean train loss 1625.747439688956
INFO:root:current train perplexity3.604295015335083
INFO:root:current mean train loss 1626.4174830309455
INFO:root:current train perplexity3.606208324432373
INFO:root:current mean train loss 1626.8481559380994
INFO:root:current train perplexity3.6073124408721924
INFO:root:current mean train loss 1627.9186091018935
INFO:root:current train perplexity3.609351873397827
INFO:root:current mean train loss 1627.9371906406584
INFO:root:current train perplexity3.6101057529449463
INFO:root:current mean train loss 1628.61409146178
INFO:root:current train perplexity3.611032485961914
INFO:root:current mean train loss 1627.7939051770593
INFO:root:current train perplexity3.6108973026275635
INFO:root:current mean train loss 1628.074447111112
INFO:root:current train perplexity3.611572265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.23s/it]
INFO:root:final mean train loss: 1628.305414874086
INFO:root:final train perplexity: 3.611704111099243
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2023.9805761026153
INFO:root:eval perplexity: 5.139092922210693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2508.028171404034
INFO:root:eval perplexity: 7.776719570159912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:50:26<25:48:19, 645.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1597.2958242378984
INFO:root:current train perplexity3.5371828079223633
INFO:root:current mean train loss 1593.2775021988825
INFO:root:current train perplexity3.5354480743408203
INFO:root:current mean train loss 1606.7122870821402
INFO:root:current train perplexity3.5543887615203857
INFO:root:current mean train loss 1613.5934474325588
INFO:root:current train perplexity3.5624115467071533
INFO:root:current mean train loss 1614.917163519003
INFO:root:current train perplexity3.565768003463745
INFO:root:current mean train loss 1613.2357304014008
INFO:root:current train perplexity3.5628740787506104
INFO:root:current mean train loss 1615.2686371927803
INFO:root:current train perplexity3.5677359104156494
INFO:root:current mean train loss 1615.8693153594686
INFO:root:current train perplexity3.5682308673858643
INFO:root:current mean train loss 1615.864377013945
INFO:root:current train perplexity3.5716848373413086
INFO:root:current mean train loss 1615.3691132843308
INFO:root:current train perplexity3.570941925048828
INFO:root:current mean train loss 1616.252534091416
INFO:root:current train perplexity3.5743486881256104
INFO:root:current mean train loss 1617.4730865186862
INFO:root:current train perplexity3.5747134685516357
INFO:root:current mean train loss 1617.8100129271584
INFO:root:current train perplexity3.5768775939941406
INFO:root:current mean train loss 1618.9757839064523
INFO:root:current train perplexity3.580096960067749
INFO:root:current mean train loss 1620.2146209779894
INFO:root:current train perplexity3.582512140274048
INFO:root:current mean train loss 1620.8036331776877
INFO:root:current train perplexity3.5833306312561035
INFO:root:current mean train loss 1621.3298220804863
INFO:root:current train perplexity3.5855867862701416
INFO:root:current mean train loss 1622.4911367611364
INFO:root:current train perplexity3.5893971920013428
INFO:root:current mean train loss 1622.0544719149912
INFO:root:current train perplexity3.5902929306030273
INFO:root:current mean train loss 1621.7594638591788
INFO:root:current train perplexity3.591813802719116

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.88s/it]
INFO:root:final mean train loss: 1621.3595766037688
INFO:root:final train perplexity: 3.5919735431671143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 2023.513966228945
INFO:root:eval perplexity: 5.1371541023254395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2506.341286517204
INFO:root:eval perplexity: 7.765998840332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [10:01:20<25:43:21, 647.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1596.6673673741957
INFO:root:current train perplexity3.5296216011047363
INFO:root:current mean train loss 1604.2337719145276
INFO:root:current train perplexity3.5366368293762207
INFO:root:current mean train loss 1603.2846114884562
INFO:root:current train perplexity3.544363021850586
INFO:root:current mean train loss 1608.186801744544
INFO:root:current train perplexity3.5594489574432373
INFO:root:current mean train loss 1607.2843690529849
INFO:root:current train perplexity3.553447723388672
INFO:root:current mean train loss 1609.0340485908616
INFO:root:current train perplexity3.5525753498077393
INFO:root:current mean train loss 1609.0769335352732
INFO:root:current train perplexity3.5523674488067627
INFO:root:current mean train loss 1606.7251892089844
INFO:root:current train perplexity3.5524487495422363
INFO:root:current mean train loss 1606.6482778804093
INFO:root:current train perplexity3.5531203746795654
INFO:root:current mean train loss 1608.9003124394692
INFO:root:current train perplexity3.559575080871582
INFO:root:current mean train loss 1611.2258137335045
INFO:root:current train perplexity3.5630905628204346
INFO:root:current mean train loss 1611.5211242257733
INFO:root:current train perplexity3.566373825073242
INFO:root:current mean train loss 1611.8285160485877
INFO:root:current train perplexity3.5669758319854736
INFO:root:current mean train loss 1611.810916030616
INFO:root:current train perplexity3.567983865737915
INFO:root:current mean train loss 1612.6927713087534
INFO:root:current train perplexity3.569302558898926
INFO:root:current mean train loss 1613.43897371876
INFO:root:current train perplexity3.5703299045562744
INFO:root:current mean train loss 1613.9724877080757
INFO:root:current train perplexity3.571261167526245
INFO:root:current mean train loss 1614.652276915123
INFO:root:current train perplexity3.571366786956787
INFO:root:current mean train loss 1615.2762666820713
INFO:root:current train perplexity3.572787284851074
INFO:root:current mean train loss 1615.8475279149002
INFO:root:current train perplexity3.574558734893799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.88s/it]
INFO:root:final mean train loss: 1615.4225381071135
INFO:root:final train perplexity: 3.5751936435699463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 2025.6866649871176
INFO:root:eval perplexity: 5.146187782287598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 2508.8379499286625
INFO:root:eval perplexity: 7.781867980957031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [10:12:11<25:35:12, 648.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1586.9196964039522
INFO:root:current train perplexity3.4929144382476807
INFO:root:current mean train loss 1591.9597860800254
INFO:root:current train perplexity3.520473003387451
INFO:root:current mean train loss 1597.2691204941063
INFO:root:current train perplexity3.5324978828430176
INFO:root:current mean train loss 1599.4627970906047
INFO:root:current train perplexity3.5416758060455322
INFO:root:current mean train loss 1600.7804861167042
INFO:root:current train perplexity3.5413410663604736
INFO:root:current mean train loss 1601.6191251836271
INFO:root:current train perplexity3.541029214859009
INFO:root:current mean train loss 1601.455070462192
INFO:root:current train perplexity3.5411975383758545
INFO:root:current mean train loss 1601.9430614301355
INFO:root:current train perplexity3.5448036193847656
INFO:root:current mean train loss 1603.862854900468
INFO:root:current train perplexity3.5440444946289062
INFO:root:current mean train loss 1604.1618832041165
INFO:root:current train perplexity3.544135570526123
INFO:root:current mean train loss 1603.298819799467
INFO:root:current train perplexity3.5435142517089844
INFO:root:current mean train loss 1604.3771767660535
INFO:root:current train perplexity3.54510235786438
INFO:root:current mean train loss 1606.246639789032
INFO:root:current train perplexity3.547020673751831
INFO:root:current mean train loss 1606.3236475314475
INFO:root:current train perplexity3.5486631393432617
INFO:root:current mean train loss 1607.0437764691183
INFO:root:current train perplexity3.551231861114502
INFO:root:current mean train loss 1608.0744556511238
INFO:root:current train perplexity3.552615165710449
INFO:root:current mean train loss 1608.8982005314585
INFO:root:current train perplexity3.55621337890625
INFO:root:current mean train loss 1609.561840204832
INFO:root:current train perplexity3.5569679737091064
INFO:root:current mean train loss 1609.7547743415328
INFO:root:current train perplexity3.5589585304260254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:38<00:00, 578.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:38<00:00, 578.53s/it]
INFO:root:final mean train loss: 1609.794746864461
INFO:root:final train perplexity: 3.5593602657318115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2030.0821243177913
INFO:root:eval perplexity: 5.164514541625977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2518.8925841852283
INFO:root:eval perplexity: 7.846124649047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [10:23:05<25:28:10, 650.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1616.0552978515625
INFO:root:current train perplexity3.478062391281128
INFO:root:current mean train loss 1573.626458859911
INFO:root:current train perplexity3.465763807296753
INFO:root:current mean train loss 1583.103770038869
INFO:root:current train perplexity3.4917526245117188
INFO:root:current mean train loss 1586.1569755503674
INFO:root:current train perplexity3.494156837463379
INFO:root:current mean train loss 1588.2883944535138
INFO:root:current train perplexity3.4992947578430176
INFO:root:current mean train loss 1590.1292192071558
INFO:root:current train perplexity3.50719952583313
INFO:root:current mean train loss 1593.748872775968
INFO:root:current train perplexity3.5168309211730957
INFO:root:current mean train loss 1594.891439149862
INFO:root:current train perplexity3.519144058227539
INFO:root:current mean train loss 1596.2651622895885
INFO:root:current train perplexity3.520078182220459
INFO:root:current mean train loss 1598.1287852623511
INFO:root:current train perplexity3.523684024810791
INFO:root:current mean train loss 1599.176015035359
INFO:root:current train perplexity3.5291662216186523
INFO:root:current mean train loss 1601.7658249427532
INFO:root:current train perplexity3.532923460006714
INFO:root:current mean train loss 1602.1300457083246
INFO:root:current train perplexity3.5328123569488525
INFO:root:current mean train loss 1602.298355219734
INFO:root:current train perplexity3.5367774963378906
INFO:root:current mean train loss 1602.4476968762538
INFO:root:current train perplexity3.5393359661102295
INFO:root:current mean train loss 1602.8528746339516
INFO:root:current train perplexity3.5404369831085205
INFO:root:current mean train loss 1602.7445485166247
INFO:root:current train perplexity3.5421407222747803
INFO:root:current mean train loss 1602.6179652499816
INFO:root:current train perplexity3.5407614707946777
INFO:root:current mean train loss 1603.131925491858
INFO:root:current train perplexity3.5409042835235596
INFO:root:current mean train loss 1603.3543796158237
INFO:root:current train perplexity3.541667938232422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.22s/it]
INFO:root:final mean train loss: 1603.8352666673068
INFO:root:final train perplexity: 3.5426712036132812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2032.3211548717309
INFO:root:eval perplexity: 5.17387580871582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2522.2417026817375
INFO:root:eval perplexity: 7.867642402648926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [10:33:43<25:08:46, 646.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1584.9077212685033
INFO:root:current train perplexity3.5129151344299316
INFO:root:current mean train loss 1589.0792667164521
INFO:root:current train perplexity3.5073599815368652
INFO:root:current mean train loss 1592.7115801806863
INFO:root:current train perplexity3.5013651847839355
INFO:root:current mean train loss 1589.1670488220022
INFO:root:current train perplexity3.4979639053344727
INFO:root:current mean train loss 1584.9473789551946
INFO:root:current train perplexity3.4915127754211426
INFO:root:current mean train loss 1589.117727761094
INFO:root:current train perplexity3.4988179206848145
INFO:root:current mean train loss 1588.0284603285288
INFO:root:current train perplexity3.5028152465820312
INFO:root:current mean train loss 1590.0691710831559
INFO:root:current train perplexity3.5084421634674072
INFO:root:current mean train loss 1589.9339460994734
INFO:root:current train perplexity3.5078186988830566
INFO:root:current mean train loss 1590.0696284280639
INFO:root:current train perplexity3.5088019371032715
INFO:root:current mean train loss 1590.7422636891254
INFO:root:current train perplexity3.510430335998535
INFO:root:current mean train loss 1591.4535028834339
INFO:root:current train perplexity3.5122854709625244
INFO:root:current mean train loss 1592.3123121378949
INFO:root:current train perplexity3.5133583545684814
INFO:root:current mean train loss 1593.0586025420241
INFO:root:current train perplexity3.5155117511749268
INFO:root:current mean train loss 1593.9721842275865
INFO:root:current train perplexity3.5165700912475586
INFO:root:current mean train loss 1594.6697331843525
INFO:root:current train perplexity3.5175623893737793
INFO:root:current mean train loss 1595.6122240864104
INFO:root:current train perplexity3.5197978019714355
INFO:root:current mean train loss 1596.2200915662268
INFO:root:current train perplexity3.5212507247924805
INFO:root:current mean train loss 1596.6566280891373
INFO:root:current train perplexity3.5235509872436523
INFO:root:current mean train loss 1597.0377515958833
INFO:root:current train perplexity3.523373603820801

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.21s/it]
INFO:root:final mean train loss: 1597.2495773400071
INFO:root:final train perplexity: 3.5243184566497803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 2035.83948100205
INFO:root:eval perplexity: 5.188618183135986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2524.329521882619
INFO:root:eval perplexity: 7.8810882568359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:44:32<24:59:50, 647.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.6241624620225
INFO:root:current train perplexity3.4498450756073
INFO:root:current mean train loss 1566.2099591423485
INFO:root:current train perplexity3.4498355388641357
INFO:root:current mean train loss 1573.3681231999801
INFO:root:current train perplexity3.471440553665161
INFO:root:current mean train loss 1579.989749000186
INFO:root:current train perplexity3.4796736240386963
INFO:root:current mean train loss 1579.0714452901018
INFO:root:current train perplexity3.4811782836914062
INFO:root:current mean train loss 1579.6902281348384
INFO:root:current train perplexity3.4809730052948
INFO:root:current mean train loss 1580.178214211134
INFO:root:current train perplexity3.4813849925994873
INFO:root:current mean train loss 1583.2809101602306
INFO:root:current train perplexity3.485599994659424
INFO:root:current mean train loss 1584.3390586159446
INFO:root:current train perplexity3.490701198577881
INFO:root:current mean train loss 1584.7112383720203
INFO:root:current train perplexity3.4902093410491943
INFO:root:current mean train loss 1584.5373369018084
INFO:root:current train perplexity3.489278793334961
INFO:root:current mean train loss 1584.3869861011774
INFO:root:current train perplexity3.489455223083496
INFO:root:current mean train loss 1585.1458652335848
INFO:root:current train perplexity3.4940812587738037
INFO:root:current mean train loss 1587.1751814973568
INFO:root:current train perplexity3.498222827911377
INFO:root:current mean train loss 1587.308912441923
INFO:root:current train perplexity3.5008695125579834
INFO:root:current mean train loss 1588.8432370821636
INFO:root:current train perplexity3.504765748977661
INFO:root:current mean train loss 1589.8971929200413
INFO:root:current train perplexity3.506377935409546
INFO:root:current mean train loss 1590.7915453229632
INFO:root:current train perplexity3.508207321166992
INFO:root:current mean train loss 1591.7920768920633
INFO:root:current train perplexity3.508695602416992
INFO:root:current mean train loss 1592.4541030757684
INFO:root:current train perplexity3.509375810623169

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.24s/it]
INFO:root:final mean train loss: 1591.7385129866068
INFO:root:final train perplexity: 3.509033679962158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 2039.3283626475234
INFO:root:eval perplexity: 5.203279495239258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2530.9035293903758
INFO:root:eval perplexity: 7.9235758781433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:55:04<24:38:28, 642.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1568.8022322744694
INFO:root:current train perplexity3.4293971061706543
INFO:root:current mean train loss 1573.8795556959763
INFO:root:current train perplexity3.4572789669036865
INFO:root:current mean train loss 1584.2340768203435
INFO:root:current train perplexity3.4789886474609375
INFO:root:current mean train loss 1583.4085108943432
INFO:root:current train perplexity3.480151891708374
INFO:root:current mean train loss 1584.5979553626862
INFO:root:current train perplexity3.4838268756866455
INFO:root:current mean train loss 1584.1185327015992
INFO:root:current train perplexity3.483543872833252
INFO:root:current mean train loss 1584.4403786535102
INFO:root:current train perplexity3.481342315673828
INFO:root:current mean train loss 1584.2789009975722
INFO:root:current train perplexity3.4767324924468994
INFO:root:current mean train loss 1583.702219132382
INFO:root:current train perplexity3.476564645767212
INFO:root:current mean train loss 1582.2517876319846
INFO:root:current train perplexity3.475451946258545
INFO:root:current mean train loss 1583.1594246396085
INFO:root:current train perplexity3.479442834854126
INFO:root:current mean train loss 1582.7114709885557
INFO:root:current train perplexity3.4800865650177
INFO:root:current mean train loss 1583.0322696232167
INFO:root:current train perplexity3.4812605381011963
INFO:root:current mean train loss 1583.8693269333482
INFO:root:current train perplexity3.4851467609405518
INFO:root:current mean train loss 1583.8973591142249
INFO:root:current train perplexity3.4860191345214844
INFO:root:current mean train loss 1583.6014329624115
INFO:root:current train perplexity3.488081455230713
INFO:root:current mean train loss 1584.3435824394803
INFO:root:current train perplexity3.4881374835968018
INFO:root:current mean train loss 1584.525244809122
INFO:root:current train perplexity3.4889397621154785
INFO:root:current mean train loss 1585.2730104844761
INFO:root:current train perplexity3.4913101196289062
INFO:root:current mean train loss 1585.7475517808139
INFO:root:current train perplexity3.492159128189087

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.32s/it]
INFO:root:final mean train loss: 1585.8210743775708
INFO:root:final train perplexity: 3.4926958084106445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 2040.4171255125223
INFO:root:eval perplexity: 5.207862854003906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2532.6853256766676
INFO:root:eval perplexity: 7.935128688812256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [11:05:38<24:21:40, 640.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.3164760044642
INFO:root:current train perplexity3.447965621948242
INFO:root:current mean train loss 1575.6664306640625
INFO:root:current train perplexity3.4389922618865967
INFO:root:current mean train loss 1569.974348506221
INFO:root:current train perplexity3.4359216690063477
INFO:root:current mean train loss 1566.3203586887669
INFO:root:current train perplexity3.4395368099212646
INFO:root:current mean train loss 1570.3773829683344
INFO:root:current train perplexity3.448223829269409
INFO:root:current mean train loss 1571.7808505945038
INFO:root:current train perplexity3.4544169902801514
INFO:root:current mean train loss 1571.63189023146
INFO:root:current train perplexity3.453376054763794
INFO:root:current mean train loss 1572.1690374200994
INFO:root:current train perplexity3.454197883605957
INFO:root:current mean train loss 1572.547721213856
INFO:root:current train perplexity3.4583730697631836
INFO:root:current mean train loss 1572.4331909179687
INFO:root:current train perplexity3.4574525356292725
INFO:root:current mean train loss 1572.179171268071
INFO:root:current train perplexity3.459815740585327
INFO:root:current mean train loss 1573.3346173669538
INFO:root:current train perplexity3.464069366455078
INFO:root:current mean train loss 1573.5497747946913
INFO:root:current train perplexity3.4656686782836914
INFO:root:current mean train loss 1575.154415470318
INFO:root:current train perplexity3.467797040939331
INFO:root:current mean train loss 1576.040826042331
INFO:root:current train perplexity3.468787670135498
INFO:root:current mean train loss 1576.313048305633
INFO:root:current train perplexity3.470041275024414
INFO:root:current mean train loss 1577.239536600627
INFO:root:current train perplexity3.4710428714752197
INFO:root:current mean train loss 1578.023719572078
INFO:root:current train perplexity3.4713478088378906
INFO:root:current mean train loss 1579.0374293689422
INFO:root:current train perplexity3.4728143215179443
INFO:root:current mean train loss 1580.388403754065
INFO:root:current train perplexity3.476155996322632

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.46s/it]
INFO:root:final mean train loss: 1579.8670701696844
INFO:root:final train perplexity: 3.4763338565826416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 2040.329471236425
INFO:root:eval perplexity: 5.207494258880615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it]
INFO:root:eval mean loss: 2533.5224501156636
INFO:root:eval perplexity: 7.940563678741455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [11:16:22<24:13:06, 641.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.9408997283585
INFO:root:current train perplexity3.405432939529419
INFO:root:current mean train loss 1563.0284345494235
INFO:root:current train perplexity3.4269471168518066
INFO:root:current mean train loss 1567.3039793220546
INFO:root:current train perplexity3.4434797763824463
INFO:root:current mean train loss 1565.599405609052
INFO:root:current train perplexity3.4378998279571533
INFO:root:current mean train loss 1565.6246450686601
INFO:root:current train perplexity3.4421732425689697
INFO:root:current mean train loss 1568.1840936767994
INFO:root:current train perplexity3.44062876701355
INFO:root:current mean train loss 1566.204385327113
INFO:root:current train perplexity3.4406116008758545
INFO:root:current mean train loss 1566.7326353041615
INFO:root:current train perplexity3.4432647228240967
INFO:root:current mean train loss 1567.6746149073863
INFO:root:current train perplexity3.445241928100586
INFO:root:current mean train loss 1568.017836612288
INFO:root:current train perplexity3.448500394821167
INFO:root:current mean train loss 1568.6884611773733
INFO:root:current train perplexity3.4517104625701904
INFO:root:current mean train loss 1569.710607797033
INFO:root:current train perplexity3.4534597396850586
INFO:root:current mean train loss 1570.7892840666277
INFO:root:current train perplexity3.4561610221862793
INFO:root:current mean train loss 1570.4019380224292
INFO:root:current train perplexity3.4563393592834473
INFO:root:current mean train loss 1571.4582301167409
INFO:root:current train perplexity3.4569480419158936
INFO:root:current mean train loss 1572.2348706654655
INFO:root:current train perplexity3.4581522941589355
INFO:root:current mean train loss 1573.199402542883
INFO:root:current train perplexity3.4591188430786133
INFO:root:current mean train loss 1572.821024223887
INFO:root:current train perplexity3.4597280025482178
INFO:root:current mean train loss 1574.034677478202
INFO:root:current train perplexity3.4609267711639404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.07s/it]
INFO:root:final mean train loss: 1574.4731647531853
INFO:root:final train perplexity: 3.4615769386291504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2046.5291120380375
INFO:root:eval perplexity: 5.233668804168701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2540.4873912621897
INFO:root:eval perplexity: 7.98592472076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [11:26:57<23:58:55, 639.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1515.1485290527344
INFO:root:current train perplexity3.3911032676696777
INFO:root:current mean train loss 1545.3066817063552
INFO:root:current train perplexity3.3977103233337402
INFO:root:current mean train loss 1548.0576524921491
INFO:root:current train perplexity3.4061405658721924
INFO:root:current mean train loss 1549.4674112420332
INFO:root:current train perplexity3.414060354232788
INFO:root:current mean train loss 1553.7665060817606
INFO:root:current train perplexity3.419382095336914
INFO:root:current mean train loss 1557.2794865199498
INFO:root:current train perplexity3.4247939586639404
INFO:root:current mean train loss 1559.9563394508614
INFO:root:current train perplexity3.4260966777801514
INFO:root:current mean train loss 1561.8151200034401
INFO:root:current train perplexity3.430478811264038
INFO:root:current mean train loss 1563.399010349862
INFO:root:current train perplexity3.43349289894104
INFO:root:current mean train loss 1564.7980707219217
INFO:root:current train perplexity3.4376442432403564
INFO:root:current mean train loss 1565.75340726936
INFO:root:current train perplexity3.440000534057617
INFO:root:current mean train loss 1567.0233701623004
INFO:root:current train perplexity3.4410665035247803
INFO:root:current mean train loss 1567.167035074329
INFO:root:current train perplexity3.440087080001831
INFO:root:current mean train loss 1567.6258295913415
INFO:root:current train perplexity3.4412312507629395
INFO:root:current mean train loss 1568.086872242115
INFO:root:current train perplexity3.4426043033599854
INFO:root:current mean train loss 1569.1663269692278
INFO:root:current train perplexity3.4444198608398438
INFO:root:current mean train loss 1569.0254574440364
INFO:root:current train perplexity3.444237470626831
INFO:root:current mean train loss 1569.0090963874065
INFO:root:current train perplexity3.4450297355651855
INFO:root:current mean train loss 1568.6638032697522
INFO:root:current train perplexity3.4445927143096924
INFO:root:current mean train loss 1569.2760949014616
INFO:root:current train perplexity3.446439504623413

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it]
INFO:root:final mean train loss: 1569.1761376731515
INFO:root:final train perplexity: 3.44714617729187
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2049.6799195201684
INFO:root:eval perplexity: 5.247023105621338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2545.1302083333335
INFO:root:eval perplexity: 8.016303062438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [11:37:30<23:43:51, 637.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1569.5604596819196
INFO:root:current train perplexity3.435340166091919
INFO:root:current mean train loss 1558.3973802298553
INFO:root:current train perplexity3.414952516555786
INFO:root:current mean train loss 1564.8034844722144
INFO:root:current train perplexity3.4197897911071777
INFO:root:current mean train loss 1558.329723322503
INFO:root:current train perplexity3.4133074283599854
INFO:root:current mean train loss 1555.3849961378228
INFO:root:current train perplexity3.4090633392333984
INFO:root:current mean train loss 1555.5976124358956
INFO:root:current train perplexity3.411036968231201
INFO:root:current mean train loss 1555.7946484453628
INFO:root:current train perplexity3.4129979610443115
INFO:root:current mean train loss 1556.1923042540743
INFO:root:current train perplexity3.411184549331665
INFO:root:current mean train loss 1556.8279816677452
INFO:root:current train perplexity3.4131438732147217
INFO:root:current mean train loss 1556.3465525806273
INFO:root:current train perplexity3.415029525756836
INFO:root:current mean train loss 1556.092794958221
INFO:root:current train perplexity3.4167592525482178
INFO:root:current mean train loss 1557.5060263096914
INFO:root:current train perplexity3.417222499847412
INFO:root:current mean train loss 1557.0235137814484
INFO:root:current train perplexity3.4180848598480225
INFO:root:current mean train loss 1557.1263758553239
INFO:root:current train perplexity3.4195830821990967
INFO:root:current mean train loss 1558.4165526141087
INFO:root:current train perplexity3.4212193489074707
INFO:root:current mean train loss 1560.5818354238577
INFO:root:current train perplexity3.4229657649993896
INFO:root:current mean train loss 1561.6691563939842
INFO:root:current train perplexity3.424513578414917
INFO:root:current mean train loss 1562.28354543257
INFO:root:current train perplexity3.427476167678833
INFO:root:current mean train loss 1562.790733676766
INFO:root:current train perplexity3.4291627407073975
INFO:root:current mean train loss 1562.9719834335144
INFO:root:current train perplexity3.429324150085449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.56s/it]
INFO:root:final mean train loss: 1562.9545866119338
INFO:root:final train perplexity: 3.4302732944488525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2050.1415933379044
INFO:root:eval perplexity: 5.2489824295043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2547.4766036229776
INFO:root:eval perplexity: 8.031700134277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:48:01<23:28:24, 635.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1520.526691637541
INFO:root:current train perplexity3.358344316482544
INFO:root:current mean train loss 1532.3289874532948
INFO:root:current train perplexity3.3525443077087402
INFO:root:current mean train loss 1539.2671231822808
INFO:root:current train perplexity3.3663341999053955
INFO:root:current mean train loss 1543.9556928104198
INFO:root:current train perplexity3.377300977706909
INFO:root:current mean train loss 1544.4828585968714
INFO:root:current train perplexity3.381704092025757
INFO:root:current mean train loss 1545.70579988274
INFO:root:current train perplexity3.3828721046447754
INFO:root:current mean train loss 1548.0985645066983
INFO:root:current train perplexity3.3896324634552
INFO:root:current mean train loss 1548.7097794861006
INFO:root:current train perplexity3.3960819244384766
INFO:root:current mean train loss 1551.0212747578405
INFO:root:current train perplexity3.401705026626587
INFO:root:current mean train loss 1551.8336897404718
INFO:root:current train perplexity3.402977705001831
INFO:root:current mean train loss 1550.3642633397685
INFO:root:current train perplexity3.399895668029785
INFO:root:current mean train loss 1551.0470564964576
INFO:root:current train perplexity3.400484323501587
INFO:root:current mean train loss 1553.0101544159872
INFO:root:current train perplexity3.403513193130493
INFO:root:current mean train loss 1554.5676207492527
INFO:root:current train perplexity3.4073023796081543
INFO:root:current mean train loss 1555.6733911166768
INFO:root:current train perplexity3.4087069034576416
INFO:root:current mean train loss 1556.5150958434504
INFO:root:current train perplexity3.4106664657592773
INFO:root:current mean train loss 1557.1030254061259
INFO:root:current train perplexity3.4121668338775635
INFO:root:current mean train loss 1557.1387864300516
INFO:root:current train perplexity3.4140563011169434
INFO:root:current mean train loss 1556.881162757583
INFO:root:current train perplexity3.414414405822754
INFO:root:current mean train loss 1557.8779917304607
INFO:root:current train perplexity3.4154012203216553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.76s/it]
INFO:root:final mean train loss: 1557.9883317278902
INFO:root:final train perplexity: 3.4168648719787598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 2054.924565741356
INFO:root:eval perplexity: 5.2693257331848145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2550.872840394365
INFO:root:eval perplexity: 8.05403995513916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [11:58:41<23:21:06, 636.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.6084716796875
INFO:root:current train perplexity3.3571107387542725
INFO:root:current mean train loss 1545.7120707850302
INFO:root:current train perplexity3.371241331100464
INFO:root:current mean train loss 1543.1422923368566
INFO:root:current train perplexity3.3669776916503906
INFO:root:current mean train loss 1541.130194349692
INFO:root:current train perplexity3.3654656410217285
INFO:root:current mean train loss 1544.142053625086
INFO:root:current train perplexity3.367414712905884
INFO:root:current mean train loss 1543.6867570206925
INFO:root:current train perplexity3.3641350269317627
INFO:root:current mean train loss 1543.5976042536379
INFO:root:current train perplexity3.3694095611572266
INFO:root:current mean train loss 1545.8341785557222
INFO:root:current train perplexity3.376011371612549
INFO:root:current mean train loss 1546.9027792055008
INFO:root:current train perplexity3.380094289779663
INFO:root:current mean train loss 1547.2519195077307
INFO:root:current train perplexity3.381209135055542
INFO:root:current mean train loss 1548.714922661804
INFO:root:current train perplexity3.3837413787841797
INFO:root:current mean train loss 1547.6859666700486
INFO:root:current train perplexity3.38275146484375
INFO:root:current mean train loss 1548.7414709326756
INFO:root:current train perplexity3.387479782104492
INFO:root:current mean train loss 1548.6957440253113
INFO:root:current train perplexity3.3891491889953613
INFO:root:current mean train loss 1549.0999906035224
INFO:root:current train perplexity3.389259099960327
INFO:root:current mean train loss 1550.3273970527282
INFO:root:current train perplexity3.3919310569763184
INFO:root:current mean train loss 1550.521790841555
INFO:root:current train perplexity3.3935861587524414
INFO:root:current mean train loss 1551.6561256343482
INFO:root:current train perplexity3.395582437515259
INFO:root:current mean train loss 1551.2664536303907
INFO:root:current train perplexity3.3974130153656006
INFO:root:current mean train loss 1552.5637251988092
INFO:root:current train perplexity3.4014523029327393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.35s/it]
INFO:root:final mean train loss: 1552.4629580622302
INFO:root:final train perplexity: 3.402007579803467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 2057.2444007819427
INFO:root:eval perplexity: 5.279219627380371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2556.649446960882
INFO:root:eval perplexity: 8.092181205749512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [12:09:16<23:09:04, 636.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1555.8512234157986
INFO:root:current train perplexity3.3851065635681152
INFO:root:current mean train loss 1548.0226390749908
INFO:root:current train perplexity3.371320962905884
INFO:root:current mean train loss 1546.3225012386547
INFO:root:current train perplexity3.3752198219299316
INFO:root:current mean train loss 1545.3014024303804
INFO:root:current train perplexity3.3742411136627197
INFO:root:current mean train loss 1540.6707476599743
INFO:root:current train perplexity3.3687126636505127
INFO:root:current mean train loss 1538.8257836828698
INFO:root:current train perplexity3.365922451019287
INFO:root:current mean train loss 1539.6351912362236
INFO:root:current train perplexity3.3673417568206787
INFO:root:current mean train loss 1541.1652492068592
INFO:root:current train perplexity3.3701539039611816
INFO:root:current mean train loss 1541.380429889084
INFO:root:current train perplexity3.3722751140594482
INFO:root:current mean train loss 1543.2233522517201
INFO:root:current train perplexity3.3749117851257324
INFO:root:current mean train loss 1542.2848174821086
INFO:root:current train perplexity3.377249240875244
INFO:root:current mean train loss 1542.416389960071
INFO:root:current train perplexity3.3765950202941895
INFO:root:current mean train loss 1541.9090747953212
INFO:root:current train perplexity3.3776755332946777
INFO:root:current mean train loss 1543.333345463255
INFO:root:current train perplexity3.3804731369018555
INFO:root:current mean train loss 1544.0769192239513
INFO:root:current train perplexity3.3818717002868652
INFO:root:current mean train loss 1544.1923626227538
INFO:root:current train perplexity3.381836175918579
INFO:root:current mean train loss 1544.680524324116
INFO:root:current train perplexity3.3817222118377686
INFO:root:current mean train loss 1546.2618911088723
INFO:root:current train perplexity3.384265184402466
INFO:root:current mean train loss 1547.2233972141885
INFO:root:current train perplexity3.3863425254821777
INFO:root:current mean train loss 1547.9631354465446
INFO:root:current train perplexity3.388862371444702

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.02s/it]
INFO:root:final mean train loss: 1547.5651590152033
INFO:root:final train perplexity: 3.38889217376709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 2062.4904239735706
INFO:root:eval perplexity: 5.301665306091309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2562.750496938719
INFO:root:eval perplexity: 8.132658958435059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [12:19:57<23:01:28, 637.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1513.1556931399227
INFO:root:current train perplexity3.333167791366577
INFO:root:current mean train loss 1519.6263208136988
INFO:root:current train perplexity3.33648943901062
INFO:root:current mean train loss 1528.7927182735457
INFO:root:current train perplexity3.3358986377716064
INFO:root:current mean train loss 1528.3008393040047
INFO:root:current train perplexity3.3413028717041016
INFO:root:current mean train loss 1530.0294756118992
INFO:root:current train perplexity3.3459420204162598
INFO:root:current mean train loss 1531.4060775679118
INFO:root:current train perplexity3.350114345550537
INFO:root:current mean train loss 1532.8978967763517
INFO:root:current train perplexity3.3529460430145264
INFO:root:current mean train loss 1534.5440191116622
INFO:root:current train perplexity3.3533432483673096
INFO:root:current mean train loss 1536.1389898894474
INFO:root:current train perplexity3.3580868244171143
INFO:root:current mean train loss 1537.9715394732684
INFO:root:current train perplexity3.36279034614563
INFO:root:current mean train loss 1536.467531314566
INFO:root:current train perplexity3.360445976257324
INFO:root:current mean train loss 1536.8017943617274
INFO:root:current train perplexity3.3610684871673584
INFO:root:current mean train loss 1536.3050794697622
INFO:root:current train perplexity3.3600001335144043
INFO:root:current mean train loss 1537.298973220814
INFO:root:current train perplexity3.3634352684020996
INFO:root:current mean train loss 1538.3494459860592
INFO:root:current train perplexity3.3652288913726807
INFO:root:current mean train loss 1539.2978382722772
INFO:root:current train perplexity3.3678972721099854
INFO:root:current mean train loss 1539.8190837022184
INFO:root:current train perplexity3.3690831661224365
INFO:root:current mean train loss 1540.8993192857174
INFO:root:current train perplexity3.3699393272399902
INFO:root:current mean train loss 1542.003965249574
INFO:root:current train perplexity3.3730907440185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.93s/it]
INFO:root:final mean train loss: 1542.0251908987625
INFO:root:final train perplexity: 3.374117136001587
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2062.2434103674923
INFO:root:eval perplexity: 5.300606727600098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2565.434855143229
INFO:root:eval perplexity: 8.150532722473145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [12:30:29<22:47:36, 636.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1557.458516438802
INFO:root:current train perplexity3.3151602745056152
INFO:root:current mean train loss 1514.3256283166274
INFO:root:current train perplexity3.3125877380371094
INFO:root:current mean train loss 1525.6698134338972
INFO:root:current train perplexity3.317270278930664
INFO:root:current mean train loss 1527.6649935853247
INFO:root:current train perplexity3.3236663341522217
INFO:root:current mean train loss 1529.7132372926608
INFO:root:current train perplexity3.3266773223876953
INFO:root:current mean train loss 1527.4919826824203
INFO:root:current train perplexity3.329526901245117
INFO:root:current mean train loss 1527.6769229901506
INFO:root:current train perplexity3.3290252685546875
INFO:root:current mean train loss 1527.0780442537734
INFO:root:current train perplexity3.330658197402954
INFO:root:current mean train loss 1527.3089672306335
INFO:root:current train perplexity3.337282419204712
INFO:root:current mean train loss 1528.2182712849665
INFO:root:current train perplexity3.3420164585113525
INFO:root:current mean train loss 1529.985111668854
INFO:root:current train perplexity3.343533754348755
INFO:root:current mean train loss 1531.933104916895
INFO:root:current train perplexity3.3471364974975586
INFO:root:current mean train loss 1532.6735213297122
INFO:root:current train perplexity3.348445177078247
INFO:root:current mean train loss 1533.4408019739126
INFO:root:current train perplexity3.351405382156372
INFO:root:current mean train loss 1534.002233730441
INFO:root:current train perplexity3.352433443069458
INFO:root:current mean train loss 1534.905210294888
INFO:root:current train perplexity3.354179620742798
INFO:root:current mean train loss 1535.2956729950674
INFO:root:current train perplexity3.3551225662231445
INFO:root:current mean train loss 1536.101846639045
INFO:root:current train perplexity3.35540771484375
INFO:root:current mean train loss 1536.482991130909
INFO:root:current train perplexity3.3567569255828857
INFO:root:current mean train loss 1537.1490918506731
INFO:root:current train perplexity3.3586068153381348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.36s/it]
INFO:root:final mean train loss: 1537.077515971943
INFO:root:final train perplexity: 3.3609771728515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2067.454863852643
INFO:root:eval perplexity: 5.322995185852051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2571.1513801737033
INFO:root:eval perplexity: 8.188724517822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [12:41:03<22:35:23, 635.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1551.9833400560462
INFO:root:current train perplexity3.3396012783050537
INFO:root:current mean train loss 1535.159455586255
INFO:root:current train perplexity3.334782838821411
INFO:root:current mean train loss 1526.9512107404357
INFO:root:current train perplexity3.321373224258423
INFO:root:current mean train loss 1526.121219977506
INFO:root:current train perplexity3.321106195449829
INFO:root:current mean train loss 1526.9729107795877
INFO:root:current train perplexity3.3214128017425537
INFO:root:current mean train loss 1526.3955626624493
INFO:root:current train perplexity3.3236255645751953
INFO:root:current mean train loss 1526.243940570764
INFO:root:current train perplexity3.3250186443328857
INFO:root:current mean train loss 1526.4392408948715
INFO:root:current train perplexity3.329709053039551
INFO:root:current mean train loss 1525.9831280436001
INFO:root:current train perplexity3.330254077911377
INFO:root:current mean train loss 1527.1469657790492
INFO:root:current train perplexity3.3336715698242188
INFO:root:current mean train loss 1526.5999831034642
INFO:root:current train perplexity3.3356282711029053
INFO:root:current mean train loss 1527.600646266105
INFO:root:current train perplexity3.3373234272003174
INFO:root:current mean train loss 1528.0720412471892
INFO:root:current train perplexity3.3383312225341797
INFO:root:current mean train loss 1528.5017574249753
INFO:root:current train perplexity3.3391928672790527
INFO:root:current mean train loss 1529.0123276432382
INFO:root:current train perplexity3.3406269550323486
INFO:root:current mean train loss 1530.8339415742469
INFO:root:current train perplexity3.3432376384735107
INFO:root:current mean train loss 1530.7321591568227
INFO:root:current train perplexity3.3446104526519775
INFO:root:current mean train loss 1530.855560851803
INFO:root:current train perplexity3.3447153568267822
INFO:root:current mean train loss 1531.5733282326737
INFO:root:current train perplexity3.347245454788208
INFO:root:current mean train loss 1532.6286605223975
INFO:root:current train perplexity3.349072217941284

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.58s/it]
INFO:root:final mean train loss: 1532.6093706601325
INFO:root:final train perplexity: 3.349154472351074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2069.645746758644
INFO:root:eval perplexity: 5.332435607910156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2574.224606344886
INFO:root:eval perplexity: 8.209332466125488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:51:38<22:24:38, 635.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1516.4029388427734
INFO:root:current train perplexity3.3042778968811035
INFO:root:current mean train loss 1512.1224461146764
INFO:root:current train perplexity3.2877140045166016
INFO:root:current mean train loss 1520.5409840901693
INFO:root:current train perplexity3.296887159347534
INFO:root:current mean train loss 1518.279031192555
INFO:root:current train perplexity3.303776979446411
INFO:root:current mean train loss 1518.4496562610973
INFO:root:current train perplexity3.304189682006836
INFO:root:current mean train loss 1520.629955376519
INFO:root:current train perplexity3.306379556655884
INFO:root:current mean train loss 1520.5694856643677
INFO:root:current train perplexity3.3094494342803955
INFO:root:current mean train loss 1520.4287399704392
INFO:root:current train perplexity3.3106882572174072
INFO:root:current mean train loss 1521.3040829613096
INFO:root:current train perplexity3.312641143798828
INFO:root:current mean train loss 1522.1304775806184
INFO:root:current train perplexity3.3148374557495117
INFO:root:current mean train loss 1521.826514845628
INFO:root:current train perplexity3.3164892196655273
INFO:root:current mean train loss 1522.0105303848
INFO:root:current train perplexity3.3173255920410156
INFO:root:current mean train loss 1523.4347472160093
INFO:root:current train perplexity3.3211874961853027
INFO:root:current mean train loss 1524.2042799309118
INFO:root:current train perplexity3.3238003253936768
INFO:root:current mean train loss 1524.5467579311794
INFO:root:current train perplexity3.3248631954193115
INFO:root:current mean train loss 1524.6108569653004
INFO:root:current train perplexity3.325464963912964
INFO:root:current mean train loss 1524.1511186553212
INFO:root:current train perplexity3.3259387016296387
INFO:root:current mean train loss 1525.2375282726068
INFO:root:current train perplexity3.3268516063690186
INFO:root:current mean train loss 1526.335099394425
INFO:root:current train perplexity3.32967209815979
INFO:root:current mean train loss 1526.6221498469718
INFO:root:current train perplexity3.331125259399414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.39s/it]
INFO:root:final mean train loss: 1526.2767670401045
INFO:root:final train perplexity: 3.3324697017669678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2072.668370889434
INFO:root:eval perplexity: 5.345485687255859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2576.3784707793106
INFO:root:eval perplexity: 8.223803520202637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [13:02:24<22:20:53, 638.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1481.4462612219024
INFO:root:current train perplexity3.264796733856201
INFO:root:current mean train loss 1507.1530077502985
INFO:root:current train perplexity3.2863707542419434
INFO:root:current mean train loss 1512.4912769599648
INFO:root:current train perplexity3.291391372680664
INFO:root:current mean train loss 1507.8924348548012
INFO:root:current train perplexity3.2888004779815674
INFO:root:current mean train loss 1511.0802517479829
INFO:root:current train perplexity3.2906363010406494
INFO:root:current mean train loss 1508.5303271309049
INFO:root:current train perplexity3.2930548191070557
INFO:root:current mean train loss 1510.7962046351788
INFO:root:current train perplexity3.2956879138946533
INFO:root:current mean train loss 1512.8053049467987
INFO:root:current train perplexity3.3004438877105713
INFO:root:current mean train loss 1513.601754650352
INFO:root:current train perplexity3.3044772148132324
INFO:root:current mean train loss 1515.5007722190928
INFO:root:current train perplexity3.3063805103302
INFO:root:current mean train loss 1516.1012335915327
INFO:root:current train perplexity3.3067946434020996
INFO:root:current mean train loss 1516.9220553095627
INFO:root:current train perplexity3.3097774982452393
INFO:root:current mean train loss 1517.7813806162055
INFO:root:current train perplexity3.311061143875122
INFO:root:current mean train loss 1518.0589712953954
INFO:root:current train perplexity3.3111159801483154
INFO:root:current mean train loss 1518.6858000640764
INFO:root:current train perplexity3.3121302127838135
INFO:root:current mean train loss 1519.4005521310012
INFO:root:current train perplexity3.3148438930511475
INFO:root:current mean train loss 1519.8035118089215
INFO:root:current train perplexity3.316004991531372
INFO:root:current mean train loss 1520.5317518291788
INFO:root:current train perplexity3.316962242126465
INFO:root:current mean train loss 1521.9494784698734
INFO:root:current train perplexity3.3197038173675537
INFO:root:current mean train loss 1522.046801832664
INFO:root:current train perplexity3.3203279972076416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.91s/it]
INFO:root:final mean train loss: 1521.654063260862
INFO:root:final train perplexity: 3.3203423023223877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2072.071128899324
INFO:root:eval perplexity: 5.342904567718506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2580.1544124522106
INFO:root:eval perplexity: 8.24924373626709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [13:12:54<22:04:50, 635.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1506.3463514173352
INFO:root:current train perplexity3.2736241817474365
INFO:root:current mean train loss 1503.4279658876617
INFO:root:current train perplexity3.2751457691192627
INFO:root:current mean train loss 1501.95974130004
INFO:root:current train perplexity3.2797329425811768
INFO:root:current mean train loss 1503.3431781626002
INFO:root:current train perplexity3.2809557914733887
INFO:root:current mean train loss 1504.2556069933412
INFO:root:current train perplexity3.2799673080444336
INFO:root:current mean train loss 1507.947111016782
INFO:root:current train perplexity3.283562183380127
INFO:root:current mean train loss 1509.1349152245225
INFO:root:current train perplexity3.286778211593628
INFO:root:current mean train loss 1509.3553810612484
INFO:root:current train perplexity3.284729242324829
INFO:root:current mean train loss 1509.4205009408074
INFO:root:current train perplexity3.2881810665130615
INFO:root:current mean train loss 1510.480895620107
INFO:root:current train perplexity3.287930965423584
INFO:root:current mean train loss 1512.1408162889534
INFO:root:current train perplexity3.290053367614746
INFO:root:current mean train loss 1511.9005227811901
INFO:root:current train perplexity3.292114734649658
INFO:root:current mean train loss 1512.2527586549193
INFO:root:current train perplexity3.2952065467834473
INFO:root:current mean train loss 1514.0799188294611
INFO:root:current train perplexity3.297809362411499
INFO:root:current mean train loss 1514.5409174884192
INFO:root:current train perplexity3.2996087074279785
INFO:root:current mean train loss 1515.1839018728408
INFO:root:current train perplexity3.302335262298584
INFO:root:current mean train loss 1516.213401001414
INFO:root:current train perplexity3.303830146789551
INFO:root:current mean train loss 1516.8745972505417
INFO:root:current train perplexity3.3048431873321533
INFO:root:current mean train loss 1516.9809606790288
INFO:root:current train perplexity3.305973768234253
INFO:root:current mean train loss 1516.8468527132013
INFO:root:current train perplexity3.3068227767944336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.45s/it]
INFO:root:final mean train loss: 1516.5439880340314
INFO:root:final train perplexity: 3.306987762451172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 2078.9367732054798
INFO:root:eval perplexity: 5.372654438018799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2587.7517146117298
INFO:root:eval perplexity: 8.300655364990234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [13:23:33<21:56:15, 636.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.4127036293785
INFO:root:current train perplexity3.2787575721740723
INFO:root:current mean train loss 1497.2611870091623
INFO:root:current train perplexity3.2765419483184814
INFO:root:current mean train loss 1494.4362465769975
INFO:root:current train perplexity3.2781355381011963
INFO:root:current mean train loss 1495.1389878216912
INFO:root:current train perplexity3.2687065601348877
INFO:root:current mean train loss 1495.336435974494
INFO:root:current train perplexity3.270578145980835
INFO:root:current mean train loss 1495.2151494421532
INFO:root:current train perplexity3.267711639404297
INFO:root:current mean train loss 1498.4191915730146
INFO:root:current train perplexity3.2687623500823975
INFO:root:current mean train loss 1499.1754576324965
INFO:root:current train perplexity3.272265672683716
INFO:root:current mean train loss 1501.773158012416
INFO:root:current train perplexity3.2773196697235107
INFO:root:current mean train loss 1503.1006972912462
INFO:root:current train perplexity3.2781693935394287
INFO:root:current mean train loss 1503.8758286459527
INFO:root:current train perplexity3.280817747116089
INFO:root:current mean train loss 1505.645963910645
INFO:root:current train perplexity3.283005475997925
INFO:root:current mean train loss 1506.228670411291
INFO:root:current train perplexity3.2844393253326416
INFO:root:current mean train loss 1507.662377122321
INFO:root:current train perplexity3.285304546356201
INFO:root:current mean train loss 1508.4121219832014
INFO:root:current train perplexity3.2864787578582764
INFO:root:current mean train loss 1509.5055323708066
INFO:root:current train perplexity3.2894420623779297
INFO:root:current mean train loss 1510.0541964755969
INFO:root:current train perplexity3.2914211750030518
INFO:root:current mean train loss 1511.4565775246676
INFO:root:current train perplexity3.292823553085327
INFO:root:current mean train loss 1511.451069364341
INFO:root:current train perplexity3.293837070465088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.20s/it]
INFO:root:final mean train loss: 1511.6438817472933
INFO:root:final train perplexity: 3.2942326068878174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2080.4868614250886
INFO:root:eval perplexity: 5.379392623901367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2590.823268159907
INFO:root:eval perplexity: 8.321534156799316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [13:34:08<21:44:18, 636.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1458.9508666992188
INFO:root:current train perplexity3.2264344692230225
INFO:root:current mean train loss 1497.0123901367188
INFO:root:current train perplexity3.244762897491455
INFO:root:current mean train loss 1496.7923337496245
INFO:root:current train perplexity3.258739471435547
INFO:root:current mean train loss 1495.6525886832894
INFO:root:current train perplexity3.26387095451355
INFO:root:current mean train loss 1496.0104753082874
INFO:root:current train perplexity3.260087013244629
INFO:root:current mean train loss 1497.0599247489388
INFO:root:current train perplexity3.2622528076171875
INFO:root:current mean train loss 1496.2350399619654
INFO:root:current train perplexity3.2625327110290527
INFO:root:current mean train loss 1496.2786175571594
INFO:root:current train perplexity3.2632057666778564
INFO:root:current mean train loss 1499.6351913603226
INFO:root:current train perplexity3.2656679153442383
INFO:root:current mean train loss 1500.9568999034193
INFO:root:current train perplexity3.2674334049224854
INFO:root:current mean train loss 1502.0051185971215
INFO:root:current train perplexity3.270195484161377
INFO:root:current mean train loss 1502.847933772669
INFO:root:current train perplexity3.2713916301727295
INFO:root:current mean train loss 1503.2331994669328
INFO:root:current train perplexity3.2720959186553955
INFO:root:current mean train loss 1504.4976397873065
INFO:root:current train perplexity3.2740118503570557
INFO:root:current mean train loss 1504.6933861645784
INFO:root:current train perplexity3.275172233581543
INFO:root:current mean train loss 1505.646681079814
INFO:root:current train perplexity3.2773265838623047
INFO:root:current mean train loss 1506.8064162980265
INFO:root:current train perplexity3.2784719467163086
INFO:root:current mean train loss 1506.6943811063745
INFO:root:current train perplexity3.2788796424865723
INFO:root:current mean train loss 1506.7739431330588
INFO:root:current train perplexity3.2803969383239746
INFO:root:current mean train loss 1506.9589283301395
INFO:root:current train perplexity3.2815101146698

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.99s/it]
INFO:root:final mean train loss: 1506.9811289638687
INFO:root:final train perplexity: 3.2821412086486816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 2086.0251720239085
INFO:root:eval perplexity: 5.403542518615723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2598.3593589836823
INFO:root:eval perplexity: 8.372979164123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [13:44:47<21:35:40, 637.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1488.9907177734376
INFO:root:current train perplexity3.241227865219116
INFO:root:current mean train loss 1484.4134990234375
INFO:root:current train perplexity3.259003162384033
INFO:root:current mean train loss 1485.4946294487847
INFO:root:current train perplexity3.2432422637939453
INFO:root:current mean train loss 1489.625342548077
INFO:root:current train perplexity3.249117612838745
INFO:root:current mean train loss 1491.2159323299632
INFO:root:current train perplexity3.2531697750091553
INFO:root:current mean train loss 1492.8658837890625
INFO:root:current train perplexity3.2531425952911377
INFO:root:current mean train loss 1490.477176171875
INFO:root:current train perplexity3.255321502685547
INFO:root:current mean train loss 1490.8417694302263
INFO:root:current train perplexity3.2532694339752197
INFO:root:current mean train loss 1493.3627530184658
INFO:root:current train perplexity3.253588914871216
INFO:root:current mean train loss 1494.6927099609375
INFO:root:current train perplexity3.256762742996216
INFO:root:current mean train loss 1494.4583477038873
INFO:root:current train perplexity3.259307861328125
INFO:root:current mean train loss 1496.2439729817709
INFO:root:current train perplexity3.260164260864258
INFO:root:current mean train loss 1498.0400867944834
INFO:root:current train perplexity3.262097120285034
INFO:root:current mean train loss 1498.4826275980247
INFO:root:current train perplexity3.2623131275177
INFO:root:current mean train loss 1499.6534503495066
INFO:root:current train perplexity3.264132022857666
INFO:root:current mean train loss 1499.9072552190062
INFO:root:current train perplexity3.2637741565704346
INFO:root:current mean train loss 1499.9292866586538
INFO:root:current train perplexity3.264970302581787
INFO:root:current mean train loss 1500.4660319010416
INFO:root:current train perplexity3.2643980979919434
INFO:root:current mean train loss 1501.7471037564212
INFO:root:current train perplexity3.266392707824707
INFO:root:current mean train loss 1502.186512847504
INFO:root:current train perplexity3.268214464187622

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.19s/it]
INFO:root:final mean train loss: 1501.8852836389585
INFO:root:final train perplexity: 3.2689766883850098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2087.4942068546375
INFO:root:eval perplexity: 5.409965991973877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2600.5427631351117
INFO:root:eval perplexity: 8.387945175170898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:55:22<21:23:19, 636.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1493.3394862583705
INFO:root:current train perplexity3.233869791030884
INFO:root:current mean train loss 1501.2513883348922
INFO:root:current train perplexity3.2445948123931885
INFO:root:current mean train loss 1498.0877549352724
INFO:root:current train perplexity3.2435357570648193
INFO:root:current mean train loss 1494.2060921652276
INFO:root:current train perplexity3.2405455112457275
INFO:root:current mean train loss 1492.6732230208038
INFO:root:current train perplexity3.2446258068084717
INFO:root:current mean train loss 1490.8525241978493
INFO:root:current train perplexity3.239689826965332
INFO:root:current mean train loss 1492.6069957697503
INFO:root:current train perplexity3.2412359714508057
INFO:root:current mean train loss 1492.8889318090887
INFO:root:current train perplexity3.2422564029693604
INFO:root:current mean train loss 1491.9861737249016
INFO:root:current train perplexity3.242799997329712
INFO:root:current mean train loss 1492.5140349758658
INFO:root:current train perplexity3.2459068298339844
INFO:root:current mean train loss 1494.1940395479696
INFO:root:current train perplexity3.24731707572937
INFO:root:current mean train loss 1492.5695978221459
INFO:root:current train perplexity3.246654510498047
INFO:root:current mean train loss 1493.2618432774443
INFO:root:current train perplexity3.248751163482666
INFO:root:current mean train loss 1492.9344204989347
INFO:root:current train perplexity3.248446464538574
INFO:root:current mean train loss 1493.8490603972077
INFO:root:current train perplexity3.2507681846618652
INFO:root:current mean train loss 1494.9833070826746
INFO:root:current train perplexity3.2518603801727295
INFO:root:current mean train loss 1495.6044486228209
INFO:root:current train perplexity3.2525112628936768
INFO:root:current mean train loss 1495.6681618060913
INFO:root:current train perplexity3.253371000289917
INFO:root:current mean train loss 1496.7583199997032
INFO:root:current train perplexity3.2546393871307373
INFO:root:current mean train loss 1496.804242402223
INFO:root:current train perplexity3.2553951740264893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.13s/it]
INFO:root:final mean train loss: 1496.812215353946
INFO:root:final train perplexity: 3.2559239864349365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 2090.3513711699356
INFO:root:eval perplexity: 5.422480583190918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2603.505628653452
INFO:root:eval perplexity: 8.408291816711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [14:05:54<21:10:37, 635.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1478.8399306475105
INFO:root:current train perplexity3.198814630508423
INFO:root:current mean train loss 1473.675777411311
INFO:root:current train perplexity3.193331241607666
INFO:root:current mean train loss 1475.255071809393
INFO:root:current train perplexity3.205970048904419
INFO:root:current mean train loss 1481.3263228477542
INFO:root:current train perplexity3.2144906520843506
INFO:root:current mean train loss 1480.5837511382592
INFO:root:current train perplexity3.2148709297180176
INFO:root:current mean train loss 1482.4936215532061
INFO:root:current train perplexity3.2137696743011475
INFO:root:current mean train loss 1483.9770478174792
INFO:root:current train perplexity3.2168214321136475
INFO:root:current mean train loss 1484.2142625087492
INFO:root:current train perplexity3.2199559211730957
INFO:root:current mean train loss 1483.8494614411288
INFO:root:current train perplexity3.2224442958831787
INFO:root:current mean train loss 1485.540537145016
INFO:root:current train perplexity3.2262768745422363
INFO:root:current mean train loss 1486.3607480892942
INFO:root:current train perplexity3.2279505729675293
INFO:root:current mean train loss 1487.0224660983674
INFO:root:current train perplexity3.2298390865325928
INFO:root:current mean train loss 1488.808653864054
INFO:root:current train perplexity3.2326855659484863
INFO:root:current mean train loss 1489.6957960205975
INFO:root:current train perplexity3.234781503677368
INFO:root:current mean train loss 1490.338099541772
INFO:root:current train perplexity3.2358343601226807
INFO:root:current mean train loss 1490.3171122063422
INFO:root:current train perplexity3.2373709678649902
INFO:root:current mean train loss 1491.3787453290997
INFO:root:current train perplexity3.238679885864258
INFO:root:current mean train loss 1491.8745278189845
INFO:root:current train perplexity3.241640329360962
INFO:root:current mean train loss 1491.7427860976163
INFO:root:current train perplexity3.2422735691070557
INFO:root:current mean train loss 1492.2939235654153
INFO:root:current train perplexity3.244133234024048

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.35s/it]
INFO:root:final mean train loss: 1492.4353311127986
INFO:root:final train perplexity: 3.244704484939575
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2092.381979651485
INFO:root:eval perplexity: 5.431393146514893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2606.7579826192655
INFO:root:eval perplexity: 8.43068790435791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [14:16:34<21:02:35, 636.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1470.3048641807154
INFO:root:current train perplexity3.2014875411987305
INFO:root:current mean train loss 1479.8280639648438
INFO:root:current train perplexity3.2097551822662354
INFO:root:current mean train loss 1477.6360734580219
INFO:root:current train perplexity3.207338333129883
INFO:root:current mean train loss 1477.9904645554564
INFO:root:current train perplexity3.209542751312256
INFO:root:current mean train loss 1478.561672178637
INFO:root:current train perplexity3.2049784660339355
INFO:root:current mean train loss 1481.315766652425
INFO:root:current train perplexity3.2071475982666016
INFO:root:current mean train loss 1481.6713397686299
INFO:root:current train perplexity3.2100303173065186
INFO:root:current mean train loss 1482.4722804433293
INFO:root:current train perplexity3.211935043334961
INFO:root:current mean train loss 1483.3522894872378
INFO:root:current train perplexity3.2145333290100098
INFO:root:current mean train loss 1483.9452620959673
INFO:root:current train perplexity3.2151973247528076
INFO:root:current mean train loss 1484.082003114835
INFO:root:current train perplexity3.2178351879119873
INFO:root:current mean train loss 1484.6478540329706
INFO:root:current train perplexity3.2198381423950195
INFO:root:current mean train loss 1486.158718192839
INFO:root:current train perplexity3.2233963012695312
INFO:root:current mean train loss 1486.0767934932264
INFO:root:current train perplexity3.2238855361938477
INFO:root:current mean train loss 1485.1572581552232
INFO:root:current train perplexity3.2243974208831787
INFO:root:current mean train loss 1485.694435778003
INFO:root:current train perplexity3.2258079051971436
INFO:root:current mean train loss 1485.8334319267183
INFO:root:current train perplexity3.2271037101745605
INFO:root:current mean train loss 1485.8351796468098
INFO:root:current train perplexity3.228029251098633
INFO:root:current mean train loss 1486.686400456215
INFO:root:current train perplexity3.229579210281372
INFO:root:current mean train loss 1487.4374198759133
INFO:root:current train perplexity3.231100559234619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.44s/it]
INFO:root:final mean train loss: 1487.1470086679155
INFO:root:final train perplexity: 3.2311999797821045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2097.573313611619
INFO:root:eval perplexity: 5.454245090484619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2613.3631526865856
INFO:root:eval perplexity: 8.47635269165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [14:27:11<20:52:21, 636.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1465.6123900054604
INFO:root:current train perplexity3.1766154766082764
INFO:root:current mean train loss 1471.1030608656492
INFO:root:current train perplexity3.1945245265960693
INFO:root:current mean train loss 1472.8750637432008
INFO:root:current train perplexity3.1979169845581055
INFO:root:current mean train loss 1475.2438119980518
INFO:root:current train perplexity3.198361873626709
INFO:root:current mean train loss 1475.4598136112609
INFO:root:current train perplexity3.1976497173309326
INFO:root:current mean train loss 1479.531436707881
INFO:root:current train perplexity3.2058265209198
INFO:root:current mean train loss 1478.4533337349499
INFO:root:current train perplexity3.209447145462036
INFO:root:current mean train loss 1479.130828588036
INFO:root:current train perplexity3.211961507797241
INFO:root:current mean train loss 1479.2742128446948
INFO:root:current train perplexity3.2109129428863525
INFO:root:current mean train loss 1480.665296725516
INFO:root:current train perplexity3.212310791015625
INFO:root:current mean train loss 1481.4107126583228
INFO:root:current train perplexity3.213078260421753
INFO:root:current mean train loss 1481.578652163663
INFO:root:current train perplexity3.2152187824249268
INFO:root:current mean train loss 1480.872321439361
INFO:root:current train perplexity3.215021848678589
INFO:root:current mean train loss 1481.0096305852644
INFO:root:current train perplexity3.215801239013672
INFO:root:current mean train loss 1481.290837057309
INFO:root:current train perplexity3.215941905975342
INFO:root:current mean train loss 1482.4804442286566
INFO:root:current train perplexity3.2161483764648438
INFO:root:current mean train loss 1482.6316203496474
INFO:root:current train perplexity3.218540668487549
INFO:root:current mean train loss 1482.8416972035345
INFO:root:current train perplexity3.2195796966552734
INFO:root:current mean train loss 1483.1533516522634
INFO:root:current train perplexity3.2196147441864014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.98s/it]
INFO:root:final mean train loss: 1482.9451670682736
INFO:root:final train perplexity: 3.220510244369507
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 2099.4404980815048
INFO:root:eval perplexity: 5.462486743927002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2617.600899337877
INFO:root:eval perplexity: 8.505779266357422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [14:37:49<20:42:10, 637.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1431.2657958984375
INFO:root:current train perplexity3.1194000244140625
INFO:root:current mean train loss 1458.643808815696
INFO:root:current train perplexity3.1626648902893066
INFO:root:current mean train loss 1462.5771263485863
INFO:root:current train perplexity3.1658103466033936
INFO:root:current mean train loss 1464.1590005197834
INFO:root:current train perplexity3.167342185974121
INFO:root:current mean train loss 1462.6250369188263
INFO:root:current train perplexity3.167546510696411
INFO:root:current mean train loss 1465.149360926011
INFO:root:current train perplexity3.1734402179718018
INFO:root:current mean train loss 1465.5626108638576
INFO:root:current train perplexity3.1791980266571045
INFO:root:current mean train loss 1466.016387337698
INFO:root:current train perplexity3.1826326847076416
INFO:root:current mean train loss 1466.773282576196
INFO:root:current train perplexity3.185398578643799
INFO:root:current mean train loss 1467.4557013543097
INFO:root:current train perplexity3.1878256797790527
INFO:root:current mean train loss 1469.936478960396
INFO:root:current train perplexity3.1894233226776123
INFO:root:current mean train loss 1470.8628108943906
INFO:root:current train perplexity3.191913366317749
INFO:root:current mean train loss 1472.2703257158769
INFO:root:current train perplexity3.1943979263305664
INFO:root:current mean train loss 1472.2970944470121
INFO:root:current train perplexity3.19586443901062
INFO:root:current mean train loss 1473.1670646505154
INFO:root:current train perplexity3.1987485885620117
INFO:root:current mean train loss 1474.0514258782596
INFO:root:current train perplexity3.199709177017212
INFO:root:current mean train loss 1474.5407883164305
INFO:root:current train perplexity3.2007007598876953
INFO:root:current mean train loss 1474.4602711103116
INFO:root:current train perplexity3.201781988143921
INFO:root:current mean train loss 1476.6644509668508
INFO:root:current train perplexity3.2057156562805176
INFO:root:current mean train loss 1477.7777259387271
INFO:root:current train perplexity3.2067348957061768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.18s/it]
INFO:root:final mean train loss: 1478.445887763273
INFO:root:final train perplexity: 3.2091028690338135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.45s/it]
INFO:root:eval mean loss: 2099.9978408272386
INFO:root:eval perplexity: 5.464950084686279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it]
INFO:root:eval mean loss: 2618.3350228384033
INFO:root:eval perplexity: 8.510889053344727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [14:48:34<20:36:07, 639.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.2811279296875
INFO:root:current train perplexity3.162379026412964
INFO:root:current mean train loss 1465.3922628567914
INFO:root:current train perplexity3.176887035369873
INFO:root:current mean train loss 1469.742407979419
INFO:root:current train perplexity3.1786837577819824
INFO:root:current mean train loss 1465.7221287718608
INFO:root:current train perplexity3.179501533508301
INFO:root:current mean train loss 1466.6000922245498
INFO:root:current train perplexity3.1788992881774902
INFO:root:current mean train loss 1466.3580088316828
INFO:root:current train perplexity3.1757097244262695
INFO:root:current mean train loss 1467.809284313634
INFO:root:current train perplexity3.1785120964050293
INFO:root:current mean train loss 1469.992421733956
INFO:root:current train perplexity3.1819825172424316
INFO:root:current mean train loss 1470.4304575614515
INFO:root:current train perplexity3.1834022998809814
INFO:root:current mean train loss 1469.1303115729504
INFO:root:current train perplexity3.181225061416626
INFO:root:current mean train loss 1469.1079272722432
INFO:root:current train perplexity3.1811838150024414
INFO:root:current mean train loss 1471.402446323723
INFO:root:current train perplexity3.1838600635528564
INFO:root:current mean train loss 1471.6006108092017
INFO:root:current train perplexity3.185868740081787
INFO:root:current mean train loss 1472.4237943647854
INFO:root:current train perplexity3.1885480880737305
INFO:root:current mean train loss 1472.9624925064054
INFO:root:current train perplexity3.1893327236175537
INFO:root:current mean train loss 1472.9595785784268
INFO:root:current train perplexity3.1911890506744385
INFO:root:current mean train loss 1472.6839709900314
INFO:root:current train perplexity3.191244125366211
INFO:root:current mean train loss 1473.1286037955315
INFO:root:current train perplexity3.193567991256714
INFO:root:current mean train loss 1473.9349423363096
INFO:root:current train perplexity3.196187973022461
INFO:root:current mean train loss 1474.8612466603286
INFO:root:current train perplexity3.1983039379119873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.85s/it]
INFO:root:final mean train loss: 1474.4741008410356
INFO:root:final train perplexity: 3.199066638946533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 2104.70634211547
INFO:root:eval perplexity: 5.485799789428711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.09s/it]
INFO:root:eval mean loss: 2624.5147601188496
INFO:root:eval perplexity: 8.554012298583984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [14:59:26<20:32:40, 643.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.4975169788706
INFO:root:current train perplexity3.1391355991363525
INFO:root:current mean train loss 1458.0889502631294
INFO:root:current train perplexity3.167863368988037
INFO:root:current mean train loss 1461.7570875824474
INFO:root:current train perplexity3.1761038303375244
INFO:root:current mean train loss 1461.9308159406794
INFO:root:current train perplexity3.169619083404541
INFO:root:current mean train loss 1463.3207411207595
INFO:root:current train perplexity3.1711747646331787
INFO:root:current mean train loss 1463.122340707218
INFO:root:current train perplexity3.169649362564087
INFO:root:current mean train loss 1464.7587991086593
INFO:root:current train perplexity3.1711182594299316
INFO:root:current mean train loss 1467.1574136057209
INFO:root:current train perplexity3.1740236282348633
INFO:root:current mean train loss 1467.9672909415729
INFO:root:current train perplexity3.174872875213623
INFO:root:current mean train loss 1467.3754029354807
INFO:root:current train perplexity3.1730408668518066
INFO:root:current mean train loss 1467.081427563196
INFO:root:current train perplexity3.1744303703308105
INFO:root:current mean train loss 1466.893430589796
INFO:root:current train perplexity3.175412178039551
INFO:root:current mean train loss 1467.918430733144
INFO:root:current train perplexity3.1766855716705322
INFO:root:current mean train loss 1468.260611761184
INFO:root:current train perplexity3.1775660514831543
INFO:root:current mean train loss 1469.4026588165198
INFO:root:current train perplexity3.1800763607025146
INFO:root:current mean train loss 1469.7848140736319
INFO:root:current train perplexity3.181584596633911
INFO:root:current mean train loss 1469.767139369844
INFO:root:current train perplexity3.1829476356506348
INFO:root:current mean train loss 1469.8152875987762
INFO:root:current train perplexity3.1848456859588623
INFO:root:current mean train loss 1469.613752451998
INFO:root:current train perplexity3.1856963634490967
INFO:root:current mean train loss 1469.9878367357294
INFO:root:current train perplexity3.187390089035034

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.87s/it]
INFO:root:final mean train loss: 1469.8407649099377
INFO:root:final train perplexity: 3.1873977184295654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2108.117612148853
INFO:root:eval perplexity: 5.500955581665039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2629.6061262847684
INFO:root:eval perplexity: 8.589703559875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [15:10:08<20:21:44, 643.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1443.546410732582
INFO:root:current train perplexity3.1180062294006348
INFO:root:current mean train loss 1447.2364365477
INFO:root:current train perplexity3.140213966369629
INFO:root:current mean train loss 1451.1875032739165
INFO:root:current train perplexity3.149355173110962
INFO:root:current mean train loss 1453.3860674829034
INFO:root:current train perplexity3.153012990951538
INFO:root:current mean train loss 1453.899920349783
INFO:root:current train perplexity3.154039144515991
INFO:root:current mean train loss 1453.7681429993872
INFO:root:current train perplexity3.157414674758911
INFO:root:current mean train loss 1455.0907355465795
INFO:root:current train perplexity3.156599998474121
INFO:root:current mean train loss 1457.240011087385
INFO:root:current train perplexity3.1611368656158447
INFO:root:current mean train loss 1457.8946102199932
INFO:root:current train perplexity3.16227388381958
INFO:root:current mean train loss 1458.0569299862611
INFO:root:current train perplexity3.163538932800293
INFO:root:current mean train loss 1458.58883750405
INFO:root:current train perplexity3.163846731185913
INFO:root:current mean train loss 1460.1115515525746
INFO:root:current train perplexity3.1656277179718018
INFO:root:current mean train loss 1460.566851840522
INFO:root:current train perplexity3.1670238971710205
INFO:root:current mean train loss 1461.8637019037587
INFO:root:current train perplexity3.1676740646362305
INFO:root:current mean train loss 1462.9146920686549
INFO:root:current train perplexity3.1694328784942627
INFO:root:current mean train loss 1462.7446302356511
INFO:root:current train perplexity3.168158769607544
INFO:root:current mean train loss 1462.4622954862941
INFO:root:current train perplexity3.1685423851013184
INFO:root:current mean train loss 1463.0557839146127
INFO:root:current train perplexity3.1700809001922607
INFO:root:current mean train loss 1464.183914176371
INFO:root:current train perplexity3.174088716506958
INFO:root:current mean train loss 1465.6624976843368
INFO:root:current train perplexity3.175551652908325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.82s/it]
INFO:root:final mean train loss: 1465.146781425072
INFO:root:final train perplexity: 3.1756200790405273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2111.721719078984
INFO:root:eval perplexity: 5.517012596130371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it]
INFO:root:eval mean loss: 2633.892007597795
INFO:root:eval perplexity: 8.619865417480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [15:20:44<20:06:38, 640.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1440.7859418820112
INFO:root:current train perplexity3.10862135887146
INFO:root:current mean train loss 1455.5591005475333
INFO:root:current train perplexity3.1356728076934814
INFO:root:current mean train loss 1450.907248956694
INFO:root:current train perplexity3.131592035293579
INFO:root:current mean train loss 1452.3392779637898
INFO:root:current train perplexity3.133108377456665
INFO:root:current mean train loss 1453.8530214700738
INFO:root:current train perplexity3.1396408081054688
INFO:root:current mean train loss 1453.5694113338695
INFO:root:current train perplexity3.138559103012085
INFO:root:current mean train loss 1454.6491436353476
INFO:root:current train perplexity3.141554832458496
INFO:root:current mean train loss 1455.165858565382
INFO:root:current train perplexity3.143683671951294
INFO:root:current mean train loss 1455.4950158329923
INFO:root:current train perplexity3.1491193771362305
INFO:root:current mean train loss 1456.8521413978624
INFO:root:current train perplexity3.1531519889831543
INFO:root:current mean train loss 1455.9959090592024
INFO:root:current train perplexity3.1537680625915527
INFO:root:current mean train loss 1457.6385947779606
INFO:root:current train perplexity3.1549816131591797
INFO:root:current mean train loss 1458.027656376082
INFO:root:current train perplexity3.1568186283111572
INFO:root:current mean train loss 1458.796770646714
INFO:root:current train perplexity3.1580498218536377
INFO:root:current mean train loss 1459.9231274182807
INFO:root:current train perplexity3.159369945526123
INFO:root:current mean train loss 1459.5348671646022
INFO:root:current train perplexity3.15926456451416
INFO:root:current mean train loss 1460.3558111725035
INFO:root:current train perplexity3.1610302925109863
INFO:root:current mean train loss 1460.479294320998
INFO:root:current train perplexity3.1616063117980957
INFO:root:current mean train loss 1460.8035951072034
INFO:root:current train perplexity3.163356065750122
INFO:root:current mean train loss 1461.336968123973
INFO:root:current train perplexity3.1651737689971924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.15s/it]
INFO:root:final mean train loss: 1460.9980018142492
INFO:root:final train perplexity: 3.1652462482452393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2115.365653396498
INFO:root:eval perplexity: 5.533295631408691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2636.0249434667276
INFO:root:eval perplexity: 8.63491153717041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [15:31:26<19:56:57, 641.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1447.6958675986841
INFO:root:current train perplexity3.131396770477295
INFO:root:current mean train loss 1444.0562493739983
INFO:root:current train perplexity3.124600410461426
INFO:root:current mean train loss 1448.2646244372352
INFO:root:current train perplexity3.130009174346924
INFO:root:current mean train loss 1444.2990725746638
INFO:root:current train perplexity3.129342794418335
INFO:root:current mean train loss 1447.1588396168718
INFO:root:current train perplexity3.131683349609375
INFO:root:current mean train loss 1448.2161257960215
INFO:root:current train perplexity3.1326839923858643
INFO:root:current mean train loss 1448.7025246599596
INFO:root:current train perplexity3.135207414627075
INFO:root:current mean train loss 1450.148299767836
INFO:root:current train perplexity3.13747239112854
INFO:root:current mean train loss 1452.4164501680343
INFO:root:current train perplexity3.1374950408935547
INFO:root:current mean train loss 1452.4171978054335
INFO:root:current train perplexity3.1418404579162598
INFO:root:current mean train loss 1453.972413781571
INFO:root:current train perplexity3.143326997756958
INFO:root:current mean train loss 1454.0731440204956
INFO:root:current train perplexity3.1459834575653076
INFO:root:current mean train loss 1454.28073570222
INFO:root:current train perplexity3.1459946632385254
INFO:root:current mean train loss 1454.9522698077676
INFO:root:current train perplexity3.1462442874908447
INFO:root:current mean train loss 1454.928525423286
INFO:root:current train perplexity3.1473453044891357
INFO:root:current mean train loss 1455.0562556634502
INFO:root:current train perplexity3.1500205993652344
INFO:root:current mean train loss 1455.4772048995208
INFO:root:current train perplexity3.150146722793579
INFO:root:current mean train loss 1455.7782745446336
INFO:root:current train perplexity3.1513023376464844
INFO:root:current mean train loss 1456.1549547019295
INFO:root:current train perplexity3.152611017227173

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.24s/it]
INFO:root:final mean train loss: 1456.6030283286843
INFO:root:final train perplexity: 3.154294013977051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2118.928957675366
INFO:root:eval perplexity: 5.549264907836914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2640.9933056121176
INFO:root:eval perplexity: 8.670069694519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [15:41:53<19:38:10, 636.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1473.7303466796875
INFO:root:current train perplexity3.1042354106903076
INFO:root:current mean train loss 1437.4435228620257
INFO:root:current train perplexity3.0946078300476074
INFO:root:current mean train loss 1439.734828157245
INFO:root:current train perplexity3.100322723388672
INFO:root:current mean train loss 1440.7027943929036
INFO:root:current train perplexity3.110947370529175
INFO:root:current mean train loss 1441.622544668253
INFO:root:current train perplexity3.1156060695648193
INFO:root:current mean train loss 1444.1458625793457
INFO:root:current train perplexity3.122204065322876
INFO:root:current mean train loss 1447.3947684094796
INFO:root:current train perplexity3.126307249069214
INFO:root:current mean train loss 1447.2561496348862
INFO:root:current train perplexity3.1287786960601807
INFO:root:current mean train loss 1447.046100184248
INFO:root:current train perplexity3.1327219009399414
INFO:root:current mean train loss 1447.8977580823396
INFO:root:current train perplexity3.1350152492523193
INFO:root:current mean train loss 1449.0859350875432
INFO:root:current train perplexity3.1359875202178955
INFO:root:current mean train loss 1449.7935357402555
INFO:root:current train perplexity3.135913372039795
INFO:root:current mean train loss 1450.7918845198728
INFO:root:current train perplexity3.137399673461914
INFO:root:current mean train loss 1450.9796447753906
INFO:root:current train perplexity3.138056993484497
INFO:root:current mean train loss 1451.462834258255
INFO:root:current train perplexity3.139253854751587
INFO:root:current mean train loss 1451.7400223666398
INFO:root:current train perplexity3.1401889324188232
INFO:root:current mean train loss 1452.111542505307
INFO:root:current train perplexity3.1425065994262695
INFO:root:current mean train loss 1452.5188234275747
INFO:root:current train perplexity3.143725633621216
INFO:root:current mean train loss 1452.5482377142832
INFO:root:current train perplexity3.1431198120117188
INFO:root:current mean train loss 1452.7032927189912
INFO:root:current train perplexity3.1439733505249023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.09s/it]
INFO:root:final mean train loss: 1452.3970408937394
INFO:root:final train perplexity: 3.1438486576080322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2121.2704303281525
INFO:root:eval perplexity: 5.5597825050354
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it]
INFO:root:eval mean loss: 2646.096636400155
INFO:root:eval perplexity: 8.706332206726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [15:52:22<19:23:10, 634.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1419.4898429081359
INFO:root:current train perplexity3.1179022789001465
INFO:root:current mean train loss 1437.3598793680353
INFO:root:current train perplexity3.114466905593872
INFO:root:current mean train loss 1437.0998311271835
INFO:root:current train perplexity3.11869215965271
INFO:root:current mean train loss 1435.249488714618
INFO:root:current train perplexity3.114604949951172
INFO:root:current mean train loss 1440.9155000273165
INFO:root:current train perplexity3.118648052215576
INFO:root:current mean train loss 1441.0023534879342
INFO:root:current train perplexity3.1121222972869873
INFO:root:current mean train loss 1442.197319188444
INFO:root:current train perplexity3.1147143840789795
INFO:root:current mean train loss 1442.1319585101594
INFO:root:current train perplexity3.1160335540771484
INFO:root:current mean train loss 1442.5077250334552
INFO:root:current train perplexity3.1168439388275146
INFO:root:current mean train loss 1443.0781331467808
INFO:root:current train perplexity3.117305278778076
INFO:root:current mean train loss 1443.9594157138301
INFO:root:current train perplexity3.1204447746276855
INFO:root:current mean train loss 1444.3811287081696
INFO:root:current train perplexity3.123079299926758
INFO:root:current mean train loss 1445.6506702246172
INFO:root:current train perplexity3.126180648803711
INFO:root:current mean train loss 1445.5587718495756
INFO:root:current train perplexity3.127013921737671
INFO:root:current mean train loss 1446.741206751744
INFO:root:current train perplexity3.129680871963501
INFO:root:current mean train loss 1447.6955514512397
INFO:root:current train perplexity3.1309614181518555
INFO:root:current mean train loss 1448.605074363226
INFO:root:current train perplexity3.1318514347076416
INFO:root:current mean train loss 1448.4172698639252
INFO:root:current train perplexity3.131401300430298
INFO:root:current mean train loss 1448.245931301044
INFO:root:current train perplexity3.1322576999664307
INFO:root:current mean train loss 1448.7575962033031
INFO:root:current train perplexity3.1338181495666504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.54s/it]
INFO:root:final mean train loss: 1448.5501643424677
INFO:root:final train perplexity: 3.1343250274658203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 2120.199433022357
INFO:root:eval perplexity: 5.554968357086182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2646.0730729339816
INFO:root:eval perplexity: 8.706161499023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [16:02:56<19:12:35, 634.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.8524700662365
INFO:root:current train perplexity3.0541329383850098
INFO:root:current mean train loss 1422.890139227044
INFO:root:current train perplexity3.084890365600586
INFO:root:current mean train loss 1425.9814606953444
INFO:root:current train perplexity3.0848898887634277
INFO:root:current mean train loss 1425.8667316767521
INFO:root:current train perplexity3.0882441997528076
INFO:root:current mean train loss 1429.5022804705018
INFO:root:current train perplexity3.0918169021606445
INFO:root:current mean train loss 1433.2800757998511
INFO:root:current train perplexity3.1031908988952637
INFO:root:current mean train loss 1434.7704416753338
INFO:root:current train perplexity3.1039979457855225
INFO:root:current mean train loss 1437.2611137983306
INFO:root:current train perplexity3.1075525283813477
INFO:root:current mean train loss 1436.8932534075798
INFO:root:current train perplexity3.109020948410034
INFO:root:current mean train loss 1437.3445759747044
INFO:root:current train perplexity3.110682249069214
INFO:root:current mean train loss 1439.6951764254452
INFO:root:current train perplexity3.112563133239746
INFO:root:current mean train loss 1439.7262613719254
INFO:root:current train perplexity3.1141836643218994
INFO:root:current mean train loss 1440.2460178234412
INFO:root:current train perplexity3.114179849624634
INFO:root:current mean train loss 1441.080621274407
INFO:root:current train perplexity3.115382432937622
INFO:root:current mean train loss 1442.2330261483726
INFO:root:current train perplexity3.1168837547302246
INFO:root:current mean train loss 1442.4841876307557
INFO:root:current train perplexity3.1179940700531006
INFO:root:current mean train loss 1443.51396956044
INFO:root:current train perplexity3.120631217956543
INFO:root:current mean train loss 1443.4310606861443
INFO:root:current train perplexity3.121175527572632
INFO:root:current mean train loss 1443.5522288346212
INFO:root:current train perplexity3.1218655109405518
INFO:root:current mean train loss 1444.4140477587239
INFO:root:current train perplexity3.1236774921417236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.21s/it]
INFO:root:final mean train loss: 1444.4527965551426
INFO:root:final train perplexity: 3.124213218688965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2124.535640635389
INFO:root:eval perplexity: 5.574483871459961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2651.022249262384
INFO:root:eval perplexity: 8.741472244262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [16:13:21<18:56:43, 631.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1422.5467296781994
INFO:root:current train perplexity3.093635320663452
INFO:root:current mean train loss 1424.1548563015242
INFO:root:current train perplexity3.0968523025512695
INFO:root:current mean train loss 1428.8859389852662
INFO:root:current train perplexity3.097917318344116
INFO:root:current mean train loss 1430.5696311929667
INFO:root:current train perplexity3.0991761684417725
INFO:root:current mean train loss 1429.8888255834065
INFO:root:current train perplexity3.094789743423462
INFO:root:current mean train loss 1429.8817591828097
INFO:root:current train perplexity3.095799684524536
INFO:root:current mean train loss 1431.629822237639
INFO:root:current train perplexity3.09906005859375
INFO:root:current mean train loss 1432.6627238862325
INFO:root:current train perplexity3.098989248275757
INFO:root:current mean train loss 1433.872160556833
INFO:root:current train perplexity3.100116014480591
INFO:root:current mean train loss 1434.4749219662676
INFO:root:current train perplexity3.0999720096588135
INFO:root:current mean train loss 1436.0719138833563
INFO:root:current train perplexity3.101170539855957
INFO:root:current mean train loss 1436.6504183348559
INFO:root:current train perplexity3.102311372756958
INFO:root:current mean train loss 1437.8794985278107
INFO:root:current train perplexity3.1053662300109863
INFO:root:current mean train loss 1438.7247009949044
INFO:root:current train perplexity3.106696844100952
INFO:root:current mean train loss 1438.6430590636749
INFO:root:current train perplexity3.108091115951538
INFO:root:current mean train loss 1439.0064590268614
INFO:root:current train perplexity3.108377695083618
INFO:root:current mean train loss 1439.063221558131
INFO:root:current train perplexity3.1103243827819824
INFO:root:current mean train loss 1439.3290447856104
INFO:root:current train perplexity3.1108994483947754
INFO:root:current mean train loss 1439.8860897897587
INFO:root:current train perplexity3.1118581295013428
INFO:root:current mean train loss 1440.3610752783925
INFO:root:current train perplexity3.11285400390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.07s/it]
INFO:root:final mean train loss: 1439.9659759013628
INFO:root:final train perplexity: 3.1131768226623535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2130.0123996599345
INFO:root:eval perplexity: 5.599229335784912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2657.2615802304963
INFO:root:eval perplexity: 8.786195755004883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [16:23:42<18:40:47, 628.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.4643280029297
INFO:root:current train perplexity3.0566887855529785
INFO:root:current mean train loss 1427.8684244791666
INFO:root:current train perplexity3.0729141235351562
INFO:root:current mean train loss 1429.0671421595982
INFO:root:current train perplexity3.0785319805145264
INFO:root:current mean train loss 1430.1881325169613
INFO:root:current train perplexity3.0797348022460938
INFO:root:current mean train loss 1428.668896738688
INFO:root:current train perplexity3.0824499130249023
INFO:root:current mean train loss 1428.1337566507273
INFO:root:current train perplexity3.0821640491485596
INFO:root:current mean train loss 1429.7708661247702
INFO:root:current train perplexity3.0850512981414795
INFO:root:current mean train loss 1430.133559319912
INFO:root:current train perplexity3.085395336151123
INFO:root:current mean train loss 1430.3427952159534
INFO:root:current train perplexity3.088623046875
INFO:root:current mean train loss 1432.0355273188377
INFO:root:current train perplexity3.0914711952209473
INFO:root:current mean train loss 1431.919085241247
INFO:root:current train perplexity3.091932535171509
INFO:root:current mean train loss 1433.0099890757415
INFO:root:current train perplexity3.094024658203125
INFO:root:current mean train loss 1433.1459702491761
INFO:root:current train perplexity3.0953023433685303
INFO:root:current mean train loss 1433.6498431661855
INFO:root:current train perplexity3.0952649116516113
INFO:root:current mean train loss 1434.0177053915488
INFO:root:current train perplexity3.097583055496216
INFO:root:current mean train loss 1435.1955350079113
INFO:root:current train perplexity3.0998032093048096
INFO:root:current mean train loss 1435.6017232259114
INFO:root:current train perplexity3.1008458137512207
INFO:root:current mean train loss 1436.0563366836377
INFO:root:current train perplexity3.102038860321045
INFO:root:current mean train loss 1436.0461722516
INFO:root:current train perplexity3.1022558212280273
INFO:root:current mean train loss 1436.1447609641334
INFO:root:current train perplexity3.1028857231140137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.76s/it]
INFO:root:final mean train loss: 1435.8152470437192
INFO:root:final train perplexity: 3.1030030250549316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2131.1626993815103
INFO:root:eval perplexity: 5.604440689086914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2661.311442490165
INFO:root:eval perplexity: 8.81534194946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [16:34:20<18:35:06, 631.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1418.5049696460212
INFO:root:current train perplexity3.073624849319458
INFO:root:current mean train loss 1421.739739277641
INFO:root:current train perplexity3.0754308700561523
INFO:root:current mean train loss 1420.2039959326337
INFO:root:current train perplexity3.074059009552002
INFO:root:current mean train loss 1418.6426239398024
INFO:root:current train perplexity3.0677402019500732
INFO:root:current mean train loss 1418.614400760029
INFO:root:current train perplexity3.0719940662384033
INFO:root:current mean train loss 1419.6683104241913
INFO:root:current train perplexity3.074727773666382
INFO:root:current mean train loss 1420.5507628606415
INFO:root:current train perplexity3.0754942893981934
INFO:root:current mean train loss 1424.3118299151604
INFO:root:current train perplexity3.0805256366729736
INFO:root:current mean train loss 1426.371595912155
INFO:root:current train perplexity3.082970142364502
INFO:root:current mean train loss 1426.8340631023932
INFO:root:current train perplexity3.0840632915496826
INFO:root:current mean train loss 1427.5929848628361
INFO:root:current train perplexity3.084231376647949
INFO:root:current mean train loss 1428.8112755236073
INFO:root:current train perplexity3.0858664512634277
INFO:root:current mean train loss 1429.4709267480243
INFO:root:current train perplexity3.087383270263672
INFO:root:current mean train loss 1429.7128158274427
INFO:root:current train perplexity3.0864362716674805
INFO:root:current mean train loss 1429.9551591790353
INFO:root:current train perplexity3.0862951278686523
INFO:root:current mean train loss 1430.8315850856832
INFO:root:current train perplexity3.0878348350524902
INFO:root:current mean train loss 1430.665866435944
INFO:root:current train perplexity3.089663028717041
INFO:root:current mean train loss 1431.5645730894807
INFO:root:current train perplexity3.091888666152954
INFO:root:current mean train loss 1431.6939136141152
INFO:root:current train perplexity3.091810703277588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.12s/it]
INFO:root:final mean train loss: 1431.4485044262954
INFO:root:final train perplexity: 3.092334747314453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2134.397856583832
INFO:root:eval perplexity: 5.619123458862305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2663.238779054466
INFO:root:eval perplexity: 8.82925033569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [16:44:49<18:23:27, 630.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1437.9323120117188
INFO:root:current train perplexity3.054051399230957
INFO:root:current mean train loss 1413.1872590717517
INFO:root:current train perplexity3.066556215286255
INFO:root:current mean train loss 1420.1030170761537
INFO:root:current train perplexity3.0583975315093994
INFO:root:current mean train loss 1421.2663733609922
INFO:root:current train perplexity3.0666840076446533
INFO:root:current mean train loss 1422.0819943930217
INFO:root:current train perplexity3.063551902770996
INFO:root:current mean train loss 1422.4628721007114
INFO:root:current train perplexity3.0648114681243896
INFO:root:current mean train loss 1420.9263540261732
INFO:root:current train perplexity3.0650577545166016
INFO:root:current mean train loss 1421.186007117691
INFO:root:current train perplexity3.065275192260742
INFO:root:current mean train loss 1422.5666418427038
INFO:root:current train perplexity3.067866563796997
INFO:root:current mean train loss 1423.0746447940885
INFO:root:current train perplexity3.069295883178711
INFO:root:current mean train loss 1423.0979450534317
INFO:root:current train perplexity3.0711004734039307
INFO:root:current mean train loss 1423.7401622724276
INFO:root:current train perplexity3.070312023162842
INFO:root:current mean train loss 1424.0897177581535
INFO:root:current train perplexity3.0724868774414062
INFO:root:current mean train loss 1424.8472088446538
INFO:root:current train perplexity3.074662208557129
INFO:root:current mean train loss 1425.837967976485
INFO:root:current train perplexity3.0746753215789795
INFO:root:current mean train loss 1426.0305715986729
INFO:root:current train perplexity3.076585292816162
INFO:root:current mean train loss 1426.2948149311203
INFO:root:current train perplexity3.0780136585235596
INFO:root:current mean train loss 1426.4207378374097
INFO:root:current train perplexity3.079468250274658
INFO:root:current mean train loss 1426.954727929903
INFO:root:current train perplexity3.080584764480591
INFO:root:current mean train loss 1427.5610272478284
INFO:root:current train perplexity3.081974744796753

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.43s/it]
INFO:root:final mean train loss: 1427.3906274931153
INFO:root:final train perplexity: 3.082454204559326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2139.8127233626997
INFO:root:eval perplexity: 5.643784999847412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2672.006203942265
INFO:root:eval perplexity: 8.892783164978027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [16:55:24<18:15:21, 631.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1411.0145106161795
INFO:root:current train perplexity3.0081589221954346
INFO:root:current mean train loss 1412.561442367903
INFO:root:current train perplexity3.0348780155181885
INFO:root:current mean train loss 1417.699045949168
INFO:root:current train perplexity3.048210382461548
INFO:root:current mean train loss 1417.1309866084073
INFO:root:current train perplexity3.0496323108673096
INFO:root:current mean train loss 1415.9893592073304
INFO:root:current train perplexity3.0420620441436768
INFO:root:current mean train loss 1415.1070066980049
INFO:root:current train perplexity3.046705961227417
INFO:root:current mean train loss 1417.3694573113733
INFO:root:current train perplexity3.0517563819885254
INFO:root:current mean train loss 1419.5083440318806
INFO:root:current train perplexity3.05383038520813
INFO:root:current mean train loss 1419.2967595399932
INFO:root:current train perplexity3.053931951522827
INFO:root:current mean train loss 1419.3756936111204
INFO:root:current train perplexity3.0575878620147705
INFO:root:current mean train loss 1420.3529792733846
INFO:root:current train perplexity3.059432029724121
INFO:root:current mean train loss 1420.6559434750773
INFO:root:current train perplexity3.061824083328247
INFO:root:current mean train loss 1420.5496796422815
INFO:root:current train perplexity3.063624620437622
INFO:root:current mean train loss 1420.3854640212658
INFO:root:current train perplexity3.064811944961548
INFO:root:current mean train loss 1420.9795186318024
INFO:root:current train perplexity3.0659289360046387
INFO:root:current mean train loss 1421.0673486870305
INFO:root:current train perplexity3.0665433406829834
INFO:root:current mean train loss 1422.1110559927768
INFO:root:current train perplexity3.0680835247039795
INFO:root:current mean train loss 1423.1516520182292
INFO:root:current train perplexity3.06966495513916
INFO:root:current mean train loss 1423.3080149327127
INFO:root:current train perplexity3.070984125137329
INFO:root:current mean train loss 1423.555717606547
INFO:root:current train perplexity3.0726616382598877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.28s/it]
INFO:root:final mean train loss: 1423.630072843289
INFO:root:final train perplexity: 3.0733261108398438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2142.0441340453235
INFO:root:eval perplexity: 5.6539788246154785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2675.248157690603
INFO:root:eval perplexity: 8.916393280029297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [17:05:46<17:59:35, 628.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1421.4793497721355
INFO:root:current train perplexity3.040919542312622
INFO:root:current mean train loss 1417.2634970175254
INFO:root:current train perplexity3.035454750061035
INFO:root:current mean train loss 1418.707536266696
INFO:root:current train perplexity3.0511438846588135
INFO:root:current mean train loss 1415.7454802414466
INFO:root:current train perplexity3.0551302433013916
INFO:root:current mean train loss 1413.9121526990618
INFO:root:current train perplexity3.0528833866119385
INFO:root:current mean train loss 1414.4943241759809
INFO:root:current train perplexity3.050431251525879
INFO:root:current mean train loss 1413.8194491539473
INFO:root:current train perplexity3.0528573989868164
INFO:root:current mean train loss 1414.587547751034
INFO:root:current train perplexity3.0548512935638428
INFO:root:current mean train loss 1416.0259901802494
INFO:root:current train perplexity3.0545451641082764
INFO:root:current mean train loss 1415.801141151396
INFO:root:current train perplexity3.05285382270813
INFO:root:current mean train loss 1415.7144649592974
INFO:root:current train perplexity3.0533761978149414
INFO:root:current mean train loss 1416.996791932641
INFO:root:current train perplexity3.056443452835083
INFO:root:current mean train loss 1417.7058841020632
INFO:root:current train perplexity3.056971788406372
INFO:root:current mean train loss 1418.2676249427682
INFO:root:current train perplexity3.0571019649505615
INFO:root:current mean train loss 1417.9544677734375
INFO:root:current train perplexity3.0587997436523438
INFO:root:current mean train loss 1417.6946024734536
INFO:root:current train perplexity3.0597915649414062
INFO:root:current mean train loss 1418.0890857733568
INFO:root:current train perplexity3.061353921890259
INFO:root:current mean train loss 1418.6614071215317
INFO:root:current train perplexity3.0612475872039795
INFO:root:current mean train loss 1419.2643308433103
INFO:root:current train perplexity3.062042236328125
INFO:root:current mean train loss 1420.0088678316904
INFO:root:current train perplexity3.0627591609954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.88s/it]
INFO:root:final mean train loss: 1419.4044912764357
INFO:root:final train perplexity: 3.063100576400757
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2144.1830734361147
INFO:root:eval perplexity: 5.6637678146362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it]
INFO:root:eval mean loss: 2675.807476070756
INFO:root:eval perplexity: 8.920473098754883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [17:16:08<17:45:34, 626.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1387.2688007061297
INFO:root:current train perplexity3.006869316101074
INFO:root:current mean train loss 1400.173263642282
INFO:root:current train perplexity3.0104308128356934
INFO:root:current mean train loss 1401.8783258402123
INFO:root:current train perplexity3.0154905319213867
INFO:root:current mean train loss 1402.9498023464255
INFO:root:current train perplexity3.0156009197235107
INFO:root:current mean train loss 1405.8915608723958
INFO:root:current train perplexity3.02492094039917
INFO:root:current mean train loss 1405.882460764657
INFO:root:current train perplexity3.0325188636779785
INFO:root:current mean train loss 1406.4771253083882
INFO:root:current train perplexity3.0353269577026367
INFO:root:current mean train loss 1406.9523943333843
INFO:root:current train perplexity3.036414861679077
INFO:root:current mean train loss 1408.6556301932803
INFO:root:current train perplexity3.039855718612671
INFO:root:current mean train loss 1410.0213070251782
INFO:root:current train perplexity3.0427584648132324
INFO:root:current mean train loss 1410.6938405498092
INFO:root:current train perplexity3.0424675941467285
INFO:root:current mean train loss 1411.26374909888
INFO:root:current train perplexity3.044142246246338
INFO:root:current mean train loss 1411.8760345579608
INFO:root:current train perplexity3.04591965675354
INFO:root:current mean train loss 1411.8889814775068
INFO:root:current train perplexity3.047557830810547
INFO:root:current mean train loss 1413.1234087530663
INFO:root:current train perplexity3.048755168914795
INFO:root:current mean train loss 1413.7340566811852
INFO:root:current train perplexity3.051239490509033
INFO:root:current mean train loss 1415.1577851533175
INFO:root:current train perplexity3.053057909011841
INFO:root:current mean train loss 1415.8038792077948
INFO:root:current train perplexity3.054853916168213
INFO:root:current mean train loss 1415.8710687468583
INFO:root:current train perplexity3.054562568664551
INFO:root:current mean train loss 1415.9640852988828
INFO:root:current train perplexity3.05399751663208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it]
INFO:root:final mean train loss: 1415.6099764871526
INFO:root:final train perplexity: 3.053948402404785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2147.9749400903147
INFO:root:eval perplexity: 5.681163311004639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.80s/it]
INFO:root:eval mean loss: 2681.8001457917776
INFO:root:eval perplexity: 8.964299201965332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [17:26:45<17:40:23, 629.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.3666962414254
INFO:root:current train perplexity3.026909112930298
INFO:root:current mean train loss 1397.4782372778589
INFO:root:current train perplexity3.025911331176758
INFO:root:current mean train loss 1401.9085758290391
INFO:root:current train perplexity3.0223259925842285
INFO:root:current mean train loss 1404.6932018339946
INFO:root:current train perplexity3.0224125385284424
INFO:root:current mean train loss 1405.383252662247
INFO:root:current train perplexity3.0276706218719482
INFO:root:current mean train loss 1404.5521508705165
INFO:root:current train perplexity3.027069330215454
INFO:root:current mean train loss 1404.1715401120898
INFO:root:current train perplexity3.0292530059814453
INFO:root:current mean train loss 1403.6193449600883
INFO:root:current train perplexity3.028526544570923
INFO:root:current mean train loss 1405.6789452516032
INFO:root:current train perplexity3.031163215637207
INFO:root:current mean train loss 1406.824618524058
INFO:root:current train perplexity3.0305442810058594
INFO:root:current mean train loss 1407.101548284788
INFO:root:current train perplexity3.0320677757263184
INFO:root:current mean train loss 1407.3845182828693
INFO:root:current train perplexity3.0310988426208496
INFO:root:current mean train loss 1408.3750748418609
INFO:root:current train perplexity3.032773017883301
INFO:root:current mean train loss 1409.0831962176928
INFO:root:current train perplexity3.0346004962921143
INFO:root:current mean train loss 1410.0200439947337
INFO:root:current train perplexity3.037515640258789
INFO:root:current mean train loss 1410.3752724590856
INFO:root:current train perplexity3.039377450942993
INFO:root:current mean train loss 1411.2767609767484
INFO:root:current train perplexity3.040904998779297
INFO:root:current mean train loss 1411.468960095201
INFO:root:current train perplexity3.0414791107177734
INFO:root:current mean train loss 1411.5642604848151
INFO:root:current train perplexity3.043466091156006
INFO:root:current mean train loss 1412.0959039682336
INFO:root:current train perplexity3.0444397926330566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.35s/it]
INFO:root:final mean train loss: 1411.649263028959
INFO:root:final train perplexity: 3.0444231033325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2152.6696560907026
INFO:root:eval perplexity: 5.702775478363037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2688.10248884918
INFO:root:eval perplexity: 9.010622024536133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [17:37:17<17:30:56, 630.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.7301247336648
INFO:root:current train perplexity3.019019365310669
INFO:root:current mean train loss 1406.0757657918498
INFO:root:current train perplexity3.0252742767333984
INFO:root:current mean train loss 1404.1245480540604
INFO:root:current train perplexity3.0214006900787354
INFO:root:current mean train loss 1403.278232813479
INFO:root:current train perplexity3.0232419967651367
INFO:root:current mean train loss 1404.4939331788578
INFO:root:current train perplexity3.0202219486236572
INFO:root:current mean train loss 1403.114310186574
INFO:root:current train perplexity3.0218300819396973
INFO:root:current mean train loss 1403.09915794187
INFO:root:current train perplexity3.0251166820526123
INFO:root:current mean train loss 1403.2646281179111
INFO:root:current train perplexity3.024578094482422
INFO:root:current mean train loss 1403.8013709623106
INFO:root:current train perplexity3.0275800228118896
INFO:root:current mean train loss 1404.081483216615
INFO:root:current train perplexity3.028036594390869
INFO:root:current mean train loss 1405.1456722020018
INFO:root:current train perplexity3.0314226150512695
INFO:root:current mean train loss 1406.8361702378936
INFO:root:current train perplexity3.033238649368286
INFO:root:current mean train loss 1406.099703535472
INFO:root:current train perplexity3.0326292514801025
INFO:root:current mean train loss 1406.2479598813607
INFO:root:current train perplexity3.0336368083953857
INFO:root:current mean train loss 1407.4040645423772
INFO:root:current train perplexity3.0348823070526123
INFO:root:current mean train loss 1408.2413427032031
INFO:root:current train perplexity3.0350639820098877
INFO:root:current mean train loss 1408.544686643568
INFO:root:current train perplexity3.0359182357788086
INFO:root:current mean train loss 1408.8696466841388
INFO:root:current train perplexity3.036278009414673
INFO:root:current mean train loss 1409.452206547854
INFO:root:current train perplexity3.037182331085205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.31s/it]
INFO:root:final mean train loss: 1409.3469197652705
INFO:root:final train perplexity: 3.038900375366211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2154.166622513575
INFO:root:eval perplexity: 5.709683418273926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2687.919775130901
INFO:root:eval perplexity: 9.00927448272705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [17:47:51<17:21:57, 631.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1383.1422653198242
INFO:root:current train perplexity3.0161304473876953
INFO:root:current mean train loss 1396.2795420679554
INFO:root:current train perplexity2.997053623199463
INFO:root:current mean train loss 1401.352480287905
INFO:root:current train perplexity3.002122640609741
INFO:root:current mean train loss 1398.719837043859
INFO:root:current train perplexity3.004314661026001
INFO:root:current mean train loss 1396.8676942678599
INFO:root:current train perplexity3.008962392807007
INFO:root:current mean train loss 1397.0906251419422
INFO:root:current train perplexity3.0109167098999023
INFO:root:current mean train loss 1396.4306073869977
INFO:root:current train perplexity3.0069637298583984
INFO:root:current mean train loss 1394.7740330189965
INFO:root:current train perplexity3.007202625274658
INFO:root:current mean train loss 1395.9512421851064
INFO:root:current train perplexity3.0094316005706787
INFO:root:current mean train loss 1396.8496358946422
INFO:root:current train perplexity3.0112173557281494
INFO:root:current mean train loss 1397.1384162001723
INFO:root:current train perplexity3.0128278732299805
INFO:root:current mean train loss 1399.0838970881637
INFO:root:current train perplexity3.0157179832458496
INFO:root:current mean train loss 1399.2895202636719
INFO:root:current train perplexity3.0165770053863525
INFO:root:current mean train loss 1400.204952993654
INFO:root:current train perplexity3.0178539752960205
INFO:root:current mean train loss 1401.3800235037077
INFO:root:current train perplexity3.020427942276001
INFO:root:current mean train loss 1402.0863223918825
INFO:root:current train perplexity3.022939682006836
INFO:root:current mean train loss 1402.686297803822
INFO:root:current train perplexity3.0242621898651123
INFO:root:current mean train loss 1403.768549209986
INFO:root:current train perplexity3.0264909267425537
INFO:root:current mean train loss 1404.562508805733
INFO:root:current train perplexity3.027864456176758
INFO:root:current mean train loss 1404.7639825299289
INFO:root:current train perplexity3.0279252529144287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.29s/it]
INFO:root:final mean train loss: 1405.0175141350405
INFO:root:final train perplexity: 3.0285425186157227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2158.4648714539007
INFO:root:eval perplexity: 5.7295660972595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2695.8675056619845
INFO:root:eval perplexity: 9.068025588989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [17:58:14<17:07:26, 629.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.6303304036458
INFO:root:current train perplexity2.9953556060791016
INFO:root:current mean train loss 1397.2936607877114
INFO:root:current train perplexity3.0215091705322266
INFO:root:current mean train loss 1392.9828609089996
INFO:root:current train perplexity3.006263256072998
INFO:root:current mean train loss 1394.1555238099427
INFO:root:current train perplexity3.004455089569092
INFO:root:current mean train loss 1396.0559211713337
INFO:root:current train perplexity3.0040900707244873
INFO:root:current mean train loss 1395.1086251722268
INFO:root:current train perplexity3.0036797523498535
INFO:root:current mean train loss 1393.939197028041
INFO:root:current train perplexity3.0043745040893555
INFO:root:current mean train loss 1395.9762369236548
INFO:root:current train perplexity3.0062060356140137
INFO:root:current mean train loss 1396.0228396045918
INFO:root:current train perplexity3.0074217319488525
INFO:root:current mean train loss 1398.051714898178
INFO:root:current train perplexity3.0084691047668457
INFO:root:current mean train loss 1398.1682865109588
INFO:root:current train perplexity3.0086631774902344
INFO:root:current mean train loss 1398.549374801757
INFO:root:current train perplexity3.010998249053955
INFO:root:current mean train loss 1398.6975008553832
INFO:root:current train perplexity3.011141777038574
INFO:root:current mean train loss 1399.3430346111918
INFO:root:current train perplexity3.012274980545044
INFO:root:current mean train loss 1399.8249234015177
INFO:root:current train perplexity3.01375150680542
INFO:root:current mean train loss 1400.182047207528
INFO:root:current train perplexity3.0154919624328613
INFO:root:current mean train loss 1400.2176847066605
INFO:root:current train perplexity3.0157814025878906
INFO:root:current mean train loss 1400.0122869087654
INFO:root:current train perplexity3.0155389308929443
INFO:root:current mean train loss 1401.1888995131571
INFO:root:current train perplexity3.017829179763794
INFO:root:current mean train loss 1401.1604168729589
INFO:root:current train perplexity3.01828932762146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it]
INFO:root:final mean train loss: 1400.8898733719034
INFO:root:final train perplexity: 3.0186991691589355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2158.5378214518228
INFO:root:eval perplexity: 5.729902744293213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2695.044079503269
INFO:root:eval perplexity: 9.061920166015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [18:08:37<16:54:06, 627.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.56984375
INFO:root:current train perplexity2.9783129692077637
INFO:root:current mean train loss 1387.5089990234376
INFO:root:current train perplexity2.987783670425415
INFO:root:current mean train loss 1391.7067280273438
INFO:root:current train perplexity2.98978328704834
INFO:root:current mean train loss 1391.1252619280133
INFO:root:current train perplexity2.989321708679199
INFO:root:current mean train loss 1389.654766438802
INFO:root:current train perplexity2.990347146987915
INFO:root:current mean train loss 1392.1231893643467
INFO:root:current train perplexity2.9958271980285645
INFO:root:current mean train loss 1392.5619606370192
INFO:root:current train perplexity2.9990720748901367
INFO:root:current mean train loss 1394.2753764648437
INFO:root:current train perplexity2.999553680419922
INFO:root:current mean train loss 1394.7108438648897
INFO:root:current train perplexity2.9990549087524414
INFO:root:current mean train loss 1396.046941560444
INFO:root:current train perplexity3.001830577850342
INFO:root:current mean train loss 1396.3236908249628
INFO:root:current train perplexity3.0044572353363037
INFO:root:current mean train loss 1395.9400440514605
INFO:root:current train perplexity3.003817319869995
INFO:root:current mean train loss 1396.1365381835938
INFO:root:current train perplexity3.003676176071167
INFO:root:current mean train loss 1396.4485858832466
INFO:root:current train perplexity3.0056676864624023
INFO:root:current mean train loss 1396.4657013570852
INFO:root:current train perplexity3.0060160160064697
INFO:root:current mean train loss 1396.7340283203125
INFO:root:current train perplexity3.0077993869781494
INFO:root:current mean train loss 1397.527881969105
INFO:root:current train perplexity3.008660078048706
INFO:root:current mean train loss 1397.9751306501116
INFO:root:current train perplexity3.009371042251587
INFO:root:current mean train loss 1397.8067060150972
INFO:root:current train perplexity3.009888172149658
INFO:root:current mean train loss 1397.821652018229
INFO:root:current train perplexity3.010180711746216

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.09s/it]
INFO:root:final mean train loss: 1397.5386098918443
INFO:root:final train perplexity: 3.0107316970825195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2163.4190686814327
INFO:root:eval perplexity: 5.752567768096924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it]
INFO:root:eval mean loss: 2702.9316674631536
INFO:root:eval perplexity: 9.120566368103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [18:19:11<16:46:44, 629.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1399.7280601387592
INFO:root:current train perplexity2.9595446586608887
INFO:root:current mean train loss 1387.955909226469
INFO:root:current train perplexity2.971580982208252
INFO:root:current mean train loss 1386.5228404070108
INFO:root:current train perplexity2.9709622859954834
INFO:root:current mean train loss 1386.3501369050152
INFO:root:current train perplexity2.975512981414795
INFO:root:current mean train loss 1385.8724961209348
INFO:root:current train perplexity2.974747657775879
INFO:root:current mean train loss 1385.7826306647514
INFO:root:current train perplexity2.9761297702789307
INFO:root:current mean train loss 1386.3338482126123
INFO:root:current train perplexity2.978104829788208
INFO:root:current mean train loss 1387.8769668121538
INFO:root:current train perplexity2.981138229370117
INFO:root:current mean train loss 1387.9720960218876
INFO:root:current train perplexity2.984447956085205
INFO:root:current mean train loss 1388.1468786103526
INFO:root:current train perplexity2.9862191677093506
INFO:root:current mean train loss 1388.2219725647258
INFO:root:current train perplexity2.989935874938965
INFO:root:current mean train loss 1389.9768312220504
INFO:root:current train perplexity2.993279457092285
INFO:root:current mean train loss 1390.130894252232
INFO:root:current train perplexity2.9943137168884277
INFO:root:current mean train loss 1391.040497696827
INFO:root:current train perplexity2.995579481124878
INFO:root:current mean train loss 1390.6069143720445
INFO:root:current train perplexity2.9969170093536377
INFO:root:current mean train loss 1390.9197575046367
INFO:root:current train perplexity2.9977965354919434
INFO:root:current mean train loss 1391.8287876360275
INFO:root:current train perplexity2.9991893768310547
INFO:root:current mean train loss 1392.9117355648918
INFO:root:current train perplexity3.0010721683502197
INFO:root:current mean train loss 1393.5876131389764
INFO:root:current train perplexity3.001894235610962
INFO:root:current mean train loss 1394.393924001394
INFO:root:current train perplexity3.0022270679473877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.92s/it]
INFO:root:final mean train loss: 1394.1514250523985
INFO:root:final train perplexity: 3.002699613571167
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2167.093105018562
INFO:root:eval perplexity: 5.769685745239258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2706.439484291888
INFO:root:eval perplexity: 9.146767616271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [18:29:33<16:32:54, 627.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1373.2839529854912
INFO:root:current train perplexity2.947481632232666
INFO:root:current mean train loss 1375.1593714175017
INFO:root:current train perplexity2.9562742710113525
INFO:root:current mean train loss 1376.9226302026022
INFO:root:current train perplexity2.964003324508667
INFO:root:current mean train loss 1376.7971035639446
INFO:root:current train perplexity2.9632818698883057
INFO:root:current mean train loss 1378.8709008082872
INFO:root:current train perplexity2.9672200679779053
INFO:root:current mean train loss 1383.4894478157776
INFO:root:current train perplexity2.9737353324890137
INFO:root:current mean train loss 1385.1027603595578
INFO:root:current train perplexity2.975538730621338
INFO:root:current mean train loss 1385.332629612514
INFO:root:current train perplexity2.9766900539398193
INFO:root:current mean train loss 1384.7414492784042
INFO:root:current train perplexity2.9790570735931396
INFO:root:current mean train loss 1384.4742870796017
INFO:root:current train perplexity2.979947566986084
INFO:root:current mean train loss 1385.3044345757178
INFO:root:current train perplexity2.9810636043548584
INFO:root:current mean train loss 1386.4503129495156
INFO:root:current train perplexity2.981754779815674
INFO:root:current mean train loss 1386.770709646825
INFO:root:current train perplexity2.9840924739837646
INFO:root:current mean train loss 1387.6711541324682
INFO:root:current train perplexity2.986502170562744
INFO:root:current mean train loss 1388.4322323863398
INFO:root:current train perplexity2.987985610961914
INFO:root:current mean train loss 1388.6867754387133
INFO:root:current train perplexity2.988422155380249
INFO:root:current mean train loss 1388.683165996488
INFO:root:current train perplexity2.989304304122925
INFO:root:current mean train loss 1389.6592392857299
INFO:root:current train perplexity2.992480993270874
INFO:root:current mean train loss 1390.5173298376128
INFO:root:current train perplexity2.993968963623047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.39s/it]
INFO:root:final mean train loss: 1390.7542953298841
INFO:root:final train perplexity: 2.9946658611297607
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it]
INFO:root:eval mean loss: 2170.269455064273
INFO:root:eval perplexity: 5.784526824951172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2710.6796165087544
INFO:root:eval perplexity: 9.178542137145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [18:40:09<16:26:32, 629.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1342.9010009765625
INFO:root:current train perplexity2.976959705352783
INFO:root:current mean train loss 1372.8065838200032
INFO:root:current train perplexity2.9591689109802246
INFO:root:current mean train loss 1379.1121358539335
INFO:root:current train perplexity2.969026803970337
INFO:root:current mean train loss 1380.7850220132111
INFO:root:current train perplexity2.969264268875122
INFO:root:current mean train loss 1379.3260495002728
INFO:root:current train perplexity2.9696595668792725
INFO:root:current mean train loss 1378.1162518712574
INFO:root:current train perplexity2.9665017127990723
INFO:root:current mean train loss 1379.5884743688905
INFO:root:current train perplexity2.96687650680542
INFO:root:current mean train loss 1381.1579664722829
INFO:root:current train perplexity2.972524881362915
INFO:root:current mean train loss 1382.3427298518454
INFO:root:current train perplexity2.9739603996276855
INFO:root:current mean train loss 1382.2330361555737
INFO:root:current train perplexity2.9750616550445557
INFO:root:current mean train loss 1381.947127335555
INFO:root:current train perplexity2.9752280712127686
INFO:root:current mean train loss 1381.7595065166256
INFO:root:current train perplexity2.9769949913024902
INFO:root:current mean train loss 1382.4153994799256
INFO:root:current train perplexity2.9791176319122314
INFO:root:current mean train loss 1383.3407314573226
INFO:root:current train perplexity2.980074882507324
INFO:root:current mean train loss 1383.370399839958
INFO:root:current train perplexity2.9811854362487793
INFO:root:current mean train loss 1383.993515878737
INFO:root:current train perplexity2.9822821617126465
INFO:root:current mean train loss 1384.804088509135
INFO:root:current train perplexity2.982675552368164
INFO:root:current mean train loss 1385.4428319106867
INFO:root:current train perplexity2.9830970764160156
INFO:root:current mean train loss 1386.820466223192
INFO:root:current train perplexity2.985157012939453
INFO:root:current mean train loss 1387.15108188587
INFO:root:current train perplexity2.9859020709991455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.14s/it]
INFO:root:final mean train loss: 1387.216578712021
INFO:root:final train perplexity: 2.9863216876983643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2170.2457180158467
INFO:root:eval perplexity: 5.7844157218933105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2712.847739361702
INFO:root:eval perplexity: 9.194831848144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [18:50:39<16:16:29, 630.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.2691311306423
INFO:root:current train perplexity2.982912063598633
INFO:root:current mean train loss 1377.4226394911943
INFO:root:current train perplexity2.9614062309265137
INFO:root:current mean train loss 1377.388613079666
INFO:root:current train perplexity2.9599413871765137
INFO:root:current mean train loss 1376.508146849818
INFO:root:current train perplexity2.9571454524993896
INFO:root:current mean train loss 1378.081726366253
INFO:root:current train perplexity2.958658218383789
INFO:root:current mean train loss 1377.1413706186656
INFO:root:current train perplexity2.96370267868042
INFO:root:current mean train loss 1377.436983275182
INFO:root:current train perplexity2.9646825790405273
INFO:root:current mean train loss 1377.6351197649178
INFO:root:current train perplexity2.9663612842559814
INFO:root:current mean train loss 1378.0237486449896
INFO:root:current train perplexity2.9670510292053223
INFO:root:current mean train loss 1379.85943045024
INFO:root:current train perplexity2.9681882858276367
INFO:root:current mean train loss 1380.5452858076114
INFO:root:current train perplexity2.969693899154663
INFO:root:current mean train loss 1380.159274461231
INFO:root:current train perplexity2.9701550006866455
INFO:root:current mean train loss 1379.9643264043898
INFO:root:current train perplexity2.9699859619140625
INFO:root:current mean train loss 1380.9831686526402
INFO:root:current train perplexity2.972238302230835
INFO:root:current mean train loss 1381.9945144115281
INFO:root:current train perplexity2.9742398262023926
INFO:root:current mean train loss 1382.3903802964685
INFO:root:current train perplexity2.974701166152954
INFO:root:current mean train loss 1383.2670193025
INFO:root:current train perplexity2.9750001430511475
INFO:root:current mean train loss 1383.6370446024175
INFO:root:current train perplexity2.9765541553497314
INFO:root:current mean train loss 1384.2288401386525
INFO:root:current train perplexity2.976806402206421
INFO:root:current mean train loss 1384.0852752144567
INFO:root:current train perplexity2.9771440029144287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.61s/it]
INFO:root:final mean train loss: 1383.9300960323394
INFO:root:final train perplexity: 2.978591203689575
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2173.737512033882
INFO:root:eval perplexity: 5.800773620605469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2717.6678873697915
INFO:root:eval perplexity: 9.231146812438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [19:01:04<16:03:43, 628.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1372.1260672433036
INFO:root:current train perplexity2.9714887142181396
INFO:root:current mean train loss 1361.7606653284145
INFO:root:current train perplexity2.96673583984375
INFO:root:current mean train loss 1365.8146167511636
INFO:root:current train perplexity2.9499378204345703
INFO:root:current mean train loss 1366.3724864447295
INFO:root:current train perplexity2.944443464279175
INFO:root:current mean train loss 1367.4714290925826
INFO:root:current train perplexity2.9484574794769287
INFO:root:current mean train loss 1370.2153525664428
INFO:root:current train perplexity2.9504120349884033
INFO:root:current mean train loss 1371.6405948188362
INFO:root:current train perplexity2.9510672092437744
INFO:root:current mean train loss 1373.0540485823235
INFO:root:current train perplexity2.9539151191711426
INFO:root:current mean train loss 1372.7050219872754
INFO:root:current train perplexity2.958505868911743
INFO:root:current mean train loss 1374.255998548212
INFO:root:current train perplexity2.958552837371826
INFO:root:current mean train loss 1375.3275464928668
INFO:root:current train perplexity2.9616878032684326
INFO:root:current mean train loss 1376.2804774616259
INFO:root:current train perplexity2.962968587875366
INFO:root:current mean train loss 1376.5633794993041
INFO:root:current train perplexity2.9643361568450928
INFO:root:current mean train loss 1377.6662262991574
INFO:root:current train perplexity2.9652483463287354
INFO:root:current mean train loss 1377.9415329138992
INFO:root:current train perplexity2.9663350582122803
INFO:root:current mean train loss 1378.1828614871743
INFO:root:current train perplexity2.9661366939544678
INFO:root:current mean train loss 1378.433898291165
INFO:root:current train perplexity2.966771125793457
INFO:root:current mean train loss 1378.8174265045254
INFO:root:current train perplexity2.9675426483154297
INFO:root:current mean train loss 1379.3640001676388
INFO:root:current train perplexity2.968099594116211
INFO:root:current mean train loss 1380.7440854252463
INFO:root:current train perplexity2.970102071762085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.87s/it]
INFO:root:final mean train loss: 1380.4274068227394
INFO:root:final train perplexity: 2.970374822616577
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 2178.9281789360316
INFO:root:eval perplexity: 5.825175762176514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2723.631646771803
INFO:root:eval perplexity: 9.27628231048584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [19:11:38<15:55:39, 630.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1366.7847313514123
INFO:root:current train perplexity2.955373525619507
INFO:root:current mean train loss 1376.0881676924855
INFO:root:current train perplexity2.956482172012329
INFO:root:current mean train loss 1378.2578972710503
INFO:root:current train perplexity2.9537432193756104
INFO:root:current mean train loss 1374.6030786687677
INFO:root:current train perplexity2.955911636352539
INFO:root:current mean train loss 1374.202777963824
INFO:root:current train perplexity2.9583632946014404
INFO:root:current mean train loss 1375.9060321752577
INFO:root:current train perplexity2.955169200897217
INFO:root:current mean train loss 1376.4037116115078
INFO:root:current train perplexity2.955270290374756
INFO:root:current mean train loss 1378.7482825745928
INFO:root:current train perplexity2.9564476013183594
INFO:root:current mean train loss 1378.6404553623827
INFO:root:current train perplexity2.9575703144073486
INFO:root:current mean train loss 1378.0598607423926
INFO:root:current train perplexity2.9585464000701904
INFO:root:current mean train loss 1377.2638155280863
INFO:root:current train perplexity2.9588260650634766
INFO:root:current mean train loss 1377.047984759013
INFO:root:current train perplexity2.957301616668701
INFO:root:current mean train loss 1377.3669528168991
INFO:root:current train perplexity2.957843542098999
INFO:root:current mean train loss 1377.2637999043661
INFO:root:current train perplexity2.9593777656555176
INFO:root:current mean train loss 1378.134272635804
INFO:root:current train perplexity2.9609358310699463
INFO:root:current mean train loss 1378.1643841143737
INFO:root:current train perplexity2.9619150161743164
INFO:root:current mean train loss 1377.9476195697923
INFO:root:current train perplexity2.9627208709716797
INFO:root:current mean train loss 1377.955571074464
INFO:root:current train perplexity2.9641010761260986
INFO:root:current mean train loss 1378.1546907692698
INFO:root:current train perplexity2.964937925338745
INFO:root:current mean train loss 1378.5926486781386
INFO:root:current train perplexity2.965365409851074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.70s/it]
INFO:root:final mean train loss: 1378.1714823497286
INFO:root:final train perplexity: 2.965094566345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2182.069026432984
INFO:root:eval perplexity: 5.839991092681885
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 2724.3837219671154
INFO:root:eval perplexity: 9.281988143920898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [19:22:03<15:42:46, 628.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1364.1119066321332
INFO:root:current train perplexity2.9275476932525635
INFO:root:current mean train loss 1360.3355127819896
INFO:root:current train perplexity2.9271745681762695
INFO:root:current mean train loss 1361.2505354757202
INFO:root:current train perplexity2.930799722671509
INFO:root:current mean train loss 1365.7206124820036
INFO:root:current train perplexity2.931079149246216
INFO:root:current mean train loss 1366.14014400653
INFO:root:current train perplexity2.9309942722320557
INFO:root:current mean train loss 1367.1704987591306
INFO:root:current train perplexity2.9324791431427
INFO:root:current mean train loss 1368.7835182452238
INFO:root:current train perplexity2.9350080490112305
INFO:root:current mean train loss 1369.4932512102264
INFO:root:current train perplexity2.9387896060943604
INFO:root:current mean train loss 1369.6139678779489
INFO:root:current train perplexity2.942802667617798
INFO:root:current mean train loss 1371.1928972966655
INFO:root:current train perplexity2.944342613220215
INFO:root:current mean train loss 1370.7587409880364
INFO:root:current train perplexity2.946240186691284
INFO:root:current mean train loss 1370.8627645657346
INFO:root:current train perplexity2.9488182067871094
INFO:root:current mean train loss 1371.3531669213887
INFO:root:current train perplexity2.947671890258789
INFO:root:current mean train loss 1370.8568694823148
INFO:root:current train perplexity2.948855400085449
INFO:root:current mean train loss 1372.3455803068096
INFO:root:current train perplexity2.9502248764038086
INFO:root:current mean train loss 1372.5943829917544
INFO:root:current train perplexity2.950519561767578
INFO:root:current mean train loss 1373.090415337473
INFO:root:current train perplexity2.9516682624816895
INFO:root:current mean train loss 1374.0034901482563
INFO:root:current train perplexity2.953362226486206
INFO:root:current mean train loss 1373.755255424128
INFO:root:current train perplexity2.953819990158081
INFO:root:current mean train loss 1373.9295493107027
INFO:root:current train perplexity2.9543278217315674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.36s/it]
INFO:root:final mean train loss: 1373.8212655471903
INFO:root:final train perplexity: 2.954939365386963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2183.5427596721242
INFO:root:eval perplexity: 5.846956253051758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2727.1110342039283
INFO:root:eval perplexity: 9.302713394165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [19:32:40<15:36:10, 631.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1361.418801950854
INFO:root:current train perplexity2.9313387870788574
INFO:root:current mean train loss 1360.9940067414313
INFO:root:current train perplexity2.9270358085632324
INFO:root:current mean train loss 1363.0629246851781
INFO:root:current train perplexity2.9327337741851807
INFO:root:current mean train loss 1362.0619102043192
INFO:root:current train perplexity2.9294533729553223
INFO:root:current mean train loss 1363.9285489306037
INFO:root:current train perplexity2.9263498783111572
INFO:root:current mean train loss 1364.4518243054074
INFO:root:current train perplexity2.9286298751831055
INFO:root:current mean train loss 1365.6165203839628
INFO:root:current train perplexity2.9297680854797363
INFO:root:current mean train loss 1364.2565931946267
INFO:root:current train perplexity2.9318251609802246
INFO:root:current mean train loss 1364.5717139663868
INFO:root:current train perplexity2.931147336959839
INFO:root:current mean train loss 1365.4989008719733
INFO:root:current train perplexity2.9332704544067383
INFO:root:current mean train loss 1366.6408591367044
INFO:root:current train perplexity2.9356250762939453
INFO:root:current mean train loss 1366.669685762608
INFO:root:current train perplexity2.9366390705108643
INFO:root:current mean train loss 1367.5942702701266
INFO:root:current train perplexity2.9388692378997803
INFO:root:current mean train loss 1367.5294782189924
INFO:root:current train perplexity2.940650224685669
INFO:root:current mean train loss 1368.9141834202558
INFO:root:current train perplexity2.942199230194092
INFO:root:current mean train loss 1368.835942579849
INFO:root:current train perplexity2.9439187049865723
INFO:root:current mean train loss 1369.5430868381848
INFO:root:current train perplexity2.945998430252075
INFO:root:current mean train loss 1370.219952317395
INFO:root:current train perplexity2.946565628051758
INFO:root:current mean train loss 1370.444765966745
INFO:root:current train perplexity2.9471845626831055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.27s/it]
INFO:root:final mean train loss: 1370.6320268916652
INFO:root:final train perplexity: 2.947516441345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2185.89801068678
INFO:root:eval perplexity: 5.8581037521362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 2732.362101236979
INFO:root:eval perplexity: 9.342751502990723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [19:43:06<15:23:27, 629.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1341.65576171875
INFO:root:current train perplexity2.8681187629699707
INFO:root:current mean train loss 1359.6682259272602
INFO:root:current train perplexity2.917717218399048
INFO:root:current mean train loss 1358.5321327547722
INFO:root:current train perplexity2.927863836288452
INFO:root:current mean train loss 1354.5195505878712
INFO:root:current train perplexity2.926332473754883
INFO:root:current mean train loss 1355.7541861332973
INFO:root:current train perplexity2.9288852214813232
INFO:root:current mean train loss 1356.6505840445607
INFO:root:current train perplexity2.9278531074523926
INFO:root:current mean train loss 1359.4127035314962
INFO:root:current train perplexity2.9304378032684326
INFO:root:current mean train loss 1358.9174335854152
INFO:root:current train perplexity2.930889368057251
INFO:root:current mean train loss 1359.6185836316936
INFO:root:current train perplexity2.931307077407837
INFO:root:current mean train loss 1360.572728762199
INFO:root:current train perplexity2.933643102645874
INFO:root:current mean train loss 1362.0287409256605
INFO:root:current train perplexity2.936121940612793
INFO:root:current mean train loss 1362.6972799015823
INFO:root:current train perplexity2.9348177909851074
INFO:root:current mean train loss 1363.4057623275794
INFO:root:current train perplexity2.9341304302215576
INFO:root:current mean train loss 1363.5229380703486
INFO:root:current train perplexity2.933868408203125
INFO:root:current mean train loss 1363.9277837077634
INFO:root:current train perplexity2.932990074157715
INFO:root:current mean train loss 1364.0979389690672
INFO:root:current train perplexity2.9333534240722656
INFO:root:current mean train loss 1365.1379731119387
INFO:root:current train perplexity2.9346718788146973
INFO:root:current mean train loss 1366.2319530905938
INFO:root:current train perplexity2.9342167377471924
INFO:root:current mean train loss 1366.88964945306
INFO:root:current train perplexity2.9362409114837646
INFO:root:current mean train loss 1367.4662502848093
INFO:root:current train perplexity2.937575340270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.40s/it]
INFO:root:final mean train loss: 1366.9490470943942
INFO:root:final train perplexity: 2.938967704772949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2187.9607470356827
INFO:root:eval perplexity: 5.867883682250977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 2737.100145705203
INFO:root:eval perplexity: 9.379027366638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [19:53:31<15:10:34, 627.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1322.7778686523438
INFO:root:current train perplexity2.889080286026001
INFO:root:current mean train loss 1357.2784993489583
INFO:root:current train perplexity2.9201483726501465
INFO:root:current mean train loss 1353.9817904385654
INFO:root:current train perplexity2.912680149078369
INFO:root:current mean train loss 1356.529154586792
INFO:root:current train perplexity2.9135355949401855
INFO:root:current mean train loss 1355.471001906622
INFO:root:current train perplexity2.9182329177856445
INFO:root:current mean train loss 1355.8848423884465
INFO:root:current train perplexity2.918807029724121
INFO:root:current mean train loss 1357.134175159085
INFO:root:current train perplexity2.917729616165161
INFO:root:current mean train loss 1356.0933507283528
INFO:root:current train perplexity2.918438196182251
INFO:root:current mean train loss 1355.1924390839367
INFO:root:current train perplexity2.91772723197937
INFO:root:current mean train loss 1355.8393574590268
INFO:root:current train perplexity2.9179985523223877
INFO:root:current mean train loss 1358.0118588915059
INFO:root:current train perplexity2.9190304279327393
INFO:root:current mean train loss 1358.8950678144183
INFO:root:current train perplexity2.9206650257110596
INFO:root:current mean train loss 1360.3343699971183
INFO:root:current train perplexity2.9227805137634277
INFO:root:current mean train loss 1361.0330596923827
INFO:root:current train perplexity2.9249770641326904
INFO:root:current mean train loss 1361.9285078021842
INFO:root:current train perplexity2.925624370574951
INFO:root:current mean train loss 1362.1691600598788
INFO:root:current train perplexity2.9275033473968506
INFO:root:current mean train loss 1362.6408088589892
INFO:root:current train perplexity2.9290671348571777
INFO:root:current mean train loss 1362.8847646314043
INFO:root:current train perplexity2.9285762310028076
INFO:root:current mean train loss 1363.4706980275585
INFO:root:current train perplexity2.9307022094726562
INFO:root:current mean train loss 1364.61386941274
INFO:root:current train perplexity2.9319331645965576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.41s/it]
INFO:root:final mean train loss: 1364.0424573227906
INFO:root:final train perplexity: 2.9322383403778076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.25s/it]
INFO:root:eval mean loss: 2193.6972115158187
INFO:root:eval perplexity: 5.895171642303467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2741.703952654034
INFO:root:eval perplexity: 9.41440486907959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [20:04:07<15:03:41, 630.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1344.2017888249577
INFO:root:current train perplexity2.8722081184387207
INFO:root:current mean train loss 1343.1633879946967
INFO:root:current train perplexity2.9050590991973877
INFO:root:current mean train loss 1344.2552526288898
INFO:root:current train perplexity2.8958027362823486
INFO:root:current mean train loss 1351.7351258954238
INFO:root:current train perplexity2.9080445766448975
INFO:root:current mean train loss 1352.84085690566
INFO:root:current train perplexity2.9163472652435303
INFO:root:current mean train loss 1355.257619051516
INFO:root:current train perplexity2.9205427169799805
INFO:root:current mean train loss 1356.4384087243673
INFO:root:current train perplexity2.9230592250823975
INFO:root:current mean train loss 1356.2012699287652
INFO:root:current train perplexity2.9199721813201904
INFO:root:current mean train loss 1356.2463349737716
INFO:root:current train perplexity2.918154001235962
INFO:root:current mean train loss 1355.8519116445439
INFO:root:current train perplexity2.917485475540161
INFO:root:current mean train loss 1356.9912256518578
INFO:root:current train perplexity2.91814923286438
INFO:root:current mean train loss 1356.6317450020956
INFO:root:current train perplexity2.917651414871216
INFO:root:current mean train loss 1357.4595706480206
INFO:root:current train perplexity2.919278860092163
INFO:root:current mean train loss 1357.762201735754
INFO:root:current train perplexity2.919309616088867
INFO:root:current mean train loss 1358.5548350547201
INFO:root:current train perplexity2.920003890991211
INFO:root:current mean train loss 1358.4560328466828
INFO:root:current train perplexity2.9205968379974365
INFO:root:current mean train loss 1359.1923766977989
INFO:root:current train perplexity2.9221503734588623
INFO:root:current mean train loss 1359.279485567452
INFO:root:current train perplexity2.923354387283325
INFO:root:current mean train loss 1360.3681436620723
INFO:root:current train perplexity2.9240939617156982
INFO:root:current mean train loss 1360.752923070369
INFO:root:current train perplexity2.9240071773529053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.20s/it]
INFO:root:final mean train loss: 1360.5634295626596
INFO:root:final train perplexity: 2.9242031574249268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2194.4682236258864
INFO:root:eval perplexity: 5.898848533630371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 2743.5175651387967
INFO:root:eval perplexity: 9.428378105163574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [20:14:31<14:50:18, 628.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1360.8533121744792
INFO:root:current train perplexity2.900167942047119
INFO:root:current mean train loss 1363.3013892235695
INFO:root:current train perplexity2.9022295475006104
INFO:root:current mean train loss 1357.9082353246495
INFO:root:current train perplexity2.9049103260040283
INFO:root:current mean train loss 1351.8506090412031
INFO:root:current train perplexity2.901791572570801
INFO:root:current mean train loss 1351.7240995835627
INFO:root:current train perplexity2.904991388320923
INFO:root:current mean train loss 1353.0055385548285
INFO:root:current train perplexity2.906433582305908
INFO:root:current mean train loss 1354.0946698203363
INFO:root:current train perplexity2.9092280864715576
INFO:root:current mean train loss 1354.705269649111
INFO:root:current train perplexity2.910369634628296
INFO:root:current mean train loss 1354.3924158886948
INFO:root:current train perplexity2.9107165336608887
INFO:root:current mean train loss 1354.2585747356934
INFO:root:current train perplexity2.912914514541626
INFO:root:current mean train loss 1354.968238092238
INFO:root:current train perplexity2.9130055904388428
INFO:root:current mean train loss 1355.6328450802914
INFO:root:current train perplexity2.912665605545044
INFO:root:current mean train loss 1355.3832037285374
INFO:root:current train perplexity2.9138712882995605
INFO:root:current mean train loss 1355.4701033216108
INFO:root:current train perplexity2.913095235824585
INFO:root:current mean train loss 1355.4291084635865
INFO:root:current train perplexity2.9132096767425537
INFO:root:current mean train loss 1356.0059564656733
INFO:root:current train perplexity2.914299726486206
INFO:root:current mean train loss 1356.779421011799
INFO:root:current train perplexity2.914584159851074
INFO:root:current mean train loss 1357.5510544119022
INFO:root:current train perplexity2.9157214164733887
INFO:root:current mean train loss 1357.7810028965034
INFO:root:current train perplexity2.9172322750091553
INFO:root:current mean train loss 1358.0110343066306
INFO:root:current train perplexity2.918318271636963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.35s/it]
INFO:root:final mean train loss: 1357.897971071983
INFO:root:final train perplexity: 2.918062925338745
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2198.075777094415
INFO:root:eval perplexity: 5.916083812713623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.54s/it]
INFO:root:eval mean loss: 2750.1294828374334
INFO:root:eval perplexity: 9.479498863220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [20:24:52<14:36:59, 626.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1364.9157835194762
INFO:root:current train perplexity2.901905059814453
INFO:root:current mean train loss 1350.8770930418493
INFO:root:current train perplexity2.895106554031372
INFO:root:current mean train loss 1354.1419348910285
INFO:root:current train perplexity2.9027061462402344
INFO:root:current mean train loss 1352.2408944101667
INFO:root:current train perplexity2.901674509048462
INFO:root:current mean train loss 1351.3228669055202
INFO:root:current train perplexity2.8971052169799805
INFO:root:current mean train loss 1350.975576531031
INFO:root:current train perplexity2.8981077671051025
INFO:root:current mean train loss 1350.7371365906763
INFO:root:current train perplexity2.9005987644195557
INFO:root:current mean train loss 1351.6527721835482
INFO:root:current train perplexity2.900944709777832
INFO:root:current mean train loss 1353.3707059560222
INFO:root:current train perplexity2.903522491455078
INFO:root:current mean train loss 1352.3465402683687
INFO:root:current train perplexity2.9028542041778564
INFO:root:current mean train loss 1352.1994265316803
INFO:root:current train perplexity2.90200138092041
INFO:root:current mean train loss 1351.5525005545808
INFO:root:current train perplexity2.903082847595215
INFO:root:current mean train loss 1351.264164478173
INFO:root:current train perplexity2.9032833576202393
INFO:root:current mean train loss 1352.1632056928395
INFO:root:current train perplexity2.904681921005249
INFO:root:current mean train loss 1352.5939650130385
INFO:root:current train perplexity2.906348466873169
INFO:root:current mean train loss 1352.7017737570118
INFO:root:current train perplexity2.9078738689422607
INFO:root:current mean train loss 1352.759832394758
INFO:root:current train perplexity2.9079749584198
INFO:root:current mean train loss 1353.352179537514
INFO:root:current train perplexity2.9086053371429443
INFO:root:current mean train loss 1353.7849125660784
INFO:root:current train perplexity2.908395290374756
INFO:root:current mean train loss 1354.5010924394937
INFO:root:current train perplexity2.9095101356506348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.38s/it]
INFO:root:final mean train loss: 1354.1949497055539
INFO:root:final train perplexity: 2.9095535278320312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 2201.9086204150044
INFO:root:eval perplexity: 5.934450626373291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2753.03226292387
INFO:root:eval perplexity: 9.502029418945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [20:35:25<14:29:14, 628.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1341.971256602894
INFO:root:current train perplexity2.8653371334075928
INFO:root:current mean train loss 1347.5915280605884
INFO:root:current train perplexity2.8731307983398438
INFO:root:current mean train loss 1346.3295970492893
INFO:root:current train perplexity2.8765101432800293
INFO:root:current mean train loss 1347.5494957363483
INFO:root:current train perplexity2.873141288757324
INFO:root:current mean train loss 1346.2352860247502
INFO:root:current train perplexity2.878833293914795
INFO:root:current mean train loss 1346.3810898138552
INFO:root:current train perplexity2.8785054683685303
INFO:root:current mean train loss 1347.7716829166857
INFO:root:current train perplexity2.8815178871154785
INFO:root:current mean train loss 1347.074624618298
INFO:root:current train perplexity2.8838295936584473
INFO:root:current mean train loss 1347.3128483402836
INFO:root:current train perplexity2.8858835697174072
INFO:root:current mean train loss 1346.5826627291167
INFO:root:current train perplexity2.8867435455322266
INFO:root:current mean train loss 1348.5709014219397
INFO:root:current train perplexity2.8892829418182373
INFO:root:current mean train loss 1348.2639147825914
INFO:root:current train perplexity2.889936923980713
INFO:root:current mean train loss 1348.9098888894787
INFO:root:current train perplexity2.8925325870513916
INFO:root:current mean train loss 1349.6476160758511
INFO:root:current train perplexity2.893378257751465
INFO:root:current mean train loss 1350.1553062521002
INFO:root:current train perplexity2.8939647674560547
INFO:root:current mean train loss 1350.0998980236293
INFO:root:current train perplexity2.8966236114501953
INFO:root:current mean train loss 1351.2669781870186
INFO:root:current train perplexity2.8987975120544434
INFO:root:current mean train loss 1351.6819208815061
INFO:root:current train perplexity2.900113105773926
INFO:root:current mean train loss 1351.6883670354293
INFO:root:current train perplexity2.9012160301208496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.25s/it]
INFO:root:final mean train loss: 1351.2503894184554
INFO:root:final train perplexity: 2.902804374694824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2204.3784629875886
INFO:root:eval perplexity: 5.946316242218018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2756.007017311475
INFO:root:eval perplexity: 9.525176048278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [20:45:48<14:16:39, 626.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1297.1686767578126
INFO:root:current train perplexity2.8005778789520264
INFO:root:current mean train loss 1339.150677780878
INFO:root:current train perplexity2.871847629547119
INFO:root:current mean train loss 1334.864432879192
INFO:root:current train perplexity2.868886709213257
INFO:root:current mean train loss 1340.9388787941855
INFO:root:current train perplexity2.8729043006896973
INFO:root:current mean train loss 1341.7281412760417
INFO:root:current train perplexity2.874195098876953
INFO:root:current mean train loss 1343.8622664952043
INFO:root:current train perplexity2.8756399154663086
INFO:root:current mean train loss 1344.299290983342
INFO:root:current train perplexity2.8816099166870117
INFO:root:current mean train loss 1344.4464284477503
INFO:root:current train perplexity2.8869106769561768
INFO:root:current mean train loss 1344.754547687791
INFO:root:current train perplexity2.8888885974884033
INFO:root:current mean train loss 1345.7433259236877
INFO:root:current train perplexity2.8902719020843506
INFO:root:current mean train loss 1345.1299617634484
INFO:root:current train perplexity2.8905189037323
INFO:root:current mean train loss 1346.4320914566247
INFO:root:current train perplexity2.8925392627716064
INFO:root:current mean train loss 1346.7347366522952
INFO:root:current train perplexity2.89333176612854
INFO:root:current mean train loss 1347.6343561983656
INFO:root:current train perplexity2.894582748413086
INFO:root:current mean train loss 1348.0356325414257
INFO:root:current train perplexity2.8953585624694824
INFO:root:current mean train loss 1348.8800003406614
INFO:root:current train perplexity2.8966448307037354
INFO:root:current mean train loss 1348.7163539993428
INFO:root:current train perplexity2.8968441486358643
INFO:root:current mean train loss 1348.5750320031846
INFO:root:current train perplexity2.89634370803833
INFO:root:current mean train loss 1349.3023904816266
INFO:root:current train perplexity2.896683692932129
INFO:root:current mean train loss 1349.4524773545152
INFO:root:current train perplexity2.8975911140441895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.68s/it]
INFO:root:final mean train loss: 1349.163718388529
INFO:root:final train perplexity: 2.89803147315979
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2205.104518159907
INFO:root:eval perplexity: 5.949809551239014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it]
INFO:root:eval mean loss: 2758.428204475565
INFO:root:eval perplexity: 9.544053077697754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [20:56:10<14:04:08, 625.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1337.882901278409
INFO:root:current train perplexity2.8564562797546387
INFO:root:current mean train loss 1332.0036681128329
INFO:root:current train perplexity2.867689371109009
INFO:root:current mean train loss 1334.0281251099732
INFO:root:current train perplexity2.861356735229492
INFO:root:current mean train loss 1335.6282576093022
INFO:root:current train perplexity2.8659987449645996
INFO:root:current mean train loss 1336.522239070368
INFO:root:current train perplexity2.866469621658325
INFO:root:current mean train loss 1337.3679437746946
INFO:root:current train perplexity2.8700122833251953
INFO:root:current mean train loss 1336.974062413648
INFO:root:current train perplexity2.870731830596924
INFO:root:current mean train loss 1337.3512820087972
INFO:root:current train perplexity2.8716506958007812
INFO:root:current mean train loss 1339.4376424153645
INFO:root:current train perplexity2.8726277351379395
INFO:root:current mean train loss 1340.7390537882575
INFO:root:current train perplexity2.875884771347046
INFO:root:current mean train loss 1340.9854848604145
INFO:root:current train perplexity2.8763999938964844
INFO:root:current mean train loss 1341.9548982834433
INFO:root:current train perplexity2.878476619720459
INFO:root:current mean train loss 1341.903325007512
INFO:root:current train perplexity2.8802852630615234
INFO:root:current mean train loss 1341.9325895785564
INFO:root:current train perplexity2.8822364807128906
INFO:root:current mean train loss 1342.4232964066346
INFO:root:current train perplexity2.8845739364624023
INFO:root:current mean train loss 1343.6602494469141
INFO:root:current train perplexity2.88602614402771
INFO:root:current mean train loss 1344.3529862522637
INFO:root:current train perplexity2.8872008323669434
INFO:root:current mean train loss 1344.5753688479965
INFO:root:current train perplexity2.888521194458008
INFO:root:current mean train loss 1345.4985025282356
INFO:root:current train perplexity2.889274835586548
INFO:root:current mean train loss 1345.5390649769731
INFO:root:current train perplexity2.8894712924957275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.42s/it]
INFO:root:final mean train loss: 1345.6343219120336
INFO:root:final train perplexity: 2.8899760246276855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2207.316849945285
INFO:root:eval perplexity: 5.9604644775390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2758.837312306073
INFO:root:eval perplexity: 9.547248840332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [21:06:43<13:56:41, 627.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1330.2721917568108
INFO:root:current train perplexity2.837522268295288
INFO:root:current mean train loss 1332.318810771695
INFO:root:current train perplexity2.8482823371887207
INFO:root:current mean train loss 1331.9416141270594
INFO:root:current train perplexity2.8576340675354004
INFO:root:current mean train loss 1329.2035156970178
INFO:root:current train perplexity2.8649415969848633
INFO:root:current mean train loss 1329.9564303526304
INFO:root:current train perplexity2.8608155250549316
INFO:root:current mean train loss 1332.670108717315
INFO:root:current train perplexity2.8637006282806396
INFO:root:current mean train loss 1333.6277558471488
INFO:root:current train perplexity2.8631818294525146
INFO:root:current mean train loss 1334.1151985302668
INFO:root:current train perplexity2.8674073219299316
INFO:root:current mean train loss 1335.759539380261
INFO:root:current train perplexity2.866556406021118
INFO:root:current mean train loss 1336.4882340598792
INFO:root:current train perplexity2.867943048477173
INFO:root:current mean train loss 1337.5871753564124
INFO:root:current train perplexity2.8706107139587402
INFO:root:current mean train loss 1338.4283539434605
INFO:root:current train perplexity2.871826410293579
INFO:root:current mean train loss 1338.3912737756318
INFO:root:current train perplexity2.872152328491211
INFO:root:current mean train loss 1339.2786971897756
INFO:root:current train perplexity2.87380051612854
INFO:root:current mean train loss 1339.4524404222225
INFO:root:current train perplexity2.8753256797790527
INFO:root:current mean train loss 1340.8074360253208
INFO:root:current train perplexity2.8772289752960205
INFO:root:current mean train loss 1341.7193405402732
INFO:root:current train perplexity2.8795719146728516
INFO:root:current mean train loss 1342.1100777290962
INFO:root:current train perplexity2.880183219909668
INFO:root:current mean train loss 1342.4511917222123
INFO:root:current train perplexity2.881927728652954
INFO:root:current mean train loss 1342.9685392256802
INFO:root:current train perplexity2.883044719696045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.76s/it]
INFO:root:final mean train loss: 1342.7873421580998
INFO:root:final train perplexity: 2.8834943771362305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2210.259040994847
INFO:root:eval perplexity: 5.974663734436035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2763.003337887162
INFO:root:eval perplexity: 9.57983112335205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [21:17:05<13:44:03, 625.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1330.79829624721
INFO:root:current train perplexity2.853976249694824
INFO:root:current mean train loss 1332.6183776855469
INFO:root:current train perplexity2.859790325164795
INFO:root:current mean train loss 1332.7479028701782
INFO:root:current train perplexity2.8581833839416504
INFO:root:current mean train loss 1331.8818469101125
INFO:root:current train perplexity2.8600947856903076
INFO:root:current mean train loss 1335.1615241870545
INFO:root:current train perplexity2.859218120574951
INFO:root:current mean train loss 1337.266374327296
INFO:root:current train perplexity2.8603515625
INFO:root:current mean train loss 1338.3107069062023
INFO:root:current train perplexity2.861288070678711
INFO:root:current mean train loss 1336.5698355215568
INFO:root:current train perplexity2.862872838973999
INFO:root:current mean train loss 1336.8777602721598
INFO:root:current train perplexity2.866241693496704
INFO:root:current mean train loss 1337.294217416931
INFO:root:current train perplexity2.870004415512085
INFO:root:current mean train loss 1337.0950326630564
INFO:root:current train perplexity2.8699023723602295
INFO:root:current mean train loss 1336.295279004582
INFO:root:current train perplexity2.870083808898926
INFO:root:current mean train loss 1336.1095813338163
INFO:root:current train perplexity2.870572328567505
INFO:root:current mean train loss 1337.2327446051404
INFO:root:current train perplexity2.87166690826416
INFO:root:current mean train loss 1337.3267778669085
INFO:root:current train perplexity2.872610569000244
INFO:root:current mean train loss 1338.3692735215998
INFO:root:current train perplexity2.8735716342926025
INFO:root:current mean train loss 1338.588402789572
INFO:root:current train perplexity2.873903274536133
INFO:root:current mean train loss 1339.031282116449
INFO:root:current train perplexity2.875232696533203
INFO:root:current mean train loss 1339.7953479372222
INFO:root:current train perplexity2.875744581222534
INFO:root:current mean train loss 1340.2383793555887
INFO:root:current train perplexity2.8769922256469727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.46s/it]
INFO:root:final mean train loss: 1340.053021329494
INFO:root:final train perplexity: 2.8772828578948975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2211.4661380416114
INFO:root:eval perplexity: 5.980498313903809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2767.149738284713
INFO:root:eval perplexity: 9.612372398376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [21:27:30<13:33:17, 625.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1327.198809061965
INFO:root:current train perplexity2.865647554397583
INFO:root:current mean train loss 1329.850305810829
INFO:root:current train perplexity2.8617770671844482
INFO:root:current mean train loss 1332.591840695112
INFO:root:current train perplexity2.859323024749756
INFO:root:current mean train loss 1332.543277689343
INFO:root:current train perplexity2.857227325439453
INFO:root:current mean train loss 1330.4891726471658
INFO:root:current train perplexity2.8589870929718018
INFO:root:current mean train loss 1331.2764800972132
INFO:root:current train perplexity2.8615353107452393
INFO:root:current mean train loss 1331.8624233115481
INFO:root:current train perplexity2.863246202468872
INFO:root:current mean train loss 1333.1422727123424
INFO:root:current train perplexity2.8634912967681885
INFO:root:current mean train loss 1334.4812099810729
INFO:root:current train perplexity2.863264799118042
INFO:root:current mean train loss 1335.488537936392
INFO:root:current train perplexity2.8630571365356445
INFO:root:current mean train loss 1336.263237404801
INFO:root:current train perplexity2.8642892837524414
INFO:root:current mean train loss 1337.3319808816868
INFO:root:current train perplexity2.8671200275421143
INFO:root:current mean train loss 1338.0632703950437
INFO:root:current train perplexity2.8672142028808594
INFO:root:current mean train loss 1337.6715034545987
INFO:root:current train perplexity2.8681657314300537
INFO:root:current mean train loss 1337.552387307472
INFO:root:current train perplexity2.8678855895996094
INFO:root:current mean train loss 1337.595964959224
INFO:root:current train perplexity2.86820912361145
INFO:root:current mean train loss 1338.312047690456
INFO:root:current train perplexity2.8689732551574707
INFO:root:current mean train loss 1338.570571236737
INFO:root:current train perplexity2.8697025775909424
INFO:root:current mean train loss 1337.9977185299736
INFO:root:current train perplexity2.870433807373047
INFO:root:current mean train loss 1338.01417382961
INFO:root:current train perplexity2.8715391159057617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.16s/it]
INFO:root:final mean train loss: 1337.5925796824276
INFO:root:final train perplexity: 2.8717048168182373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2214.928724356577
INFO:root:eval perplexity: 5.997269153594971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2770.340905155696
INFO:root:eval perplexity: 9.637490272521973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [21:38:03<13:25:49, 627.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1325.446114095052
INFO:root:current train perplexity2.859492778778076
INFO:root:current mean train loss 1322.371064196135
INFO:root:current train perplexity2.8460853099823
INFO:root:current mean train loss 1328.3703508048222
INFO:root:current train perplexity2.8529696464538574
INFO:root:current mean train loss 1330.8654181064703
INFO:root:current train perplexity2.855743646621704
INFO:root:current mean train loss 1331.0458109952965
INFO:root:current train perplexity2.856963872909546
INFO:root:current mean train loss 1330.8638152558924
INFO:root:current train perplexity2.8560781478881836
INFO:root:current mean train loss 1329.9963676120924
INFO:root:current train perplexity2.8564796447753906
INFO:root:current mean train loss 1330.8383399673655
INFO:root:current train perplexity2.85742449760437
INFO:root:current mean train loss 1331.4661747278792
INFO:root:current train perplexity2.8585665225982666
INFO:root:current mean train loss 1331.2627028340041
INFO:root:current train perplexity2.859860897064209
INFO:root:current mean train loss 1331.576586466098
INFO:root:current train perplexity2.8594963550567627
INFO:root:current mean train loss 1331.7562861081933
INFO:root:current train perplexity2.861454963684082
INFO:root:current mean train loss 1331.4217607838239
INFO:root:current train perplexity2.861478805541992
INFO:root:current mean train loss 1331.809625375871
INFO:root:current train perplexity2.861219882965088
INFO:root:current mean train loss 1332.8969330038801
INFO:root:current train perplexity2.8616955280303955
INFO:root:current mean train loss 1332.7937290407576
INFO:root:current train perplexity2.861266613006592
INFO:root:current mean train loss 1332.8597906891412
INFO:root:current train perplexity2.8616957664489746
INFO:root:current mean train loss 1333.623924621923
INFO:root:current train perplexity2.862147808074951
INFO:root:current mean train loss 1334.461546818163
INFO:root:current train perplexity2.864436149597168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.64s/it]
INFO:root:final mean train loss: 1334.914271336881
INFO:root:final train perplexity: 2.8656458854675293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2217.3140020708665
INFO:root:eval perplexity: 6.00885009765625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2771.6176649594136
INFO:root:eval perplexity: 9.647560119628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [21:48:26<13:13:16, 626.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1331.9145333426338
INFO:root:current train perplexity2.7783432006835938
INFO:root:current mean train loss 1324.880372234594
INFO:root:current train perplexity2.8245186805725098
INFO:root:current mean train loss 1329.8372950162288
INFO:root:current train perplexity2.8394508361816406
INFO:root:current mean train loss 1327.4815793115076
INFO:root:current train perplexity2.8413162231445312
INFO:root:current mean train loss 1323.4723515241094
INFO:root:current train perplexity2.842641592025757
INFO:root:current mean train loss 1326.0056698891303
INFO:root:current train perplexity2.846714973449707
INFO:root:current mean train loss 1326.2295905275046
INFO:root:current train perplexity2.8454229831695557
INFO:root:current mean train loss 1326.9087744555009
INFO:root:current train perplexity2.844172716140747
INFO:root:current mean train loss 1326.6307764821483
INFO:root:current train perplexity2.843419075012207
INFO:root:current mean train loss 1327.3747872181211
INFO:root:current train perplexity2.845839262008667
INFO:root:current mean train loss 1326.5663360626008
INFO:root:current train perplexity2.846381902694702
INFO:root:current mean train loss 1326.8893245707359
INFO:root:current train perplexity2.847943067550659
INFO:root:current mean train loss 1327.2358380233145
INFO:root:current train perplexity2.847830057144165
INFO:root:current mean train loss 1327.6244081411091
INFO:root:current train perplexity2.848703384399414
INFO:root:current mean train loss 1328.0342684422474
INFO:root:current train perplexity2.850057601928711
INFO:root:current mean train loss 1329.209423568918
INFO:root:current train perplexity2.851264238357544
INFO:root:current mean train loss 1328.9497125764478
INFO:root:current train perplexity2.8519070148468018
INFO:root:current mean train loss 1329.7367539051058
INFO:root:current train perplexity2.853585720062256
INFO:root:current mean train loss 1330.309613547143
INFO:root:current train perplexity2.855213165283203
INFO:root:current mean train loss 1330.948069996026
INFO:root:current train perplexity2.8566577434539795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.10s/it]
INFO:root:final mean train loss: 1331.1094720468218
INFO:root:final train perplexity: 2.8570597171783447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2221.7062758858324
INFO:root:eval perplexity: 6.030231952667236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2778.592274767287
INFO:root:eval perplexity: 9.702746391296387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [21:58:47<13:01:11, 624.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1311.2645365397136
INFO:root:current train perplexity2.824652671813965
INFO:root:current mean train loss 1318.0274362871723
INFO:root:current train perplexity2.8323943614959717
INFO:root:current mean train loss 1318.5910372052874
INFO:root:current train perplexity2.821469783782959
INFO:root:current mean train loss 1320.5860478907455
INFO:root:current train perplexity2.8295912742614746
INFO:root:current mean train loss 1323.7627531807377
INFO:root:current train perplexity2.832875967025757
INFO:root:current mean train loss 1322.672763271186
INFO:root:current train perplexity2.83239483833313
INFO:root:current mean train loss 1323.112445342235
INFO:root:current train perplexity2.8358798027038574
INFO:root:current mean train loss 1323.5960748999157
INFO:root:current train perplexity2.8373026847839355
INFO:root:current mean train loss 1323.1075543153634
INFO:root:current train perplexity2.8406155109405518
INFO:root:current mean train loss 1322.6439022708248
INFO:root:current train perplexity2.841648817062378
INFO:root:current mean train loss 1323.8195515871048
INFO:root:current train perplexity2.844061851501465
INFO:root:current mean train loss 1324.0563187242826
INFO:root:current train perplexity2.8442866802215576
INFO:root:current mean train loss 1325.7913305743848
INFO:root:current train perplexity2.8458938598632812
INFO:root:current mean train loss 1325.9531118156688
INFO:root:current train perplexity2.8455400466918945
INFO:root:current mean train loss 1326.192749280608
INFO:root:current train perplexity2.846630811691284
INFO:root:current mean train loss 1326.8442850588501
INFO:root:current train perplexity2.8476812839508057
INFO:root:current mean train loss 1327.3597574468904
INFO:root:current train perplexity2.847858190536499
INFO:root:current mean train loss 1328.0585026929107
INFO:root:current train perplexity2.8495259284973145
INFO:root:current mean train loss 1328.5422329149749
INFO:root:current train perplexity2.8505516052246094
INFO:root:current mean train loss 1329.0837878189564
INFO:root:current train perplexity2.8513500690460205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.35s/it]
INFO:root:final mean train loss: 1328.862602507052
INFO:root:final train perplexity: 2.852001190185547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2223.1336436170213
INFO:root:eval perplexity: 6.037198066711426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2779.649744344941
INFO:root:eval perplexity: 9.711142539978027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [22:09:21<12:54:06, 627.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1313.9452172256097
INFO:root:current train perplexity2.8241052627563477
INFO:root:current mean train loss 1319.0663352587544
INFO:root:current train perplexity2.824162006378174
INFO:root:current mean train loss 1318.9857623468297
INFO:root:current train perplexity2.825082302093506
INFO:root:current mean train loss 1319.8617043593063
INFO:root:current train perplexity2.8262321949005127
INFO:root:current mean train loss 1322.123121611926
INFO:root:current train perplexity2.826894760131836
INFO:root:current mean train loss 1322.2228044943536
INFO:root:current train perplexity2.825183391571045
INFO:root:current mean train loss 1322.3263211778471
INFO:root:current train perplexity2.8251991271972656
INFO:root:current mean train loss 1321.456594202039
INFO:root:current train perplexity2.8253705501556396
INFO:root:current mean train loss 1321.326034273744
INFO:root:current train perplexity2.8258283138275146
INFO:root:current mean train loss 1322.0725305214698
INFO:root:current train perplexity2.8287062644958496
INFO:root:current mean train loss 1322.4053389872643
INFO:root:current train perplexity2.8309097290039062
INFO:root:current mean train loss 1322.951919167842
INFO:root:current train perplexity2.8329238891601562
INFO:root:current mean train loss 1323.0594156835466
INFO:root:current train perplexity2.8348731994628906
INFO:root:current mean train loss 1324.058810763889
INFO:root:current train perplexity2.8372178077697754
INFO:root:current mean train loss 1324.6237471062304
INFO:root:current train perplexity2.8382837772369385
INFO:root:current mean train loss 1325.4127265390523
INFO:root:current train perplexity2.8404221534729004
INFO:root:current mean train loss 1325.7572481944603
INFO:root:current train perplexity2.8429956436157227
INFO:root:current mean train loss 1326.3349286144592
INFO:root:current train perplexity2.844008207321167
INFO:root:current mean train loss 1326.4683741746164
INFO:root:current train perplexity2.8448262214660645
INFO:root:current mean train loss 1326.7474041977596
INFO:root:current train perplexity2.845775842666626

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.12s/it]
INFO:root:final mean train loss: 1326.2651525700387
INFO:root:final train perplexity: 2.846165418624878
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2226.169518436946
INFO:root:eval perplexity: 6.05203914642334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2784.269876683012
INFO:root:eval perplexity: 9.747904777526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [22:19:43<12:41:32, 625.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1299.192890035695
INFO:root:current train perplexity2.8039662837982178
INFO:root:current mean train loss 1304.6522278604627
INFO:root:current train perplexity2.818481206893921
INFO:root:current mean train loss 1311.2766576959182
INFO:root:current train perplexity2.8284075260162354
INFO:root:current mean train loss 1312.3529086832227
INFO:root:current train perplexity2.827000141143799
INFO:root:current mean train loss 1313.8172887277394
INFO:root:current train perplexity2.825333833694458
INFO:root:current mean train loss 1315.6071103550628
INFO:root:current train perplexity2.8246419429779053
INFO:root:current mean train loss 1316.9198942329383
INFO:root:current train perplexity2.826942205429077
INFO:root:current mean train loss 1317.761734371135
INFO:root:current train perplexity2.828505039215088
INFO:root:current mean train loss 1318.46110225224
INFO:root:current train perplexity2.827407121658325
INFO:root:current mean train loss 1318.9726317849686
INFO:root:current train perplexity2.8287131786346436
INFO:root:current mean train loss 1320.3460654130731
INFO:root:current train perplexity2.8301992416381836
INFO:root:current mean train loss 1320.4551698358566
INFO:root:current train perplexity2.831515312194824
INFO:root:current mean train loss 1320.9238230791684
INFO:root:current train perplexity2.8329880237579346
INFO:root:current mean train loss 1321.222534359467
INFO:root:current train perplexity2.833707571029663
INFO:root:current mean train loss 1321.3452942145705
INFO:root:current train perplexity2.8338687419891357
INFO:root:current mean train loss 1322.1141838494866
INFO:root:current train perplexity2.834183931350708
INFO:root:current mean train loss 1322.416107656297
INFO:root:current train perplexity2.8352222442626953
INFO:root:current mean train loss 1323.0056214142714
INFO:root:current train perplexity2.8362293243408203
INFO:root:current mean train loss 1323.4399013950442
INFO:root:current train perplexity2.8373100757598877
INFO:root:current mean train loss 1323.5792120991007
INFO:root:current train perplexity2.83879017829895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.76s/it]
INFO:root:final mean train loss: 1323.3412534989795
INFO:root:final train perplexity: 2.839609384536743
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2229.1225321884694
INFO:root:eval perplexity: 6.066510200500488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2787.728864953873
INFO:root:eval perplexity: 9.775519371032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [22:30:09<12:31:03, 625.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1312.8221956380207
INFO:root:current train perplexity2.826103925704956
INFO:root:current mean train loss 1313.1518310546876
INFO:root:current train perplexity2.8095908164978027
INFO:root:current mean train loss 1314.236093306108
INFO:root:current train perplexity2.8187270164489746
INFO:root:current mean train loss 1315.1288089192708
INFO:root:current train perplexity2.8205819129943848
INFO:root:current mean train loss 1313.304995888158
INFO:root:current train perplexity2.8199453353881836
INFO:root:current mean train loss 1314.6291047469429
INFO:root:current train perplexity2.822335958480835
INFO:root:current mean train loss 1314.2276479311342
INFO:root:current train perplexity2.8204615116119385
INFO:root:current mean train loss 1315.4543179813509
INFO:root:current train perplexity2.821814775466919
INFO:root:current mean train loss 1317.0866911272321
INFO:root:current train perplexity2.824028730392456
INFO:root:current mean train loss 1317.066875751202
INFO:root:current train perplexity2.825594902038574
INFO:root:current mean train loss 1317.9479273028705
INFO:root:current train perplexity2.8264546394348145
INFO:root:current mean train loss 1318.2007083194815
INFO:root:current train perplexity2.8264715671539307
INFO:root:current mean train loss 1317.9361308976715
INFO:root:current train perplexity2.8268091678619385
INFO:root:current mean train loss 1318.3590589488635
INFO:root:current train perplexity2.8288352489471436
INFO:root:current mean train loss 1319.2254306806144
INFO:root:current train perplexity2.8295016288757324
INFO:root:current mean train loss 1319.2191943359376
INFO:root:current train perplexity2.831087589263916
INFO:root:current mean train loss 1319.5155897271454
INFO:root:current train perplexity2.8318474292755127
INFO:root:current mean train loss 1320.3546809666593
INFO:root:current train perplexity2.8326897621154785
INFO:root:current mean train loss 1321.0525446614583
INFO:root:current train perplexity2.833540916442871
INFO:root:current mean train loss 1320.7956822957872
INFO:root:current train perplexity2.833531618118286

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.20s/it]
INFO:root:final mean train loss: 1320.6067765890439
INFO:root:final train perplexity: 2.8334920406341553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2232.301841357076
INFO:root:eval perplexity: 6.082127094268799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2793.51959401665
INFO:root:eval perplexity: 9.82192325592041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [22:40:32<12:19:38, 625.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.3320219620414
INFO:root:current train perplexity2.788282871246338
INFO:root:current mean train loss 1306.281452178955
INFO:root:current train perplexity2.8041157722473145
INFO:root:current mean train loss 1303.8916935332834
INFO:root:current train perplexity2.808690309524536
INFO:root:current mean train loss 1307.89187435228
INFO:root:current train perplexity2.814901351928711
INFO:root:current mean train loss 1308.265110667159
INFO:root:current train perplexity2.8126025199890137
INFO:root:current mean train loss 1309.750831397804
INFO:root:current train perplexity2.8142709732055664
INFO:root:current mean train loss 1311.1110352973717
INFO:root:current train perplexity2.817934274673462
INFO:root:current mean train loss 1311.456056382921
INFO:root:current train perplexity2.8201510906219482
INFO:root:current mean train loss 1311.4539124356256
INFO:root:current train perplexity2.820594310760498
INFO:root:current mean train loss 1312.1141010407478
INFO:root:current train perplexity2.8207695484161377
INFO:root:current mean train loss 1313.0936942187857
INFO:root:current train perplexity2.822970151901245
INFO:root:current mean train loss 1313.2769980206585
INFO:root:current train perplexity2.8231050968170166
INFO:root:current mean train loss 1314.2227751079358
INFO:root:current train perplexity2.8235981464385986
INFO:root:current mean train loss 1314.7057606488809
INFO:root:current train perplexity2.822847366333008
INFO:root:current mean train loss 1315.5395377724165
INFO:root:current train perplexity2.823293924331665
INFO:root:current mean train loss 1316.592963290574
INFO:root:current train perplexity2.8247640132904053
INFO:root:current mean train loss 1317.4494159960013
INFO:root:current train perplexity2.82452392578125
INFO:root:current mean train loss 1317.739783355168
INFO:root:current train perplexity2.825657367706299
INFO:root:current mean train loss 1318.1261531515304
INFO:root:current train perplexity2.8271758556365967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.20s/it]
INFO:root:final mean train loss: 1317.997921049625
INFO:root:final train perplexity: 2.8276681900024414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 2233.1158282773713
INFO:root:eval perplexity: 6.086133003234863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2793.535236331588
INFO:root:eval perplexity: 9.822050094604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [22:51:11<12:14:11, 629.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1297.1504855685764
INFO:root:current train perplexity2.755676031112671
INFO:root:current mean train loss 1310.0434447122277
INFO:root:current train perplexity2.808265447616577
INFO:root:current mean train loss 1308.1771497224506
INFO:root:current train perplexity2.814767837524414
INFO:root:current mean train loss 1308.5609237522756
INFO:root:current train perplexity2.815544843673706
INFO:root:current mean train loss 1309.6460680227117
INFO:root:current train perplexity2.8129615783691406
INFO:root:current mean train loss 1311.2678119532018
INFO:root:current train perplexity2.815997362136841
INFO:root:current mean train loss 1310.81280407334
INFO:root:current train perplexity2.8145205974578857
INFO:root:current mean train loss 1311.113581002347
INFO:root:current train perplexity2.816659688949585
INFO:root:current mean train loss 1311.5040394862
INFO:root:current train perplexity2.8184010982513428
INFO:root:current mean train loss 1311.2009915224921
INFO:root:current train perplexity2.8186488151550293
INFO:root:current mean train loss 1311.4481151569469
INFO:root:current train perplexity2.8192594051361084
INFO:root:current mean train loss 1312.3185402239842
INFO:root:current train perplexity2.819028615951538
INFO:root:current mean train loss 1312.3950792033384
INFO:root:current train perplexity2.8196394443511963
INFO:root:current mean train loss 1313.4287032906202
INFO:root:current train perplexity2.820272207260132
INFO:root:current mean train loss 1313.7227970337174
INFO:root:current train perplexity2.8215038776397705
INFO:root:current mean train loss 1314.5277024377174
INFO:root:current train perplexity2.8213109970092773
INFO:root:current mean train loss 1314.0955941038446
INFO:root:current train perplexity2.821126699447632
INFO:root:current mean train loss 1314.5168836313496
INFO:root:current train perplexity2.8212625980377197
INFO:root:current mean train loss 1314.793217614186
INFO:root:current train perplexity2.821206569671631
INFO:root:current mean train loss 1315.3551938520045
INFO:root:current train perplexity2.8211162090301514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.23s/it]
INFO:root:final mean train loss: 1315.4607996707364
INFO:root:final train perplexity: 2.8220160007476807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2236.4707074537346
INFO:root:eval perplexity: 6.102668285369873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2799.4154130651596
INFO:root:eval perplexity: 9.869397163391113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [23:01:39<12:03:13, 628.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1272.8473604642427
INFO:root:current train perplexity2.8121864795684814
INFO:root:current mean train loss 1299.4195304749503
INFO:root:current train perplexity2.7909038066864014
INFO:root:current mean train loss 1301.0707678330682
INFO:root:current train perplexity2.7923007011413574
INFO:root:current mean train loss 1303.803022326136
INFO:root:current train perplexity2.7976043224334717
INFO:root:current mean train loss 1305.2146620772814
INFO:root:current train perplexity2.7983956336975098
INFO:root:current mean train loss 1307.369057542924
INFO:root:current train perplexity2.8008227348327637
INFO:root:current mean train loss 1307.6895900153504
INFO:root:current train perplexity2.802764892578125
INFO:root:current mean train loss 1307.9865115667506
INFO:root:current train perplexity2.804168939590454
INFO:root:current mean train loss 1309.0722629648722
INFO:root:current train perplexity2.8052408695220947
INFO:root:current mean train loss 1310.2875193519674
INFO:root:current train perplexity2.8080856800079346
INFO:root:current mean train loss 1310.8522083066825
INFO:root:current train perplexity2.8084466457366943
INFO:root:current mean train loss 1311.4469656529266
INFO:root:current train perplexity2.810378074645996
INFO:root:current mean train loss 1311.4300388753122
INFO:root:current train perplexity2.8100674152374268
INFO:root:current mean train loss 1311.776497819305
INFO:root:current train perplexity2.810938596725464
INFO:root:current mean train loss 1311.3048935471545
INFO:root:current train perplexity2.8110344409942627
INFO:root:current mean train loss 1311.586049091144
INFO:root:current train perplexity2.811850070953369
INFO:root:current mean train loss 1312.2859377702664
INFO:root:current train perplexity2.8135504722595215
INFO:root:current mean train loss 1312.7377295996887
INFO:root:current train perplexity2.815732717514038
INFO:root:current mean train loss 1313.5537654212376
INFO:root:current train perplexity2.8164284229278564
INFO:root:current mean train loss 1313.7497684720397
INFO:root:current train perplexity2.8173863887786865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.51s/it]
INFO:root:final mean train loss: 1313.7189168848297
INFO:root:final train perplexity: 2.8181421756744385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.40s/it]
INFO:root:eval mean loss: 2240.01731450507
INFO:root:eval perplexity: 6.1201982498168945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2800.588792733267
INFO:root:eval perplexity: 9.87887191772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [23:12:17<11:55:41, 631.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1300.4369322311047
INFO:root:current train perplexity2.7978873252868652
INFO:root:current mean train loss 1304.3573151701814
INFO:root:current train perplexity2.7974939346313477
INFO:root:current mean train loss 1303.300249264564
INFO:root:current train perplexity2.789618730545044
INFO:root:current mean train loss 1307.110251201485
INFO:root:current train perplexity2.7952799797058105
INFO:root:current mean train loss 1307.110062782167
INFO:root:current train perplexity2.798734664916992
INFO:root:current mean train loss 1307.2974086923055
INFO:root:current train perplexity2.798381805419922
INFO:root:current mean train loss 1307.808153119836
INFO:root:current train perplexity2.799511432647705
INFO:root:current mean train loss 1306.8767804521892
INFO:root:current train perplexity2.798121929168701
INFO:root:current mean train loss 1307.2257673777153
INFO:root:current train perplexity2.7980353832244873
INFO:root:current mean train loss 1306.8325702752188
INFO:root:current train perplexity2.800645351409912
INFO:root:current mean train loss 1307.4011284306089
INFO:root:current train perplexity2.802804708480835
INFO:root:current mean train loss 1307.9784100016063
INFO:root:current train perplexity2.8041718006134033
INFO:root:current mean train loss 1308.8272963360444
INFO:root:current train perplexity2.804788112640381
INFO:root:current mean train loss 1308.5788130657227
INFO:root:current train perplexity2.805532455444336
INFO:root:current mean train loss 1309.0323888153478
INFO:root:current train perplexity2.806950807571411
INFO:root:current mean train loss 1309.5104092828499
INFO:root:current train perplexity2.8084371089935303
INFO:root:current mean train loss 1309.8845181410006
INFO:root:current train perplexity2.808310031890869
INFO:root:current mean train loss 1309.8829684670602
INFO:root:current train perplexity2.8094053268432617
INFO:root:current mean train loss 1310.3719300939154
INFO:root:current train perplexity2.8094520568847656
INFO:root:current mean train loss 1310.8522847441134
INFO:root:current train perplexity2.811185836791992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.82s/it]
INFO:root:final mean train loss: 1310.7120309311274
INFO:root:final train perplexity: 2.811466932296753
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 2240.401511767232
INFO:root:eval perplexity: 6.122099876403809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 2804.330925258339
INFO:root:eval perplexity: 9.909151077270508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [23:23:09<11:52:09, 637.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1299.530411783854
INFO:root:current train perplexity2.8087880611419678
INFO:root:current mean train loss 1307.357260131836
INFO:root:current train perplexity2.787813425064087
INFO:root:current mean train loss 1305.0211594801683
INFO:root:current train perplexity2.7847836017608643
INFO:root:current mean train loss 1305.619443766276
INFO:root:current train perplexity2.7890350818634033
INFO:root:current mean train loss 1306.7891062860904
INFO:root:current train perplexity2.7924420833587646
INFO:root:current mean train loss 1307.1081839425224
INFO:root:current train perplexity2.789764881134033
INFO:root:current mean train loss 1307.4372691761364
INFO:root:current train perplexity2.792039394378662
INFO:root:current mean train loss 1306.6693523206209
INFO:root:current train perplexity2.795330047607422
INFO:root:current mean train loss 1307.2999747342842
INFO:root:current train perplexity2.7965149879455566
INFO:root:current mean train loss 1306.636440149943
INFO:root:current train perplexity2.798153877258301
INFO:root:current mean train loss 1306.6228920990566
INFO:root:current train perplexity2.7984771728515625
INFO:root:current mean train loss 1307.21450142696
INFO:root:current train perplexity2.800354242324829
INFO:root:current mean train loss 1308.1765230693513
INFO:root:current train perplexity2.8011553287506104
INFO:root:current mean train loss 1308.130687489229
INFO:root:current train perplexity2.801614761352539
INFO:root:current mean train loss 1308.313147056266
INFO:root:current train perplexity2.801048755645752
INFO:root:current mean train loss 1307.9498046875
INFO:root:current train perplexity2.801943778991699
INFO:root:current mean train loss 1308.2577957337162
INFO:root:current train perplexity2.8039755821228027
INFO:root:current mean train loss 1308.8048067959871
INFO:root:current train perplexity2.804959774017334
INFO:root:current mean train loss 1308.7496445522513
INFO:root:current train perplexity2.8058979511260986
INFO:root:current mean train loss 1308.9938131527024
INFO:root:current train perplexity2.8064398765563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.61s/it]
INFO:root:final mean train loss: 1308.610348515359
INFO:root:final train perplexity: 2.8068108558654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2242.324383674784
INFO:root:eval perplexity: 6.131628513336182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2805.7194936765845
INFO:root:eval perplexity: 9.92041301727295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [23:33:42<11:39:45, 636.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.0406842912946
INFO:root:current train perplexity2.7632246017456055
INFO:root:current mean train loss 1295.144978151483
INFO:root:current train perplexity2.782323122024536
INFO:root:current mean train loss 1295.3067477119528
INFO:root:current train perplexity2.77777099609375
INFO:root:current mean train loss 1296.0172086761231
INFO:root:current train perplexity2.7801477909088135
INFO:root:current mean train loss 1296.0905513483524
INFO:root:current train perplexity2.7809078693389893
INFO:root:current mean train loss 1297.0216341597163
INFO:root:current train perplexity2.7838425636291504
INFO:root:current mean train loss 1298.571622276588
INFO:root:current train perplexity2.7864151000976562
INFO:root:current mean train loss 1299.5883664949827
INFO:root:current train perplexity2.7893435955047607
INFO:root:current mean train loss 1300.884018170521
INFO:root:current train perplexity2.790182590484619
INFO:root:current mean train loss 1301.4712518791582
INFO:root:current train perplexity2.7895472049713135
INFO:root:current mean train loss 1302.1467087939589
INFO:root:current train perplexity2.7938928604125977
INFO:root:current mean train loss 1301.820881988603
INFO:root:current train perplexity2.7941553592681885
INFO:root:current mean train loss 1301.883916485935
INFO:root:current train perplexity2.793799877166748
INFO:root:current mean train loss 1302.3194199771922
INFO:root:current train perplexity2.7946908473968506
INFO:root:current mean train loss 1302.9731690775484
INFO:root:current train perplexity2.7960195541381836
INFO:root:current mean train loss 1303.4615490126625
INFO:root:current train perplexity2.7961881160736084
INFO:root:current mean train loss 1304.037311369703
INFO:root:current train perplexity2.7977025508880615
INFO:root:current mean train loss 1304.9126331713605
INFO:root:current train perplexity2.7985241413116455
INFO:root:current mean train loss 1305.3062843643863
INFO:root:current train perplexity2.800278902053833
INFO:root:current mean train loss 1305.7192687833917
INFO:root:current train perplexity2.799821615219116

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.55s/it]
INFO:root:final mean train loss: 1305.4361747091489
INFO:root:final train perplexity: 2.799793243408203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2248.2004978910404
INFO:root:eval perplexity: 6.160836219787598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2810.476350824884
INFO:root:eval perplexity: 9.959078788757324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [23:44:11<11:26:57, 634.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1285.4197959088265
INFO:root:current train perplexity2.759570598602295
INFO:root:current mean train loss 1290.9811665643122
INFO:root:current train perplexity2.770555257797241
INFO:root:current mean train loss 1293.1407960645195
INFO:root:current train perplexity2.7738916873931885
INFO:root:current mean train loss 1295.5473555356718
INFO:root:current train perplexity2.771409749984741
INFO:root:current mean train loss 1295.9932928046717
INFO:root:current train perplexity2.775596857070923
INFO:root:current mean train loss 1298.463628801031
INFO:root:current train perplexity2.7799718379974365
INFO:root:current mean train loss 1299.1874899740521
INFO:root:current train perplexity2.7818779945373535
INFO:root:current mean train loss 1299.0163383579975
INFO:root:current train perplexity2.7834553718566895
INFO:root:current mean train loss 1300.6331171296054
INFO:root:current train perplexity2.786505937576294
INFO:root:current mean train loss 1301.2282631334883
INFO:root:current train perplexity2.7879061698913574
INFO:root:current mean train loss 1301.350667168933
INFO:root:current train perplexity2.788297176361084
INFO:root:current mean train loss 1301.49846676007
INFO:root:current train perplexity2.7896010875701904
INFO:root:current mean train loss 1301.7360420050172
INFO:root:current train perplexity2.7897024154663086
INFO:root:current mean train loss 1302.4910442073171
INFO:root:current train perplexity2.7911713123321533
INFO:root:current mean train loss 1302.5569469446798
INFO:root:current train perplexity2.791194438934326
INFO:root:current mean train loss 1302.5556806040229
INFO:root:current train perplexity2.7923126220703125
INFO:root:current mean train loss 1303.5433011646114
INFO:root:current train perplexity2.7938289642333984
INFO:root:current mean train loss 1303.6822425391497
INFO:root:current train perplexity2.7947936058044434
INFO:root:current mean train loss 1303.8568061095482
INFO:root:current train perplexity2.7953639030456543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.43s/it]
INFO:root:final mean train loss: 1303.8400993712671
INFO:root:final train perplexity: 2.7962710857391357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 2247.04911685159
INFO:root:eval perplexity: 6.155102729797363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2811.104687846299
INFO:root:eval perplexity: 9.96419906616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [23:54:41<11:14:58, 632.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.4069602272727
INFO:root:current train perplexity2.8102519512176514
INFO:root:current mean train loss 1294.1698943816864
INFO:root:current train perplexity2.7675304412841797
INFO:root:current mean train loss 1290.2237392624409
INFO:root:current train perplexity2.773366928100586
INFO:root:current mean train loss 1292.8273011235178
INFO:root:current train perplexity2.7713136672973633
INFO:root:current mean train loss 1293.3798320241217
INFO:root:current train perplexity2.770555257797241
INFO:root:current mean train loss 1293.826167097297
INFO:root:current train perplexity2.772935628890991
INFO:root:current mean train loss 1294.4332377282376
INFO:root:current train perplexity2.7757444381713867
INFO:root:current mean train loss 1295.2644269597179
INFO:root:current train perplexity2.778285503387451
INFO:root:current mean train loss 1296.3259068123361
INFO:root:current train perplexity2.7814009189605713
INFO:root:current mean train loss 1296.9753350970773
INFO:root:current train perplexity2.7819950580596924
INFO:root:current mean train loss 1297.3510280952491
INFO:root:current train perplexity2.7827343940734863
INFO:root:current mean train loss 1298.549745794892
INFO:root:current train perplexity2.7842180728912354
INFO:root:current mean train loss 1298.6540514239587
INFO:root:current train perplexity2.784147262573242
INFO:root:current mean train loss 1299.1168357214792
INFO:root:current train perplexity2.7848548889160156
INFO:root:current mean train loss 1300.0976315071869
INFO:root:current train perplexity2.7875735759735107
INFO:root:current mean train loss 1300.0788913527363
INFO:root:current train perplexity2.7883925437927246
INFO:root:current mean train loss 1300.234567690754
INFO:root:current train perplexity2.7890284061431885
INFO:root:current mean train loss 1300.4117753403984
INFO:root:current train perplexity2.78885555267334
INFO:root:current mean train loss 1301.6255918152092
INFO:root:current train perplexity2.7904717922210693
INFO:root:current mean train loss 1301.987015768597
INFO:root:current train perplexity2.7911391258239746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.22s/it]
INFO:root:final mean train loss: 1301.598037973655
INFO:root:final train perplexity: 2.791330337524414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 2250.591113800698
INFO:root:eval perplexity: 6.172759532928467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2816.871878549562
INFO:root:eval perplexity: 10.011310577392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [24:05:18<11:05:55, 634.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.2031032017298
INFO:root:current train perplexity2.743494749069214
INFO:root:current mean train loss 1286.4393157958984
INFO:root:current train perplexity2.755603551864624
INFO:root:current mean train loss 1290.4886303282622
INFO:root:current train perplexity2.7600996494293213
INFO:root:current mean train loss 1293.6263256538205
INFO:root:current train perplexity2.766120195388794
INFO:root:current mean train loss 1291.2956965081046
INFO:root:current train perplexity2.7686214447021484
INFO:root:current mean train loss 1291.5675918116715
INFO:root:current train perplexity2.76892352104187
INFO:root:current mean train loss 1291.8220541401274
INFO:root:current train perplexity2.7707157135009766
INFO:root:current mean train loss 1291.5236216115427
INFO:root:current train perplexity2.771049976348877
INFO:root:current mean train loss 1292.9531583187086
INFO:root:current train perplexity2.77382493019104
INFO:root:current mean train loss 1293.5394460743871
INFO:root:current train perplexity2.7735824584960938
INFO:root:current mean train loss 1294.129817265017
INFO:root:current train perplexity2.77504825592041
INFO:root:current mean train loss 1294.950328312867
INFO:root:current train perplexity2.7789816856384277
INFO:root:current mean train loss 1295.9256457599056
INFO:root:current train perplexity2.7802700996398926
INFO:root:current mean train loss 1296.266203639019
INFO:root:current train perplexity2.782012939453125
INFO:root:current mean train loss 1296.2011601637726
INFO:root:current train perplexity2.7832205295562744
INFO:root:current mean train loss 1296.559746867075
INFO:root:current train perplexity2.7835986614227295
INFO:root:current mean train loss 1296.6330612145127
INFO:root:current train perplexity2.783574104309082
INFO:root:current mean train loss 1297.4518287799976
INFO:root:current train perplexity2.78389835357666
INFO:root:current mean train loss 1299.002627516732
INFO:root:current train perplexity2.7852389812469482
INFO:root:current mean train loss 1299.099407275188
INFO:root:current train perplexity2.7853493690490723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.04s/it]
INFO:root:final mean train loss: 1299.0305151465682
INFO:root:final train perplexity: 2.785684108734131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2250.4798064536235
INFO:root:eval perplexity: 6.17220401763916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2816.807769558954
INFO:root:eval perplexity: 10.010785102844238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [24:15:53<10:55:37, 634.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.3951551649307
INFO:root:current train perplexity2.769523859024048
INFO:root:current mean train loss 1289.3718135439117
INFO:root:current train perplexity2.764195442199707
INFO:root:current mean train loss 1286.6663389867665
INFO:root:current train perplexity2.7575223445892334
INFO:root:current mean train loss 1285.6710074162138
INFO:root:current train perplexity2.7559566497802734
INFO:root:current mean train loss 1284.799133437939
INFO:root:current train perplexity2.757189989089966
INFO:root:current mean train loss 1286.849339252437
INFO:root:current train perplexity2.7595720291137695
INFO:root:current mean train loss 1288.1656244322312
INFO:root:current train perplexity2.760962724685669
INFO:root:current mean train loss 1288.5100292641046
INFO:root:current train perplexity2.7630090713500977
INFO:root:current mean train loss 1290.0956940238998
INFO:root:current train perplexity2.766322612762451
INFO:root:current mean train loss 1290.6687627883184
INFO:root:current train perplexity2.767211437225342
INFO:root:current mean train loss 1291.4561163651315
INFO:root:current train perplexity2.768808603286743
INFO:root:current mean train loss 1292.513249586347
INFO:root:current train perplexity2.769040584564209
INFO:root:current mean train loss 1293.2196299847828
INFO:root:current train perplexity2.771942377090454
INFO:root:current mean train loss 1293.853230098455
INFO:root:current train perplexity2.772951364517212
INFO:root:current mean train loss 1294.7075060992918
INFO:root:current train perplexity2.774242639541626
INFO:root:current mean train loss 1295.4048049087278
INFO:root:current train perplexity2.7752342224121094
INFO:root:current mean train loss 1295.8062804248195
INFO:root:current train perplexity2.7769763469696045
INFO:root:current mean train loss 1296.2526033505328
INFO:root:current train perplexity2.7773349285125732
INFO:root:current mean train loss 1296.6637376407944
INFO:root:current train perplexity2.7783305644989014
INFO:root:current mean train loss 1296.5944185938504
INFO:root:current train perplexity2.779715061187744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.50s/it]
INFO:root:final mean train loss: 1296.343892015235
INFO:root:final train perplexity: 2.7797882556915283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2255.5386828699857
INFO:root:eval perplexity: 6.197508335113525
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2818.9861199128713
INFO:root:eval perplexity: 10.028635025024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [24:26:28<10:45:00, 634.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1280.861322218372
INFO:root:current train perplexity2.757711172103882
INFO:root:current mean train loss 1287.205644018856
INFO:root:current train perplexity2.7577922344207764
INFO:root:current mean train loss 1289.2436644575978
INFO:root:current train perplexity2.7574381828308105
INFO:root:current mean train loss 1291.1573064814615
INFO:root:current train perplexity2.7575862407684326
INFO:root:current mean train loss 1293.1389527424074
INFO:root:current train perplexity2.763460397720337
INFO:root:current mean train loss 1292.271536287464
INFO:root:current train perplexity2.760110378265381
INFO:root:current mean train loss 1291.093505859375
INFO:root:current train perplexity2.7616238594055176
INFO:root:current mean train loss 1291.750364608965
INFO:root:current train perplexity2.764871120452881
INFO:root:current mean train loss 1293.2847271629387
INFO:root:current train perplexity2.7663726806640625
INFO:root:current mean train loss 1294.4398933141
INFO:root:current train perplexity2.7660865783691406
INFO:root:current mean train loss 1295.9249120450065
INFO:root:current train perplexity2.768674373626709
INFO:root:current mean train loss 1295.7764653059785
INFO:root:current train perplexity2.7704834938049316
INFO:root:current mean train loss 1295.0301415976935
INFO:root:current train perplexity2.769590377807617
INFO:root:current mean train loss 1294.2117144658878
INFO:root:current train perplexity2.7691168785095215
INFO:root:current mean train loss 1293.9496630291605
INFO:root:current train perplexity2.769324541091919
INFO:root:current mean train loss 1294.0040463729642
INFO:root:current train perplexity2.770562171936035
INFO:root:current mean train loss 1294.9120139662539
INFO:root:current train perplexity2.7719409465789795
INFO:root:current mean train loss 1295.3139854890128
INFO:root:current train perplexity2.7737555503845215
INFO:root:current mean train loss 1295.2389089746198
INFO:root:current train perplexity2.7756659984588623
INFO:root:current mean train loss 1295.4747743130217
INFO:root:current train perplexity2.7767088413238525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.50s/it]
INFO:root:final mean train loss: 1295.111653307262
INFO:root:final train perplexity: 2.777088165283203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.17s/it]
INFO:root:eval mean loss: 2258.217361341977
INFO:root:eval perplexity: 6.210947513580322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.50s/it]
INFO:root:eval mean loss: 2826.1269786645335
INFO:root:eval perplexity: 10.087371826171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [24:37:16<10:38:38, 638.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.368244412579
INFO:root:current train perplexity2.7667458057403564
INFO:root:current mean train loss 1287.4362486088075
INFO:root:current train perplexity2.763150691986084
INFO:root:current mean train loss 1283.6981288677475
INFO:root:current train perplexity2.7584025859832764
INFO:root:current mean train loss 1284.5953842605952
INFO:root:current train perplexity2.7569994926452637
INFO:root:current mean train loss 1286.783143236642
INFO:root:current train perplexity2.7617149353027344
INFO:root:current mean train loss 1286.2902241708496
INFO:root:current train perplexity2.760652780532837
INFO:root:current mean train loss 1288.478181055263
INFO:root:current train perplexity2.7633018493652344
INFO:root:current mean train loss 1289.2204911081415
INFO:root:current train perplexity2.7632720470428467
INFO:root:current mean train loss 1289.2392786436114
INFO:root:current train perplexity2.7654716968536377
INFO:root:current mean train loss 1290.635298544832
INFO:root:current train perplexity2.768418073654175
INFO:root:current mean train loss 1291.4890911678565
INFO:root:current train perplexity2.768527030944824
INFO:root:current mean train loss 1291.4311873393103
INFO:root:current train perplexity2.7682290077209473
INFO:root:current mean train loss 1291.4518461726996
INFO:root:current train perplexity2.768228769302368
INFO:root:current mean train loss 1291.5685946635356
INFO:root:current train perplexity2.767918825149536
INFO:root:current mean train loss 1293.2217103082478
INFO:root:current train perplexity2.7696332931518555
INFO:root:current mean train loss 1293.4611958654114
INFO:root:current train perplexity2.771366834640503
INFO:root:current mean train loss 1293.5777195288072
INFO:root:current train perplexity2.772005796432495
INFO:root:current mean train loss 1293.201509198022
INFO:root:current train perplexity2.771745443344116
INFO:root:current mean train loss 1293.254051707919
INFO:root:current train perplexity2.7721896171569824
INFO:root:current mean train loss 1293.4025910364492
INFO:root:current train perplexity2.772514820098877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.31s/it]
INFO:root:final mean train loss: 1293.1000545961474
INFO:root:final train perplexity: 2.7726857662200928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2258.4612205992353
INFO:root:eval perplexity: 6.212172508239746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2826.2466430664062
INFO:root:eval perplexity: 10.088359832763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [24:47:45<10:25:08, 635.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1282.5648829142253
INFO:root:current train perplexity2.7494571208953857
INFO:root:current mean train loss 1281.859280333227
INFO:root:current train perplexity2.755450487136841
INFO:root:current mean train loss 1280.9677569415119
INFO:root:current train perplexity2.7486815452575684
INFO:root:current mean train loss 1282.7185012354996
INFO:root:current train perplexity2.751887559890747
INFO:root:current mean train loss 1284.039438309208
INFO:root:current train perplexity2.7534971237182617
INFO:root:current mean train loss 1286.0057192808829
INFO:root:current train perplexity2.754906415939331
INFO:root:current mean train loss 1285.7891223074375
INFO:root:current train perplexity2.754629373550415
INFO:root:current mean train loss 1286.0154671980508
INFO:root:current train perplexity2.756862163543701
INFO:root:current mean train loss 1286.8702957970756
INFO:root:current train perplexity2.758741617202759
INFO:root:current mean train loss 1287.936184925248
INFO:root:current train perplexity2.760192632675171
INFO:root:current mean train loss 1288.7608861992828
INFO:root:current train perplexity2.7609927654266357
INFO:root:current mean train loss 1288.1717272091869
INFO:root:current train perplexity2.7608518600463867
INFO:root:current mean train loss 1288.2221641069577
INFO:root:current train perplexity2.7611770629882812
INFO:root:current mean train loss 1288.8776966521255
INFO:root:current train perplexity2.7613751888275146
INFO:root:current mean train loss 1288.9785650732683
INFO:root:current train perplexity2.761077404022217
INFO:root:current mean train loss 1290.267872516374
INFO:root:current train perplexity2.7634057998657227
INFO:root:current mean train loss 1290.4429585438854
INFO:root:current train perplexity2.7651240825653076
INFO:root:current mean train loss 1291.2867889744136
INFO:root:current train perplexity2.765793800354004
INFO:root:current mean train loss 1291.3950508858081
INFO:root:current train perplexity2.767347812652588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.64s/it]
INFO:root:final mean train loss: 1290.8138036530727
INFO:root:final train perplexity: 2.767690896987915
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2260.6522255755485
INFO:root:eval perplexity: 6.223191261291504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2828.899298052416
INFO:root:eval perplexity: 10.110269546508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [24:58:15<10:12:50, 633.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.7664982722356
INFO:root:current train perplexity2.74125075340271
INFO:root:current mean train loss 1296.9805746162888
INFO:root:current train perplexity2.753117561340332
INFO:root:current mean train loss 1290.014071898841
INFO:root:current train perplexity2.740614414215088
INFO:root:current mean train loss 1287.9500720721844
INFO:root:current train perplexity2.7433390617370605
INFO:root:current mean train loss 1287.0499619306145
INFO:root:current train perplexity2.7435731887817383
INFO:root:current mean train loss 1286.090169746741
INFO:root:current train perplexity2.745023727416992
INFO:root:current mean train loss 1286.6371727798735
INFO:root:current train perplexity2.748192071914673
INFO:root:current mean train loss 1285.5655411430027
INFO:root:current train perplexity2.7508041858673096
INFO:root:current mean train loss 1285.7222868859549
INFO:root:current train perplexity2.75158953666687
INFO:root:current mean train loss 1285.210019098054
INFO:root:current train perplexity2.751234292984009
INFO:root:current mean train loss 1285.4364870453635
INFO:root:current train perplexity2.752944231033325
INFO:root:current mean train loss 1285.8314854980908
INFO:root:current train perplexity2.753884792327881
INFO:root:current mean train loss 1285.8876452968814
INFO:root:current train perplexity2.7547054290771484
INFO:root:current mean train loss 1286.3358286315035
INFO:root:current train perplexity2.7550714015960693
INFO:root:current mean train loss 1286.804401805362
INFO:root:current train perplexity2.7554192543029785
INFO:root:current mean train loss 1287.463783117926
INFO:root:current train perplexity2.7557549476623535
INFO:root:current mean train loss 1287.5222488847935
INFO:root:current train perplexity2.7573273181915283
INFO:root:current mean train loss 1287.7021102415354
INFO:root:current train perplexity2.7582221031188965
INFO:root:current mean train loss 1287.9711485166808
INFO:root:current train perplexity2.7589104175567627
INFO:root:current mean train loss 1288.1398132611369
INFO:root:current train perplexity2.7600924968719482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.76s/it]
INFO:root:final mean train loss: 1287.984500671479
INFO:root:final train perplexity: 2.761522054672241
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2261.52295051737
INFO:root:eval perplexity: 6.227574348449707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2829.6190969047816
INFO:root:eval perplexity: 10.116222381591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [25:09:02<10:06:03, 637.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1276.7046142578124
INFO:root:current train perplexity2.7135491371154785
INFO:root:current mean train loss 1281.0807964618389
INFO:root:current train perplexity2.7321717739105225
INFO:root:current mean train loss 1286.0386485224185
INFO:root:current train perplexity2.733675003051758
INFO:root:current mean train loss 1284.7142337683476
INFO:root:current train perplexity2.736739158630371
INFO:root:current mean train loss 1286.3630209279615
INFO:root:current train perplexity2.7398691177368164
INFO:root:current mean train loss 1285.3764176278744
INFO:root:current train perplexity2.7441320419311523
INFO:root:current mean train loss 1285.3918300083706
INFO:root:current train perplexity2.7470412254333496
INFO:root:current mean train loss 1284.851399460884
INFO:root:current train perplexity2.7487235069274902
INFO:root:current mean train loss 1285.3882641895707
INFO:root:current train perplexity2.7498719692230225
INFO:root:current mean train loss 1285.0121642410115
INFO:root:current train perplexity2.749753952026367
INFO:root:current mean train loss 1285.4868116656553
INFO:root:current train perplexity2.752096652984619
INFO:root:current mean train loss 1286.7008252169178
INFO:root:current train perplexity2.7537004947662354
INFO:root:current mean train loss 1286.2831172788046
INFO:root:current train perplexity2.7536280155181885
INFO:root:current mean train loss 1286.791708947662
INFO:root:current train perplexity2.7546067237854004
INFO:root:current mean train loss 1286.841663365931
INFO:root:current train perplexity2.7559456825256348
INFO:root:current mean train loss 1286.0609747593699
INFO:root:current train perplexity2.7558324337005615
INFO:root:current mean train loss 1286.3421138084739
INFO:root:current train perplexity2.7569756507873535
INFO:root:current mean train loss 1286.5849630543262
INFO:root:current train perplexity2.75787353515625
INFO:root:current mean train loss 1286.7517767567451
INFO:root:current train perplexity2.757920026779175
INFO:root:current mean train loss 1287.1344545038253
INFO:root:current train perplexity2.758164644241333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.83s/it]
INFO:root:final mean train loss: 1286.5635537259577
INFO:root:final train perplexity: 2.758429765701294
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2266.0329689404643
INFO:root:eval perplexity: 6.250331401824951
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2834.4337015354886
INFO:root:eval perplexity: 10.156133651733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [25:19:33<9:53:19, 635.70s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.3000929812167
INFO:root:current train perplexity2.7284693717956543
INFO:root:current mean train loss 1273.558174392804
INFO:root:current train perplexity2.7314743995666504
INFO:root:current mean train loss 1274.4074336372407
INFO:root:current train perplexity2.730799913406372
INFO:root:current mean train loss 1275.661771307074
INFO:root:current train perplexity2.732227325439453
INFO:root:current mean train loss 1278.0370170712738
INFO:root:current train perplexity2.737422227859497
INFO:root:current mean train loss 1277.7492122336323
INFO:root:current train perplexity2.735215663909912
INFO:root:current mean train loss 1278.837995526227
INFO:root:current train perplexity2.740140438079834
INFO:root:current mean train loss 1280.4455420967724
INFO:root:current train perplexity2.7413110733032227
INFO:root:current mean train loss 1281.565955728398
INFO:root:current train perplexity2.7426819801330566
INFO:root:current mean train loss 1282.4709537107312
INFO:root:current train perplexity2.7449169158935547
INFO:root:current mean train loss 1282.6694521316485
INFO:root:current train perplexity2.746384382247925
INFO:root:current mean train loss 1282.6636713854416
INFO:root:current train perplexity2.7471516132354736
INFO:root:current mean train loss 1283.2223900838576
INFO:root:current train perplexity2.747833490371704
INFO:root:current mean train loss 1284.190568976342
INFO:root:current train perplexity2.7487244606018066
INFO:root:current mean train loss 1284.4691901955014
INFO:root:current train perplexity2.749886989593506
INFO:root:current mean train loss 1284.6147646370748
INFO:root:current train perplexity2.750168561935425
INFO:root:current mean train loss 1284.9408987725078
INFO:root:current train perplexity2.751103639602661
INFO:root:current mean train loss 1284.7270486151483
INFO:root:current train perplexity2.752192497253418
INFO:root:current mean train loss 1284.8908993442703
INFO:root:current train perplexity2.752880096435547
INFO:root:current mean train loss 1284.945692692283
INFO:root:current train perplexity2.7533631324768066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.86s/it]
INFO:root:final mean train loss: 1284.3536479140073
INFO:root:final train perplexity: 2.7536261081695557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2269.3546233481547
INFO:root:eval perplexity: 6.267144680023193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 2838.911549669631
INFO:root:eval perplexity: 10.193391799926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [25:30:14<9:44:16, 637.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1276.9803409576416
INFO:root:current train perplexity2.728306531906128
INFO:root:current mean train loss 1275.0104734839463
INFO:root:current train perplexity2.728592872619629
INFO:root:current mean train loss 1269.1625273733428
INFO:root:current train perplexity2.728470802307129
INFO:root:current mean train loss 1271.815661419879
INFO:root:current train perplexity2.7304108142852783
INFO:root:current mean train loss 1272.9482021989493
INFO:root:current train perplexity2.735630989074707
INFO:root:current mean train loss 1275.0462687607353
INFO:root:current train perplexity2.739394187927246
INFO:root:current mean train loss 1275.180868861187
INFO:root:current train perplexity2.7398722171783447
INFO:root:current mean train loss 1276.610409881432
INFO:root:current train perplexity2.7388675212860107
INFO:root:current mean train loss 1276.2304482636628
INFO:root:current train perplexity2.739604949951172
INFO:root:current mean train loss 1276.8133543655586
INFO:root:current train perplexity2.741352081298828
INFO:root:current mean train loss 1277.9974421450966
INFO:root:current train perplexity2.7442963123321533
INFO:root:current mean train loss 1278.0134446186707
INFO:root:current train perplexity2.744452714920044
INFO:root:current mean train loss 1278.6712410842315
INFO:root:current train perplexity2.7447197437286377
INFO:root:current mean train loss 1279.0153197347245
INFO:root:current train perplexity2.7452733516693115
INFO:root:current mean train loss 1279.8275562557367
INFO:root:current train perplexity2.7458512783050537
INFO:root:current mean train loss 1280.5668025102152
INFO:root:current train perplexity2.746885299682617
INFO:root:current mean train loss 1280.9043293732864
INFO:root:current train perplexity2.747314691543579
INFO:root:current mean train loss 1281.3941721667509
INFO:root:current train perplexity2.748624563217163
INFO:root:current mean train loss 1282.3346774383676
INFO:root:current train perplexity2.749904155731201
INFO:root:current mean train loss 1282.7551669181
INFO:root:current train perplexity2.749720573425293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.60s/it]
INFO:root:final mean train loss: 1282.5292761298183
INFO:root:final train perplexity: 2.749667167663574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 2270.7057434514904
INFO:root:eval perplexity: 6.273995399475098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2839.4875453651375
INFO:root:eval perplexity: 10.198198318481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [25:40:56<9:34:56, 638.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1289.952149944541
INFO:root:current train perplexity2.7471466064453125
INFO:root:current mean train loss 1284.4227369108253
INFO:root:current train perplexity2.7406232357025146
INFO:root:current mean train loss 1282.230536952986
INFO:root:current train perplexity2.739213228225708
INFO:root:current mean train loss 1280.62719053734
INFO:root:current train perplexity2.742690324783325
INFO:root:current mean train loss 1280.3287099731192
INFO:root:current train perplexity2.74106764793396
INFO:root:current mean train loss 1279.9321721876345
INFO:root:current train perplexity2.7415454387664795
INFO:root:current mean train loss 1279.294059854247
INFO:root:current train perplexity2.741877794265747
INFO:root:current mean train loss 1279.0838551148868
INFO:root:current train perplexity2.7420549392700195
INFO:root:current mean train loss 1280.2597994333498
INFO:root:current train perplexity2.742746114730835
INFO:root:current mean train loss 1279.5170204092603
INFO:root:current train perplexity2.743426561355591
INFO:root:current mean train loss 1279.8063670113393
INFO:root:current train perplexity2.7439866065979004
INFO:root:current mean train loss 1279.8981091194896
INFO:root:current train perplexity2.743934154510498
INFO:root:current mean train loss 1279.3709226990936
INFO:root:current train perplexity2.744748115539551
INFO:root:current mean train loss 1279.2619865798674
INFO:root:current train perplexity2.7443430423736572
INFO:root:current mean train loss 1279.7713741737793
INFO:root:current train perplexity2.744314432144165
INFO:root:current mean train loss 1279.8100890920255
INFO:root:current train perplexity2.744319200515747
INFO:root:current mean train loss 1280.4152547369963
INFO:root:current train perplexity2.7449498176574707
INFO:root:current mean train loss 1280.9122077989016
INFO:root:current train perplexity2.7452311515808105
INFO:root:current mean train loss 1280.73034440831
INFO:root:current train perplexity2.745086908340454
INFO:root:current mean train loss 1280.9240425645191
INFO:root:current train perplexity2.745304822921753

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.96s/it]
INFO:root:final mean train loss: 1280.5702396764095
INFO:root:final train perplexity: 2.7454216480255127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 2270.0356912815823
INFO:root:eval perplexity: 6.270596981048584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2841.2190131870566
INFO:root:eval perplexity: 10.212648391723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [25:51:28<9:22:28, 636.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1266.533053651148
INFO:root:current train perplexity2.729060173034668
INFO:root:current mean train loss 1271.1742559876104
INFO:root:current train perplexity2.7249865531921387
INFO:root:current mean train loss 1270.1033513625996
INFO:root:current train perplexity2.7315194606781006
INFO:root:current mean train loss 1269.5761451912886
INFO:root:current train perplexity2.728986978530884
INFO:root:current mean train loss 1273.7001480041258
INFO:root:current train perplexity2.7310807704925537
INFO:root:current mean train loss 1274.645575175716
INFO:root:current train perplexity2.731577157974243
INFO:root:current mean train loss 1274.8745865698872
INFO:root:current train perplexity2.7315826416015625
INFO:root:current mean train loss 1274.8041415489406
INFO:root:current train perplexity2.7317893505096436
INFO:root:current mean train loss 1274.781188285165
INFO:root:current train perplexity2.732525110244751
INFO:root:current mean train loss 1275.2110868465447
INFO:root:current train perplexity2.7335000038146973
INFO:root:current mean train loss 1276.1847623119806
INFO:root:current train perplexity2.73469877243042
INFO:root:current mean train loss 1276.5633749730996
INFO:root:current train perplexity2.735960006713867
INFO:root:current mean train loss 1276.8719278344388
INFO:root:current train perplexity2.7372403144836426
INFO:root:current mean train loss 1276.7532596615422
INFO:root:current train perplexity2.7374677658081055
INFO:root:current mean train loss 1277.0588364238256
INFO:root:current train perplexity2.736771583557129
INFO:root:current mean train loss 1277.5933041912742
INFO:root:current train perplexity2.7375266551971436
INFO:root:current mean train loss 1277.7662296003111
INFO:root:current train perplexity2.7379512786865234
INFO:root:current mean train loss 1278.0705533139035
INFO:root:current train perplexity2.739211082458496
INFO:root:current mean train loss 1278.447316691295
INFO:root:current train perplexity2.7398011684417725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.49s/it]
INFO:root:final mean train loss: 1278.5673208539677
INFO:root:final train perplexity: 2.741088628768921
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 2272.9453930144614
INFO:root:eval perplexity: 6.285369396209717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2844.6137712627437
INFO:root:eval perplexity: 10.241042137145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [26:02:19<9:15:27, 640.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.8559488932292
INFO:root:current train perplexity2.7246527671813965
INFO:root:current mean train loss 1279.9171577785326
INFO:root:current train perplexity2.732154369354248
INFO:root:current mean train loss 1266.8872217932412
INFO:root:current train perplexity2.729151964187622
INFO:root:current mean train loss 1269.8289729042658
INFO:root:current train perplexity2.7331643104553223
INFO:root:current mean train loss 1270.736703748588
INFO:root:current train perplexity2.730130434036255
INFO:root:current mean train loss 1271.5587895365595
INFO:root:current train perplexity2.7308616638183594
INFO:root:current mean train loss 1272.602579554116
INFO:root:current train perplexity2.7303988933563232
INFO:root:current mean train loss 1273.7562298541302
INFO:root:current train perplexity2.7299726009368896
INFO:root:current mean train loss 1274.45397559792
INFO:root:current train perplexity2.7286336421966553
INFO:root:current mean train loss 1274.8351750608351
INFO:root:current train perplexity2.72990083694458
INFO:root:current mean train loss 1275.2599824651709
INFO:root:current train perplexity2.7308740615844727
INFO:root:current mean train loss 1275.3966748703756
INFO:root:current train perplexity2.733131170272827
INFO:root:current mean train loss 1275.6397811575682
INFO:root:current train perplexity2.73244047164917
INFO:root:current mean train loss 1276.399643071976
INFO:root:current train perplexity2.733153820037842
INFO:root:current mean train loss 1275.9051022802562
INFO:root:current train perplexity2.7340030670166016
INFO:root:current mean train loss 1275.5233253403464
INFO:root:current train perplexity2.733973979949951
INFO:root:current mean train loss 1275.6808022324883
INFO:root:current train perplexity2.73486590385437
INFO:root:current mean train loss 1276.1264237028518
INFO:root:current train perplexity2.735529899597168
INFO:root:current mean train loss 1276.1207676238594
INFO:root:current train perplexity2.7356746196746826
INFO:root:current mean train loss 1276.5818968770398
INFO:root:current train perplexity2.7368903160095215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.90s/it]
INFO:root:final mean train loss: 1276.8208787449669
INFO:root:final train perplexity: 2.7373154163360596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it]
INFO:root:eval mean loss: 2275.7921835175644
INFO:root:eval perplexity: 6.2998576164245605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2848.131554136885
INFO:root:eval perplexity: 10.270547866821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [26:12:55<9:03:29, 639.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.7307052612305
INFO:root:current train perplexity2.7294762134552
INFO:root:current mean train loss 1267.4314991344106
INFO:root:current train perplexity2.7128543853759766
INFO:root:current mean train loss 1268.037887047077
INFO:root:current train perplexity2.7230417728424072
INFO:root:current mean train loss 1265.815070462514
INFO:root:current train perplexity2.722649335861206
INFO:root:current mean train loss 1268.8269721137153
INFO:root:current train perplexity2.721850633621216
INFO:root:current mean train loss 1269.10361956833
INFO:root:current train perplexity2.7207255363464355
INFO:root:current mean train loss 1270.4502211944966
INFO:root:current train perplexity2.7229981422424316
INFO:root:current mean train loss 1270.8345160145577
INFO:root:current train perplexity2.7251508235931396
INFO:root:current mean train loss 1271.5530358828032
INFO:root:current train perplexity2.7254223823547363
INFO:root:current mean train loss 1272.111821252389
INFO:root:current train perplexity2.7271246910095215
INFO:root:current mean train loss 1272.6760594567588
INFO:root:current train perplexity2.7260546684265137
INFO:root:current mean train loss 1273.0758458868775
INFO:root:current train perplexity2.7279086112976074
INFO:root:current mean train loss 1272.7066886208274
INFO:root:current train perplexity2.7273812294006348
INFO:root:current mean train loss 1272.6867640956386
INFO:root:current train perplexity2.727114677429199
INFO:root:current mean train loss 1273.2035534395186
INFO:root:current train perplexity2.727576732635498
INFO:root:current mean train loss 1273.5752737976552
INFO:root:current train perplexity2.729768991470337
INFO:root:current mean train loss 1274.0182446498497
INFO:root:current train perplexity2.730372428894043
INFO:root:current mean train loss 1274.6178667099316
INFO:root:current train perplexity2.7313709259033203
INFO:root:current mean train loss 1274.6258538924972
INFO:root:current train perplexity2.73060941696167
INFO:root:current mean train loss 1274.7239767828837
INFO:root:current train perplexity2.731776237487793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.83s/it]
INFO:root:final mean train loss: 1274.4494150905252
INFO:root:final train perplexity: 2.732201099395752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 2278.5596348106437
INFO:root:eval perplexity: 6.313973426818848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2851.9829971638133
INFO:root:eval perplexity: 10.302946090698242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [26:23:33<8:52:31, 639.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.4268076371172
INFO:root:current train perplexity2.702958106994629
INFO:root:current mean train loss 1264.0022849268562
INFO:root:current train perplexity2.7090964317321777
INFO:root:current mean train loss 1263.0576608190574
INFO:root:current train perplexity2.709160804748535
INFO:root:current mean train loss 1263.9701609789129
INFO:root:current train perplexity2.710615396499634
INFO:root:current mean train loss 1265.5648073735906
INFO:root:current train perplexity2.709184408187866
INFO:root:current mean train loss 1265.3841710603085
INFO:root:current train perplexity2.7115955352783203
INFO:root:current mean train loss 1267.4645038716415
INFO:root:current train perplexity2.7162599563598633
INFO:root:current mean train loss 1268.1356290809622
INFO:root:current train perplexity2.7174110412597656
INFO:root:current mean train loss 1269.4980527700327
INFO:root:current train perplexity2.7168400287628174
INFO:root:current mean train loss 1269.5514959208706
INFO:root:current train perplexity2.719709873199463
INFO:root:current mean train loss 1270.3028332880274
INFO:root:current train perplexity2.7206239700317383
INFO:root:current mean train loss 1270.8788118022126
INFO:root:current train perplexity2.721567392349243
INFO:root:current mean train loss 1270.696289746641
INFO:root:current train perplexity2.7219884395599365
INFO:root:current mean train loss 1271.0559222289949
INFO:root:current train perplexity2.722933292388916
INFO:root:current mean train loss 1271.0995070179056
INFO:root:current train perplexity2.723318338394165
INFO:root:current mean train loss 1271.9294571504045
INFO:root:current train perplexity2.724921464920044
INFO:root:current mean train loss 1271.895914294056
INFO:root:current train perplexity2.7250988483428955
INFO:root:current mean train loss 1272.4228247614708
INFO:root:current train perplexity2.7262802124023438
INFO:root:current mean train loss 1272.4931781907028
INFO:root:current train perplexity2.7268595695495605
INFO:root:current mean train loss 1272.8756459266972
INFO:root:current train perplexity2.72751784324646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.78s/it]
INFO:root:final mean train loss: 1272.585836605778
INFO:root:final train perplexity: 2.7281887531280518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2278.278903825909
INFO:root:eval perplexity: 6.312540054321289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2851.93030131455
INFO:root:eval perplexity: 10.30250358581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [26:34:02<8:39:25, 636.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1268.2700324781013
INFO:root:current train perplexity2.72420597076416
INFO:root:current mean train loss 1263.8952533767883
INFO:root:current train perplexity2.7115259170532227
INFO:root:current mean train loss 1264.0948587288533
INFO:root:current train perplexity2.707627296447754
INFO:root:current mean train loss 1265.735304201887
INFO:root:current train perplexity2.7114546298980713
INFO:root:current mean train loss 1264.2298447768576
INFO:root:current train perplexity2.7119007110595703
INFO:root:current mean train loss 1264.5733666302037
INFO:root:current train perplexity2.714603900909424
INFO:root:current mean train loss 1265.5819801124367
INFO:root:current train perplexity2.7165019512176514
INFO:root:current mean train loss 1265.5072204749204
INFO:root:current train perplexity2.7145726680755615
INFO:root:current mean train loss 1265.6918511159427
INFO:root:current train perplexity2.716055393218994
INFO:root:current mean train loss 1266.2282199267274
INFO:root:current train perplexity2.7164714336395264
INFO:root:current mean train loss 1267.039975279044
INFO:root:current train perplexity2.717942953109741
INFO:root:current mean train loss 1267.5452297727609
INFO:root:current train perplexity2.7195680141448975
INFO:root:current mean train loss 1268.7809485846785
INFO:root:current train perplexity2.7223007678985596
INFO:root:current mean train loss 1268.6268111266643
INFO:root:current train perplexity2.7224135398864746
INFO:root:current mean train loss 1270.0694703314184
INFO:root:current train perplexity2.72365403175354
INFO:root:current mean train loss 1270.4663096850554
INFO:root:current train perplexity2.7239878177642822
INFO:root:current mean train loss 1270.459594360205
INFO:root:current train perplexity2.724384307861328
INFO:root:current mean train loss 1270.77737015479
INFO:root:current train perplexity2.7248048782348633
INFO:root:current mean train loss 1271.0406114061034
INFO:root:current train perplexity2.725031852722168
INFO:root:current mean train loss 1271.2208040223845
INFO:root:current train perplexity2.724271535873413

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.37s/it]
INFO:root:final mean train loss: 1270.879580745418
INFO:root:final train perplexity: 2.7245194911956787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2282.322614953873
INFO:root:eval perplexity: 6.333219051361084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 2856.4470530841368
INFO:root:eval perplexity: 10.340629577636719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [26:44:32<8:27:30, 634.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1259.5886362834149
INFO:root:current train perplexity2.7052674293518066
INFO:root:current mean train loss 1264.0647106066428
INFO:root:current train perplexity2.711676836013794
INFO:root:current mean train loss 1262.388708970572
INFO:root:current train perplexity2.7068350315093994
INFO:root:current mean train loss 1264.9083577048996
INFO:root:current train perplexity2.7093148231506348
INFO:root:current mean train loss 1265.99435393213
INFO:root:current train perplexity2.7076499462127686
INFO:root:current mean train loss 1266.3262625378566
INFO:root:current train perplexity2.709616184234619
INFO:root:current mean train loss 1266.1005686010135
INFO:root:current train perplexity2.7102878093719482
INFO:root:current mean train loss 1267.3555864550906
INFO:root:current train perplexity2.7142868041992188
INFO:root:current mean train loss 1267.0418426064375
INFO:root:current train perplexity2.712766408920288
INFO:root:current mean train loss 1267.776684967693
INFO:root:current train perplexity2.714743137359619
INFO:root:current mean train loss 1267.505130785434
INFO:root:current train perplexity2.715718984603882
INFO:root:current mean train loss 1268.0338070789637
INFO:root:current train perplexity2.716318130493164
INFO:root:current mean train loss 1268.1661303691908
INFO:root:current train perplexity2.7174339294433594
INFO:root:current mean train loss 1268.3543175113261
INFO:root:current train perplexity2.7176945209503174
INFO:root:current mean train loss 1268.040740370027
INFO:root:current train perplexity2.7170069217681885
INFO:root:current mean train loss 1268.0794447165686
INFO:root:current train perplexity2.7173423767089844
INFO:root:current mean train loss 1268.0298083662915
INFO:root:current train perplexity2.7171902656555176
INFO:root:current mean train loss 1267.9967922824724
INFO:root:current train perplexity2.7181777954101562
INFO:root:current mean train loss 1268.467727863719
INFO:root:current train perplexity2.7188613414764404
INFO:root:current mean train loss 1268.6324607860663
INFO:root:current train perplexity2.7196953296661377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.39s/it]
INFO:root:final mean train loss: 1268.6324607860663
INFO:root:final train perplexity: 2.7196953296661377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2282.5917973078735
INFO:root:eval perplexity: 6.334597110748291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2855.8939931883033
INFO:root:eval perplexity: 10.335956573486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [26:55:01<8:15:38, 632.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.3911779785155
INFO:root:current train perplexity2.725735902786255
INFO:root:current mean train loss 1263.6733404541017
INFO:root:current train perplexity2.7168595790863037
INFO:root:current mean train loss 1267.932384033203
INFO:root:current train perplexity2.716231346130371
INFO:root:current mean train loss 1267.3713540649414
INFO:root:current train perplexity2.713871955871582
INFO:root:current mean train loss 1267.1664968261719
INFO:root:current train perplexity2.713550090789795
INFO:root:current mean train loss 1266.2026155598958
INFO:root:current train perplexity2.710982322692871
INFO:root:current mean train loss 1266.8407503836495
INFO:root:current train perplexity2.7123258113861084
INFO:root:current mean train loss 1266.2121510314942
INFO:root:current train perplexity2.7103991508483887
INFO:root:current mean train loss 1266.4297055392794
INFO:root:current train perplexity2.712400197982788
INFO:root:current mean train loss 1267.1575819091797
INFO:root:current train perplexity2.7138404846191406
INFO:root:current mean train loss 1268.251289950284
INFO:root:current train perplexity2.7143301963806152
INFO:root:current mean train loss 1267.0697101847331
INFO:root:current train perplexity2.7140133380889893
INFO:root:current mean train loss 1267.1399801870493
INFO:root:current train perplexity2.713865041732788
INFO:root:current mean train loss 1267.4053681291853
INFO:root:current train perplexity2.71506667137146
INFO:root:current mean train loss 1267.5891158854167
INFO:root:current train perplexity2.713925838470459
INFO:root:current mean train loss 1268.032833557129
INFO:root:current train perplexity2.7144172191619873
INFO:root:current mean train loss 1267.3653304515165
INFO:root:current train perplexity2.71547794342041
INFO:root:current mean train loss 1267.506023627387
INFO:root:current train perplexity2.7157678604125977
INFO:root:current mean train loss 1267.433517680921
INFO:root:current train perplexity2.716078281402588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.71s/it]
INFO:root:final mean train loss: 1266.9520096540812
INFO:root:final train perplexity: 2.7160933017730713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2285.4152459760085
INFO:root:eval perplexity: 6.349079132080078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 2860.0977311371066
INFO:root:eval perplexity: 10.371550559997559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [27:05:26<8:03:14, 630.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1238.8058220358455
INFO:root:current train perplexity2.64933705329895
INFO:root:current mean train loss 1254.8215874565972
INFO:root:current train perplexity2.698904275894165
INFO:root:current mean train loss 1256.3102211666546
INFO:root:current train perplexity2.7016382217407227
INFO:root:current mean train loss 1259.1159548593996
INFO:root:current train perplexity2.7040369510650635
INFO:root:current mean train loss 1261.8960180488423
INFO:root:current train perplexity2.705752372741699
INFO:root:current mean train loss 1261.7248065291797
INFO:root:current train perplexity2.7020955085754395
INFO:root:current mean train loss 1261.2971169643308
INFO:root:current train perplexity2.70151948928833
INFO:root:current mean train loss 1262.733801252506
INFO:root:current train perplexity2.703653573989868
INFO:root:current mean train loss 1262.867750039445
INFO:root:current train perplexity2.70548939704895
INFO:root:current mean train loss 1263.4639049933546
INFO:root:current train perplexity2.7065601348876953
INFO:root:current mean train loss 1263.54139263862
INFO:root:current train perplexity2.7060797214508057
INFO:root:current mean train loss 1264.5519187879434
INFO:root:current train perplexity2.708024263381958
INFO:root:current mean train loss 1264.6748277574852
INFO:root:current train perplexity2.707528829574585
INFO:root:current mean train loss 1264.5719568807244
INFO:root:current train perplexity2.7087693214416504
INFO:root:current mean train loss 1265.7269911675194
INFO:root:current train perplexity2.709535598754883
INFO:root:current mean train loss 1266.1916536093545
INFO:root:current train perplexity2.710742950439453
INFO:root:current mean train loss 1266.4123323779086
INFO:root:current train perplexity2.711994171142578
INFO:root:current mean train loss 1266.0526196274843
INFO:root:current train perplexity2.7123022079467773
INFO:root:current mean train loss 1266.5160690080877
INFO:root:current train perplexity2.713742733001709
INFO:root:current mean train loss 1266.6576700782675
INFO:root:current train perplexity2.7137820720672607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.80s/it]
INFO:root:final mean train loss: 1266.0268102541033
INFO:root:final train perplexity: 2.7141120433807373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2287.6534839386636
INFO:root:eval perplexity: 6.360580921173096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2861.582711294188
INFO:root:eval perplexity: 10.384154319763184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [27:15:58<7:53:09, 630.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1263.3732371610754
INFO:root:current train perplexity2.686492919921875
INFO:root:current mean train loss 1260.00122252507
INFO:root:current train perplexity2.7045912742614746
INFO:root:current mean train loss 1257.9316077599158
INFO:root:current train perplexity2.702636241912842
INFO:root:current mean train loss 1258.3533730878087
INFO:root:current train perplexity2.6992554664611816
INFO:root:current mean train loss 1259.2200860230055
INFO:root:current train perplexity2.7014803886413574
INFO:root:current mean train loss 1260.4684253935511
INFO:root:current train perplexity2.702989339828491
INFO:root:current mean train loss 1260.9974089902282
INFO:root:current train perplexity2.702448844909668
INFO:root:current mean train loss 1262.1332547138431
INFO:root:current train perplexity2.7024412155151367
INFO:root:current mean train loss 1263.1991039980517
INFO:root:current train perplexity2.7026705741882324
INFO:root:current mean train loss 1262.8597307552361
INFO:root:current train perplexity2.7020068168640137
INFO:root:current mean train loss 1261.8597736764461
INFO:root:current train perplexity2.7030258178710938
INFO:root:current mean train loss 1261.6831925541846
INFO:root:current train perplexity2.7035131454467773
INFO:root:current mean train loss 1261.8281134260724
INFO:root:current train perplexity2.7037746906280518
INFO:root:current mean train loss 1262.4048539694995
INFO:root:current train perplexity2.705246925354004
INFO:root:current mean train loss 1262.4553227763795
INFO:root:current train perplexity2.7061829566955566
INFO:root:current mean train loss 1262.8306080247464
INFO:root:current train perplexity2.706496238708496
INFO:root:current mean train loss 1263.5066662044828
INFO:root:current train perplexity2.707371234893799
INFO:root:current mean train loss 1264.0140524471508
INFO:root:current train perplexity2.7087056636810303
INFO:root:current mean train loss 1264.2949309936657
INFO:root:current train perplexity2.7089016437530518
INFO:root:current mean train loss 1264.6966008025586
INFO:root:current train perplexity2.710334300994873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.99s/it]
INFO:root:final mean train loss: 1264.3535584080898
INFO:root:final train perplexity: 2.7105329036712646
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2286.789219200188
INFO:root:eval perplexity: 6.356137752532959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2861.8983102352063
INFO:root:eval perplexity: 10.386836051940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [27:26:20<7:40:37, 628.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1253.7501148897059
INFO:root:current train perplexity2.7102930545806885
INFO:root:current mean train loss 1257.5363607848717
INFO:root:current train perplexity2.7037549018859863
INFO:root:current mean train loss 1257.2338949864604
INFO:root:current train perplexity2.6989428997039795
INFO:root:current mean train loss 1258.0699574179798
INFO:root:current train perplexity2.695587635040283
INFO:root:current mean train loss 1261.1185762866373
INFO:root:current train perplexity2.699282169342041
INFO:root:current mean train loss 1260.8178345391193
INFO:root:current train perplexity2.7006616592407227
INFO:root:current mean train loss 1261.7037959179388
INFO:root:current train perplexity2.701072931289673
INFO:root:current mean train loss 1260.8186807238785
INFO:root:current train perplexity2.7012526988983154
INFO:root:current mean train loss 1260.5324979573663
INFO:root:current train perplexity2.7017698287963867
INFO:root:current mean train loss 1260.924228993124
INFO:root:current train perplexity2.7006444931030273
INFO:root:current mean train loss 1261.4682715912302
INFO:root:current train perplexity2.701197385787964
INFO:root:current mean train loss 1261.797196455358
INFO:root:current train perplexity2.702120304107666
INFO:root:current mean train loss 1262.1521653770733
INFO:root:current train perplexity2.702850341796875
INFO:root:current mean train loss 1262.268861805925
INFO:root:current train perplexity2.703928232192993
INFO:root:current mean train loss 1263.062951096496
INFO:root:current train perplexity2.7048704624176025
INFO:root:current mean train loss 1263.0321417980083
INFO:root:current train perplexity2.704646348953247
INFO:root:current mean train loss 1262.9619321031762
INFO:root:current train perplexity2.7047736644744873
INFO:root:current mean train loss 1263.0787460179006
INFO:root:current train perplexity2.7056519985198975
INFO:root:current mean train loss 1262.7451330810416
INFO:root:current train perplexity2.706031084060669
INFO:root:current mean train loss 1262.8151592682839
INFO:root:current train perplexity2.705688714981079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.61s/it]
INFO:root:final mean train loss: 1262.370353387091
INFO:root:final train perplexity: 2.706296920776367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2289.495843116273
INFO:root:eval perplexity: 6.3700666427612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.37s/it]
INFO:root:eval mean loss: 2865.594154303801
INFO:root:eval perplexity: 10.41827392578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [27:36:40<7:28:29, 625.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.1697782628676
INFO:root:current train perplexity2.6775426864624023
INFO:root:current mean train loss 1251.5027276901972
INFO:root:current train perplexity2.6871566772460938
INFO:root:current mean train loss 1252.1671898685283
INFO:root:current train perplexity2.6909947395324707
INFO:root:current mean train loss 1254.4967601610267
INFO:root:current train perplexity2.695753812789917
INFO:root:current mean train loss 1255.7613707974426
INFO:root:current train perplexity2.696711540222168
INFO:root:current mean train loss 1255.1412555533395
INFO:root:current train perplexity2.695315361022949
INFO:root:current mean train loss 1255.339664664811
INFO:root:current train perplexity2.699054479598999
INFO:root:current mean train loss 1256.330069700877
INFO:root:current train perplexity2.7002978324890137
INFO:root:current mean train loss 1257.4232295866937
INFO:root:current train perplexity2.7017877101898193
INFO:root:current mean train loss 1257.90965069227
INFO:root:current train perplexity2.703237533569336
INFO:root:current mean train loss 1258.6697391124253
INFO:root:current train perplexity2.702798843383789
INFO:root:current mean train loss 1259.118676172544
INFO:root:current train perplexity2.703159809112549
INFO:root:current mean train loss 1259.874272776703
INFO:root:current train perplexity2.70198392868042
INFO:root:current mean train loss 1260.0121335035178
INFO:root:current train perplexity2.702385425567627
INFO:root:current mean train loss 1259.6117987775672
INFO:root:current train perplexity2.7017128467559814
INFO:root:current mean train loss 1259.9651024487555
INFO:root:current train perplexity2.7018256187438965
INFO:root:current mean train loss 1260.281785557882
INFO:root:current train perplexity2.7031164169311523
INFO:root:current mean train loss 1260.339596571426
INFO:root:current train perplexity2.7026162147521973
INFO:root:current mean train loss 1260.4733072481013
INFO:root:current train perplexity2.7027719020843506
INFO:root:current mean train loss 1261.3341185406941
INFO:root:current train perplexity2.703416347503662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.88s/it]
INFO:root:final mean train loss: 1261.0066539093034
INFO:root:final train perplexity: 2.70338773727417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2290.090800833195
INFO:root:eval perplexity: 6.373130798339844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2866.8878095910904
INFO:root:eval perplexity: 10.429306030273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [27:47:07<7:18:10, 625.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1247.9876278147979
INFO:root:current train perplexity2.685866355895996
INFO:root:current mean train loss 1249.9819428315034
INFO:root:current train perplexity2.691992998123169
INFO:root:current mean train loss 1252.9151200143915
INFO:root:current train perplexity2.6934211254119873
INFO:root:current mean train loss 1253.5616157036322
INFO:root:current train perplexity2.6933860778808594
INFO:root:current mean train loss 1254.524955450628
INFO:root:current train perplexity2.6942155361175537
INFO:root:current mean train loss 1252.9461784688835
INFO:root:current train perplexity2.6949965953826904
INFO:root:current mean train loss 1253.9447404624773
INFO:root:current train perplexity2.694355010986328
INFO:root:current mean train loss 1254.4055227097433
INFO:root:current train perplexity2.69474196434021
INFO:root:current mean train loss 1254.7268972623147
INFO:root:current train perplexity2.693488597869873
INFO:root:current mean train loss 1256.1234845931156
INFO:root:current train perplexity2.6939022541046143
INFO:root:current mean train loss 1255.4497096189157
INFO:root:current train perplexity2.693722724914551
INFO:root:current mean train loss 1255.5798348084784
INFO:root:current train perplexity2.6942694187164307
INFO:root:current mean train loss 1255.973161535597
INFO:root:current train perplexity2.69515061378479
INFO:root:current mean train loss 1256.851526804349
INFO:root:current train perplexity2.6952478885650635
INFO:root:current mean train loss 1257.3278159196127
INFO:root:current train perplexity2.6954736709594727
INFO:root:current mean train loss 1257.567318273117
INFO:root:current train perplexity2.6965715885162354
INFO:root:current mean train loss 1258.3534959923265
INFO:root:current train perplexity2.6969704627990723
INFO:root:current mean train loss 1258.961967472536
INFO:root:current train perplexity2.697469711303711
INFO:root:current mean train loss 1259.3286314137101
INFO:root:current train perplexity2.6982483863830566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.06s/it]
INFO:root:final mean train loss: 1259.0206450261796
INFO:root:final train perplexity: 2.6991569995880127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 2292.3291859728224
INFO:root:eval perplexity: 6.384677886962891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 2871.3759185574577
INFO:root:eval perplexity: 10.467657089233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [27:57:27<7:06:39, 624.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1162.0153198242188
INFO:root:current train perplexity2.6378462314605713
INFO:root:current mean train loss 1243.9483810125612
INFO:root:current train perplexity2.6868045330047607
INFO:root:current mean train loss 1246.0441815971149
INFO:root:current train perplexity2.68188738822937
INFO:root:current mean train loss 1251.0331497697641
INFO:root:current train perplexity2.682821750640869
INFO:root:current mean train loss 1250.6998594673119
INFO:root:current train perplexity2.6817424297332764
INFO:root:current mean train loss 1251.7376388002676
INFO:root:current train perplexity2.682664155960083
INFO:root:current mean train loss 1253.1395022370095
INFO:root:current train perplexity2.684474229812622
INFO:root:current mean train loss 1253.4676285876847
INFO:root:current train perplexity2.684701442718506
INFO:root:current mean train loss 1254.6714346640722
INFO:root:current train perplexity2.6873230934143066
INFO:root:current mean train loss 1254.5232242152854
INFO:root:current train perplexity2.6896321773529053
INFO:root:current mean train loss 1254.5082215939215
INFO:root:current train perplexity2.691145181655884
INFO:root:current mean train loss 1255.9181789945128
INFO:root:current train perplexity2.693113327026367
INFO:root:current mean train loss 1255.9768623948692
INFO:root:current train perplexity2.6927497386932373
INFO:root:current mean train loss 1256.0396178167903
INFO:root:current train perplexity2.6919209957122803
INFO:root:current mean train loss 1257.1830765619427
INFO:root:current train perplexity2.6923656463623047
INFO:root:current mean train loss 1257.4959696478913
INFO:root:current train perplexity2.69404935836792
INFO:root:current mean train loss 1257.9130566772003
INFO:root:current train perplexity2.6950645446777344
INFO:root:current mean train loss 1257.779836365535
INFO:root:current train perplexity2.695652723312378
INFO:root:current mean train loss 1257.8814200042486
INFO:root:current train perplexity2.696204662322998
INFO:root:current mean train loss 1258.02911723525
INFO:root:current train perplexity2.69653582572937

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.13s/it]
INFO:root:final mean train loss: 1257.9077554415167
INFO:root:final train perplexity: 2.6967885494232178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2294.6347305622508
INFO:root:eval perplexity: 6.396595001220703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2871.79551058289
INFO:root:eval perplexity: 10.471248626708984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [28:08:01<6:58:04, 627.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.0205656352796
INFO:root:current train perplexity2.706033706665039
INFO:root:current mean train loss 1254.3325420988708
INFO:root:current train perplexity2.6767096519470215
INFO:root:current mean train loss 1255.923314760809
INFO:root:current train perplexity2.679558515548706
INFO:root:current mean train loss 1252.5569888506564
INFO:root:current train perplexity2.6846096515655518
INFO:root:current mean train loss 1253.043226292139
INFO:root:current train perplexity2.685502529144287
INFO:root:current mean train loss 1251.672931296288
INFO:root:current train perplexity2.685793876647949
INFO:root:current mean train loss 1252.0440163065427
INFO:root:current train perplexity2.686234474182129
INFO:root:current mean train loss 1252.695891951984
INFO:root:current train perplexity2.685793399810791
INFO:root:current mean train loss 1253.0254386184563
INFO:root:current train perplexity2.6873998641967773
INFO:root:current mean train loss 1253.638853585759
INFO:root:current train perplexity2.6891088485717773
INFO:root:current mean train loss 1254.378167958208
INFO:root:current train perplexity2.690000534057617
INFO:root:current mean train loss 1254.492058993451
INFO:root:current train perplexity2.6911051273345947
INFO:root:current mean train loss 1255.5057615384985
INFO:root:current train perplexity2.691746234893799
INFO:root:current mean train loss 1256.7214786740665
INFO:root:current train perplexity2.692749500274658
INFO:root:current mean train loss 1256.798385179236
INFO:root:current train perplexity2.6921608448028564
INFO:root:current mean train loss 1256.424141939727
INFO:root:current train perplexity2.6938490867614746
INFO:root:current mean train loss 1256.0349621740368
INFO:root:current train perplexity2.6940693855285645
INFO:root:current mean train loss 1256.272683845418
INFO:root:current train perplexity2.694131851196289
INFO:root:current mean train loss 1256.469508661288
INFO:root:current train perplexity2.6931443214416504
INFO:root:current mean train loss 1256.8515244603716
INFO:root:current train perplexity2.693608283996582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.95s/it]
INFO:root:final mean train loss: 1256.3556986090755
INFO:root:final train perplexity: 2.6934900283813477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2297.304055504765
INFO:root:eval perplexity: 6.410419464111328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.60s/it]
INFO:root:eval mean loss: 2874.9895564951794
INFO:root:eval perplexity: 10.498636245727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [28:18:23<6:46:44, 625.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1254.1725667317708
INFO:root:current train perplexity2.673952341079712
INFO:root:current mean train loss 1251.2001136330998
INFO:root:current train perplexity2.665252447128296
INFO:root:current mean train loss 1251.5457965398239
INFO:root:current train perplexity2.6794912815093994
INFO:root:current mean train loss 1251.8982718331474
INFO:root:current train perplexity2.6803014278411865
INFO:root:current mean train loss 1253.5640233591062
INFO:root:current train perplexity2.6825926303863525
INFO:root:current mean train loss 1252.5230175416862
INFO:root:current train perplexity2.6836864948272705
INFO:root:current mean train loss 1253.4954837823063
INFO:root:current train perplexity2.682460069656372
INFO:root:current mean train loss 1253.44408648947
INFO:root:current train perplexity2.6861977577209473
INFO:root:current mean train loss 1253.6716897042745
INFO:root:current train perplexity2.685610055923462
INFO:root:current mean train loss 1253.4271265013606
INFO:root:current train perplexity2.685804843902588
INFO:root:current mean train loss 1253.6623643558457
INFO:root:current train perplexity2.686950206756592
INFO:root:current mean train loss 1254.402193096322
INFO:root:current train perplexity2.6879920959472656
INFO:root:current mean train loss 1254.266738545933
INFO:root:current train perplexity2.6878533363342285
INFO:root:current mean train loss 1254.3812069464586
INFO:root:current train perplexity2.6887435913085938
INFO:root:current mean train loss 1254.5146116293904
INFO:root:current train perplexity2.6887733936309814
INFO:root:current mean train loss 1255.2167230447133
INFO:root:current train perplexity2.6889591217041016
INFO:root:current mean train loss 1255.0740335553082
INFO:root:current train perplexity2.6895575523376465
INFO:root:current mean train loss 1254.9020110099545
INFO:root:current train perplexity2.6903886795043945
INFO:root:current mean train loss 1255.0449609694138
INFO:root:current train perplexity2.690533399581909
INFO:root:current mean train loss 1255.0043080857963
INFO:root:current train perplexity2.6899333000183105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.92s/it]
INFO:root:final mean train loss: 1254.6308185925582
INFO:root:final train perplexity: 2.689828395843506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2296.782532171155
INFO:root:eval perplexity: 6.40771484375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 2876.6666086616247
INFO:root:eval perplexity: 10.513046264648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [28:28:44<6:35:15, 624.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1249.3755136165978
INFO:root:current train perplexity2.6705162525177
INFO:root:current mean train loss 1251.039990393944
INFO:root:current train perplexity2.666456460952759
INFO:root:current mean train loss 1252.3083486443923
INFO:root:current train perplexity2.667214870452881
INFO:root:current mean train loss 1250.1673933250709
INFO:root:current train perplexity2.667344808578491
INFO:root:current mean train loss 1249.2596408599786
INFO:root:current train perplexity2.6711418628692627
INFO:root:current mean train loss 1249.1320555757657
INFO:root:current train perplexity2.6734235286712646
INFO:root:current mean train loss 1249.4583850527613
INFO:root:current train perplexity2.6747004985809326
INFO:root:current mean train loss 1249.9660456481365
INFO:root:current train perplexity2.676818370819092
INFO:root:current mean train loss 1250.2354963868333
INFO:root:current train perplexity2.6769208908081055
INFO:root:current mean train loss 1250.3763563510379
INFO:root:current train perplexity2.6774063110351562
INFO:root:current mean train loss 1250.4787082943822
INFO:root:current train perplexity2.677058696746826
INFO:root:current mean train loss 1251.0500652382711
INFO:root:current train perplexity2.677057981491089
INFO:root:current mean train loss 1251.1576627227466
INFO:root:current train perplexity2.6776978969573975
INFO:root:current mean train loss 1252.3961664328112
INFO:root:current train perplexity2.680875062942505
INFO:root:current mean train loss 1251.5908503890118
INFO:root:current train perplexity2.681121349334717
INFO:root:current mean train loss 1251.86171901725
INFO:root:current train perplexity2.6819918155670166
INFO:root:current mean train loss 1252.0099384287091
INFO:root:current train perplexity2.682736396789551
INFO:root:current mean train loss 1252.0313511797856
INFO:root:current train perplexity2.6827852725982666
INFO:root:current mean train loss 1252.4700073308065
INFO:root:current train perplexity2.684004545211792
INFO:root:current mean train loss 1252.9038281575022
INFO:root:current train perplexity2.685443639755249

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.33s/it]
INFO:root:final mean train loss: 1252.5072582281423
INFO:root:final train perplexity: 2.6853272914886475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2298.595587114916
INFO:root:eval perplexity: 6.41711950302124
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it]
INFO:root:eval mean loss: 2877.716773499834
INFO:root:eval perplexity: 10.522079467773438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [28:39:04<6:24:09, 622.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.7297903878348
INFO:root:current train perplexity2.6849355697631836
INFO:root:current mean train loss 1248.6327773150276
INFO:root:current train perplexity2.6834487915039062
INFO:root:current mean train loss 1249.01982421875
INFO:root:current train perplexity2.685502052307129
INFO:root:current mean train loss 1248.759903861381
INFO:root:current train perplexity2.6774652004241943
INFO:root:current mean train loss 1249.2103471471908
INFO:root:current train perplexity2.675337076187134
INFO:root:current mean train loss 1250.5947873834978
INFO:root:current train perplexity2.6748154163360596
INFO:root:current mean train loss 1250.4109506180037
INFO:root:current train perplexity2.6763010025024414
INFO:root:current mean train loss 1250.5191109793527
INFO:root:current train perplexity2.67691707611084
INFO:root:current mean train loss 1250.7543009440103
INFO:root:current train perplexity2.6772775650024414
INFO:root:current mean train loss 1251.101638384947
INFO:root:current train perplexity2.677217721939087
INFO:root:current mean train loss 1250.7879327221451
INFO:root:current train perplexity2.6782991886138916
INFO:root:current mean train loss 1250.184566660824
INFO:root:current train perplexity2.6793458461761475
INFO:root:current mean train loss 1250.1129258043184
INFO:root:current train perplexity2.6793625354766846
INFO:root:current mean train loss 1249.93795032362
INFO:root:current train perplexity2.6787965297698975
INFO:root:current mean train loss 1250.085268272348
INFO:root:current train perplexity2.6799373626708984
INFO:root:current mean train loss 1250.4871879043094
INFO:root:current train perplexity2.6796696186065674
INFO:root:current mean train loss 1250.7388110497754
INFO:root:current train perplexity2.680202007293701
INFO:root:current mean train loss 1251.2201089805128
INFO:root:current train perplexity2.681011199951172
INFO:root:current mean train loss 1251.1021452388661
INFO:root:current train perplexity2.6818642616271973
INFO:root:current mean train loss 1251.6697488078007
INFO:root:current train perplexity2.682753324508667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.27s/it]
INFO:root:final mean train loss: 1251.2690575580914
INFO:root:final train perplexity: 2.682706117630005
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2300.6592874729886
INFO:root:eval perplexity: 6.4278364181518555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 2879.8293816316213
INFO:root:eval perplexity: 10.540274620056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [28:49:25<6:13:23, 622.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1237.014019845546
INFO:root:current train perplexity2.6635186672210693
INFO:root:current mean train loss 1245.4559045475435
INFO:root:current train perplexity2.670003652572632
INFO:root:current mean train loss 1244.8277120025316
INFO:root:current train perplexity2.667172908782959
INFO:root:current mean train loss 1247.1793149805192
INFO:root:current train perplexity2.668092966079712
INFO:root:current mean train loss 1246.594698238177
INFO:root:current train perplexity2.6695261001586914
INFO:root:current mean train loss 1245.9756801416763
INFO:root:current train perplexity2.671682834625244
INFO:root:current mean train loss 1245.9741162962268
INFO:root:current train perplexity2.6724061965942383
INFO:root:current mean train loss 1246.3464209666852
INFO:root:current train perplexity2.673074960708618
INFO:root:current mean train loss 1246.613135921646
INFO:root:current train perplexity2.673168659210205
INFO:root:current mean train loss 1246.1676414976728
INFO:root:current train perplexity2.674253463745117
INFO:root:current mean train loss 1246.9750139926043
INFO:root:current train perplexity2.6749267578125
INFO:root:current mean train loss 1247.4920994695135
INFO:root:current train perplexity2.675180435180664
INFO:root:current mean train loss 1248.2774306314345
INFO:root:current train perplexity2.6763882637023926
INFO:root:current mean train loss 1247.8159876729226
INFO:root:current train perplexity2.6774983406066895
INFO:root:current mean train loss 1248.2105613559704
INFO:root:current train perplexity2.677290439605713
INFO:root:current mean train loss 1248.936514899501
INFO:root:current train perplexity2.6785590648651123
INFO:root:current mean train loss 1249.4775140261465
INFO:root:current train perplexity2.6797749996185303
INFO:root:current mean train loss 1250.0595463356228
INFO:root:current train perplexity2.6805663108825684
INFO:root:current mean train loss 1250.125436852581
INFO:root:current train perplexity2.6800687313079834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it]
INFO:root:final mean train loss: 1250.2193252017146
INFO:root:final train perplexity: 2.6804862022399902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2301.43811251593
INFO:root:eval perplexity: 6.431887626647949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2881.400611390459
INFO:root:eval perplexity: 10.553826332092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [28:59:58<6:05:00, 625.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1234.9429626464844
INFO:root:current train perplexity2.699101686477661
INFO:root:current mean train loss 1238.226061307467
INFO:root:current train perplexity2.660107135772705
INFO:root:current mean train loss 1240.3537531834022
INFO:root:current train perplexity2.6642446517944336
INFO:root:current mean train loss 1241.253207959627
INFO:root:current train perplexity2.6647942066192627
INFO:root:current mean train loss 1244.0754071226215
INFO:root:current train perplexity2.665381908416748
INFO:root:current mean train loss 1244.7320515466115
INFO:root:current train perplexity2.667205572128296
INFO:root:current mean train loss 1244.6457208292375
INFO:root:current train perplexity2.6707663536071777
INFO:root:current mean train loss 1245.2253926017067
INFO:root:current train perplexity2.67083477973938
INFO:root:current mean train loss 1245.4629581887923
INFO:root:current train perplexity2.6691017150878906
INFO:root:current mean train loss 1245.6387735552491
INFO:root:current train perplexity2.6703555583953857
INFO:root:current mean train loss 1246.491434773601
INFO:root:current train perplexity2.671398401260376
INFO:root:current mean train loss 1246.5365100805311
INFO:root:current train perplexity2.671739101409912
INFO:root:current mean train loss 1247.5264017605703
INFO:root:current train perplexity2.673011541366577
INFO:root:current mean train loss 1247.8528222394136
INFO:root:current train perplexity2.673814535140991
INFO:root:current mean train loss 1247.3476824203449
INFO:root:current train perplexity2.6742160320281982
INFO:root:current mean train loss 1247.5373377698534
INFO:root:current train perplexity2.6758511066436768
INFO:root:current mean train loss 1247.5932029667044
INFO:root:current train perplexity2.6761412620544434
INFO:root:current mean train loss 1248.0018228880117
INFO:root:current train perplexity2.6754860877990723
INFO:root:current mean train loss 1248.2289819823136
INFO:root:current train perplexity2.6761984825134277
INFO:root:current mean train loss 1248.366600613634
INFO:root:current train perplexity2.676866054534912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.55s/it]
INFO:root:final mean train loss: 1248.7557929227044
INFO:root:final train perplexity: 2.677394151687622
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2301.0631181432846
INFO:root:eval perplexity: 6.429937362670898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2880.9063954454787
INFO:root:eval perplexity: 10.549562454223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [29:10:25<5:54:41, 625.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.093273344494
INFO:root:current train perplexity2.650996685028076
INFO:root:current mean train loss 1246.951260653409
INFO:root:current train perplexity2.668268918991089
INFO:root:current mean train loss 1246.5339189762444
INFO:root:current train perplexity2.661203145980835
INFO:root:current mean train loss 1245.0858507958528
INFO:root:current train perplexity2.66133189201355
INFO:root:current mean train loss 1245.6532663811981
INFO:root:current train perplexity2.6623919010162354
INFO:root:current mean train loss 1244.3661286981917
INFO:root:current train perplexity2.665750503540039
INFO:root:current mean train loss 1245.6778739400916
INFO:root:current train perplexity2.6673755645751953
INFO:root:current mean train loss 1245.7040125070432
INFO:root:current train perplexity2.668715476989746
INFO:root:current mean train loss 1246.0302643677203
INFO:root:current train perplexity2.6679582595825195
INFO:root:current mean train loss 1246.7251700236666
INFO:root:current train perplexity2.6682915687561035
INFO:root:current mean train loss 1246.448154072103
INFO:root:current train perplexity2.668621063232422
INFO:root:current mean train loss 1246.0616102261165
INFO:root:current train perplexity2.6711316108703613
INFO:root:current mean train loss 1246.9035467574286
INFO:root:current train perplexity2.6709177494049072
INFO:root:current mean train loss 1246.5820464048306
INFO:root:current train perplexity2.6707565784454346
INFO:root:current mean train loss 1246.634080450607
INFO:root:current train perplexity2.670210361480713
INFO:root:current mean train loss 1246.7492406119022
INFO:root:current train perplexity2.67083740234375
INFO:root:current mean train loss 1247.146127652563
INFO:root:current train perplexity2.6712677478790283
INFO:root:current mean train loss 1247.110204524872
INFO:root:current train perplexity2.6717581748962402
INFO:root:current mean train loss 1247.2528682836526
INFO:root:current train perplexity2.672886371612549
INFO:root:current mean train loss 1247.4442896766006
INFO:root:current train perplexity2.6738646030426025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.03s/it]
INFO:root:final mean train loss: 1247.2931986090755
INFO:root:final train perplexity: 2.674307346343994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2304.7475793716753
INFO:root:eval perplexity: 6.449126243591309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2884.1613791174923
INFO:root:eval perplexity: 10.577681541442871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [29:20:59<5:45:38, 628.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.0946237664473
INFO:root:current train perplexity2.661128520965576
INFO:root:current mean train loss 1240.4498927904212
INFO:root:current train perplexity2.654949903488159
INFO:root:current mean train loss 1243.4934210256367
INFO:root:current train perplexity2.656668186187744
INFO:root:current mean train loss 1243.45470794136
INFO:root:current train perplexity2.6549792289733887
INFO:root:current mean train loss 1245.3585781985767
INFO:root:current train perplexity2.660496473312378
INFO:root:current mean train loss 1243.855233912131
INFO:root:current train perplexity2.6603822708129883
INFO:root:current mean train loss 1244.436120682002
INFO:root:current train perplexity2.659844160079956
INFO:root:current mean train loss 1245.9596201992294
INFO:root:current train perplexity2.663104295730591
INFO:root:current mean train loss 1246.5688399358125
INFO:root:current train perplexity2.6634318828582764
INFO:root:current mean train loss 1245.7855130909347
INFO:root:current train perplexity2.6647491455078125
INFO:root:current mean train loss 1245.6555096988275
INFO:root:current train perplexity2.666638135910034
INFO:root:current mean train loss 1245.5594058715606
INFO:root:current train perplexity2.6683189868927
INFO:root:current mean train loss 1245.1774797824742
INFO:root:current train perplexity2.6700375080108643
INFO:root:current mean train loss 1245.329649966572
INFO:root:current train perplexity2.670109272003174
INFO:root:current mean train loss 1245.7398152782457
INFO:root:current train perplexity2.6703693866729736
INFO:root:current mean train loss 1245.541273972768
INFO:root:current train perplexity2.6705408096313477
INFO:root:current mean train loss 1245.7547140156394
INFO:root:current train perplexity2.670884132385254
INFO:root:current mean train loss 1246.0224082604377
INFO:root:current train perplexity2.6712968349456787
INFO:root:current mean train loss 1245.9580861154916
INFO:root:current train perplexity2.6708431243896484
INFO:root:current mean train loss 1246.391206881087
INFO:root:current train perplexity2.6715927124023438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.45s/it]
INFO:root:final mean train loss: 1245.9583668211044
INFO:root:final train perplexity: 2.6714937686920166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2307.137599647468
INFO:root:eval perplexity: 6.461602210998535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it]
INFO:root:eval mean loss: 2886.096695270944
INFO:root:eval perplexity: 10.594437599182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [29:31:19<5:33:46, 625.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.7013694069603
INFO:root:current train perplexity2.656170606613159
INFO:root:current mean train loss 1239.4883481917843
INFO:root:current train perplexity2.6507198810577393
INFO:root:current mean train loss 1242.018311025582
INFO:root:current train perplexity2.6561670303344727
INFO:root:current mean train loss 1242.7097147337147
INFO:root:current train perplexity2.657460927963257
INFO:root:current mean train loss 1241.7350642277645
INFO:root:current train perplexity2.6583938598632812
INFO:root:current mean train loss 1242.693343758798
INFO:root:current train perplexity2.660425901412964
INFO:root:current mean train loss 1243.2575670548067
INFO:root:current train perplexity2.6629486083984375
INFO:root:current mean train loss 1243.4736481723407
INFO:root:current train perplexity2.6628499031066895
INFO:root:current mean train loss 1242.7840035064876
INFO:root:current train perplexity2.6632447242736816
INFO:root:current mean train loss 1243.2803360704352
INFO:root:current train perplexity2.663719415664673
INFO:root:current mean train loss 1243.148010196053
INFO:root:current train perplexity2.6628963947296143
INFO:root:current mean train loss 1243.4257753314394
INFO:root:current train perplexity2.6632280349731445
INFO:root:current mean train loss 1244.6066549232758
INFO:root:current train perplexity2.663456678390503
INFO:root:current mean train loss 1244.3501663939978
INFO:root:current train perplexity2.6638123989105225
INFO:root:current mean train loss 1244.3436635859644
INFO:root:current train perplexity2.6652770042419434
INFO:root:current mean train loss 1244.6793307877813
INFO:root:current train perplexity2.6666934490203857
INFO:root:current mean train loss 1244.6968834822271
INFO:root:current train perplexity2.6685335636138916
INFO:root:current mean train loss 1244.5864389968394
INFO:root:current train perplexity2.6691017150878906
INFO:root:current mean train loss 1244.879254693291
INFO:root:current train perplexity2.6694140434265137
INFO:root:current mean train loss 1244.9255291170477
INFO:root:current train perplexity2.6689703464508057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.94s/it]
INFO:root:final mean train loss: 1244.793718900695
INFO:root:final train perplexity: 2.669041156768799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 2307.767743049784
INFO:root:eval perplexity: 6.4648966789245605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2887.4024610587044
INFO:root:eval perplexity: 10.605757713317871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [29:41:53<5:24:38, 628.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.0120934380425
INFO:root:current train perplexity2.6407089233398438
INFO:root:current mean train loss 1243.9272553199946
INFO:root:current train perplexity2.6481516361236572
INFO:root:current mean train loss 1244.7565801283893
INFO:root:current train perplexity2.652330160140991
INFO:root:current mean train loss 1245.256583921371
INFO:root:current train perplexity2.658456802368164
INFO:root:current mean train loss 1244.4347971253476
INFO:root:current train perplexity2.6566858291625977
INFO:root:current mean train loss 1242.8330884813429
INFO:root:current train perplexity2.66029691696167
INFO:root:current mean train loss 1242.066624414353
INFO:root:current train perplexity2.6597256660461426
INFO:root:current mean train loss 1242.4250742857937
INFO:root:current train perplexity2.6597378253936768
INFO:root:current mean train loss 1242.5394292708932
INFO:root:current train perplexity2.6611077785491943
INFO:root:current mean train loss 1242.7273411377957
INFO:root:current train perplexity2.661747932434082
INFO:root:current mean train loss 1241.7241369218968
INFO:root:current train perplexity2.6611123085021973
INFO:root:current mean train loss 1242.3504304332537
INFO:root:current train perplexity2.6627633571624756
INFO:root:current mean train loss 1242.8156122171654
INFO:root:current train perplexity2.662196159362793
INFO:root:current mean train loss 1243.0042689020363
INFO:root:current train perplexity2.663553237915039
INFO:root:current mean train loss 1243.2603656934655
INFO:root:current train perplexity2.6640784740448
INFO:root:current mean train loss 1242.7974093294022
INFO:root:current train perplexity2.664106845855713
INFO:root:current mean train loss 1242.6379104687267
INFO:root:current train perplexity2.6643028259277344
INFO:root:current mean train loss 1242.8269046413172
INFO:root:current train perplexity2.664531946182251
INFO:root:current mean train loss 1243.2536801721296
INFO:root:current train perplexity2.665933132171631
INFO:root:current mean train loss 1243.6671940492085
INFO:root:current train perplexity2.666020631790161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.89s/it]
INFO:root:final mean train loss: 1243.3058208209725
INFO:root:final train perplexity: 2.6659107208251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2308.6927503220577
INFO:root:eval perplexity: 6.469734191894531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2890.7026267626607
INFO:root:eval perplexity: 10.634420394897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [29:52:17<5:13:27, 626.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1235.7555919175738
INFO:root:current train perplexity2.661339282989502
INFO:root:current mean train loss 1238.7281597480571
INFO:root:current train perplexity2.6662678718566895
INFO:root:current mean train loss 1242.5635656864997
INFO:root:current train perplexity2.662445068359375
INFO:root:current mean train loss 1243.1229577542576
INFO:root:current train perplexity2.6604526042938232
INFO:root:current mean train loss 1242.8474782619983
INFO:root:current train perplexity2.6633224487304688
INFO:root:current mean train loss 1241.4023468587516
INFO:root:current train perplexity2.6621570587158203
INFO:root:current mean train loss 1241.544472394038
INFO:root:current train perplexity2.6623432636260986
INFO:root:current mean train loss 1242.3132720289725
INFO:root:current train perplexity2.661872625350952
INFO:root:current mean train loss 1242.4265162808017
INFO:root:current train perplexity2.6621525287628174
INFO:root:current mean train loss 1242.4810438011486
INFO:root:current train perplexity2.661092519760132
INFO:root:current mean train loss 1242.0819548019256
INFO:root:current train perplexity2.660597801208496
INFO:root:current mean train loss 1241.675091434668
INFO:root:current train perplexity2.660611867904663
INFO:root:current mean train loss 1241.8050943379073
INFO:root:current train perplexity2.661383867263794
INFO:root:current mean train loss 1241.9904066268448
INFO:root:current train perplexity2.662156105041504
INFO:root:current mean train loss 1241.5207440829101
INFO:root:current train perplexity2.6615726947784424
INFO:root:current mean train loss 1241.990560638447
INFO:root:current train perplexity2.66316556930542
INFO:root:current mean train loss 1242.2508403988122
INFO:root:current train perplexity2.663757801055908
INFO:root:current mean train loss 1242.3221941159516
INFO:root:current train perplexity2.6642303466796875
INFO:root:current mean train loss 1242.7695932221702
INFO:root:current train perplexity2.664041757583618

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.13s/it]
INFO:root:final mean train loss: 1243.0781024696246
INFO:root:final train perplexity: 2.6654322147369385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2308.766096832059
INFO:root:eval perplexity: 6.470118522644043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2889.684330933483
INFO:root:eval perplexity: 10.625570297241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [30:02:38<5:02:16, 625.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.677978515625
INFO:root:current train perplexity2.6573755741119385
INFO:root:current mean train loss 1243.8961895636792
INFO:root:current train perplexity2.6405446529388428
INFO:root:current mean train loss 1239.2875295102017
INFO:root:current train perplexity2.641831159591675
INFO:root:current mean train loss 1238.148000679764
INFO:root:current train perplexity2.6432807445526123
INFO:root:current mean train loss 1239.4387261151094
INFO:root:current train perplexity2.648676633834839
INFO:root:current mean train loss 1241.6279103878458
INFO:root:current train perplexity2.6529183387756348
INFO:root:current mean train loss 1240.2634778919787
INFO:root:current train perplexity2.6515979766845703
INFO:root:current mean train loss 1239.930163332153
INFO:root:current train perplexity2.653013229370117
INFO:root:current mean train loss 1238.9965396246898
INFO:root:current train perplexity2.6544394493103027
INFO:root:current mean train loss 1239.1927611496276
INFO:root:current train perplexity2.6554203033447266
INFO:root:current mean train loss 1239.2357566029605
INFO:root:current train perplexity2.6566004753112793
INFO:root:current mean train loss 1239.420963446012
INFO:root:current train perplexity2.6568820476531982
INFO:root:current mean train loss 1240.2590702493392
INFO:root:current train perplexity2.6578094959259033
INFO:root:current mean train loss 1240.634329499366
INFO:root:current train perplexity2.6578123569488525
INFO:root:current mean train loss 1241.6391228232242
INFO:root:current train perplexity2.659058094024658
INFO:root:current mean train loss 1241.2655292728825
INFO:root:current train perplexity2.6596615314483643
INFO:root:current mean train loss 1241.8183483537077
INFO:root:current train perplexity2.6598103046417236
INFO:root:current mean train loss 1242.1999724948253
INFO:root:current train perplexity2.6611008644104004
INFO:root:current mean train loss 1242.1114164671365
INFO:root:current train perplexity2.6620116233825684
INFO:root:current mean train loss 1242.0679678021297
INFO:root:current train perplexity2.661972999572754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.59s/it]
INFO:root:final mean train loss: 1241.6912520462013
INFO:root:final train perplexity: 2.66251802444458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2311.2482762979275
INFO:root:eval perplexity: 6.483119964599609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2893.2671582377548
INFO:root:eval perplexity: 10.656750679016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [30:13:10<4:52:41, 627.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1227.8186831266983
INFO:root:current train perplexity2.638404130935669
INFO:root:current mean train loss 1231.8747747157647
INFO:root:current train perplexity2.6502652168273926
INFO:root:current mean train loss 1232.204769938516
INFO:root:current train perplexity2.6555380821228027
INFO:root:current mean train loss 1232.1562337491534
INFO:root:current train perplexity2.652416944503784
INFO:root:current mean train loss 1233.7147323572326
INFO:root:current train perplexity2.651864767074585
INFO:root:current mean train loss 1234.4860982220214
INFO:root:current train perplexity2.656158685684204
INFO:root:current mean train loss 1235.9096889342773
INFO:root:current train perplexity2.6564059257507324
INFO:root:current mean train loss 1235.6704550673194
INFO:root:current train perplexity2.655395269393921
INFO:root:current mean train loss 1236.9718606422766
INFO:root:current train perplexity2.6560633182525635
INFO:root:current mean train loss 1237.9660542695779
INFO:root:current train perplexity2.655871629714966
INFO:root:current mean train loss 1237.9972771041437
INFO:root:current train perplexity2.655221939086914
INFO:root:current mean train loss 1237.5103606498358
INFO:root:current train perplexity2.6541502475738525
INFO:root:current mean train loss 1237.7849076178263
INFO:root:current train perplexity2.6543688774108887
INFO:root:current mean train loss 1239.0069069837136
INFO:root:current train perplexity2.6565961837768555
INFO:root:current mean train loss 1240.034603030432
INFO:root:current train perplexity2.656181573867798
INFO:root:current mean train loss 1240.2025926355775
INFO:root:current train perplexity2.6570096015930176
INFO:root:current mean train loss 1240.4103894095617
INFO:root:current train perplexity2.6579604148864746
INFO:root:current mean train loss 1240.3674024514382
INFO:root:current train perplexity2.6587352752685547
INFO:root:current mean train loss 1240.0886211049994
INFO:root:current train perplexity2.6591756343841553
INFO:root:current mean train loss 1240.2980623131175
INFO:root:current train perplexity2.659224033355713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.65s/it]
INFO:root:final mean train loss: 1240.1029073048649
INFO:root:final train perplexity: 2.6591851711273193
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2311.7293441447805
INFO:root:eval perplexity: 6.485642433166504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2892.645152856272
INFO:root:eval perplexity: 10.65132999420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [30:23:32<4:41:33, 625.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1232.021694946289
INFO:root:current train perplexity2.6535987854003906
INFO:root:current mean train loss 1235.4999014718192
INFO:root:current train perplexity2.6534011363983154
INFO:root:current mean train loss 1240.1429438273112
INFO:root:current train perplexity2.651090621948242
INFO:root:current mean train loss 1239.3389303768383
INFO:root:current train perplexity2.6508846282958984
INFO:root:current mean train loss 1238.0056807084518
INFO:root:current train perplexity2.6524159908294678
INFO:root:current mean train loss 1237.9800575538918
INFO:root:current train perplexity2.652202606201172
INFO:root:current mean train loss 1238.212845993042
INFO:root:current train perplexity2.6521172523498535
INFO:root:current mean train loss 1238.590725295608
INFO:root:current train perplexity2.6508829593658447
INFO:root:current mean train loss 1237.4346872965496
INFO:root:current train perplexity2.6513407230377197
INFO:root:current mean train loss 1237.6272023302442
INFO:root:current train perplexity2.6525449752807617
INFO:root:current mean train loss 1237.5204973660982
INFO:root:current train perplexity2.652681827545166
INFO:root:current mean train loss 1237.017310748184
INFO:root:current train perplexity2.6534554958343506
INFO:root:current mean train loss 1237.3771917527722
INFO:root:current train perplexity2.65336275100708
INFO:root:current mean train loss 1237.1623673624067
INFO:root:current train perplexity2.654907703399658
INFO:root:current mean train loss 1237.6917540656195
INFO:root:current train perplexity2.655879497528076
INFO:root:current mean train loss 1238.0384971717735
INFO:root:current train perplexity2.656393527984619
INFO:root:current mean train loss 1238.4353277439025
INFO:root:current train perplexity2.6571221351623535
INFO:root:current mean train loss 1239.0115653202452
INFO:root:current train perplexity2.657726764678955
INFO:root:current mean train loss 1238.8895639834197
INFO:root:current train perplexity2.6573686599731445
INFO:root:current mean train loss 1239.196343427835
INFO:root:current train perplexity2.6571898460388184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.10s/it]
INFO:root:final mean train loss: 1239.1243110999158
INFO:root:final train perplexity: 2.6571335792541504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2313.228378404117
INFO:root:eval perplexity: 6.4935102462768555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it]
INFO:root:eval mean loss: 2894.50358116204
INFO:root:eval perplexity: 10.667529106140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [30:33:55<4:30:45, 624.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1238.214783785636
INFO:root:current train perplexity2.659669876098633
INFO:root:current mean train loss 1230.3738010673767
INFO:root:current train perplexity2.6465442180633545
INFO:root:current mean train loss 1232.8077530322835
INFO:root:current train perplexity2.646348237991333
INFO:root:current mean train loss 1233.8222847732843
INFO:root:current train perplexity2.6439976692199707
INFO:root:current mean train loss 1234.3234489324057
INFO:root:current train perplexity2.6426820755004883
INFO:root:current mean train loss 1234.3615317216254
INFO:root:current train perplexity2.6467671394348145
INFO:root:current mean train loss 1234.0127228108352
INFO:root:current train perplexity2.6473326683044434
INFO:root:current mean train loss 1233.9065076860759
INFO:root:current train perplexity2.6465351581573486
INFO:root:current mean train loss 1234.4150612830003
INFO:root:current train perplexity2.648622512817383
INFO:root:current mean train loss 1235.4031361228122
INFO:root:current train perplexity2.649250030517578
INFO:root:current mean train loss 1234.9638698437132
INFO:root:current train perplexity2.64898943901062
INFO:root:current mean train loss 1234.95640159086
INFO:root:current train perplexity2.649472951889038
INFO:root:current mean train loss 1236.2579544783587
INFO:root:current train perplexity2.6503758430480957
INFO:root:current mean train loss 1236.4667928269794
INFO:root:current train perplexity2.6502530574798584
INFO:root:current mean train loss 1236.560136008279
INFO:root:current train perplexity2.6508185863494873
INFO:root:current mean train loss 1236.941106993492
INFO:root:current train perplexity2.6510009765625
INFO:root:current mean train loss 1237.1139453066064
INFO:root:current train perplexity2.6515328884124756
INFO:root:current mean train loss 1237.6136849782788
INFO:root:current train perplexity2.6528286933898926
INFO:root:current mean train loss 1237.7108603268462
INFO:root:current train perplexity2.652426242828369
INFO:root:current mean train loss 1237.9586625759493
INFO:root:current train perplexity2.653672695159912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it]
INFO:root:final mean train loss: 1237.5677826343253
INFO:root:final train perplexity: 2.653873920440674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2313.003661243628
INFO:root:eval perplexity: 6.4923295974731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2894.89384211547
INFO:root:eval perplexity: 10.670937538146973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [30:44:24<4:20:51, 626.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.8863987278294
INFO:root:current train perplexity2.643341541290283
INFO:root:current mean train loss 1233.8870204180137
INFO:root:current train perplexity2.6385509967803955
INFO:root:current mean train loss 1229.40052071453
INFO:root:current train perplexity2.6446380615234375
INFO:root:current mean train loss 1229.7151965788978
INFO:root:current train perplexity2.6451334953308105
INFO:root:current mean train loss 1230.722256559863
INFO:root:current train perplexity2.6455278396606445
INFO:root:current mean train loss 1231.8485611440412
INFO:root:current train perplexity2.6461005210876465
INFO:root:current mean train loss 1233.086586428679
INFO:root:current train perplexity2.647731065750122
INFO:root:current mean train loss 1234.1444236893371
INFO:root:current train perplexity2.6480116844177246
INFO:root:current mean train loss 1234.6944353815074
INFO:root:current train perplexity2.6490020751953125
INFO:root:current mean train loss 1234.913147223314
INFO:root:current train perplexity2.649380922317505
INFO:root:current mean train loss 1235.027365231647
INFO:root:current train perplexity2.6502082347869873
INFO:root:current mean train loss 1235.8428383198466
INFO:root:current train perplexity2.650622844696045
INFO:root:current mean train loss 1236.5214903156275
INFO:root:current train perplexity2.6513421535491943
INFO:root:current mean train loss 1236.2309181180062
INFO:root:current train perplexity2.6505868434906006
INFO:root:current mean train loss 1236.6780381429146
INFO:root:current train perplexity2.6515276432037354
INFO:root:current mean train loss 1236.7464726022722
INFO:root:current train perplexity2.652279853820801
INFO:root:current mean train loss 1237.2859753024193
INFO:root:current train perplexity2.653484582901001
INFO:root:current mean train loss 1237.673294222207
INFO:root:current train perplexity2.6541173458099365
INFO:root:current mean train loss 1237.750684609917
INFO:root:current train perplexity2.6540112495422363
INFO:root:current mean train loss 1238.001467812025
INFO:root:current train perplexity2.653794765472412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.71s/it]
INFO:root:final mean train loss: 1237.5960464669909
INFO:root:final train perplexity: 2.653933048248291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2314.155453945728
INFO:root:eval perplexity: 6.498380184173584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2897.5262386240856
INFO:root:eval perplexity: 10.693933486938477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [30:54:48<4:10:09, 625.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.6890815483346
INFO:root:current train perplexity2.6468870639801025
INFO:root:current mean train loss 1229.7854055035177
INFO:root:current train perplexity2.6438677310943604
INFO:root:current mean train loss 1231.2262768302996
INFO:root:current train perplexity2.645416021347046
INFO:root:current mean train loss 1232.802306972806
INFO:root:current train perplexity2.6436362266540527
INFO:root:current mean train loss 1233.3766070519348
INFO:root:current train perplexity2.646050214767456
INFO:root:current mean train loss 1234.65673332408
INFO:root:current train perplexity2.6476683616638184
INFO:root:current mean train loss 1235.2199678766056
INFO:root:current train perplexity2.6478915214538574
INFO:root:current mean train loss 1235.4241389336087
INFO:root:current train perplexity2.650395154953003
INFO:root:current mean train loss 1235.352380275191
INFO:root:current train perplexity2.649732828140259
INFO:root:current mean train loss 1235.6356110019472
INFO:root:current train perplexity2.648341417312622
INFO:root:current mean train loss 1234.7599690382247
INFO:root:current train perplexity2.6486241817474365
INFO:root:current mean train loss 1235.479498029656
INFO:root:current train perplexity2.6488027572631836
INFO:root:current mean train loss 1235.619945381336
INFO:root:current train perplexity2.649688720703125
INFO:root:current mean train loss 1235.607952894023
INFO:root:current train perplexity2.6496384143829346
INFO:root:current mean train loss 1235.8333608421362
INFO:root:current train perplexity2.6502885818481445
INFO:root:current mean train loss 1236.1357968160748
INFO:root:current train perplexity2.650681734085083
INFO:root:current mean train loss 1236.5059135883675
INFO:root:current train perplexity2.651362657546997
INFO:root:current mean train loss 1236.5338635042617
INFO:root:current train perplexity2.6515491008758545
INFO:root:current mean train loss 1236.3051032233277
INFO:root:current train perplexity2.651372194290161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it]
INFO:root:final mean train loss: 1236.5564558266751
INFO:root:final train perplexity: 2.6517579555511475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2315.804515649241
INFO:root:eval perplexity: 6.507053852081299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2898.845868915531
INFO:root:eval perplexity: 10.70547866821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [31:05:10<3:59:25, 624.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.8773040771484
INFO:root:current train perplexity2.651590585708618
INFO:root:current mean train loss 1241.1948117856625
INFO:root:current train perplexity2.6556005477905273
INFO:root:current mean train loss 1238.554943378155
INFO:root:current train perplexity2.6555023193359375
INFO:root:current mean train loss 1233.2561066862825
INFO:root:current train perplexity2.6511569023132324
INFO:root:current mean train loss 1233.4481096454695
INFO:root:current train perplexity2.6477067470550537
INFO:root:current mean train loss 1233.5668476735514
INFO:root:current train perplexity2.6494715213775635
INFO:root:current mean train loss 1233.6662840592235
INFO:root:current train perplexity2.650678873062134
INFO:root:current mean train loss 1234.9144904357565
INFO:root:current train perplexity2.6497814655303955
INFO:root:current mean train loss 1234.3279446139195
INFO:root:current train perplexity2.647822141647339
INFO:root:current mean train loss 1234.5763984041591
INFO:root:current train perplexity2.6489574909210205
INFO:root:current mean train loss 1234.7469777909537
INFO:root:current train perplexity2.6479544639587402
INFO:root:current mean train loss 1234.8816550354666
INFO:root:current train perplexity2.6493589878082275
INFO:root:current mean train loss 1234.6147391211907
INFO:root:current train perplexity2.6488516330718994
INFO:root:current mean train loss 1234.4229726995532
INFO:root:current train perplexity2.6488895416259766
INFO:root:current mean train loss 1234.514893358404
INFO:root:current train perplexity2.6479427814483643
INFO:root:current mean train loss 1234.0648658813152
INFO:root:current train perplexity2.64774489402771
INFO:root:current mean train loss 1234.2138252068514
INFO:root:current train perplexity2.6486263275146484
INFO:root:current mean train loss 1234.4922738354435
INFO:root:current train perplexity2.648890972137451
INFO:root:current mean train loss 1234.8486643428296
INFO:root:current train perplexity2.648646354675293
INFO:root:current mean train loss 1235.5074210816708
INFO:root:current train perplexity2.648726463317871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.59s/it]
INFO:root:final mean train loss: 1234.9686799465378
INFO:root:final train perplexity: 2.648439407348633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 2317.1294326241136
INFO:root:eval perplexity: 6.514029502868652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2900.7379501018117
INFO:root:eval perplexity: 10.72205924987793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [31:15:44<3:49:59, 627.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.7954296875
INFO:root:current train perplexity2.69064998626709
INFO:root:current mean train loss 1228.0850830078125
INFO:root:current train perplexity2.6469385623931885
INFO:root:current mean train loss 1232.6304112413195
INFO:root:current train perplexity2.640753984451294
INFO:root:current mean train loss 1229.99369140625
INFO:root:current train perplexity2.640944004058838
INFO:root:current mean train loss 1229.445952722886
INFO:root:current train perplexity2.640188455581665
INFO:root:current mean train loss 1230.5811328125
INFO:root:current train perplexity2.640873908996582
INFO:root:current mean train loss 1230.5100908203126
INFO:root:current train perplexity2.6421256065368652
INFO:root:current mean train loss 1230.3713880657328
INFO:root:current train perplexity2.6425294876098633
INFO:root:current mean train loss 1230.472177290483
INFO:root:current train perplexity2.644031047821045
INFO:root:current mean train loss 1231.318069309544
INFO:root:current train perplexity2.6442458629608154
INFO:root:current mean train loss 1232.1635866044207
INFO:root:current train perplexity2.6439247131347656
INFO:root:current mean train loss 1231.8158764105904
INFO:root:current train perplexity2.6433587074279785
INFO:root:current mean train loss 1231.8595412149234
INFO:root:current train perplexity2.6446149349212646
INFO:root:current mean train loss 1232.9940918890036
INFO:root:current train perplexity2.64504337310791
INFO:root:current mean train loss 1233.209188082511
INFO:root:current train perplexity2.644298553466797
INFO:root:current mean train loss 1233.1498500736425
INFO:root:current train perplexity2.6452717781066895
INFO:root:current mean train loss 1233.6636890024038
INFO:root:current train perplexity2.6449804306030273
INFO:root:current mean train loss 1233.6299097741169
INFO:root:current train perplexity2.6453301906585693
INFO:root:current mean train loss 1233.532003290882
INFO:root:current train perplexity2.6461026668548584
INFO:root:current mean train loss 1234.0454045124798
INFO:root:current train perplexity2.6462409496307373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.96s/it]
INFO:root:final mean train loss: 1234.034861231355
INFO:root:final train perplexity: 2.6464896202087402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2318.0040252901986
INFO:root:eval perplexity: 6.5186381340026855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2902.1984672816934
INFO:root:eval perplexity: 10.734871864318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [31:26:05<3:38:57, 625.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1227.3359549386162
INFO:root:current train perplexity2.6252965927124023
INFO:root:current mean train loss 1226.2772517674405
INFO:root:current train perplexity2.6273605823516846
INFO:root:current mean train loss 1228.2023184279765
INFO:root:current train perplexity2.626591682434082
INFO:root:current mean train loss 1228.2506785253336
INFO:root:current train perplexity2.632028579711914
INFO:root:current mean train loss 1229.2599746911235
INFO:root:current train perplexity2.6376752853393555
INFO:root:current mean train loss 1230.3334679410027
INFO:root:current train perplexity2.6378836631774902
INFO:root:current mean train loss 1229.328504901066
INFO:root:current train perplexity2.6374635696411133
INFO:root:current mean train loss 1229.4035080243957
INFO:root:current train perplexity2.6388628482818604
INFO:root:current mean train loss 1229.8999585946779
INFO:root:current train perplexity2.6406350135803223
INFO:root:current mean train loss 1229.259272030711
INFO:root:current train perplexity2.6397457122802734
INFO:root:current mean train loss 1229.8352679876814
INFO:root:current train perplexity2.6406350135803223
INFO:root:current mean train loss 1231.0561083043729
INFO:root:current train perplexity2.641295909881592
INFO:root:current mean train loss 1231.2844322806586
INFO:root:current train perplexity2.642338991165161
INFO:root:current mean train loss 1231.9759807103437
INFO:root:current train perplexity2.642390727996826
INFO:root:current mean train loss 1232.8470430202194
INFO:root:current train perplexity2.6433193683624268
INFO:root:current mean train loss 1233.2738798663465
INFO:root:current train perplexity2.6432430744171143
INFO:root:current mean train loss 1233.0791391054402
INFO:root:current train perplexity2.6440672874450684
INFO:root:current mean train loss 1232.7116875807262
INFO:root:current train perplexity2.6435282230377197
INFO:root:current mean train loss 1232.8650761872498
INFO:root:current train perplexity2.643470287322998
INFO:root:current mean train loss 1233.355901150453
INFO:root:current train perplexity2.6445860862731934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.47s/it]
INFO:root:final mean train loss: 1232.9223988004483
INFO:root:final train perplexity: 2.6441688537597656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2319.2325872326574
INFO:root:eval perplexity: 6.525119304656982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2903.295275099734
INFO:root:eval perplexity: 10.7445068359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [31:36:26<3:28:04, 624.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1226.148164393538
INFO:root:current train perplexity2.6063570976257324
INFO:root:current mean train loss 1235.5455184072819
INFO:root:current train perplexity2.6295528411865234
INFO:root:current mean train loss 1232.361336608651
INFO:root:current train perplexity2.6336257457733154
INFO:root:current mean train loss 1230.754506060672
INFO:root:current train perplexity2.6329598426818848
INFO:root:current mean train loss 1230.3886830448325
INFO:root:current train perplexity2.6325769424438477
INFO:root:current mean train loss 1229.6152856925733
INFO:root:current train perplexity2.635756492614746
INFO:root:current mean train loss 1231.2095584203694
INFO:root:current train perplexity2.6359429359436035
INFO:root:current mean train loss 1231.1520114742877
INFO:root:current train perplexity2.6345081329345703
INFO:root:current mean train loss 1230.7053613451778
INFO:root:current train perplexity2.6349680423736572
INFO:root:current mean train loss 1229.7673043259988
INFO:root:current train perplexity2.6363706588745117
INFO:root:current mean train loss 1228.9482978626284
INFO:root:current train perplexity2.636592388153076
INFO:root:current mean train loss 1229.0760264227986
INFO:root:current train perplexity2.6380908489227295
INFO:root:current mean train loss 1229.930284180463
INFO:root:current train perplexity2.6390533447265625
INFO:root:current mean train loss 1229.8706795732444
INFO:root:current train perplexity2.6386899948120117
INFO:root:current mean train loss 1230.1039866708254
INFO:root:current train perplexity2.6381583213806152
INFO:root:current mean train loss 1230.7392748819857
INFO:root:current train perplexity2.64019775390625
INFO:root:current mean train loss 1231.2298703185043
INFO:root:current train perplexity2.6400368213653564
INFO:root:current mean train loss 1231.8076867932552
INFO:root:current train perplexity2.640692949295044
INFO:root:current mean train loss 1232.0369569676868
INFO:root:current train perplexity2.641268253326416
INFO:root:current mean train loss 1232.0857522447477
INFO:root:current train perplexity2.641587495803833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.48s/it]
INFO:root:final mean train loss: 1231.81421187762
INFO:root:final train perplexity: 2.6418588161468506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 2319.297966273964
INFO:root:eval perplexity: 6.525463104248047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it]
INFO:root:eval mean loss: 2903.2478204821864
INFO:root:eval perplexity: 10.744091987609863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [31:47:01<3:18:40, 627.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.6023270456415
INFO:root:current train perplexity2.6253628730773926
INFO:root:current mean train loss 1228.8657178011808
INFO:root:current train perplexity2.6325840950012207
INFO:root:current mean train loss 1229.6951864491339
INFO:root:current train perplexity2.6328086853027344
INFO:root:current mean train loss 1227.0248406592837
INFO:root:current train perplexity2.6330854892730713
INFO:root:current mean train loss 1227.8321653734736
INFO:root:current train perplexity2.636420488357544
INFO:root:current mean train loss 1228.9635560777451
INFO:root:current train perplexity2.634725332260132
INFO:root:current mean train loss 1228.3254051434217
INFO:root:current train perplexity2.6348021030426025
INFO:root:current mean train loss 1229.5148291833623
INFO:root:current train perplexity2.636906623840332
INFO:root:current mean train loss 1229.4880265187999
INFO:root:current train perplexity2.638836145401001
INFO:root:current mean train loss 1228.4182885592102
INFO:root:current train perplexity2.6380598545074463
INFO:root:current mean train loss 1228.4570621079229
INFO:root:current train perplexity2.6378183364868164
INFO:root:current mean train loss 1229.1109257912149
INFO:root:current train perplexity2.6380863189697266
INFO:root:current mean train loss 1229.8450511585581
INFO:root:current train perplexity2.638746500015259
INFO:root:current mean train loss 1230.0002220508663
INFO:root:current train perplexity2.638873338699341
INFO:root:current mean train loss 1230.4004217215024
INFO:root:current train perplexity2.6393792629241943
INFO:root:current mean train loss 1231.196878268634
INFO:root:current train perplexity2.6401572227478027
INFO:root:current mean train loss 1231.6805805943745
INFO:root:current train perplexity2.641310214996338
INFO:root:current mean train loss 1231.8585621601826
INFO:root:current train perplexity2.6400880813598633
INFO:root:current mean train loss 1231.6251250635078
INFO:root:current train perplexity2.639711618423462
INFO:root:current mean train loss 1231.6579266135027
INFO:root:current train perplexity2.640939950942993

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.23s/it]
INFO:root:final mean train loss: 1231.3584156430736
INFO:root:final train perplexity: 2.640909433364868
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2321.808779019836
INFO:root:eval perplexity: 6.538727283477783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2905.580284605635
INFO:root:eval perplexity: 10.764607429504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [31:57:26<3:07:58, 626.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1235.0387960454468
INFO:root:current train perplexity2.636021852493286
INFO:root:current mean train loss 1232.1530047006559
INFO:root:current train perplexity2.631988048553467
INFO:root:current mean train loss 1229.9327117607456
INFO:root:current train perplexity2.62917160987854
INFO:root:current mean train loss 1229.7717477735368
INFO:root:current train perplexity2.633599281311035
INFO:root:current mean train loss 1230.8580091990998
INFO:root:current train perplexity2.6335928440093994
INFO:root:current mean train loss 1229.6699062302382
INFO:root:current train perplexity2.634854793548584
INFO:root:current mean train loss 1230.0989669645676
INFO:root:current train perplexity2.638883352279663
INFO:root:current mean train loss 1231.4145697152328
INFO:root:current train perplexity2.640115737915039
INFO:root:current mean train loss 1230.8718421654098
INFO:root:current train perplexity2.6389622688293457
INFO:root:current mean train loss 1230.123550891396
INFO:root:current train perplexity2.6391754150390625
INFO:root:current mean train loss 1230.2698649609733
INFO:root:current train perplexity2.640259027481079
INFO:root:current mean train loss 1230.1539688302205
INFO:root:current train perplexity2.6393282413482666
INFO:root:current mean train loss 1229.9847809569558
INFO:root:current train perplexity2.63940167427063
INFO:root:current mean train loss 1230.3832353207163
INFO:root:current train perplexity2.639042615890503
INFO:root:current mean train loss 1230.241762420593
INFO:root:current train perplexity2.6387243270874023
INFO:root:current mean train loss 1230.8137732707548
INFO:root:current train perplexity2.6396896839141846
INFO:root:current mean train loss 1230.926900648465
INFO:root:current train perplexity2.6396701335906982
INFO:root:current mean train loss 1230.8731161139892
INFO:root:current train perplexity2.639533758163452
INFO:root:current mean train loss 1231.2574861408602
INFO:root:current train perplexity2.639352560043335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.54s/it]
INFO:root:final mean train loss: 1230.8728172005997
INFO:root:final train perplexity: 2.6398983001708984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2321.7257772675644
INFO:root:eval perplexity: 6.538288593292236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2905.66003201532
INFO:root:eval perplexity: 10.765307426452637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [32:07:49<2:57:16, 625.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.0547973632813
INFO:root:current train perplexity2.5931248664855957
INFO:root:current mean train loss 1226.720926180753
INFO:root:current train perplexity2.6159305572509766
INFO:root:current mean train loss 1227.9251761300222
INFO:root:current train perplexity2.626408815383911
INFO:root:current mean train loss 1226.8844742313509
INFO:root:current train perplexity2.6313533782958984
INFO:root:current mean train loss 1227.5894438952935
INFO:root:current train perplexity2.636436939239502
INFO:root:current mean train loss 1228.0402678844976
INFO:root:current train perplexity2.6392438411712646
INFO:root:current mean train loss 1228.912690709849
INFO:root:current train perplexity2.6391420364379883
INFO:root:current mean train loss 1229.0567216040383
INFO:root:current train perplexity2.6384902000427246
INFO:root:current mean train loss 1228.6983336648823
INFO:root:current train perplexity2.6377036571502686
INFO:root:current mean train loss 1228.8394661368905
INFO:root:current train perplexity2.637333631515503
INFO:root:current mean train loss 1229.0508156955832
INFO:root:current train perplexity2.638291358947754
INFO:root:current mean train loss 1229.2377288543425
INFO:root:current train perplexity2.638791799545288
INFO:root:current mean train loss 1230.127916068085
INFO:root:current train perplexity2.637115478515625
INFO:root:current mean train loss 1230.2937522364027
INFO:root:current train perplexity2.6371421813964844
INFO:root:current mean train loss 1230.4400222670101
INFO:root:current train perplexity2.6367759704589844
INFO:root:current mean train loss 1230.0277157815087
INFO:root:current train perplexity2.6356003284454346
INFO:root:current mean train loss 1229.3862159871167
INFO:root:current train perplexity2.6348657608032227
INFO:root:current mean train loss 1229.5873582271108
INFO:root:current train perplexity2.635377883911133
INFO:root:current mean train loss 1229.2217724204722
INFO:root:current train perplexity2.635486602783203
INFO:root:current mean train loss 1229.2527683757362
INFO:root:current train perplexity2.6363067626953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.07s/it]
INFO:root:final mean train loss: 1229.2095399395841
INFO:root:final train perplexity: 2.6364376544952393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2322.28134912802
INFO:root:eval perplexity: 6.541226863861084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 2905.9201049804688
INFO:root:eval perplexity: 10.767597198486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [32:18:09<2:46:20, 623.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1220.574508101852
INFO:root:current train perplexity2.6228458881378174
INFO:root:current mean train loss 1221.7125811238927
INFO:root:current train perplexity2.6269004344940186
INFO:root:current mean train loss 1224.751759533315
INFO:root:current train perplexity2.627793073654175
INFO:root:current mean train loss 1223.9977060487147
INFO:root:current train perplexity2.6210827827453613
INFO:root:current mean train loss 1224.58335972949
INFO:root:current train perplexity2.6236257553100586
INFO:root:current mean train loss 1223.5814957157259
INFO:root:current train perplexity2.6252918243408203
INFO:root:current mean train loss 1225.2123768394263
INFO:root:current train perplexity2.62492036819458
INFO:root:current mean train loss 1226.080887281583
INFO:root:current train perplexity2.6259262561798096
INFO:root:current mean train loss 1227.0776872000642
INFO:root:current train perplexity2.629122734069824
INFO:root:current mean train loss 1227.989253598638
INFO:root:current train perplexity2.631619691848755
INFO:root:current mean train loss 1228.0673147051104
INFO:root:current train perplexity2.6349427700042725
INFO:root:current mean train loss 1228.375459036366
INFO:root:current train perplexity2.634341239929199
INFO:root:current mean train loss 1228.9315764560092
INFO:root:current train perplexity2.634916305541992
INFO:root:current mean train loss 1228.9355630651846
INFO:root:current train perplexity2.6356470584869385
INFO:root:current mean train loss 1228.72319457409
INFO:root:current train perplexity2.6354799270629883
INFO:root:current mean train loss 1229.2469259385743
INFO:root:current train perplexity2.6354246139526367
INFO:root:current mean train loss 1229.4784157629313
INFO:root:current train perplexity2.6357178688049316
INFO:root:current mean train loss 1228.9551901582631
INFO:root:current train perplexity2.635565757751465
INFO:root:current mean train loss 1229.0039230872844
INFO:root:current train perplexity2.6355361938476562
INFO:root:current mean train loss 1229.1441237366007
INFO:root:current train perplexity2.634876251220703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.58s/it]
INFO:root:final mean train loss: 1228.4995489615835
INFO:root:final train perplexity: 2.6349616050720215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2322.790638159353
INFO:root:eval perplexity: 6.54392147064209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2906.5970441669438
INFO:root:eval perplexity: 10.7735595703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [32:28:31<2:35:49, 623.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.5305730646307
INFO:root:current train perplexity2.64215350151062
INFO:root:current mean train loss 1227.2743437025283
INFO:root:current train perplexity2.633605718612671
INFO:root:current mean train loss 1226.2628273885757
INFO:root:current train perplexity2.6307573318481445
INFO:root:current mean train loss 1226.791774661042
INFO:root:current train perplexity2.6310932636260986
INFO:root:current mean train loss 1226.5424900914097
INFO:root:current train perplexity2.6311111450195312
INFO:root:current mean train loss 1224.9136541029986
INFO:root:current train perplexity2.631838321685791
INFO:root:current mean train loss 1224.3762898889388
INFO:root:current train perplexity2.630481719970703
INFO:root:current mean train loss 1224.987777874034
INFO:root:current train perplexity2.6298999786376953
INFO:root:current mean train loss 1227.5239050987207
INFO:root:current train perplexity2.630671501159668
INFO:root:current mean train loss 1226.8800152277543
INFO:root:current train perplexity2.631108283996582
INFO:root:current mean train loss 1227.363236233649
INFO:root:current train perplexity2.630734443664551
INFO:root:current mean train loss 1227.9888956563457
INFO:root:current train perplexity2.6300692558288574
INFO:root:current mean train loss 1228.2433226361536
INFO:root:current train perplexity2.6309897899627686
INFO:root:current mean train loss 1227.7738638378326
INFO:root:current train perplexity2.6301076412200928
INFO:root:current mean train loss 1228.4930340457822
INFO:root:current train perplexity2.6319477558135986
INFO:root:current mean train loss 1228.2352844396403
INFO:root:current train perplexity2.632119655609131
INFO:root:current mean train loss 1227.906055311217
INFO:root:current train perplexity2.632385015487671
INFO:root:current mean train loss 1227.9452413156491
INFO:root:current train perplexity2.633035659790039
INFO:root:current mean train loss 1228.399707719716
INFO:root:current train perplexity2.634154796600342
INFO:root:current mean train loss 1228.1518767557027
INFO:root:current train perplexity2.6340229511260986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.22s/it]
INFO:root:final mean train loss: 1228.0351256554738
INFO:root:final train perplexity: 2.6339967250823975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2322.26479907746
INFO:root:eval perplexity: 6.541140079498291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2906.4022389946253
INFO:root:eval perplexity: 10.771843910217285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [32:39:08<2:26:22, 627.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.8376284740011
INFO:root:current train perplexity2.617295265197754
INFO:root:current mean train loss 1234.3320555124224
INFO:root:current train perplexity2.628401517868042
INFO:root:current mean train loss 1233.7452219528257
INFO:root:current train perplexity2.631620168685913
INFO:root:current mean train loss 1232.1862732102666
INFO:root:current train perplexity2.634650468826294
INFO:root:current mean train loss 1230.012077811483
INFO:root:current train perplexity2.6320760250091553
INFO:root:current mean train loss 1230.2070153656277
INFO:root:current train perplexity2.6316874027252197
INFO:root:current mean train loss 1229.556163054912
INFO:root:current train perplexity2.63301682472229
INFO:root:current mean train loss 1228.2361382022011
INFO:root:current train perplexity2.6342756748199463
INFO:root:current mean train loss 1228.7765619896015
INFO:root:current train perplexity2.6351280212402344
INFO:root:current mean train loss 1227.6363644793428
INFO:root:current train perplexity2.6337804794311523
INFO:root:current mean train loss 1227.5060215985068
INFO:root:current train perplexity2.6333253383636475
INFO:root:current mean train loss 1226.8134948572756
INFO:root:current train perplexity2.6323981285095215
INFO:root:current mean train loss 1226.5678878409062
INFO:root:current train perplexity2.6325795650482178
INFO:root:current mean train loss 1227.7796102575658
INFO:root:current train perplexity2.6331746578216553
INFO:root:current mean train loss 1228.2804983610326
INFO:root:current train perplexity2.6316144466400146
INFO:root:current mean train loss 1228.4315686027337
INFO:root:current train perplexity2.632676362991333
INFO:root:current mean train loss 1228.18038479267
INFO:root:current train perplexity2.6333632469177246
INFO:root:current mean train loss 1227.8886282735084
INFO:root:current train perplexity2.632920503616333
INFO:root:current mean train loss 1227.566605196404
INFO:root:current train perplexity2.6321167945861816
INFO:root:current mean train loss 1227.5606388167907
INFO:root:current train perplexity2.632553815841675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it]
INFO:root:final mean train loss: 1227.1361381619251
INFO:root:final train perplexity: 2.6321301460266113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2323.658792698637
INFO:root:eval perplexity: 6.54851770401001
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2908.405395074939
INFO:root:eval perplexity: 10.789505004882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [32:49:50<2:16:53, 631.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.2544821714744
INFO:root:current train perplexity2.637549638748169
INFO:root:current mean train loss 1223.2484206296085
INFO:root:current train perplexity2.6326076984405518
INFO:root:current mean train loss 1223.015330362663
INFO:root:current train perplexity2.622209072113037
INFO:root:current mean train loss 1223.1452698076844
INFO:root:current train perplexity2.621537446975708
INFO:root:current mean train loss 1222.1872571362612
INFO:root:current train perplexity2.6219568252563477
INFO:root:current mean train loss 1222.6383977447827
INFO:root:current train perplexity2.624752998352051
INFO:root:current mean train loss 1222.6118036230757
INFO:root:current train perplexity2.625255584716797
INFO:root:current mean train loss 1223.0883046912656
INFO:root:current train perplexity2.624138832092285
INFO:root:current mean train loss 1223.145914898918
INFO:root:current train perplexity2.6258411407470703
INFO:root:current mean train loss 1224.113686902879
INFO:root:current train perplexity2.626587152481079
INFO:root:current mean train loss 1224.4179970594416
INFO:root:current train perplexity2.6277658939361572
INFO:root:current mean train loss 1224.6779554072382
INFO:root:current train perplexity2.6282379627227783
INFO:root:current mean train loss 1225.7513961672596
INFO:root:current train perplexity2.628526210784912
INFO:root:current mean train loss 1226.0767174708308
INFO:root:current train perplexity2.627387285232544
INFO:root:current mean train loss 1226.3556826621173
INFO:root:current train perplexity2.6281075477600098
INFO:root:current mean train loss 1226.401826923791
INFO:root:current train perplexity2.627466917037964
INFO:root:current mean train loss 1226.1244559941615
INFO:root:current train perplexity2.627307415008545
INFO:root:current mean train loss 1226.2555992375342
INFO:root:current train perplexity2.62786602973938
INFO:root:current mean train loss 1226.6745299967968
INFO:root:current train perplexity2.6293864250183105
INFO:root:current mean train loss 1226.5147840231807
INFO:root:current train perplexity2.630040407180786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it]
INFO:root:final mean train loss: 1226.2193502867638
INFO:root:final train perplexity: 2.63022780418396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2324.4591627188606
INFO:root:eval perplexity: 6.552758693695068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2908.855335857851
INFO:root:eval perplexity: 10.793475151062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [33:00:13<2:05:50, 629.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1225.45486353824
INFO:root:current train perplexity2.630636692047119
INFO:root:current mean train loss 1224.5524482922676
INFO:root:current train perplexity2.6183876991271973
INFO:root:current mean train loss 1224.975506902145
INFO:root:current train perplexity2.6153061389923096
INFO:root:current mean train loss 1223.8614134196994
INFO:root:current train perplexity2.6142494678497314
INFO:root:current mean train loss 1225.2823483862057
INFO:root:current train perplexity2.619483470916748
INFO:root:current mean train loss 1225.1900517824317
INFO:root:current train perplexity2.6218326091766357
INFO:root:current mean train loss 1224.4630638067672
INFO:root:current train perplexity2.6213855743408203
INFO:root:current mean train loss 1223.8821676002358
INFO:root:current train perplexity2.6214756965637207
INFO:root:current mean train loss 1223.894805669518
INFO:root:current train perplexity2.621455669403076
INFO:root:current mean train loss 1224.9775547660176
INFO:root:current train perplexity2.62288236618042
INFO:root:current mean train loss 1224.8741573246646
INFO:root:current train perplexity2.6245763301849365
INFO:root:current mean train loss 1225.3576151444822
INFO:root:current train perplexity2.6256072521209717
INFO:root:current mean train loss 1224.9036188427547
INFO:root:current train perplexity2.6261534690856934
INFO:root:current mean train loss 1224.8707826675907
INFO:root:current train perplexity2.627281904220581
INFO:root:current mean train loss 1225.5064983048965
INFO:root:current train perplexity2.6280124187469482
INFO:root:current mean train loss 1225.6249501004115
INFO:root:current train perplexity2.629127264022827
INFO:root:current mean train loss 1226.157441103775
INFO:root:current train perplexity2.629312038421631
INFO:root:current mean train loss 1226.271334694355
INFO:root:current train perplexity2.630168914794922
INFO:root:current mean train loss 1226.3280476351213
INFO:root:current train perplexity2.630833625793457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.83s/it]
INFO:root:final mean train loss: 1226.1950623882099
INFO:root:final train perplexity: 2.6301772594451904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2324.808139232879
INFO:root:eval perplexity: 6.55460786819458
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2909.4678587135695
INFO:root:eval perplexity: 10.798882484436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [33:10:44<1:55:28, 629.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1224.9420064290364
INFO:root:current train perplexity2.6285271644592285
INFO:root:current mean train loss 1220.6442565917969
INFO:root:current train perplexity2.6095950603485107
INFO:root:current mean train loss 1220.5451435592938
INFO:root:current train perplexity2.6215016841888428
INFO:root:current mean train loss 1221.0494466928335
INFO:root:current train perplexity2.6196951866149902
INFO:root:current mean train loss 1220.4245457325167
INFO:root:current train perplexity2.6187942028045654
INFO:root:current mean train loss 1220.7338228225708
INFO:root:current train perplexity2.622392416000366
INFO:root:current mean train loss 1223.1448555740656
INFO:root:current train perplexity2.6222727298736572
INFO:root:current mean train loss 1223.8677963085388
INFO:root:current train perplexity2.623483896255493
INFO:root:current mean train loss 1224.245571944514
INFO:root:current train perplexity2.625824213027954
INFO:root:current mean train loss 1223.164669371488
INFO:root:current train perplexity2.6265461444854736
INFO:root:current mean train loss 1223.7817932852643
INFO:root:current train perplexity2.626412868499756
INFO:root:current mean train loss 1224.133199787826
INFO:root:current train perplexity2.625873565673828
INFO:root:current mean train loss 1224.5969875826695
INFO:root:current train perplexity2.6256892681121826
INFO:root:current mean train loss 1224.3168080957923
INFO:root:current train perplexity2.626131296157837
INFO:root:current mean train loss 1224.766079997206
INFO:root:current train perplexity2.627073287963867
INFO:root:current mean train loss 1224.9528616446037
INFO:root:current train perplexity2.626631259918213
INFO:root:current mean train loss 1224.7693476901752
INFO:root:current train perplexity2.627285957336426
INFO:root:current mean train loss 1224.7216579401604
INFO:root:current train perplexity2.626918315887451
INFO:root:current mean train loss 1225.0508213337946
INFO:root:current train perplexity2.627333402633667
INFO:root:current mean train loss 1225.2969174564632
INFO:root:current train perplexity2.6279995441436768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.21s/it]
INFO:root:final mean train loss: 1224.9672065461698
INFO:root:final train perplexity: 2.627631187438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2324.949935588431
INFO:root:eval perplexity: 6.555359840393066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 2910.1325337294993
INFO:root:eval perplexity: 10.804754257202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [33:21:11<1:44:48, 628.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.1448890422953
INFO:root:current train perplexity2.618164300918579
INFO:root:current mean train loss 1218.9995836361434
INFO:root:current train perplexity2.6221234798431396
INFO:root:current mean train loss 1220.2270321242154
INFO:root:current train perplexity2.6200931072235107
INFO:root:current mean train loss 1222.1421310285666
INFO:root:current train perplexity2.6235554218292236
INFO:root:current mean train loss 1225.0587903714124
INFO:root:current train perplexity2.6259260177612305
INFO:root:current mean train loss 1224.5466696265064
INFO:root:current train perplexity2.625406503677368
INFO:root:current mean train loss 1223.3162589505291
INFO:root:current train perplexity2.6252708435058594
INFO:root:current mean train loss 1224.67299556863
INFO:root:current train perplexity2.6252682209014893
INFO:root:current mean train loss 1223.9109435961532
INFO:root:current train perplexity2.624537229537964
INFO:root:current mean train loss 1224.6261534264834
INFO:root:current train perplexity2.626666784286499
INFO:root:current mean train loss 1224.2912562067238
INFO:root:current train perplexity2.6272685527801514
INFO:root:current mean train loss 1223.5290462470246
INFO:root:current train perplexity2.627028226852417
INFO:root:current mean train loss 1224.0033819138082
INFO:root:current train perplexity2.6259701251983643
INFO:root:current mean train loss 1224.5416528889791
INFO:root:current train perplexity2.626451015472412
INFO:root:current mean train loss 1224.9711070077415
INFO:root:current train perplexity2.627774953842163
INFO:root:current mean train loss 1225.0530629828525
INFO:root:current train perplexity2.627023935317993
INFO:root:current mean train loss 1225.0106579597336
INFO:root:current train perplexity2.6279051303863525
INFO:root:current mean train loss 1224.5493618737348
INFO:root:current train perplexity2.6275203227996826
INFO:root:current mean train loss 1224.623134773634
INFO:root:current train perplexity2.6273388862609863
INFO:root:current mean train loss 1224.73569568814
INFO:root:current train perplexity2.627016067504883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.77s/it]
INFO:root:final mean train loss: 1224.8829992681938
INFO:root:final train perplexity: 2.6274569034576416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2325.655664322224
INFO:root:eval perplexity: 6.559103012084961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2911.2024964677526
INFO:root:eval perplexity: 10.814212799072266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [33:31:31<1:33:56, 626.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1213.490282141644
INFO:root:current train perplexity2.5940065383911133
INFO:root:current mean train loss 1213.0146526179901
INFO:root:current train perplexity2.6045823097229004
INFO:root:current mean train loss 1218.2752566453887
INFO:root:current train perplexity2.6176204681396484
INFO:root:current mean train loss 1219.9373359459673
INFO:root:current train perplexity2.6219236850738525
INFO:root:current mean train loss 1220.0771418686938
INFO:root:current train perplexity2.620328187942505
INFO:root:current mean train loss 1220.4717876727764
INFO:root:current train perplexity2.620805263519287
INFO:root:current mean train loss 1220.9085273860778
INFO:root:current train perplexity2.621931314468384
INFO:root:current mean train loss 1221.2008185910795
INFO:root:current train perplexity2.621370792388916
INFO:root:current mean train loss 1222.1575702640182
INFO:root:current train perplexity2.6204841136932373
INFO:root:current mean train loss 1221.9703513663617
INFO:root:current train perplexity2.619950532913208
INFO:root:current mean train loss 1222.7806436163062
INFO:root:current train perplexity2.6204380989074707
INFO:root:current mean train loss 1223.1930001942899
INFO:root:current train perplexity2.620326280593872
INFO:root:current mean train loss 1223.486994221352
INFO:root:current train perplexity2.6225640773773193
INFO:root:current mean train loss 1223.7726784149215
INFO:root:current train perplexity2.6234798431396484
INFO:root:current mean train loss 1223.636664721646
INFO:root:current train perplexity2.6240077018737793
INFO:root:current mean train loss 1223.4519647793197
INFO:root:current train perplexity2.624504327774048
INFO:root:current mean train loss 1223.6765442265341
INFO:root:current train perplexity2.6252617835998535
INFO:root:current mean train loss 1224.170923187151
INFO:root:current train perplexity2.6254658699035645
INFO:root:current mean train loss 1224.6236197987203
INFO:root:current train perplexity2.6259567737579346
INFO:root:current mean train loss 1224.3744533809336
INFO:root:current train perplexity2.6255414485931396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.76s/it]
INFO:root:final mean train loss: 1224.0849917782598
INFO:root:final train perplexity: 2.6258041858673096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2326.3920565124945
INFO:root:eval perplexity: 6.563010215759277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 2911.895793508976
INFO:root:eval perplexity: 10.820350646972656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [33:41:58<1:23:30, 626.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1242.8293437655009
INFO:root:current train perplexity2.612978935241699
INFO:root:current mean train loss 1224.7514521124904
INFO:root:current train perplexity2.626603126525879
INFO:root:current mean train loss 1222.1089187448015
INFO:root:current train perplexity2.6241350173950195
INFO:root:current mean train loss 1224.576085114282
INFO:root:current train perplexity2.6216135025024414
INFO:root:current mean train loss 1225.6612485551937
INFO:root:current train perplexity2.6216633319854736
INFO:root:current mean train loss 1224.8527216259158
INFO:root:current train perplexity2.623180627822876
INFO:root:current mean train loss 1225.4188291339674
INFO:root:current train perplexity2.625019073486328
INFO:root:current mean train loss 1225.6523003934408
INFO:root:current train perplexity2.624314308166504
INFO:root:current mean train loss 1224.3083248558353
INFO:root:current train perplexity2.623321056365967
INFO:root:current mean train loss 1224.0678132909852
INFO:root:current train perplexity2.6233808994293213
INFO:root:current mean train loss 1224.305352628175
INFO:root:current train perplexity2.6251368522644043
INFO:root:current mean train loss 1224.0567918746306
INFO:root:current train perplexity2.624774694442749
INFO:root:current mean train loss 1224.367690375563
INFO:root:current train perplexity2.625150680541992
INFO:root:current mean train loss 1223.9467899717133
INFO:root:current train perplexity2.6246800422668457
INFO:root:current mean train loss 1223.7370088985335
INFO:root:current train perplexity2.6256487369537354
INFO:root:current mean train loss 1223.7448803882758
INFO:root:current train perplexity2.62514591217041
INFO:root:current mean train loss 1223.781145252955
INFO:root:current train perplexity2.624803066253662
INFO:root:current mean train loss 1224.2527253599378
INFO:root:current train perplexity2.62410044670105
INFO:root:current mean train loss 1224.0984832223103
INFO:root:current train perplexity2.624558448791504
INFO:root:current mean train loss 1223.5665247135482
INFO:root:current train perplexity2.6245498657226562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.50s/it]
INFO:root:final mean train loss: 1223.4559160579772
INFO:root:final train perplexity: 2.6245017051696777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2326.4222490026596
INFO:root:eval perplexity: 6.563169479370117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2911.9815154379985
INFO:root:eval perplexity: 10.821104049682617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [33:52:19<1:12:54, 624.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.7262832641602
INFO:root:current train perplexity2.6229634284973145
INFO:root:current mean train loss 1222.5257554796008
INFO:root:current train perplexity2.6256866455078125
INFO:root:current mean train loss 1221.1450897216796
INFO:root:current train perplexity2.6259384155273438
INFO:root:current mean train loss 1222.1353656969573
INFO:root:current train perplexity2.627187728881836
INFO:root:current mean train loss 1222.951197052002
INFO:root:current train perplexity2.623927593231201
INFO:root:current mean train loss 1222.3429115032327
INFO:root:current train perplexity2.6221625804901123
INFO:root:current mean train loss 1221.2129040886375
INFO:root:current train perplexity2.619192361831665
INFO:root:current mean train loss 1221.327388665615
INFO:root:current train perplexity2.6196582317352295
INFO:root:current mean train loss 1221.447608531605
INFO:root:current train perplexity2.6190876960754395
INFO:root:current mean train loss 1221.4437336824378
INFO:root:current train perplexity2.618669271469116
INFO:root:current mean train loss 1221.3467641194661
INFO:root:current train perplexity2.619168996810913
INFO:root:current mean train loss 1222.240595723815
INFO:root:current train perplexity2.6204421520233154
INFO:root:current mean train loss 1222.127101802826
INFO:root:current train perplexity2.6200876235961914
INFO:root:current mean train loss 1222.3778497225996
INFO:root:current train perplexity2.6200332641601562
INFO:root:current mean train loss 1221.8947998046874
INFO:root:current train perplexity2.620173692703247
INFO:root:current mean train loss 1221.381481856334
INFO:root:current train perplexity2.6204705238342285
INFO:root:current mean train loss 1221.296278236026
INFO:root:current train perplexity2.6205008029937744
INFO:root:current mean train loss 1222.0467647938247
INFO:root:current train perplexity2.6212992668151855
INFO:root:current mean train loss 1222.289039774144
INFO:root:current train perplexity2.622093439102173
INFO:root:current mean train loss 1222.4731075402462
INFO:root:current train perplexity2.6218488216400146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.76s/it]
INFO:root:final mean train loss: 1222.1131103023158
INFO:root:final train perplexity: 2.6217234134674072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2327.506355447972
INFO:root:eval perplexity: 6.56892728805542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 2912.997350814495
INFO:root:eval perplexity: 10.830099105834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [34:02:45<1:02:30, 625.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1212.7876630960052
INFO:root:current train perplexity2.6210179328918457
INFO:root:current mean train loss 1214.9077929191783
INFO:root:current train perplexity2.615882396697998
INFO:root:current mean train loss 1217.9271371757943
INFO:root:current train perplexity2.621199607849121
INFO:root:current mean train loss 1220.1608074966546
INFO:root:current train perplexity2.6173317432403564
INFO:root:current mean train loss 1220.4250900913291
INFO:root:current train perplexity2.6155753135681152
INFO:root:current mean train loss 1219.4180084177397
INFO:root:current train perplexity2.6166458129882812
INFO:root:current mean train loss 1219.816037061738
INFO:root:current train perplexity2.620659351348877
INFO:root:current mean train loss 1220.154668293454
INFO:root:current train perplexity2.619885206222534
INFO:root:current mean train loss 1221.2055527975194
INFO:root:current train perplexity2.6196348667144775
INFO:root:current mean train loss 1221.0351443735503
INFO:root:current train perplexity2.6210179328918457
INFO:root:current mean train loss 1221.21128301351
INFO:root:current train perplexity2.621358633041382
INFO:root:current mean train loss 1221.5632674010874
INFO:root:current train perplexity2.6219899654388428
INFO:root:current mean train loss 1221.9880614857905
INFO:root:current train perplexity2.6211259365081787
INFO:root:current mean train loss 1222.2265818110516
INFO:root:current train perplexity2.6214711666107178
INFO:root:current mean train loss 1221.9941399726536
INFO:root:current train perplexity2.6219022274017334
INFO:root:current mean train loss 1222.6052693251752
INFO:root:current train perplexity2.621624708175659
INFO:root:current mean train loss 1222.7657691537456
INFO:root:current train perplexity2.6222503185272217
INFO:root:current mean train loss 1223.0952392985705
INFO:root:current train perplexity2.622602939605713
INFO:root:current mean train loss 1223.0515717791454
INFO:root:current train perplexity2.622422218322754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.86s/it]
INFO:root:final mean train loss: 1222.6369823123011
INFO:root:final train perplexity: 2.622807025909424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2327.197235756732
INFO:root:eval perplexity: 6.56728458404541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2912.843235746343
INFO:root:eval perplexity: 10.828736305236816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [34:13:06<51:59, 623.83s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1196.645795549665
INFO:root:current train perplexity2.621680498123169
INFO:root:current mean train loss 1222.8481059827302
INFO:root:current train perplexity2.627119541168213
INFO:root:current mean train loss 1223.5220707688377
INFO:root:current train perplexity2.623270034790039
INFO:root:current mean train loss 1222.3426785803144
INFO:root:current train perplexity2.619621753692627
INFO:root:current mean train loss 1222.2168573204447
INFO:root:current train perplexity2.620129346847534
INFO:root:current mean train loss 1222.2030045921238
INFO:root:current train perplexity2.6221277713775635
INFO:root:current mean train loss 1221.193554806787
INFO:root:current train perplexity2.621427297592163
INFO:root:current mean train loss 1221.800092766599
INFO:root:current train perplexity2.621600866317749
INFO:root:current mean train loss 1222.1945392880452
INFO:root:current train perplexity2.620414972305298
INFO:root:current mean train loss 1222.5103628880606
INFO:root:current train perplexity2.6213274002075195
INFO:root:current mean train loss 1221.8837398250662
INFO:root:current train perplexity2.6213417053222656
INFO:root:current mean train loss 1221.3066511445243
INFO:root:current train perplexity2.620712995529175
INFO:root:current mean train loss 1221.5908978382092
INFO:root:current train perplexity2.6206464767456055
INFO:root:current mean train loss 1221.4070415990357
INFO:root:current train perplexity2.620266914367676
INFO:root:current mean train loss 1221.498152456324
INFO:root:current train perplexity2.620279550552368
INFO:root:current mean train loss 1222.1558361381017
INFO:root:current train perplexity2.6195356845855713
INFO:root:current mean train loss 1222.4892187106714
INFO:root:current train perplexity2.6200926303863525
INFO:root:current mean train loss 1222.3524723297796
INFO:root:current train perplexity2.6204144954681396
INFO:root:current mean train loss 1222.5395412255805
INFO:root:current train perplexity2.621022939682007
INFO:root:current mean train loss 1222.4002615391523
INFO:root:current train perplexity2.6208415031433105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.45s/it]
INFO:root:final mean train loss: 1221.8988005714589
INFO:root:final train perplexity: 2.6212801933288574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2327.391331449468
INFO:root:eval perplexity: 6.568315029144287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it]
INFO:root:eval mean loss: 2912.629732605413
INFO:root:eval perplexity: 10.8268461227417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [34:23:27<41:31, 622.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1211.3888096963205
INFO:root:current train perplexity2.633559465408325
INFO:root:current mean train loss 1222.2771415419252
INFO:root:current train perplexity2.623623847961426
INFO:root:current mean train loss 1225.0954880487352
INFO:root:current train perplexity2.6199402809143066
INFO:root:current mean train loss 1223.3247210453644
INFO:root:current train perplexity2.618896484375
INFO:root:current mean train loss 1223.511035892637
INFO:root:current train perplexity2.6211490631103516
INFO:root:current mean train loss 1225.2178932089366
INFO:root:current train perplexity2.623478651046753
INFO:root:current mean train loss 1224.8583212488238
INFO:root:current train perplexity2.621523141860962
INFO:root:current mean train loss 1224.3887857627608
INFO:root:current train perplexity2.6219396591186523
INFO:root:current mean train loss 1224.4785314897338
INFO:root:current train perplexity2.6224470138549805
INFO:root:current mean train loss 1224.0455237039305
INFO:root:current train perplexity2.6227173805236816
INFO:root:current mean train loss 1223.181876477631
INFO:root:current train perplexity2.6221940517425537
INFO:root:current mean train loss 1222.0750745373632
INFO:root:current train perplexity2.621767997741699
INFO:root:current mean train loss 1222.3299016139065
INFO:root:current train perplexity2.6209793090820312
INFO:root:current mean train loss 1222.3784383290877
INFO:root:current train perplexity2.6213550567626953
INFO:root:current mean train loss 1222.0613646010765
INFO:root:current train perplexity2.6215312480926514
INFO:root:current mean train loss 1221.571572192271
INFO:root:current train perplexity2.620900869369507
INFO:root:current mean train loss 1220.9713857008737
INFO:root:current train perplexity2.6197547912597656
INFO:root:current mean train loss 1220.9779231150255
INFO:root:current train perplexity2.619338035583496
INFO:root:current mean train loss 1221.2593118114462
INFO:root:current train perplexity2.6202120780944824
INFO:root:current mean train loss 1221.600895001072
INFO:root:current train perplexity2.6202609539031982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.84s/it]
INFO:root:final mean train loss: 1221.1355932931135
INFO:root:final train perplexity: 2.6197028160095215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2327.5784115622228
INFO:root:eval perplexity: 6.569310188293457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 2913.2579016719305
INFO:root:eval perplexity: 10.83240795135498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [34:33:47<31:06, 622.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1219.3518931070964
INFO:root:current train perplexity2.6260287761688232
INFO:root:current mean train loss 1217.8178545977619
INFO:root:current train perplexity2.620420217514038
INFO:root:current mean train loss 1217.0071416055002
INFO:root:current train perplexity2.6150968074798584
INFO:root:current mean train loss 1218.4459291655442
INFO:root:current train perplexity2.6139681339263916
INFO:root:current mean train loss 1217.3738019125801
INFO:root:current train perplexity2.6137149333953857
INFO:root:current mean train loss 1218.7624703288948
INFO:root:current train perplexity2.6109225749969482
INFO:root:current mean train loss 1218.608745056906
INFO:root:current train perplexity2.612424850463867
INFO:root:current mean train loss 1218.5683497464593
INFO:root:current train perplexity2.613626003265381
INFO:root:current mean train loss 1219.4806607804207
INFO:root:current train perplexity2.6141133308410645
INFO:root:current mean train loss 1219.6653669011241
INFO:root:current train perplexity2.617100238800049
INFO:root:current mean train loss 1220.538573053957
INFO:root:current train perplexity2.6184775829315186
INFO:root:current mean train loss 1220.5687518501945
INFO:root:current train perplexity2.619398832321167
INFO:root:current mean train loss 1221.3199700575608
INFO:root:current train perplexity2.6207664012908936
INFO:root:current mean train loss 1222.0535724764409
INFO:root:current train perplexity2.621337413787842
INFO:root:current mean train loss 1222.1193657132144
INFO:root:current train perplexity2.6200222969055176
INFO:root:current mean train loss 1221.9977528180264
INFO:root:current train perplexity2.619821786880493
INFO:root:current mean train loss 1221.642445240206
INFO:root:current train perplexity2.6193788051605225
INFO:root:current mean train loss 1221.3344507282877
INFO:root:current train perplexity2.6192173957824707
INFO:root:current mean train loss 1221.5889469823796
INFO:root:current train perplexity2.619368076324463
INFO:root:current mean train loss 1221.412505288878
INFO:root:current train perplexity2.619415044784546

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.09s/it]
INFO:root:final mean train loss: 1220.885249704889
INFO:root:final train perplexity: 2.6191859245300293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 2327.910541507369
INFO:root:eval perplexity: 6.57107400894165
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2913.660162743102
INFO:root:eval perplexity: 10.835969924926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [34:44:08<20:43, 621.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1205.9424879807693
INFO:root:current train perplexity2.6235499382019043
INFO:root:current mean train loss 1214.9562855113636
INFO:root:current train perplexity2.617281436920166
INFO:root:current mean train loss 1219.1237760723761
INFO:root:current train perplexity2.622357130050659
INFO:root:current mean train loss 1219.0257785744864
INFO:root:current train perplexity2.6265323162078857
INFO:root:current mean train loss 1220.598254000756
INFO:root:current train perplexity2.6258127689361572
INFO:root:current mean train loss 1220.6020352253872
INFO:root:current train perplexity2.6255714893341064
INFO:root:current mean train loss 1220.3325980968045
INFO:root:current train perplexity2.6253740787506104
INFO:root:current mean train loss 1220.2185304330064
INFO:root:current train perplexity2.6250088214874268
INFO:root:current mean train loss 1220.2901162560966
INFO:root:current train perplexity2.6243691444396973
INFO:root:current mean train loss 1220.5548181721583
INFO:root:current train perplexity2.625840187072754
INFO:root:current mean train loss 1221.2729313380282
INFO:root:current train perplexity2.6249091625213623
INFO:root:current mean train loss 1221.2139100430861
INFO:root:current train perplexity2.623317003250122
INFO:root:current mean train loss 1221.3003107244317
INFO:root:current train perplexity2.6234824657440186
INFO:root:current mean train loss 1221.4485246036515
INFO:root:current train perplexity2.6223959922790527
INFO:root:current mean train loss 1220.761395284503
INFO:root:current train perplexity2.6217291355133057
INFO:root:current mean train loss 1221.3913469698482
INFO:root:current train perplexity2.6213722229003906
INFO:root:current mean train loss 1221.2023019601634
INFO:root:current train perplexity2.6211750507354736
INFO:root:current mean train loss 1221.2235647574362
INFO:root:current train perplexity2.6198575496673584
INFO:root:current mean train loss 1221.1366364098108
INFO:root:current train perplexity2.6194567680358887
INFO:root:current mean train loss 1221.2138900485052
INFO:root:current train perplexity2.6192123889923096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.10s/it]
INFO:root:final mean train loss: 1220.835356265562
INFO:root:final train perplexity: 2.6190829277038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2327.7628896726783
INFO:root:eval perplexity: 6.5702900886535645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2913.4536821081283
INFO:root:eval perplexity: 10.83414077758789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [34:54:41<10:25, 625.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1203.6881148175496
INFO:root:current train perplexity2.622149705886841
INFO:root:current mean train loss 1213.8879656110491
INFO:root:current train perplexity2.616459369659424
INFO:root:current mean train loss 1216.6952588236925
INFO:root:current train perplexity2.6175267696380615
INFO:root:current mean train loss 1215.21993235643
INFO:root:current train perplexity2.614283800125122
INFO:root:current mean train loss 1217.972698544071
INFO:root:current train perplexity2.6156160831451416
INFO:root:current mean train loss 1219.4358140873335
INFO:root:current train perplexity2.6172597408294678
INFO:root:current mean train loss 1219.819642008225
INFO:root:current train perplexity2.617486000061035
INFO:root:current mean train loss 1220.7145234325048
INFO:root:current train perplexity2.616811990737915
INFO:root:current mean train loss 1219.9110472802402
INFO:root:current train perplexity2.617006301879883
INFO:root:current mean train loss 1219.6779993993443
INFO:root:current train perplexity2.6185224056243896
INFO:root:current mean train loss 1220.7852459412186
INFO:root:current train perplexity2.619075298309326
INFO:root:current mean train loss 1220.4850232532585
INFO:root:current train perplexity2.6187753677368164
INFO:root:current mean train loss 1220.7709774308942
INFO:root:current train perplexity2.6189587116241455
INFO:root:current mean train loss 1220.9807277298526
INFO:root:current train perplexity2.6193227767944336
INFO:root:current mean train loss 1220.7956689173072
INFO:root:current train perplexity2.6192095279693604
INFO:root:current mean train loss 1220.8667181620253
INFO:root:current train perplexity2.6193737983703613
INFO:root:current mean train loss 1221.3071116698059
INFO:root:current train perplexity2.6191375255584717
INFO:root:current mean train loss 1221.261569724206
INFO:root:current train perplexity2.619213819503784
INFO:root:current mean train loss 1221.1494962751042
INFO:root:current train perplexity2.6194663047790527
INFO:root:current mean train loss 1221.2106763914783
INFO:root:current train perplexity2.6192071437835693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.69s/it]
INFO:root:final mean train loss: 1220.8956032895826
INFO:root:final train perplexity: 2.6192076206207275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2327.677390673482
INFO:root:eval perplexity: 6.569836616516113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2913.3664702286956
INFO:root:eval perplexity: 10.83337116241455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil12_minilml12/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:05:03<00:00, 624.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:05:04<00:00, 631.52s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.74s/it]
INFO:root:eval mean loss: 2327.677390673482
INFO:root:eval perplexity: 6.569836616516113
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.67s/it]
INFO:root:eval mean loss: 2913.3664702286956
INFO:root:eval perplexity: 10.83337116241455
INFO:root:evalaution complete
INFO:root:save model final: allminil12_minilml12/final
