INFO:root:Output: distilgpt2_baseline
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Using pad_token, but it is not set yet.
INFO:root:pad token is not set, adding [PAD] to tokenizer and embedding
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 53309.39859532828
INFO:root:current train perplexity1.7545973130895924e+20
INFO:root:current mean train loss 34536.44292752827
INFO:root:current train perplexity15456061620224.0
INFO:root:current mean train loss 24631.633817640835
INFO:root:current train perplexity2520983296.0
INFO:root:current mean train loss 19456.538190569197
INFO:root:current train perplexity26634990.0
INFO:root:current mean train loss 16292.392339855493
INFO:root:current train perplexity1635020.875
INFO:root:current mean train loss 14157.438243834125
INFO:root:current train perplexity244972.5
INFO:root:current mean train loss 12610.980102713698
INFO:root:current train perplexity62645.19921875
INFO:root:current mean train loss 11443.625858617217
INFO:root:current train perplexity22386.416015625
INFO:root:current mean train loss 10522.137703459573
INFO:root:current train perplexity9955.677734375
INFO:root:current mean train loss 9775.592554224146
INFO:root:current train perplexity5235.89208984375
INFO:root:current mean train loss 9163.107819964172
INFO:root:current train perplexity3060.693359375
INFO:root:current mean train loss 8649.124732646671
INFO:root:current train perplexity1949.6527099609375
INFO:root:current mean train loss 8209.868445040356
INFO:root:current train perplexity1331.5245361328125
INFO:root:current mean train loss 7829.957912878619
INFO:root:current train perplexity957.4874877929688
INFO:root:current mean train loss 7499.357258843135
INFO:root:current train perplexity718.3903198242188
INFO:root:current mean train loss 7209.994667382446
INFO:root:current train perplexity557.937744140625
INFO:root:current mean train loss 6951.364729424938
INFO:root:current train perplexity445.4490966796875
INFO:root:current mean train loss 6721.650013489482
INFO:root:current train perplexity364.2229309082031
INFO:root:current mean train loss 6513.2186978035315
INFO:root:current train perplexity304.2035827636719

100%|██████████| 1/1 [05:36<00:00, 336.40s/it][A100%|██████████| 1/1 [05:36<00:00, 336.40s/it]
INFO:root:final mean train loss: 6354.497192998397
INFO:root:final train perplexity: 265.0820617675781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 2527.284943276263
INFO:root:eval perplexity: 9.794341087341309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2728.927914883228
INFO:root:eval perplexity: 12.276350975036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/1
  0%|          | 1/200 [06:08<20:22:29, 368.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2776.800827026367
INFO:root:current train perplexity11.112446784973145
INFO:root:current mean train loss 2766.1645297346445
INFO:root:current train perplexity10.993558883666992
INFO:root:current mean train loss 2739.242218017578
INFO:root:current train perplexity10.93664836883545
INFO:root:current mean train loss 2728.582012707674
INFO:root:current train perplexity10.869662284851074
INFO:root:current mean train loss 2716.7721692598784
INFO:root:current train perplexity10.749946594238281
INFO:root:current mean train loss 2710.6968639285064
INFO:root:current train perplexity10.6769380569458
INFO:root:current mean train loss 2700.5430519797587
INFO:root:current train perplexity10.614386558532715
INFO:root:current mean train loss 2684.1032309079305
INFO:root:current train perplexity10.516200065612793
INFO:root:current mean train loss 2674.0792508592795
INFO:root:current train perplexity10.434591293334961
INFO:root:current mean train loss 2667.6479153695586
INFO:root:current train perplexity10.368057250976562
INFO:root:current mean train loss 2658.071178766686
INFO:root:current train perplexity10.287761688232422
INFO:root:current mean train loss 2652.6729108475442
INFO:root:current train perplexity10.237709999084473
INFO:root:current mean train loss 2644.2422955161646
INFO:root:current train perplexity10.169319152832031
INFO:root:current mean train loss 2638.454951787792
INFO:root:current train perplexity10.114389419555664
INFO:root:current mean train loss 2631.3694875253796
INFO:root:current train perplexity10.056581497192383
INFO:root:current mean train loss 2627.9283257235325
INFO:root:current train perplexity10.010443687438965
INFO:root:current mean train loss 2622.3350461449954
INFO:root:current train perplexity9.956289291381836
INFO:root:current mean train loss 2614.214493900468
INFO:root:current train perplexity9.903936386108398
INFO:root:current mean train loss 2604.57010828766
INFO:root:current train perplexity9.84599494934082
INFO:root:current mean train loss 2599.8516581939507
INFO:root:current train perplexity9.794294357299805

100%|██████████| 1/1 [05:35<00:00, 335.21s/it][A100%|██████████| 1/1 [05:35<00:00, 335.21s/it]
INFO:root:final mean train loss: 2594.9129525404414
INFO:root:final train perplexity: 9.763556480407715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 2281.6426058289007
INFO:root:eval perplexity: 7.846145153045654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2527.1447944370566
INFO:root:eval perplexity: 10.1986083984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/2
  1%|          | 2/200 [12:15<20:13:59, 367.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2458.549553148674
INFO:root:current train perplexity8.627556800842285
INFO:root:current mean train loss 2461.3585535494008
INFO:root:current train perplexity8.644384384155273
INFO:root:current mean train loss 2447.51931854379
INFO:root:current train perplexity8.604022026062012
INFO:root:current mean train loss 2443.34777575427
INFO:root:current train perplexity8.566108703613281
INFO:root:current mean train loss 2446.0186558959117
INFO:root:current train perplexity8.568804740905762
INFO:root:current mean train loss 2449.3805604974054
INFO:root:current train perplexity8.55756950378418
INFO:root:current mean train loss 2444.5424758404915
INFO:root:current train perplexity8.532815933227539
INFO:root:current mean train loss 2441.3272217129947
INFO:root:current train perplexity8.499319076538086
INFO:root:current mean train loss 2436.731560055663
INFO:root:current train perplexity8.480998039245605
INFO:root:current mean train loss 2435.0143191224124
INFO:root:current train perplexity8.462647438049316
INFO:root:current mean train loss 2430.819877986409
INFO:root:current train perplexity8.43950080871582
INFO:root:current mean train loss 2427.5938680839035
INFO:root:current train perplexity8.41752815246582
INFO:root:current mean train loss 2424.640945570699
INFO:root:current train perplexity8.388496398925781
INFO:root:current mean train loss 2420.2014988915685
INFO:root:current train perplexity8.366878509521484
INFO:root:current mean train loss 2416.682577917148
INFO:root:current train perplexity8.342631340026855
INFO:root:current mean train loss 2413.930038422288
INFO:root:current train perplexity8.320544242858887
INFO:root:current mean train loss 2412.4145733564087
INFO:root:current train perplexity8.307319641113281
INFO:root:current mean train loss 2411.067513546776
INFO:root:current train perplexity8.29416275024414
INFO:root:current mean train loss 2407.480698505907
INFO:root:current train perplexity8.271342277526855
INFO:root:current mean train loss 2404.553258210097
INFO:root:current train perplexity8.254789352416992

100%|██████████| 1/1 [05:35<00:00, 335.05s/it][A100%|██████████| 1/1 [05:35<00:00, 335.05s/it]
INFO:root:final mean train loss: 2402.9784068513027
INFO:root:final train perplexity: 8.24918270111084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 2171.33340822044
INFO:root:eval perplexity: 7.102362632751465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2447.289719601895
INFO:root:eval perplexity: 9.47702693939209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/3
  2%|▏         | 3/200 [18:23<20:06:56, 367.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2317.0938940429687
INFO:root:current train perplexity7.807400703430176
INFO:root:current mean train loss 2336.7811458333335
INFO:root:current train perplexity7.765014171600342
INFO:root:current mean train loss 2328.8229208984376
INFO:root:current train perplexity7.723010540008545
INFO:root:current mean train loss 2324.169756905692
INFO:root:current train perplexity7.699653625488281
INFO:root:current mean train loss 2320.0782695855037
INFO:root:current train perplexity7.678826332092285
INFO:root:current mean train loss 2317.8380506480826
INFO:root:current train perplexity7.671658515930176
INFO:root:current mean train loss 2315.97661733774
INFO:root:current train perplexity7.658041954040527
INFO:root:current mean train loss 2316.946700683594
INFO:root:current train perplexity7.662432670593262
INFO:root:current mean train loss 2314.433845358456
INFO:root:current train perplexity7.6452956199646
INFO:root:current mean train loss 2315.6659881270557
INFO:root:current train perplexity7.632343292236328
INFO:root:current mean train loss 2313.330897391183
INFO:root:current train perplexity7.622783184051514
INFO:root:current mean train loss 2312.408234650985
INFO:root:current train perplexity7.612022399902344
INFO:root:current mean train loss 2311.0132490234373
INFO:root:current train perplexity7.5988850593566895
INFO:root:current mean train loss 2308.539864818432
INFO:root:current train perplexity7.585987567901611
INFO:root:current mean train loss 2306.153090315194
INFO:root:current train perplexity7.571120738983154
INFO:root:current mean train loss 2305.592743825605
INFO:root:current train perplexity7.558225154876709
INFO:root:current mean train loss 2304.0339888879025
INFO:root:current train perplexity7.5478692054748535
INFO:root:current mean train loss 2302.100244001116
INFO:root:current train perplexity7.540005207061768
INFO:root:current mean train loss 2298.3765105706293
INFO:root:current train perplexity7.525844097137451
INFO:root:current mean train loss 2296.26971091246
INFO:root:current train perplexity7.511874198913574

100%|██████████| 1/1 [05:35<00:00, 335.25s/it][A100%|██████████| 1/1 [05:35<00:00, 335.25s/it]
INFO:root:final mean train loss: 2295.4703697862496
INFO:root:final train perplexity: 7.506046772003174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.61s/it][A100%|██████████| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 2105.501811142509
INFO:root:eval perplexity: 6.6925201416015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 2396.4553568955007
INFO:root:eval perplexity: 9.04450798034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/4
  2%|▏         | 4/200 [24:30<20:00:32, 367.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2224.5387837424205
INFO:root:current train perplexity7.15129280090332
INFO:root:current mean train loss 2226.666974644461
INFO:root:current train perplexity7.159547328948975
INFO:root:current mean train loss 2232.4059189928603
INFO:root:current train perplexity7.167206764221191
INFO:root:current mean train loss 2239.6499598864316
INFO:root:current train perplexity7.160205364227295
INFO:root:current mean train loss 2236.6013899809286
INFO:root:current train perplexity7.149938106536865
INFO:root:current mean train loss 2242.4061453683034
INFO:root:current train perplexity7.1650390625
INFO:root:current mean train loss 2242.274170653931
INFO:root:current train perplexity7.1626715660095215
INFO:root:current mean train loss 2237.9136264209174
INFO:root:current train perplexity7.151976585388184
INFO:root:current mean train loss 2238.3546353772435
INFO:root:current train perplexity7.1451897621154785
INFO:root:current mean train loss 2236.85438816895
INFO:root:current train perplexity7.14045524597168
INFO:root:current mean train loss 2235.844105571257
INFO:root:current train perplexity7.130007743835449
INFO:root:current mean train loss 2235.581025922002
INFO:root:current train perplexity7.122403621673584
INFO:root:current mean train loss 2235.7164744051215
INFO:root:current train perplexity7.117067813873291
INFO:root:current mean train loss 2231.5128773910424
INFO:root:current train perplexity7.102238178253174
INFO:root:current mean train loss 2230.002783069988
INFO:root:current train perplexity7.091996192932129
INFO:root:current mean train loss 2229.876934506746
INFO:root:current train perplexity7.086486339569092
INFO:root:current mean train loss 2230.221515071986
INFO:root:current train perplexity7.07855749130249
INFO:root:current mean train loss 2226.709812684591
INFO:root:current train perplexity7.064009666442871
INFO:root:current mean train loss 2225.6550081127393
INFO:root:current train perplexity7.05513334274292
INFO:root:current mean train loss 2224.419592527187
INFO:root:current train perplexity7.046121597290039

100%|██████████| 1/1 [05:35<00:00, 335.07s/it][A100%|██████████| 1/1 [05:35<00:00, 335.08s/it]
INFO:root:final mean train loss: 2223.0400626393684
INFO:root:final train perplexity: 7.043503284454346
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 2060.5017752140125
INFO:root:eval perplexity: 6.4260573387146
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 2364.0710860448526
INFO:root:eval perplexity: 8.77932071685791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/5
  2%|▎         | 5/200 [30:37<19:54:05, 367.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2190.818139939081
INFO:root:current train perplexity6.839908123016357
INFO:root:current mean train loss 2185.7088981296706
INFO:root:current train perplexity6.8128886222839355
INFO:root:current mean train loss 2187.926504215724
INFO:root:current train perplexity6.820869445800781
INFO:root:current mean train loss 2186.804825146993
INFO:root:current train perplexity6.801519870758057
INFO:root:current mean train loss 2184.193306158397
INFO:root:current train perplexity6.78793478012085
INFO:root:current mean train loss 2186.057212516053
INFO:root:current train perplexity6.795170783996582
INFO:root:current mean train loss 2187.9364361679345
INFO:root:current train perplexity6.799993991851807
INFO:root:current mean train loss 2186.4458010926537
INFO:root:current train perplexity6.789085388183594
INFO:root:current mean train loss 2185.027210080246
INFO:root:current train perplexity6.783596992492676
INFO:root:current mean train loss 2181.765227403098
INFO:root:current train perplexity6.7761759757995605
INFO:root:current mean train loss 2179.851679277596
INFO:root:current train perplexity6.764811992645264
INFO:root:current mean train loss 2178.937106983082
INFO:root:current train perplexity6.762630939483643
INFO:root:current mean train loss 2179.2068313170817
INFO:root:current train perplexity6.762546062469482
INFO:root:current mean train loss 2176.8756606261854
INFO:root:current train perplexity6.75014591217041
INFO:root:current mean train loss 2176.6997147634665
INFO:root:current train perplexity6.749605178833008
INFO:root:current mean train loss 2177.067284940469
INFO:root:current train perplexity6.749676704406738
INFO:root:current mean train loss 2174.8573622171216
INFO:root:current train perplexity6.738171100616455
INFO:root:current mean train loss 2173.701296408615
INFO:root:current train perplexity6.7326788902282715
INFO:root:current mean train loss 2170.575535800553
INFO:root:current train perplexity6.726325511932373

100%|██████████| 1/1 [05:34<00:00, 334.74s/it][A100%|██████████| 1/1 [05:34<00:00, 334.74s/it]
INFO:root:final mean train loss: 2169.674397263212
INFO:root:final train perplexity: 6.721048831939697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 2026.2518245615859
INFO:root:eval perplexity: 6.23038387298584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2345.0005900065103
INFO:root:eval perplexity: 8.626810073852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/6
  3%|▎         | 6/200 [36:44<19:47:25, 367.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2378.445556640625
INFO:root:current train perplexity7.6625165939331055
INFO:root:current mean train loss 2129.2056969368814
INFO:root:current train perplexity6.570478916168213
INFO:root:current mean train loss 2136.4045561985
INFO:root:current train perplexity6.533634662628174
INFO:root:current mean train loss 2146.886716722254
INFO:root:current train perplexity6.536961078643799
INFO:root:current mean train loss 2142.618692830911
INFO:root:current train perplexity6.531637191772461
INFO:root:current mean train loss 2142.52441113866
INFO:root:current train perplexity6.52170467376709
INFO:root:current mean train loss 2138.081560842606
INFO:root:current train perplexity6.5108160972595215
INFO:root:current mean train loss 2136.227080907019
INFO:root:current train perplexity6.505593299865723
INFO:root:current mean train loss 2131.6383093216
INFO:root:current train perplexity6.5036516189575195
INFO:root:current mean train loss 2129.4191092471037
INFO:root:current train perplexity6.503349304199219
INFO:root:current mean train loss 2128.891847166505
INFO:root:current train perplexity6.508285045623779
INFO:root:current mean train loss 2130.272584670896
INFO:root:current train perplexity6.505453586578369
INFO:root:current mean train loss 2130.929934689842
INFO:root:current train perplexity6.502042293548584
INFO:root:current mean train loss 2130.208158406544
INFO:root:current train perplexity6.497196674346924
INFO:root:current mean train loss 2129.3304747446023
INFO:root:current train perplexity6.492702007293701
INFO:root:current mean train loss 2130.0801392821454
INFO:root:current train perplexity6.490287780761719
INFO:root:current mean train loss 2129.638163388483
INFO:root:current train perplexity6.488830089569092
INFO:root:current mean train loss 2129.11855137201
INFO:root:current train perplexity6.484195232391357
INFO:root:current mean train loss 2127.912825258754
INFO:root:current train perplexity6.473725318908691
INFO:root:current mean train loss 2126.9804643192524
INFO:root:current train perplexity6.469485282897949

100%|██████████| 1/1 [05:34<00:00, 334.13s/it][A100%|██████████| 1/1 [05:34<00:00, 334.13s/it]
INFO:root:final mean train loss: 2126.206899915148
INFO:root:final train perplexity: 6.46934175491333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.63s/it][A100%|██████████| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 1998.5716327640182
INFO:root:eval perplexity: 6.076606750488281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2327.005207034713
INFO:root:eval perplexity: 8.48532772064209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/7
  4%|▎         | 7/200 [42:51<19:40:15, 366.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.4475775824653
INFO:root:current train perplexity6.221875190734863
INFO:root:current mean train loss 2075.821706998146
INFO:root:current train perplexity6.349066257476807
INFO:root:current mean train loss 2078.887189112672
INFO:root:current train perplexity6.325651168823242
INFO:root:current mean train loss 2091.518425707547
INFO:root:current train perplexity6.3046555519104
INFO:root:current mean train loss 2089.796325975628
INFO:root:current train perplexity6.30150032043457
INFO:root:current mean train loss 2094.750480740227
INFO:root:current train perplexity6.306117534637451
INFO:root:current mean train loss 2096.916191224527
INFO:root:current train perplexity6.315256118774414
INFO:root:current mean train loss 2092.9178079164126
INFO:root:current train perplexity6.304591655731201
INFO:root:current mean train loss 2095.4437582673536
INFO:root:current train perplexity6.303378582000732
INFO:root:current mean train loss 2092.8517285847715
INFO:root:current train perplexity6.293200492858887
INFO:root:current mean train loss 2094.5044089206776
INFO:root:current train perplexity6.290499210357666
INFO:root:current mean train loss 2094.8840419380313
INFO:root:current train perplexity6.2891645431518555
INFO:root:current mean train loss 2095.534222281821
INFO:root:current train perplexity6.289784908294678
INFO:root:current mean train loss 2094.500829300135
INFO:root:current train perplexity6.287855625152588
INFO:root:current mean train loss 2094.8370478405436
INFO:root:current train perplexity6.286856174468994
INFO:root:current mean train loss 2094.185407595829
INFO:root:current train perplexity6.28441047668457
INFO:root:current mean train loss 2092.8652225301057
INFO:root:current train perplexity6.280236721038818
INFO:root:current mean train loss 2091.03718533144
INFO:root:current train perplexity6.274257183074951
INFO:root:current mean train loss 2090.7370702158105
INFO:root:current train perplexity6.272424221038818
INFO:root:current mean train loss 2091.750967652258
INFO:root:current train perplexity6.275844573974609

100%|██████████| 1/1 [05:35<00:00, 335.01s/it][A100%|██████████| 1/1 [05:35<00:00, 335.01s/it]
INFO:root:final mean train loss: 2091.2168592952203
INFO:root:final train perplexity: 6.273589134216309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.60s/it][A100%|██████████| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 1976.0819710805906
INFO:root:eval perplexity: 5.954464435577393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 2312.27854497382
INFO:root:eval perplexity: 8.371273040771484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/8
  4%|▍         | 8/200 [48:58<19:34:21, 366.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2064.6871826171873
INFO:root:current train perplexity6.247076034545898
INFO:root:current mean train loss 2086.733790870949
INFO:root:current train perplexity6.218760013580322
INFO:root:current mean train loss 2071.831318567154
INFO:root:current train perplexity6.178318977355957
INFO:root:current mean train loss 2072.0490387418376
INFO:root:current train perplexity6.178274631500244
INFO:root:current mean train loss 2072.180126953125
INFO:root:current train perplexity6.181166172027588
INFO:root:current mean train loss 2069.339172933703
INFO:root:current train perplexity6.1751604080200195
INFO:root:current mean train loss 2069.024283533772
INFO:root:current train perplexity6.17250919342041
INFO:root:current mean train loss 2064.6587236261694
INFO:root:current train perplexity6.157968044281006
INFO:root:current mean train loss 2065.53089168343
INFO:root:current train perplexity6.158156871795654
INFO:root:current mean train loss 2065.0295804436832
INFO:root:current train perplexity6.1554670333862305
INFO:root:current mean train loss 2061.9958236620623
INFO:root:current train perplexity6.140260219573975
INFO:root:current mean train loss 2061.8426541635117
INFO:root:current train perplexity6.138809680938721
INFO:root:current mean train loss 2062.8522073475456
INFO:root:current train perplexity6.131592750549316
INFO:root:current mean train loss 2063.0846015844454
INFO:root:current train perplexity6.132162094116211
INFO:root:current mean train loss 2061.8914582255825
INFO:root:current train perplexity6.1263628005981445
INFO:root:current mean train loss 2063.3920984324104
INFO:root:current train perplexity6.1285247802734375
INFO:root:current mean train loss 2062.840628210412
INFO:root:current train perplexity6.127010345458984
INFO:root:current mean train loss 2063.3241823751578
INFO:root:current train perplexity6.124602794647217
INFO:root:current mean train loss 2063.807870907485
INFO:root:current train perplexity6.122813701629639
INFO:root:current mean train loss 2062.96598288366
INFO:root:current train perplexity6.116255283355713

100%|██████████| 1/1 [05:34<00:00, 334.83s/it][A100%|██████████| 1/1 [05:34<00:00, 334.83s/it]
INFO:root:final mean train loss: 2061.8623523337037
INFO:root:final train perplexity: 6.1139421463012695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.61s/it][A100%|██████████| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 1959.4719350828348
INFO:root:eval perplexity: 5.865834712982178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 2299.6537661721522
INFO:root:eval perplexity: 8.274715423583984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/9
  4%|▍         | 9/200 [55:05<19:28:12, 366.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.3200073242188
INFO:root:current train perplexity5.971074104309082
INFO:root:current mean train loss 2035.434167159231
INFO:root:current train perplexity5.9688920974731445
INFO:root:current mean train loss 2045.503425719246
INFO:root:current train perplexity6.0066046714782715
INFO:root:current mean train loss 2046.7722837274725
INFO:root:current train perplexity5.989979267120361
INFO:root:current mean train loss 2042.9112429998618
INFO:root:current train perplexity5.977229595184326
INFO:root:current mean train loss 2045.6501705888388
INFO:root:current train perplexity5.9850263595581055
INFO:root:current mean train loss 2044.8013404892997
INFO:root:current train perplexity5.985185623168945
INFO:root:current mean train loss 2043.9289987442341
INFO:root:current train perplexity5.979376792907715
INFO:root:current mean train loss 2043.7636641381491
INFO:root:current train perplexity5.983945369720459
INFO:root:current mean train loss 2045.3916908071822
INFO:root:current train perplexity5.990443229675293
INFO:root:current mean train loss 2042.5715076751128
INFO:root:current train perplexity5.987317085266113
INFO:root:current mean train loss 2041.004304462009
INFO:root:current train perplexity5.980018615722656
INFO:root:current mean train loss 2040.8895087196424
INFO:root:current train perplexity5.979275703430176
INFO:root:current mean train loss 2038.5249747552816
INFO:root:current train perplexity5.97322416305542
INFO:root:current mean train loss 2037.2674773245146
INFO:root:current train perplexity5.973491191864014
INFO:root:current mean train loss 2036.8890935366915
INFO:root:current train perplexity5.973142623901367
INFO:root:current mean train loss 2038.0157983516665
INFO:root:current train perplexity5.977484226226807
INFO:root:current mean train loss 2038.1586721759952
INFO:root:current train perplexity5.976372718811035
INFO:root:current mean train loss 2037.4067178483144
INFO:root:current train perplexity5.973329544067383
INFO:root:current mean train loss 2035.4150050429048
INFO:root:current train perplexity5.970479488372803

100%|██████████| 1/1 [05:34<00:00, 334.78s/it][A100%|██████████| 1/1 [05:34<00:00, 334.78s/it]
INFO:root:final mean train loss: 2034.733849291241
INFO:root:final train perplexity: 5.970016002655029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.61s/it][A100%|██████████| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 1942.6258354457557
INFO:root:eval perplexity: 5.7772908210754395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2290.1138474484706
INFO:root:eval perplexity: 8.202494621276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/10
  5%|▌         | 10/200 [1:01:11<19:21:59, 366.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.6026204427083
INFO:root:current train perplexity5.794965744018555
INFO:root:current mean train loss 2008.696986813517
INFO:root:current train perplexity5.804734706878662
INFO:root:current mean train loss 2011.4101852927508
INFO:root:current train perplexity5.7971320152282715
INFO:root:current mean train loss 2006.3613956110264
INFO:root:current train perplexity5.812312602996826
INFO:root:current mean train loss 2007.0153907499334
INFO:root:current train perplexity5.8189287185668945
INFO:root:current mean train loss 2007.2457798855585
INFO:root:current train perplexity5.8378801345825195
INFO:root:current mean train loss 2009.1326982757614
INFO:root:current train perplexity5.850444316864014
INFO:root:current mean train loss 2008.4830725462757
INFO:root:current train perplexity5.852553367614746
INFO:root:current mean train loss 2009.2919927493886
INFO:root:current train perplexity5.852668285369873
INFO:root:current mean train loss 2011.5631434831334
INFO:root:current train perplexity5.855831146240234
INFO:root:current mean train loss 2013.3814384381942
INFO:root:current train perplexity5.870386600494385
INFO:root:current mean train loss 2014.2728438560937
INFO:root:current train perplexity5.871849060058594
INFO:root:current mean train loss 2013.8166864634125
INFO:root:current train perplexity5.866093158721924
INFO:root:current mean train loss 2014.012890946003
INFO:root:current train perplexity5.865187644958496
INFO:root:current mean train loss 2013.7215169824817
INFO:root:current train perplexity5.8582611083984375
INFO:root:current mean train loss 2013.531716496873
INFO:root:current train perplexity5.855644702911377
INFO:root:current mean train loss 2014.4825745177454
INFO:root:current train perplexity5.856851100921631
INFO:root:current mean train loss 2015.435165413899
INFO:root:current train perplexity5.857028961181641
INFO:root:current mean train loss 2013.7856355833458
INFO:root:current train perplexity5.855230808258057
INFO:root:current mean train loss 2013.0912728220028
INFO:root:current train perplexity5.854997158050537

100%|██████████| 1/1 [05:34<00:00, 334.77s/it][A100%|██████████| 1/1 [05:34<00:00, 334.77s/it]
INFO:root:final mean train loss: 2012.450983690963
INFO:root:final train perplexity: 5.854334831237793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.60s/it][A100%|██████████| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 1929.7480196039728
INFO:root:eval perplexity: 5.710506916046143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2281.003516231023
INFO:root:eval perplexity: 8.134109497070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/11
  6%|▌         | 11/200 [1:07:18<19:15:50, 366.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1994.644668933957
INFO:root:current train perplexity5.798054218292236
INFO:root:current mean train loss 2002.0176851005965
INFO:root:current train perplexity5.798830032348633
INFO:root:current mean train loss 1999.956505835473
INFO:root:current train perplexity5.78334903717041
INFO:root:current mean train loss 1998.2068247424506
INFO:root:current train perplexity5.762734889984131
INFO:root:current mean train loss 1991.9722634146733
INFO:root:current train perplexity5.75129508972168
INFO:root:current mean train loss 1991.9880706474644
INFO:root:current train perplexity5.7611846923828125
INFO:root:current mean train loss 1992.508955619078
INFO:root:current train perplexity5.761542797088623
INFO:root:current mean train loss 1992.9005653439588
INFO:root:current train perplexity5.763088703155518
INFO:root:current mean train loss 1990.8956914690762
INFO:root:current train perplexity5.753535270690918
INFO:root:current mean train loss 1990.390097349217
INFO:root:current train perplexity5.753279685974121
INFO:root:current mean train loss 1988.6035160746144
INFO:root:current train perplexity5.748183250427246
INFO:root:current mean train loss 1989.9599140032146
INFO:root:current train perplexity5.750620365142822
INFO:root:current mean train loss 1989.8484687864502
INFO:root:current train perplexity5.749300479888916
INFO:root:current mean train loss 1989.2892670954805
INFO:root:current train perplexity5.7488813400268555
INFO:root:current mean train loss 1990.2864848120216
INFO:root:current train perplexity5.751288414001465
INFO:root:current mean train loss 1989.7889293463804
INFO:root:current train perplexity5.749259948730469
INFO:root:current mean train loss 1991.7359334599505
INFO:root:current train perplexity5.749120712280273
INFO:root:current mean train loss 1991.7345754659723
INFO:root:current train perplexity5.748844623565674
INFO:root:current mean train loss 1992.0668150496256
INFO:root:current train perplexity5.748595237731934

100%|██████████| 1/1 [05:34<00:00, 334.67s/it][A100%|██████████| 1/1 [05:34<00:00, 334.68s/it]
INFO:root:final mean train loss: 1991.9400497490387
INFO:root:final train perplexity: 5.74983549118042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.60s/it][A100%|██████████| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 1916.220984925615
INFO:root:eval perplexity: 5.641189098358154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 2274.04388124723
INFO:root:eval perplexity: 8.082256317138672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/12
  6%|▌         | 12/200 [1:13:25<19:09:30, 366.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1981.3735758463542
INFO:root:current train perplexity5.637553691864014
INFO:root:current mean train loss 1961.1262941823422
INFO:root:current train perplexity5.627374649047852
INFO:root:current mean train loss 1971.426161291564
INFO:root:current train perplexity5.629591941833496
INFO:root:current mean train loss 1977.1931502842667
INFO:root:current train perplexity5.654088020324707
INFO:root:current mean train loss 1976.9462106103638
INFO:root:current train perplexity5.6524739265441895
INFO:root:current mean train loss 1976.0343124359313
INFO:root:current train perplexity5.64184045791626
INFO:root:current mean train loss 1970.98079589034
INFO:root:current train perplexity5.639461994171143
INFO:root:current mean train loss 1967.0841611425365
INFO:root:current train perplexity5.630176544189453
INFO:root:current mean train loss 1968.1682559116691
INFO:root:current train perplexity5.630735397338867
INFO:root:current mean train loss 1969.01004653542
INFO:root:current train perplexity5.634982109069824
INFO:root:current mean train loss 1970.7874323805927
INFO:root:current train perplexity5.643661975860596
INFO:root:current mean train loss 1970.6512562949767
INFO:root:current train perplexity5.646225929260254
INFO:root:current mean train loss 1972.314648051908
INFO:root:current train perplexity5.6547417640686035
INFO:root:current mean train loss 1971.5417260311242
INFO:root:current train perplexity5.651948928833008
INFO:root:current mean train loss 1972.2108075990902
INFO:root:current train perplexity5.651780128479004
INFO:root:current mean train loss 1973.031108843511
INFO:root:current train perplexity5.650184631347656
INFO:root:current mean train loss 1972.0800159095008
INFO:root:current train perplexity5.647674560546875
INFO:root:current mean train loss 1973.3559398281525
INFO:root:current train perplexity5.652071952819824
INFO:root:current mean train loss 1972.8763469710855
INFO:root:current train perplexity5.649785995483398
INFO:root:current mean train loss 1972.5661365791677
INFO:root:current train perplexity5.64988899230957

100%|██████████| 1/1 [05:34<00:00, 334.46s/it][A100%|██████████| 1/1 [05:34<00:00, 334.46s/it]
INFO:root:final mean train loss: 1972.5612890538819
INFO:root:final train perplexity: 5.6528191566467285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.58s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 1906.5009977732989
INFO:root:eval perplexity: 5.591897964477539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 2266.238278219886
INFO:root:eval perplexity: 8.024489402770996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/13
  6%|▋         | 13/200 [1:19:32<19:03:12, 366.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.1940612792969
INFO:root:current train perplexity5.499027252197266
INFO:root:current mean train loss 1938.2426798502604
INFO:root:current train perplexity5.518351078033447
INFO:root:current mean train loss 1941.3092257412998
INFO:root:current train perplexity5.508455753326416
INFO:root:current mean train loss 1950.9960777282715
INFO:root:current train perplexity5.5486321449279785
INFO:root:current mean train loss 1954.0257777622767
INFO:root:current train perplexity5.558206558227539
INFO:root:current mean train loss 1953.1890362079328
INFO:root:current train perplexity5.565323352813721
INFO:root:current mean train loss 1953.438846908077
INFO:root:current train perplexity5.572722911834717
INFO:root:current mean train loss 1954.4520429823133
INFO:root:current train perplexity5.576495170593262
INFO:root:current mean train loss 1953.7131463771914
INFO:root:current train perplexity5.5726189613342285
INFO:root:current mean train loss 1954.0916572902513
INFO:root:current train perplexity5.571427345275879
INFO:root:current mean train loss 1955.6960665833717
INFO:root:current train perplexity5.577467918395996
INFO:root:current mean train loss 1954.4941834586007
INFO:root:current train perplexity5.575591087341309
INFO:root:current mean train loss 1954.8752947697874
INFO:root:current train perplexity5.572638988494873
INFO:root:current mean train loss 1955.6233901515152
INFO:root:current train perplexity5.578125476837158
INFO:root:current mean train loss 1955.4258360956755
INFO:root:current train perplexity5.574665069580078
INFO:root:current mean train loss 1956.3914776450708
INFO:root:current train perplexity5.577959060668945
INFO:root:current mean train loss 1956.71794516481
INFO:root:current train perplexity5.574952602386475
INFO:root:current mean train loss 1957.0641642725745
INFO:root:current train perplexity5.575089454650879
INFO:root:current mean train loss 1957.2647860684237
INFO:root:current train perplexity5.575371742248535
INFO:root:current mean train loss 1957.81795946757
INFO:root:current train perplexity5.575816631317139

100%|██████████| 1/1 [05:35<00:00, 335.23s/it][A100%|██████████| 1/1 [05:35<00:00, 335.23s/it]
INFO:root:final mean train loss: 1956.9283148091788
INFO:root:final train perplexity: 5.575749397277832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.63s/it][A100%|██████████| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 1897.8495764766178
INFO:root:eval perplexity: 5.548389434814453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2261.2066040039062
INFO:root:eval perplexity: 7.9874749183654785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/14
  7%|▋         | 14/200 [1:25:39<18:57:37, 366.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.7121186127533
INFO:root:current train perplexity5.5696892738342285
INFO:root:current mean train loss 1973.556232535926
INFO:root:current train perplexity5.575990676879883
INFO:root:current mean train loss 1962.5370547781513
INFO:root:current train perplexity5.54390811920166
INFO:root:current mean train loss 1962.0071249942043
INFO:root:current train perplexity5.541844844818115
INFO:root:current mean train loss 1949.1117161242312
INFO:root:current train perplexity5.509999752044678
INFO:root:current mean train loss 1947.0041817606495
INFO:root:current train perplexity5.4937286376953125
INFO:root:current mean train loss 1942.9949516164638
INFO:root:current train perplexity5.4974164962768555
INFO:root:current mean train loss 1945.431219921345
INFO:root:current train perplexity5.510429382324219
INFO:root:current mean train loss 1941.560604774539
INFO:root:current train perplexity5.500950336456299
INFO:root:current mean train loss 1940.4867605170675
INFO:root:current train perplexity5.498933792114258
INFO:root:current mean train loss 1940.5142120685043
INFO:root:current train perplexity5.498409748077393
INFO:root:current mean train loss 1940.6849794681384
INFO:root:current train perplexity5.504180431365967
INFO:root:current mean train loss 1942.259749441062
INFO:root:current train perplexity5.506529331207275
INFO:root:current mean train loss 1943.7147472441509
INFO:root:current train perplexity5.508686542510986
INFO:root:current mean train loss 1942.743836511069
INFO:root:current train perplexity5.506892204284668
INFO:root:current mean train loss 1941.743854947112
INFO:root:current train perplexity5.502177715301514
INFO:root:current mean train loss 1942.6440958385433
INFO:root:current train perplexity5.502302646636963
INFO:root:current mean train loss 1942.5936385414418
INFO:root:current train perplexity5.501380443572998
INFO:root:current mean train loss 1941.2436769305848
INFO:root:current train perplexity5.500369548797607
INFO:root:current mean train loss 1941.6538637995288
INFO:root:current train perplexity5.498676300048828

100%|██████████| 1/1 [05:35<00:00, 335.15s/it][A100%|██████████| 1/1 [05:35<00:00, 335.15s/it]
INFO:root:final mean train loss: 1941.4212673570073
INFO:root:final train perplexity: 5.500338077545166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 1890.1109069391346
INFO:root:eval perplexity: 5.509758949279785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 2256.389995602006
INFO:root:eval perplexity: 7.952198505401611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/15
  8%|▊         | 15/200 [1:31:46<18:51:48, 367.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.692461932147
INFO:root:current train perplexity5.391586780548096
INFO:root:current mean train loss 1933.8228062220983
INFO:root:current train perplexity5.41813850402832
INFO:root:current mean train loss 1929.34598907711
INFO:root:current train perplexity5.395300388336182
INFO:root:current mean train loss 1934.7725805939929
INFO:root:current train perplexity5.4204277992248535
INFO:root:current mean train loss 1937.2646914578745
INFO:root:current train perplexity5.43950080871582
INFO:root:current mean train loss 1934.7435862406926
INFO:root:current train perplexity5.443271636962891
INFO:root:current mean train loss 1934.3976229513094
INFO:root:current train perplexity5.438117504119873
INFO:root:current mean train loss 1934.8358733888015
INFO:root:current train perplexity5.447547435760498
INFO:root:current mean train loss 1933.475758608387
INFO:root:current train perplexity5.443751335144043
INFO:root:current mean train loss 1932.6730598753604
INFO:root:current train perplexity5.444465637207031
INFO:root:current mean train loss 1931.0633579666746
INFO:root:current train perplexity5.440027713775635
INFO:root:current mean train loss 1929.4867108376436
INFO:root:current train perplexity5.44097900390625
INFO:root:current mean train loss 1929.395282167377
INFO:root:current train perplexity5.443019866943359
INFO:root:current mean train loss 1930.1137038080167
INFO:root:current train perplexity5.44365119934082
INFO:root:current mean train loss 1930.262333131394
INFO:root:current train perplexity5.443331241607666
INFO:root:current mean train loss 1928.5297443875936
INFO:root:current train perplexity5.438124656677246
INFO:root:current mean train loss 1928.1211385484762
INFO:root:current train perplexity5.436721324920654
INFO:root:current mean train loss 1928.3036819162228
INFO:root:current train perplexity5.435319900512695
INFO:root:current mean train loss 1927.6195832780263
INFO:root:current train perplexity5.430848121643066
INFO:root:current mean train loss 1927.3706139649437
INFO:root:current train perplexity5.4304914474487305

100%|██████████| 1/1 [05:34<00:00, 334.90s/it][A100%|██████████| 1/1 [05:34<00:00, 334.90s/it]
INFO:root:final mean train loss: 1926.6620291336221
INFO:root:final train perplexity: 5.429511070251465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.59s/it][A100%|██████████| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 1883.9831962855994
INFO:root:eval perplexity: 5.479359149932861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2255.056645819481
INFO:root:eval perplexity: 7.942462921142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/16
  8%|▊         | 16/200 [1:37:53<18:45:36, 367.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1895.007950044014
INFO:root:current train perplexity5.32366943359375
INFO:root:current mean train loss 1898.4263352065059
INFO:root:current train perplexity5.350843906402588
INFO:root:current mean train loss 1896.4354905695052
INFO:root:current train perplexity5.3291754722595215
INFO:root:current mean train loss 1904.7160338532892
INFO:root:current train perplexity5.335838317871094
INFO:root:current mean train loss 1904.4963713238953
INFO:root:current train perplexity5.336842060089111
INFO:root:current mean train loss 1906.6851966978163
INFO:root:current train perplexity5.339434623718262
INFO:root:current mean train loss 1911.9779212826588
INFO:root:current train perplexity5.354568004608154
INFO:root:current mean train loss 1912.4533658157527
INFO:root:current train perplexity5.357993125915527
INFO:root:current mean train loss 1911.777621526532
INFO:root:current train perplexity5.359231472015381
INFO:root:current mean train loss 1914.3413016793656
INFO:root:current train perplexity5.364201068878174
INFO:root:current mean train loss 1913.671730931956
INFO:root:current train perplexity5.361899375915527
INFO:root:current mean train loss 1912.2997880083797
INFO:root:current train perplexity5.3602495193481445
INFO:root:current mean train loss 1912.4469427293348
INFO:root:current train perplexity5.361504554748535
INFO:root:current mean train loss 1911.4970599841586
INFO:root:current train perplexity5.3624958992004395
INFO:root:current mean train loss 1910.8270044592591
INFO:root:current train perplexity5.361643314361572
INFO:root:current mean train loss 1912.2986455245962
INFO:root:current train perplexity5.36207389831543
INFO:root:current mean train loss 1910.494562428701
INFO:root:current train perplexity5.355637073516846
INFO:root:current mean train loss 1912.0712661786245
INFO:root:current train perplexity5.356916427612305
INFO:root:current mean train loss 1912.6212333707742
INFO:root:current train perplexity5.359009742736816
INFO:root:current mean train loss 1913.0539791701349
INFO:root:current train perplexity5.36233377456665

100%|██████████| 1/1 [05:35<00:00, 335.50s/it][A100%|██████████| 1/1 [05:35<00:00, 335.50s/it]
INFO:root:final mean train loss: 1912.7290746060755
INFO:root:final train perplexity: 5.363485813140869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.58s/it][A100%|██████████| 1/1 [00:15<00:00, 15.58s/it]
INFO:root:eval mean loss: 1875.9141689868684
INFO:root:eval perplexity: 5.439586639404297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 2247.1881739839596
INFO:root:eval perplexity: 7.885241985321045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/17
  8%|▊         | 17/200 [1:44:01<18:40:07, 367.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1904.5720228715377
INFO:root:current train perplexity5.333179473876953
INFO:root:current mean train loss 1916.1128858201048
INFO:root:current train perplexity5.3090901374816895
INFO:root:current mean train loss 1914.2339918348525
INFO:root:current train perplexity5.312930583953857
INFO:root:current mean train loss 1914.1928399469434
INFO:root:current train perplexity5.303102016448975
INFO:root:current mean train loss 1908.0399715235976
INFO:root:current train perplexity5.298696994781494
INFO:root:current mean train loss 1905.3033482558062
INFO:root:current train perplexity5.293204307556152
INFO:root:current mean train loss 1906.5397010625795
INFO:root:current train perplexity5.295741081237793
INFO:root:current mean train loss 1907.5853084041382
INFO:root:current train perplexity5.304405689239502
INFO:root:current mean train loss 1906.7363630415084
INFO:root:current train perplexity5.30420446395874
INFO:root:current mean train loss 1905.6263241169424
INFO:root:current train perplexity5.303719520568848
INFO:root:current mean train loss 1903.766030367683
INFO:root:current train perplexity5.301825046539307
INFO:root:current mean train loss 1904.013767024082
INFO:root:current train perplexity5.303342342376709
INFO:root:current mean train loss 1903.7228554672336
INFO:root:current train perplexity5.304021835327148
INFO:root:current mean train loss 1903.7484390302764
INFO:root:current train perplexity5.306361675262451
INFO:root:current mean train loss 1902.676051478232
INFO:root:current train perplexity5.3039960861206055
INFO:root:current mean train loss 1902.6180274636679
INFO:root:current train perplexity5.304917335510254
INFO:root:current mean train loss 1901.4030863685066
INFO:root:current train perplexity5.303823471069336
INFO:root:current mean train loss 1902.3270206323407
INFO:root:current train perplexity5.3088250160217285
INFO:root:current mean train loss 1901.0220397690596
INFO:root:current train perplexity5.306347846984863

100%|██████████| 1/1 [05:35<00:00, 335.48s/it][A100%|██████████| 1/1 [05:35<00:00, 335.48s/it]
INFO:root:final mean train loss: 1900.4814642417089
INFO:root:final train perplexity: 5.306110858917236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1870.2823767695866
INFO:root:eval perplexity: 5.411997318267822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2244.8690098972183
INFO:root:eval perplexity: 7.868454456329346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/18
  9%|▉         | 18/200 [1:50:09<18:34:30, 367.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1797.089990234375
INFO:root:current train perplexity4.9514899253845215
INFO:root:current mean train loss 1901.2172677176338
INFO:root:current train perplexity5.281023025512695
INFO:root:current mean train loss 1899.0712819169207
INFO:root:current train perplexity5.271547317504883
INFO:root:current mean train loss 1895.0946817366803
INFO:root:current train perplexity5.2658915519714355
INFO:root:current mean train loss 1892.4087848427855
INFO:root:current train perplexity5.258481502532959
INFO:root:current mean train loss 1890.1174098855197
INFO:root:current train perplexity5.251967906951904
INFO:root:current mean train loss 1890.0923874531895
INFO:root:current train perplexity5.254207134246826
INFO:root:current mean train loss 1888.6064399448692
INFO:root:current train perplexity5.252928256988525
INFO:root:current mean train loss 1891.4670196343652
INFO:root:current train perplexity5.2648138999938965
INFO:root:current mean train loss 1890.0611777289796
INFO:root:current train perplexity5.25999641418457
INFO:root:current mean train loss 1891.4545636077426
INFO:root:current train perplexity5.259422302246094
INFO:root:current mean train loss 1892.0120567908655
INFO:root:current train perplexity5.257112503051758
INFO:root:current mean train loss 1890.4225890860023
INFO:root:current train perplexity5.256720066070557
INFO:root:current mean train loss 1891.0202715292744
INFO:root:current train perplexity5.258795261383057
INFO:root:current mean train loss 1890.308907744384
INFO:root:current train perplexity5.255059242248535
INFO:root:current mean train loss 1889.5030390235672
INFO:root:current train perplexity5.256130218505859
INFO:root:current mean train loss 1890.4733237958771
INFO:root:current train perplexity5.257033824920654
INFO:root:current mean train loss 1890.5265273466139
INFO:root:current train perplexity5.25497579574585
INFO:root:current mean train loss 1890.878643511405
INFO:root:current train perplexity5.25741720199585
INFO:root:current mean train loss 1889.9953494094489
INFO:root:current train perplexity5.256335735321045

100%|██████████| 1/1 [05:36<00:00, 336.96s/it][A100%|██████████| 1/1 [05:36<00:00, 336.96s/it]
INFO:root:final mean train loss: 1889.464411887026
INFO:root:final train perplexity: 5.255025386810303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1866.0840917276153
INFO:root:eval perplexity: 5.391520977020264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2245.779654861342
INFO:root:eval perplexity: 7.875041961669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/19
 10%|▉         | 19/200 [1:56:18<18:30:03, 367.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1927.7512817382812
INFO:root:current train perplexity5.310605049133301
INFO:root:current mean train loss 1873.0219066182121
INFO:root:current train perplexity5.178437232971191
INFO:root:current mean train loss 1875.883375563063
INFO:root:current train perplexity5.164395332336426
INFO:root:current mean train loss 1873.3518998993109
INFO:root:current train perplexity5.189687252044678
INFO:root:current mean train loss 1874.4415500152732
INFO:root:current train perplexity5.194461822509766
INFO:root:current mean train loss 1877.5453659583782
INFO:root:current train perplexity5.194762229919434
INFO:root:current mean train loss 1876.1217676880276
INFO:root:current train perplexity5.194755554199219
INFO:root:current mean train loss 1873.9619067923845
INFO:root:current train perplexity5.193016529083252
INFO:root:current mean train loss 1874.6259732954113
INFO:root:current train perplexity5.19710636138916
INFO:root:current mean train loss 1873.8643491666385
INFO:root:current train perplexity5.197821617126465
INFO:root:current mean train loss 1873.708893718085
INFO:root:current train perplexity5.196033000946045
INFO:root:current mean train loss 1876.4099638967803
INFO:root:current train perplexity5.202625751495361
INFO:root:current mean train loss 1876.7114506548244
INFO:root:current train perplexity5.2003984451293945
INFO:root:current mean train loss 1876.7814905394584
INFO:root:current train perplexity5.196331024169922
INFO:root:current mean train loss 1875.741325882752
INFO:root:current train perplexity5.194660186767578
INFO:root:current mean train loss 1876.7625656228186
INFO:root:current train perplexity5.1984710693359375
INFO:root:current mean train loss 1876.4124708446122
INFO:root:current train perplexity5.195393085479736
INFO:root:current mean train loss 1876.9831654263983
INFO:root:current train perplexity5.1963276863098145
INFO:root:current mean train loss 1877.482845168213
INFO:root:current train perplexity5.1971755027771
INFO:root:current mean train loss 1878.6467415991237
INFO:root:current train perplexity5.201606273651123

100%|██████████| 1/1 [05:36<00:00, 336.21s/it][A100%|██████████| 1/1 [05:36<00:00, 336.21s/it]
INFO:root:final mean train loss: 1878.1495698975964
INFO:root:final train perplexity: 5.2030720710754395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1859.7954244410737
INFO:root:eval perplexity: 5.360996246337891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2238.415783171958
INFO:root:eval perplexity: 7.821933269500732
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/20
 10%|█         | 20/200 [2:02:27<18:24:29, 368.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1890.0133275741186
INFO:root:current train perplexity5.1844024658203125
INFO:root:current mean train loss 1872.075882945987
INFO:root:current train perplexity5.198073863983154
INFO:root:current mean train loss 1859.5651165950248
INFO:root:current train perplexity5.158277988433838
INFO:root:current mean train loss 1868.6611616196533
INFO:root:current train perplexity5.165918350219727
INFO:root:current mean train loss 1864.026486755232
INFO:root:current train perplexity5.153409004211426
INFO:root:current mean train loss 1864.1339056973998
INFO:root:current train perplexity5.149965763092041
INFO:root:current mean train loss 1862.8556991362236
INFO:root:current train perplexity5.159112453460693
INFO:root:current mean train loss 1863.8271540537255
INFO:root:current train perplexity5.1637797355651855
INFO:root:current mean train loss 1862.2900741267972
INFO:root:current train perplexity5.154623031616211
INFO:root:current mean train loss 1862.976844990723
INFO:root:current train perplexity5.162400245666504
INFO:root:current mean train loss 1863.7116675721095
INFO:root:current train perplexity5.1620001792907715
INFO:root:current mean train loss 1863.2778782229134
INFO:root:current train perplexity5.158838748931885
INFO:root:current mean train loss 1864.894077845982
INFO:root:current train perplexity5.156470775604248
INFO:root:current mean train loss 1865.4850672179857
INFO:root:current train perplexity5.157542705535889
INFO:root:current mean train loss 1864.4887670711812
INFO:root:current train perplexity5.149972915649414
INFO:root:current mean train loss 1865.057152067089
INFO:root:current train perplexity5.153068542480469
INFO:root:current mean train loss 1866.0420673363378
INFO:root:current train perplexity5.151768684387207
INFO:root:current mean train loss 1865.3004893763027
INFO:root:current train perplexity5.148766040802002
INFO:root:current mean train loss 1866.6670490076128
INFO:root:current train perplexity5.152074813842773
INFO:root:current mean train loss 1867.3739866716091
INFO:root:current train perplexity5.153780937194824

100%|██████████| 1/1 [05:36<00:00, 336.12s/it][A100%|██████████| 1/1 [05:36<00:00, 336.12s/it]
INFO:root:final mean train loss: 1867.606238630163
INFO:root:final train perplexity: 5.15512228012085
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 1856.3619986459719
INFO:root:eval perplexity: 5.3444037437438965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2236.5690190741357
INFO:root:eval perplexity: 7.8086700439453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/21
 10%|█         | 21/200 [2:08:35<18:18:40, 368.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.1518184116908
INFO:root:current train perplexity5.128855228424072
INFO:root:current mean train loss 1857.815661308093
INFO:root:current train perplexity5.112040996551514
INFO:root:current mean train loss 1857.5180358886719
INFO:root:current train perplexity5.105069160461426
INFO:root:current mean train loss 1852.6648158384173
INFO:root:current train perplexity5.094357013702393
INFO:root:current mean train loss 1852.2753678706654
INFO:root:current train perplexity5.084141254425049
INFO:root:current mean train loss 1857.0585805769447
INFO:root:current train perplexity5.094316005706787
INFO:root:current mean train loss 1855.0306141550948
INFO:root:current train perplexity5.095103740692139
INFO:root:current mean train loss 1854.4527025979662
INFO:root:current train perplexity5.092864990234375
INFO:root:current mean train loss 1857.046702589944
INFO:root:current train perplexity5.093960762023926
INFO:root:current mean train loss 1855.6669686927955
INFO:root:current train perplexity5.092554092407227
INFO:root:current mean train loss 1857.4466908772786
INFO:root:current train perplexity5.10173225402832
INFO:root:current mean train loss 1858.4973038934095
INFO:root:current train perplexity5.105325222015381
INFO:root:current mean train loss 1860.3151271358417
INFO:root:current train perplexity5.111728191375732
INFO:root:current mean train loss 1860.3899531631694
INFO:root:current train perplexity5.111142635345459
INFO:root:current mean train loss 1859.2294755034395
INFO:root:current train perplexity5.110468864440918
INFO:root:current mean train loss 1859.8568895825383
INFO:root:current train perplexity5.109540939331055
INFO:root:current mean train loss 1860.050310070388
INFO:root:current train perplexity5.113584041595459
INFO:root:current mean train loss 1859.034410967642
INFO:root:current train perplexity5.112977504730225
INFO:root:current mean train loss 1858.3867604485874
INFO:root:current train perplexity5.112590789794922
INFO:root:current mean train loss 1857.5443712480228
INFO:root:current train perplexity5.107576370239258

100%|██████████| 1/1 [05:35<00:00, 335.97s/it][A100%|██████████| 1/1 [05:35<00:00, 335.97s/it]
INFO:root:final mean train loss: 1857.2747469703418
INFO:root:final train perplexity: 5.108564376831055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1853.5483762051197
INFO:root:eval perplexity: 5.330843925476074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2238.3491193622563
INFO:root:eval perplexity: 7.821454048156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/22
 11%|█         | 22/200 [2:14:44<18:12:29, 368.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.3360227819992
INFO:root:current train perplexity5.039002895355225
INFO:root:current mean train loss 1850.5805918081646
INFO:root:current train perplexity5.057059288024902
INFO:root:current mean train loss 1850.8934983473557
INFO:root:current train perplexity5.067619800567627
INFO:root:current mean train loss 1844.274875180651
INFO:root:current train perplexity5.052909851074219
INFO:root:current mean train loss 1844.5811037220865
INFO:root:current train perplexity5.057108402252197
INFO:root:current mean train loss 1845.4098744017915
INFO:root:current train perplexity5.0457444190979
INFO:root:current mean train loss 1848.6949653342078
INFO:root:current train perplexity5.058374881744385
INFO:root:current mean train loss 1850.0381121518233
INFO:root:current train perplexity5.067137241363525
INFO:root:current mean train loss 1847.8102859549506
INFO:root:current train perplexity5.0627241134643555
INFO:root:current mean train loss 1848.365072660064
INFO:root:current train perplexity5.066854476928711
INFO:root:current mean train loss 1850.0701154582655
INFO:root:current train perplexity5.070317268371582
INFO:root:current mean train loss 1849.8724751322063
INFO:root:current train perplexity5.0691938400268555
INFO:root:current mean train loss 1848.5966559063236
INFO:root:current train perplexity5.069615840911865
INFO:root:current mean train loss 1848.786967389356
INFO:root:current train perplexity5.067287921905518
INFO:root:current mean train loss 1849.9097652603637
INFO:root:current train perplexity5.072285175323486
INFO:root:current mean train loss 1850.1392085032332
INFO:root:current train perplexity5.072399616241455
INFO:root:current mean train loss 1849.2509659096215
INFO:root:current train perplexity5.072626113891602
INFO:root:current mean train loss 1849.1185156084762
INFO:root:current train perplexity5.07273006439209
INFO:root:current mean train loss 1849.3168495614073
INFO:root:current train perplexity5.070303440093994
INFO:root:current mean train loss 1849.076408838658
INFO:root:current train perplexity5.069794178009033

100%|██████████| 1/1 [05:36<00:00, 336.34s/it][A100%|██████████| 1/1 [05:36<00:00, 336.34s/it]
INFO:root:final mean train loss: 1848.390704810469
INFO:root:final train perplexity: 5.06886625289917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1849.0621537012412
INFO:root:eval perplexity: 5.309295654296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2235.2210156596298
INFO:root:eval perplexity: 7.799002647399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/23
 12%|█▏        | 23/200 [2:20:52<18:06:36, 368.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.913399251302
INFO:root:current train perplexity4.9533514976501465
INFO:root:current mean train loss 1837.485328433388
INFO:root:current train perplexity4.9994001388549805
INFO:root:current mean train loss 1831.6711602572736
INFO:root:current train perplexity4.983059406280518
INFO:root:current mean train loss 1837.3900321764825
INFO:root:current train perplexity4.999358654022217
INFO:root:current mean train loss 1840.8041603555484
INFO:root:current train perplexity5.002562999725342
INFO:root:current mean train loss 1843.8916917703918
INFO:root:current train perplexity5.016726970672607
INFO:root:current mean train loss 1841.2458366946898
INFO:root:current train perplexity5.0097761154174805
INFO:root:current mean train loss 1840.5243150155757
INFO:root:current train perplexity5.01578426361084
INFO:root:current mean train loss 1840.4097055499474
INFO:root:current train perplexity5.021768093109131
INFO:root:current mean train loss 1840.506695494989
INFO:root:current train perplexity5.025753021240234
INFO:root:current mean train loss 1840.2269292708932
INFO:root:current train perplexity5.028082847595215
INFO:root:current mean train loss 1840.148109756598
INFO:root:current train perplexity5.024696350097656
INFO:root:current mean train loss 1839.247834434805
INFO:root:current train perplexity5.025487899780273
INFO:root:current mean train loss 1840.316766840434
INFO:root:current train perplexity5.0276360511779785
INFO:root:current mean train loss 1839.3289096909082
INFO:root:current train perplexity5.0251288414001465
INFO:root:current mean train loss 1839.384349664652
INFO:root:current train perplexity5.026148796081543
INFO:root:current mean train loss 1839.6460179074982
INFO:root:current train perplexity5.027434349060059
INFO:root:current mean train loss 1839.1526956398393
INFO:root:current train perplexity5.025092601776123
INFO:root:current mean train loss 1839.509032105138
INFO:root:current train perplexity5.025031089782715

100%|██████████| 1/1 [05:35<00:00, 335.91s/it][A100%|██████████| 1/1 [05:35<00:00, 335.91s/it]
INFO:root:final mean train loss: 1838.3180253283278
INFO:root:final train perplexity: 5.024229526519775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 1845.6576780495068
INFO:root:eval perplexity: 5.293001174926758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.88s/it][A100%|██████████| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2237.381480981272
INFO:root:eval perplexity: 7.814503192901611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/24
 12%|█▏        | 24/200 [2:27:00<18:00:24, 368.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1837.423549107143
INFO:root:current train perplexity5.092072010040283
INFO:root:current mean train loss 1830.9660176785192
INFO:root:current train perplexity4.983783721923828
INFO:root:current mean train loss 1832.1172010633682
INFO:root:current train perplexity4.978933811187744
INFO:root:current mean train loss 1829.5878568270307
INFO:root:current train perplexity4.990073204040527
INFO:root:current mean train loss 1827.2585275261056
INFO:root:current train perplexity4.980532169342041
INFO:root:current mean train loss 1827.2248113809017
INFO:root:current train perplexity4.984557151794434
INFO:root:current mean train loss 1828.9172377358552
INFO:root:current train perplexity4.990635871887207
INFO:root:current mean train loss 1829.710033627177
INFO:root:current train perplexity4.985858917236328
INFO:root:current mean train loss 1829.5306644557872
INFO:root:current train perplexity4.986551761627197
INFO:root:current mean train loss 1828.278295144751
INFO:root:current train perplexity4.982950687408447
INFO:root:current mean train loss 1828.6801018359763
INFO:root:current train perplexity4.9854841232299805
INFO:root:current mean train loss 1830.9650958301575
INFO:root:current train perplexity4.988104343414307
INFO:root:current mean train loss 1830.026957109731
INFO:root:current train perplexity4.988193511962891
INFO:root:current mean train loss 1829.9843377344646
INFO:root:current train perplexity4.9859299659729
INFO:root:current mean train loss 1828.5984923492192
INFO:root:current train perplexity4.982536315917969
INFO:root:current mean train loss 1830.3364812677557
INFO:root:current train perplexity4.984432220458984
INFO:root:current mean train loss 1831.4222411349758
INFO:root:current train perplexity4.988439083099365
INFO:root:current mean train loss 1830.2343517587278
INFO:root:current train perplexity4.984976768493652
INFO:root:current mean train loss 1830.1470953345497
INFO:root:current train perplexity4.983727931976318
INFO:root:current mean train loss 1829.3991647369273
INFO:root:current train perplexity4.981821060180664

100%|██████████| 1/1 [05:36<00:00, 336.30s/it][A100%|██████████| 1/1 [05:36<00:00, 336.30s/it]
INFO:root:final mean train loss: 1829.1455287115778
INFO:root:final train perplexity: 4.983923435211182
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1843.000678312694
INFO:root:eval perplexity: 5.2803192138671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.86s/it][A100%|██████████| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 2235.153656222296
INFO:root:eval perplexity: 7.798519134521484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/25
 12%|█▎        | 25/200 [2:33:09<17:54:32, 368.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.016362508138
INFO:root:current train perplexity4.919068336486816
INFO:root:current mean train loss 1817.170651343561
INFO:root:current train perplexity4.935194969177246
INFO:root:current mean train loss 1817.4401997157506
INFO:root:current train perplexity4.947236061096191
INFO:root:current mean train loss 1816.6782011809173
INFO:root:current train perplexity4.947059154510498
INFO:root:current mean train loss 1810.9613417139594
INFO:root:current train perplexity4.948492527008057
INFO:root:current mean train loss 1813.2140498270514
INFO:root:current train perplexity4.948413848876953
INFO:root:current mean train loss 1813.0029036693084
INFO:root:current train perplexity4.9442315101623535
INFO:root:current mean train loss 1814.8412227735994
INFO:root:current train perplexity4.950675964355469
INFO:root:current mean train loss 1816.1383034419086
INFO:root:current train perplexity4.952779769897461
INFO:root:current mean train loss 1818.182982209441
INFO:root:current train perplexity4.951045989990234
INFO:root:current mean train loss 1818.8137687444687
INFO:root:current train perplexity4.951907157897949
INFO:root:current mean train loss 1818.1927969175727
INFO:root:current train perplexity4.951720237731934
INFO:root:current mean train loss 1819.84812448539
INFO:root:current train perplexity4.956797122955322
INFO:root:current mean train loss 1821.089027612231
INFO:root:current train perplexity4.956991672515869
INFO:root:current mean train loss 1823.0384479479844
INFO:root:current train perplexity4.957507610321045
INFO:root:current mean train loss 1823.4286824223877
INFO:root:current train perplexity4.954529762268066
INFO:root:current mean train loss 1824.3906820513346
INFO:root:current train perplexity4.957022666931152
INFO:root:current mean train loss 1823.360028614301
INFO:root:current train perplexity4.953897476196289
INFO:root:current mean train loss 1822.3908723530017
INFO:root:current train perplexity4.951901912689209
INFO:root:current mean train loss 1822.0062231115394
INFO:root:current train perplexity4.952108383178711

100%|██████████| 1/1 [05:36<00:00, 336.77s/it][A100%|██████████| 1/1 [05:36<00:00, 336.77s/it]
INFO:root:final mean train loss: 1821.600487628731
INFO:root:final train perplexity: 4.951011657714844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1840.9518640396443
INFO:root:eval perplexity: 5.270559787750244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2234.5058559120125
INFO:root:eval perplexity: 7.793879508972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/26
 13%|█▎        | 26/200 [2:39:18<17:48:56, 368.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.6511170922256
INFO:root:current train perplexity4.886314868927002
INFO:root:current mean train loss 1806.2473179161125
INFO:root:current train perplexity4.89571475982666
INFO:root:current mean train loss 1812.1975634563019
INFO:root:current train perplexity4.903947353363037
INFO:root:current mean train loss 1809.0378790265304
INFO:root:current train perplexity4.903086185455322
INFO:root:current mean train loss 1811.651658938315
INFO:root:current train perplexity4.900942325592041
INFO:root:current mean train loss 1811.3027136162777
INFO:root:current train perplexity4.898284435272217
INFO:root:current mean train loss 1812.571526918694
INFO:root:current train perplexity4.904139041900635
INFO:root:current mean train loss 1814.9263593130588
INFO:root:current train perplexity4.9167866706848145
INFO:root:current mean train loss 1815.371512214579
INFO:root:current train perplexity4.921482086181641
INFO:root:current mean train loss 1813.960778198891
INFO:root:current train perplexity4.915125370025635
INFO:root:current mean train loss 1812.6294971359796
INFO:root:current train perplexity4.910350799560547
INFO:root:current mean train loss 1812.1798389912906
INFO:root:current train perplexity4.9070820808410645
INFO:root:current mean train loss 1811.743522502644
INFO:root:current train perplexity4.905831813812256
INFO:root:current mean train loss 1812.0615328135195
INFO:root:current train perplexity4.904074668884277
INFO:root:current mean train loss 1812.389438944174
INFO:root:current train perplexity4.905007362365723
INFO:root:current mean train loss 1812.5605833138993
INFO:root:current train perplexity4.906092643737793
INFO:root:current mean train loss 1813.9686184080545
INFO:root:current train perplexity4.907932281494141
INFO:root:current mean train loss 1812.8715903749417
INFO:root:current train perplexity4.908401966094971
INFO:root:current mean train loss 1813.7442684639802
INFO:root:current train perplexity4.913699150085449
INFO:root:current mean train loss 1814.3705833313209
INFO:root:current train perplexity4.916666030883789

100%|██████████| 1/1 [05:36<00:00, 336.16s/it][A100%|██████████| 1/1 [05:36<00:00, 336.16s/it]
INFO:root:final mean train loss: 1814.0198015837254
INFO:root:final train perplexity: 4.918164253234863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1834.3790131697417
INFO:root:eval perplexity: 5.239374160766602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.83s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 2227.3763860607824
INFO:root:eval perplexity: 7.742984771728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/27
 14%|█▎        | 27/200 [2:45:27<17:42:43, 368.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.8567673255657
INFO:root:current train perplexity4.832642078399658
INFO:root:current mean train loss 1826.0531168104726
INFO:root:current train perplexity4.868875980377197
INFO:root:current mean train loss 1805.8008105847262
INFO:root:current train perplexity4.857044696807861
INFO:root:current mean train loss 1800.755814706813
INFO:root:current train perplexity4.869298458099365
INFO:root:current mean train loss 1801.5865886305096
INFO:root:current train perplexity4.862136363983154
INFO:root:current mean train loss 1799.2774607887404
INFO:root:current train perplexity4.853797435760498
INFO:root:current mean train loss 1800.8094771828694
INFO:root:current train perplexity4.856156349182129
INFO:root:current mean train loss 1802.3386335146458
INFO:root:current train perplexity4.862939357757568
INFO:root:current mean train loss 1805.666506893985
INFO:root:current train perplexity4.865940570831299
INFO:root:current mean train loss 1807.671741334282
INFO:root:current train perplexity4.87046480178833
INFO:root:current mean train loss 1807.8692389273688
INFO:root:current train perplexity4.8717360496521
INFO:root:current mean train loss 1806.6189391773598
INFO:root:current train perplexity4.870640754699707
INFO:root:current mean train loss 1805.4583439425178
INFO:root:current train perplexity4.874599933624268
INFO:root:current mean train loss 1806.142447964608
INFO:root:current train perplexity4.877552032470703
INFO:root:current mean train loss 1805.9700375989958
INFO:root:current train perplexity4.879410266876221
INFO:root:current mean train loss 1804.939412617714
INFO:root:current train perplexity4.876838207244873
INFO:root:current mean train loss 1805.0902228453192
INFO:root:current train perplexity4.875803470611572
INFO:root:current mean train loss 1804.305322432274
INFO:root:current train perplexity4.875755786895752
INFO:root:current mean train loss 1805.3147183552753
INFO:root:current train perplexity4.8791584968566895
INFO:root:current mean train loss 1806.3710958697093
INFO:root:current train perplexity4.8823699951171875

100%|██████████| 1/1 [05:36<00:00, 336.31s/it][A100%|██████████| 1/1 [05:36<00:00, 336.31s/it]
INFO:root:final mean train loss: 1805.8704765346756
INFO:root:final train perplexity: 4.883094787597656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1832.671647308566
INFO:root:eval perplexity: 5.231305122375488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2226.0036928433897
INFO:root:eval perplexity: 7.733225345611572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/28
 14%|█▍        | 28/200 [2:51:35<17:36:35, 368.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.8721630859375
INFO:root:current train perplexity4.844052791595459
INFO:root:current mean train loss 1786.813076171875
INFO:root:current train perplexity4.825718879699707
INFO:root:current mean train loss 1795.852498668324
INFO:root:current train perplexity4.840141296386719
INFO:root:current mean train loss 1792.987219075521
INFO:root:current train perplexity4.837788105010986
INFO:root:current mean train loss 1795.1056787109376
INFO:root:current train perplexity4.840447425842285
INFO:root:current mean train loss 1794.2953052819294
INFO:root:current train perplexity4.83885383605957
INFO:root:current mean train loss 1795.8131662326389
INFO:root:current train perplexity4.84227180480957
INFO:root:current mean train loss 1796.5906703629032
INFO:root:current train perplexity4.840339660644531
INFO:root:current mean train loss 1796.0308410993302
INFO:root:current train perplexity4.837752342224121
INFO:root:current mean train loss 1797.4315571163863
INFO:root:current train perplexity4.845966339111328
INFO:root:current mean train loss 1797.4795922283793
INFO:root:current train perplexity4.843450546264648
INFO:root:current mean train loss 1797.02555248504
INFO:root:current train perplexity4.843469619750977
INFO:root:current mean train loss 1796.9522125842525
INFO:root:current train perplexity4.844676494598389
INFO:root:current mean train loss 1797.545392134233
INFO:root:current train perplexity4.847684383392334
INFO:root:current mean train loss 1798.5684221067268
INFO:root:current train perplexity4.850069046020508
INFO:root:current mean train loss 1799.629060484871
INFO:root:current train perplexity4.853037357330322
INFO:root:current mean train loss 1800.7540945662313
INFO:root:current train perplexity4.853410243988037
INFO:root:current mean train loss 1800.221005171655
INFO:root:current train perplexity4.851053714752197
INFO:root:current mean train loss 1799.0817115885416
INFO:root:current train perplexity4.850286483764648
INFO:root:current mean train loss 1798.908498813291
INFO:root:current train perplexity4.850346565246582

100%|██████████| 1/1 [05:36<00:00, 336.87s/it][A100%|██████████| 1/1 [05:36<00:00, 336.87s/it]
INFO:root:final mean train loss: 1798.3550433814376
INFO:root:final train perplexity: 4.850974082946777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1831.3427046106217
INFO:root:eval perplexity: 5.225030899047852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2230.234627798094
INFO:root:eval perplexity: 7.763350009918213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/29
 14%|█▍        | 29/200 [2:57:44<17:30:57, 368.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1771.0264985457711
INFO:root:current train perplexity4.800324440002441
INFO:root:current mean train loss 1795.8760299682617
INFO:root:current train perplexity4.834423542022705
INFO:root:current mean train loss 1798.2455055550354
INFO:root:current train perplexity4.834510803222656
INFO:root:current mean train loss 1801.4134832888233
INFO:root:current train perplexity4.85365104675293
INFO:root:current mean train loss 1796.4741228305227
INFO:root:current train perplexity4.842096328735352
INFO:root:current mean train loss 1797.210718515757
INFO:root:current train perplexity4.837871551513672
INFO:root:current mean train loss 1796.839540867447
INFO:root:current train perplexity4.837494373321533
INFO:root:current mean train loss 1796.0055392486881
INFO:root:current train perplexity4.83528995513916
INFO:root:current mean train loss 1795.265110580376
INFO:root:current train perplexity4.834066390991211
INFO:root:current mean train loss 1794.5089677379976
INFO:root:current train perplexity4.832586288452148
INFO:root:current mean train loss 1793.2194963951251
INFO:root:current train perplexity4.827542781829834
INFO:root:current mean train loss 1795.1241646581047
INFO:root:current train perplexity4.831484794616699
INFO:root:current mean train loss 1795.3781570103883
INFO:root:current train perplexity4.831532955169678
INFO:root:current mean train loss 1792.6034553790914
INFO:root:current train perplexity4.8283233642578125
INFO:root:current mean train loss 1792.688412663764
INFO:root:current train perplexity4.824445724487305
INFO:root:current mean train loss 1792.8059990657634
INFO:root:current train perplexity4.824097633361816
INFO:root:current mean train loss 1792.4202519410046
INFO:root:current train perplexity4.82197380065918
INFO:root:current mean train loss 1791.9105328151159
INFO:root:current train perplexity4.819145679473877
INFO:root:current mean train loss 1792.3170246664615
INFO:root:current train perplexity4.822353363037109

100%|██████████| 1/1 [05:36<00:00, 336.75s/it][A100%|██████████| 1/1 [05:36<00:00, 336.76s/it]
INFO:root:final mean train loss: 1791.724360956066
INFO:root:final train perplexity: 4.822811603546143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1827.3075176266068
INFO:root:eval perplexity: 5.206029415130615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2226.4037479914673
INFO:root:eval perplexity: 7.7360687255859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/30
 15%|█▌        | 30/200 [3:03:53<17:25:01, 368.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1778.7740614149307
INFO:root:current train perplexity4.871108531951904
INFO:root:current mean train loss 1781.590302913561
INFO:root:current train perplexity4.7710771560668945
INFO:root:current mean train loss 1791.077192242636
INFO:root:current train perplexity4.803043365478516
INFO:root:current mean train loss 1792.3436950881119
INFO:root:current train perplexity4.794950485229492
INFO:root:current mean train loss 1794.246408625745
INFO:root:current train perplexity4.787464141845703
INFO:root:current mean train loss 1792.379841562807
INFO:root:current train perplexity4.791784286499023
INFO:root:current mean train loss 1787.4519026933242
INFO:root:current train perplexity4.790581703186035
INFO:root:current mean train loss 1783.6448280754144
INFO:root:current train perplexity4.786641597747803
INFO:root:current mean train loss 1783.6023688581581
INFO:root:current train perplexity4.789095878601074
INFO:root:current mean train loss 1784.4599743665772
INFO:root:current train perplexity4.789677143096924
INFO:root:current mean train loss 1784.9495285835683
INFO:root:current train perplexity4.791621685028076
INFO:root:current mean train loss 1784.4876254385285
INFO:root:current train perplexity4.791683197021484
INFO:root:current mean train loss 1784.7930369034002
INFO:root:current train perplexity4.789113998413086
INFO:root:current mean train loss 1784.662950345266
INFO:root:current train perplexity4.789137363433838
INFO:root:current mean train loss 1783.3009838052808
INFO:root:current train perplexity4.7888031005859375
INFO:root:current mean train loss 1784.5593409756307
INFO:root:current train perplexity4.791278839111328
INFO:root:current mean train loss 1784.9093443193074
INFO:root:current train perplexity4.791163444519043
INFO:root:current mean train loss 1784.8139987005834
INFO:root:current train perplexity4.793053150177002
INFO:root:current mean train loss 1785.6511928206191
INFO:root:current train perplexity4.794201850891113
INFO:root:current mean train loss 1785.0702112116946
INFO:root:current train perplexity4.793629169464111

100%|██████████| 1/1 [05:36<00:00, 336.69s/it][A100%|██████████| 1/1 [05:36<00:00, 336.69s/it]
INFO:root:final mean train loss: 1784.60793751896
INFO:root:final train perplexity: 4.79276704788208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 1826.931097368822
INFO:root:eval perplexity: 5.20426082611084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 2227.944851489777
INFO:root:eval perplexity: 7.747028827667236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/31
 16%|█▌        | 31/200 [3:10:02<17:18:55, 368.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.045658991887
INFO:root:current train perplexity4.743992805480957
INFO:root:current mean train loss 1778.657214936756
INFO:root:current train perplexity4.782036781311035
INFO:root:current mean train loss 1777.8124810953057
INFO:root:current train perplexity4.751595497131348
INFO:root:current mean train loss 1777.8907856385401
INFO:root:current train perplexity4.753464698791504
INFO:root:current mean train loss 1777.9844151170041
INFO:root:current train perplexity4.758477687835693
INFO:root:current mean train loss 1778.4538321259356
INFO:root:current train perplexity4.764910697937012
INFO:root:current mean train loss 1773.2101198629068
INFO:root:current train perplexity4.75499963760376
INFO:root:current mean train loss 1772.9992302508394
INFO:root:current train perplexity4.748540878295898
INFO:root:current mean train loss 1772.7348501283955
INFO:root:current train perplexity4.75029182434082
INFO:root:current mean train loss 1773.0159089518932
INFO:root:current train perplexity4.748807430267334
INFO:root:current mean train loss 1773.4732957509061
INFO:root:current train perplexity4.751677989959717
INFO:root:current mean train loss 1775.1105649145204
INFO:root:current train perplexity4.756202697753906
INFO:root:current mean train loss 1775.162052521698
INFO:root:current train perplexity4.755748748779297
INFO:root:current mean train loss 1774.4781002545249
INFO:root:current train perplexity4.7544965744018555
INFO:root:current mean train loss 1775.670707370924
INFO:root:current train perplexity4.759183406829834
INFO:root:current mean train loss 1775.6218937665108
INFO:root:current train perplexity4.75965690612793
INFO:root:current mean train loss 1775.3677980767845
INFO:root:current train perplexity4.759024143218994
INFO:root:current mean train loss 1777.0269797315188
INFO:root:current train perplexity4.761449813842773
INFO:root:current mean train loss 1777.5898053105534
INFO:root:current train perplexity4.761687278747559
INFO:root:current mean train loss 1777.8770025615752
INFO:root:current train perplexity4.761851787567139

100%|██████████| 1/1 [05:36<00:00, 336.69s/it][A100%|██████████| 1/1 [05:36<00:00, 336.69s/it]
INFO:root:final mean train loss: 1777.1683161856247
INFO:root:final train perplexity: 4.761558532714844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1825.7500445859653
INFO:root:eval perplexity: 5.198714733123779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2228.5062372735206
INFO:root:eval perplexity: 7.751028537750244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/32
 16%|█▌        | 32/200 [3:16:11<17:12:51, 368.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.8408969613008
INFO:root:current train perplexity4.684142112731934
INFO:root:current mean train loss 1762.2755775718422
INFO:root:current train perplexity4.712014675140381
INFO:root:current mean train loss 1758.65915155607
INFO:root:current train perplexity4.693415641784668
INFO:root:current mean train loss 1760.4036808291955
INFO:root:current train perplexity4.701378345489502
INFO:root:current mean train loss 1758.2242004532309
INFO:root:current train perplexity4.694866180419922
INFO:root:current mean train loss 1763.2706132470794
INFO:root:current train perplexity4.703581809997559
INFO:root:current mean train loss 1761.4928498690829
INFO:root:current train perplexity4.699844837188721
INFO:root:current mean train loss 1767.2272980434577
INFO:root:current train perplexity4.714730739593506
INFO:root:current mean train loss 1768.1475983571045
INFO:root:current train perplexity4.716009616851807
INFO:root:current mean train loss 1768.1157216206589
INFO:root:current train perplexity4.716178894042969
INFO:root:current mean train loss 1769.1202470993378
INFO:root:current train perplexity4.7227253913879395
INFO:root:current mean train loss 1770.311338356265
INFO:root:current train perplexity4.721529006958008
INFO:root:current mean train loss 1769.286114153321
INFO:root:current train perplexity4.72508430480957
INFO:root:current mean train loss 1767.9875781868077
INFO:root:current train perplexity4.722971439361572
INFO:root:current mean train loss 1768.2432231096782
INFO:root:current train perplexity4.726369380950928
INFO:root:current mean train loss 1769.365056609613
INFO:root:current train perplexity4.728967666625977
INFO:root:current mean train loss 1770.7531085951764
INFO:root:current train perplexity4.732513427734375
INFO:root:current mean train loss 1770.7415938867075
INFO:root:current train perplexity4.7359619140625
INFO:root:current mean train loss 1771.4649055468537
INFO:root:current train perplexity4.735844612121582
INFO:root:current mean train loss 1771.7595318506135
INFO:root:current train perplexity4.736818790435791

100%|██████████| 1/1 [05:36<00:00, 336.77s/it][A100%|██████████| 1/1 [05:36<00:00, 336.77s/it]
INFO:root:final mean train loss: 1771.2768364472036
INFO:root:final train perplexity: 4.736987590789795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1823.869128937417
INFO:root:eval perplexity: 5.1898932456970215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2224.3114329669493
INFO:root:eval perplexity: 7.721206188201904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/33
 16%|█▋        | 33/200 [3:22:20<17:06:49, 368.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.170351155599
INFO:root:current train perplexity4.687607765197754
INFO:root:current mean train loss 1763.9772453308105
INFO:root:current train perplexity4.677028179168701
INFO:root:current mean train loss 1764.4973022460938
INFO:root:current train perplexity4.681859970092773
INFO:root:current mean train loss 1762.9703382703992
INFO:root:current train perplexity4.684803485870361
INFO:root:current mean train loss 1761.727635657269
INFO:root:current train perplexity4.687368392944336
INFO:root:current mean train loss 1760.0855747767857
INFO:root:current train perplexity4.691116809844971
INFO:root:current mean train loss 1758.3455812396426
INFO:root:current train perplexity4.6850504875183105
INFO:root:current mean train loss 1760.1499667519017
INFO:root:current train perplexity4.691004753112793
INFO:root:current mean train loss 1758.7933119662973
INFO:root:current train perplexity4.694186687469482
INFO:root:current mean train loss 1762.3751542409261
INFO:root:current train perplexity4.698023796081543
INFO:root:current mean train loss 1763.7255032521373
INFO:root:current train perplexity4.704746246337891
INFO:root:current mean train loss 1763.0790347395273
INFO:root:current train perplexity4.699338912963867
INFO:root:current mean train loss 1765.510065762959
INFO:root:current train perplexity4.705544948577881
INFO:root:current mean train loss 1763.8037532133214
INFO:root:current train perplexity4.702846527099609
INFO:root:current mean train loss 1763.9739438409674
INFO:root:current train perplexity4.702237606048584
INFO:root:current mean train loss 1763.991192157452
INFO:root:current train perplexity4.701346397399902
INFO:root:current mean train loss 1763.9577529355704
INFO:root:current train perplexity4.701578617095947
INFO:root:current mean train loss 1763.63552162864
INFO:root:current train perplexity4.701672554016113
INFO:root:current mean train loss 1764.1105746361518
INFO:root:current train perplexity4.705866813659668
INFO:root:current mean train loss 1764.2525383151308
INFO:root:current train perplexity4.706767559051514

100%|██████████| 1/1 [05:36<00:00, 336.48s/it][A100%|██████████| 1/1 [05:36<00:00, 336.48s/it]
INFO:root:final mean train loss: 1764.217849123556
INFO:root:final train perplexity: 4.707716941833496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1822.3022322417996
INFO:root:eval perplexity: 5.182556629180908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2227.2043037144003
INFO:root:eval perplexity: 7.741759300231934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/34
 17%|█▋        | 34/200 [3:28:29<17:00:29, 368.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.1389033329951
INFO:root:current train perplexity4.694973468780518
INFO:root:current mean train loss 1747.2903473417637
INFO:root:current train perplexity4.675418853759766
INFO:root:current mean train loss 1747.8777719215366
INFO:root:current train perplexity4.668111801147461
INFO:root:current mean train loss 1751.6178428589192
INFO:root:current train perplexity4.665178298950195
INFO:root:current mean train loss 1752.937669670057
INFO:root:current train perplexity4.666316032409668
INFO:root:current mean train loss 1754.2896624851062
INFO:root:current train perplexity4.669251441955566
INFO:root:current mean train loss 1756.2304741593196
INFO:root:current train perplexity4.671721935272217
INFO:root:current mean train loss 1756.6915883342886
INFO:root:current train perplexity4.670968532562256
INFO:root:current mean train loss 1754.4232891783067
INFO:root:current train perplexity4.66954231262207
INFO:root:current mean train loss 1754.8533748130837
INFO:root:current train perplexity4.672298431396484
INFO:root:current mean train loss 1756.0986815499507
INFO:root:current train perplexity4.669666290283203
INFO:root:current mean train loss 1756.9811807403953
INFO:root:current train perplexity4.675670146942139
INFO:root:current mean train loss 1756.6294356355838
INFO:root:current train perplexity4.676865100860596
INFO:root:current mean train loss 1757.337884330888
INFO:root:current train perplexity4.6782546043396
INFO:root:current mean train loss 1757.3050491653266
INFO:root:current train perplexity4.678945541381836
INFO:root:current mean train loss 1758.9179016384205
INFO:root:current train perplexity4.6827569007873535
INFO:root:current mean train loss 1758.120373193039
INFO:root:current train perplexity4.683500289916992
INFO:root:current mean train loss 1758.8895960235166
INFO:root:current train perplexity4.684046745300293
INFO:root:current mean train loss 1758.6136066190854
INFO:root:current train perplexity4.681666851043701
INFO:root:current mean train loss 1758.3744956649912
INFO:root:current train perplexity4.6819233894348145

100%|██████████| 1/1 [05:36<00:00, 336.27s/it][A100%|██████████| 1/1 [05:36<00:00, 336.27s/it]
INFO:root:final mean train loss: 1757.9596026675965
INFO:root:final train perplexity: 4.681915283203125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1820.1091486071864
INFO:root:eval perplexity: 5.172304153442383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2226.2917878712324
INFO:root:eval perplexity: 7.735272407531738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/35
 18%|█▊        | 35/200 [3:34:38<16:54:11, 368.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1741.0377963451629
INFO:root:current train perplexity4.626101016998291
INFO:root:current mean train loss 1754.9193134111229
INFO:root:current train perplexity4.6590495109558105
INFO:root:current mean train loss 1753.8521350678943
INFO:root:current train perplexity4.653322219848633
INFO:root:current mean train loss 1752.3385037649707
INFO:root:current train perplexity4.652219772338867
INFO:root:current mean train loss 1750.742588058657
INFO:root:current train perplexity4.652956962585449
INFO:root:current mean train loss 1750.82917636653
INFO:root:current train perplexity4.652424335479736
INFO:root:current mean train loss 1748.4527035584024
INFO:root:current train perplexity4.6497483253479
INFO:root:current mean train loss 1747.1078628040382
INFO:root:current train perplexity4.642261505126953
INFO:root:current mean train loss 1748.346217076517
INFO:root:current train perplexity4.641696453094482
INFO:root:current mean train loss 1750.1532084351813
INFO:root:current train perplexity4.64943265914917
INFO:root:current mean train loss 1750.359953439214
INFO:root:current train perplexity4.650155544281006
INFO:root:current mean train loss 1748.70148369615
INFO:root:current train perplexity4.650521278381348
INFO:root:current mean train loss 1747.8515265581227
INFO:root:current train perplexity4.65128231048584
INFO:root:current mean train loss 1748.5345724316546
INFO:root:current train perplexity4.652875900268555
INFO:root:current mean train loss 1750.8464013116268
INFO:root:current train perplexity4.654383182525635
INFO:root:current mean train loss 1751.226556909578
INFO:root:current train perplexity4.6587934494018555
INFO:root:current mean train loss 1751.3191642175739
INFO:root:current train perplexity4.65908670425415
INFO:root:current mean train loss 1752.4143397778837
INFO:root:current train perplexity4.6579365730285645
INFO:root:current mean train loss 1751.9664581846662
INFO:root:current train perplexity4.655188083648682

100%|██████████| 1/1 [05:36<00:00, 336.58s/it][A100%|██████████| 1/1 [05:36<00:00, 336.58s/it]
INFO:root:final mean train loss: 1751.135927016604
INFO:root:final train perplexity: 4.653944969177246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 1819.0844471167165
INFO:root:eval perplexity: 5.167521953582764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2227.060913518811
INFO:root:eval perplexity: 7.7407402992248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/36
 18%|█▊        | 36/200 [3:40:46<16:48:09, 368.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.9467995383523
INFO:root:current train perplexity4.503493309020996
INFO:root:current mean train loss 1743.5478504627674
INFO:root:current train perplexity4.616596221923828
INFO:root:current mean train loss 1747.1177955374333
INFO:root:current train perplexity4.6197428703308105
INFO:root:current mean train loss 1748.6236116955135
INFO:root:current train perplexity4.634047031402588
INFO:root:current mean train loss 1743.9584334250494
INFO:root:current train perplexity4.616429805755615
INFO:root:current mean train loss 1745.8363533990491
INFO:root:current train perplexity4.626987934112549
INFO:root:current mean train loss 1741.568878223775
INFO:root:current train perplexity4.617854118347168
INFO:root:current mean train loss 1740.862390874978
INFO:root:current train perplexity4.6157684326171875
INFO:root:current mean train loss 1742.9804232934841
INFO:root:current train perplexity4.618983268737793
INFO:root:current mean train loss 1741.9828406123509
INFO:root:current train perplexity4.620369911193848
INFO:root:current mean train loss 1740.716250033808
INFO:root:current train perplexity4.6190924644470215
INFO:root:current mean train loss 1741.344960924315
INFO:root:current train perplexity4.618159294128418
INFO:root:current mean train loss 1742.211950552552
INFO:root:current train perplexity4.62066650390625
INFO:root:current mean train loss 1742.8186668320343
INFO:root:current train perplexity4.62474250793457
INFO:root:current mean train loss 1742.8138832616771
INFO:root:current train perplexity4.624863624572754
INFO:root:current mean train loss 1744.758236635765
INFO:root:current train perplexity4.626911163330078
INFO:root:current mean train loss 1745.7201039120694
INFO:root:current train perplexity4.629547119140625
INFO:root:current mean train loss 1746.5873308566354
INFO:root:current train perplexity4.632874011993408
INFO:root:current mean train loss 1746.885324142178
INFO:root:current train perplexity4.635447978973389
INFO:root:current mean train loss 1747.4286082860128
INFO:root:current train perplexity4.636178016662598

100%|██████████| 1/1 [05:37<00:00, 337.08s/it][A100%|██████████| 1/1 [05:37<00:00, 337.08s/it]
INFO:root:final mean train loss: 1746.7324842644412
INFO:root:final train perplexity: 4.635984420776367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1817.9392821399879
INFO:root:eval perplexity: 5.162181377410889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2226.3740074211823
INFO:root:eval perplexity: 7.735857009887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/37
 18%|█▊        | 37/200 [3:46:56<16:42:30, 369.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.8097839355469
INFO:root:current train perplexity4.691962718963623
INFO:root:current mean train loss 1746.0049934387207
INFO:root:current train perplexity4.633180141448975
INFO:root:current mean train loss 1733.2176176372327
INFO:root:current train perplexity4.598965644836426
INFO:root:current mean train loss 1736.7040315953698
INFO:root:current train perplexity4.606256484985352
INFO:root:current mean train loss 1734.3492987802094
INFO:root:current train perplexity4.5982279777526855
INFO:root:current mean train loss 1736.6649179169626
INFO:root:current train perplexity4.605645179748535
INFO:root:current mean train loss 1737.136276731066
INFO:root:current train perplexity4.614431381225586
INFO:root:current mean train loss 1735.8912303211926
INFO:root:current train perplexity4.608588695526123
INFO:root:current mean train loss 1734.9443744161854
INFO:root:current train perplexity4.600331783294678
INFO:root:current mean train loss 1735.6926199814368
INFO:root:current train perplexity4.60405158996582
INFO:root:current mean train loss 1736.2467260694689
INFO:root:current train perplexity4.602973461151123
INFO:root:current mean train loss 1737.8597468382923
INFO:root:current train perplexity4.607850074768066
INFO:root:current mean train loss 1738.0865746911263
INFO:root:current train perplexity4.608749866485596
INFO:root:current mean train loss 1740.6929489503425
INFO:root:current train perplexity4.612036228179932
INFO:root:current mean train loss 1741.3999020872998
INFO:root:current train perplexity4.60914421081543
INFO:root:current mean train loss 1741.0986499886237
INFO:root:current train perplexity4.607210159301758
INFO:root:current mean train loss 1741.2845330015741
INFO:root:current train perplexity4.608126640319824
INFO:root:current mean train loss 1741.8510907491047
INFO:root:current train perplexity4.607856273651123
INFO:root:current mean train loss 1741.864304356815
INFO:root:current train perplexity4.611334800720215
INFO:root:current mean train loss 1740.9157413466837
INFO:root:current train perplexity4.610453128814697

100%|██████████| 1/1 [05:36<00:00, 336.48s/it][A100%|██████████| 1/1 [05:36<00:00, 336.48s/it]
INFO:root:final mean train loss: 1740.306153698035
INFO:root:final train perplexity: 4.609896659851074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 1817.473019863697
INFO:root:eval perplexity: 5.160009384155273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2227.033476268146
INFO:root:eval perplexity: 7.740546703338623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/38
 19%|█▉        | 38/200 [3:53:05<16:36:04, 368.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.5194390190973
INFO:root:current train perplexity4.50223970413208
INFO:root:current mean train loss 1729.789565934806
INFO:root:current train perplexity4.547773361206055
INFO:root:current mean train loss 1731.317764967315
INFO:root:current train perplexity4.567476272583008
INFO:root:current mean train loss 1733.5091924252717
INFO:root:current train perplexity4.562903881072998
INFO:root:current mean train loss 1733.1136161889922
INFO:root:current train perplexity4.563749313354492
INFO:root:current mean train loss 1732.0782334073967
INFO:root:current train perplexity4.574545383453369
INFO:root:current mean train loss 1733.5551604514899
INFO:root:current train perplexity4.574536323547363
INFO:root:current mean train loss 1733.0687257497902
INFO:root:current train perplexity4.5764079093933105
INFO:root:current mean train loss 1732.0860069861778
INFO:root:current train perplexity4.575050354003906
INFO:root:current mean train loss 1733.131845754795
INFO:root:current train perplexity4.576548099517822
INFO:root:current mean train loss 1734.2762890391373
INFO:root:current train perplexity4.576946258544922
INFO:root:current mean train loss 1733.0261119592658
INFO:root:current train perplexity4.5761003494262695
INFO:root:current mean train loss 1731.9838994650477
INFO:root:current train perplexity4.576498508453369
INFO:root:current mean train loss 1732.260713598542
INFO:root:current train perplexity4.581008434295654
INFO:root:current mean train loss 1732.4062083524816
INFO:root:current train perplexity4.581355571746826
INFO:root:current mean train loss 1733.9707112630208
INFO:root:current train perplexity4.585459232330322
INFO:root:current mean train loss 1734.6044075174534
INFO:root:current train perplexity4.58734655380249
INFO:root:current mean train loss 1735.4975873449812
INFO:root:current train perplexity4.589499473571777
INFO:root:current mean train loss 1735.1342509448043
INFO:root:current train perplexity4.587995529174805
INFO:root:current mean train loss 1735.0497433699188
INFO:root:current train perplexity4.588228702545166

100%|██████████| 1/1 [05:37<00:00, 337.08s/it][A100%|██████████| 1/1 [05:37<00:00, 337.08s/it]
INFO:root:final mean train loss: 1734.8259094515295
INFO:root:final train perplexity: 4.587765216827393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1816.4850784193538
INFO:root:eval perplexity: 5.1554083824157715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.83s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 2228.6097883941434
INFO:root:eval perplexity: 7.751768112182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/39
 20%|█▉        | 39/200 [3:59:14<16:30:25, 369.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.0223959645916
INFO:root:current train perplexity4.531781196594238
INFO:root:current mean train loss 1714.4550487377026
INFO:root:current train perplexity4.512509822845459
INFO:root:current mean train loss 1724.605360191287
INFO:root:current train perplexity4.544748783111572
INFO:root:current mean train loss 1724.5604949445355
INFO:root:current train perplexity4.548488140106201
INFO:root:current mean train loss 1725.1205779897186
INFO:root:current train perplexity4.553727626800537
INFO:root:current mean train loss 1725.1455664583796
INFO:root:current train perplexity4.54910945892334
INFO:root:current mean train loss 1727.518659608962
INFO:root:current train perplexity4.553021430969238
INFO:root:current mean train loss 1727.8124171780164
INFO:root:current train perplexity4.5538859367370605
INFO:root:current mean train loss 1727.6707698529945
INFO:root:current train perplexity4.554903507232666
INFO:root:current mean train loss 1729.9697468652546
INFO:root:current train perplexity4.559406280517578
INFO:root:current mean train loss 1729.4820929058528
INFO:root:current train perplexity4.561778545379639
INFO:root:current mean train loss 1729.1817476728902
INFO:root:current train perplexity4.560719013214111
INFO:root:current mean train loss 1729.2789455601228
INFO:root:current train perplexity4.560735702514648
INFO:root:current mean train loss 1729.496260453951
INFO:root:current train perplexity4.562931537628174
INFO:root:current mean train loss 1729.0481885500385
INFO:root:current train perplexity4.5650105476379395
INFO:root:current mean train loss 1728.350332028124
INFO:root:current train perplexity4.560901165008545
INFO:root:current mean train loss 1728.6951937348404
INFO:root:current train perplexity4.559996128082275
INFO:root:current mean train loss 1728.1492967724664
INFO:root:current train perplexity4.5595269203186035
INFO:root:current mean train loss 1729.0001431146575
INFO:root:current train perplexity4.5615153312683105
INFO:root:current mean train loss 1729.0125224728831
INFO:root:current train perplexity4.561941623687744

100%|██████████| 1/1 [05:35<00:00, 335.82s/it][A100%|██████████| 1/1 [05:35<00:00, 335.83s/it]
INFO:root:final mean train loss: 1728.803559442271
INFO:root:final train perplexity: 4.563567638397217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1814.4477223064882
INFO:root:eval perplexity: 5.145933628082275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2225.409502178219
INFO:root:eval perplexity: 7.729004383087158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/40
 20%|██        | 40/200 [4:05:22<16:23:30, 368.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1719.32289915447
INFO:root:current train perplexity4.545309543609619
INFO:root:current mean train loss 1716.7868686441602
INFO:root:current train perplexity4.537142276763916
INFO:root:current mean train loss 1714.024870841734
INFO:root:current train perplexity4.508306503295898
INFO:root:current mean train loss 1718.4614016248556
INFO:root:current train perplexity4.532419204711914
INFO:root:current mean train loss 1720.7942972521691
INFO:root:current train perplexity4.536809921264648
INFO:root:current mean train loss 1722.6817582678918
INFO:root:current train perplexity4.543739318847656
INFO:root:current mean train loss 1726.3888439240266
INFO:root:current train perplexity4.5476603507995605
INFO:root:current mean train loss 1725.4895796769697
INFO:root:current train perplexity4.5443620681762695
INFO:root:current mean train loss 1725.0284057200565
INFO:root:current train perplexity4.544723033905029
INFO:root:current mean train loss 1722.1718205110046
INFO:root:current train perplexity4.53751277923584
INFO:root:current mean train loss 1722.4392803711842
INFO:root:current train perplexity4.538107872009277
INFO:root:current mean train loss 1721.2528834063892
INFO:root:current train perplexity4.538054943084717
INFO:root:current mean train loss 1721.1878856811047
INFO:root:current train perplexity4.538258075714111
INFO:root:current mean train loss 1721.33698833153
INFO:root:current train perplexity4.536357879638672
INFO:root:current mean train loss 1722.3989193434647
INFO:root:current train perplexity4.538244724273682
INFO:root:current mean train loss 1722.6395482455273
INFO:root:current train perplexity4.5385870933532715
INFO:root:current mean train loss 1724.2403192934783
INFO:root:current train perplexity4.543025016784668
INFO:root:current mean train loss 1725.1906483710784
INFO:root:current train perplexity4.544856548309326
INFO:root:current mean train loss 1724.476098710771
INFO:root:current train perplexity4.543396472930908
INFO:root:current mean train loss 1724.4068380223796
INFO:root:current train perplexity4.54428768157959

100%|██████████| 1/1 [05:36<00:00, 336.69s/it][A100%|██████████| 1/1 [05:36<00:00, 336.69s/it]
INFO:root:final mean train loss: 1724.0850915336512
INFO:root:final train perplexity: 4.544698238372803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1813.5933855205562
INFO:root:eval perplexity: 5.141966342926025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2226.103877507203
INFO:root:eval perplexity: 7.7339372634887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/41
 20%|██        | 41/200 [4:11:31<16:17:27, 368.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.891637166341
INFO:root:current train perplexity4.441967487335205
INFO:root:current mean train loss 1701.239594751475
INFO:root:current train perplexity4.473430156707764
INFO:root:current mean train loss 1705.1322982375686
INFO:root:current train perplexity4.478783130645752
INFO:root:current mean train loss 1711.133125073982
INFO:root:current train perplexity4.492630481719971
INFO:root:current mean train loss 1713.606958696919
INFO:root:current train perplexity4.5001749992370605
INFO:root:current mean train loss 1713.5098031063208
INFO:root:current train perplexity4.5048394203186035
INFO:root:current mean train loss 1714.1090756120352
INFO:root:current train perplexity4.505568027496338
INFO:root:current mean train loss 1714.3582768272515
INFO:root:current train perplexity4.504395961761475
INFO:root:current mean train loss 1712.7064304351807
INFO:root:current train perplexity4.5007710456848145
INFO:root:current mean train loss 1713.5500321598895
INFO:root:current train perplexity4.504495620727539
INFO:root:current mean train loss 1715.1641064943187
INFO:root:current train perplexity4.5079169273376465
INFO:root:current mean train loss 1715.200286559038
INFO:root:current train perplexity4.508644104003906
INFO:root:current mean train loss 1715.919926678693
INFO:root:current train perplexity4.512228488922119
INFO:root:current mean train loss 1717.214242405058
INFO:root:current train perplexity4.516798496246338
INFO:root:current mean train loss 1717.5004106817398
INFO:root:current train perplexity4.517459392547607
INFO:root:current mean train loss 1718.2145962440281
INFO:root:current train perplexity4.518929958343506
INFO:root:current mean train loss 1718.5638218285903
INFO:root:current train perplexity4.52084493637085
INFO:root:current mean train loss 1718.332257175233
INFO:root:current train perplexity4.522378444671631
INFO:root:current mean train loss 1718.8457677656086
INFO:root:current train perplexity4.524055480957031

100%|██████████| 1/1 [05:36<00:00, 336.18s/it][A100%|██████████| 1/1 [05:36<00:00, 336.18s/it]
INFO:root:final mean train loss: 1718.7548074650151
INFO:root:final train perplexity: 4.523475646972656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1813.548828125
INFO:root:eval perplexity: 5.141759872436523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2229.1966851417055
INFO:root:eval perplexity: 7.7559494972229
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/42
 21%|██        | 42/200 [4:17:40<16:11:02, 368.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.9227576622595
INFO:root:current train perplexity4.5452046394348145
INFO:root:current mean train loss 1693.015526695589
INFO:root:current train perplexity4.462573051452637
INFO:root:current mean train loss 1696.7202990894586
INFO:root:current train perplexity4.466827392578125
INFO:root:current mean train loss 1701.625465661192
INFO:root:current train perplexity4.470127582550049
INFO:root:current mean train loss 1708.2619487032764
INFO:root:current train perplexity4.477227210998535
INFO:root:current mean train loss 1708.6775861297667
INFO:root:current train perplexity4.473374843597412
INFO:root:current mean train loss 1712.0911253887134
INFO:root:current train perplexity4.487786769866943
INFO:root:current mean train loss 1712.1393602967764
INFO:root:current train perplexity4.488605499267578
INFO:root:current mean train loss 1712.7254509544607
INFO:root:current train perplexity4.49827241897583
INFO:root:current mean train loss 1712.8896404153545
INFO:root:current train perplexity4.497537612915039
INFO:root:current mean train loss 1712.112965771147
INFO:root:current train perplexity4.496959209442139
INFO:root:current mean train loss 1714.1139487431913
INFO:root:current train perplexity4.500435829162598
INFO:root:current mean train loss 1713.3494255147684
INFO:root:current train perplexity4.499718189239502
INFO:root:current mean train loss 1712.4179114801505
INFO:root:current train perplexity4.498745441436768
INFO:root:current mean train loss 1713.7433179246561
INFO:root:current train perplexity4.500529766082764
INFO:root:current mean train loss 1714.174850110888
INFO:root:current train perplexity4.503838062286377
INFO:root:current mean train loss 1714.2000789937956
INFO:root:current train perplexity4.505125522613525
INFO:root:current mean train loss 1713.8038018666996
INFO:root:current train perplexity4.505825519561768
INFO:root:current mean train loss 1713.9177028616027
INFO:root:current train perplexity4.507031440734863
INFO:root:current mean train loss 1713.0071351469592
INFO:root:current train perplexity4.502443313598633

100%|██████████| 1/1 [05:36<00:00, 336.36s/it][A100%|██████████| 1/1 [05:36<00:00, 336.36s/it]
INFO:root:final mean train loss: 1713.7117268326183
INFO:root:final train perplexity: 4.503488540649414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1812.1057626710715
INFO:root:eval perplexity: 5.135064125061035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2230.4740695818095
INFO:root:eval perplexity: 7.765056610107422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/43
 22%|██▏       | 43/200 [4:23:48<16:04:53, 368.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1741.5977335611979
INFO:root:current train perplexity4.56649923324585
INFO:root:current mean train loss 1685.5504112830529
INFO:root:current train perplexity4.424479961395264
INFO:root:current mean train loss 1706.0978361710258
INFO:root:current train perplexity4.471147537231445
INFO:root:current mean train loss 1702.6837953509707
INFO:root:current train perplexity4.465257167816162
INFO:root:current mean train loss 1705.4598567519076
INFO:root:current train perplexity4.455841541290283
INFO:root:current mean train loss 1706.319130721182
INFO:root:current train perplexity4.456009387969971
INFO:root:current mean train loss 1704.9379470098586
INFO:root:current train perplexity4.463850021362305
INFO:root:current mean train loss 1705.309608940229
INFO:root:current train perplexity4.468533515930176
INFO:root:current mean train loss 1706.4064463420086
INFO:root:current train perplexity4.474727630615234
INFO:root:current mean train loss 1705.3985593077957
INFO:root:current train perplexity4.475735187530518
INFO:root:current mean train loss 1705.3125811826835
INFO:root:current train perplexity4.477658748626709
INFO:root:current mean train loss 1705.613296697836
INFO:root:current train perplexity4.479269981384277
INFO:root:current mean train loss 1706.5002629970147
INFO:root:current train perplexity4.479668617248535
INFO:root:current mean train loss 1706.874166158805
INFO:root:current train perplexity4.48098087310791
INFO:root:current mean train loss 1707.1085876038023
INFO:root:current train perplexity4.480935096740723
INFO:root:current mean train loss 1707.5423847273285
INFO:root:current train perplexity4.481234550476074
INFO:root:current mean train loss 1706.8608251653566
INFO:root:current train perplexity4.4803547859191895
INFO:root:current mean train loss 1706.9155364461028
INFO:root:current train perplexity4.476163387298584
INFO:root:current mean train loss 1707.884328373143
INFO:root:current train perplexity4.479493141174316
INFO:root:current mean train loss 1708.357700612755
INFO:root:current train perplexity4.479094505310059

100%|██████████| 1/1 [05:36<00:00, 336.44s/it][A100%|██████████| 1/1 [05:36<00:00, 336.44s/it]
INFO:root:final mean train loss: 1707.9637512114693
INFO:root:final train perplexity: 4.480813503265381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1808.970370245318
INFO:root:eval perplexity: 5.120547771453857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2225.4942808759974
INFO:root:eval perplexity: 7.729605197906494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/44
 22%|██▏       | 44/200 [4:29:57<15:58:47, 368.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.75724889877
INFO:root:current train perplexity4.430273056030273
INFO:root:current mean train loss 1697.0099591105973
INFO:root:current train perplexity4.443864345550537
INFO:root:current mean train loss 1703.9157863107287
INFO:root:current train perplexity4.453744411468506
INFO:root:current mean train loss 1700.3331277720865
INFO:root:current train perplexity4.459443092346191
INFO:root:current mean train loss 1703.610653051594
INFO:root:current train perplexity4.457373142242432
INFO:root:current mean train loss 1708.928812476791
INFO:root:current train perplexity4.468159198760986
INFO:root:current mean train loss 1707.0553831309771
INFO:root:current train perplexity4.460740089416504
INFO:root:current mean train loss 1705.5780076686956
INFO:root:current train perplexity4.460232734680176
INFO:root:current mean train loss 1705.0461957586979
INFO:root:current train perplexity4.4598388671875
INFO:root:current mean train loss 1703.42769312632
INFO:root:current train perplexity4.459568500518799
INFO:root:current mean train loss 1703.7999563718138
INFO:root:current train perplexity4.461062431335449
INFO:root:current mean train loss 1704.4704151369742
INFO:root:current train perplexity4.461768627166748
INFO:root:current mean train loss 1704.1643370847846
INFO:root:current train perplexity4.461457252502441
INFO:root:current mean train loss 1704.1751653703832
INFO:root:current train perplexity4.460933208465576
INFO:root:current mean train loss 1703.790554170536
INFO:root:current train perplexity4.462480068206787
INFO:root:current mean train loss 1703.1325839042047
INFO:root:current train perplexity4.4625244140625
INFO:root:current mean train loss 1703.5654582965715
INFO:root:current train perplexity4.463685512542725
INFO:root:current mean train loss 1703.6451012142468
INFO:root:current train perplexity4.464902877807617
INFO:root:current mean train loss 1703.7669273917586
INFO:root:current train perplexity4.464186668395996
INFO:root:current mean train loss 1704.1871650119776
INFO:root:current train perplexity4.46269416809082

100%|██████████| 1/1 [05:36<00:00, 336.81s/it][A100%|██████████| 1/1 [05:36<00:00, 336.81s/it]
INFO:root:final mean train loss: 1703.8451114564127
INFO:root:final train perplexity: 4.464637756347656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 1810.5127091644504
INFO:root:eval perplexity: 5.127683639526367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2229.3189398582945
INFO:root:eval perplexity: 7.756818771362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/45
 22%|██▎       | 45/200 [4:36:06<15:52:48, 368.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.7304401397705
INFO:root:current train perplexity4.350820064544678
INFO:root:current mean train loss 1681.8287896877382
INFO:root:current train perplexity4.422333717346191
INFO:root:current mean train loss 1697.0300889448686
INFO:root:current train perplexity4.429411888122559
INFO:root:current mean train loss 1693.830365526807
INFO:root:current train perplexity4.428738594055176
INFO:root:current mean train loss 1692.427588101091
INFO:root:current train perplexity4.429445266723633
INFO:root:current mean train loss 1693.353247892772
INFO:root:current train perplexity4.4281325340271
INFO:root:current mean train loss 1692.750792721668
INFO:root:current train perplexity4.421597480773926
INFO:root:current mean train loss 1694.0646648307122
INFO:root:current train perplexity4.426163196563721
INFO:root:current mean train loss 1694.5804384019639
INFO:root:current train perplexity4.432372570037842
INFO:root:current mean train loss 1695.6464794364708
INFO:root:current train perplexity4.438712120056152
INFO:root:current mean train loss 1696.210467575188
INFO:root:current train perplexity4.439342975616455
INFO:root:current mean train loss 1696.6036062338917
INFO:root:current train perplexity4.439718723297119
INFO:root:current mean train loss 1697.5493415156498
INFO:root:current train perplexity4.439800262451172
INFO:root:current mean train loss 1696.9919083670786
INFO:root:current train perplexity4.437937259674072
INFO:root:current mean train loss 1696.7149432239637
INFO:root:current train perplexity4.441708564758301
INFO:root:current mean train loss 1697.4298745079723
INFO:root:current train perplexity4.44482421875
INFO:root:current mean train loss 1698.6003626309907
INFO:root:current train perplexity4.445346355438232
INFO:root:current mean train loss 1698.5344037598763
INFO:root:current train perplexity4.445023059844971
INFO:root:current mean train loss 1699.0266469537955
INFO:root:current train perplexity4.44748067855835
INFO:root:current mean train loss 1699.4340773075517
INFO:root:current train perplexity4.446131706237793

100%|██████████| 1/1 [05:36<00:00, 336.07s/it][A100%|██████████| 1/1 [05:36<00:00, 336.07s/it]
INFO:root:final mean train loss: 1699.21611551582
INFO:root:final train perplexity: 4.446526527404785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 1810.8133683441379
INFO:root:eval perplexity: 5.1290764808654785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2231.7374691794103
INFO:root:eval perplexity: 7.774077892303467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/46
 23%|██▎       | 46/200 [4:42:15<15:46:20, 368.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1665.628547574267
INFO:root:current train perplexity4.385643005371094
INFO:root:current mean train loss 1689.6749112461152
INFO:root:current train perplexity4.436767101287842
INFO:root:current mean train loss 1683.8394301879448
INFO:root:current train perplexity4.411789417266846
INFO:root:current mean train loss 1686.835118891999
INFO:root:current train perplexity4.410637378692627
INFO:root:current mean train loss 1687.1547676451241
INFO:root:current train perplexity4.4145708084106445
INFO:root:current mean train loss 1685.6167675024876
INFO:root:current train perplexity4.412148952484131
INFO:root:current mean train loss 1687.2044579146018
INFO:root:current train perplexity4.417510509490967
INFO:root:current mean train loss 1686.6260378321062
INFO:root:current train perplexity4.416136741638184
INFO:root:current mean train loss 1687.0901969364093
INFO:root:current train perplexity4.4190263748168945
INFO:root:current mean train loss 1686.745973795075
INFO:root:current train perplexity4.417459487915039
INFO:root:current mean train loss 1689.093404566988
INFO:root:current train perplexity4.421497344970703
INFO:root:current mean train loss 1689.8841396658022
INFO:root:current train perplexity4.423520565032959
INFO:root:current mean train loss 1690.8416879551194
INFO:root:current train perplexity4.423473358154297
INFO:root:current mean train loss 1692.5500800307466
INFO:root:current train perplexity4.427685260772705
INFO:root:current mean train loss 1693.1934366889454
INFO:root:current train perplexity4.42687463760376
INFO:root:current mean train loss 1693.2381746218523
INFO:root:current train perplexity4.427371978759766
INFO:root:current mean train loss 1693.3081698806282
INFO:root:current train perplexity4.426741123199463
INFO:root:current mean train loss 1692.539170999329
INFO:root:current train perplexity4.424891471862793
INFO:root:current mean train loss 1693.0186204276524
INFO:root:current train perplexity4.425623893737793
INFO:root:current mean train loss 1694.3919174910675
INFO:root:current train perplexity4.425947189331055

100%|██████████| 1/1 [05:36<00:00, 336.45s/it][A100%|██████████| 1/1 [05:36<00:00, 336.45s/it]
INFO:root:final mean train loss: 1693.9965335232287
INFO:root:final train perplexity: 4.426192760467529
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1810.9314995082557
INFO:root:eval perplexity: 5.129623889923096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2234.626782139988
INFO:root:eval perplexity: 7.794745445251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/47
 24%|██▎       | 47/200 [4:48:23<15:40:13, 368.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1693.4316867127711
INFO:root:current train perplexity4.377450942993164
INFO:root:current mean train loss 1691.2099979285038
INFO:root:current train perplexity4.38367223739624
INFO:root:current mean train loss 1689.1226188096425
INFO:root:current train perplexity4.3895487785339355
INFO:root:current mean train loss 1690.146202815837
INFO:root:current train perplexity4.394222736358643
INFO:root:current mean train loss 1688.6897097668016
INFO:root:current train perplexity4.393269062042236
INFO:root:current mean train loss 1691.2455703582252
INFO:root:current train perplexity4.3951029777526855
INFO:root:current mean train loss 1688.6996786997447
INFO:root:current train perplexity4.394687175750732
INFO:root:current mean train loss 1690.1543101834175
INFO:root:current train perplexity4.396352291107178
INFO:root:current mean train loss 1692.4849440270914
INFO:root:current train perplexity4.403961181640625
INFO:root:current mean train loss 1695.3638684840384
INFO:root:current train perplexity4.409299373626709
INFO:root:current mean train loss 1695.1080870359106
INFO:root:current train perplexity4.410783290863037
INFO:root:current mean train loss 1694.3697334506078
INFO:root:current train perplexity4.408672332763672
INFO:root:current mean train loss 1693.0197419106316
INFO:root:current train perplexity4.406075477600098
INFO:root:current mean train loss 1693.7898537740857
INFO:root:current train perplexity4.410004138946533
INFO:root:current mean train loss 1692.5603996246298
INFO:root:current train perplexity4.41010046005249
INFO:root:current mean train loss 1690.6507331552136
INFO:root:current train perplexity4.408193588256836
INFO:root:current mean train loss 1690.1183588861436
INFO:root:current train perplexity4.405376434326172
INFO:root:current mean train loss 1690.8849760231637
INFO:root:current train perplexity4.40687894821167
INFO:root:current mean train loss 1690.7149436958723
INFO:root:current train perplexity4.409255504608154

100%|██████████| 1/1 [05:36<00:00, 336.73s/it][A100%|██████████| 1/1 [05:36<00:00, 336.73s/it]
INFO:root:final mean train loss: 1689.8585816353063
INFO:root:final train perplexity: 4.4101386070251465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1811.6292434584163
INFO:root:eval perplexity: 5.1328558921813965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2235.0846670164283
INFO:root:eval perplexity: 7.7980265617370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/48
 24%|██▍       | 48/200 [4:54:32<15:34:16, 368.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.658846028646
INFO:root:current train perplexity4.541807174682617
INFO:root:current mean train loss 1679.4469015370244
INFO:root:current train perplexity4.372017860412598
INFO:root:current mean train loss 1679.418701739644
INFO:root:current train perplexity4.35696268081665
INFO:root:current mean train loss 1677.4692642454118
INFO:root:current train perplexity4.3640336990356445
INFO:root:current mean train loss 1680.5274464067206
INFO:root:current train perplexity4.369133472442627
INFO:root:current mean train loss 1682.5697497914139
INFO:root:current train perplexity4.374588966369629
INFO:root:current mean train loss 1682.0687674669716
INFO:root:current train perplexity4.369346618652344
INFO:root:current mean train loss 1681.3757503482846
INFO:root:current train perplexity4.3725056648254395
INFO:root:current mean train loss 1681.4482306544767
INFO:root:current train perplexity4.374601364135742
INFO:root:current mean train loss 1681.1990094294313
INFO:root:current train perplexity4.37792444229126
INFO:root:current mean train loss 1682.57217482393
INFO:root:current train perplexity4.382434368133545
INFO:root:current mean train loss 1682.8718546367013
INFO:root:current train perplexity4.387473106384277
INFO:root:current mean train loss 1683.0374452441808
INFO:root:current train perplexity4.386124610900879
INFO:root:current mean train loss 1683.0933328258675
INFO:root:current train perplexity4.388986110687256
INFO:root:current mean train loss 1684.0185701296102
INFO:root:current train perplexity4.3906145095825195
INFO:root:current mean train loss 1683.4312150306828
INFO:root:current train perplexity4.387945175170898
INFO:root:current mean train loss 1684.951690163627
INFO:root:current train perplexity4.391353607177734
INFO:root:current mean train loss 1685.5175426071655
INFO:root:current train perplexity4.3922576904296875
INFO:root:current mean train loss 1685.9213487189006
INFO:root:current train perplexity4.392818927764893
INFO:root:current mean train loss 1685.8617929483519
INFO:root:current train perplexity4.391576766967773

100%|██████████| 1/1 [05:36<00:00, 336.71s/it][A100%|██████████| 1/1 [05:36<00:00, 336.71s/it]
INFO:root:final mean train loss: 1685.0714866649726
INFO:root:final train perplexity: 4.391639232635498
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1808.8505465460162
INFO:root:eval perplexity: 5.119994163513184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2233.4651082356772
INFO:root:eval perplexity: 7.7864298820495605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/49
 24%|██▍       | 49/200 [5:00:42<15:28:23, 368.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.2744216918945
INFO:root:current train perplexity4.348393440246582
INFO:root:current mean train loss 1689.4565179998224
INFO:root:current train perplexity4.373170852661133
INFO:root:current mean train loss 1680.896833748653
INFO:root:current train perplexity4.357843399047852
INFO:root:current mean train loss 1681.3140692653426
INFO:root:current train perplexity4.360150337219238
INFO:root:current mean train loss 1689.4148217660409
INFO:root:current train perplexity4.377563953399658
INFO:root:current mean train loss 1684.1441391105939
INFO:root:current train perplexity4.362518310546875
INFO:root:current mean train loss 1686.1066025359721
INFO:root:current train perplexity4.376485824584961
INFO:root:current mean train loss 1684.9859222245348
INFO:root:current train perplexity4.374601364135742
INFO:root:current mean train loss 1682.721274155837
INFO:root:current train perplexity4.371884346008301
INFO:root:current mean train loss 1683.258231363583
INFO:root:current train perplexity4.369036674499512
INFO:root:current mean train loss 1681.8021729935047
INFO:root:current train perplexity4.368885517120361
INFO:root:current mean train loss 1680.4425319496397
INFO:root:current train perplexity4.366313934326172
INFO:root:current mean train loss 1680.3293621509106
INFO:root:current train perplexity4.3660407066345215
INFO:root:current mean train loss 1681.517361569333
INFO:root:current train perplexity4.370758056640625
INFO:root:current mean train loss 1682.085145577372
INFO:root:current train perplexity4.371975898742676
INFO:root:current mean train loss 1681.6897640377672
INFO:root:current train perplexity4.370640754699707
INFO:root:current mean train loss 1681.9921748591405
INFO:root:current train perplexity4.37089204788208
INFO:root:current mean train loss 1681.6555456994038
INFO:root:current train perplexity4.3704962730407715
INFO:root:current mean train loss 1681.4987561754785
INFO:root:current train perplexity4.372445583343506
INFO:root:current mean train loss 1681.389900665599
INFO:root:current train perplexity4.373393535614014

100%|██████████| 1/1 [05:36<00:00, 336.33s/it][A100%|██████████| 1/1 [05:36<00:00, 336.33s/it]
INFO:root:final mean train loss: 1680.1499269055528
INFO:root:final train perplexity: 4.3727006912231445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1810.9295974623226
INFO:root:eval perplexity: 5.129613876342773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2238.4626122873724
INFO:root:eval perplexity: 7.822268962860107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/50
 25%|██▌       | 50/200 [5:06:50<15:21:59, 368.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1690.582706373565
INFO:root:current train perplexity4.397363662719727
INFO:root:current mean train loss 1682.9271821911702
INFO:root:current train perplexity4.36358642578125
INFO:root:current mean train loss 1680.1953928997239
INFO:root:current train perplexity4.347562789916992
INFO:root:current mean train loss 1675.2988648510252
INFO:root:current train perplexity4.347227096557617
INFO:root:current mean train loss 1676.0696613677094
INFO:root:current train perplexity4.346220016479492
INFO:root:current mean train loss 1679.5608810674948
INFO:root:current train perplexity4.352240085601807
INFO:root:current mean train loss 1679.8553346419371
INFO:root:current train perplexity4.35907506942749
INFO:root:current mean train loss 1678.7763015074788
INFO:root:current train perplexity4.3495683670043945
INFO:root:current mean train loss 1679.1871138034637
INFO:root:current train perplexity4.352179050445557
INFO:root:current mean train loss 1677.5889878428773
INFO:root:current train perplexity4.351916790008545
INFO:root:current mean train loss 1678.217793452842
INFO:root:current train perplexity4.350438594818115
INFO:root:current mean train loss 1676.9323417059331
INFO:root:current train perplexity4.35053825378418
INFO:root:current mean train loss 1676.3150372837333
INFO:root:current train perplexity4.3493146896362305
INFO:root:current mean train loss 1676.8088211500706
INFO:root:current train perplexity4.350987911224365
INFO:root:current mean train loss 1677.6068274456522
INFO:root:current train perplexity4.352858066558838
INFO:root:current mean train loss 1678.093453295851
INFO:root:current train perplexity4.35479211807251
INFO:root:current mean train loss 1677.9750410256927
INFO:root:current train perplexity4.358776092529297
INFO:root:current mean train loss 1676.863049602563
INFO:root:current train perplexity4.358065128326416
INFO:root:current mean train loss 1677.4489399490644
INFO:root:current train perplexity4.361603260040283
INFO:root:current mean train loss 1676.6462858933066
INFO:root:current train perplexity4.3579182624816895

100%|██████████| 1/1 [05:35<00:00, 335.75s/it][A100%|██████████| 1/1 [05:35<00:00, 335.75s/it]
INFO:root:final mean train loss: 1676.6494114770471
INFO:root:final train perplexity: 4.359279632568359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 1810.2084173107824
INFO:root:eval perplexity: 5.126275539398193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2235.760972909048
INFO:root:eval perplexity: 7.802873134613037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/51
 26%|██▌       | 51/200 [5:12:58<15:15:19, 368.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1633.3317630652225
INFO:root:current train perplexity4.268756866455078
INFO:root:current mean train loss 1653.5978606810052
INFO:root:current train perplexity4.269639015197754
INFO:root:current mean train loss 1646.923412810591
INFO:root:current train perplexity4.272124290466309
INFO:root:current mean train loss 1649.5890109369664
INFO:root:current train perplexity4.28565788269043
INFO:root:current mean train loss 1656.506328795601
INFO:root:current train perplexity4.293240070343018
INFO:root:current mean train loss 1661.8040590319954
INFO:root:current train perplexity4.303215980529785
INFO:root:current mean train loss 1666.9697973119603
INFO:root:current train perplexity4.319095611572266
INFO:root:current mean train loss 1669.7813245808175
INFO:root:current train perplexity4.322962284088135
INFO:root:current mean train loss 1669.2400962353854
INFO:root:current train perplexity4.3254475593566895
INFO:root:current mean train loss 1667.9835984761178
INFO:root:current train perplexity4.325661659240723
INFO:root:current mean train loss 1668.6400784318935
INFO:root:current train perplexity4.332068920135498
INFO:root:current mean train loss 1668.668104220827
INFO:root:current train perplexity4.3309855461120605
INFO:root:current mean train loss 1669.0123800124038
INFO:root:current train perplexity4.328485012054443
INFO:root:current mean train loss 1668.8597083252312
INFO:root:current train perplexity4.3333282470703125
INFO:root:current mean train loss 1669.3430812778447
INFO:root:current train perplexity4.334843158721924
INFO:root:current mean train loss 1669.712217757224
INFO:root:current train perplexity4.334984302520752
INFO:root:current mean train loss 1671.335579642013
INFO:root:current train perplexity4.337186336517334
INFO:root:current mean train loss 1671.7585955886582
INFO:root:current train perplexity4.338474750518799
INFO:root:current mean train loss 1671.7836756404702
INFO:root:current train perplexity4.338728904724121
INFO:root:current mean train loss 1672.294145058276
INFO:root:current train perplexity4.340946674346924

100%|██████████| 1/1 [05:36<00:00, 336.12s/it][A100%|██████████| 1/1 [05:36<00:00, 336.12s/it]
INFO:root:final mean train loss: 1671.7745612486408
INFO:root:final train perplexity: 4.340659141540527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1807.5818433829234
INFO:root:eval perplexity: 5.114133358001709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2233.8191775058176
INFO:root:eval perplexity: 7.788962364196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/52
 26%|██▌       | 52/200 [5:19:07<15:09:01, 368.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1667.0521416721574
INFO:root:current train perplexity4.289829730987549
INFO:root:current mean train loss 1674.400771511057
INFO:root:current train perplexity4.297874927520752
INFO:root:current mean train loss 1672.7186141266839
INFO:root:current train perplexity4.305619716644287
INFO:root:current mean train loss 1673.1886735323515
INFO:root:current train perplexity4.314120769500732
INFO:root:current mean train loss 1670.6096924333592
INFO:root:current train perplexity4.318519115447998
INFO:root:current mean train loss 1668.8925588617603
INFO:root:current train perplexity4.323428630828857
INFO:root:current mean train loss 1670.4524193871248
INFO:root:current train perplexity4.3248610496521
INFO:root:current mean train loss 1668.3287967764707
INFO:root:current train perplexity4.32616662979126
INFO:root:current mean train loss 1667.0604022707566
INFO:root:current train perplexity4.330530166625977
INFO:root:current mean train loss 1665.9002866851713
INFO:root:current train perplexity4.328956127166748
INFO:root:current mean train loss 1667.0813894509608
INFO:root:current train perplexity4.3333420753479
INFO:root:current mean train loss 1667.395495842799
INFO:root:current train perplexity4.331389904022217
INFO:root:current mean train loss 1668.0681976294572
INFO:root:current train perplexity4.327615261077881
INFO:root:current mean train loss 1668.3084428170757
INFO:root:current train perplexity4.326733112335205
INFO:root:current mean train loss 1669.030714141784
INFO:root:current train perplexity4.328667640686035
INFO:root:current mean train loss 1668.6786918905213
INFO:root:current train perplexity4.327516078948975
INFO:root:current mean train loss 1668.9398686572758
INFO:root:current train perplexity4.327389240264893
INFO:root:current mean train loss 1669.1374940984515
INFO:root:current train perplexity4.328512668609619
INFO:root:current mean train loss 1669.3023934468144
INFO:root:current train perplexity4.327250003814697
INFO:root:current mean train loss 1668.1902247595774
INFO:root:current train perplexity4.3270182609558105

100%|██████████| 1/1 [05:36<00:00, 336.14s/it][A100%|██████████| 1/1 [05:36<00:00, 336.14s/it]
INFO:root:final mean train loss: 1668.1902247595774
INFO:root:final train perplexity: 4.3270182609558105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.83s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 1809.9997459032857
INFO:root:eval perplexity: 5.125309467315674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2241.247211429244
INFO:root:eval perplexity: 7.842311382293701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/53
 26%|██▋       | 53/200 [5:25:15<15:02:55, 368.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1652.2101928710938
INFO:root:current train perplexity4.26841402053833
INFO:root:current mean train loss 1663.0001623535156
INFO:root:current train perplexity4.291536331176758
INFO:root:current mean train loss 1656.9900549316405
INFO:root:current train perplexity4.29054069519043
INFO:root:current mean train loss 1656.6677508544922
INFO:root:current train perplexity4.284830093383789
INFO:root:current mean train loss 1655.4261577148438
INFO:root:current train perplexity4.285096645355225
INFO:root:current mean train loss 1656.62851175944
INFO:root:current train perplexity4.290486812591553
INFO:root:current mean train loss 1657.1608096749442
INFO:root:current train perplexity4.293542385101318
INFO:root:current mean train loss 1656.5227322387695
INFO:root:current train perplexity4.293986797332764
INFO:root:current mean train loss 1658.094572075738
INFO:root:current train perplexity4.2965617179870605
INFO:root:current mean train loss 1658.2044809570311
INFO:root:current train perplexity4.297760486602783
INFO:root:current mean train loss 1659.8481288840553
INFO:root:current train perplexity4.301182746887207
INFO:root:current mean train loss 1657.606227315267
INFO:root:current train perplexity4.2971625328063965
INFO:root:current mean train loss 1657.521719125601
INFO:root:current train perplexity4.301023006439209
INFO:root:current mean train loss 1659.1056809779575
INFO:root:current train perplexity4.303966045379639
INFO:root:current mean train loss 1660.069637125651
INFO:root:current train perplexity4.303403377532959
INFO:root:current mean train loss 1661.3332017517089
INFO:root:current train perplexity4.306201934814453
INFO:root:current mean train loss 1662.524482278263
INFO:root:current train perplexity4.3076395988464355
INFO:root:current mean train loss 1663.6798821343316
INFO:root:current train perplexity4.307803153991699
INFO:root:current mean train loss 1663.6300389982525
INFO:root:current train perplexity4.307333469390869

100%|██████████| 1/1 [05:35<00:00, 335.75s/it][A100%|██████████| 1/1 [05:35<00:00, 335.75s/it]
INFO:root:final mean train loss: 1663.385460619366
INFO:root:final train perplexity: 4.308799743652344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1809.001975201546
INFO:root:eval perplexity: 5.120694160461426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2238.370250079649
INFO:root:eval perplexity: 7.8216047286987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/54
 27%|██▋       | 54/200 [5:31:23<14:56:27, 368.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.0763083065258
INFO:root:current train perplexity4.256344795227051
INFO:root:current mean train loss 1676.9354060246394
INFO:root:current train perplexity4.316259384155273
INFO:root:current mean train loss 1669.4783294255833
INFO:root:current train perplexity4.287678241729736
INFO:root:current mean train loss 1662.6966891604643
INFO:root:current train perplexity4.287303924560547
INFO:root:current mean train loss 1661.2937231269673
INFO:root:current train perplexity4.283820629119873
INFO:root:current mean train loss 1659.2344160836255
INFO:root:current train perplexity4.282474994659424
INFO:root:current mean train loss 1660.5364663790265
INFO:root:current train perplexity4.286625385284424
INFO:root:current mean train loss 1661.0060405225768
INFO:root:current train perplexity4.28836727142334
INFO:root:current mean train loss 1661.677427032732
INFO:root:current train perplexity4.288877964019775
INFO:root:current mean train loss 1661.0273569288015
INFO:root:current train perplexity4.288906097412109
INFO:root:current mean train loss 1661.8136479650627
INFO:root:current train perplexity4.288036346435547
INFO:root:current mean train loss 1662.3636201399186
INFO:root:current train perplexity4.288917541503906
INFO:root:current mean train loss 1662.9051038229572
INFO:root:current train perplexity4.2900190353393555
INFO:root:current mean train loss 1661.5032321289805
INFO:root:current train perplexity4.289100170135498
INFO:root:current mean train loss 1662.1919082286245
INFO:root:current train perplexity4.291914463043213
INFO:root:current mean train loss 1661.347292292173
INFO:root:current train perplexity4.290919303894043
INFO:root:current mean train loss 1660.8230599501874
INFO:root:current train perplexity4.29449987411499
INFO:root:current mean train loss 1660.8628920753404
INFO:root:current train perplexity4.296438694000244
INFO:root:current mean train loss 1661.1042268172555
INFO:root:current train perplexity4.29355001449585
INFO:root:current mean train loss 1660.1564288708962
INFO:root:current train perplexity4.292893409729004

100%|██████████| 1/1 [05:35<00:00, 335.90s/it][A100%|██████████| 1/1 [05:35<00:00, 335.90s/it]
INFO:root:final mean train loss: 1659.3281523934893
INFO:root:final train perplexity: 4.29347562789917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1810.18911548371
INFO:root:eval perplexity: 5.126186847686768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2241.7883421985816
INFO:root:eval perplexity: 7.846210479736328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/55
 28%|██▊       | 55/200 [5:37:32<14:50:14, 368.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1649.02489157284
INFO:root:current train perplexity4.280106544494629
INFO:root:current mean train loss 1642.851339311742
INFO:root:current train perplexity4.259214878082275
INFO:root:current mean train loss 1651.4114885900774
INFO:root:current train perplexity4.255260467529297
INFO:root:current mean train loss 1647.9440716954762
INFO:root:current train perplexity4.234719753265381
INFO:root:current mean train loss 1648.1461488222747
INFO:root:current train perplexity4.238353252410889
INFO:root:current mean train loss 1650.0019775847818
INFO:root:current train perplexity4.250927448272705
INFO:root:current mean train loss 1651.9114041012544
INFO:root:current train perplexity4.2545599937438965
INFO:root:current mean train loss 1652.5522615604245
INFO:root:current train perplexity4.260562419891357
INFO:root:current mean train loss 1654.8314648086218
INFO:root:current train perplexity4.262442111968994
INFO:root:current mean train loss 1655.646396939198
INFO:root:current train perplexity4.262202739715576
INFO:root:current mean train loss 1656.6240002984466
INFO:root:current train perplexity4.269463539123535
INFO:root:current mean train loss 1655.6115796931838
INFO:root:current train perplexity4.274082183837891
INFO:root:current mean train loss 1654.7729267633522
INFO:root:current train perplexity4.274438858032227
INFO:root:current mean train loss 1654.4908382295669
INFO:root:current train perplexity4.274450302124023
INFO:root:current mean train loss 1654.6110203103208
INFO:root:current train perplexity4.274872303009033
INFO:root:current mean train loss 1654.7992717638476
INFO:root:current train perplexity4.275862216949463
INFO:root:current mean train loss 1655.7210006060186
INFO:root:current train perplexity4.275228977203369
INFO:root:current mean train loss 1655.768553349936
INFO:root:current train perplexity4.2777557373046875
INFO:root:current mean train loss 1656.080597955502
INFO:root:current train perplexity4.276858806610107
INFO:root:current mean train loss 1655.6859406685262
INFO:root:current train perplexity4.277953624725342

100%|██████████| 1/1 [05:36<00:00, 336.88s/it][A100%|██████████| 1/1 [05:36<00:00, 336.88s/it]
INFO:root:final mean train loss: 1655.7625766278995
INFO:root:final train perplexity: 4.280054092407227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1810.98245953499
INFO:root:eval perplexity: 5.129859924316406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2244.1580481563055
INFO:root:eval perplexity: 7.863317966461182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/56
 28%|██▊       | 56/200 [5:43:41<14:44:43, 368.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1671.9682114545037
INFO:root:current train perplexity4.292272567749023
INFO:root:current mean train loss 1658.5348425858858
INFO:root:current train perplexity4.280318260192871
INFO:root:current mean train loss 1652.2124845345181
INFO:root:current train perplexity4.268735408782959
INFO:root:current mean train loss 1654.9808526976497
INFO:root:current train perplexity4.270358085632324
INFO:root:current mean train loss 1656.6800556055987
INFO:root:current train perplexity4.273167610168457
INFO:root:current mean train loss 1653.7124116485652
INFO:root:current train perplexity4.267908573150635
INFO:root:current mean train loss 1651.5576357511882
INFO:root:current train perplexity4.264903545379639
INFO:root:current mean train loss 1652.1388646518185
INFO:root:current train perplexity4.2632155418396
INFO:root:current mean train loss 1648.9379742237993
INFO:root:current train perplexity4.256407737731934
INFO:root:current mean train loss 1649.7589392436416
INFO:root:current train perplexity4.256655216217041
INFO:root:current mean train loss 1650.4068313148564
INFO:root:current train perplexity4.258920192718506
INFO:root:current mean train loss 1651.4642113388154
INFO:root:current train perplexity4.262090682983398
INFO:root:current mean train loss 1652.0084384640725
INFO:root:current train perplexity4.264097213745117
INFO:root:current mean train loss 1651.8776462422222
INFO:root:current train perplexity4.265036106109619
INFO:root:current mean train loss 1651.5078369813652
INFO:root:current train perplexity4.265041351318359
INFO:root:current mean train loss 1652.1186495891009
INFO:root:current train perplexity4.269100189208984
INFO:root:current mean train loss 1653.3571810615488
INFO:root:current train perplexity4.269989013671875
INFO:root:current mean train loss 1652.0290216416513
INFO:root:current train perplexity4.267527103424072
INFO:root:current mean train loss 1651.372162442282
INFO:root:current train perplexity4.265280246734619
INFO:root:current mean train loss 1651.8034091716788
INFO:root:current train perplexity4.264118671417236

100%|██████████| 1/1 [05:36<00:00, 336.19s/it][A100%|██████████| 1/1 [05:36<00:00, 336.19s/it]
INFO:root:final mean train loss: 1651.5360724852653
INFO:root:final train perplexity: 4.264198303222656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 1811.601540423454
INFO:root:eval perplexity: 5.132727146148682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2248.888837665531
INFO:root:eval perplexity: 7.8975749015808105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/57
 28%|██▊       | 57/200 [5:49:49<14:38:34, 368.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1647.7532653808594
INFO:root:current train perplexity4.249800205230713
INFO:root:current mean train loss 1658.1083766392298
INFO:root:current train perplexity4.256750583648682
INFO:root:current mean train loss 1652.4681118637768
INFO:root:current train perplexity4.236091613769531
INFO:root:current mean train loss 1648.1234137493632
INFO:root:current train perplexity4.234546661376953
INFO:root:current mean train loss 1647.900883601262
INFO:root:current train perplexity4.230331897735596
INFO:root:current mean train loss 1647.8910735224333
INFO:root:current train perplexity4.24171257019043
INFO:root:current mean train loss 1649.4434635367936
INFO:root:current train perplexity4.244739532470703
INFO:root:current mean train loss 1649.3576828638713
INFO:root:current train perplexity4.243606090545654
INFO:root:current mean train loss 1647.7769394272484
INFO:root:current train perplexity4.2444329261779785
INFO:root:current mean train loss 1646.1239200308303
INFO:root:current train perplexity4.240591526031494
INFO:root:current mean train loss 1646.9597864043847
INFO:root:current train perplexity4.243542194366455
INFO:root:current mean train loss 1647.3651062429767
INFO:root:current train perplexity4.244831085205078
INFO:root:current mean train loss 1647.413717853534
INFO:root:current train perplexity4.247303485870361
INFO:root:current mean train loss 1647.9259237545973
INFO:root:current train perplexity4.24968957901001
INFO:root:current mean train loss 1648.482581697303
INFO:root:current train perplexity4.250545501708984
INFO:root:current mean train loss 1648.1890536717005
INFO:root:current train perplexity4.24899435043335
INFO:root:current mean train loss 1647.4309843141111
INFO:root:current train perplexity4.250278949737549
INFO:root:current mean train loss 1647.8549466370457
INFO:root:current train perplexity4.252257823944092
INFO:root:current mean train loss 1646.9801270446123
INFO:root:current train perplexity4.249886989593506
INFO:root:current mean train loss 1648.3180695820631
INFO:root:current train perplexity4.250626087188721

100%|██████████| 1/1 [05:37<00:00, 337.06s/it][A100%|██████████| 1/1 [05:37<00:00, 337.06s/it]
INFO:root:final mean train loss: 1647.8297341366458
INFO:root:final train perplexity: 4.250341892242432
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1810.7885335286458
INFO:root:eval perplexity: 5.128961563110352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2244.3947108924813
INFO:root:eval perplexity: 7.865025997161865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/58
 29%|██▉       | 58/200 [5:55:59<14:32:59, 368.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1644.8231071920957
INFO:root:current train perplexity4.231385707855225
INFO:root:current mean train loss 1648.233092931799
INFO:root:current train perplexity4.229650020599365
INFO:root:current mean train loss 1641.981825229578
INFO:root:current train perplexity4.210970878601074
INFO:root:current mean train loss 1645.4049547864245
INFO:root:current train perplexity4.213584899902344
INFO:root:current mean train loss 1643.7767047056218
INFO:root:current train perplexity4.207812786102295
INFO:root:current mean train loss 1644.6205303485576
INFO:root:current train perplexity4.217552185058594
INFO:root:current mean train loss 1647.3357920848541
INFO:root:current train perplexity4.224542617797852
INFO:root:current mean train loss 1647.1108698559415
INFO:root:current train perplexity4.2278733253479
INFO:root:current mean train loss 1647.393333857477
INFO:root:current train perplexity4.231030464172363
INFO:root:current mean train loss 1645.7845715517926
INFO:root:current train perplexity4.227963924407959
INFO:root:current mean train loss 1645.4902752151138
INFO:root:current train perplexity4.231864929199219
INFO:root:current mean train loss 1645.5131323963278
INFO:root:current train perplexity4.233905792236328
INFO:root:current mean train loss 1645.5221243654244
INFO:root:current train perplexity4.2338032722473145
INFO:root:current mean train loss 1645.644163628864
INFO:root:current train perplexity4.237078666687012
INFO:root:current mean train loss 1646.4478969381314
INFO:root:current train perplexity4.237222671508789
INFO:root:current mean train loss 1645.7562252008577
INFO:root:current train perplexity4.236826419830322
INFO:root:current mean train loss 1645.3632112678506
INFO:root:current train perplexity4.237415313720703
INFO:root:current mean train loss 1645.59263249245
INFO:root:current train perplexity4.237773895263672
INFO:root:current mean train loss 1645.4327862726914
INFO:root:current train perplexity4.238007068634033

100%|██████████| 1/1 [05:36<00:00, 336.35s/it][A100%|██████████| 1/1 [05:36<00:00, 336.36s/it]
INFO:root:final mean train loss: 1644.5996400926429
INFO:root:final train perplexity: 4.238304138183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.62s/it][A100%|██████████| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 1809.2262742062833
INFO:root:eval perplexity: 5.121730804443359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2246.0498665884033
INFO:root:eval perplexity: 7.876996994018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/59
 30%|██▉       | 59/200 [6:02:07<14:26:36, 368.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1529.5485229492188
INFO:root:current train perplexity4.377151966094971
INFO:root:current mean train loss 1629.6119396733302
INFO:root:current train perplexity4.237723350524902
INFO:root:current mean train loss 1638.5122426854502
INFO:root:current train perplexity4.223629951477051
INFO:root:current mean train loss 1634.3570593019194
INFO:root:current train perplexity4.221724987030029
INFO:root:current mean train loss 1636.077457257171
INFO:root:current train perplexity4.214217662811279
INFO:root:current mean train loss 1633.9575073728524
INFO:root:current train perplexity4.217995643615723
INFO:root:current mean train loss 1637.841155904472
INFO:root:current train perplexity4.21937894821167
INFO:root:current mean train loss 1636.469043525196
INFO:root:current train perplexity4.220373153686523
INFO:root:current mean train loss 1637.5698223922616
INFO:root:current train perplexity4.22590446472168
INFO:root:current mean train loss 1637.0463550508418
INFO:root:current train perplexity4.222935199737549
INFO:root:current mean train loss 1639.2903673853466
INFO:root:current train perplexity4.220786094665527
INFO:root:current mean train loss 1638.7241375987196
INFO:root:current train perplexity4.220143795013428
INFO:root:current mean train loss 1637.9208711189358
INFO:root:current train perplexity4.219228744506836
INFO:root:current mean train loss 1638.711958034064
INFO:root:current train perplexity4.2197065353393555
INFO:root:current mean train loss 1637.9642259105296
INFO:root:current train perplexity4.216163635253906
INFO:root:current mean train loss 1638.486720911831
INFO:root:current train perplexity4.214272975921631
INFO:root:current mean train loss 1637.1640453552932
INFO:root:current train perplexity4.212884426116943
INFO:root:current mean train loss 1637.203367060696
INFO:root:current train perplexity4.214078903198242
INFO:root:current mean train loss 1638.5979827643764
INFO:root:current train perplexity4.216137409210205
INFO:root:current mean train loss 1638.857085251031
INFO:root:current train perplexity4.21852970123291

100%|██████████| 1/1 [05:37<00:00, 337.32s/it][A100%|██████████| 1/1 [05:37<00:00, 337.34s/it]
INFO:root:final mean train loss: 1639.5453374865556
INFO:root:final train perplexity: 4.219534397125244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 1810.292702532829
INFO:root:eval perplexity: 5.1266655921936035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2248.768840383976
INFO:root:eval perplexity: 7.896703243255615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/60
 30%|███       | 60/200 [6:08:17<14:21:08, 369.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1610.847964638158
INFO:root:current train perplexity4.1772685050964355
INFO:root:current mean train loss 1641.2799810842305
INFO:root:current train perplexity4.227230072021484
INFO:root:current mean train loss 1636.3099900337115
INFO:root:current train perplexity4.219193458557129
INFO:root:current mean train loss 1636.2324103950334
INFO:root:current train perplexity4.205817222595215
INFO:root:current mean train loss 1634.8018519144355
INFO:root:current train perplexity4.209779262542725
INFO:root:current mean train loss 1637.3125536262644
INFO:root:current train perplexity4.213447093963623
INFO:root:current mean train loss 1635.4576112318887
INFO:root:current train perplexity4.210786819458008
INFO:root:current mean train loss 1634.0738150181458
INFO:root:current train perplexity4.203999996185303
INFO:root:current mean train loss 1631.7623841002746
INFO:root:current train perplexity4.198503494262695
INFO:root:current mean train loss 1631.8480512849394
INFO:root:current train perplexity4.2003374099731445
INFO:root:current mean train loss 1631.5560428518309
INFO:root:current train perplexity4.2035369873046875
INFO:root:current mean train loss 1632.224204437556
INFO:root:current train perplexity4.203548431396484
INFO:root:current mean train loss 1633.4179294952316
INFO:root:current train perplexity4.203037738800049
INFO:root:current mean train loss 1633.241151336832
INFO:root:current train perplexity4.202606201171875
INFO:root:current mean train loss 1633.9606600674715
INFO:root:current train perplexity4.204362869262695
INFO:root:current mean train loss 1634.14931176131
INFO:root:current train perplexity4.201839923858643
INFO:root:current mean train loss 1635.142913347118
INFO:root:current train perplexity4.203732490539551
INFO:root:current mean train loss 1635.5833448373419
INFO:root:current train perplexity4.2043280601501465
INFO:root:current mean train loss 1636.1590249353612
INFO:root:current train perplexity4.204405307769775
INFO:root:current mean train loss 1637.4833602070373
INFO:root:current train perplexity4.207189083099365

100%|██████████| 1/1 [05:36<00:00, 336.89s/it][A100%|██████████| 1/1 [05:36<00:00, 336.89s/it]
INFO:root:final mean train loss: 1636.3727112585887
INFO:root:final train perplexity: 4.2077956199646
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1811.0277978342476
INFO:root:eval perplexity: 5.130069255828857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2248.8409229035074
INFO:root:eval perplexity: 7.897226810455322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/61
 30%|███       | 61/200 [6:14:26<14:15:06, 369.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1655.029981825087
INFO:root:current train perplexity4.265131950378418
INFO:root:current mean train loss 1644.4604070326861
INFO:root:current train perplexity4.197956562042236
INFO:root:current mean train loss 1638.6710805084747
INFO:root:current train perplexity4.193767547607422
INFO:root:current mean train loss 1633.8748270670574
INFO:root:current train perplexity4.198665618896484
INFO:root:current mean train loss 1635.6282239441477
INFO:root:current train perplexity4.204009532928467
INFO:root:current mean train loss 1632.0357850487553
INFO:root:current train perplexity4.203540325164795
INFO:root:current mean train loss 1631.4101902223983
INFO:root:current train perplexity4.2027740478515625
INFO:root:current mean train loss 1632.9641385285752
INFO:root:current train perplexity4.200769424438477
INFO:root:current mean train loss 1631.0475792405707
INFO:root:current train perplexity4.198136806488037
INFO:root:current mean train loss 1630.9610728728464
INFO:root:current train perplexity4.193608283996582
INFO:root:current mean train loss 1631.1645327534916
INFO:root:current train perplexity4.191721439361572
INFO:root:current mean train loss 1631.8689482782927
INFO:root:current train perplexity4.191053867340088
INFO:root:current mean train loss 1632.475271971866
INFO:root:current train perplexity4.197829246520996
INFO:root:current mean train loss 1632.807699329125
INFO:root:current train perplexity4.198056221008301
INFO:root:current mean train loss 1634.4447264604914
INFO:root:current train perplexity4.19588565826416
INFO:root:current mean train loss 1634.2886215051014
INFO:root:current train perplexity4.197803497314453
INFO:root:current mean train loss 1634.141365181846
INFO:root:current train perplexity4.1978278160095215
INFO:root:current mean train loss 1633.4829744963054
INFO:root:current train perplexity4.196025371551514
INFO:root:current mean train loss 1633.5240916000732
INFO:root:current train perplexity4.196324348449707
INFO:root:current mean train loss 1633.3472549816793
INFO:root:current train perplexity4.19740629196167

100%|██████████| 1/1 [05:36<00:00, 336.70s/it][A100%|██████████| 1/1 [05:36<00:00, 336.70s/it]
INFO:root:final mean train loss: 1633.3473559065533
INFO:root:final train perplexity: 4.196631908416748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1811.2282411832336
INFO:root:eval perplexity: 5.130997180938721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2251.611415565437
INFO:root:eval perplexity: 7.917357444763184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/62
 31%|███       | 62/200 [6:20:35<14:08:49, 369.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.877192659198
INFO:root:current train perplexity4.127636909484863
INFO:root:current mean train loss 1612.5718778722426
INFO:root:current train perplexity4.136746406555176
INFO:root:current mean train loss 1616.613467974154
INFO:root:current train perplexity4.1370673179626465
INFO:root:current mean train loss 1620.2407409840873
INFO:root:current train perplexity4.149726867675781
INFO:root:current mean train loss 1620.0587012688845
INFO:root:current train perplexity4.142614364624023
INFO:root:current mean train loss 1623.8035005703973
INFO:root:current train perplexity4.156239032745361
INFO:root:current mean train loss 1624.393603104362
INFO:root:current train perplexity4.1560540199279785
INFO:root:current mean train loss 1625.4358004181192
INFO:root:current train perplexity4.163492202758789
INFO:root:current mean train loss 1625.8878049324992
INFO:root:current train perplexity4.162683963775635
INFO:root:current mean train loss 1626.4832695783873
INFO:root:current train perplexity4.164271831512451
INFO:root:current mean train loss 1628.424810367885
INFO:root:current train perplexity4.171228885650635
INFO:root:current mean train loss 1629.3353264073342
INFO:root:current train perplexity4.172319412231445
INFO:root:current mean train loss 1630.888582538626
INFO:root:current train perplexity4.174678325653076
INFO:root:current mean train loss 1632.5530163186265
INFO:root:current train perplexity4.1770453453063965
INFO:root:current mean train loss 1631.6771844284992
INFO:root:current train perplexity4.177103042602539
INFO:root:current mean train loss 1631.9084059204965
INFO:root:current train perplexity4.180488109588623
INFO:root:current mean train loss 1631.3758485843684
INFO:root:current train perplexity4.183653354644775
INFO:root:current mean train loss 1631.1866041445692
INFO:root:current train perplexity4.18373966217041
INFO:root:current mean train loss 1631.0233084467122
INFO:root:current train perplexity4.183726787567139
INFO:root:current mean train loss 1629.0547254399282
INFO:root:current train perplexity4.179752349853516

100%|██████████| 1/1 [05:36<00:00, 336.18s/it][A100%|██████████| 1/1 [05:36<00:00, 336.18s/it]
INFO:root:final mean train loss: 1628.9561314816074
INFO:root:final train perplexity: 4.180480480194092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.63s/it][A100%|██████████| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 1812.0387391435338
INFO:root:eval perplexity: 5.134753704071045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2254.752168263104
INFO:root:eval perplexity: 7.9402384757995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/63
 32%|███▏      | 63/200 [6:26:44<14:02:11, 368.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.8957763671874
INFO:root:current train perplexity4.109612464904785
INFO:root:current mean train loss 1622.6883200252757
INFO:root:current train perplexity4.130043029785156
INFO:root:current mean train loss 1622.1269911024306
INFO:root:current train perplexity4.1340484619140625
INFO:root:current mean train loss 1622.3862548828124
INFO:root:current train perplexity4.1405348777771
INFO:root:current mean train loss 1622.1368153673536
INFO:root:current train perplexity4.1486310958862305
INFO:root:current mean train loss 1624.253785892955
INFO:root:current train perplexity4.1563029289245605
INFO:root:current mean train loss 1625.6443494198927
INFO:root:current train perplexity4.158897876739502
INFO:root:current mean train loss 1622.6907790939529
INFO:root:current train perplexity4.158239364624023
INFO:root:current mean train loss 1623.7394396551724
INFO:root:current train perplexity4.160337448120117
INFO:root:current mean train loss 1624.125167123067
INFO:root:current train perplexity4.161252975463867
INFO:root:current mean train loss 1624.6988533376534
INFO:root:current train perplexity4.161302089691162
INFO:root:current mean train loss 1624.0188446305756
INFO:root:current train perplexity4.1611480712890625
INFO:root:current mean train loss 1626.2486616480069
INFO:root:current train perplexity4.16355562210083
INFO:root:current mean train loss 1626.7576549669252
INFO:root:current train perplexity4.16451358795166
INFO:root:current mean train loss 1627.5945727705146
INFO:root:current train perplexity4.166427135467529
INFO:root:current mean train loss 1626.7733701669486
INFO:root:current train perplexity4.166965484619141
INFO:root:current mean train loss 1626.1581627760104
INFO:root:current train perplexity4.166985511779785
INFO:root:current mean train loss 1625.7646034025204
INFO:root:current train perplexity4.167365074157715
INFO:root:current mean train loss 1625.1590186460771
INFO:root:current train perplexity4.167072296142578
INFO:root:current mean train loss 1625.7907695634717
INFO:root:current train perplexity4.1678972244262695

100%|██████████| 1/1 [05:36<00:00, 336.13s/it][A100%|██████████| 1/1 [05:36<00:00, 336.13s/it]
INFO:root:final mean train loss: 1625.411822297389
INFO:root:final train perplexity: 4.167490005493164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 1812.2281714906085
INFO:root:eval perplexity: 5.135632038116455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2255.0523144877548
INFO:root:eval perplexity: 7.9424309730529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/64
 32%|███▏      | 64/200 [6:32:52<13:55:50, 368.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1626.1234902568247
INFO:root:current train perplexity4.171405792236328
INFO:root:current mean train loss 1623.8881287600268
INFO:root:current train perplexity4.145162582397461
INFO:root:current mean train loss 1622.4175812724575
INFO:root:current train perplexity4.147401332855225
INFO:root:current mean train loss 1620.5156890317144
INFO:root:current train perplexity4.152587890625
INFO:root:current mean train loss 1619.76497028202
INFO:root:current train perplexity4.146058082580566
INFO:root:current mean train loss 1621.3169841603892
INFO:root:current train perplexity4.149201393127441
INFO:root:current mean train loss 1622.878246146345
INFO:root:current train perplexity4.154431343078613
INFO:root:current mean train loss 1623.602928229481
INFO:root:current train perplexity4.152721881866455
INFO:root:current mean train loss 1621.9594743077087
INFO:root:current train perplexity4.148064613342285
INFO:root:current mean train loss 1623.4324529429457
INFO:root:current train perplexity4.1484808921813965
INFO:root:current mean train loss 1622.3320379880117
INFO:root:current train perplexity4.149367332458496
INFO:root:current mean train loss 1623.021868788503
INFO:root:current train perplexity4.151504993438721
INFO:root:current mean train loss 1621.9865138388088
INFO:root:current train perplexity4.150753498077393
INFO:root:current mean train loss 1621.0480139415386
INFO:root:current train perplexity4.150816440582275
INFO:root:current mean train loss 1622.6937198395206
INFO:root:current train perplexity4.15418815612793
INFO:root:current mean train loss 1622.3528495841456
INFO:root:current train perplexity4.154073238372803
INFO:root:current mean train loss 1623.3694485866183
INFO:root:current train perplexity4.154527187347412
INFO:root:current mean train loss 1623.6527116686923
INFO:root:current train perplexity4.156223773956299
INFO:root:current mean train loss 1622.3547595518887
INFO:root:current train perplexity4.155941963195801

100%|██████████| 1/1 [05:36<00:00, 336.17s/it][A100%|██████████| 1/1 [05:36<00:00, 336.17s/it]
INFO:root:final mean train loss: 1622.1495335165803
INFO:root:final train perplexity: 4.155567646026611
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 1815.414718736148
INFO:root:eval perplexity: 5.150428771972656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2260.9343802810563
INFO:root:eval perplexity: 7.985477447509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/65
 32%|███▎      | 65/200 [6:39:01<13:49:34, 368.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.7293395996094
INFO:root:current train perplexity4.0598063468933105
INFO:root:current mean train loss 1619.1992668738733
INFO:root:current train perplexity4.124546051025391
INFO:root:current mean train loss 1615.6490047679229
INFO:root:current train perplexity4.121005535125732
INFO:root:current mean train loss 1617.7321098729183
INFO:root:current train perplexity4.115886211395264
INFO:root:current mean train loss 1616.516124763111
INFO:root:current train perplexity4.125982284545898
INFO:root:current mean train loss 1617.980444771903
INFO:root:current train perplexity4.127969741821289
INFO:root:current mean train loss 1616.7932326967352
INFO:root:current train perplexity4.133949279785156
INFO:root:current mean train loss 1616.6503876772795
INFO:root:current train perplexity4.136800289154053
INFO:root:current mean train loss 1617.3569580381782
INFO:root:current train perplexity4.1317524909973145
INFO:root:current mean train loss 1618.6765025991253
INFO:root:current train perplexity4.135066032409668
INFO:root:current mean train loss 1618.1389971121373
INFO:root:current train perplexity4.133989334106445
INFO:root:current mean train loss 1619.0902080812316
INFO:root:current train perplexity4.134408473968506
INFO:root:current mean train loss 1620.2187355016158
INFO:root:current train perplexity4.136345386505127
INFO:root:current mean train loss 1619.8207156877577
INFO:root:current train perplexity4.140450477600098
INFO:root:current mean train loss 1619.9098065585492
INFO:root:current train perplexity4.1372246742248535
INFO:root:current mean train loss 1619.0706432423692
INFO:root:current train perplexity4.138901233673096
INFO:root:current mean train loss 1619.0745057370002
INFO:root:current train perplexity4.138881683349609
INFO:root:current mean train loss 1618.9400000773685
INFO:root:current train perplexity4.139435291290283
INFO:root:current mean train loss 1619.109089988827
INFO:root:current train perplexity4.1407790184021
INFO:root:current mean train loss 1619.085181805266
INFO:root:current train perplexity4.141401767730713

100%|██████████| 1/1 [05:36<00:00, 336.46s/it][A100%|██████████| 1/1 [05:36<00:00, 336.46s/it]
INFO:root:final mean train loss: 1618.727712718754
INFO:root:final train perplexity: 4.143100261688232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 1812.8691302360373
INFO:root:eval perplexity: 5.138604640960693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2257.9297342503323
INFO:root:eval perplexity: 7.963457107543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/66
 33%|███▎      | 66/200 [6:45:10<13:43:32, 368.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.339122953869
INFO:root:current train perplexity4.1246867179870605
INFO:root:current mean train loss 1609.4787093233472
INFO:root:current train perplexity4.105658531188965
INFO:root:current mean train loss 1608.2827562703267
INFO:root:current train perplexity4.1151556968688965
INFO:root:current mean train loss 1603.9837292822722
INFO:root:current train perplexity4.103710651397705
INFO:root:current mean train loss 1607.128351859412
INFO:root:current train perplexity4.104569435119629
INFO:root:current mean train loss 1612.9328158739204
INFO:root:current train perplexity4.114716529846191
INFO:root:current mean train loss 1612.4139593004604
INFO:root:current train perplexity4.117498874664307
INFO:root:current mean train loss 1611.81049354331
INFO:root:current train perplexity4.11875057220459
INFO:root:current mean train loss 1612.6828672755214
INFO:root:current train perplexity4.12058162689209
INFO:root:current mean train loss 1613.833332803169
INFO:root:current train perplexity4.122564792633057
INFO:root:current mean train loss 1615.1926083018334
INFO:root:current train perplexity4.12615966796875
INFO:root:current mean train loss 1615.472741731887
INFO:root:current train perplexity4.127773761749268
INFO:root:current mean train loss 1614.9641420206606
INFO:root:current train perplexity4.126053810119629
INFO:root:current mean train loss 1615.2603574026543
INFO:root:current train perplexity4.126927852630615
INFO:root:current mean train loss 1614.9483725046457
INFO:root:current train perplexity4.129980087280273
INFO:root:current mean train loss 1615.5899437497433
INFO:root:current train perplexity4.1320481300354
INFO:root:current mean train loss 1615.6642321634263
INFO:root:current train perplexity4.132627487182617
INFO:root:current mean train loss 1614.956246127229
INFO:root:current train perplexity4.130330562591553
INFO:root:current mean train loss 1615.4625256877232
INFO:root:current train perplexity4.131427764892578
INFO:root:current mean train loss 1616.414370122271
INFO:root:current train perplexity4.132413864135742

100%|██████████| 1/1 [05:36<00:00, 336.05s/it][A100%|██████████| 1/1 [05:36<00:00, 336.05s/it]
INFO:root:final mean train loss: 1616.0195551654394
INFO:root:final train perplexity: 4.133259296417236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1813.068549406444
INFO:root:eval perplexity: 5.139529705047607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2257.9219139586103
INFO:root:eval perplexity: 7.963401794433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/67
 34%|███▎      | 67/200 [6:51:18<13:37:09, 368.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.127675909745
INFO:root:current train perplexity4.090847492218018
INFO:root:current mean train loss 1598.8023566646852
INFO:root:current train perplexity4.080398082733154
INFO:root:current mean train loss 1602.3870880383404
INFO:root:current train perplexity4.084927082061768
INFO:root:current mean train loss 1608.1714376415728
INFO:root:current train perplexity4.1035966873168945
INFO:root:current mean train loss 1607.6548999803795
INFO:root:current train perplexity4.114352226257324
INFO:root:current mean train loss 1607.98885620571
INFO:root:current train perplexity4.109941482543945
INFO:root:current mean train loss 1609.302091688198
INFO:root:current train perplexity4.111929893493652
INFO:root:current mean train loss 1609.0453724434706
INFO:root:current train perplexity4.113887786865234
INFO:root:current mean train loss 1608.101996738188
INFO:root:current train perplexity4.1112589836120605
INFO:root:current mean train loss 1608.9313056474048
INFO:root:current train perplexity4.112180709838867
INFO:root:current mean train loss 1609.081610354385
INFO:root:current train perplexity4.115693092346191
INFO:root:current mean train loss 1611.043035470329
INFO:root:current train perplexity4.116808891296387
INFO:root:current mean train loss 1611.1582944312272
INFO:root:current train perplexity4.11939001083374
INFO:root:current mean train loss 1611.896706437138
INFO:root:current train perplexity4.118411064147949
INFO:root:current mean train loss 1611.9391026185185
INFO:root:current train perplexity4.120335578918457
INFO:root:current mean train loss 1612.1171885318038
INFO:root:current train perplexity4.121852874755859
INFO:root:current mean train loss 1611.2836587647378
INFO:root:current train perplexity4.1193766593933105
INFO:root:current mean train loss 1611.723535675997
INFO:root:current train perplexity4.119980812072754
INFO:root:current mean train loss 1612.167774486853
INFO:root:current train perplexity4.119103908538818
INFO:root:current mean train loss 1612.3524725474072
INFO:root:current train perplexity4.120035648345947

100%|██████████| 1/1 [05:35<00:00, 335.83s/it][A100%|██████████| 1/1 [05:35<00:00, 335.83s/it]
INFO:root:final mean train loss: 1612.1972622085086
INFO:root:final train perplexity: 4.119409561157227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1814.5628363426695
INFO:root:eval perplexity: 5.146468639373779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2261.628935252521
INFO:root:eval perplexity: 7.990573883056641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/68
 34%|███▍      | 68/200 [6:57:26<13:30:41, 368.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.4533269708807
INFO:root:current train perplexity4.073957443237305
INFO:root:current mean train loss 1605.9016743321572
INFO:root:current train perplexity4.109595775604248
INFO:root:current mean train loss 1603.0352773628983
INFO:root:current train perplexity4.10075569152832
INFO:root:current mean train loss 1605.3884026325925
INFO:root:current train perplexity4.104328155517578
INFO:root:current mean train loss 1605.9271554129464
INFO:root:current train perplexity4.102808952331543
INFO:root:current mean train loss 1604.0514327315598
INFO:root:current train perplexity4.0969157218933105
INFO:root:current mean train loss 1603.6364634273616
INFO:root:current train perplexity4.095743656158447
INFO:root:current mean train loss 1602.5707501746172
INFO:root:current train perplexity4.093104839324951
INFO:root:current mean train loss 1603.4958937260142
INFO:root:current train perplexity4.096184730529785
INFO:root:current mean train loss 1605.2912180955498
INFO:root:current train perplexity4.097846031188965
INFO:root:current mean train loss 1606.510542825274
INFO:root:current train perplexity4.100369930267334
INFO:root:current mean train loss 1605.7339331160376
INFO:root:current train perplexity4.099648475646973
INFO:root:current mean train loss 1604.4089742592132
INFO:root:current train perplexity4.09745979309082
INFO:root:current mean train loss 1603.6891685345076
INFO:root:current train perplexity4.095951557159424
INFO:root:current mean train loss 1605.4788979441848
INFO:root:current train perplexity4.100003242492676
INFO:root:current mean train loss 1605.102559080461
INFO:root:current train perplexity4.0983357429504395
INFO:root:current mean train loss 1606.148096293193
INFO:root:current train perplexity4.101090431213379
INFO:root:current mean train loss 1606.897457807492
INFO:root:current train perplexity4.1027045249938965
INFO:root:current mean train loss 1607.7381197618345
INFO:root:current train perplexity4.104393482208252
INFO:root:current mean train loss 1608.8035647028853
INFO:root:current train perplexity4.106106758117676

100%|██████████| 1/1 [05:36<00:00, 336.75s/it][A100%|██████████| 1/1 [05:36<00:00, 336.75s/it]
INFO:root:final mean train loss: 1608.577615327205
INFO:root:final train perplexity: 4.10633659362793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1813.7769156381594
INFO:root:eval perplexity: 5.142817974090576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2260.663618371842
INFO:root:eval perplexity: 7.983489990234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/69
 34%|███▍      | 69/200 [7:03:35<13:24:55, 368.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.4253845214844
INFO:root:current train perplexity4.093157768249512
INFO:root:current mean train loss 1606.2968246105106
INFO:root:current train perplexity4.061310291290283
INFO:root:current mean train loss 1602.448605256922
INFO:root:current train perplexity4.0876030921936035
INFO:root:current mean train loss 1605.2754467379661
INFO:root:current train perplexity4.0929646492004395
INFO:root:current mean train loss 1605.5598289360435
INFO:root:current train perplexity4.090280055999756
INFO:root:current mean train loss 1603.739857280171
INFO:root:current train perplexity4.08743953704834
INFO:root:current mean train loss 1605.452965690976
INFO:root:current train perplexity4.091357707977295
INFO:root:current mean train loss 1603.4854600343062
INFO:root:current train perplexity4.091571807861328
INFO:root:current mean train loss 1602.0560515517489
INFO:root:current train perplexity4.095290660858154
INFO:root:current mean train loss 1602.8729786813994
INFO:root:current train perplexity4.095768928527832
INFO:root:current mean train loss 1601.4725087863296
INFO:root:current train perplexity4.094971179962158
INFO:root:current mean train loss 1601.139307015585
INFO:root:current train perplexity4.094081878662109
INFO:root:current mean train loss 1601.8336795830876
INFO:root:current train perplexity4.092854976654053
INFO:root:current mean train loss 1602.8597362284759
INFO:root:current train perplexity4.0946269035339355
INFO:root:current mean train loss 1603.631229068922
INFO:root:current train perplexity4.093430042266846
INFO:root:current mean train loss 1604.4867142927253
INFO:root:current train perplexity4.0949835777282715
INFO:root:current mean train loss 1603.9862754858282
INFO:root:current train perplexity4.094638347625732
INFO:root:current mean train loss 1604.5303508681045
INFO:root:current train perplexity4.094637393951416
INFO:root:current mean train loss 1605.9452473567083
INFO:root:current train perplexity4.097426414489746
INFO:root:current mean train loss 1606.323635697123
INFO:root:current train perplexity4.096096038818359

100%|██████████| 1/1 [05:35<00:00, 335.66s/it][A100%|██████████| 1/1 [05:35<00:00, 335.66s/it]
INFO:root:final mean train loss: 1605.7343167965303
INFO:root:final train perplexity: 4.096096992492676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1818.1945896013408
INFO:root:eval perplexity: 5.163371562957764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2270.547895715592
INFO:root:eval perplexity: 8.056334495544434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/70
 35%|███▌      | 70/200 [7:09:43<13:18:18, 368.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.5852037065486
INFO:root:current train perplexity4.088997840881348
INFO:root:current mean train loss 1601.3973317625662
INFO:root:current train perplexity4.0736212730407715
INFO:root:current mean train loss 1598.3447992133433
INFO:root:current train perplexity4.058439254760742
INFO:root:current mean train loss 1597.5506707904885
INFO:root:current train perplexity4.054596900939941
INFO:root:current mean train loss 1601.1637686824993
INFO:root:current train perplexity4.070185661315918
INFO:root:current mean train loss 1599.583005739999
INFO:root:current train perplexity4.071846008300781
INFO:root:current mean train loss 1600.3391410927295
INFO:root:current train perplexity4.075160026550293
INFO:root:current mean train loss 1601.3948946760634
INFO:root:current train perplexity4.077537536621094
INFO:root:current mean train loss 1602.1391966812255
INFO:root:current train perplexity4.081717014312744
INFO:root:current mean train loss 1600.684588456419
INFO:root:current train perplexity4.078365325927734
INFO:root:current mean train loss 1600.1063875841153
INFO:root:current train perplexity4.078515529632568
INFO:root:current mean train loss 1599.4655107733981
INFO:root:current train perplexity4.080509185791016
INFO:root:current mean train loss 1600.7287536100234
INFO:root:current train perplexity4.080860614776611
INFO:root:current mean train loss 1599.6598984874179
INFO:root:current train perplexity4.079743385314941
INFO:root:current mean train loss 1600.6207199147918
INFO:root:current train perplexity4.079948902130127
INFO:root:current mean train loss 1601.273599517803
INFO:root:current train perplexity4.079720973968506
INFO:root:current mean train loss 1601.6880819479907
INFO:root:current train perplexity4.080046653747559
INFO:root:current mean train loss 1602.2518225254594
INFO:root:current train perplexity4.081269264221191
INFO:root:current mean train loss 1602.8080071792078
INFO:root:current train perplexity4.081323146820068

100%|██████████| 1/1 [05:37<00:00, 337.12s/it][A100%|██████████| 1/1 [05:37<00:00, 337.12s/it]
INFO:root:final mean train loss: 1602.39599455479
INFO:root:final train perplexity: 4.084107398986816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1815.6452091298204
INFO:root:eval perplexity: 5.151500225067139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2268.101595398382
INFO:root:eval perplexity: 8.038244247436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/71
 36%|███▌      | 71/200 [7:15:52<13:12:43, 368.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1580.835184733073
INFO:root:current train perplexity4.024487018585205
INFO:root:current mean train loss 1598.3179505546138
INFO:root:current train perplexity4.080559730529785
INFO:root:current mean train loss 1597.0077698346481
INFO:root:current train perplexity4.053686141967773
INFO:root:current mean train loss 1592.7926540000765
INFO:root:current train perplexity4.048299312591553
INFO:root:current mean train loss 1595.2028234322083
INFO:root:current train perplexity4.048828601837158
INFO:root:current mean train loss 1595.9634257079113
INFO:root:current train perplexity4.055247783660889
INFO:root:current mean train loss 1594.3865990969214
INFO:root:current train perplexity4.059686660766602
INFO:root:current mean train loss 1594.2715758412824
INFO:root:current train perplexity4.056828022003174
INFO:root:current mean train loss 1597.5525671719913
INFO:root:current train perplexity4.064644813537598
INFO:root:current mean train loss 1597.7530982415408
INFO:root:current train perplexity4.065783500671387
INFO:root:current mean train loss 1596.6812508736643
INFO:root:current train perplexity4.061577796936035
INFO:root:current mean train loss 1596.35453799146
INFO:root:current train perplexity4.060593128204346
INFO:root:current mean train loss 1597.056943270302
INFO:root:current train perplexity4.061644077301025
INFO:root:current mean train loss 1595.6314485091345
INFO:root:current train perplexity4.058782577514648
INFO:root:current mean train loss 1597.4967736451758
INFO:root:current train perplexity4.062282085418701
INFO:root:current mean train loss 1597.71535302475
INFO:root:current train perplexity4.064156532287598
INFO:root:current mean train loss 1597.9435918102527
INFO:root:current train perplexity4.068576335906982
INFO:root:current mean train loss 1597.620100658636
INFO:root:current train perplexity4.070010185241699
INFO:root:current mean train loss 1598.540861786666
INFO:root:current train perplexity4.068486213684082
INFO:root:current mean train loss 1598.572607178503
INFO:root:current train perplexity4.069942474365234

100%|██████████| 1/1 [05:36<00:00, 336.67s/it][A100%|██████████| 1/1 [05:36<00:00, 336.67s/it]
INFO:root:final mean train loss: 1598.6027493460035
INFO:root:final train perplexity: 4.070526123046875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1817.6030974692487
INFO:root:eval perplexity: 5.16061544418335
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2270.680277073637
INFO:root:eval perplexity: 8.057313919067383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/72
 36%|███▌      | 72/200 [7:22:01<13:06:41, 368.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1551.993360436481
INFO:root:current train perplexity4.0103936195373535
INFO:root:current mean train loss 1586.8889596830538
INFO:root:current train perplexity4.021921157836914
INFO:root:current mean train loss 1587.0123559241872
INFO:root:current train perplexity4.0336103439331055
INFO:root:current mean train loss 1593.3903759463283
INFO:root:current train perplexity4.039199352264404
INFO:root:current mean train loss 1594.662822461861
INFO:root:current train perplexity4.053162097930908
INFO:root:current mean train loss 1595.1013550038092
INFO:root:current train perplexity4.048898220062256
INFO:root:current mean train loss 1594.0863462298105
INFO:root:current train perplexity4.051381587982178
INFO:root:current mean train loss 1593.6721211666884
INFO:root:current train perplexity4.049469470977783
INFO:root:current mean train loss 1595.2010477281572
INFO:root:current train perplexity4.0523834228515625
INFO:root:current mean train loss 1592.7545726771991
INFO:root:current train perplexity4.0477519035339355
INFO:root:current mean train loss 1592.285320084349
INFO:root:current train perplexity4.050515174865723
INFO:root:current mean train loss 1592.5449111136813
INFO:root:current train perplexity4.05142879486084
INFO:root:current mean train loss 1593.7780568083094
INFO:root:current train perplexity4.053886890411377
INFO:root:current mean train loss 1594.608126616532
INFO:root:current train perplexity4.053203105926514
INFO:root:current mean train loss 1595.617491946619
INFO:root:current train perplexity4.0561394691467285
INFO:root:current mean train loss 1595.753998343755
INFO:root:current train perplexity4.055780410766602
INFO:root:current mean train loss 1595.7691368342769
INFO:root:current train perplexity4.056125640869141
INFO:root:current mean train loss 1595.8144920203
INFO:root:current train perplexity4.057854652404785
INFO:root:current mean train loss 1595.879650323128
INFO:root:current train perplexity4.0589423179626465
INFO:root:current mean train loss 1597.1333193806267
INFO:root:current train perplexity4.0616583824157715

100%|██████████| 1/1 [05:36<00:00, 336.24s/it][A100%|██████████| 1/1 [05:36<00:00, 336.24s/it]
INFO:root:final mean train loss: 1596.0892448483005
INFO:root:final train perplexity: 4.061551570892334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1817.2839926861702
INFO:root:eval perplexity: 5.159128189086914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.81s/it][A100%|██████████| 1/1 [00:15<00:00, 15.81s/it]
INFO:root:eval mean loss: 2270.226707079732
INFO:root:eval perplexity: 8.053956985473633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/73
 36%|███▋      | 73/200 [7:28:10<13:00:26, 368.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.8876861572267
INFO:root:current train perplexity4.042153358459473
INFO:root:current mean train loss 1582.2056492396764
INFO:root:current train perplexity4.011381149291992
INFO:root:current mean train loss 1587.229079691569
INFO:root:current train perplexity4.02047872543335
INFO:root:current mean train loss 1584.8692802877988
INFO:root:current train perplexity4.027462959289551
INFO:root:current mean train loss 1583.7371082652699
INFO:root:current train perplexity4.02579402923584
INFO:root:current mean train loss 1584.1691268355758
INFO:root:current train perplexity4.024733066558838
INFO:root:current mean train loss 1588.0749197006226
INFO:root:current train perplexity4.037542343139648
INFO:root:current mean train loss 1589.41466229413
INFO:root:current train perplexity4.040674209594727
INFO:root:current mean train loss 1589.0643198649088
INFO:root:current train perplexity4.038814067840576
INFO:root:current mean train loss 1589.3037572982464
INFO:root:current train perplexity4.037081718444824
INFO:root:current mean train loss 1589.9959584162787
INFO:root:current train perplexity4.0375471115112305
INFO:root:current mean train loss 1591.561613812363
INFO:root:current train perplexity4.0415873527526855
INFO:root:current mean train loss 1591.337672178207
INFO:root:current train perplexity4.041159629821777
INFO:root:current mean train loss 1591.6395778371327
INFO:root:current train perplexity4.043511867523193
INFO:root:current mean train loss 1592.5784066094293
INFO:root:current train perplexity4.045660018920898
INFO:root:current mean train loss 1591.9227352786374
INFO:root:current train perplexity4.046627521514893
INFO:root:current mean train loss 1591.9435094321645
INFO:root:current train perplexity4.046579360961914
INFO:root:current mean train loss 1592.3922125454608
INFO:root:current train perplexity4.046140670776367
INFO:root:current mean train loss 1593.1906666631285
INFO:root:current train perplexity4.0486860275268555
INFO:root:current mean train loss 1593.1485703930412
INFO:root:current train perplexity4.049351215362549

100%|██████████| 1/1 [05:36<00:00, 336.42s/it][A100%|██████████| 1/1 [05:36<00:00, 336.42s/it]
INFO:root:final mean train loss: 1592.9634378176413
INFO:root:final train perplexity: 4.050417900085449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 1818.6859083243296
INFO:root:eval perplexity: 5.16566276550293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2273.123207903923
INFO:root:eval perplexity: 8.075423240661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/74
 37%|███▋      | 74/200 [7:34:19<12:54:18, 368.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1571.0072449801262
INFO:root:current train perplexity4.011094093322754
INFO:root:current mean train loss 1577.3004764629777
INFO:root:current train perplexity4.013989448547363
INFO:root:current mean train loss 1582.438361141932
INFO:root:current train perplexity4.023615837097168
INFO:root:current mean train loss 1587.4792367630646
INFO:root:current train perplexity4.025953769683838
INFO:root:current mean train loss 1587.520977128778
INFO:root:current train perplexity4.028122425079346
INFO:root:current mean train loss 1588.454226701007
INFO:root:current train perplexity4.025920391082764
INFO:root:current mean train loss 1591.266876731652
INFO:root:current train perplexity4.028328895568848
INFO:root:current mean train loss 1589.2888785076268
INFO:root:current train perplexity4.023996353149414
INFO:root:current mean train loss 1588.9945123910625
INFO:root:current train perplexity4.025154113769531
INFO:root:current mean train loss 1587.5001128863391
INFO:root:current train perplexity4.024685859680176
INFO:root:current mean train loss 1588.1032146645134
INFO:root:current train perplexity4.029154300689697
INFO:root:current mean train loss 1587.9349844231108
INFO:root:current train perplexity4.028697490692139
INFO:root:current mean train loss 1587.5905670433074
INFO:root:current train perplexity4.030073642730713
INFO:root:current mean train loss 1587.7795676426056
INFO:root:current train perplexity4.0327606201171875
INFO:root:current mean train loss 1589.1943056922132
INFO:root:current train perplexity4.034659385681152
INFO:root:current mean train loss 1589.8272013581557
INFO:root:current train perplexity4.035511493682861
INFO:root:current mean train loss 1589.3664253893285
INFO:root:current train perplexity4.035765171051025
INFO:root:current mean train loss 1590.8247480224193
INFO:root:current train perplexity4.04031229019165
INFO:root:current mean train loss 1591.0030874520396
INFO:root:current train perplexity4.041314125061035
INFO:root:current mean train loss 1590.2910510547074
INFO:root:current train perplexity4.039487838745117

100%|██████████| 1/1 [05:37<00:00, 337.08s/it][A100%|██████████| 1/1 [05:37<00:00, 337.08s/it]
INFO:root:final mean train loss: 1589.5013382796742
INFO:root:final train perplexity: 4.03812313079834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1819.5076298274048
INFO:root:eval perplexity: 5.169496536254883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.81s/it][A100%|██████████| 1/1 [00:15<00:00, 15.81s/it]
INFO:root:eval mean loss: 2277.0800447937445
INFO:root:eval perplexity: 8.104837417602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/75
 38%|███▊      | 75/200 [7:40:28<12:48:37, 368.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1580.5099602776604
INFO:root:current train perplexity4.01155424118042
INFO:root:current mean train loss 1581.5050645148617
INFO:root:current train perplexity4.018675804138184
INFO:root:current mean train loss 1582.0762302370838
INFO:root:current train perplexity4.016327381134033
INFO:root:current mean train loss 1585.8541060666987
INFO:root:current train perplexity4.021775245666504
INFO:root:current mean train loss 1583.140806560275
INFO:root:current train perplexity4.01336669921875
INFO:root:current mean train loss 1583.284698379995
INFO:root:current train perplexity4.021460056304932
INFO:root:current mean train loss 1582.9746292974546
INFO:root:current train perplexity4.019224643707275
INFO:root:current mean train loss 1583.4982214639354
INFO:root:current train perplexity4.023069858551025
INFO:root:current mean train loss 1583.9202143409432
INFO:root:current train perplexity4.0269455909729
INFO:root:current mean train loss 1584.0608828816814
INFO:root:current train perplexity4.025306224822998
INFO:root:current mean train loss 1586.7525016457896
INFO:root:current train perplexity4.029045104980469
INFO:root:current mean train loss 1585.844527548379
INFO:root:current train perplexity4.027599334716797
INFO:root:current mean train loss 1585.655184807171
INFO:root:current train perplexity4.025409698486328
INFO:root:current mean train loss 1585.598660709209
INFO:root:current train perplexity4.029219150543213
INFO:root:current mean train loss 1586.0824039205606
INFO:root:current train perplexity4.028319358825684
INFO:root:current mean train loss 1586.1069377041226
INFO:root:current train perplexity4.0266947746276855
INFO:root:current mean train loss 1586.035173094828
INFO:root:current train perplexity4.0278449058532715
INFO:root:current mean train loss 1586.137594091852
INFO:root:current train perplexity4.02640962600708
INFO:root:current mean train loss 1586.5248245027556
INFO:root:current train perplexity4.026477813720703
INFO:root:current mean train loss 1586.7025342514207
INFO:root:current train perplexity4.02685546875

100%|██████████| 1/1 [05:36<00:00, 336.89s/it][A100%|██████████| 1/1 [05:36<00:00, 336.89s/it]
INFO:root:final mean train loss: 1586.3961716583144
INFO:root:final train perplexity: 4.027128219604492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1820.057794665614
INFO:root:eval perplexity: 5.172064304351807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 2277.6830634800253
INFO:root:eval perplexity: 8.109329223632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/76
 38%|███▊      | 76/200 [7:46:37<12:42:40, 369.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1561.8092269059066
INFO:root:current train perplexity3.9640119075775146
INFO:root:current mean train loss 1572.0373062213678
INFO:root:current train perplexity3.9921631813049316
INFO:root:current mean train loss 1571.0967447077696
INFO:root:current train perplexity3.9887943267822266
INFO:root:current mean train loss 1573.3841237412084
INFO:root:current train perplexity3.9974911212921143
INFO:root:current mean train loss 1576.9508088960667
INFO:root:current train perplexity4.011897563934326
INFO:root:current mean train loss 1577.917370378265
INFO:root:current train perplexity4.015138149261475
INFO:root:current mean train loss 1578.873794666075
INFO:root:current train perplexity4.008296012878418
INFO:root:current mean train loss 1579.2142479048969
INFO:root:current train perplexity4.006896018981934
INFO:root:current mean train loss 1582.8125846682976
INFO:root:current train perplexity4.014593124389648
INFO:root:current mean train loss 1582.3085735486566
INFO:root:current train perplexity4.014184474945068
INFO:root:current mean train loss 1581.438475331727
INFO:root:current train perplexity4.012031078338623
INFO:root:current mean train loss 1583.6266262717452
INFO:root:current train perplexity4.013473033905029
INFO:root:current mean train loss 1583.8480515838316
INFO:root:current train perplexity4.015725612640381
INFO:root:current mean train loss 1583.253775754993
INFO:root:current train perplexity4.015857219696045
INFO:root:current mean train loss 1582.6919782038585
INFO:root:current train perplexity4.013027191162109
INFO:root:current mean train loss 1582.4471253707377
INFO:root:current train perplexity4.013091087341309
INFO:root:current mean train loss 1583.3921231947165
INFO:root:current train perplexity4.014148235321045
INFO:root:current mean train loss 1583.7142415773528
INFO:root:current train perplexity4.015442848205566
INFO:root:current mean train loss 1583.7615038520253
INFO:root:current train perplexity4.015887260437012

100%|██████████| 1/1 [05:36<00:00, 336.26s/it][A100%|██████████| 1/1 [05:36<00:00, 336.26s/it]
INFO:root:final mean train loss: 1584.1137696543667
INFO:root:final train perplexity: 4.019063949584961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1818.1700517370346
INFO:root:eval perplexity: 5.163257598876953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2274.6917148887687
INFO:root:eval perplexity: 8.087067604064941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/77
 38%|███▊      | 77/200 [7:52:46<12:36:14, 368.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1526.7776336669922
INFO:root:current train perplexity4.030938625335693
INFO:root:current mean train loss 1580.8216451009114
INFO:root:current train perplexity4.008974075317383
INFO:root:current mean train loss 1573.6555809607873
INFO:root:current train perplexity3.9953036308288574
INFO:root:current mean train loss 1578.939608487216
INFO:root:current train perplexity4.014782428741455
INFO:root:current mean train loss 1577.6870159074372
INFO:root:current train perplexity4.001884937286377
INFO:root:current mean train loss 1577.1494049312562
INFO:root:current train perplexity4.005533218383789
INFO:root:current mean train loss 1578.4509895726253
INFO:root:current train perplexity4.010098934173584
INFO:root:current mean train loss 1578.6011445643537
INFO:root:current train perplexity4.01025915145874
INFO:root:current mean train loss 1579.2026261433516
INFO:root:current train perplexity4.008912563323975
INFO:root:current mean train loss 1579.9360941748262
INFO:root:current train perplexity4.010946750640869
INFO:root:current mean train loss 1580.1041532244
INFO:root:current train perplexity4.010316371917725
INFO:root:current mean train loss 1579.8244862470385
INFO:root:current train perplexity4.009422779083252
INFO:root:current mean train loss 1578.3436087298867
INFO:root:current train perplexity4.004741668701172
INFO:root:current mean train loss 1580.3314409635118
INFO:root:current train perplexity4.010420799255371
INFO:root:current mean train loss 1580.6128256537697
INFO:root:current train perplexity4.008991718292236
INFO:root:current mean train loss 1580.275845717372
INFO:root:current train perplexity4.006631374359131
INFO:root:current mean train loss 1580.8559931664918
INFO:root:current train perplexity4.007559776306152
INFO:root:current mean train loss 1581.5232879138384
INFO:root:current train perplexity4.009195327758789
INFO:root:current mean train loss 1581.907577312098
INFO:root:current train perplexity4.0092291831970215
INFO:root:current mean train loss 1581.7400494141648
INFO:root:current train perplexity4.009359359741211

100%|██████████| 1/1 [05:35<00:00, 335.41s/it][A100%|██████████| 1/1 [05:35<00:00, 335.41s/it]
INFO:root:final mean train loss: 1581.3502204652634
INFO:root:final train perplexity: 4.0093231201171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1821.5315504141734
INFO:root:eval perplexity: 5.178951740264893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2280.4292048461048
INFO:root:eval perplexity: 8.129820823669434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/78
 39%|███▉      | 78/200 [7:58:54<12:29:22, 368.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1543.6162890625
INFO:root:current train perplexity3.962019205093384
INFO:root:current mean train loss 1556.3176201171875
INFO:root:current train perplexity3.963881015777588
INFO:root:current mean train loss 1562.6858637152777
INFO:root:current train perplexity3.965686082839966
INFO:root:current mean train loss 1568.349288236178
INFO:root:current train perplexity3.9820549488067627
INFO:root:current mean train loss 1568.318199965533
INFO:root:current train perplexity3.983128070831299
INFO:root:current mean train loss 1573.6278050595238
INFO:root:current train perplexity3.9851298332214355
INFO:root:current mean train loss 1575.2486392578126
INFO:root:current train perplexity3.987760305404663
INFO:root:current mean train loss 1575.4811331492456
INFO:root:current train perplexity3.989563226699829
INFO:root:current mean train loss 1575.525926550663
INFO:root:current train perplexity3.994821071624756
INFO:root:current mean train loss 1577.2522113861908
INFO:root:current train perplexity3.9945919513702393
INFO:root:current mean train loss 1577.8599184213033
INFO:root:current train perplexity3.995988368988037
INFO:root:current mean train loss 1577.1159699435764
INFO:root:current train perplexity3.9951016902923584
INFO:root:current mean train loss 1577.3382246492347
INFO:root:current train perplexity3.9936230182647705
INFO:root:current mean train loss 1577.4530979142098
INFO:root:current train perplexity3.9929709434509277
INFO:root:current mean train loss 1576.0779655804552
INFO:root:current train perplexity3.990067481994629
INFO:root:current mean train loss 1576.0633785860655
INFO:root:current train perplexity3.989079713821411
INFO:root:current mean train loss 1577.0197629957934
INFO:root:current train perplexity3.9947359561920166
INFO:root:current mean train loss 1577.8507306527401
INFO:root:current train perplexity3.9959022998809814
INFO:root:current mean train loss 1578.0543180784462
INFO:root:current train perplexity3.996821641921997
INFO:root:current mean train loss 1578.4443247133725
INFO:root:current train perplexity3.997687578201294

100%|██████████| 1/1 [05:36<00:00, 336.60s/it][A100%|██████████| 1/1 [05:36<00:00, 336.60s/it]
INFO:root:final mean train loss: 1578.0898567696022
INFO:root:final train perplexity: 3.9978604316711426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.83s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 1820.587684144365
INFO:root:eval perplexity: 5.1745405197143555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2278.293637539478
INFO:root:eval perplexity: 8.113882064819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/79
 40%|███▉      | 79/200 [8:05:03<12:23:30, 368.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1554.7726411365327
INFO:root:current train perplexity3.9051613807678223
INFO:root:current mean train loss 1582.2849662673304
INFO:root:current train perplexity3.967836618423462
INFO:root:current mean train loss 1579.26049350707
INFO:root:current train perplexity3.9634501934051514
INFO:root:current mean train loss 1572.366448296441
INFO:root:current train perplexity3.9578943252563477
INFO:root:current mean train loss 1573.2810746274922
INFO:root:current train perplexity3.9586870670318604
INFO:root:current mean train loss 1572.3191390934905
INFO:root:current train perplexity3.9655749797821045
INFO:root:current mean train loss 1572.5268898842119
INFO:root:current train perplexity3.974008560180664
INFO:root:current mean train loss 1572.6886238036452
INFO:root:current train perplexity3.974863290786743
INFO:root:current mean train loss 1573.4441421037616
INFO:root:current train perplexity3.9804766178131104
INFO:root:current mean train loss 1575.008648461344
INFO:root:current train perplexity3.982304811477661
INFO:root:current mean train loss 1574.269074013503
INFO:root:current train perplexity3.9840517044067383
INFO:root:current mean train loss 1574.0440934643855
INFO:root:current train perplexity3.982797622680664
INFO:root:current mean train loss 1573.1582431271072
INFO:root:current train perplexity3.983180284500122
INFO:root:current mean train loss 1573.744690305252
INFO:root:current train perplexity3.9859085083007812
INFO:root:current mean train loss 1573.7743719897223
INFO:root:current train perplexity3.985840082168579
INFO:root:current mean train loss 1573.8911595919717
INFO:root:current train perplexity3.9859883785247803
INFO:root:current mean train loss 1574.5353694641633
INFO:root:current train perplexity3.9878766536712646
INFO:root:current mean train loss 1575.412613563231
INFO:root:current train perplexity3.9889779090881348
INFO:root:current mean train loss 1575.3195168560412
INFO:root:current train perplexity3.9892351627349854
INFO:root:current mean train loss 1575.1568540657586
INFO:root:current train perplexity3.9882922172546387

100%|██████████| 1/1 [05:36<00:00, 336.35s/it][A100%|██████████| 1/1 [05:36<00:00, 336.35s/it]
INFO:root:final mean train loss: 1575.2464024653893
INFO:root:final train perplexity: 3.9878909587860107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1823.3675160509474
INFO:root:eval perplexity: 5.187543869018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2284.4262115262077
INFO:root:eval perplexity: 8.159734725952148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/80
 40%|████      | 80/200 [8:11:11<12:17:21, 368.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1559.1801075046346
INFO:root:current train perplexity3.9496395587921143
INFO:root:current mean train loss 1563.0184103527909
INFO:root:current train perplexity3.953385829925537
INFO:root:current mean train loss 1561.819607414334
INFO:root:current train perplexity3.9567606449127197
INFO:root:current mean train loss 1570.4678040400854
INFO:root:current train perplexity3.965826988220215
INFO:root:current mean train loss 1565.6158811614923
INFO:root:current train perplexity3.956857442855835
INFO:root:current mean train loss 1567.8127974235522
INFO:root:current train perplexity3.961660861968994
INFO:root:current mean train loss 1567.1782187663007
INFO:root:current train perplexity3.962419271469116
INFO:root:current mean train loss 1567.3721402737463
INFO:root:current train perplexity3.9594035148620605
INFO:root:current mean train loss 1568.3727100803078
INFO:root:current train perplexity3.9621756076812744
INFO:root:current mean train loss 1569.3545648696152
INFO:root:current train perplexity3.965681791305542
INFO:root:current mean train loss 1570.9437941712406
INFO:root:current train perplexity3.968433141708374
INFO:root:current mean train loss 1571.850536224655
INFO:root:current train perplexity3.9709365367889404
INFO:root:current mean train loss 1571.395220816372
INFO:root:current train perplexity3.9697046279907227
INFO:root:current mean train loss 1572.7269883538274
INFO:root:current train perplexity3.973829507827759
INFO:root:current mean train loss 1572.337569092299
INFO:root:current train perplexity3.973615884780884
INFO:root:current mean train loss 1571.2221556755883
INFO:root:current train perplexity3.9733774662017822
INFO:root:current mean train loss 1571.593548094673
INFO:root:current train perplexity3.974015235900879
INFO:root:current mean train loss 1572.493871709445
INFO:root:current train perplexity3.9763741493225098
INFO:root:current mean train loss 1572.2780804400677
INFO:root:current train perplexity3.977349281311035
INFO:root:current mean train loss 1572.7215099480761
INFO:root:current train perplexity3.9777607917785645

100%|██████████| 1/1 [05:36<00:00, 336.73s/it][A100%|██████████| 1/1 [05:36<00:00, 336.73s/it]
INFO:root:final mean train loss: 1572.3795374083027
INFO:root:final train perplexity: 3.9778637886047363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1822.2972433753048
INFO:root:eval perplexity: 5.182533264160156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2284.1256454143117
INFO:root:eval perplexity: 8.157482147216797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/81
 40%|████      | 81/200 [8:17:20<12:11:26, 368.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1549.6722347861842
INFO:root:current train perplexity3.9468820095062256
INFO:root:current mean train loss 1554.9848473288796
INFO:root:current train perplexity3.9330174922943115
INFO:root:current mean train loss 1557.7770929751189
INFO:root:current train perplexity3.93577241897583
INFO:root:current mean train loss 1561.1100694372299
INFO:root:current train perplexity3.9404759407043457
INFO:root:current mean train loss 1560.4295772263984
INFO:root:current train perplexity3.9357869625091553
INFO:root:current mean train loss 1562.3203112284343
INFO:root:current train perplexity3.940775156021118
INFO:root:current mean train loss 1562.9173421464727
INFO:root:current train perplexity3.9454660415649414
INFO:root:current mean train loss 1565.3120790461903
INFO:root:current train perplexity3.9489827156066895
INFO:root:current mean train loss 1568.7982307329569
INFO:root:current train perplexity3.9569339752197266
INFO:root:current mean train loss 1569.5454021516393
INFO:root:current train perplexity3.9552323818206787
INFO:root:current mean train loss 1570.1488501112701
INFO:root:current train perplexity3.955235719680786
INFO:root:current mean train loss 1569.5717129869527
INFO:root:current train perplexity3.955538749694824
INFO:root:current mean train loss 1569.4576340439178
INFO:root:current train perplexity3.9563159942626953
INFO:root:current mean train loss 1569.2387839029002
INFO:root:current train perplexity3.955312967300415
INFO:root:current mean train loss 1569.1785173286914
INFO:root:current train perplexity3.9587318897247314
INFO:root:current mean train loss 1568.2573552785186
INFO:root:current train perplexity3.95989727973938
INFO:root:current mean train loss 1568.0598279274734
INFO:root:current train perplexity3.960416078567505
INFO:root:current mean train loss 1567.924768396326
INFO:root:current train perplexity3.9603986740112305
INFO:root:current mean train loss 1568.607696793481
INFO:root:current train perplexity3.9627037048339844
INFO:root:current mean train loss 1569.5628158631112
INFO:root:current train perplexity3.966423511505127

100%|██████████| 1/1 [05:36<00:00, 336.33s/it][A100%|██████████| 1/1 [05:36<00:00, 336.33s/it]
INFO:root:final mean train loss: 1568.965821543668
INFO:root:final train perplexity: 3.9659578800201416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1823.0560233474623
INFO:root:eval perplexity: 5.186084270477295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.84s/it][A100%|██████████| 1/1 [00:15<00:00, 15.85s/it]
INFO:root:eval mean loss: 2286.95782081117
INFO:root:eval perplexity: 8.178740501403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/82
 41%|████      | 82/200 [8:23:29<12:05:16, 368.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.8003874747983
INFO:root:current train perplexity3.950192928314209
INFO:root:current mean train loss 1569.7281626963245
INFO:root:current train perplexity3.9607319831848145
INFO:root:current mean train loss 1571.7353436466776
INFO:root:current train perplexity3.946082592010498
INFO:root:current mean train loss 1568.0641325739505
INFO:root:current train perplexity3.939598560333252
INFO:root:current mean train loss 1565.0922460343243
INFO:root:current train perplexity3.936612367630005
INFO:root:current mean train loss 1568.5054478765942
INFO:root:current train perplexity3.9459428787231445
INFO:root:current mean train loss 1568.413006847211
INFO:root:current train perplexity3.945516347885132
INFO:root:current mean train loss 1567.5154602897424
INFO:root:current train perplexity3.9469096660614014
INFO:root:current mean train loss 1567.1348922063096
INFO:root:current train perplexity3.9513185024261475
INFO:root:current mean train loss 1566.9496722418255
INFO:root:current train perplexity3.9490928649902344
INFO:root:current mean train loss 1566.6352427378774
INFO:root:current train perplexity3.9499258995056152
INFO:root:current mean train loss 1566.6316869564648
INFO:root:current train perplexity3.950927972793579
INFO:root:current mean train loss 1566.3142542060916
INFO:root:current train perplexity3.9502804279327393
INFO:root:current mean train loss 1566.6348413383885
INFO:root:current train perplexity3.951204538345337
INFO:root:current mean train loss 1566.5615701234667
INFO:root:current train perplexity3.9509294033050537
INFO:root:current mean train loss 1566.1780143014605
INFO:root:current train perplexity3.950484275817871
INFO:root:current mean train loss 1566.7742374102463
INFO:root:current train perplexity3.9526050090789795
INFO:root:current mean train loss 1566.2248514050953
INFO:root:current train perplexity3.9532384872436523
INFO:root:current mean train loss 1566.4563533825278
INFO:root:current train perplexity3.954878330230713

100%|██████████| 1/1 [05:36<00:00, 336.29s/it][A100%|██████████| 1/1 [05:36<00:00, 336.29s/it]
INFO:root:final mean train loss: 1566.324466276337
INFO:root:final train perplexity: 3.9567692279815674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1822.3336848265735
INFO:root:eval perplexity: 5.182703495025635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2285.047922986619
INFO:root:eval perplexity: 8.164399147033691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/83
 42%|████▏     | 83/200 [8:29:38<11:59:02, 368.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1529.35703125
INFO:root:current train perplexity3.9417340755462646
INFO:root:current mean train loss 1561.8889581853693
INFO:root:current train perplexity3.9343678951263428
INFO:root:current mean train loss 1555.1611496698288
INFO:root:current train perplexity3.9276199340820312
INFO:root:current mean train loss 1560.5882879441783
INFO:root:current train perplexity3.9456870555877686
INFO:root:current mean train loss 1562.359738233613
INFO:root:current train perplexity3.93544864654541
INFO:root:current mean train loss 1563.5276427025888
INFO:root:current train perplexity3.9449870586395264
INFO:root:current mean train loss 1564.1362873014857
INFO:root:current train perplexity3.948941946029663
INFO:root:current mean train loss 1563.902852147062
INFO:root:current train perplexity3.9513537883758545
INFO:root:current mean train loss 1562.6610315393518
INFO:root:current train perplexity3.9507315158843994
INFO:root:current mean train loss 1562.0090102646377
INFO:root:current train perplexity3.951388120651245
INFO:root:current mean train loss 1564.2482229704904
INFO:root:current train perplexity3.9510178565979004
INFO:root:current mean train loss 1565.0178457999014
INFO:root:current train perplexity3.952437400817871
INFO:root:current mean train loss 1565.0845156330709
INFO:root:current train perplexity3.9516425132751465
INFO:root:current mean train loss 1564.5911261405654
INFO:root:current train perplexity3.95084547996521
INFO:root:current mean train loss 1565.3221918633644
INFO:root:current train perplexity3.952056646347046
INFO:root:current mean train loss 1564.293326634287
INFO:root:current train perplexity3.9481825828552246
INFO:root:current mean train loss 1565.0629225452494
INFO:root:current train perplexity3.9520246982574463
INFO:root:current mean train loss 1564.5849269576938
INFO:root:current train perplexity3.95196533203125
INFO:root:current mean train loss 1563.4319246239425
INFO:root:current train perplexity3.9488604068756104
INFO:root:current mean train loss 1564.4071009770737
INFO:root:current train perplexity3.9506454467773438

100%|██████████| 1/1 [05:35<00:00, 335.11s/it][A100%|██████████| 1/1 [05:35<00:00, 335.11s/it]
INFO:root:final mean train loss: 1563.9009962365656
INFO:root:final train perplexity: 3.948357582092285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1824.3004011871121
INFO:root:eval perplexity: 5.191915035247803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2288.919184691517
INFO:root:eval perplexity: 8.193495750427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/84
 42%|████▏     | 84/200 [8:35:45<11:52:05, 368.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1529.8788519965278
INFO:root:current train perplexity3.915253162384033
INFO:root:current mean train loss 1543.464712067852
INFO:root:current train perplexity3.9154038429260254
INFO:root:current mean train loss 1553.3022918028978
INFO:root:current train perplexity3.9239542484283447
INFO:root:current mean train loss 1557.8410398150802
INFO:root:current train perplexity3.931628942489624
INFO:root:current mean train loss 1555.0737710635613
INFO:root:current train perplexity3.9307029247283936
INFO:root:current mean train loss 1554.9349339754804
INFO:root:current train perplexity3.928122043609619
INFO:root:current mean train loss 1556.41444311796
INFO:root:current train perplexity3.9290974140167236
INFO:root:current mean train loss 1556.1432158458347
INFO:root:current train perplexity3.9272305965423584
INFO:root:current mean train loss 1558.3623235810912
INFO:root:current train perplexity3.9332191944122314
INFO:root:current mean train loss 1558.0306414920021
INFO:root:current train perplexity3.932185411453247
INFO:root:current mean train loss 1558.287741240415
INFO:root:current train perplexity3.9335477352142334
INFO:root:current mean train loss 1558.987718231824
INFO:root:current train perplexity3.936943769454956
INFO:root:current mean train loss 1558.2461802040355
INFO:root:current train perplexity3.9330503940582275
INFO:root:current mean train loss 1559.0377770361365
INFO:root:current train perplexity3.93574857711792
INFO:root:current mean train loss 1559.6536448638424
INFO:root:current train perplexity3.937411308288574
INFO:root:current mean train loss 1559.6651554569826
INFO:root:current train perplexity3.937636613845825
INFO:root:current mean train loss 1560.1839610863553
INFO:root:current train perplexity3.938490390777588
INFO:root:current mean train loss 1561.4499496875226
INFO:root:current train perplexity3.9405324459075928
INFO:root:current mean train loss 1561.838400955075
INFO:root:current train perplexity3.941479444503784
INFO:root:current mean train loss 1561.5725059014376
INFO:root:current train perplexity3.9395806789398193

100%|██████████| 1/1 [05:36<00:00, 336.56s/it][A100%|██████████| 1/1 [05:36<00:00, 336.56s/it]
INFO:root:final mean train loss: 1561.572098247703
INFO:root:final train perplexity: 3.940290927886963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1826.361559712295
INFO:root:eval perplexity: 5.201585292816162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2293.466193882286
INFO:root:eval perplexity: 8.227802276611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/85
 42%|████▎     | 85/200 [8:41:54<11:46:19, 368.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1547.1139692826705
INFO:root:current train perplexity3.909555196762085
INFO:root:current mean train loss 1553.0460323757595
INFO:root:current train perplexity3.9323110580444336
INFO:root:current mean train loss 1550.2207466500704
INFO:root:current train perplexity3.9311134815216064
INFO:root:current mean train loss 1550.7126972287201
INFO:root:current train perplexity3.928980827331543
INFO:root:current mean train loss 1548.6110270732158
INFO:root:current train perplexity3.9179952144622803
INFO:root:current mean train loss 1552.1645658156451
INFO:root:current train perplexity3.9237582683563232
INFO:root:current mean train loss 1555.818014393682
INFO:root:current train perplexity3.930199384689331
INFO:root:current mean train loss 1555.0906399962723
INFO:root:current train perplexity3.9266438484191895
INFO:root:current mean train loss 1553.7161314182372
INFO:root:current train perplexity3.919527769088745
INFO:root:current mean train loss 1553.321841870324
INFO:root:current train perplexity3.9190783500671387
INFO:root:current mean train loss 1553.1218175193817
INFO:root:current train perplexity3.918520212173462
INFO:root:current mean train loss 1554.2573926165387
INFO:root:current train perplexity3.921093463897705
INFO:root:current mean train loss 1554.325817144952
INFO:root:current train perplexity3.9207377433776855
INFO:root:current mean train loss 1554.369460151309
INFO:root:current train perplexity3.921773672103882
INFO:root:current mean train loss 1554.9060910718922
INFO:root:current train perplexity3.920764446258545
INFO:root:current mean train loss 1557.1369392513611
INFO:root:current train perplexity3.9252407550811768
INFO:root:current mean train loss 1558.0675217380199
INFO:root:current train perplexity3.9270358085632324
INFO:root:current mean train loss 1557.636694881894
INFO:root:current train perplexity3.9259867668151855
INFO:root:current mean train loss 1558.8028410210268
INFO:root:current train perplexity3.928631067276001
INFO:root:current mean train loss 1558.644404156218
INFO:root:current train perplexity3.929581880569458

100%|██████████| 1/1 [05:36<00:00, 336.79s/it][A100%|██████████| 1/1 [05:36<00:00, 336.79s/it]
INFO:root:final mean train loss: 1558.7722617960674
INFO:root:final train perplexity: 3.9306154251098633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1824.9387202702515
INFO:root:eval perplexity: 5.1949076652526855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2290.726505360705
INFO:root:eval perplexity: 8.207113265991211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/86
 43%|████▎     | 86/200 [8:48:03<11:40:25, 368.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1561.3434138063524
INFO:root:current train perplexity3.9150583744049072
INFO:root:current mean train loss 1555.8872661709045
INFO:root:current train perplexity3.9179646968841553
INFO:root:current mean train loss 1553.0818217193487
INFO:root:current train perplexity3.911227226257324
INFO:root:current mean train loss 1551.144346622879
INFO:root:current train perplexity3.911200523376465
INFO:root:current mean train loss 1549.0361603511387
INFO:root:current train perplexity3.9088449478149414
INFO:root:current mean train loss 1550.073923474752
INFO:root:current train perplexity3.9070489406585693
INFO:root:current mean train loss 1551.1115264661735
INFO:root:current train perplexity3.9104039669036865
INFO:root:current mean train loss 1550.9343810313321
INFO:root:current train perplexity3.907966136932373
INFO:root:current mean train loss 1549.5398356119792
INFO:root:current train perplexity3.9087014198303223
INFO:root:current mean train loss 1551.1746531475594
INFO:root:current train perplexity3.910940408706665
INFO:root:current mean train loss 1555.3078097847697
INFO:root:current train perplexity3.9160773754119873
INFO:root:current mean train loss 1554.756542800522
INFO:root:current train perplexity3.9172890186309814
INFO:root:current mean train loss 1554.6901351117974
INFO:root:current train perplexity3.918022632598877
INFO:root:current mean train loss 1555.0040720898294
INFO:root:current train perplexity3.9161171913146973
INFO:root:current mean train loss 1554.572316007203
INFO:root:current train perplexity3.9181783199310303
INFO:root:current mean train loss 1554.719969764724
INFO:root:current train perplexity3.9196531772613525
INFO:root:current mean train loss 1554.6975602546706
INFO:root:current train perplexity3.9208998680114746
INFO:root:current mean train loss 1555.2152125257312
INFO:root:current train perplexity3.9206175804138184
INFO:root:current mean train loss 1556.1548237910774
INFO:root:current train perplexity3.9216740131378174
INFO:root:current mean train loss 1556.5767868329895
INFO:root:current train perplexity3.9207358360290527

100%|██████████| 1/1 [05:37<00:00, 337.07s/it][A100%|██████████| 1/1 [05:37<00:00, 337.07s/it]
INFO:root:final mean train loss: 1555.8317678108158
INFO:root:final train perplexity: 3.9204792976379395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1827.3121489396333
INFO:root:eval perplexity: 5.206051349639893
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.91s/it][A100%|██████████| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2294.5224856112864
INFO:root:eval perplexity: 8.235790252685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/87
 44%|████▎     | 87/200 [8:54:13<11:34:48, 368.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.9945553510618
INFO:root:current train perplexity3.885694980621338
INFO:root:current mean train loss 1556.5691260862886
INFO:root:current train perplexity3.892437696456909
INFO:root:current mean train loss 1554.044851618705
INFO:root:current train perplexity3.9049253463745117
INFO:root:current mean train loss 1551.8384460772156
INFO:root:current train perplexity3.906803607940674
INFO:root:current mean train loss 1551.1911363162756
INFO:root:current train perplexity3.909438133239746
INFO:root:current mean train loss 1550.3815618072827
INFO:root:current train perplexity3.908417224884033
INFO:root:current mean train loss 1550.4249717689897
INFO:root:current train perplexity3.908522367477417
INFO:root:current mean train loss 1551.4751677917636
INFO:root:current train perplexity3.9071216583251953
INFO:root:current mean train loss 1551.5245298763614
INFO:root:current train perplexity3.9065637588500977
INFO:root:current mean train loss 1551.4847231125782
INFO:root:current train perplexity3.908576011657715
INFO:root:current mean train loss 1551.4039483291542
INFO:root:current train perplexity3.90628981590271
INFO:root:current mean train loss 1552.578716802678
INFO:root:current train perplexity3.9075353145599365
INFO:root:current mean train loss 1553.594574499951
INFO:root:current train perplexity3.9123692512512207
INFO:root:current mean train loss 1552.4321685923894
INFO:root:current train perplexity3.9087371826171875
INFO:root:current mean train loss 1552.9977080844574
INFO:root:current train perplexity3.9104490280151367
INFO:root:current mean train loss 1552.0442257338452
INFO:root:current train perplexity3.908588171005249
INFO:root:current mean train loss 1552.183277225608
INFO:root:current train perplexity3.909017324447632
INFO:root:current mean train loss 1552.321304716061
INFO:root:current train perplexity3.910228967666626
INFO:root:current mean train loss 1553.0602819343217
INFO:root:current train perplexity3.911715507507324
INFO:root:current mean train loss 1554.065548363542
INFO:root:current train perplexity3.9134411811828613

100%|██████████| 1/1 [05:36<00:00, 336.13s/it][A100%|██████████| 1/1 [05:36<00:00, 336.13s/it]
INFO:root:final mean train loss: 1553.7669598631828
INFO:root:final train perplexity: 3.913377285003662
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:16<00:00, 16.03s/it][A100%|██████████| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 1827.1551734437335
INFO:root:eval perplexity: 5.2053141593933105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2294.615918747922
INFO:root:eval perplexity: 8.236496925354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/88
 44%|████▍     | 88/200 [9:00:22<11:28:35, 368.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.316511615954
INFO:root:current train perplexity3.8860487937927246
INFO:root:current mean train loss 1545.7290408403446
INFO:root:current train perplexity3.8625645637512207
INFO:root:current mean train loss 1539.3703555349575
INFO:root:current train perplexity3.8608341217041016
INFO:root:current mean train loss 1539.3772887410996
INFO:root:current train perplexity3.8705151081085205
INFO:root:current mean train loss 1541.840772224195
INFO:root:current train perplexity3.877521276473999
INFO:root:current mean train loss 1542.6162109375
INFO:root:current train perplexity3.8811252117156982
INFO:root:current mean train loss 1541.0225812514052
INFO:root:current train perplexity3.8819456100463867
INFO:root:current mean train loss 1544.8783355137086
INFO:root:current train perplexity3.885744094848633
INFO:root:current mean train loss 1545.818669665459
INFO:root:current train perplexity3.8875036239624023
INFO:root:current mean train loss 1547.3038869886543
INFO:root:current train perplexity3.8912248611450195
INFO:root:current mean train loss 1547.4319364922233
INFO:root:current train perplexity3.8927276134490967
INFO:root:current mean train loss 1548.1912408677106
INFO:root:current train perplexity3.8933491706848145
INFO:root:current mean train loss 1548.1986809807854
INFO:root:current train perplexity3.894235134124756
INFO:root:current mean train loss 1548.671594719562
INFO:root:current train perplexity3.8945071697235107
INFO:root:current mean train loss 1549.0847501110472
INFO:root:current train perplexity3.8973240852355957
INFO:root:current mean train loss 1549.8650936306083
INFO:root:current train perplexity3.897090435028076
INFO:root:current mean train loss 1549.801143427936
INFO:root:current train perplexity3.8997819423675537
INFO:root:current mean train loss 1550.8905861687194
INFO:root:current train perplexity3.9011523723602295
INFO:root:current mean train loss 1550.4382044648746
INFO:root:current train perplexity3.901108980178833

100%|██████████| 1/1 [05:35<00:00, 335.66s/it][A100%|██████████| 1/1 [05:35<00:00, 335.68s/it]
INFO:root:final mean train loss: 1550.601703622638
INFO:root:final train perplexity: 3.902515172958374
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1828.358709240636
INFO:root:eval perplexity: 5.210973262786865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2297.5037214130375
INFO:root:eval perplexity: 8.258383750915527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/89
 44%|████▍     | 89/200 [9:06:30<11:22:01, 368.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1573.3440755208333
INFO:root:current train perplexity3.9229257106781006
INFO:root:current mean train loss 1546.0273709978376
INFO:root:current train perplexity3.876051187515259
INFO:root:current mean train loss 1550.4016182377654
INFO:root:current train perplexity3.8905954360961914
INFO:root:current mean train loss 1545.8143455309746
INFO:root:current train perplexity3.8882341384887695
INFO:root:current mean train loss 1545.3319142165694
INFO:root:current train perplexity3.886721611022949
INFO:root:current mean train loss 1546.4852004051208
INFO:root:current train perplexity3.8860344886779785
INFO:root:current mean train loss 1546.682326372932
INFO:root:current train perplexity3.886108636856079
INFO:root:current mean train loss 1547.8195421883229
INFO:root:current train perplexity3.886240243911743
INFO:root:current mean train loss 1547.1237812512027
INFO:root:current train perplexity3.8860270977020264
INFO:root:current mean train loss 1547.8474014014528
INFO:root:current train perplexity3.887580156326294
INFO:root:current mean train loss 1546.3266725804024
INFO:root:current train perplexity3.8841187953948975
INFO:root:current mean train loss 1547.4984209897707
INFO:root:current train perplexity3.891737461090088
INFO:root:current mean train loss 1547.6452791824593
INFO:root:current train perplexity3.889385223388672
INFO:root:current mean train loss 1548.1142818171804
INFO:root:current train perplexity3.8908803462982178
INFO:root:current mean train loss 1549.243035854091
INFO:root:current train perplexity3.8949079513549805
INFO:root:current mean train loss 1550.1602804194051
INFO:root:current train perplexity3.8945963382720947
INFO:root:current mean train loss 1549.2945199971164
INFO:root:current train perplexity3.8923392295837402
INFO:root:current mean train loss 1549.7719970417913
INFO:root:current train perplexity3.8942782878875732
INFO:root:current mean train loss 1548.8388297984143
INFO:root:current train perplexity3.8941993713378906
INFO:root:current mean train loss 1548.9034440427645
INFO:root:current train perplexity3.895463705062866

100%|██████████| 1/1 [05:35<00:00, 335.98s/it][A100%|██████████| 1/1 [05:35<00:00, 335.98s/it]
INFO:root:final mean train loss: 1548.8570034933161
INFO:root:final train perplexity: 3.896540880203247
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1828.317488000748
INFO:root:eval perplexity: 5.210779666900635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2296.4959937562335
INFO:root:eval perplexity: 8.250740051269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/90
 45%|████▌     | 90/200 [9:12:38<11:15:43, 368.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1544.3111151333512
INFO:root:current train perplexity3.9013774394989014
INFO:root:current mean train loss 1549.4821569161822
INFO:root:current train perplexity3.882371425628662
INFO:root:current mean train loss 1544.6706809497816
INFO:root:current train perplexity3.8664729595184326
INFO:root:current mean train loss 1541.214538017667
INFO:root:current train perplexity3.85860013961792
INFO:root:current mean train loss 1540.7653845584755
INFO:root:current train perplexity3.860555648803711
INFO:root:current mean train loss 1542.981453850499
INFO:root:current train perplexity3.867493152618408
INFO:root:current mean train loss 1543.8103955000497
INFO:root:current train perplexity3.8763949871063232
INFO:root:current mean train loss 1546.1207831321267
INFO:root:current train perplexity3.8817601203918457
INFO:root:current mean train loss 1545.1347763742556
INFO:root:current train perplexity3.8826119899749756
INFO:root:current mean train loss 1544.8660983279651
INFO:root:current train perplexity3.882478713989258
INFO:root:current mean train loss 1544.9050317881058
INFO:root:current train perplexity3.8844263553619385
INFO:root:current mean train loss 1545.3445225353257
INFO:root:current train perplexity3.885446071624756
INFO:root:current mean train loss 1545.2158353105613
INFO:root:current train perplexity3.8873095512390137
INFO:root:current mean train loss 1544.2607397075162
INFO:root:current train perplexity3.885801076889038
INFO:root:current mean train loss 1545.5088574867968
INFO:root:current train perplexity3.8901286125183105
INFO:root:current mean train loss 1546.3392393063532
INFO:root:current train perplexity3.8877029418945312
INFO:root:current mean train loss 1546.8217044312798
INFO:root:current train perplexity3.8879213333129883
INFO:root:current mean train loss 1546.2017049883198
INFO:root:current train perplexity3.8873376846313477
INFO:root:current mean train loss 1546.3892444508397
INFO:root:current train perplexity3.888195753097534
INFO:root:current mean train loss 1547.0437572394214
INFO:root:current train perplexity3.8878977298736572

100%|██████████| 1/1 [05:36<00:00, 336.47s/it][A100%|██████████| 1/1 [05:36<00:00, 336.47s/it]
INFO:root:final mean train loss: 1546.1978014293368
INFO:root:final train perplexity: 3.8874523639678955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1830.3127973840592
INFO:root:eval perplexity: 5.220175743103027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2302.9978256766676
INFO:root:eval perplexity: 8.30018424987793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/91
 46%|████▌     | 91/200 [9:18:47<11:09:40, 368.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1539.7335072393003
INFO:root:current train perplexity3.86568546295166
INFO:root:current mean train loss 1545.222192215593
INFO:root:current train perplexity3.8705663681030273
INFO:root:current mean train loss 1539.097475625635
INFO:root:current train perplexity3.8625540733337402
INFO:root:current mean train loss 1539.3217949839686
INFO:root:current train perplexity3.8530826568603516
INFO:root:current mean train loss 1535.5271434014153
INFO:root:current train perplexity3.8561604022979736
INFO:root:current mean train loss 1539.23774937221
INFO:root:current train perplexity3.8607683181762695
INFO:root:current mean train loss 1541.4669357630492
INFO:root:current train perplexity3.8632428646087646
INFO:root:current mean train loss 1541.5170014818616
INFO:root:current train perplexity3.866584539413452
INFO:root:current mean train loss 1542.2168098612035
INFO:root:current train perplexity3.866509437561035
INFO:root:current mean train loss 1542.9311380204892
INFO:root:current train perplexity3.8680856227874756
INFO:root:current mean train loss 1542.7929039803792
INFO:root:current train perplexity3.8709399700164795
INFO:root:current mean train loss 1541.922208296691
INFO:root:current train perplexity3.870532989501953
INFO:root:current mean train loss 1541.937601202755
INFO:root:current train perplexity3.868159532546997
INFO:root:current mean train loss 1543.5161076583975
INFO:root:current train perplexity3.870319366455078
INFO:root:current mean train loss 1544.074830114594
INFO:root:current train perplexity3.8724184036254883
INFO:root:current mean train loss 1542.3975895613933
INFO:root:current train perplexity3.8730697631835938
INFO:root:current mean train loss 1542.790362259597
INFO:root:current train perplexity3.8753161430358887
INFO:root:current mean train loss 1543.6387819200584
INFO:root:current train perplexity3.8768603801727295
INFO:root:current mean train loss 1543.329668071908
INFO:root:current train perplexity3.8767683506011963
INFO:root:current mean train loss 1543.2109381900173
INFO:root:current train perplexity3.87634015083313

100%|██████████| 1/1 [05:36<00:00, 336.14s/it][A100%|██████████| 1/1 [05:36<00:00, 336.14s/it]
INFO:root:final mean train loss: 1543.0492756238082
INFO:root:final train perplexity: 3.8767194747924805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1829.2525245179522
INFO:root:eval perplexity: 5.215180397033691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2300.5426821877772
INFO:root:eval perplexity: 8.281478881835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/92
 46%|████▌     | 92/200 [9:24:55<11:03:27, 368.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1539.6595052083333
INFO:root:current train perplexity3.843412160873413
INFO:root:current mean train loss 1527.2553883183953
INFO:root:current train perplexity3.824122667312622
INFO:root:current mean train loss 1531.8561009164093
INFO:root:current train perplexity3.8380768299102783
INFO:root:current mean train loss 1530.7740821523114
INFO:root:current train perplexity3.8426201343536377
INFO:root:current mean train loss 1531.1049435576404
INFO:root:current train perplexity3.8440682888031006
INFO:root:current mean train loss 1534.9359959116202
INFO:root:current train perplexity3.8536806106567383
INFO:root:current mean train loss 1537.0319179805335
INFO:root:current train perplexity3.8614208698272705
INFO:root:current mean train loss 1537.0358350761283
INFO:root:current train perplexity3.8606886863708496
INFO:root:current mean train loss 1536.2659234569633
INFO:root:current train perplexity3.8605477809906006
INFO:root:current mean train loss 1538.372233199677
INFO:root:current train perplexity3.8621456623077393
INFO:root:current mean train loss 1538.6622102007143
INFO:root:current train perplexity3.858874797821045
INFO:root:current mean train loss 1539.8082007738608
INFO:root:current train perplexity3.8623929023742676
INFO:root:current mean train loss 1539.9740636830093
INFO:root:current train perplexity3.8636233806610107
INFO:root:current mean train loss 1540.343663485017
INFO:root:current train perplexity3.864790916442871
INFO:root:current mean train loss 1540.3138239163693
INFO:root:current train perplexity3.864823341369629
INFO:root:current mean train loss 1539.3387166106845
INFO:root:current train perplexity3.8648974895477295
INFO:root:current mean train loss 1540.10433561746
INFO:root:current train perplexity3.8663039207458496
INFO:root:current mean train loss 1541.4752677791982
INFO:root:current train perplexity3.868884325027466
INFO:root:current mean train loss 1541.5589194018803
INFO:root:current train perplexity3.8698766231536865
INFO:root:current mean train loss 1541.1075126037754
INFO:root:current train perplexity3.869155168533325

100%|██████████| 1/1 [05:36<00:00, 336.93s/it][A100%|██████████| 1/1 [05:36<00:00, 336.93s/it]
INFO:root:final mean train loss: 1540.9379886198212
INFO:root:final train perplexity: 3.8695387840270996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1831.9572922726895
INFO:root:eval perplexity: 5.227931499481201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2305.7966161416775
INFO:root:eval perplexity: 8.321557998657227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/93
 46%|████▋     | 93/200 [9:31:04<10:57:39, 368.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1523.1719055175781
INFO:root:current train perplexity3.8762333393096924
INFO:root:current mean train loss 1531.7289815266927
INFO:root:current train perplexity3.881697654724121
INFO:root:current mean train loss 1537.5421530587332
INFO:root:current train perplexity3.882821798324585
INFO:root:current mean train loss 1536.1991114566201
INFO:root:current train perplexity3.8761515617370605
INFO:root:current mean train loss 1539.4924392700195
INFO:root:current train perplexity3.8675153255462646
INFO:root:current mean train loss 1538.4141544736665
INFO:root:current train perplexity3.8672280311584473
INFO:root:current mean train loss 1541.1882895076976
INFO:root:current train perplexity3.8738815784454346
INFO:root:current mean train loss 1538.8109655135718
INFO:root:current train perplexity3.8674604892730713
INFO:root:current mean train loss 1535.063047651811
INFO:root:current train perplexity3.8617026805877686
INFO:root:current mean train loss 1536.1642877072704
INFO:root:current train perplexity3.8605597019195557
INFO:root:current mean train loss 1536.6104988380714
INFO:root:current train perplexity3.8638665676116943
INFO:root:current mean train loss 1535.9964173397775
INFO:root:current train perplexity3.8621437549591064
INFO:root:current mean train loss 1535.930686378479
INFO:root:current train perplexity3.8617324829101562
INFO:root:current mean train loss 1535.7405629033628
INFO:root:current train perplexity3.8612782955169678
INFO:root:current mean train loss 1536.9200717410527
INFO:root:current train perplexity3.8617634773254395
INFO:root:current mean train loss 1537.2306133801424
INFO:root:current train perplexity3.8613593578338623
INFO:root:current mean train loss 1536.9570963541667
INFO:root:current train perplexity3.8630495071411133
INFO:root:current mean train loss 1538.5264681355336
INFO:root:current train perplexity3.8637163639068604
INFO:root:current mean train loss 1538.325867543322
INFO:root:current train perplexity3.86377215385437
INFO:root:current mean train loss 1539.3689046223958
INFO:root:current train perplexity3.862450361251831

100%|██████████| 1/1 [05:36<00:00, 336.47s/it][A100%|██████████| 1/1 [05:36<00:00, 336.47s/it]
INFO:root:final mean train loss: 1538.889903904871
INFO:root:final train perplexity: 3.862586736679077
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1831.9475387681462
INFO:root:eval perplexity: 5.2278852462768555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2305.3100010215812
INFO:root:eval perplexity: 8.317838668823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/94
 47%|████▋     | 94/200 [9:37:13<10:51:29, 368.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1538.4966688647712
INFO:root:current train perplexity3.8495235443115234
INFO:root:current mean train loss 1532.4005312847003
INFO:root:current train perplexity3.8363993167877197
INFO:root:current mean train loss 1533.2390921750052
INFO:root:current train perplexity3.8415539264678955
INFO:root:current mean train loss 1536.230422012752
INFO:root:current train perplexity3.8455698490142822
INFO:root:current mean train loss 1533.1288669517103
INFO:root:current train perplexity3.842463970184326
INFO:root:current mean train loss 1531.6859689070352
INFO:root:current train perplexity3.8478879928588867
INFO:root:current mean train loss 1532.4735440181694
INFO:root:current train perplexity3.8491830825805664
INFO:root:current mean train loss 1534.375882367717
INFO:root:current train perplexity3.8547897338867188
INFO:root:current mean train loss 1534.9823021181717
INFO:root:current train perplexity3.855499029159546
INFO:root:current mean train loss 1534.5394143857354
INFO:root:current train perplexity3.85345458984375
INFO:root:current mean train loss 1536.3777111404684
INFO:root:current train perplexity3.8548178672790527
INFO:root:current mean train loss 1535.654192447264
INFO:root:current train perplexity3.8547251224517822
INFO:root:current mean train loss 1535.4337003850533
INFO:root:current train perplexity3.8539934158325195
INFO:root:current mean train loss 1535.2026049996923
INFO:root:current train perplexity3.853475332260132
INFO:root:current mean train loss 1535.9867222237444
INFO:root:current train perplexity3.8513219356536865
INFO:root:current mean train loss 1536.6968031795457
INFO:root:current train perplexity3.8528754711151123
INFO:root:current mean train loss 1536.1615182295502
INFO:root:current train perplexity3.852341651916504
INFO:root:current mean train loss 1536.3598707535564
INFO:root:current train perplexity3.8526549339294434
INFO:root:current mean train loss 1536.3285195889068
INFO:root:current train perplexity3.8524909019470215

100%|██████████| 1/1 [05:36<00:00, 336.49s/it][A100%|██████████| 1/1 [05:36<00:00, 336.49s/it]
INFO:root:final mean train loss: 1536.2089468859328
INFO:root:final train perplexity: 3.8535029888153076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1831.986807748781
INFO:root:eval perplexity: 5.2280707359313965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2306.057087350399
INFO:root:eval perplexity: 8.323548316955566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/95
 48%|████▊     | 95/200 [9:43:22<10:45:21, 368.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1511.870640345982
INFO:root:current train perplexity3.807316303253174
INFO:root:current mean train loss 1540.999397143983
INFO:root:current train perplexity3.8261618614196777
INFO:root:current mean train loss 1534.027723651066
INFO:root:current train perplexity3.8174469470977783
INFO:root:current mean train loss 1526.4965540406051
INFO:root:current train perplexity3.8181345462799072
INFO:root:current mean train loss 1529.6432268078202
INFO:root:current train perplexity3.8182127475738525
INFO:root:current mean train loss 1531.7691617141902
INFO:root:current train perplexity3.8244104385375977
INFO:root:current mean train loss 1532.9747242880956
INFO:root:current train perplexity3.8264105319976807
INFO:root:current mean train loss 1533.2046236951812
INFO:root:current train perplexity3.8307857513427734
INFO:root:current mean train loss 1536.0538974921299
INFO:root:current train perplexity3.8379464149475098
INFO:root:current mean train loss 1536.8140682162027
INFO:root:current train perplexity3.8419976234436035
INFO:root:current mean train loss 1535.2272178755238
INFO:root:current train perplexity3.8397393226623535
INFO:root:current mean train loss 1535.2424320789385
INFO:root:current train perplexity3.842482566833496
INFO:root:current mean train loss 1533.8971087033117
INFO:root:current train perplexity3.8410820960998535
INFO:root:current mean train loss 1534.2328857236075
INFO:root:current train perplexity3.8430278301239014
INFO:root:current mean train loss 1535.6496257431268
INFO:root:current train perplexity3.843240737915039
INFO:root:current mean train loss 1536.1191240963249
INFO:root:current train perplexity3.845003843307495
INFO:root:current mean train loss 1535.527675623935
INFO:root:current train perplexity3.84590220451355
INFO:root:current mean train loss 1535.3948181223564
INFO:root:current train perplexity3.8464365005493164
INFO:root:current mean train loss 1534.7789577833216
INFO:root:current train perplexity3.846557855606079
INFO:root:current mean train loss 1534.2182897808907
INFO:root:current train perplexity3.8457164764404297

100%|██████████| 1/1 [05:35<00:00, 335.92s/it][A100%|██████████| 1/1 [05:35<00:00, 335.92s/it]
INFO:root:final mean train loss: 1534.3279823384019
INFO:root:final train perplexity: 3.8471434116363525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1833.7039786264406
INFO:root:eval perplexity: 5.23618221282959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2308.775243880901
INFO:root:eval perplexity: 8.344366073608398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/96
 48%|████▊     | 96/200 [9:49:30<10:38:57, 368.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1517.7015814012098
INFO:root:current train perplexity3.777210235595703
INFO:root:current mean train loss 1533.8301098073712
INFO:root:current train perplexity3.7845590114593506
INFO:root:current mean train loss 1537.1658914409159
INFO:root:current train perplexity3.8053746223449707
INFO:root:current mean train loss 1547.1406899074773
INFO:root:current train perplexity3.8239102363586426
INFO:root:current mean train loss 1545.3615504572397
INFO:root:current train perplexity3.830782413482666
INFO:root:current mean train loss 1542.6575615087247
INFO:root:current train perplexity3.8259389400482178
INFO:root:current mean train loss 1540.0595366512728
INFO:root:current train perplexity3.8319132328033447
INFO:root:current mean train loss 1541.1832621061687
INFO:root:current train perplexity3.8327388763427734
INFO:root:current mean train loss 1539.3723482391322
INFO:root:current train perplexity3.834807872772217
INFO:root:current mean train loss 1538.200265591434
INFO:root:current train perplexity3.837982177734375
INFO:root:current mean train loss 1535.7876370834217
INFO:root:current train perplexity3.83390736579895
INFO:root:current mean train loss 1534.2342754873314
INFO:root:current train perplexity3.8351871967315674
INFO:root:current mean train loss 1534.626177963641
INFO:root:current train perplexity3.838016986846924
INFO:root:current mean train loss 1534.4344786909808
INFO:root:current train perplexity3.8402740955352783
INFO:root:current mean train loss 1534.243046428006
INFO:root:current train perplexity3.8417117595672607
INFO:root:current mean train loss 1534.568479770932
INFO:root:current train perplexity3.8393394947052
INFO:root:current mean train loss 1533.1469666687424
INFO:root:current train perplexity3.8376238346099854
INFO:root:current mean train loss 1533.1652688170223
INFO:root:current train perplexity3.837921380996704
INFO:root:current mean train loss 1532.4433842424094
INFO:root:current train perplexity3.837404727935791
INFO:root:current mean train loss 1532.7411435491244
INFO:root:current train perplexity3.8382396697998047

100%|██████████| 1/1 [05:36<00:00, 336.63s/it][A100%|██████████| 1/1 [05:36<00:00, 336.64s/it]
INFO:root:final mean train loss: 1531.7900443873018
INFO:root:final train perplexity: 3.8385791778564453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1834.42337750374
INFO:root:eval perplexity: 5.239584922790527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2310.728858027898
INFO:root:eval perplexity: 8.359359741210938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/97
 48%|████▊     | 97/200 [9:55:39<10:33:00, 368.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.135004679362
INFO:root:current train perplexity3.8532962799072266
INFO:root:current mean train loss 1545.2581721125423
INFO:root:current train perplexity3.8456075191497803
INFO:root:current mean train loss 1549.4876014955582
INFO:root:current train perplexity3.85224986076355
INFO:root:current mean train loss 1541.2748504287895
INFO:root:current train perplexity3.8356430530548096
INFO:root:current mean train loss 1536.923930304391
INFO:root:current train perplexity3.837008237838745
INFO:root:current mean train loss 1535.0126523205834
INFO:root:current train perplexity3.837920904159546
INFO:root:current mean train loss 1536.5973333664883
INFO:root:current train perplexity3.8420379161834717
INFO:root:current mean train loss 1533.6388885987633
INFO:root:current train perplexity3.83746337890625
INFO:root:current mean train loss 1532.5259989612507
INFO:root:current train perplexity3.834333658218384
INFO:root:current mean train loss 1533.0373759209356
INFO:root:current train perplexity3.8337833881378174
INFO:root:current mean train loss 1532.8373769512614
INFO:root:current train perplexity3.8323514461517334
INFO:root:current mean train loss 1530.7065887982837
INFO:root:current train perplexity3.8298933506011963
INFO:root:current mean train loss 1529.7860692342122
INFO:root:current train perplexity3.8288767337799072
INFO:root:current mean train loss 1530.0542056482693
INFO:root:current train perplexity3.8300044536590576
INFO:root:current mean train loss 1530.3088384807438
INFO:root:current train perplexity3.8318850994110107
INFO:root:current mean train loss 1530.9116807883408
INFO:root:current train perplexity3.8333921432495117
INFO:root:current mean train loss 1531.462590337957
INFO:root:current train perplexity3.8346903324127197
INFO:root:current mean train loss 1531.7644904723702
INFO:root:current train perplexity3.8346619606018066
INFO:root:current mean train loss 1531.243891199946
INFO:root:current train perplexity3.8331546783447266
INFO:root:current mean train loss 1530.7325146183587
INFO:root:current train perplexity3.8331615924835205

100%|██████████| 1/1 [05:36<00:00, 336.41s/it][A100%|██████████| 1/1 [05:36<00:00, 336.41s/it]
INFO:root:final mean train loss: 1529.8938907963786
INFO:root:final train perplexity: 3.832192897796631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1835.1634608059064
INFO:root:eval perplexity: 5.243086814880371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2312.2200001385195
INFO:root:eval perplexity: 8.370821952819824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/98
 49%|████▉     | 98/200 [10:01:48<10:26:50, 368.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.6459153395433
INFO:root:current train perplexity3.7884013652801514
INFO:root:current mean train loss 1521.0357288707387
INFO:root:current train perplexity3.797574281692505
INFO:root:current mean train loss 1515.991224296138
INFO:root:current train perplexity3.786653995513916
INFO:root:current mean train loss 1519.2506287457193
INFO:root:current train perplexity3.785515308380127
INFO:root:current mean train loss 1521.3021185105847
INFO:root:current train perplexity3.7930209636688232
INFO:root:current mean train loss 1523.0215550245437
INFO:root:current train perplexity3.8013393878936768
INFO:root:current mean train loss 1521.7426240160949
INFO:root:current train perplexity3.803571939468384
INFO:root:current mean train loss 1521.0726568882762
INFO:root:current train perplexity3.8049910068511963
INFO:root:current mean train loss 1521.4492634855942
INFO:root:current train perplexity3.809706211090088
INFO:root:current mean train loss 1521.6690578954824
INFO:root:current train perplexity3.8064663410186768
INFO:root:current mean train loss 1522.4871071972198
INFO:root:current train perplexity3.809457778930664
INFO:root:current mean train loss 1523.8249219378688
INFO:root:current train perplexity3.8103420734405518
INFO:root:current mean train loss 1525.1995739601346
INFO:root:current train perplexity3.814415454864502
INFO:root:current mean train loss 1527.3693895053514
INFO:root:current train perplexity3.8174824714660645
INFO:root:current mean train loss 1526.240373193526
INFO:root:current train perplexity3.8179266452789307
INFO:root:current mean train loss 1526.5016474422175
INFO:root:current train perplexity3.8189635276794434
INFO:root:current mean train loss 1526.5745840811514
INFO:root:current train perplexity3.8195316791534424
INFO:root:current mean train loss 1527.0543508902488
INFO:root:current train perplexity3.820971727371216
INFO:root:current mean train loss 1527.4342061306133
INFO:root:current train perplexity3.8227438926696777
INFO:root:current mean train loss 1527.9422458949587
INFO:root:current train perplexity3.823819160461426

100%|██████████| 1/1 [05:35<00:00, 335.91s/it][A100%|██████████| 1/1 [05:35<00:00, 335.91s/it]
INFO:root:final mean train loss: 1527.5165054698334
INFO:root:final train perplexity: 3.8242011070251465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1837.7870422796154
INFO:root:eval perplexity: 5.255521297454834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2318.024920524435
INFO:root:eval perplexity: 8.415594100952148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/99
 50%|████▉     | 99/200 [10:07:56<10:20:26, 368.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1515.2082102705792
INFO:root:current train perplexity3.823946714401245
INFO:root:current mean train loss 1509.6590495685955
INFO:root:current train perplexity3.8108103275299072
INFO:root:current mean train loss 1512.736121644365
INFO:root:current train perplexity3.8072571754455566
INFO:root:current mean train loss 1515.1045778284522
INFO:root:current train perplexity3.805758476257324
INFO:root:current mean train loss 1517.1932598446415
INFO:root:current train perplexity3.80137300491333
INFO:root:current mean train loss 1518.4137235556273
INFO:root:current train perplexity3.8064403533935547
INFO:root:current mean train loss 1520.034406108241
INFO:root:current train perplexity3.805086135864258
INFO:root:current mean train loss 1519.8578455307904
INFO:root:current train perplexity3.799333333969116
INFO:root:current mean train loss 1520.362611939307
INFO:root:current train perplexity3.800658941268921
INFO:root:current mean train loss 1521.1833263638064
INFO:root:current train perplexity3.8038218021392822
INFO:root:current mean train loss 1522.010390643051
INFO:root:current train perplexity3.8069100379943848
INFO:root:current mean train loss 1523.01500266861
INFO:root:current train perplexity3.808061122894287
INFO:root:current mean train loss 1523.566524035473
INFO:root:current train perplexity3.808617353439331
INFO:root:current mean train loss 1523.789415196641
INFO:root:current train perplexity3.8106908798217773
INFO:root:current mean train loss 1524.9451421616693
INFO:root:current train perplexity3.8137331008911133
INFO:root:current mean train loss 1525.440789262504
INFO:root:current train perplexity3.814707040786743
INFO:root:current mean train loss 1524.7987503977083
INFO:root:current train perplexity3.8138625621795654
INFO:root:current mean train loss 1524.6083785719609
INFO:root:current train perplexity3.8146369457244873
INFO:root:current mean train loss 1524.3973274514728
INFO:root:current train perplexity3.8142035007476807
INFO:root:current mean train loss 1525.1494964691994
INFO:root:current train perplexity3.8148560523986816

100%|██████████| 1/1 [05:37<00:00, 337.43s/it][A100%|██████████| 1/1 [05:37<00:00, 337.43s/it]
INFO:root:final mean train loss: 1524.7082439505327
INFO:root:final train perplexity: 3.8147828578948975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1837.6447537469526
INFO:root:eval perplexity: 5.254846096038818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2316.322652613863
INFO:root:eval perplexity: 8.402440071105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/100
 50%|█████     | 100/200 [10:14:06<10:14:50, 368.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.2018845683397
INFO:root:current train perplexity3.7953553199768066
INFO:root:current mean train loss 1520.737363575691
INFO:root:current train perplexity3.784914255142212
INFO:root:current mean train loss 1517.6790048860787
INFO:root:current train perplexity3.7902610301971436
INFO:root:current mean train loss 1517.771224325462
INFO:root:current train perplexity3.8053171634674072
INFO:root:current mean train loss 1516.487731566649
INFO:root:current train perplexity3.80045223236084
INFO:root:current mean train loss 1518.7401838350377
INFO:root:current train perplexity3.8011813163757324
INFO:root:current mean train loss 1518.0926386187857
INFO:root:current train perplexity3.807812452316284
INFO:root:current mean train loss 1519.371924103127
INFO:root:current train perplexity3.8039002418518066
INFO:root:current mean train loss 1520.2566003513018
INFO:root:current train perplexity3.806288957595825
INFO:root:current mean train loss 1519.437363022202
INFO:root:current train perplexity3.80482816696167
INFO:root:current mean train loss 1519.774524247896
INFO:root:current train perplexity3.8040406703948975
INFO:root:current mean train loss 1520.9711803089488
INFO:root:current train perplexity3.80592942237854
INFO:root:current mean train loss 1520.2299026594976
INFO:root:current train perplexity3.8078455924987793
INFO:root:current mean train loss 1519.7958088261985
INFO:root:current train perplexity3.804896116256714
INFO:root:current mean train loss 1519.4119631186416
INFO:root:current train perplexity3.804159641265869
INFO:root:current mean train loss 1519.9596703048048
INFO:root:current train perplexity3.8062870502471924
INFO:root:current mean train loss 1520.67811682366
INFO:root:current train perplexity3.80759596824646
INFO:root:current mean train loss 1521.7238887598144
INFO:root:current train perplexity3.807807445526123
INFO:root:current mean train loss 1522.5982843432193
INFO:root:current train perplexity3.8075780868530273

100%|██████████| 1/1 [05:35<00:00, 335.91s/it][A100%|██████████| 1/1 [05:35<00:00, 335.91s/it]
INFO:root:final mean train loss: 1522.4690497278625
INFO:root:final train perplexity: 3.807288646697998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1838.3990283722574
INFO:root:eval perplexity: 5.258426189422607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2318.2167358398438
INFO:root:eval perplexity: 8.41707706451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/101
 50%|█████     | 101/200 [10:20:14<10:08:19, 368.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1532.5911254882812
INFO:root:current train perplexity3.8318471908569336
INFO:root:current mean train loss 1518.0896017140356
INFO:root:current train perplexity3.7925493717193604
INFO:root:current mean train loss 1524.9140930175781
INFO:root:current train perplexity3.8006882667541504
INFO:root:current mean train loss 1523.0363951091524
INFO:root:current train perplexity3.802446126937866
INFO:root:current mean train loss 1525.5673071054312
INFO:root:current train perplexity3.8051137924194336
INFO:root:current mean train loss 1521.5203658702762
INFO:root:current train perplexity3.7980759143829346
INFO:root:current mean train loss 1521.4174905752207
INFO:root:current train perplexity3.796403646469116
INFO:root:current mean train loss 1521.5510369838948
INFO:root:current train perplexity3.801076650619507
INFO:root:current mean train loss 1520.1309440463197
INFO:root:current train perplexity3.7984063625335693
INFO:root:current mean train loss 1519.757249723876
INFO:root:current train perplexity3.7981669902801514
INFO:root:current mean train loss 1518.7377622108759
INFO:root:current train perplexity3.796297788619995
INFO:root:current mean train loss 1518.7208810895147
INFO:root:current train perplexity3.79692006111145
INFO:root:current mean train loss 1518.5652270066112
INFO:root:current train perplexity3.797908306121826
INFO:root:current mean train loss 1519.0018741874346
INFO:root:current train perplexity3.7990612983703613
INFO:root:current mean train loss 1518.8268264511885
INFO:root:current train perplexity3.7978670597076416
INFO:root:current mean train loss 1519.1734331679534
INFO:root:current train perplexity3.7985758781433105
INFO:root:current mean train loss 1519.4646348103438
INFO:root:current train perplexity3.798259735107422
INFO:root:current mean train loss 1519.2747553756465
INFO:root:current train perplexity3.7985382080078125
INFO:root:current mean train loss 1520.1266135329192
INFO:root:current train perplexity3.8002870082855225
INFO:root:current mean train loss 1521.2162876965358
INFO:root:current train perplexity3.8014206886291504

100%|██████████| 1/1 [05:36<00:00, 336.27s/it][A100%|██████████| 1/1 [05:36<00:00, 336.27s/it]
INFO:root:final mean train loss: 1520.7929943275162
INFO:root:final train perplexity: 3.801689386367798
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1839.8583378352173
INFO:root:eval perplexity: 5.265359401702881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.86s/it][A100%|██████████| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 2320.7060447314107
INFO:root:eval perplexity: 8.436351776123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/102
 51%|█████     | 102/200 [10:26:23<10:02:09, 368.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1521.230742483428
INFO:root:current train perplexity3.7692086696624756
INFO:root:current mean train loss 1513.211959953595
INFO:root:current train perplexity3.777034044265747
INFO:root:current mean train loss 1517.5285429729413
INFO:root:current train perplexity3.7818708419799805
INFO:root:current mean train loss 1521.5173299520222
INFO:root:current train perplexity3.7898380756378174
INFO:root:current mean train loss 1521.1924098765878
INFO:root:current train perplexity3.7922067642211914
INFO:root:current mean train loss 1518.9353851833666
INFO:root:current train perplexity3.790567398071289
INFO:root:current mean train loss 1520.1122917669456
INFO:root:current train perplexity3.789645195007324
INFO:root:current mean train loss 1518.7842746125725
INFO:root:current train perplexity3.783949613571167
INFO:root:current mean train loss 1519.9541516802033
INFO:root:current train perplexity3.786304473876953
INFO:root:current mean train loss 1518.8769833481963
INFO:root:current train perplexity3.787503957748413
INFO:root:current mean train loss 1517.7585108887192
INFO:root:current train perplexity3.7877280712127686
INFO:root:current mean train loss 1517.8695481006591
INFO:root:current train perplexity3.7875139713287354
INFO:root:current mean train loss 1518.7626396729902
INFO:root:current train perplexity3.7900772094726562
INFO:root:current mean train loss 1518.189799006148
INFO:root:current train perplexity3.7908055782318115
INFO:root:current mean train loss 1517.6859761229446
INFO:root:current train perplexity3.789975881576538
INFO:root:current mean train loss 1518.0848687278315
INFO:root:current train perplexity3.7902145385742188
INFO:root:current mean train loss 1518.475207168196
INFO:root:current train perplexity3.7906017303466797
INFO:root:current mean train loss 1518.9779184454792
INFO:root:current train perplexity3.792557954788208
INFO:root:current mean train loss 1518.9360582650327
INFO:root:current train perplexity3.7921841144561768
INFO:root:current mean train loss 1518.299198945939
INFO:root:current train perplexity3.7914984226226807

100%|██████████| 1/1 [05:36<00:00, 336.36s/it][A100%|██████████| 1/1 [05:36<00:00, 336.36s/it]
INFO:root:final mean train loss: 1517.9211366685183
INFO:root:final train perplexity: 3.792114019393921
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1840.6975855184785
INFO:root:eval perplexity: 5.269350528717041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2322.136283712184
INFO:root:eval perplexity: 8.447447776794434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/103
 52%|█████▏    | 103/200 [10:32:31<9:55:57, 368.64s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1505.3733056640624
INFO:root:current train perplexity3.711421489715576
INFO:root:current mean train loss 1512.4809301757812
INFO:root:current train perplexity3.76446533203125
INFO:root:current mean train loss 1511.7629633789063
INFO:root:current train perplexity3.7653746604919434
INFO:root:current mean train loss 1513.1464390345982
INFO:root:current train perplexity3.7742319107055664
INFO:root:current mean train loss 1512.3715787760416
INFO:root:current train perplexity3.7817182540893555
INFO:root:current mean train loss 1511.607254971591
INFO:root:current train perplexity3.783376455307007
INFO:root:current mean train loss 1510.8939083158052
INFO:root:current train perplexity3.785324811935425
INFO:root:current mean train loss 1509.8740528971355
INFO:root:current train perplexity3.780622959136963
INFO:root:current mean train loss 1509.275587086397
INFO:root:current train perplexity3.774761915206909
INFO:root:current mean train loss 1510.0333661852385
INFO:root:current train perplexity3.775381088256836
INFO:root:current mean train loss 1509.8029954892113
INFO:root:current train perplexity3.775050401687622
INFO:root:current mean train loss 1510.894219705333
INFO:root:current train perplexity3.778421640396118
INFO:root:current mean train loss 1511.9219829101562
INFO:root:current train perplexity3.7775235176086426
INFO:root:current mean train loss 1512.576092574508
INFO:root:current train perplexity3.7794547080993652
INFO:root:current mean train loss 1514.4704658876617
INFO:root:current train perplexity3.7815232276916504
INFO:root:current mean train loss 1515.0227253181704
INFO:root:current train perplexity3.783292531967163
INFO:root:current mean train loss 1515.5400633285985
INFO:root:current train perplexity3.783447742462158
INFO:root:current mean train loss 1516.2338226841518
INFO:root:current train perplexity3.7832441329956055
INFO:root:current mean train loss 1516.0914854967273
INFO:root:current train perplexity3.7843236923217773
INFO:root:current mean train loss 1516.6456586788863
INFO:root:current train perplexity3.785900592803955

100%|██████████| 1/1 [05:36<00:00, 336.33s/it][A100%|██████████| 1/1 [05:36<00:00, 336.34s/it]
INFO:root:final mean train loss: 1516.3521865790863
INFO:root:final train perplexity: 3.786893129348755
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 1841.7968269510473
INFO:root:eval perplexity: 5.274582386016846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2323.7190794166945
INFO:root:eval perplexity: 8.459744453430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/104
 52%|█████▏    | 104/200 [10:38:40<9:49:48, 368.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.7580293114506
INFO:root:current train perplexity3.7559707164764404
INFO:root:current mean train loss 1510.1121767695079
INFO:root:current train perplexity3.7690136432647705
INFO:root:current mean train loss 1507.2399678319582
INFO:root:current train perplexity3.776301622390747
INFO:root:current mean train loss 1510.713132769925
INFO:root:current train perplexity3.7756364345550537
INFO:root:current mean train loss 1508.4605495934823
INFO:root:current train perplexity3.769103527069092
INFO:root:current mean train loss 1512.1198476424713
INFO:root:current train perplexity3.774174690246582
INFO:root:current mean train loss 1510.0787556661123
INFO:root:current train perplexity3.770266056060791
INFO:root:current mean train loss 1512.9311894263874
INFO:root:current train perplexity3.7754220962524414
INFO:root:current mean train loss 1512.9960522151187
INFO:root:current train perplexity3.775564432144165
INFO:root:current mean train loss 1512.7599119326444
INFO:root:current train perplexity3.7736542224884033
INFO:root:current mean train loss 1514.3394386413058
INFO:root:current train perplexity3.776886463165283
INFO:root:current mean train loss 1514.1485800722674
INFO:root:current train perplexity3.776670455932617
INFO:root:current mean train loss 1514.1810783500641
INFO:root:current train perplexity3.778245449066162
INFO:root:current mean train loss 1514.7031840259522
INFO:root:current train perplexity3.7787117958068848
INFO:root:current mean train loss 1514.2598382680694
INFO:root:current train perplexity3.777834415435791
INFO:root:current mean train loss 1513.832617062859
INFO:root:current train perplexity3.778935194015503
INFO:root:current mean train loss 1513.916529462662
INFO:root:current train perplexity3.7783663272857666
INFO:root:current mean train loss 1514.8813846849357
INFO:root:current train perplexity3.778463125228882
INFO:root:current mean train loss 1514.9132190575622
INFO:root:current train perplexity3.7775299549102783
INFO:root:current mean train loss 1514.4150801456453
INFO:root:current train perplexity3.7790329456329346

100%|██████████| 1/1 [05:35<00:00, 335.31s/it][A100%|██████████| 1/1 [05:35<00:00, 335.31s/it]
INFO:root:final mean train loss: 1513.8286132504709
INFO:root:final train perplexity: 3.778510332107544
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1842.2703277371454
INFO:root:eval perplexity: 5.276838302612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2325.9174484361147
INFO:root:eval perplexity: 8.476849555969238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/105
 52%|█████▎    | 105/200 [10:44:47<9:43:10, 368.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.3717070079986
INFO:root:current train perplexity3.7401041984558105
INFO:root:current mean train loss 1496.6414244278617
INFO:root:current train perplexity3.7514188289642334
INFO:root:current mean train loss 1503.4787090462698
INFO:root:current train perplexity3.749769926071167
INFO:root:current mean train loss 1504.9552405675252
INFO:root:current train perplexity3.7604265213012695
INFO:root:current mean train loss 1506.5193605028894
INFO:root:current train perplexity3.760075092315674
INFO:root:current mean train loss 1506.9346905015918
INFO:root:current train perplexity3.763195753097534
INFO:root:current mean train loss 1509.5270516021908
INFO:root:current train perplexity3.76393723487854
INFO:root:current mean train loss 1508.0105260732223
INFO:root:current train perplexity3.7609119415283203
INFO:root:current mean train loss 1508.045352711397
INFO:root:current train perplexity3.762216567993164
INFO:root:current mean train loss 1509.4359215216907
INFO:root:current train perplexity3.764106512069702
INFO:root:current mean train loss 1509.8236808073036
INFO:root:current train perplexity3.764744997024536
INFO:root:current mean train loss 1509.410711546202
INFO:root:current train perplexity3.7649805545806885
INFO:root:current mean train loss 1508.5643076673846
INFO:root:current train perplexity3.764261245727539
INFO:root:current mean train loss 1508.77625984677
INFO:root:current train perplexity3.7651822566986084
INFO:root:current mean train loss 1510.5572265460485
INFO:root:current train perplexity3.7676525115966797
INFO:root:current mean train loss 1511.7296957150854
INFO:root:current train perplexity3.7696871757507324
INFO:root:current mean train loss 1512.069272872671
INFO:root:current train perplexity3.7705078125
INFO:root:current mean train loss 1512.3806204346797
INFO:root:current train perplexity3.7719900608062744
INFO:root:current mean train loss 1513.1518354476636
INFO:root:current train perplexity3.772376775741577

100%|██████████| 1/1 [05:36<00:00, 336.93s/it][A100%|██████████| 1/1 [05:36<00:00, 336.93s/it]
INFO:root:final mean train loss: 1512.2969197221796
INFO:root:final train perplexity: 3.773432493209839
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1840.6360348099513
INFO:root:eval perplexity: 5.269056797027588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2323.0510106729275
INFO:root:eval perplexity: 8.454550743103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/106
 53%|█████▎    | 106/200 [10:50:57<9:37:26, 368.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1614.7845458984375
INFO:root:current train perplexity3.9021918773651123
INFO:root:current mean train loss 1506.3809065110613
INFO:root:current train perplexity3.746037006378174
INFO:root:current mean train loss 1500.290471470771
INFO:root:current train perplexity3.7410078048706055
INFO:root:current mean train loss 1497.5888619153602
INFO:root:current train perplexity3.7453856468200684
INFO:root:current mean train loss 1499.0549085051043
INFO:root:current train perplexity3.740567207336426
INFO:root:current mean train loss 1500.9618660627964
INFO:root:current train perplexity3.741888999938965
INFO:root:current mean train loss 1500.327360689541
INFO:root:current train perplexity3.746372938156128
INFO:root:current mean train loss 1499.2872014936809
INFO:root:current train perplexity3.7477807998657227
INFO:root:current mean train loss 1500.354141673494
INFO:root:current train perplexity3.7496774196624756
INFO:root:current mean train loss 1501.462527801141
INFO:root:current train perplexity3.75113582611084
INFO:root:current mean train loss 1501.4721678468015
INFO:root:current train perplexity3.752389430999756
INFO:root:current mean train loss 1503.6038626550437
INFO:root:current train perplexity3.755206346511841
INFO:root:current mean train loss 1504.3617396676273
INFO:root:current train perplexity3.7577619552612305
INFO:root:current mean train loss 1504.7853625779148
INFO:root:current train perplexity3.7593839168548584
INFO:root:current mean train loss 1505.7168921090126
INFO:root:current train perplexity3.7600064277648926
INFO:root:current mean train loss 1506.7519946012553
INFO:root:current train perplexity3.7613096237182617
INFO:root:current mean train loss 1508.206050798939
INFO:root:current train perplexity3.762908458709717
INFO:root:current mean train loss 1508.090003926918
INFO:root:current train perplexity3.7626054286956787
INFO:root:current mean train loss 1509.1513917913442
INFO:root:current train perplexity3.76391339302063
INFO:root:current mean train loss 1510.1974174262723
INFO:root:current train perplexity3.765448808670044

100%|██████████| 1/1 [05:36<00:00, 336.11s/it][A100%|██████████| 1/1 [05:36<00:00, 336.11s/it]
INFO:root:final mean train loss: 1510.4702356812693
INFO:root:final train perplexity: 3.7673840522766113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.58s/it][A100%|██████████| 1/1 [00:15<00:00, 15.58s/it]
INFO:root:eval mean loss: 1842.1642997146498
INFO:root:eval perplexity: 5.276333332061768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.68s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 2326.608458174036
INFO:root:eval perplexity: 8.482233047485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/107
 54%|█████▎    | 107/200 [10:57:05<9:31:04, 368.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1467.1339586046006
INFO:root:current train perplexity3.6899096965789795
INFO:root:current mean train loss 1506.63146662308
INFO:root:current train perplexity3.7386488914489746
INFO:root:current mean train loss 1506.8244158543578
INFO:root:current train perplexity3.742039442062378
INFO:root:current mean train loss 1506.712360885908
INFO:root:current train perplexity3.742668867111206
INFO:root:current mean train loss 1506.0584912459817
INFO:root:current train perplexity3.746870517730713
INFO:root:current mean train loss 1504.722358850899
INFO:root:current train perplexity3.751901865005493
INFO:root:current mean train loss 1504.5896171890802
INFO:root:current train perplexity3.7493503093719482
INFO:root:current mean train loss 1502.5570119363683
INFO:root:current train perplexity3.7465925216674805
INFO:root:current mean train loss 1503.0575318278193
INFO:root:current train perplexity3.743640184402466
INFO:root:current mean train loss 1503.633039752902
INFO:root:current train perplexity3.7470951080322266
INFO:root:current mean train loss 1503.6879838445097
INFO:root:current train perplexity3.7501964569091797
INFO:root:current mean train loss 1504.4399714324898
INFO:root:current train perplexity3.752382755279541
INFO:root:current mean train loss 1505.1372631555316
INFO:root:current train perplexity3.753425121307373
INFO:root:current mean train loss 1504.7994088388539
INFO:root:current train perplexity3.751922130584717
INFO:root:current mean train loss 1506.6201853678156
INFO:root:current train perplexity3.7549216747283936
INFO:root:current mean train loss 1507.1236989620645
INFO:root:current train perplexity3.755438804626465
INFO:root:current mean train loss 1507.3818648330066
INFO:root:current train perplexity3.7553393840789795
INFO:root:current mean train loss 1508.337084094082
INFO:root:current train perplexity3.757768392562866
INFO:root:current mean train loss 1508.0572817962948
INFO:root:current train perplexity3.7566959857940674
INFO:root:current mean train loss 1508.2294149229747
INFO:root:current train perplexity3.758450508117676

100%|██████████| 1/1 [05:36<00:00, 336.02s/it][A100%|██████████| 1/1 [05:36<00:00, 336.02s/it]
INFO:root:final mean train loss: 1507.7884102579444
INFO:root:final train perplexity: 3.7585227489471436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1844.8034680954954
INFO:root:eval perplexity: 5.2889204025268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.77s/it][A100%|██████████| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 2330.001518087184
INFO:root:eval perplexity: 8.508722305297852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/108
 54%|█████▍    | 108/200 [11:03:13<9:24:54, 368.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1495.9419956752233
INFO:root:current train perplexity3.7606022357940674
INFO:root:current mean train loss 1507.306093569155
INFO:root:current train perplexity3.746800422668457
INFO:root:current mean train loss 1503.6708132480053
INFO:root:current train perplexity3.73732328414917
INFO:root:current mean train loss 1504.5613018889926
INFO:root:current train perplexity3.7448511123657227
INFO:root:current mean train loss 1508.665022505837
INFO:root:current train perplexity3.751890182495117
INFO:root:current mean train loss 1507.4459242205753
INFO:root:current train perplexity3.748748302459717
INFO:root:current mean train loss 1508.161666653851
INFO:root:current train perplexity3.749380111694336
INFO:root:current mean train loss 1508.1566843045812
INFO:root:current train perplexity3.7485673427581787
INFO:root:current mean train loss 1507.5204852989334
INFO:root:current train perplexity3.7451841831207275
INFO:root:current mean train loss 1505.827144390249
INFO:root:current train perplexity3.7432291507720947
INFO:root:current mean train loss 1505.2836120310612
INFO:root:current train perplexity3.74198317527771
INFO:root:current mean train loss 1504.5047460077092
INFO:root:current train perplexity3.7436084747314453
INFO:root:current mean train loss 1505.027569407104
INFO:root:current train perplexity3.745295763015747
INFO:root:current mean train loss 1504.6889401553722
INFO:root:current train perplexity3.7463228702545166
INFO:root:current mean train loss 1503.867388256751
INFO:root:current train perplexity3.7449610233306885
INFO:root:current mean train loss 1504.85206056278
INFO:root:current train perplexity3.7467212677001953
INFO:root:current mean train loss 1505.3642701315223
INFO:root:current train perplexity3.7475180625915527
INFO:root:current mean train loss 1505.5756601646929
INFO:root:current train perplexity3.748138666152954
INFO:root:current mean train loss 1505.7317475945163
INFO:root:current train perplexity3.749887466430664
INFO:root:current mean train loss 1506.34617828448
INFO:root:current train perplexity3.7525246143341064

100%|██████████| 1/1 [05:36<00:00, 336.90s/it][A100%|██████████| 1/1 [05:36<00:00, 336.90s/it]
INFO:root:final mean train loss: 1506.1825165395117
INFO:root:final train perplexity: 3.753225564956665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1844.6868199558123
INFO:root:eval perplexity: 5.288362979888916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2331.4887998323916
INFO:root:eval perplexity: 8.520360946655273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/109
 55%|█████▍    | 109/200 [11:09:22<9:19:03, 368.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1499.2440255972056
INFO:root:current train perplexity3.6970632076263428
INFO:root:current mean train loss 1494.4682167454769
INFO:root:current train perplexity3.7113888263702393
INFO:root:current mean train loss 1496.7031574552022
INFO:root:current train perplexity3.727360248565674
INFO:root:current mean train loss 1500.3232692371714
INFO:root:current train perplexity3.727234125137329
INFO:root:current mean train loss 1497.592366716503
INFO:root:current train perplexity3.7242348194122314
INFO:root:current mean train loss 1499.9484927412393
INFO:root:current train perplexity3.7305586338043213
INFO:root:current mean train loss 1501.0174676626007
INFO:root:current train perplexity3.7273900508880615
INFO:root:current mean train loss 1501.2512106388174
INFO:root:current train perplexity3.728407859802246
INFO:root:current mean train loss 1500.8215284750495
INFO:root:current train perplexity3.7291109561920166
INFO:root:current mean train loss 1500.5386796197972
INFO:root:current train perplexity3.7305221557617188
INFO:root:current mean train loss 1500.9182950444094
INFO:root:current train perplexity3.735097646713257
INFO:root:current mean train loss 1502.51930809021
INFO:root:current train perplexity3.737485408782959
INFO:root:current mean train loss 1501.6091426569053
INFO:root:current train perplexity3.7380480766296387
INFO:root:current mean train loss 1503.2844700559356
INFO:root:current train perplexity3.7423970699310303
INFO:root:current mean train loss 1503.5948514071379
INFO:root:current train perplexity3.743159532546997
INFO:root:current mean train loss 1503.4702333273347
INFO:root:current train perplexity3.7429614067077637
INFO:root:current mean train loss 1504.564215339125
INFO:root:current train perplexity3.743770122528076
INFO:root:current mean train loss 1504.1913781013664
INFO:root:current train perplexity3.745695114135742
INFO:root:current mean train loss 1504.340705294846
INFO:root:current train perplexity3.7452547550201416
INFO:root:current mean train loss 1504.7290593131643
INFO:root:current train perplexity3.7463600635528564

100%|██████████| 1/1 [05:36<00:00, 336.91s/it][A100%|██████████| 1/1 [05:36<00:00, 336.91s/it]
INFO:root:final mean train loss: 1504.4956569315746
INFO:root:final train perplexity: 3.7476704120635986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1845.4843918820645
INFO:root:eval perplexity: 5.292173385620117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2332.48932057915
INFO:root:eval perplexity: 8.528197288513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/110
 55%|█████▌    | 110/200 [11:15:31<9:13:11, 368.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1475.835746433424
INFO:root:current train perplexity3.665454387664795
INFO:root:current mean train loss 1491.6093728330713
INFO:root:current train perplexity3.7119626998901367
INFO:root:current mean train loss 1496.762340446387
INFO:root:current train perplexity3.7247955799102783
INFO:root:current mean train loss 1493.7760085852813
INFO:root:current train perplexity3.716338872909546
INFO:root:current mean train loss 1497.4754063457822
INFO:root:current train perplexity3.722245931625366
INFO:root:current mean train loss 1497.4062727406908
INFO:root:current train perplexity3.7255234718322754
INFO:root:current mean train loss 1496.764896774862
INFO:root:current train perplexity3.72969913482666
INFO:root:current mean train loss 1496.8132906790984
INFO:root:current train perplexity3.731204032897949
INFO:root:current mean train loss 1496.8617954758972
INFO:root:current train perplexity3.7291197776794434
INFO:root:current mean train loss 1497.965897535515
INFO:root:current train perplexity3.730656862258911
INFO:root:current mean train loss 1499.8618552312325
INFO:root:current train perplexity3.7307424545288086
INFO:root:current mean train loss 1499.6237370056206
INFO:root:current train perplexity3.7324297428131104
INFO:root:current mean train loss 1501.1016635999988
INFO:root:current train perplexity3.734482765197754
INFO:root:current mean train loss 1501.6503735940069
INFO:root:current train perplexity3.735610008239746
INFO:root:current mean train loss 1500.8213691685457
INFO:root:current train perplexity3.73563814163208
INFO:root:current mean train loss 1501.396492232936
INFO:root:current train perplexity3.7370455265045166
INFO:root:current mean train loss 1500.6342466250373
INFO:root:current train perplexity3.7361154556274414
INFO:root:current mean train loss 1501.8895533482457
INFO:root:current train perplexity3.7392282485961914
INFO:root:current mean train loss 1502.2192821716994
INFO:root:current train perplexity3.739518880844116
INFO:root:current mean train loss 1502.2547019078927
INFO:root:current train perplexity3.739194393157959

100%|██████████| 1/1 [05:36<00:00, 336.66s/it][A100%|██████████| 1/1 [05:36<00:00, 336.66s/it]
INFO:root:final mean train loss: 1502.1611515878128
INFO:root:final train perplexity: 3.7399954795837402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1847.1894981438386
INFO:root:eval perplexity: 5.300326347351074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.81s/it][A100%|██████████| 1/1 [00:15<00:00, 15.81s/it]
INFO:root:eval mean loss: 2334.447861258865
INFO:root:eval perplexity: 8.543558120727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/111
 56%|█████▌    | 111/200 [11:21:40<9:07:08, 368.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1491.5206611101019
INFO:root:current train perplexity3.7052125930786133
INFO:root:current mean train loss 1489.5854124663979
INFO:root:current train perplexity3.7236173152923584
INFO:root:current mean train loss 1489.503548575448
INFO:root:current train perplexity3.7199034690856934
INFO:root:current mean train loss 1492.7908432718386
INFO:root:current train perplexity3.7212343215942383
INFO:root:current mean train loss 1490.9428223660943
INFO:root:current train perplexity3.7082059383392334
INFO:root:current mean train loss 1492.6873906366654
INFO:root:current train perplexity3.716221570968628
INFO:root:current mean train loss 1493.6007873713102
INFO:root:current train perplexity3.720057725906372
INFO:root:current mean train loss 1497.5002472467397
INFO:root:current train perplexity3.7293100357055664
INFO:root:current mean train loss 1497.8294236848371
INFO:root:current train perplexity3.7302799224853516
INFO:root:current mean train loss 1497.0371644675852
INFO:root:current train perplexity3.7277660369873047
INFO:root:current mean train loss 1497.3943168963297
INFO:root:current train perplexity3.727206230163574
INFO:root:current mean train loss 1498.5627832525295
INFO:root:current train perplexity3.7309157848358154
INFO:root:current mean train loss 1499.1808567551395
INFO:root:current train perplexity3.7324955463409424
INFO:root:current mean train loss 1499.1049116830977
INFO:root:current train perplexity3.731070041656494
INFO:root:current mean train loss 1498.5317504389932
INFO:root:current train perplexity3.7311973571777344
INFO:root:current mean train loss 1499.0527112078096
INFO:root:current train perplexity3.7313241958618164
INFO:root:current mean train loss 1498.7513946859015
INFO:root:current train perplexity3.729471445083618
INFO:root:current mean train loss 1499.6939570821012
INFO:root:current train perplexity3.728923797607422
INFO:root:current mean train loss 1499.4098507505964
INFO:root:current train perplexity3.730281114578247

100%|██████████| 1/1 [05:36<00:00, 336.11s/it][A100%|██████████| 1/1 [05:36<00:00, 336.11s/it]
INFO:root:final mean train loss: 1499.8349002101359
INFO:root:final train perplexity: 3.732363700866699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 1847.537311094027
INFO:root:eval perplexity: 5.3019914627075195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2337.568990504488
INFO:root:eval perplexity: 8.568098068237305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/112
 56%|█████▌    | 112/200 [11:27:49<9:00:51, 368.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1494.0288899739583
INFO:root:current train perplexity3.678678274154663
INFO:root:current mean train loss 1494.3410988224364
INFO:root:current train perplexity3.724008321762085
INFO:root:current mean train loss 1498.4964846155326
INFO:root:current train perplexity3.7187678813934326
INFO:root:current mean train loss 1494.8944752507477
INFO:root:current train perplexity3.712783098220825
INFO:root:current mean train loss 1494.5074368990386
INFO:root:current train perplexity3.7095212936401367
INFO:root:current mean train loss 1496.6959944434952
INFO:root:current train perplexity3.7098488807678223
INFO:root:current mean train loss 1497.6252277431204
INFO:root:current train perplexity3.709853410720825
INFO:root:current mean train loss 1499.1728849017604
INFO:root:current train perplexity3.7128264904022217
INFO:root:current mean train loss 1499.1210070998404
INFO:root:current train perplexity3.717097520828247
INFO:root:current mean train loss 1497.6516064615344
INFO:root:current train perplexity3.718935012817383
INFO:root:current mean train loss 1496.9162372501635
INFO:root:current train perplexity3.7179646492004395
INFO:root:current mean train loss 1496.7977097927173
INFO:root:current train perplexity3.7190773487091064
INFO:root:current mean train loss 1497.4985945171252
INFO:root:current train perplexity3.721565008163452
INFO:root:current mean train loss 1496.984516369226
INFO:root:current train perplexity3.721106767654419
INFO:root:current mean train loss 1497.240239682405
INFO:root:current train perplexity3.7214460372924805
INFO:root:current mean train loss 1497.9742782501403
INFO:root:current train perplexity3.7233340740203857
INFO:root:current mean train loss 1497.3369572402087
INFO:root:current train perplexity3.7221527099609375
INFO:root:current mean train loss 1498.2926400274791
INFO:root:current train perplexity3.7244062423706055
INFO:root:current mean train loss 1498.3234071821487
INFO:root:current train perplexity3.726590871810913
INFO:root:current mean train loss 1498.682278367011
INFO:root:current train perplexity3.726919651031494

100%|██████████| 1/1 [05:36<00:00, 336.63s/it][A100%|██████████| 1/1 [05:36<00:00, 336.63s/it]
INFO:root:final mean train loss: 1498.4232732067792
INFO:root:final train perplexity: 3.7277398109436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1847.699362463985
INFO:root:eval perplexity: 5.302767753601074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2336.827693858045
INFO:root:eval perplexity: 8.562263488769531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/113
 56%|█████▋    | 113/200 [11:33:58<8:54:47, 368.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1488.956231689453
INFO:root:current train perplexity3.6659727096557617
INFO:root:current mean train loss 1465.9368448893229
INFO:root:current train perplexity3.661816358566284
INFO:root:current mean train loss 1475.9002435857599
INFO:root:current train perplexity3.683551549911499
INFO:root:current mean train loss 1479.9933040618896
INFO:root:current train perplexity3.6943509578704834
INFO:root:current mean train loss 1484.7014654250372
INFO:root:current train perplexity3.706522226333618
INFO:root:current mean train loss 1488.6743368295522
INFO:root:current train perplexity3.7067999839782715
INFO:root:current mean train loss 1490.1265938051286
INFO:root:current train perplexity3.710038661956787
INFO:root:current mean train loss 1491.2418585883247
INFO:root:current train perplexity3.7114901542663574
INFO:root:current mean train loss 1490.956983166206
INFO:root:current train perplexity3.7113215923309326
INFO:root:current mean train loss 1492.508808699898
INFO:root:current train perplexity3.712552070617676
INFO:root:current mean train loss 1491.7025348738127
INFO:root:current train perplexity3.7109525203704834
INFO:root:current mean train loss 1492.649695478167
INFO:root:current train perplexity3.7119240760803223
INFO:root:current mean train loss 1493.0601627537462
INFO:root:current train perplexity3.7131824493408203
INFO:root:current mean train loss 1494.254862467448
INFO:root:current train perplexity3.7157931327819824
INFO:root:current mean train loss 1494.3187484526297
INFO:root:current train perplexity3.71586012840271
INFO:root:current mean train loss 1494.604282419305
INFO:root:current train perplexity3.7176926136016846
INFO:root:current mean train loss 1495.4569856620128
INFO:root:current train perplexity3.720076322555542
INFO:root:current mean train loss 1495.7727639131767
INFO:root:current train perplexity3.7221171855926514
INFO:root:current mean train loss 1496.3162131508627
INFO:root:current train perplexity3.721684694290161
INFO:root:current mean train loss 1496.6112869262695
INFO:root:current train perplexity3.720935344696045

100%|██████████| 1/1 [05:36<00:00, 336.13s/it][A100%|██████████| 1/1 [05:36<00:00, 336.13s/it]
INFO:root:final mean train loss: 1496.5956405816628
INFO:root:final train perplexity: 3.7217624187469482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1849.3176459995568
INFO:root:eval perplexity: 5.310520172119141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.83s/it][A100%|██████████| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 2340.0575886178526
INFO:root:eval perplexity: 8.587715148925781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/114
 57%|█████▋    | 114/200 [11:40:06<8:48:30, 368.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1500.6079959353885
INFO:root:current train perplexity3.730496406555176
INFO:root:current mean train loss 1497.2732209811245
INFO:root:current train perplexity3.7083168029785156
INFO:root:current mean train loss 1493.9399171982134
INFO:root:current train perplexity3.7104132175445557
INFO:root:current mean train loss 1494.0000054333966
INFO:root:current train perplexity3.7081127166748047
INFO:root:current mean train loss 1495.5142973107659
INFO:root:current train perplexity3.711636543273926
INFO:root:current mean train loss 1496.4246867089298
INFO:root:current train perplexity3.720848560333252
INFO:root:current mean train loss 1494.5821090530562
INFO:root:current train perplexity3.7212064266204834
INFO:root:current mean train loss 1492.5724246311058
INFO:root:current train perplexity3.7148687839508057
INFO:root:current mean train loss 1494.2938487646543
INFO:root:current train perplexity3.7159805297851562
INFO:root:current mean train loss 1494.3987770039855
INFO:root:current train perplexity3.715740442276001
INFO:root:current mean train loss 1494.4862744470227
INFO:root:current train perplexity3.7162375450134277
INFO:root:current mean train loss 1494.8669407826928
INFO:root:current train perplexity3.71720290184021
INFO:root:current mean train loss 1495.328055034073
INFO:root:current train perplexity3.7170820236206055
INFO:root:current mean train loss 1495.4970941422318
INFO:root:current train perplexity3.7169268131256104
INFO:root:current mean train loss 1495.8996741733538
INFO:root:current train perplexity3.7174124717712402
INFO:root:current mean train loss 1495.9875074497043
INFO:root:current train perplexity3.720276355743408
INFO:root:current mean train loss 1495.6718595641082
INFO:root:current train perplexity3.7186455726623535
INFO:root:current mean train loss 1496.155212156376
INFO:root:current train perplexity3.7191925048828125
INFO:root:current mean train loss 1495.4122481909405
INFO:root:current train perplexity3.7166852951049805
INFO:root:current mean train loss 1494.9345672245056
INFO:root:current train perplexity3.7150588035583496

100%|██████████| 1/1 [05:36<00:00, 336.02s/it][A100%|██████████| 1/1 [05:36<00:00, 336.03s/it]
INFO:root:final mean train loss: 1494.8131208780494
INFO:root:final train perplexity: 3.7159411907196045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.56s/it][A100%|██████████| 1/1 [00:15<00:00, 15.56s/it]
INFO:root:eval mean loss: 1850.2936254190215
INFO:root:eval perplexity: 5.315201282501221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 2342.326320350593
INFO:root:eval perplexity: 8.60563850402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/115
 57%|█████▊    | 115/200 [11:46:14<8:42:04, 368.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1478.2913953993057
INFO:root:current train perplexity3.7008614540100098
INFO:root:current mean train loss 1485.718827681108
INFO:root:current train perplexity3.693305253982544
INFO:root:current mean train loss 1484.5497181809794
INFO:root:current train perplexity3.694246530532837
INFO:root:current mean train loss 1489.9164911474886
INFO:root:current train perplexity3.7022316455841064
INFO:root:current mean train loss 1491.7653945721192
INFO:root:current train perplexity3.7001335620880127
INFO:root:current mean train loss 1490.5531827740722
INFO:root:current train perplexity3.694666862487793
INFO:root:current mean train loss 1489.1392206314506
INFO:root:current train perplexity3.693357229232788
INFO:root:current mean train loss 1490.3215314222584
INFO:root:current train perplexity3.6932590007781982
INFO:root:current mean train loss 1490.821432287855
INFO:root:current train perplexity3.69781494140625
INFO:root:current mean train loss 1489.8843141951652
INFO:root:current train perplexity3.698856830596924
INFO:root:current mean train loss 1491.1531915248459
INFO:root:current train perplexity3.7036640644073486
INFO:root:current mean train loss 1491.3209262365278
INFO:root:current train perplexity3.7048051357269287
INFO:root:current mean train loss 1493.00773949144
INFO:root:current train perplexity3.7054688930511475
INFO:root:current mean train loss 1492.4662932673446
INFO:root:current train perplexity3.705000162124634
INFO:root:current mean train loss 1491.366171058959
INFO:root:current train perplexity3.7040913105010986
INFO:root:current mean train loss 1491.6820491756405
INFO:root:current train perplexity3.7041285037994385
INFO:root:current mean train loss 1492.1976930187
INFO:root:current train perplexity3.7041854858398438
INFO:root:current mean train loss 1491.8793642572557
INFO:root:current train perplexity3.704789161682129
INFO:root:current mean train loss 1493.1732011813563
INFO:root:current train perplexity3.7073092460632324
INFO:root:current mean train loss 1493.5120995793884
INFO:root:current train perplexity3.708414077758789

100%|██████████| 1/1 [05:36<00:00, 336.21s/it][A100%|██████████| 1/1 [05:36<00:00, 336.21s/it]
INFO:root:final mean train loss: 1492.3381042634364
INFO:root:final train perplexity: 3.707873582839966
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1852.8731615864638
INFO:root:eval perplexity: 5.327595233917236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.79s/it][A100%|██████████| 1/1 [00:15<00:00, 15.79s/it]
INFO:root:eval mean loss: 2345.8399891954787
INFO:root:eval perplexity: 8.633468627929688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/116
 58%|█████▊    | 116/200 [11:52:23<8:35:57, 368.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1478.5716741857395
INFO:root:current train perplexity3.7003281116485596
INFO:root:current mean train loss 1490.5469620911
INFO:root:current train perplexity3.6982245445251465
INFO:root:current mean train loss 1492.4520988886648
INFO:root:current train perplexity3.7058417797088623
INFO:root:current mean train loss 1490.9800314684762
INFO:root:current train perplexity3.7003400325775146
INFO:root:current mean train loss 1494.6586245397093
INFO:root:current train perplexity3.705953598022461
INFO:root:current mean train loss 1492.860587365573
INFO:root:current train perplexity3.704427480697632
INFO:root:current mean train loss 1491.8686583472079
INFO:root:current train perplexity3.704209327697754
INFO:root:current mean train loss 1492.5089708221872
INFO:root:current train perplexity3.7005393505096436
INFO:root:current mean train loss 1491.1544716415667
INFO:root:current train perplexity3.70090913772583
INFO:root:current mean train loss 1491.1303282245672
INFO:root:current train perplexity3.7022290229797363
INFO:root:current mean train loss 1491.5966902874432
INFO:root:current train perplexity3.701712131500244
INFO:root:current mean train loss 1490.9571040126627
INFO:root:current train perplexity3.699436664581299
INFO:root:current mean train loss 1491.3545645076772
INFO:root:current train perplexity3.700598955154419
INFO:root:current mean train loss 1490.693266152814
INFO:root:current train perplexity3.700995922088623
INFO:root:current mean train loss 1489.8765018548713
INFO:root:current train perplexity3.699789524078369
INFO:root:current mean train loss 1491.3300863614438
INFO:root:current train perplexity3.7024614810943604
INFO:root:current mean train loss 1491.2821130393008
INFO:root:current train perplexity3.7029731273651123
INFO:root:current mean train loss 1491.9125443064918
INFO:root:current train perplexity3.703766345977783
INFO:root:current mean train loss 1492.0497010158128
INFO:root:current train perplexity3.7043352127075195
INFO:root:current mean train loss 1491.3346405571212
INFO:root:current train perplexity3.7039501667022705

100%|██████████| 1/1 [05:36<00:00, 336.40s/it][A100%|██████████| 1/1 [05:36<00:00, 336.40s/it]
INFO:root:final mean train loss: 1491.1735354763537
INFO:root:final train perplexity: 3.7040843963623047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.86s/it][A100%|██████████| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 1852.3441343916224
INFO:root:eval perplexity: 5.3250508308410645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2343.394663276402
INFO:root:eval perplexity: 8.61408805847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/117
 58%|█████▊    | 117/200 [11:58:32<8:29:58, 368.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1477.9694033536043
INFO:root:current train perplexity3.69435977935791
INFO:root:current mean train loss 1479.1275933448305
INFO:root:current train perplexity3.6891138553619385
INFO:root:current mean train loss 1484.7732823689778
INFO:root:current train perplexity3.683525562286377
INFO:root:current mean train loss 1484.6965992721086
INFO:root:current train perplexity3.6975343227386475
INFO:root:current mean train loss 1484.717414230597
INFO:root:current train perplexity3.693662166595459
INFO:root:current mean train loss 1485.100663165657
INFO:root:current train perplexity3.6925721168518066
INFO:root:current mean train loss 1487.068551884141
INFO:root:current train perplexity3.692744255065918
INFO:root:current mean train loss 1485.1088402452808
INFO:root:current train perplexity3.6879701614379883
INFO:root:current mean train loss 1486.6222935582066
INFO:root:current train perplexity3.689243793487549
INFO:root:current mean train loss 1486.8592130220854
INFO:root:current train perplexity3.689072608947754
INFO:root:current mean train loss 1486.038423538208
INFO:root:current train perplexity3.6894912719726562
INFO:root:current mean train loss 1487.0477097636522
INFO:root:current train perplexity3.6883726119995117
INFO:root:current mean train loss 1487.2898337796607
INFO:root:current train perplexity3.688276767730713
INFO:root:current mean train loss 1488.1740734089349
INFO:root:current train perplexity3.691903591156006
INFO:root:current mean train loss 1489.0896239742156
INFO:root:current train perplexity3.6901981830596924
INFO:root:current mean train loss 1488.9022873270721
INFO:root:current train perplexity3.691950798034668
INFO:root:current mean train loss 1490.0261476344972
INFO:root:current train perplexity3.6939797401428223
INFO:root:current mean train loss 1489.5792861699524
INFO:root:current train perplexity3.6946020126342773
INFO:root:current mean train loss 1489.1360699928414
INFO:root:current train perplexity3.6961252689361572

100%|██████████| 1/1 [05:36<00:00, 336.69s/it][A100%|██████████| 1/1 [05:36<00:00, 336.71s/it]
INFO:root:final mean train loss: 1488.826667173908
INFO:root:final train perplexity: 3.696458101272583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.70s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1854.8267791964483
INFO:root:eval perplexity: 5.337000370025635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.80s/it][A100%|██████████| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 2349.6013205237423
INFO:root:eval perplexity: 8.663360595703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/118
 59%|█████▉    | 118/200 [12:04:41<8:24:00, 368.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1474.86943359375
INFO:root:current train perplexity3.809997797012329
INFO:root:current mean train loss 1478.8048502604167
INFO:root:current train perplexity3.6667401790618896
INFO:root:current mean train loss 1481.9537972799162
INFO:root:current train perplexity3.6801490783691406
INFO:root:current mean train loss 1486.545550637167
INFO:root:current train perplexity3.675539255142212
INFO:root:current mean train loss 1485.0230929904515
INFO:root:current train perplexity3.6738688945770264
INFO:root:current mean train loss 1484.1891301825494
INFO:root:current train perplexity3.674762487411499
INFO:root:current mean train loss 1484.8050478596333
INFO:root:current train perplexity3.678204298019409
INFO:root:current mean train loss 1487.2270286181295
INFO:root:current train perplexity3.6813390254974365
INFO:root:current mean train loss 1487.47098502402
INFO:root:current train perplexity3.6825671195983887
INFO:root:current mean train loss 1486.3639920903834
INFO:root:current train perplexity3.6813833713531494
INFO:root:current mean train loss 1487.2287234481887
INFO:root:current train perplexity3.6834516525268555
INFO:root:current mean train loss 1486.2773881592902
INFO:root:current train perplexity3.6856844425201416
INFO:root:current mean train loss 1486.2947665772497
INFO:root:current train perplexity3.686523199081421
INFO:root:current mean train loss 1486.5641439737487
INFO:root:current train perplexity3.687897205352783
INFO:root:current mean train loss 1486.4683797055716
INFO:root:current train perplexity3.688420057296753
INFO:root:current mean train loss 1485.493083925976
INFO:root:current train perplexity3.6872642040252686
INFO:root:current mean train loss 1484.9437569971767
INFO:root:current train perplexity3.6863012313842773
INFO:root:current mean train loss 1486.6867858349754
INFO:root:current train perplexity3.6899685859680176
INFO:root:current mean train loss 1487.406576986128
INFO:root:current train perplexity3.691303014755249
INFO:root:current mean train loss 1487.7041819815247
INFO:root:current train perplexity3.691798448562622

100%|██████████| 1/1 [05:36<00:00, 336.27s/it][A100%|██████████| 1/1 [05:36<00:00, 336.27s/it]
INFO:root:final mean train loss: 1487.522322615769
INFO:root:final train perplexity: 3.6922271251678467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 1853.346077560533
INFO:root:eval perplexity: 5.32987117767334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.82s/it][A100%|██████████| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 2348.4962314037566
INFO:root:eval perplexity: 8.654565811157227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/119
 60%|█████▉    | 119/200 [12:10:50<8:17:48, 368.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1459.38447154652
INFO:root:current train perplexity3.6252238750457764
INFO:root:current mean train loss 1478.5605538790344
INFO:root:current train perplexity3.6738839149475098
INFO:root:current mean train loss 1479.940552857545
INFO:root:current train perplexity3.6790931224823
INFO:root:current mean train loss 1480.6119274826524
INFO:root:current train perplexity3.684006452560425
INFO:root:current mean train loss 1484.3733610180318
INFO:root:current train perplexity3.6900899410247803
INFO:root:current mean train loss 1487.1815316503532
INFO:root:current train perplexity3.6848092079162598
INFO:root:current mean train loss 1485.2788503959632
INFO:root:current train perplexity3.685291290283203
INFO:root:current mean train loss 1484.1257374940487
INFO:root:current train perplexity3.683647632598877
INFO:root:current mean train loss 1482.3831141116846
INFO:root:current train perplexity3.6797380447387695
INFO:root:current mean train loss 1482.6789153589343
INFO:root:current train perplexity3.6809589862823486
INFO:root:current mean train loss 1482.3221033025395
INFO:root:current train perplexity3.681039810180664
INFO:root:current mean train loss 1482.4368332915553
INFO:root:current train perplexity3.680757522583008
INFO:root:current mean train loss 1482.6978293261238
INFO:root:current train perplexity3.680100679397583
INFO:root:current mean train loss 1484.0011339057771
INFO:root:current train perplexity3.6816444396972656
INFO:root:current mean train loss 1484.0332561766547
INFO:root:current train perplexity3.680482864379883
INFO:root:current mean train loss 1483.9926227664823
INFO:root:current train perplexity3.6823248863220215
INFO:root:current mean train loss 1485.5889924939552
INFO:root:current train perplexity3.6856918334960938
INFO:root:current mean train loss 1485.85051164616
INFO:root:current train perplexity3.6871771812438965
INFO:root:current mean train loss 1486.17494538325
INFO:root:current train perplexity3.688152313232422
INFO:root:current mean train loss 1487.1890683685208
INFO:root:current train perplexity3.689380407333374

100%|██████████| 1/1 [05:35<00:00, 335.68s/it][A100%|██████████| 1/1 [05:35<00:00, 335.68s/it]
INFO:root:final mean train loss: 1486.494340905263
INFO:root:final train perplexity: 3.6888957023620605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1854.0597451933731
INFO:root:eval perplexity: 5.333305835723877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2349.830489354776
INFO:root:eval perplexity: 8.665184020996094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/120
 60%|██████    | 120/200 [12:16:58<8:11:19, 368.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1489.1941888271233
INFO:root:current train perplexity3.694044828414917
INFO:root:current mean train loss 1468.220208696324
INFO:root:current train perplexity3.6725094318389893
INFO:root:current mean train loss 1478.3825407786348
INFO:root:current train perplexity3.665037155151367
INFO:root:current mean train loss 1475.5800583200821
INFO:root:current train perplexity3.6545443534851074
INFO:root:current mean train loss 1476.0573179901053
INFO:root:current train perplexity3.664283275604248
INFO:root:current mean train loss 1476.3712620213214
INFO:root:current train perplexity3.6633572578430176
INFO:root:current mean train loss 1478.1110448225377
INFO:root:current train perplexity3.663330554962158
INFO:root:current mean train loss 1479.7673491812204
INFO:root:current train perplexity3.6662590503692627
INFO:root:current mean train loss 1479.9994884395485
INFO:root:current train perplexity3.66784930229187
INFO:root:current mean train loss 1480.8272655678
INFO:root:current train perplexity3.6688547134399414
INFO:root:current mean train loss 1481.191143898693
INFO:root:current train perplexity3.668968915939331
INFO:root:current mean train loss 1481.0475511559275
INFO:root:current train perplexity3.669456958770752
INFO:root:current mean train loss 1481.3099896274719
INFO:root:current train perplexity3.671600580215454
INFO:root:current mean train loss 1480.9609509924617
INFO:root:current train perplexity3.6704351902008057
INFO:root:current mean train loss 1481.7984961853663
INFO:root:current train perplexity3.6737849712371826
INFO:root:current mean train loss 1482.413025893818
INFO:root:current train perplexity3.6749696731567383
INFO:root:current mean train loss 1484.4020927573501
INFO:root:current train perplexity3.6794137954711914
INFO:root:current mean train loss 1484.5195723846768
INFO:root:current train perplexity3.680556535720825
INFO:root:current mean train loss 1485.22563120773
INFO:root:current train perplexity3.682508707046509
INFO:root:current mean train loss 1485.3319016250523
INFO:root:current train perplexity3.682896375656128

100%|██████████| 1/1 [05:34<00:00, 334.97s/it][A100%|██████████| 1/1 [05:34<00:00, 334.97s/it]
INFO:root:final mean train loss: 1484.7901759683875
INFO:root:final train perplexity: 3.6833794116973877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1854.2639259717143
INFO:root:eval perplexity: 5.33428955078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2349.6222958395665
INFO:root:eval perplexity: 8.663527488708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/121
 60%|██████    | 121/200 [12:23:05<8:04:41, 368.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1477.6988677978516
INFO:root:current train perplexity3.6167445182800293
INFO:root:current mean train loss 1486.0943149664463
INFO:root:current train perplexity3.6253411769866943
INFO:root:current mean train loss 1484.91663646698
INFO:root:current train perplexity3.638158082962036
INFO:root:current mean train loss 1481.761522614554
INFO:root:current train perplexity3.6464805603027344
INFO:root:current mean train loss 1482.926513404177
INFO:root:current train perplexity3.6548073291778564
INFO:root:current mean train loss 1481.0647820122808
INFO:root:current train perplexity3.6531965732574463
INFO:root:current mean train loss 1481.4698981308356
INFO:root:current train perplexity3.6559555530548096
INFO:root:current mean train loss 1480.8369503929503
INFO:root:current train perplexity3.6574015617370605
INFO:root:current mean train loss 1481.1128227733006
INFO:root:current train perplexity3.6591577529907227
INFO:root:current mean train loss 1481.9088806407722
INFO:root:current train perplexity3.663939952850342
INFO:root:current mean train loss 1482.3288907137785
INFO:root:current train perplexity3.6643574237823486
INFO:root:current mean train loss 1482.7154961292306
INFO:root:current train perplexity3.6666409969329834
INFO:root:current mean train loss 1482.165055487566
INFO:root:current train perplexity3.667297601699829
INFO:root:current mean train loss 1482.0248457196892
INFO:root:current train perplexity3.667837619781494
INFO:root:current mean train loss 1482.1031118539663
INFO:root:current train perplexity3.6689846515655518
INFO:root:current mean train loss 1482.9993898053401
INFO:root:current train perplexity3.6712758541107178
INFO:root:current mean train loss 1482.0623644400334
INFO:root:current train perplexity3.6720011234283447
INFO:root:current mean train loss 1481.8832986262503
INFO:root:current train perplexity3.6731104850769043
INFO:root:current mean train loss 1482.2420542486782
INFO:root:current train perplexity3.673250675201416
INFO:root:current mean train loss 1482.1860709161115
INFO:root:current train perplexity3.6736087799072266

100%|██████████| 1/1 [05:35<00:00, 335.01s/it][A100%|██████████| 1/1 [05:35<00:00, 335.01s/it]
INFO:root:final mean train loss: 1481.8318408190814
INFO:root:final train perplexity: 3.673823118209839
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1855.8628600641346
INFO:root:eval perplexity: 5.341995716094971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2351.6385537005485
INFO:root:eval perplexity: 8.679594039916992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/122
 61%|██████    | 122/200 [12:29:12<7:58:13, 367.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1461.7866578820633
INFO:root:current train perplexity3.623878002166748
INFO:root:current mean train loss 1466.9291914570538
INFO:root:current train perplexity3.6299004554748535
INFO:root:current mean train loss 1464.9932092240442
INFO:root:current train perplexity3.6256916522979736
INFO:root:current mean train loss 1464.2636892201115
INFO:root:current train perplexity3.62587308883667
INFO:root:current mean train loss 1470.4937155725588
INFO:root:current train perplexity3.6325438022613525
INFO:root:current mean train loss 1474.3243648935154
INFO:root:current train perplexity3.6410348415374756
INFO:root:current mean train loss 1474.670324543787
INFO:root:current train perplexity3.646998167037964
INFO:root:current mean train loss 1475.620493347247
INFO:root:current train perplexity3.650252103805542
INFO:root:current mean train loss 1475.1888345235539
INFO:root:current train perplexity3.6520988941192627
INFO:root:current mean train loss 1475.845081231332
INFO:root:current train perplexity3.6541852951049805
INFO:root:current mean train loss 1476.0108548152814
INFO:root:current train perplexity3.6524250507354736
INFO:root:current mean train loss 1476.4260554659195
INFO:root:current train perplexity3.652892589569092
INFO:root:current mean train loss 1475.2365815671335
INFO:root:current train perplexity3.6543891429901123
INFO:root:current mean train loss 1475.719809068873
INFO:root:current train perplexity3.654771566390991
INFO:root:current mean train loss 1476.766048724038
INFO:root:current train perplexity3.6591484546661377
INFO:root:current mean train loss 1477.2227897280277
INFO:root:current train perplexity3.660446882247925
INFO:root:current mean train loss 1478.7493036957608
INFO:root:current train perplexity3.6641430854797363
INFO:root:current mean train loss 1479.2205347189174
INFO:root:current train perplexity3.6659836769104004
INFO:root:current mean train loss 1480.1006320152956
INFO:root:current train perplexity3.668063163757324
INFO:root:current mean train loss 1481.0359866745994
INFO:root:current train perplexity3.670287847518921

100%|██████████| 1/1 [05:34<00:00, 334.62s/it][A100%|██████████| 1/1 [05:34<00:00, 334.63s/it]
INFO:root:final mean train loss: 1480.7340076810112
INFO:root:final train perplexity: 3.670283079147339
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 1853.6519939882535
INFO:root:eval perplexity: 5.331343173980713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2347.9346365421375
INFO:root:eval perplexity: 8.650099754333496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/123
 62%|██████▏   | 123/200 [12:35:19<7:51:42, 367.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1476.8652303059896
INFO:root:current train perplexity3.6450788974761963
INFO:root:current mean train loss 1472.320654296875
INFO:root:current train perplexity3.6373631954193115
INFO:root:current mean train loss 1472.298907681169
INFO:root:current train perplexity3.647043466567993
INFO:root:current mean train loss 1472.5721817407853
INFO:root:current train perplexity3.6472725868225098
INFO:root:current mean train loss 1473.6546381736289
INFO:root:current train perplexity3.64852237701416
INFO:root:current mean train loss 1476.324546891552
INFO:root:current train perplexity3.6576836109161377
INFO:root:current mean train loss 1478.8834596495697
INFO:root:current train perplexity3.663491725921631
INFO:root:current mean train loss 1477.96438050089
INFO:root:current train perplexity3.6595869064331055
INFO:root:current mean train loss 1476.7109402431531
INFO:root:current train perplexity3.659698724746704
INFO:root:current mean train loss 1478.408400533657
INFO:root:current train perplexity3.6619338989257812
INFO:root:current mean train loss 1477.228669948753
INFO:root:current train perplexity3.660578727722168
INFO:root:current mean train loss 1477.3826744271928
INFO:root:current train perplexity3.6605381965637207
INFO:root:current mean train loss 1477.7241105900255
INFO:root:current train perplexity3.6618409156799316
INFO:root:current mean train loss 1477.7579436158105
INFO:root:current train perplexity3.6619889736175537
INFO:root:current mean train loss 1478.2526653929845
INFO:root:current train perplexity3.6649227142333984
INFO:root:current mean train loss 1478.5557702406397
INFO:root:current train perplexity3.66504168510437
INFO:root:current mean train loss 1478.6870248647836
INFO:root:current train perplexity3.6638429164886475
INFO:root:current mean train loss 1478.8428668656163
INFO:root:current train perplexity3.663078784942627
INFO:root:current mean train loss 1479.269586988984
INFO:root:current train perplexity3.663665533065796

100%|██████████| 1/1 [05:35<00:00, 335.50s/it][A100%|██████████| 1/1 [05:35<00:00, 335.50s/it]
INFO:root:final mean train loss: 1479.5640047335949
INFO:root:final train perplexity: 3.6665143966674805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 1856.934692815686
INFO:root:eval perplexity: 5.347167491912842
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.71s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 2353.0342234077184
INFO:root:eval perplexity: 8.6907320022583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/124
 62%|██████▏   | 124/200 [12:41:27<7:45:41, 367.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1524.6309291294642
INFO:root:current train perplexity3.6684553623199463
INFO:root:current mean train loss 1485.275252582871
INFO:root:current train perplexity3.660799026489258
INFO:root:current mean train loss 1479.992725317029
INFO:root:current train perplexity3.6611499786376953
INFO:root:current mean train loss 1475.82606014289
INFO:root:current train perplexity3.643510580062866
INFO:root:current mean train loss 1476.9637829079968
INFO:root:current train perplexity3.6469643115997314
INFO:root:current mean train loss 1475.7575616178192
INFO:root:current train perplexity3.6444857120513916
INFO:root:current mean train loss 1476.3861872313246
INFO:root:current train perplexity3.6495375633239746
INFO:root:current mean train loss 1475.818874245823
INFO:root:current train perplexity3.653829336166382
INFO:root:current mean train loss 1475.2038604471616
INFO:root:current train perplexity3.6511807441711426
INFO:root:current mean train loss 1474.8946125404836
INFO:root:current train perplexity3.656768560409546
INFO:root:current mean train loss 1475.1241587209843
INFO:root:current train perplexity3.6599044799804688
INFO:root:current mean train loss 1475.2026093714712
INFO:root:current train perplexity3.6598634719848633
INFO:root:current mean train loss 1476.625890799762
INFO:root:current train perplexity3.6607017517089844
INFO:root:current mean train loss 1477.502255825752
INFO:root:current train perplexity3.661862850189209
INFO:root:current mean train loss 1478.0656348732066
INFO:root:current train perplexity3.663691759109497
INFO:root:current mean train loss 1478.0470401634818
INFO:root:current train perplexity3.6615042686462402
INFO:root:current mean train loss 1477.7251030495245
INFO:root:current train perplexity3.660984516143799
INFO:root:current mean train loss 1477.7345184522828
INFO:root:current train perplexity3.6599364280700684
INFO:root:current mean train loss 1478.204408190695
INFO:root:current train perplexity3.6598401069641113
INFO:root:current mean train loss 1478.3927008994413
INFO:root:current train perplexity3.6597015857696533

100%|██████████| 1/1 [05:35<00:00, 335.06s/it][A100%|██████████| 1/1 [05:35<00:00, 335.08s/it]
INFO:root:final mean train loss: 1477.4715420429116
INFO:root:final train perplexity: 3.659783363342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1858.1564625408632
INFO:root:eval perplexity: 5.353069305419922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2355.7592163085938
INFO:root:eval perplexity: 8.71252155303955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/125
 62%|██████▎   | 125/200 [12:47:34<7:39:27, 367.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1480.491419474284
INFO:root:current train perplexity3.672642469406128
INFO:root:current mean train loss 1474.127182499055
INFO:root:current train perplexity3.636131525039673
INFO:root:current mean train loss 1471.9649042401995
INFO:root:current train perplexity3.648716688156128
INFO:root:current mean train loss 1475.4557796525366
INFO:root:current train perplexity3.6510183811187744
INFO:root:current mean train loss 1472.9932236581478
INFO:root:current train perplexity3.652794122695923
INFO:root:current mean train loss 1473.6527511946117
INFO:root:current train perplexity3.653390884399414
INFO:root:current mean train loss 1474.479169209798
INFO:root:current train perplexity3.6495633125305176
INFO:root:current mean train loss 1474.410635257953
INFO:root:current train perplexity3.654836654663086
INFO:root:current mean train loss 1476.0533368749525
INFO:root:current train perplexity3.6572422981262207
INFO:root:current mean train loss 1476.982095297281
INFO:root:current train perplexity3.653212308883667
INFO:root:current mean train loss 1478.1459647417068
INFO:root:current train perplexity3.6516783237457275
INFO:root:current mean train loss 1476.9567080460408
INFO:root:current train perplexity3.6517045497894287
INFO:root:current mean train loss 1477.0187069761987
INFO:root:current train perplexity3.652897834777832
INFO:root:current mean train loss 1477.4647568071716
INFO:root:current train perplexity3.6539409160614014
INFO:root:current mean train loss 1477.921392976568
INFO:root:current train perplexity3.6554739475250244
INFO:root:current mean train loss 1478.1101729425545
INFO:root:current train perplexity3.6549625396728516
INFO:root:current mean train loss 1477.8896637714556
INFO:root:current train perplexity3.656850814819336
INFO:root:current mean train loss 1476.932989062953
INFO:root:current train perplexity3.6551320552825928
INFO:root:current mean train loss 1476.6776520578485
INFO:root:current train perplexity3.655583381652832
INFO:root:current mean train loss 1477.0419017767956
INFO:root:current train perplexity3.6562564373016357

100%|██████████| 1/1 [05:34<00:00, 334.85s/it][A100%|██████████| 1/1 [05:34<00:00, 334.85s/it]
INFO:root:final mean train loss: 1476.4726529566256
INFO:root:final train perplexity: 3.6565744876861572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1861.016121938719
INFO:root:eval perplexity: 5.366907596588135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2360.0025297124334
INFO:root:eval perplexity: 8.746559143066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/126
 63%|██████▎   | 126/200 [12:53:41<7:33:08, 367.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.2242908012577
INFO:root:current train perplexity3.6232144832611084
INFO:root:current mean train loss 1472.9835205078125
INFO:root:current train perplexity3.6204559803009033
INFO:root:current mean train loss 1468.058582606652
INFO:root:current train perplexity3.632397174835205
INFO:root:current mean train loss 1470.3328159365835
INFO:root:current train perplexity3.6426279544830322
INFO:root:current mean train loss 1470.5131595118517
INFO:root:current train perplexity3.6453921794891357
INFO:root:current mean train loss 1470.9701333883288
INFO:root:current train perplexity3.6466121673583984
INFO:root:current mean train loss 1473.680738333049
INFO:root:current train perplexity3.6511032581329346
INFO:root:current mean train loss 1472.009713073813
INFO:root:current train perplexity3.648388385772705
INFO:root:current mean train loss 1472.3783080909539
INFO:root:current train perplexity3.647456169128418
INFO:root:current mean train loss 1472.3346829389031
INFO:root:current train perplexity3.6474716663360596
INFO:root:current mean train loss 1472.835086525689
INFO:root:current train perplexity3.6525490283966064
INFO:root:current mean train loss 1472.3810180343107
INFO:root:current train perplexity3.651360511779785
INFO:root:current mean train loss 1472.996591966062
INFO:root:current train perplexity3.653069019317627
INFO:root:current mean train loss 1473.205510787338
INFO:root:current train perplexity3.653001070022583
INFO:root:current mean train loss 1474.1766524304953
INFO:root:current train perplexity3.6519198417663574
INFO:root:current mean train loss 1475.0466207198551
INFO:root:current train perplexity3.6526038646698
INFO:root:current mean train loss 1474.9700425617002
INFO:root:current train perplexity3.6513748168945312
INFO:root:current mean train loss 1474.6153479613906
INFO:root:current train perplexity3.649794340133667
INFO:root:current mean train loss 1474.9533621121334
INFO:root:current train perplexity3.650609254837036
INFO:root:current mean train loss 1474.6294099394038
INFO:root:current train perplexity3.649540662765503

100%|██████████| 1/1 [05:35<00:00, 335.16s/it][A100%|██████████| 1/1 [05:35<00:00, 335.16s/it]
INFO:root:final mean train loss: 1474.390085040471
INFO:root:final train perplexity: 3.6498939990997314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1858.9282395383145
INFO:root:eval perplexity: 5.356800556182861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 2356.401303555103
INFO:root:eval perplexity: 8.717662811279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/127
 64%|██████▎   | 127/200 [12:59:49<7:27:00, 367.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1464.3084295864762
INFO:root:current train perplexity3.6203935146331787
INFO:root:current mean train loss 1473.8873283289656
INFO:root:current train perplexity3.614182233810425
INFO:root:current mean train loss 1474.381310278131
INFO:root:current train perplexity3.6320598125457764
INFO:root:current mean train loss 1471.6680400145121
INFO:root:current train perplexity3.6365368366241455
INFO:root:current mean train loss 1471.1576751309192
INFO:root:current train perplexity3.6312355995178223
INFO:root:current mean train loss 1473.8098835825492
INFO:root:current train perplexity3.6391401290893555
INFO:root:current mean train loss 1473.6968022030537
INFO:root:current train perplexity3.636742115020752
INFO:root:current mean train loss 1474.9660731494268
INFO:root:current train perplexity3.637951374053955
INFO:root:current mean train loss 1474.3463710971646
INFO:root:current train perplexity3.639458179473877
INFO:root:current mean train loss 1473.9133316071895
INFO:root:current train perplexity3.639126777648926
INFO:root:current mean train loss 1472.5743501659601
INFO:root:current train perplexity3.6386709213256836
INFO:root:current mean train loss 1472.6595854289792
INFO:root:current train perplexity3.640573740005493
INFO:root:current mean train loss 1473.7548962033609
INFO:root:current train perplexity3.6435043811798096
INFO:root:current mean train loss 1472.7798026847559
INFO:root:current train perplexity3.6427314281463623
INFO:root:current mean train loss 1472.128339853797
INFO:root:current train perplexity3.6419308185577393
INFO:root:current mean train loss 1472.4389783200618
INFO:root:current train perplexity3.6420905590057373
INFO:root:current mean train loss 1473.1945342833515
INFO:root:current train perplexity3.642570734024048
INFO:root:current mean train loss 1473.4689122743573
INFO:root:current train perplexity3.643573522567749
INFO:root:current mean train loss 1473.826723359501
INFO:root:current train perplexity3.6450462341308594
INFO:root:current mean train loss 1473.4147179888996
INFO:root:current train perplexity3.6460561752319336

100%|██████████| 1/1 [05:35<00:00, 335.16s/it][A100%|██████████| 1/1 [05:35<00:00, 335.16s/it]
INFO:root:final mean train loss: 1473.222830675734
INFO:root:final train perplexity: 3.6461544036865234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1861.400108824385
INFO:root:eval perplexity: 5.368770122528076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2362.2563277440713
INFO:root:eval perplexity: 8.764693260192871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/128
 64%|██████▍   | 128/200 [13:05:56<7:20:52, 367.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1457.5579720052083
INFO:root:current train perplexity3.5957658290863037
INFO:root:current mean train loss 1461.2065506417412
INFO:root:current train perplexity3.596463441848755
INFO:root:current mean train loss 1463.9328005149148
INFO:root:current train perplexity3.605520248413086
INFO:root:current mean train loss 1468.9898427734374
INFO:root:current train perplexity3.6182429790496826
INFO:root:current mean train loss 1468.687490234375
INFO:root:current train perplexity3.6210219860076904
INFO:root:current mean train loss 1468.40673382303
INFO:root:current train perplexity3.6257975101470947
INFO:root:current mean train loss 1468.0694538483797
INFO:root:current train perplexity3.6281325817108154
INFO:root:current mean train loss 1468.23498062626
INFO:root:current train perplexity3.626516342163086
INFO:root:current mean train loss 1468.0056481584822
INFO:root:current train perplexity3.6285722255706787
INFO:root:current mean train loss 1468.4004542267628
INFO:root:current train perplexity3.6306498050689697
INFO:root:current mean train loss 1470.2994188317587
INFO:root:current train perplexity3.632742166519165
INFO:root:current mean train loss 1470.9308604138962
INFO:root:current train perplexity3.6343023777008057
INFO:root:current mean train loss 1469.8401141237746
INFO:root:current train perplexity3.6332602500915527
INFO:root:current mean train loss 1469.4484461115057
INFO:root:current train perplexity3.6349828243255615
INFO:root:current mean train loss 1470.0702915618378
INFO:root:current train perplexity3.637451410293579
INFO:root:current mean train loss 1470.4258927021328
INFO:root:current train perplexity3.636653184890747
INFO:root:current mean train loss 1470.5664200967817
INFO:root:current train perplexity3.6381771564483643
INFO:root:current mean train loss 1471.5932637131382
INFO:root:current train perplexity3.63966703414917
INFO:root:current mean train loss 1471.4336040364583
INFO:root:current train perplexity3.6411190032958984
INFO:root:current mean train loss 1472.1619729652887
INFO:root:current train perplexity3.6417622566223145

100%|██████████| 1/1 [05:34<00:00, 334.66s/it][A100%|██████████| 1/1 [05:34<00:00, 334.66s/it]
INFO:root:final mean train loss: 1471.7947525278341
INFO:root:final train perplexity: 3.641584634780884
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.64s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1860.963298824662
INFO:root:eval perplexity: 5.366652011871338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.72s/it][A100%|██████████| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 2360.7526504841258
INFO:root:eval perplexity: 8.75259017944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/129
 64%|██████▍   | 129/200 [13:12:03<7:14:33, 367.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1467.8695665442426
INFO:root:current train perplexity3.6504104137420654
INFO:root:current mean train loss 1470.2219975789387
INFO:root:current train perplexity3.636662721633911
INFO:root:current mean train loss 1463.6859511283978
INFO:root:current train perplexity3.6140968799591064
INFO:root:current mean train loss 1461.8820810123366
INFO:root:current train perplexity3.6125168800354004
INFO:root:current mean train loss 1461.097283340082
INFO:root:current train perplexity3.6168367862701416
INFO:root:current mean train loss 1458.6375534470017
INFO:root:current train perplexity3.614867687225342
INFO:root:current mean train loss 1460.1915371404218
INFO:root:current train perplexity3.6172661781311035
INFO:root:current mean train loss 1462.3402549666587
INFO:root:current train perplexity3.6200344562530518
INFO:root:current mean train loss 1463.2357185945382
INFO:root:current train perplexity3.6215195655822754
INFO:root:current mean train loss 1466.6541339505104
INFO:root:current train perplexity3.627915143966675
INFO:root:current mean train loss 1467.3916821602063
INFO:root:current train perplexity3.6296064853668213
INFO:root:current mean train loss 1468.045899359172
INFO:root:current train perplexity3.630139112472534
INFO:root:current mean train loss 1467.4684706177136
INFO:root:current train perplexity3.6300907135009766
INFO:root:current mean train loss 1468.0421157486137
INFO:root:current train perplexity3.6304361820220947
INFO:root:current mean train loss 1468.25350510339
INFO:root:current train perplexity3.6317381858825684
INFO:root:current mean train loss 1468.4002585866344
INFO:root:current train perplexity3.6328725814819336
INFO:root:current mean train loss 1468.6036128772348
INFO:root:current train perplexity3.635003089904785
INFO:root:current mean train loss 1469.2638866560799
INFO:root:current train perplexity3.635512351989746
INFO:root:current mean train loss 1470.3965048921032
INFO:root:current train perplexity3.6370623111724854

100%|██████████| 1/1 [05:35<00:00, 335.08s/it][A100%|██████████| 1/1 [05:35<00:00, 335.08s/it]
INFO:root:final mean train loss: 1470.172505173368
INFO:root:final train perplexity: 3.6364009380340576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1863.178579776845
INFO:root:eval perplexity: 5.377396106719971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2364.4099194682235
INFO:root:eval perplexity: 8.78205680847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/130
 65%|██████▌   | 130/200 [13:18:10<7:08:26, 367.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1423.571533203125
INFO:root:current train perplexity3.6350975036621094
INFO:root:current mean train loss 1473.2449234428755
INFO:root:current train perplexity3.6402783393859863
INFO:root:current mean train loss 1461.4248514129786
INFO:root:current train perplexity3.605799913406372
INFO:root:current mean train loss 1462.849096205628
INFO:root:current train perplexity3.6043903827667236
INFO:root:current mean train loss 1467.3662748080303
INFO:root:current train perplexity3.6085946559906006
INFO:root:current mean train loss 1465.796614551357
INFO:root:current train perplexity3.6034576892852783
INFO:root:current mean train loss 1466.6535353887648
INFO:root:current train perplexity3.6136136054992676
INFO:root:current mean train loss 1466.2002819152747
INFO:root:current train perplexity3.6144981384277344
INFO:root:current mean train loss 1466.1260352588554
INFO:root:current train perplexity3.6144511699676514
INFO:root:current mean train loss 1466.2981769490425
INFO:root:current train perplexity3.6176626682281494
INFO:root:current mean train loss 1466.0570793038435
INFO:root:current train perplexity3.61725115776062
INFO:root:current mean train loss 1466.325643637462
INFO:root:current train perplexity3.6208560466766357
INFO:root:current mean train loss 1467.8108575535373
INFO:root:current train perplexity3.6228599548339844
INFO:root:current mean train loss 1467.7835159010338
INFO:root:current train perplexity3.621938467025757
INFO:root:current mean train loss 1467.9339704439096
INFO:root:current train perplexity3.622286081314087
INFO:root:current mean train loss 1469.6442115535951
INFO:root:current train perplexity3.6260364055633545
INFO:root:current mean train loss 1469.924510019325
INFO:root:current train perplexity3.6279826164245605
INFO:root:current mean train loss 1469.1988303249798
INFO:root:current train perplexity3.6278231143951416
INFO:root:current mean train loss 1468.401442427079
INFO:root:current train perplexity3.6277589797973633
INFO:root:current mean train loss 1468.2063693590599
INFO:root:current train perplexity3.6284894943237305

100%|██████████| 1/1 [05:34<00:00, 334.57s/it][A100%|██████████| 1/1 [05:34<00:00, 334.58s/it]
INFO:root:final mean train loss: 1468.2339033702979
INFO:root:final train perplexity: 3.630215883255005
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.63s/it][A100%|██████████| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 1862.7056884765625
INFO:root:eval perplexity: 5.375101566314697
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2364.343275137827
INFO:root:eval perplexity: 8.781517028808594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/131
 66%|██████▌   | 131/200 [13:24:17<7:02:08, 367.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1499.5548283503606
INFO:root:current train perplexity3.6705849170684814
INFO:root:current mean train loss 1463.4764811197917
INFO:root:current train perplexity3.619349956512451
INFO:root:current mean train loss 1462.1795616487486
INFO:root:current train perplexity3.5993897914886475
INFO:root:current mean train loss 1458.1909063608368
INFO:root:current train perplexity3.6044836044311523
INFO:root:current mean train loss 1455.5502173195423
INFO:root:current train perplexity3.6012885570526123
INFO:root:current mean train loss 1454.9050896358128
INFO:root:current train perplexity3.598952293395996
INFO:root:current mean train loss 1458.3577666358826
INFO:root:current train perplexity3.6026759147644043
INFO:root:current mean train loss 1461.1787422117122
INFO:root:current train perplexity3.6085684299468994
INFO:root:current mean train loss 1459.913571706407
INFO:root:current train perplexity3.608630895614624
INFO:root:current mean train loss 1460.6831240561303
INFO:root:current train perplexity3.609229564666748
INFO:root:current mean train loss 1464.5919574938323
INFO:root:current train perplexity3.617825508117676
INFO:root:current mean train loss 1465.596829727742
INFO:root:current train perplexity3.617704391479492
INFO:root:current mean train loss 1467.1884514713754
INFO:root:current train perplexity3.622398614883423
INFO:root:current mean train loss 1467.290850747225
INFO:root:current train perplexity3.622312307357788
INFO:root:current mean train loss 1468.7080775791933
INFO:root:current train perplexity3.6258490085601807
INFO:root:current mean train loss 1468.800834525772
INFO:root:current train perplexity3.6237921714782715
INFO:root:current mean train loss 1468.2569244497377
INFO:root:current train perplexity3.624692916870117
INFO:root:current mean train loss 1467.827634738467
INFO:root:current train perplexity3.6247191429138184
INFO:root:current mean train loss 1467.471159518222
INFO:root:current train perplexity3.624502420425415
INFO:root:current mean train loss 1467.3687521042234
INFO:root:current train perplexity3.6260592937469482

100%|██████████| 1/1 [05:35<00:00, 335.92s/it][A100%|██████████| 1/1 [05:35<00:00, 335.92s/it]
INFO:root:final mean train loss: 1466.777686784199
INFO:root:final train perplexity: 3.625576972961426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 1864.3198545198914
INFO:root:eval perplexity: 5.382941246032715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.78s/it][A100%|██████████| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 2366.7496173398713
INFO:root:eval perplexity: 8.800959587097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/132
 66%|██████▌   | 132/200 [13:30:25<6:56:25, 367.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1473.4107296965842
INFO:root:current train perplexity3.614177942276001
INFO:root:current mean train loss 1465.5225377649695
INFO:root:current train perplexity3.613281011581421
INFO:root:current mean train loss 1463.2727829419046
INFO:root:current train perplexity3.6237833499908447
INFO:root:current mean train loss 1464.9708824936224
INFO:root:current train perplexity3.619771957397461
INFO:root:current mean train loss 1465.9101460545112
INFO:root:current train perplexity3.6194570064544678
INFO:root:current mean train loss 1466.1452216329276
INFO:root:current train perplexity3.619882106781006
INFO:root:current mean train loss 1466.9840744754204
INFO:root:current train perplexity3.6170480251312256
INFO:root:current mean train loss 1466.9449407030725
INFO:root:current train perplexity3.6175482273101807
INFO:root:current mean train loss 1465.14929300582
INFO:root:current train perplexity3.6174659729003906
INFO:root:current mean train loss 1466.0664050849598
INFO:root:current train perplexity3.618008852005005
INFO:root:current mean train loss 1466.358656973761
INFO:root:current train perplexity3.615741729736328
INFO:root:current mean train loss 1467.386630214314
INFO:root:current train perplexity3.621870756149292
INFO:root:current mean train loss 1467.9705947053499
INFO:root:current train perplexity3.622735023498535
INFO:root:current mean train loss 1466.8167780054566
INFO:root:current train perplexity3.621807098388672
INFO:root:current mean train loss 1466.8095358824119
INFO:root:current train perplexity3.6231086254119873
INFO:root:current mean train loss 1466.854601837178
INFO:root:current train perplexity3.6247196197509766
INFO:root:current mean train loss 1466.6631125359004
INFO:root:current train perplexity3.6241273880004883
INFO:root:current mean train loss 1466.9765251715567
INFO:root:current train perplexity3.624001979827881
INFO:root:current mean train loss 1466.9634612358204
INFO:root:current train perplexity3.624398708343506
INFO:root:current mean train loss 1466.7700128089014
INFO:root:current train perplexity3.6244056224823

100%|██████████| 1/1 [05:35<00:00, 335.12s/it][A100%|██████████| 1/1 [05:35<00:00, 335.12s/it]
INFO:root:final mean train loss: 1466.085043949006
INFO:root:final train perplexity: 3.6233725547790527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1866.5821875173149
INFO:root:eval perplexity: 5.393947124481201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2369.9255063753603
INFO:root:eval perplexity: 8.826680183410645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/133
 66%|██████▋   | 133/200 [13:36:33<6:50:18, 367.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1453.5913431803385
INFO:root:current train perplexity3.633958101272583
INFO:root:current mean train loss 1450.6604949951172
INFO:root:current train perplexity3.6069483757019043
INFO:root:current mean train loss 1451.8719801682691
INFO:root:current train perplexity3.611903429031372
INFO:root:current mean train loss 1455.3110829671225
INFO:root:current train perplexity3.605114459991455
INFO:root:current mean train loss 1461.0727706245755
INFO:root:current train perplexity3.6167471408843994
INFO:root:current mean train loss 1460.3632143293107
INFO:root:current train perplexity3.6119837760925293
INFO:root:current mean train loss 1460.5415656812263
INFO:root:current train perplexity3.616182327270508
INFO:root:current mean train loss 1460.8154160348993
INFO:root:current train perplexity3.615787982940674
INFO:root:current mean train loss 1461.16151194018
INFO:root:current train perplexity3.6162025928497314
INFO:root:current mean train loss 1462.4010632832844
INFO:root:current train perplexity3.6180989742279053
INFO:root:current mean train loss 1463.1480817686836
INFO:root:current train perplexity3.61673903465271
INFO:root:current mean train loss 1463.7041567046067
INFO:root:current train perplexity3.615443229675293
INFO:root:current mean train loss 1463.6589304121715
INFO:root:current train perplexity3.615206003189087
INFO:root:current mean train loss 1463.8588940788718
INFO:root:current train perplexity3.615997076034546
INFO:root:current mean train loss 1464.3475243137307
INFO:root:current train perplexity3.6165904998779297
INFO:root:current mean train loss 1464.3078908284506
INFO:root:current train perplexity3.61544132232666
INFO:root:current mean train loss 1464.8231376923711
INFO:root:current train perplexity3.6168603897094727
INFO:root:current mean train loss 1463.9255473050205
INFO:root:current train perplexity3.6150858402252197
INFO:root:current mean train loss 1463.8144034436955
INFO:root:current train perplexity3.6151185035705566
INFO:root:current mean train loss 1464.309167418188
INFO:root:current train perplexity3.6167988777160645

100%|██████████| 1/1 [05:36<00:00, 336.16s/it][A100%|██████████| 1/1 [05:36<00:00, 336.16s/it]
INFO:root:final mean train loss: 1464.1539948386974
INFO:root:final train perplexity: 3.6172330379486084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.66s/it][A100%|██████████| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 1864.2650501440603
INFO:root:eval perplexity: 5.382674217224121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2367.1453134523217
INFO:root:eval perplexity: 8.804160118103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/134
 67%|██████▋   | 134/200 [13:42:41<6:44:28, 367.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1478.3623696859781
INFO:root:current train perplexity3.625547170639038
INFO:root:current mean train loss 1462.245650296831
INFO:root:current train perplexity3.6051390171051025
INFO:root:current mean train loss 1464.4377190214632
INFO:root:current train perplexity3.607818365097046
INFO:root:current mean train loss 1462.6125235721984
INFO:root:current train perplexity3.5983834266662598
INFO:root:current mean train loss 1462.1287731754455
INFO:root:current train perplexity3.5974628925323486
INFO:root:current mean train loss 1460.995533749797
INFO:root:current train perplexity3.5982794761657715
INFO:root:current mean train loss 1460.988843458618
INFO:root:current train perplexity3.6019110679626465
INFO:root:current mean train loss 1462.9773106323398
INFO:root:current train perplexity3.6023013591766357
INFO:root:current mean train loss 1463.5010181805426
INFO:root:current train perplexity3.606138229370117
INFO:root:current mean train loss 1464.3693725211106
INFO:root:current train perplexity3.6112618446350098
INFO:root:current mean train loss 1464.1073833384112
INFO:root:current train perplexity3.6112756729125977
INFO:root:current mean train loss 1463.9998526236923
INFO:root:current train perplexity3.6127068996429443
INFO:root:current mean train loss 1464.7350582878573
INFO:root:current train perplexity3.6129205226898193
INFO:root:current mean train loss 1463.7896966982685
INFO:root:current train perplexity3.613544225692749
INFO:root:current mean train loss 1463.2559772302916
INFO:root:current train perplexity3.6150665283203125
INFO:root:current mean train loss 1462.926334939883
INFO:root:current train perplexity3.6144630908966064
INFO:root:current mean train loss 1463.4737711151797
INFO:root:current train perplexity3.614995241165161
INFO:root:current mean train loss 1462.7455209056916
INFO:root:current train perplexity3.6125285625457764
INFO:root:current mean train loss 1462.9006060852798
INFO:root:current train perplexity3.613450288772583
INFO:root:current mean train loss 1463.4269971369974
INFO:root:current train perplexity3.6136035919189453

100%|██████████| 1/1 [05:35<00:00, 335.72s/it][A100%|██████████| 1/1 [05:35<00:00, 335.72s/it]
INFO:root:final mean train loss: 1462.9643307530514
INFO:root:final train perplexity: 3.6134562492370605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.69s/it][A100%|██████████| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 1867.1095585383423
INFO:root:eval perplexity: 5.396515369415283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.75s/it][A100%|██████████| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 2371.042169665614
INFO:root:eval perplexity: 8.83574390411377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/135
 68%|██████▊   | 135/200 [13:48:49<6:38:25, 367.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1465.393787140542
INFO:root:current train perplexity3.59018874168396
INFO:root:current mean train loss 1463.7021585051546
INFO:root:current train perplexity3.592482328414917
INFO:root:current mean train loss 1461.3131165796397
INFO:root:current train perplexity3.5972342491149902
INFO:root:current mean train loss 1461.7070197865442
INFO:root:current train perplexity3.5918562412261963
INFO:root:current mean train loss 1462.1892448147298
INFO:root:current train perplexity3.598449468612671
INFO:root:current mean train loss 1464.8170761981796
INFO:root:current train perplexity3.605579137802124
INFO:root:current mean train loss 1465.185832350673
INFO:root:current train perplexity3.6062660217285156
INFO:root:current mean train loss 1464.3597046205919
INFO:root:current train perplexity3.608220338821411
INFO:root:current mean train loss 1464.280206667497
INFO:root:current train perplexity3.608030319213867
INFO:root:current mean train loss 1464.5815440740143
INFO:root:current train perplexity3.607408046722412
INFO:root:current mean train loss 1464.684584818113
INFO:root:current train perplexity3.608051300048828
INFO:root:current mean train loss 1465.121370708523
INFO:root:current train perplexity3.6094563007354736
INFO:root:current mean train loss 1463.7682408328403
INFO:root:current train perplexity3.607846975326538
INFO:root:current mean train loss 1462.2015189084636
INFO:root:current train perplexity3.6077966690063477
INFO:root:current mean train loss 1462.216004153332
INFO:root:current train perplexity3.6066370010375977
INFO:root:current mean train loss 1462.635261947268
INFO:root:current train perplexity3.606867551803589
INFO:root:current mean train loss 1462.2134041994493
INFO:root:current train perplexity3.607171058654785
INFO:root:current mean train loss 1461.8634013470466
INFO:root:current train perplexity3.606909990310669
INFO:root:current mean train loss 1462.0579980932798
INFO:root:current train perplexity3.608809232711792

100%|██████████| 1/1 [05:35<00:00, 335.37s/it][A100%|██████████| 1/1 [05:35<00:00, 335.38s/it]
INFO:root:final mean train loss: 1461.5693096212829
INFO:root:final train perplexity: 3.60903263092041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.65s/it][A100%|██████████| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 1865.2367696559174
INFO:root:eval perplexity: 5.3873982429504395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.73s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2366.7621022758753
INFO:root:eval perplexity: 8.80105972290039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/136
 68%|██████▊   | 136/200 [13:54:56<6:32:14, 367.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1444.9401300603693
INFO:root:current train perplexity3.5426275730133057
INFO:root:current mean train loss 1459.927766267244
INFO:root:current train perplexity3.606496810913086
INFO:root:current mean train loss 1465.6927872065685
INFO:root:current train perplexity3.6085667610168457
INFO:root:current mean train loss 1465.681641410018
INFO:root:current train perplexity3.607044219970703
INFO:root:current mean train loss 1464.8518642601887
INFO:root:current train perplexity3.6121582984924316
INFO:root:current mean train loss 1461.9534405672853
INFO:root:current train perplexity3.6090807914733887
INFO:root:current mean train loss 1460.447059244259
INFO:root:current train perplexity3.6067686080932617
INFO:root:current mean train loss 1461.1490306827423
INFO:root:current train perplexity3.604423999786377
INFO:root:current mean train loss 1459.3365802129895
INFO:root:current train perplexity3.602169990539551
INFO:root:current mean train loss 1459.9114786560529
INFO:root:current train perplexity3.600799322128296
INFO:root:current mean train loss 1460.40057548123
INFO:root:current train perplexity3.6036105155944824
INFO:root:current mean train loss 1458.6260662199034
INFO:root:current train perplexity3.604336738586426
INFO:root:current mean train loss 1457.5278133830188
INFO:root:current train perplexity3.6010966300964355
INFO:root:current mean train loss 1458.351799284748
INFO:root:current train perplexity3.6022517681121826
INFO:root:current mean train loss 1459.3251780098335
INFO:root:current train perplexity3.6043155193328857
INFO:root:current mean train loss 1459.9595168471574
INFO:root:current train perplexity3.6049821376800537
INFO:root:current mean train loss 1459.977602787598
INFO:root:current train perplexity3.603759288787842
INFO:root:current mean train loss 1460.7478156477162
INFO:root:current train perplexity3.6049044132232666
INFO:root:current mean train loss 1459.2078812934626
INFO:root:current train perplexity3.60180926322937
INFO:root:current mean train loss 1459.704978986787
INFO:root:current train perplexity3.6026227474212646

100%|██████████| 1/1 [05:35<00:00, 335.62s/it][A100%|██████████| 1/1 [05:35<00:00, 335.63s/it]
INFO:root:final mean train loss: 1459.8565454064628
INFO:root:final train perplexity: 3.6036083698272705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 1867.0510898887687
INFO:root:eval perplexity: 5.396231651306152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.74s/it][A100%|██████████| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2372.143234361148
INFO:root:eval perplexity: 8.844687461853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/137
 68%|██████▊   | 137/200 [14:01:04<6:26:09, 367.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1467.8534676688057
INFO:root:current train perplexity3.568436861038208
INFO:root:current mean train loss 1460.8134326934814
INFO:root:current train perplexity3.58819842338562
INFO:root:current mean train loss 1452.200593647204
INFO:root:current train perplexity3.5886929035186768
INFO:root:current mean train loss 1456.6917144031058
INFO:root:current train perplexity3.591779947280884
INFO:root:current mean train loss 1456.3864831657054
INFO:root:current train perplexity3.5962541103363037
INFO:root:current mean train loss 1457.2918548583984
INFO:root:current train perplexity3.6002352237701416
INFO:root:current mean train loss 1458.539242106638
INFO:root:current train perplexity3.598518133163452
INFO:root:current mean train loss 1457.8897306002104
INFO:root:current train perplexity3.596994161605835
INFO:root:current mean train loss 1457.2797900213711
INFO:root:current train perplexity3.594852924346924
INFO:root:current mean train loss 1457.9505996704102
INFO:root:current train perplexity3.5962533950805664
INFO:root:current mean train loss 1456.8411900858007
INFO:root:current train perplexity3.5949628353118896
INFO:root:current mean train loss 1458.6059520532053
INFO:root:current train perplexity3.59716796875
INFO:root:current mean train loss 1458.8492331240775
INFO:root:current train perplexity3.6015212535858154
INFO:root:current mean train loss 1459.4232210825726
INFO:root:current train perplexity3.600928783416748
INFO:root:current mean train loss 1460.1907556357503
INFO:root:current train perplexity3.600693702697754
INFO:root:current mean train loss 1460.600694666358
INFO:root:current train perplexity3.603590488433838
INFO:root:current mean train loss 1460.3241758604308
INFO:root:current train perplexity3.6041970252990723
INFO:root:current mean train loss 1460.3179633529098
INFO:root:current train perplexity3.603315830230713
INFO:root:current mean train loss 1459.6704972348537
INFO:root:current train perplexity3.600754976272583
INFO:root:current mean train loss 1459.8219128367318
INFO:root:current train perplexity3.600612163543701

100%|██████████| 1/1 [05:35<00:00, 335.56s/it][A100%|██████████| 1/1 [05:35<00:00, 335.56s/it]
INFO:root:final mean train loss: 1458.7880125906631
INFO:root:final train perplexity: 3.600229263305664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.67s/it][A100%|██████████| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 1867.5312599560893
INFO:root:eval perplexity: 5.398571491241455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:15<00:00, 15.76s/it][A100%|██████████| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 2373.1077240206673
INFO:root:eval perplexity: 8.85252857208252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilgpt2_baseline/138
 69%|██████▉   | 138/200 [14:07:12<6:20:02, 367.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1428.8956814236112
INFO:root:current train perplexity3.5665948390960693
INFO:root:current mean train loss 1461.1803323679958
INFO:root:current train perplexity3.583444595336914
INFO:root:current mean train loss 1460.2314119300063
INFO:root:current train perplexity3.5896475315093994
INFO:root:current mean train loss 1462.4058024088542
INFO:root:current train perplexity3.5945281982421875
INFO:root:current mean train loss 1461.924485110165
INFO:root:current train perplexity3.5991156101226807
INFO:root:current mean train loss 1461.0591344430907
INFO:root:current train perplexity3.5883874893188477
INFO:root:current mean train loss 1461.0412056383236
INFO:root:current train perplexity3.5916202068328857
INFO:root:current mean train loss 1460.699058829698
INFO:root:current train perplexity3.593294382095337
INFO:root:current mean train loss 1461.050704251803
INFO:root:current train perplexity3.5944395065307617
INFO:root:current mean train loss 1460.4650304077795
INFO:root:current train perplexity3.5946850776672363
INFO:root:current mean train loss 1459.9390155408942
INFO:root:current train perplexity3.5931687355041504
INFO:root:current mean train loss 1458.5174691679176
INFO:root:current train perplexity3.591780424118042
INFO:root:current mean train loss 1457.9712165066517
INFO:root:current train perplexity3.5915157794952393
INFO:root:current mean train loss 1459.018074483765
INFO:root:current train perplexity3.59330415725708
INFO:root:current mean train loss 1459.9817458842451
INFO:root:current train perplexity3.5965628623962402
slurmstepd: error: *** JOB 30826745 ON gr043 CANCELLED AT 2023-03-08T13:14:07 ***
