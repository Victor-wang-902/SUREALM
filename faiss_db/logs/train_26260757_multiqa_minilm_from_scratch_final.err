INFO:root:Output: small_multiqa_minilm_from_scratch_final
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24865.727272727272
INFO:root:current train perplexity17183.275390625
INFO:root:current mean train loss 23993.219221105526
INFO:root:current train perplexity12342.92578125
INFO:root:current mean train loss 23043.003115854932
INFO:root:current train perplexity8636.3056640625
INFO:root:current mean train loss 22033.592345120614
INFO:root:current train perplexity5860.68408203125
INFO:root:current mean train loss 20949.69567455223
INFO:root:current train perplexity3864.9853515625
INFO:root:current mean train loss 19866.606978427586
INFO:root:current train perplexity2524.072998046875
INFO:root:current mean train loss 18861.721844543543
INFO:root:current train perplexity1699.303955078125
INFO:root:current mean train loss 17988.60731676314
INFO:root:current train perplexity1199.4000244140625
INFO:root:current mean train loss 17231.150576378266
INFO:root:current train perplexity889.8338012695312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.07s/it]
INFO:root:final mean train loss: 16599.966492683656
INFO:root:final train perplexity: 698.661376953125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.99s/it]
INFO:root:eval mean loss: 9976.691759474734
INFO:root:eval perplexity: 56.502296447753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.24s/it]
INFO:root:eval mean loss: 10268.254210992907
INFO:root:eval perplexity: 66.60839080810547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/1
  0%|          | 1/200 [02:45<9:07:45, 165.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10419.620814732143
INFO:root:current train perplexity61.234474182128906
INFO:root:current mean train loss 10155.187436112734
INFO:root:current train perplexity55.75228500366211
INFO:root:current mean train loss 9988.011176215277
INFO:root:current train perplexity51.5562629699707
INFO:root:current mean train loss 9822.40945961421
INFO:root:current train perplexity48.09531021118164
INFO:root:current mean train loss 9654.600283611026
INFO:root:current train perplexity45.125328063964844
INFO:root:current mean train loss 9512.711720483543
INFO:root:current train perplexity42.67033767700195
INFO:root:current mean train loss 9376.706629041391
INFO:root:current train perplexity40.4262809753418
INFO:root:current mean train loss 9263.57247557903
INFO:root:current train perplexity38.51620864868164
INFO:root:current mean train loss 9141.485371529392
INFO:root:current train perplexity36.78649139404297
INFO:root:current mean train loss 9035.545533437844
INFO:root:current train perplexity35.235015869140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.13s/it]
INFO:root:final mean train loss: 8943.169625066941
INFO:root:final train perplexity: 34.06734848022461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.34s/it]
INFO:root:eval mean loss: 7604.27625290891
INFO:root:eval perplexity: 21.64871597290039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 8071.869590813387
INFO:root:eval perplexity: 27.13158416748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/2
  1%|          | 2/200 [05:35<9:14:22, 167.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7987.075455729167
INFO:root:current train perplexity22.798847198486328
INFO:root:current mean train loss 7926.087240998641
INFO:root:current train perplexity22.482044219970703
INFO:root:current mean train loss 7861.4266805959305
INFO:root:current train perplexity21.887920379638672
INFO:root:current mean train loss 7770.364606584822
INFO:root:current train perplexity21.31136703491211
INFO:root:current mean train loss 7706.920219550076
INFO:root:current train perplexity20.806926727294922
INFO:root:current mean train loss 7650.399191254551
INFO:root:current train perplexity20.36130142211914
INFO:root:current mean train loss 7587.446993299034
INFO:root:current train perplexity19.939701080322266
INFO:root:current mean train loss 7534.453345580201
INFO:root:current train perplexity19.54251480102539
INFO:root:current mean train loss 7498.64237981691
INFO:root:current train perplexity19.206762313842773
INFO:root:current mean train loss 7455.146132172131
INFO:root:current train perplexity18.88062286376953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.86s/it]
INFO:root:final mean train loss: 7414.166081213182
INFO:root:final train perplexity: 18.636144638061523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it]
INFO:root:eval mean loss: 6659.420240469858
INFO:root:eval perplexity: 14.77407455444336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it]
INFO:root:eval mean loss: 7208.637054659796
INFO:root:eval perplexity: 19.06226921081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/3
  2%|â–         | 3/200 [08:22<9:11:14, 167.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6991.066236413043
INFO:root:current train perplexity15.579392433166504
INFO:root:current mean train loss 6935.666182355183
INFO:root:current train perplexity15.398371696472168
INFO:root:current mean train loss 6886.043665043441
INFO:root:current train perplexity15.183344841003418
INFO:root:current mean train loss 6846.686419129741
INFO:root:current train perplexity14.96504020690918
INFO:root:current mean train loss 6832.332415641622
INFO:root:current train perplexity14.789373397827148
INFO:root:current mean train loss 6803.015816391312
INFO:root:current train perplexity14.622227668762207
INFO:root:current mean train loss 6769.7088895402785
INFO:root:current train perplexity14.441864013671875
INFO:root:current mean train loss 6742.412842809907
INFO:root:current train perplexity14.288970947265625
INFO:root:current mean train loss 6718.378685544501
INFO:root:current train perplexity14.138562202453613
INFO:root:current mean train loss 6683.536388855972
INFO:root:current train perplexity13.963092803955078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.81s/it]
INFO:root:final mean train loss: 6666.654395934074
INFO:root:final train perplexity: 13.876378059387207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 6095.823522689495
INFO:root:eval perplexity: 11.763153076171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 6706.57559701906
INFO:root:eval perplexity: 15.524367332458496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/4
  2%|â–         | 4/200 [11:09<9:07:05, 167.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6345.481303553427
INFO:root:current train perplexity12.221299171447754
INFO:root:current mean train loss 6355.76754457896
INFO:root:current train perplexity12.264300346374512
INFO:root:current mean train loss 6361.405721557088
INFO:root:current train perplexity12.254424095153809
INFO:root:current mean train loss 6336.000138665974
INFO:root:current train perplexity12.117401123046875
INFO:root:current mean train loss 6318.3910589019
INFO:root:current train perplexity12.031911849975586
INFO:root:current mean train loss 6286.35312481609
INFO:root:current train perplexity11.892191886901855
INFO:root:current mean train loss 6265.880128113857
INFO:root:current train perplexity11.820964813232422
INFO:root:current mean train loss 6247.870664917493
INFO:root:current train perplexity11.731180191040039
INFO:root:current mean train loss 6226.924316993833
INFO:root:current train perplexity11.642642974853516
INFO:root:current mean train loss 6211.3621462976635
INFO:root:current train perplexity11.567842483520508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.30s/it]
INFO:root:final mean train loss: 6194.835975893082
INFO:root:final train perplexity: 11.519511222839355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5741.35381690492
INFO:root:eval perplexity: 10.192322731018066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it]
INFO:root:eval mean loss: 6397.073747783688
INFO:root:eval perplexity: 13.678853988647461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/5
  2%|â–Ž         | 5/200 [13:53<9:00:24, 166.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5979.9600986578525
INFO:root:current train perplexity10.484546661376953
INFO:root:current mean train loss 5950.087356677158
INFO:root:current train perplexity10.48181438446045
INFO:root:current mean train loss 5951.102755622385
INFO:root:current train perplexity10.455674171447754
INFO:root:current mean train loss 5947.866689136246
INFO:root:current train perplexity10.45859146118164
INFO:root:current mean train loss 5941.683714986119
INFO:root:current train perplexity10.404723167419434
INFO:root:current mean train loss 5927.136344612419
INFO:root:current train perplexity10.348554611206055
INFO:root:current mean train loss 5913.499213706719
INFO:root:current train perplexity10.30330753326416
INFO:root:current mean train loss 5900.9069880381
INFO:root:current train perplexity10.242143630981445
INFO:root:current mean train loss 5891.842272934669
INFO:root:current train perplexity10.20274829864502
INFO:root:current mean train loss 5878.534092327276
INFO:root:current train perplexity10.152228355407715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.59s/it]
INFO:root:final mean train loss: 5867.8488257623485
INFO:root:final train perplexity: 10.125288009643555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 5491.464123448582
INFO:root:eval perplexity: 9.212735176086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.93s/it]
INFO:root:eval mean loss: 6180.196528008643
INFO:root:eval perplexity: 12.517992973327637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/6
  3%|â–Ž         | 6/200 [16:33<8:50:43, 164.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5779.563673952793
INFO:root:current train perplexity9.62733268737793
INFO:root:current mean train loss 5767.697278911564
INFO:root:current train perplexity9.615959167480469
INFO:root:current mean train loss 5737.736173930921
INFO:root:current train perplexity9.513385772705078
INFO:root:current mean train loss 5716.041008589247
INFO:root:current train perplexity9.465882301330566
INFO:root:current mean train loss 5705.957224596267
INFO:root:current train perplexity9.433725357055664
INFO:root:current mean train loss 5681.241122564842
INFO:root:current train perplexity9.366374969482422
INFO:root:current mean train loss 5671.4181302526085
INFO:root:current train perplexity9.323723793029785
INFO:root:current mean train loss 5655.209548480379
INFO:root:current train perplexity9.281676292419434
INFO:root:current mean train loss 5644.36884661858
INFO:root:current train perplexity9.246468544006348
INFO:root:current mean train loss 5636.571034867509
INFO:root:current train perplexity9.223955154418945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.38s/it]
INFO:root:final mean train loss: 5628.7214805849135
INFO:root:final train perplexity: 9.213714599609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 5322.901706560284
INFO:root:eval perplexity: 8.60570240020752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 6048.743344137854
INFO:root:eval perplexity: 11.862879753112793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/7
  4%|â–Ž         | 7/200 [19:20<8:50:11, 164.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5540.688778409091
INFO:root:current train perplexity8.764540672302246
INFO:root:current mean train loss 5496.992272555443
INFO:root:current train perplexity8.748968124389648
INFO:root:current mean train loss 5478.025517003676
INFO:root:current train perplexity8.71114730834961
INFO:root:current mean train loss 5473.010200264084
INFO:root:current train perplexity8.677458763122559
INFO:root:current mean train loss 5476.34070548592
INFO:root:current train perplexity8.679442405700684
INFO:root:current mean train loss 5471.6581081081085
INFO:root:current train perplexity8.670751571655273
INFO:root:current mean train loss 5460.206457985449
INFO:root:current train perplexity8.628143310546875
INFO:root:current mean train loss 5450.992248939363
INFO:root:current train perplexity8.60290241241455
INFO:root:current mean train loss 5449.781221445541
INFO:root:current train perplexity8.590476989746094
INFO:root:current mean train loss 5446.10971705252
INFO:root:current train perplexity8.56641674041748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 138.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 138.00s/it]
INFO:root:final mean train loss: 5442.7317952802105
INFO:root:final train perplexity: 8.561841011047363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 5157.724813691268
INFO:root:eval perplexity: 8.049681663513184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 5894.561706975842
INFO:root:eval perplexity: 11.13805103302002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/8
  4%|â–         | 8/200 [22:01<8:44:18, 163.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5356.442708333333
INFO:root:current train perplexity8.236146926879883
INFO:root:current mean train loss 5362.0957660324
INFO:root:current train perplexity8.24052906036377
INFO:root:current mean train loss 5340.945405329135
INFO:root:current train perplexity8.204853057861328
INFO:root:current mean train loss 5334.547953792183
INFO:root:current train perplexity8.207919120788574
INFO:root:current mean train loss 5340.234555337135
INFO:root:current train perplexity8.195042610168457
INFO:root:current mean train loss 5325.405564845138
INFO:root:current train perplexity8.155348777770996
INFO:root:current mean train loss 5322.57296232796
INFO:root:current train perplexity8.14622974395752
INFO:root:current mean train loss 5313.849139652277
INFO:root:current train perplexity8.122103691101074
INFO:root:current mean train loss 5309.792465192279
INFO:root:current train perplexity8.106903076171875
INFO:root:current mean train loss 5299.94018123702
INFO:root:current train perplexity8.080329895019531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.67s/it]
INFO:root:final mean train loss: 5294.731628541023
INFO:root:final train perplexity: 8.076227188110352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it]
INFO:root:eval mean loss: 5039.073436114805
INFO:root:eval perplexity: 7.672585964202881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it]
INFO:root:eval mean loss: 5794.810467226285
INFO:root:eval perplexity: 10.692874908447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/9
  4%|â–         | 9/200 [24:45<8:41:15, 163.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5177.270535321303
INFO:root:current train perplexity7.787250518798828
INFO:root:current mean train loss 5194.664442274306
INFO:root:current train perplexity7.808908462524414
INFO:root:current mean train loss 5191.006001715291
INFO:root:current train perplexity7.778929710388184
INFO:root:current mean train loss 5197.4841696849735
INFO:root:current train perplexity7.784454822540283
INFO:root:current mean train loss 5198.515903869758
INFO:root:current train perplexity7.780651092529297
INFO:root:current mean train loss 5196.5787988452275
INFO:root:current train perplexity7.767982006072998
INFO:root:current mean train loss 5187.552716182703
INFO:root:current train perplexity7.738419055938721
INFO:root:current mean train loss 5184.059021233585
INFO:root:current train perplexity7.7283501625061035
INFO:root:current mean train loss 5179.2957459547215
INFO:root:current train perplexity7.703680515289307
INFO:root:current mean train loss 5174.9495843323575
INFO:root:current train perplexity7.690823554992676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.82s/it]
INFO:root:final mean train loss: 5171.201011719242
INFO:root:final train perplexity: 7.692059516906738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.55s/it]
INFO:root:eval mean loss: 4946.980839289672
INFO:root:eval perplexity: 7.392115116119385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.23s/it]
INFO:root:eval mean loss: 5719.799534574468
INFO:root:eval perplexity: 10.369871139526367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/10
  5%|â–Œ         | 10/200 [27:30<8:39:23, 164.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5028.102026058149
INFO:root:current train perplexity7.439098358154297
INFO:root:current mean train loss 5097.932360771648
INFO:root:current train perplexity7.462721347808838
INFO:root:current mean train loss 5104.0233499944
INFO:root:current train perplexity7.467489242553711
INFO:root:current mean train loss 5103.310041845317
INFO:root:current train perplexity7.458953857421875
INFO:root:current mean train loss 5097.531400867693
INFO:root:current train perplexity7.443732261657715
INFO:root:current mean train loss 5089.079860548899
INFO:root:current train perplexity7.428623676300049
INFO:root:current mean train loss 5087.628050499356
INFO:root:current train perplexity7.426434516906738
INFO:root:current mean train loss 5085.392974892691
INFO:root:current train perplexity7.416069984436035
INFO:root:current mean train loss 5077.63922626031
INFO:root:current train perplexity7.398993492126465
INFO:root:current mean train loss 5072.3900658955245
INFO:root:current train perplexity7.385735988616943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.08s/it]
INFO:root:final mean train loss: 5067.740782583914
INFO:root:final train perplexity: 7.384404182434082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it]
INFO:root:eval mean loss: 4864.260461685505
INFO:root:eval perplexity: 7.148939609527588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.13s/it]
INFO:root:eval mean loss: 5649.8966436724295
INFO:root:eval perplexity: 10.077652931213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/11
  6%|â–Œ         | 11/200 [30:17<8:40:26, 165.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5061.313706672055
INFO:root:current train perplexity7.228973865509033
INFO:root:current mean train loss 5035.557899189505
INFO:root:current train perplexity7.224379539489746
INFO:root:current mean train loss 5022.693075253158
INFO:root:current train perplexity7.188724040985107
INFO:root:current mean train loss 5008.128279180798
INFO:root:current train perplexity7.175393581390381
INFO:root:current mean train loss 5005.346955410999
INFO:root:current train perplexity7.178178310394287
INFO:root:current mean train loss 5001.171764367281
INFO:root:current train perplexity7.170248508453369
INFO:root:current mean train loss 4994.562367090839
INFO:root:current train perplexity7.156240463256836
INFO:root:current mean train loss 4988.96681921061
INFO:root:current train perplexity7.143776893615723
INFO:root:current mean train loss 4982.593555127889
INFO:root:current train perplexity7.129233360290527
INFO:root:current mean train loss 4981.689489733726
INFO:root:current train perplexity7.127126693725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.89s/it]
INFO:root:final mean train loss: 4977.540074317686
INFO:root:final train perplexity: 7.12623929977417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 4795.85950313054
INFO:root:eval perplexity: 6.953915119171143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 5588.775916999113
INFO:root:eval perplexity: 9.828901290893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/12
  6%|â–Œ         | 12/200 [32:59<8:34:36, 164.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4915.684097450658
INFO:root:current train perplexity7.0009870529174805
INFO:root:current mean train loss 4906.430969551282
INFO:root:current train perplexity6.950881004333496
INFO:root:current mean train loss 4915.258044226695
INFO:root:current train perplexity6.949285984039307
INFO:root:current mean train loss 4916.219386619858
INFO:root:current train perplexity6.9464850425720215
INFO:root:current mean train loss 4913.941853101326
INFO:root:current train perplexity6.94288444519043
INFO:root:current mean train loss 4909.863924632353
INFO:root:current train perplexity6.940468788146973
INFO:root:current mean train loss 4912.563633936601
INFO:root:current train perplexity6.934065818786621
INFO:root:current mean train loss 4910.995742433176
INFO:root:current train perplexity6.929140090942383
INFO:root:current mean train loss 4905.764254539106
INFO:root:current train perplexity6.919520854949951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.09s/it]
INFO:root:final mean train loss: 4899.247684847924
INFO:root:final train perplexity: 6.909482955932617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it]
INFO:root:eval mean loss: 4737.271193484043
INFO:root:eval perplexity: 6.791102409362793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it]
INFO:root:eval mean loss: 5539.579506732048
INFO:root:eval perplexity: 9.633151054382324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/13
  6%|â–‹         | 13/200 [35:41<8:29:46, 163.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4535.78564453125
INFO:root:current train perplexity6.373170852661133
INFO:root:current mean train loss 4794.1515046647455
INFO:root:current train perplexity6.685624122619629
INFO:root:current mean train loss 4806.056219692888
INFO:root:current train perplexity6.70878791809082
INFO:root:current mean train loss 4845.505182549505
INFO:root:current train perplexity6.7483415603637695
INFO:root:current mean train loss 4836.901614357165
INFO:root:current train perplexity6.741330146789551
INFO:root:current mean train loss 4836.764450406933
INFO:root:current train perplexity6.738072872161865
INFO:root:current mean train loss 4837.931800956157
INFO:root:current train perplexity6.733563423156738
INFO:root:current mean train loss 4839.8225406738975
INFO:root:current train perplexity6.7292938232421875
INFO:root:current mean train loss 4836.007386242022
INFO:root:current train perplexity6.727587699890137
INFO:root:current mean train loss 4836.863420218197
INFO:root:current train perplexity6.7292799949646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.67s/it]
INFO:root:final mean train loss: 4830.449239792362
INFO:root:final train perplexity: 6.724463939666748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.59s/it]
INFO:root:eval mean loss: 4683.239621426197
INFO:root:eval perplexity: 6.644334316253662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it]
INFO:root:eval mean loss: 5495.981677332668
INFO:root:eval perplexity: 9.462933540344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/14
  7%|â–‹         | 14/200 [38:26<8:28:00, 163.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4805.725807883523
INFO:root:current train perplexity6.702199459075928
INFO:root:current mean train loss 4798.329026780687
INFO:root:current train perplexity6.624505043029785
INFO:root:current mean train loss 4782.3157212677725
INFO:root:current train perplexity6.607550621032715
INFO:root:current mean train loss 4794.982603999196
INFO:root:current train perplexity6.618744373321533
INFO:root:current mean train loss 4785.271963151992
INFO:root:current train perplexity6.6032843589782715
INFO:root:current mean train loss 4782.943380396893
INFO:root:current train perplexity6.593518257141113
INFO:root:current mean train loss 4778.035375217369
INFO:root:current train perplexity6.587488174438477
INFO:root:current mean train loss 4774.598164447081
INFO:root:current train perplexity6.578826904296875
INFO:root:current mean train loss 4771.069842581978
INFO:root:current train perplexity6.571372032165527
INFO:root:current mean train loss 4772.020523892014
INFO:root:current train perplexity6.568882942199707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.64s/it]
INFO:root:final mean train loss: 4770.4340405617995
INFO:root:final train perplexity: 6.567112445831299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4637.664097129876
INFO:root:eval perplexity: 6.523005485534668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it]
INFO:root:eval mean loss: 5463.0311945921985
INFO:root:eval perplexity: 9.336284637451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/15
  8%|â–Š         | 15/200 [41:34<8:47:27, 171.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4635.6697419819075
INFO:root:current train perplexity6.346646308898926
INFO:root:current mean train loss 4702.752642463235
INFO:root:current train perplexity6.443777561187744
INFO:root:current mean train loss 4712.751716787957
INFO:root:current train perplexity6.427562236785889
INFO:root:current mean train loss 4717.930327316811
INFO:root:current train perplexity6.422133445739746
INFO:root:current mean train loss 4714.506330176015
INFO:root:current train perplexity6.417064189910889
INFO:root:current mean train loss 4722.641367300397
INFO:root:current train perplexity6.425734519958496
INFO:root:current mean train loss 4721.701887337187
INFO:root:current train perplexity6.428225994110107
INFO:root:current mean train loss 4719.809966913682
INFO:root:current train perplexity6.423361778259277
INFO:root:current mean train loss 4719.954152835012
INFO:root:current train perplexity6.4278693199157715
INFO:root:current mean train loss 4720.612775966573
INFO:root:current train perplexity6.424001693725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it]
INFO:root:final mean train loss: 4713.857298204975
INFO:root:final train perplexity: 6.4221510887146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4597.253424894725
INFO:root:eval perplexity: 6.417280197143555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 5429.357169076906
INFO:root:eval perplexity: 9.208608627319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/16
  8%|â–Š         | 16/200 [44:23<8:43:16, 170.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4685.605161313658
INFO:root:current train perplexity6.341894149780273
INFO:root:current mean train loss 4666.596174104946
INFO:root:current train perplexity6.301779747009277
INFO:root:current mean train loss 4684.976621653015
INFO:root:current train perplexity6.315349578857422
INFO:root:current mean train loss 4695.396395528717
INFO:root:current train perplexity6.33945894241333
INFO:root:current mean train loss 4681.968496711249
INFO:root:current train perplexity6.3312530517578125
INFO:root:current mean train loss 4674.159197754832
INFO:root:current train perplexity6.321706771850586
INFO:root:current mean train loss 4673.21531684547
INFO:root:current train perplexity6.31110143661499
INFO:root:current mean train loss 4672.048630999076
INFO:root:current train perplexity6.311280250549316
INFO:root:current mean train loss 4669.941255396482
INFO:root:current train perplexity6.303862571716309
INFO:root:current mean train loss 4668.777173878691
INFO:root:current train perplexity6.297909259796143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.32s/it]
INFO:root:final mean train loss: 4663.279762944868
INFO:root:final train perplexity: 6.295271396636963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it]
INFO:root:eval mean loss: 4559.931652745457
INFO:root:eval perplexity: 6.3211588859558105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it]
INFO:root:eval mean loss: 5393.420939993351
INFO:root:eval perplexity: 9.074280738830566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/17
  8%|â–Š         | 17/200 [47:07<8:33:30, 168.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4624.2100864955355
INFO:root:current train perplexity6.095941066741943
INFO:root:current mean train loss 4616.7212890625
INFO:root:current train perplexity6.159030437469482
INFO:root:current mean train loss 4613.936065284242
INFO:root:current train perplexity6.164787292480469
INFO:root:current mean train loss 4611.0077592992075
INFO:root:current train perplexity6.154656887054443
INFO:root:current mean train loss 4621.916146394577
INFO:root:current train perplexity6.1681671142578125
INFO:root:current mean train loss 4625.542738299503
INFO:root:current train perplexity6.185962200164795
INFO:root:current mean train loss 4623.507486082062
INFO:root:current train perplexity6.188358306884766
INFO:root:current mean train loss 4626.172954533376
INFO:root:current train perplexity6.1887125968933105
INFO:root:current mean train loss 4627.80194727732
INFO:root:current train perplexity6.190304756164551
INFO:root:current mean train loss 4624.1495023186835
INFO:root:current train perplexity6.187266826629639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.42s/it]
INFO:root:final mean train loss: 4617.629665067119
INFO:root:final train perplexity: 6.182906150817871
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.08s/it]
INFO:root:eval mean loss: 4533.296597960993
INFO:root:eval perplexity: 6.253443241119385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.96s/it]
INFO:root:eval mean loss: 5379.584463998781
INFO:root:eval perplexity: 9.02308177947998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/18
  9%|â–‰         | 18/200 [49:49<8:25:20, 166.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4551.422925372456
INFO:root:current train perplexity5.9695048332214355
INFO:root:current mean train loss 4577.721954559112
INFO:root:current train perplexity6.073991775512695
INFO:root:current mean train loss 4584.351220904064
INFO:root:current train perplexity6.091500282287598
INFO:root:current mean train loss 4597.2722609272505
INFO:root:current train perplexity6.091753959655762
INFO:root:current mean train loss 4593.007635043383
INFO:root:current train perplexity6.082805156707764
INFO:root:current mean train loss 4583.9570914983315
INFO:root:current train perplexity6.076920509338379
INFO:root:current mean train loss 4577.447124000656
INFO:root:current train perplexity6.07329797744751
INFO:root:current mean train loss 4577.917098978487
INFO:root:current train perplexity6.079464435577393
INFO:root:current mean train loss 4579.6994142362655
INFO:root:current train perplexity6.082525253295898
INFO:root:current mean train loss 4580.453007719297
INFO:root:current train perplexity6.084474563598633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.88s/it]
INFO:root:final mean train loss: 4575.944860889065
INFO:root:final train perplexity: 6.08205509185791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it]
INFO:root:eval mean loss: 4498.069348057957
INFO:root:eval perplexity: 6.164995193481445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it]
INFO:root:eval mean loss: 5343.992457613032
INFO:root:eval perplexity: 8.89271068572998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/19
 10%|â–‰         | 19/200 [52:35<8:21:45, 166.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4537.041896446079
INFO:root:current train perplexity5.948668003082275
INFO:root:current mean train loss 4497.213275429429
INFO:root:current train perplexity5.9358720779418945
INFO:root:current mean train loss 4522.589007252241
INFO:root:current train perplexity5.958785057067871
INFO:root:current mean train loss 4519.887031055244
INFO:root:current train perplexity5.961370944976807
INFO:root:current mean train loss 4527.635434711059
INFO:root:current train perplexity5.97321891784668
INFO:root:current mean train loss 4537.828269003091
INFO:root:current train perplexity5.987894535064697
INFO:root:current mean train loss 4539.8528818344375
INFO:root:current train perplexity5.991264820098877
INFO:root:current mean train loss 4541.630233906874
INFO:root:current train perplexity5.993325710296631
INFO:root:current mean train loss 4539.435392243041
INFO:root:current train perplexity5.991568088531494
INFO:root:current mean train loss 4540.361509112529
INFO:root:current train perplexity5.9892778396606445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.42s/it]
INFO:root:final mean train loss: 4537.073082216324
INFO:root:final train perplexity: 5.989492416381836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 4466.340695644947
INFO:root:eval perplexity: 6.086401462554932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.89s/it]
INFO:root:eval mean loss: 5314.235457183621
INFO:root:eval perplexity: 8.785160064697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/20
 10%|â–ˆ         | 20/200 [55:53<8:47:44, 175.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4503.220607951536
INFO:root:current train perplexity5.886219024658203
INFO:root:current mean train loss 4511.269138168239
INFO:root:current train perplexity5.910200595855713
INFO:root:current mean train loss 4509.171836352256
INFO:root:current train perplexity5.907900810241699
INFO:root:current mean train loss 4510.348016680449
INFO:root:current train perplexity5.913593769073486
INFO:root:current mean train loss 4508.893898292824
INFO:root:current train perplexity5.915502548217773
INFO:root:current mean train loss 4506.291617023284
INFO:root:current train perplexity5.9100799560546875
INFO:root:current mean train loss 4506.75538739449
INFO:root:current train perplexity5.906862735748291
INFO:root:current mean train loss 4510.101627475502
INFO:root:current train perplexity5.908519744873047
INFO:root:current mean train loss 4509.062440883295
INFO:root:current train perplexity5.90717887878418
INFO:root:current mean train loss 4506.557324167834
INFO:root:current train perplexity5.904644966125488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.55s/it]
INFO:root:final mean train loss: 4500.853669935657
INFO:root:final train perplexity: 5.904513359069824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it]
INFO:root:eval mean loss: 4448.491619570035
INFO:root:eval perplexity: 6.042631149291992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.23s/it]
INFO:root:eval mean loss: 5306.603891359154
INFO:root:eval perplexity: 8.75778579711914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/21
 10%|â–ˆ         | 21/200 [58:36<8:33:16, 172.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4464.686618178638
INFO:root:current train perplexity5.8037543296813965
INFO:root:current mean train loss 4451.447601866579
INFO:root:current train perplexity5.807855606079102
INFO:root:current mean train loss 4459.156308520599
INFO:root:current train perplexity5.810975551605225
INFO:root:current mean train loss 4465.958254614058
INFO:root:current train perplexity5.813467979431152
INFO:root:current mean train loss 4467.026918202958
INFO:root:current train perplexity5.816755771636963
INFO:root:current mean train loss 4470.478315403852
INFO:root:current train perplexity5.82660436630249
INFO:root:current mean train loss 4468.771003780336
INFO:root:current train perplexity5.8272385597229
INFO:root:current mean train loss 4469.700450912137
INFO:root:current train perplexity5.826691150665283
INFO:root:current mean train loss 4471.988739119269
INFO:root:current train perplexity5.826179027557373
INFO:root:current mean train loss 4470.874201177934
INFO:root:current train perplexity5.823627948760986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.23s/it]
INFO:root:final mean train loss: 4466.147229840679
INFO:root:final train perplexity: 5.824215412139893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it]
INFO:root:eval mean loss: 4427.124111743684
INFO:root:eval perplexity: 5.990644931793213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it]
INFO:root:eval mean loss: 5288.979874847629
INFO:root:eval perplexity: 8.694900512695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/22
 11%|â–ˆ         | 22/200 [1:01:19<8:22:30, 169.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4405.3841341145835
INFO:root:current train perplexity5.7538652420043945
INFO:root:current mean train loss 4398.387328404018
INFO:root:current train perplexity5.737775802612305
INFO:root:current mean train loss 4428.7220596590905
INFO:root:current train perplexity5.757425785064697
INFO:root:current mean train loss 4426.786728515625
INFO:root:current train perplexity5.737524032592773
INFO:root:current mean train loss 4432.448734580592
INFO:root:current train perplexity5.7517008781433105
INFO:root:current mean train loss 4431.0077683423915
INFO:root:current train perplexity5.752338409423828
INFO:root:current mean train loss 4434.528497540509
INFO:root:current train perplexity5.7514190673828125
INFO:root:current mean train loss 4436.537435735887
INFO:root:current train perplexity5.748660087585449
INFO:root:current mean train loss 4436.825101841518
INFO:root:current train perplexity5.746676445007324
INFO:root:current mean train loss 4438.412722355769
INFO:root:current train perplexity5.7531046867370605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.96s/it]
INFO:root:final mean train loss: 4435.260398372527
INFO:root:final train perplexity: 5.753673076629639
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it]
INFO:root:eval mean loss: 4412.943224318484
INFO:root:eval perplexity: 5.956390857696533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it]
INFO:root:eval mean loss: 5281.208574010971
INFO:root:eval perplexity: 8.667312622070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/23
 12%|â–ˆâ–        | 23/200 [1:04:06<8:17:31, 168.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4383.536697571536
INFO:root:current train perplexity5.657289028167725
INFO:root:current mean train loss 4398.009237320697
INFO:root:current train perplexity5.660550117492676
INFO:root:current mean train loss 4413.217242021864
INFO:root:current train perplexity5.680367469787598
INFO:root:current mean train loss 4413.237082219933
INFO:root:current train perplexity5.68317985534668
INFO:root:current mean train loss 4411.554385736122
INFO:root:current train perplexity5.685547351837158
INFO:root:current mean train loss 4406.885290338899
INFO:root:current train perplexity5.681145191192627
INFO:root:current mean train loss 4405.902167525508
INFO:root:current train perplexity5.685311794281006
INFO:root:current mean train loss 4409.818256792285
INFO:root:current train perplexity5.687770843505859
INFO:root:current mean train loss 4408.430436787762
INFO:root:current train perplexity5.689206123352051
INFO:root:current mean train loss 4409.743446450995
INFO:root:current train perplexity5.688201427459717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.36s/it]
INFO:root:final mean train loss: 4406.353553525863
INFO:root:final train perplexity: 5.68842887878418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it]
INFO:root:eval mean loss: 4398.082690949135
INFO:root:eval perplexity: 5.920703887939453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it]
INFO:root:eval mean loss: 5275.456072002438
INFO:root:eval perplexity: 8.64694881439209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/24
 12%|â–ˆâ–        | 24/200 [1:07:24<8:40:52, 177.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4390.226688594608
INFO:root:current train perplexity5.610279560089111
INFO:root:current mean train loss 4369.298233751227
INFO:root:current train perplexity5.599504470825195
INFO:root:current mean train loss 4366.9278895846755
INFO:root:current train perplexity5.593348503112793
INFO:root:current mean train loss 4370.207405890345
INFO:root:current train perplexity5.592012405395508
INFO:root:current mean train loss 4387.136728197397
INFO:root:current train perplexity5.614501476287842
INFO:root:current mean train loss 4378.006525701275
INFO:root:current train perplexity5.6084699630737305
INFO:root:current mean train loss 4377.321190840946
INFO:root:current train perplexity5.613084316253662
INFO:root:current mean train loss 4380.351802936848
INFO:root:current train perplexity5.61644983291626
INFO:root:current mean train loss 4377.636635999755
INFO:root:current train perplexity5.617276191711426
INFO:root:current mean train loss 4380.5467594581705
INFO:root:current train perplexity5.623046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.75s/it]
INFO:root:final mean train loss: 4377.206690142231
INFO:root:final train perplexity: 5.623389720916748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]
INFO:root:eval mean loss: 4369.600542650155
INFO:root:eval perplexity: 5.852906703948975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.94s/it]
INFO:root:eval mean loss: 5246.379720052083
INFO:root:eval perplexity: 8.544748306274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/25
 12%|â–ˆâ–Ž        | 25/200 [1:10:05<8:22:36, 172.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4292.570714468908
INFO:root:current train perplexity5.498753547668457
INFO:root:current mean train loss 4325.602411471419
INFO:root:current train perplexity5.538480281829834
INFO:root:current mean train loss 4338.7938105860685
INFO:root:current train perplexity5.545673370361328
INFO:root:current mean train loss 4336.188475338738
INFO:root:current train perplexity5.5474677085876465
INFO:root:current mean train loss 4339.311161385271
INFO:root:current train perplexity5.550516605377197
INFO:root:current mean train loss 4340.595037138721
INFO:root:current train perplexity5.551969528198242
INFO:root:current mean train loss 4345.869394894492
INFO:root:current train perplexity5.55793571472168
INFO:root:current mean train loss 4347.73074589086
INFO:root:current train perplexity5.560572624206543
INFO:root:current mean train loss 4350.90013915201
INFO:root:current train perplexity5.563771724700928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.93s/it]
INFO:root:final mean train loss: 4350.813398176624
INFO:root:final train perplexity: 5.565138339996338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4352.196822362589
INFO:root:eval perplexity: 5.811858654022217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it]
INFO:root:eval mean loss: 5231.347947140957
INFO:root:eval perplexity: 8.492387771606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/26
 13%|â–ˆâ–Ž        | 26/200 [1:12:47<8:10:52, 169.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4277.364885602678
INFO:root:current train perplexity5.475363254547119
INFO:root:current mean train loss 4305.635046272634
INFO:root:current train perplexity5.469272136688232
INFO:root:current mean train loss 4322.466366385492
INFO:root:current train perplexity5.48280143737793
INFO:root:current mean train loss 4324.716220321407
INFO:root:current train perplexity5.494775772094727
INFO:root:current mean train loss 4326.990517506142
INFO:root:current train perplexity5.5037970542907715
INFO:root:current mean train loss 4328.216559475931
INFO:root:current train perplexity5.504868030548096
INFO:root:current mean train loss 4329.5985061167885
INFO:root:current train perplexity5.510614395141602
INFO:root:current mean train loss 4327.467526879641
INFO:root:current train perplexity5.509838581085205
INFO:root:current mean train loss 4329.25367663075
INFO:root:current train perplexity5.5059685707092285
INFO:root:current mean train loss 4331.178443917103
INFO:root:current train perplexity5.509498596191406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.27s/it]
INFO:root:final mean train loss: 4325.90385172444
INFO:root:final train perplexity: 5.510713577270508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 4341.076966630651
INFO:root:eval perplexity: 5.78578519821167
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.52s/it]
INFO:root:eval mean loss: 5227.218961242243
INFO:root:eval perplexity: 8.478062629699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/27
 14%|â–ˆâ–Ž        | 27/200 [1:15:26<7:59:21, 166.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4257.033072916666
INFO:root:current train perplexity5.4436726570129395
INFO:root:current mean train loss 4288.447025730299
INFO:root:current train perplexity5.439408779144287
INFO:root:current mean train loss 4299.001594295059
INFO:root:current train perplexity5.450697422027588
INFO:root:current mean train loss 4310.828786117311
INFO:root:current train perplexity5.45432710647583
INFO:root:current mean train loss 4304.686572265625
INFO:root:current train perplexity5.455173492431641
INFO:root:current mean train loss 4304.407717214047
INFO:root:current train perplexity5.4533538818359375
INFO:root:current mean train loss 4307.30031996316
INFO:root:current train perplexity5.45661735534668
INFO:root:current mean train loss 4309.307018616149
INFO:root:current train perplexity5.460167407989502
INFO:root:current mean train loss 4309.128717827358
INFO:root:current train perplexity5.45913553237915
INFO:root:current mean train loss 4309.103990565232
INFO:root:current train perplexity5.462581157684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.98s/it]
INFO:root:final mean train loss: 4302.621346196821
INFO:root:final train perplexity: 5.4603271484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.92s/it]
INFO:root:eval mean loss: 4328.015555740249
INFO:root:eval perplexity: 5.755307197570801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it]
INFO:root:eval mean loss: 5211.969193262411
INFO:root:eval perplexity: 8.4253568649292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/28
 14%|â–ˆâ–        | 28/200 [1:18:36<8:16:38, 173.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4213.999129585598
INFO:root:current train perplexity5.333372116088867
INFO:root:current mean train loss 4237.536740186738
INFO:root:current train perplexity5.37432336807251
INFO:root:current mean train loss 4267.964516404499
INFO:root:current train perplexity5.397352695465088
INFO:root:current mean train loss 4274.148036141883
INFO:root:current train perplexity5.409916877746582
INFO:root:current mean train loss 4273.990746319999
INFO:root:current train perplexity5.4112772941589355
INFO:root:current mean train loss 4274.547906645853
INFO:root:current train perplexity5.412032127380371
INFO:root:current mean train loss 4272.249939258753
INFO:root:current train perplexity5.406444072723389
INFO:root:current mean train loss 4279.874382388378
INFO:root:current train perplexity5.406886577606201
INFO:root:current mean train loss 4279.033334539698
INFO:root:current train perplexity5.40711784362793
INFO:root:current mean train loss 4282.153432463773
INFO:root:current train perplexity5.412303447723389

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.50s/it]
INFO:root:final mean train loss: 4279.008128196962
INFO:root:final train perplexity: 5.409693717956543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it]
INFO:root:eval mean loss: 4312.675722379211
INFO:root:eval perplexity: 5.719717025756836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.55s/it]
INFO:root:eval mean loss: 5200.202735413896
INFO:root:eval perplexity: 8.384915351867676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/29
 14%|â–ˆâ–        | 29/200 [1:21:19<8:05:04, 170.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4281.758600050403
INFO:root:current train perplexity5.403223514556885
INFO:root:current mean train loss 4273.307087905534
INFO:root:current train perplexity5.386126518249512
INFO:root:current mean train loss 4259.819900314529
INFO:root:current train perplexity5.372664928436279
INFO:root:current mean train loss 4269.97082187618
INFO:root:current train perplexity5.382759094238281
INFO:root:current mean train loss 4266.626824540494
INFO:root:current train perplexity5.379951000213623
INFO:root:current mean train loss 4260.70766573976
INFO:root:current train perplexity5.374185562133789
INFO:root:current mean train loss 4263.630039511317
INFO:root:current train perplexity5.36869478225708
INFO:root:current mean train loss 4260.689022956566
INFO:root:current train perplexity5.367151260375977
INFO:root:current mean train loss 4260.8592786364325
INFO:root:current train perplexity5.365083694458008
INFO:root:current mean train loss 4260.633356899503
INFO:root:current train perplexity5.362992286682129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.58s/it]
INFO:root:final mean train loss: 4257.2600156107255
INFO:root:final train perplexity: 5.363476276397705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it]
INFO:root:eval mean loss: 4298.26839019559
INFO:root:eval perplexity: 5.686491966247559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it]
INFO:root:eval mean loss: 5187.730297332115
INFO:root:eval perplexity: 8.34226131439209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/30
 15%|â–ˆâ–Œ        | 30/200 [1:24:39<8:28:07, 179.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4234.3331956129805
INFO:root:current train perplexity5.346285343170166
INFO:root:current mean train loss 4238.980665467626
INFO:root:current train perplexity5.330044269561768
INFO:root:current mean train loss 4227.925310334401
INFO:root:current train perplexity5.305525779724121
INFO:root:current mean train loss 4234.394915105319
INFO:root:current train perplexity5.300531387329102
INFO:root:current mean train loss 4237.433521453232
INFO:root:current train perplexity5.307625770568848
INFO:root:current mean train loss 4237.5497181738465
INFO:root:current train perplexity5.311962604522705
INFO:root:current mean train loss 4237.292755174712
INFO:root:current train perplexity5.3142781257629395
INFO:root:current mean train loss 4239.134483492261
INFO:root:current train perplexity5.316609859466553
INFO:root:current mean train loss 4238.738073774117
INFO:root:current train perplexity5.3160529136657715
INFO:root:current mean train loss 4239.430481542033
INFO:root:current train perplexity5.31912088394165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.05s/it]
INFO:root:final mean train loss: 4236.805261919575
INFO:root:final train perplexity: 5.320366859436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 4291.077427208001
INFO:root:eval perplexity: 5.669980049133301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it]
INFO:root:eval mean loss: 5187.545687195257
INFO:root:eval perplexity: 8.341630935668945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/31
 16%|â–ˆâ–Œ        | 31/200 [1:27:27<8:15:24, 175.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4211.775847739362
INFO:root:current train perplexity5.25222635269165
INFO:root:current mean train loss 4216.241654376594
INFO:root:current train perplexity5.270960330963135
INFO:root:current mean train loss 4219.374659982287
INFO:root:current train perplexity5.274035453796387
INFO:root:current mean train loss 4210.03767223523
INFO:root:current train perplexity5.271833896636963
INFO:root:current mean train loss 4209.057377962458
INFO:root:current train perplexity5.26430606842041
INFO:root:current mean train loss 4212.741468914248
INFO:root:current train perplexity5.267307758331299
INFO:root:current mean train loss 4217.223286789388
INFO:root:current train perplexity5.2723002433776855
INFO:root:current mean train loss 4220.866375985714
INFO:root:current train perplexity5.2760539054870605
INFO:root:current mean train loss 4219.79133326723
INFO:root:current train perplexity5.274848461151123
INFO:root:current mean train loss 4219.187504124868
INFO:root:current train perplexity5.276325702667236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.03s/it]
INFO:root:final mean train loss: 4216.329674628473
INFO:root:final train perplexity: 5.277561187744141
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 4283.478900016622
INFO:root:eval perplexity: 5.652585029602051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.27s/it]
INFO:root:eval mean loss: 5181.120361328125
INFO:root:eval perplexity: 8.319743156433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/32
 16%|â–ˆâ–Œ        | 32/200 [1:30:08<7:59:41, 171.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4177.315194424716
INFO:root:current train perplexity5.204564571380615
INFO:root:current mean train loss 4183.722446761592
INFO:root:current train perplexity5.2281999588012695
INFO:root:current mean train loss 4193.744679649203
INFO:root:current train perplexity5.233027458190918
INFO:root:current mean train loss 4192.379481871699
INFO:root:current train perplexity5.221012115478516
INFO:root:current mean train loss 4190.54860973987
INFO:root:current train perplexity5.22166109085083
INFO:root:current mean train loss 4192.221364284206
INFO:root:current train perplexity5.225519180297852
INFO:root:current mean train loss 4199.698856825501
INFO:root:current train perplexity5.237943649291992
INFO:root:current mean train loss 4199.322157621068
INFO:root:current train perplexity5.240395545959473
INFO:root:current mean train loss 4198.165420550073
INFO:root:current train perplexity5.234625339508057
INFO:root:current mean train loss 4196.317876973577
INFO:root:current train perplexity5.233013153076172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:18<00:00, 138.14s/it]
INFO:root:final mean train loss: 4197.033606929163
INFO:root:final train perplexity: 5.237536430358887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it]
INFO:root:eval mean loss: 4270.529612006871
INFO:root:eval perplexity: 5.62306547164917
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.43s/it]
INFO:root:eval mean loss: 5169.950844622673
INFO:root:eval perplexity: 8.281827926635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/33
 16%|â–ˆâ–‹        | 33/200 [1:32:49<7:48:01, 168.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4182.545882936508
INFO:root:current train perplexity5.182584762573242
INFO:root:current mean train loss 4173.1894036977565
INFO:root:current train perplexity5.17534065246582
INFO:root:current mean train loss 4171.573909628981
INFO:root:current train perplexity5.188967704772949
INFO:root:current mean train loss 4170.076540439911
INFO:root:current train perplexity5.180818557739258
INFO:root:current mean train loss 4175.17545115922
INFO:root:current train perplexity5.187726020812988
INFO:root:current mean train loss 4171.478935824406
INFO:root:current train perplexity5.189420700073242
INFO:root:current mean train loss 4176.229052145197
INFO:root:current train perplexity5.193124294281006
INFO:root:current mean train loss 4180.491885443971
INFO:root:current train perplexity5.1946611404418945
INFO:root:current mean train loss 4180.655448268214
INFO:root:current train perplexity5.196866035461426
INFO:root:current mean train loss 4182.478000470534
INFO:root:current train perplexity5.2011494636535645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.72s/it]
INFO:root:final mean train loss: 4179.304928687311
INFO:root:final train perplexity: 5.2010297775268555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it]
INFO:root:eval mean loss: 4264.229653216423
INFO:root:eval perplexity: 5.608757019042969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 5175.025814840979
INFO:root:eval perplexity: 8.299034118652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/34
 17%|â–ˆâ–‹        | 34/200 [1:35:26<7:35:58, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4146.1351507482395
INFO:root:current train perplexity5.113500595092773
INFO:root:current mean train loss 4163.010515179551
INFO:root:current train perplexity5.122849464416504
INFO:root:current mean train loss 4156.582012331354
INFO:root:current train perplexity5.141140937805176
INFO:root:current mean train loss 4159.248483827493
INFO:root:current train perplexity5.143733978271484
INFO:root:current mean train loss 4155.189671866707
INFO:root:current train perplexity5.146671295166016
INFO:root:current mean train loss 4154.2946952646125
INFO:root:current train perplexity5.150899410247803
INFO:root:current mean train loss 4155.762521757987
INFO:root:current train perplexity5.151944637298584
INFO:root:current mean train loss 4156.514656987171
INFO:root:current train perplexity5.1566877365112305
INFO:root:current mean train loss 4159.431918401532
INFO:root:current train perplexity5.159514427185059
INFO:root:current mean train loss 4162.474746656958
INFO:root:current train perplexity5.161619186401367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.04s/it]
INFO:root:final mean train loss: 4160.544139308314
INFO:root:final train perplexity: 5.162675857543945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 4256.643722642398
INFO:root:eval perplexity: 5.591578960418701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it]
INFO:root:eval mean loss: 5167.807648354388
INFO:root:eval perplexity: 8.274575233459473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/35
 18%|â–ˆâ–Š        | 35/200 [1:38:09<7:31:52, 164.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4125.098067271559
INFO:root:current train perplexity5.124694347381592
INFO:root:current mean train loss 4121.008656762831
INFO:root:current train perplexity5.108335971832275
INFO:root:current mean train loss 4133.878721613183
INFO:root:current train perplexity5.11461067199707
INFO:root:current mean train loss 4135.730195621702
INFO:root:current train perplexity5.120726108551025
INFO:root:current mean train loss 4136.285501308879
INFO:root:current train perplexity5.112120628356934
INFO:root:current mean train loss 4140.268819489422
INFO:root:current train perplexity5.118278980255127
INFO:root:current mean train loss 4146.386184085627
INFO:root:current train perplexity5.126108169555664
INFO:root:current mean train loss 4145.894806730885
INFO:root:current train perplexity5.126086711883545
INFO:root:current mean train loss 4145.997222240739
INFO:root:current train perplexity5.1249589920043945
INFO:root:current mean train loss 4146.746174049572
INFO:root:current train perplexity5.1266398429870605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.81s/it]
INFO:root:final mean train loss: 4143.369212673557
INFO:root:final train perplexity: 5.127811908721924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.95s/it]
INFO:root:eval mean loss: 4248.43748614805
INFO:root:eval perplexity: 5.573055267333984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.37s/it]
INFO:root:eval mean loss: 5156.519307887301
INFO:root:eval perplexity: 8.236467361450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/36
 18%|â–ˆâ–Š        | 36/200 [1:40:43<7:20:46, 161.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4177.676513671875
INFO:root:current train perplexity5.159700393676758
INFO:root:current mean train loss 4146.50529275986
INFO:root:current train perplexity5.114433288574219
INFO:root:current mean train loss 4142.336443645198
INFO:root:current train perplexity5.110044479370117
INFO:root:current mean train loss 4138.972678329901
INFO:root:current train perplexity5.0976996421813965
INFO:root:current mean train loss 4135.310285188334
INFO:root:current train perplexity5.0885009765625
INFO:root:current mean train loss 4136.884570562048
INFO:root:current train perplexity5.100576400756836
INFO:root:current mean train loss 4132.485333793896
INFO:root:current train perplexity5.097384929656982
INFO:root:current mean train loss 4133.048325883994
INFO:root:current train perplexity5.097933769226074
INFO:root:current mean train loss 4133.074629687941
INFO:root:current train perplexity5.0965895652771
INFO:root:current mean train loss 4129.262768529952
INFO:root:current train perplexity5.093570232391357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.22s/it]
INFO:root:final mean train loss: 4126.499135171213
INFO:root:final train perplexity: 5.0937957763671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 4239.96961228391
INFO:root:eval perplexity: 5.5540056228637695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.27s/it]
INFO:root:eval mean loss: 5153.872395833333
INFO:root:eval perplexity: 8.227559089660645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/37
 18%|â–ˆâ–Š        | 37/200 [1:43:20<7:14:32, 159.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4099.023892372533
INFO:root:current train perplexity5.071996212005615
INFO:root:current mean train loss 4097.97386318109
INFO:root:current train perplexity5.077375888824463
INFO:root:current mean train loss 4104.665592723782
INFO:root:current train perplexity5.071769714355469
INFO:root:current mean train loss 4106.938814032832
INFO:root:current train perplexity5.0622334480285645
INFO:root:current mean train loss 4107.877039437342
INFO:root:current train perplexity5.060397148132324
INFO:root:current mean train loss 4107.880529887736
INFO:root:current train perplexity5.060539245605469
INFO:root:current mean train loss 4108.83207164737
INFO:root:current train perplexity5.0655083656311035
INFO:root:current mean train loss 4108.886106709414
INFO:root:current train perplexity5.063432693481445
INFO:root:current mean train loss 4109.557427876222
INFO:root:current train perplexity5.060233116149902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.95s/it]
INFO:root:final mean train loss: 4110.03378000567
INFO:root:final train perplexity: 5.060813903808594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it]
INFO:root:eval mean loss: 4234.005575410018
INFO:root:eval perplexity: 5.5406270027160645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.55s/it]
INFO:root:eval mean loss: 5149.599721922096
INFO:root:eval perplexity: 8.213194847106934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/38
 19%|â–ˆâ–‰        | 38/200 [1:45:57<7:09:42, 159.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4175.140055338542
INFO:root:current train perplexity4.943322658538818
INFO:root:current mean train loss 4101.525428549758
INFO:root:current train perplexity4.991077423095703
INFO:root:current mean train loss 4090.5461461861146
INFO:root:current train perplexity4.99633264541626
INFO:root:current mean train loss 4083.1962479695235
INFO:root:current train perplexity5.004787445068359
INFO:root:current mean train loss 4087.9200757502326
INFO:root:current train perplexity5.013308525085449
INFO:root:current mean train loss 4092.0884390920105
INFO:root:current train perplexity5.015231609344482
INFO:root:current mean train loss 4093.9238155738235
INFO:root:current train perplexity5.01814079284668
INFO:root:current mean train loss 4091.95652629912
INFO:root:current train perplexity5.019054889678955
INFO:root:current mean train loss 4092.6619959697036
INFO:root:current train perplexity5.022369384765625
INFO:root:current mean train loss 4094.525559874204
INFO:root:current train perplexity5.02480411529541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.59s/it]
INFO:root:final mean train loss: 4093.843380589639
INFO:root:final train perplexity: 5.028589725494385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it]
INFO:root:eval mean loss: 4226.479596077128
INFO:root:eval perplexity: 5.52379035949707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it]
INFO:root:eval mean loss: 5146.779163549978
INFO:root:eval perplexity: 8.203726768493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/39
 20%|â–ˆâ–‰        | 39/200 [1:48:35<7:06:02, 158.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4029.036376953125
INFO:root:current train perplexity4.9779558181762695
INFO:root:current mean train loss 4067.7027730855857
INFO:root:current train perplexity5.003993034362793
INFO:root:current mean train loss 4075.0344747389663
INFO:root:current train perplexity4.99880838394165
INFO:root:current mean train loss 4066.4917345445638
INFO:root:current train perplexity4.989529609680176
INFO:root:current mean train loss 4073.6621450159673
INFO:root:current train perplexity4.98334264755249
INFO:root:current mean train loss 4077.572506421233
INFO:root:current train perplexity4.990498065948486
INFO:root:current mean train loss 4076.894927628887
INFO:root:current train perplexity4.994561672210693
INFO:root:current mean train loss 4075.6809507817993
INFO:root:current train perplexity4.995067119598389
INFO:root:current mean train loss 4080.133650886733
INFO:root:current train perplexity4.99928092956543
INFO:root:current mean train loss 4083.2162099727293
INFO:root:current train perplexity5.0014142990112305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:14<00:00, 134.90s/it]
INFO:root:final mean train loss: 4079.0094828451834
INFO:root:final train perplexity: 4.999246597290039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it]
INFO:root:eval mean loss: 4223.064250540226
INFO:root:eval perplexity: 5.516168117523193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 5142.869724138409
INFO:root:eval perplexity: 8.190624237060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/40
 20%|â–ˆâ–ˆ        | 40/200 [1:51:13<7:02:35, 158.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4082.7928659539475
INFO:root:current train perplexity5.0261735916137695
INFO:root:current mean train loss 4047.90313566833
INFO:root:current train perplexity4.93574857711792
INFO:root:current mean train loss 4063.771775337115
INFO:root:current train perplexity4.947294235229492
INFO:root:current mean train loss 4067.402626922512
INFO:root:current train perplexity4.960182189941406
INFO:root:current mean train loss 4062.3654010199134
INFO:root:current train perplexity4.95253324508667
INFO:root:current mean train loss 4067.8618201694967
INFO:root:current train perplexity4.958387851715088
INFO:root:current mean train loss 4064.227499621365
INFO:root:current train perplexity4.961404323577881
INFO:root:current mean train loss 4065.5679702440457
INFO:root:current train perplexity4.962120056152344
INFO:root:current mean train loss 4068.1475515586844
INFO:root:current train perplexity4.967974662780762
INFO:root:current mean train loss 4067.7991588704604
INFO:root:current train perplexity4.969267845153809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.64s/it]
INFO:root:final mean train loss: 4064.840424814532
INFO:root:final train perplexity: 4.971378803253174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it]
INFO:root:eval mean loss: 4217.609504862035
INFO:root:eval perplexity: 5.504013538360596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.75s/it]
INFO:root:eval mean loss: 5145.57677443484
INFO:root:eval perplexity: 8.19969654083252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/41
 20%|â–ˆâ–ˆ        | 41/200 [1:53:51<7:00:07, 158.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3950.07470703125
INFO:root:current train perplexity4.82586669921875
INFO:root:current mean train loss 4024.4024283341537
INFO:root:current train perplexity4.917032718658447
INFO:root:current mean train loss 4047.7122313377618
INFO:root:current train perplexity4.951489448547363
INFO:root:current mean train loss 4046.0437474615346
INFO:root:current train perplexity4.941954612731934
INFO:root:current mean train loss 4054.797510223031
INFO:root:current train perplexity4.939584732055664
INFO:root:current mean train loss 4054.559651383865
INFO:root:current train perplexity4.940650939941406
INFO:root:current mean train loss 4055.5179558226178
INFO:root:current train perplexity4.941861629486084
INFO:root:current mean train loss 4053.576884483537
INFO:root:current train perplexity4.940389156341553
INFO:root:current mean train loss 4054.437122718599
INFO:root:current train perplexity4.942560195922852
INFO:root:current mean train loss 4052.2284950824233
INFO:root:current train perplexity4.94080924987793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.59s/it]
INFO:root:final mean train loss: 4048.9076391650783
INFO:root:final train perplexity: 4.940225601196289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.83s/it]
INFO:root:eval mean loss: 4210.759540530807
INFO:root:eval perplexity: 5.488787651062012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 5137.794307194703
INFO:root:eval perplexity: 8.173643112182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/42
 21%|â–ˆâ–ˆ        | 42/200 [1:56:30<6:57:53, 158.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4008.5424176897322
INFO:root:current train perplexity4.897428035736084
INFO:root:current mean train loss 4029.712628399884
INFO:root:current train perplexity4.894139766693115
INFO:root:current mean train loss 4019.5658545960773
INFO:root:current train perplexity4.882549285888672
INFO:root:current mean train loss 4030.9839231576493
INFO:root:current train perplexity4.886780261993408
INFO:root:current mean train loss 4031.445397808908
INFO:root:current train perplexity4.896096229553223
INFO:root:current mean train loss 4030.8905396648656
INFO:root:current train perplexity4.898706436157227
INFO:root:current mean train loss 4031.7175408310777
INFO:root:current train perplexity4.902622222900391
INFO:root:current mean train loss 4037.3921685666455
INFO:root:current train perplexity4.911503314971924
INFO:root:current mean train loss 4036.599205007953
INFO:root:current train perplexity4.907357692718506
INFO:root:current mean train loss 4039.1581963360627
INFO:root:current train perplexity4.911744594573975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:15<00:00, 135.46s/it]
INFO:root:final mean train loss: 4034.548238323581
INFO:root:final train perplexity: 4.912317752838135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.64s/it]
INFO:root:eval mean loss: 4205.748770639406
INFO:root:eval perplexity: 5.477678298950195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.06s/it]
INFO:root:eval mean loss: 5133.258103390957
INFO:root:eval perplexity: 8.158495903015137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/43
 22%|â–ˆâ–ˆâ–       | 43/200 [1:59:10<6:55:38, 158.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4050.817502043968
INFO:root:current train perplexity4.911550521850586
INFO:root:current mean train loss 4039.481756036932
INFO:root:current train perplexity4.902553558349609
INFO:root:current mean train loss 4032.0812144338347
INFO:root:current train perplexity4.884710788726807
INFO:root:current mean train loss 4024.1222753052116
INFO:root:current train perplexity4.875744819641113
INFO:root:current mean train loss 4019.6182930216564
INFO:root:current train perplexity4.877408027648926
INFO:root:current mean train loss 4024.2031740079706
INFO:root:current train perplexity4.881012916564941
INFO:root:current mean train loss 4022.308858393881
INFO:root:current train perplexity4.882830619812012
INFO:root:current mean train loss 4028.57714285151
INFO:root:current train perplexity4.889318943023682
INFO:root:current mean train loss 4021.7040508808755
INFO:root:current train perplexity4.884035110473633
INFO:root:current mean train loss 4022.338664211625
INFO:root:current train perplexity4.883969783782959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.22s/it]
INFO:root:final mean train loss: 4021.15053361462
INFO:root:final train perplexity: 4.8864216804504395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.84s/it]
INFO:root:eval mean loss: 4200.61286569149
INFO:root:eval perplexity: 5.466314315795898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.73s/it]
INFO:root:eval mean loss: 5136.854554521276
INFO:root:eval perplexity: 8.170502662658691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/44
 22%|â–ˆâ–ˆâ–       | 44/200 [2:02:23<7:19:34, 169.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3977.983814912684
INFO:root:current train perplexity4.863472938537598
INFO:root:current mean train loss 4007.4141514253934
INFO:root:current train perplexity4.86215877532959
INFO:root:current mean train loss 4006.706611055777
INFO:root:current train perplexity4.86531400680542
INFO:root:current mean train loss 4010.9346002214656
INFO:root:current train perplexity4.869499683380127
INFO:root:current mean train loss 4013.0714178994594
INFO:root:current train perplexity4.870327949523926
INFO:root:current mean train loss 4013.8286301185344
INFO:root:current train perplexity4.867405414581299
INFO:root:current mean train loss 4011.6632899505566
INFO:root:current train perplexity4.863338470458984
INFO:root:current mean train loss 4011.6403883363846
INFO:root:current train perplexity4.864267349243164
INFO:root:current mean train loss 4012.007897992252
INFO:root:current train perplexity4.861259460449219
INFO:root:current mean train loss 4009.5951896852
INFO:root:current train perplexity4.858535289764404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.69s/it]
INFO:root:final mean train loss: 4007.6969599569998
INFO:root:final train perplexity: 4.86055326461792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.53s/it]
INFO:root:eval mean loss: 4193.4180535931955
INFO:root:eval perplexity: 5.450432300567627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it]
INFO:root:eval mean loss: 5132.202756191822
INFO:root:eval perplexity: 8.154973983764648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:05:02<7:09:42, 166.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3994.042885990466
INFO:root:current train perplexity4.830340385437012
INFO:root:current mean train loss 3994.729983539701
INFO:root:current train perplexity4.82939338684082
INFO:root:current mean train loss 3995.155705161076
INFO:root:current train perplexity4.826590538024902
INFO:root:current mean train loss 3991.9269047049092
INFO:root:current train perplexity4.8332343101501465
INFO:root:current mean train loss 3997.194226366762
INFO:root:current train perplexity4.83339262008667
INFO:root:current mean train loss 3997.113734591626
INFO:root:current train perplexity4.831503868103027
INFO:root:current mean train loss 3996.941563700327
INFO:root:current train perplexity4.832949638366699
INFO:root:current mean train loss 4000.453498126647
INFO:root:current train perplexity4.836553573608398
INFO:root:current mean train loss 4002.004301308753
INFO:root:current train perplexity4.838663578033447
INFO:root:current mean train loss 3997.8583839265348
INFO:root:current train perplexity4.834349632263184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.46s/it]
INFO:root:final mean train loss: 3994.1088694295577
INFO:root:final train perplexity: 4.834567070007324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it]
INFO:root:eval mean loss: 4192.074904421543
INFO:root:eval perplexity: 5.447474002838135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it]
INFO:root:eval mean loss: 5131.930432042332
INFO:root:eval perplexity: 8.15406608581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [2:07:50<7:07:44, 166.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3951.46776979361
INFO:root:current train perplexity4.795823574066162
INFO:root:current mean train loss 3968.8602960095436
INFO:root:current train perplexity4.793290615081787
INFO:root:current mean train loss 3962.665446877926
INFO:root:current train perplexity4.785041332244873
INFO:root:current mean train loss 3973.7823542872957
INFO:root:current train perplexity4.797740936279297
INFO:root:current mean train loss 3975.676935559422
INFO:root:current train perplexity4.796411514282227
INFO:root:current mean train loss 3975.6970804742614
INFO:root:current train perplexity4.794181823730469
INFO:root:current mean train loss 3978.80140349747
INFO:root:current train perplexity4.8028483390808105
INFO:root:current mean train loss 3979.642580034835
INFO:root:current train perplexity4.801608085632324
INFO:root:current mean train loss 3978.3268423465433
INFO:root:current train perplexity4.8065924644470215
INFO:root:current mean train loss 3984.001647128684
INFO:root:current train perplexity4.809370994567871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.09s/it]
INFO:root:final mean train loss: 3981.322426826723
INFO:root:final train perplexity: 4.810239791870117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 4185.425166569703
INFO:root:eval perplexity: 5.432845592498779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it]
INFO:root:eval mean loss: 5127.32275390625
INFO:root:eval perplexity: 8.138718605041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [2:10:29<6:59:31, 164.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3963.7140755208334
INFO:root:current train perplexity4.762415409088135
INFO:root:current mean train loss 3942.2733858816964
INFO:root:current train perplexity4.757599830627441
INFO:root:current mean train loss 3956.4554714133524
INFO:root:current train perplexity4.775418281555176
INFO:root:current mean train loss 3954.6531712239585
INFO:root:current train perplexity4.767819881439209
INFO:root:current mean train loss 3960.556353310033
INFO:root:current train perplexity4.774327754974365
INFO:root:current mean train loss 3959.817369650136
INFO:root:current train perplexity4.771043300628662
INFO:root:current mean train loss 3963.552435619213
INFO:root:current train perplexity4.773310661315918
INFO:root:current mean train loss 3964.0494808467743
INFO:root:current train perplexity4.775100231170654
INFO:root:current mean train loss 3967.1425223214287
INFO:root:current train perplexity4.77927303314209
INFO:root:current mean train loss 3970.382290164263
INFO:root:current train perplexity4.784140110015869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.88s/it]
INFO:root:final mean train loss: 3967.496234093943
INFO:root:final train perplexity: 4.784071922302246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 4184.518475038785
INFO:root:eval perplexity: 5.430853843688965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it]
INFO:root:eval mean loss: 5126.1669437056735
INFO:root:eval perplexity: 8.134871482849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/48
 24%|â–ˆâ–ˆâ–       | 48/200 [2:13:15<6:57:56, 164.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3943.5743452324923
INFO:root:current train perplexity4.758941173553467
INFO:root:current mean train loss 3950.40380859375
INFO:root:current train perplexity4.756624221801758
INFO:root:current mean train loss 3961.9732816985975
INFO:root:current train perplexity4.756814479827881
INFO:root:current mean train loss 3960.541194746451
INFO:root:current train perplexity4.758207321166992
INFO:root:current mean train loss 3954.7354759074146
INFO:root:current train perplexity4.755445957183838
INFO:root:current mean train loss 3957.6353435221913
INFO:root:current train perplexity4.762732028961182
INFO:root:current mean train loss 3955.6783195261028
INFO:root:current train perplexity4.757767677307129
INFO:root:current mean train loss 3955.449597277099
INFO:root:current train perplexity4.756221294403076
INFO:root:current mean train loss 3958.044504651667
INFO:root:current train perplexity4.759973526000977
INFO:root:current mean train loss 3959.147366311276
INFO:root:current train perplexity4.7613115310668945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 149.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 149.00s/it]
INFO:root:final mean train loss: 3955.139944384175
INFO:root:final train perplexity: 4.760806560516357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 4178.84109388852
INFO:root:eval perplexity: 5.418400764465332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 5127.506894808289
INFO:root:eval perplexity: 8.139331817626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/49
 24%|â–ˆâ–ˆâ–       | 49/200 [2:16:49<7:31:48, 179.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3960.7282983130153
INFO:root:current train perplexity4.737768650054932
INFO:root:current mean train loss 3931.013343371646
INFO:root:current train perplexity4.72219181060791
INFO:root:current mean train loss 3933.442691553909
INFO:root:current train perplexity4.724985122680664
INFO:root:current mean train loss 3934.187278962196
INFO:root:current train perplexity4.719000339508057
INFO:root:current mean train loss 3942.190164165924
INFO:root:current train perplexity4.731479644775391
INFO:root:current mean train loss 3946.6514274997357
INFO:root:current train perplexity4.738453388214111
INFO:root:current mean train loss 3948.2039598832084
INFO:root:current train perplexity4.737246036529541
INFO:root:current mean train loss 3947.9008051393607
INFO:root:current train perplexity4.7407660484313965
INFO:root:current mean train loss 3944.9874534735372
INFO:root:current train perplexity4.7400922775268555
INFO:root:current mean train loss 3947.0241327218405
INFO:root:current train perplexity4.73961877822876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.50s/it]
INFO:root:final mean train loss: 3943.772195508403
INFO:root:final train perplexity: 4.739502906799316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it]
INFO:root:eval mean loss: 4174.122279823249
INFO:root:eval perplexity: 5.408071517944336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it]
INFO:root:eval mean loss: 5121.381380554632
INFO:root:eval perplexity: 8.118969917297363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [2:19:42<7:23:38, 177.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3902.805318813131
INFO:root:current train perplexity4.6871514320373535
INFO:root:current mean train loss 3914.7732068545856
INFO:root:current train perplexity4.695511341094971
INFO:root:current mean train loss 3923.1560573003762
INFO:root:current train perplexity4.698114395141602
INFO:root:current mean train loss 3927.2681092379385
INFO:root:current train perplexity4.705179691314697
INFO:root:current mean train loss 3930.1617179671844
INFO:root:current train perplexity4.70872688293457
INFO:root:current mean train loss 3931.076888401242
INFO:root:current train perplexity4.707767486572266
INFO:root:current mean train loss 3935.217455600635
INFO:root:current train perplexity4.711467266082764
INFO:root:current mean train loss 3932.2314682293295
INFO:root:current train perplexity4.712028503417969
INFO:root:current mean train loss 3934.6051846887167
INFO:root:current train perplexity4.71574068069458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.81s/it]
INFO:root:final mean train loss: 3931.9802414063483
INFO:root:final train perplexity: 4.717504501342773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4172.725580743018
INFO:root:eval perplexity: 5.405019283294678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it]
INFO:root:eval mean loss: 5119.090602144282
INFO:root:eval perplexity: 8.111367225646973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [2:22:33<7:16:27, 175.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3804.252511160714
INFO:root:current train perplexity4.6746087074279785
INFO:root:current mean train loss 3911.1864527051694
INFO:root:current train perplexity4.653787612915039
INFO:root:current mean train loss 3918.826420733318
INFO:root:current train perplexity4.675384044647217
INFO:root:current mean train loss 3914.1024364757227
INFO:root:current train perplexity4.670683860778809
INFO:root:current mean train loss 3909.9502397017045
INFO:root:current train perplexity4.6700825691223145
INFO:root:current mean train loss 3907.5725203594984
INFO:root:current train perplexity4.669370174407959
INFO:root:current mean train loss 3913.9784987322387
INFO:root:current train perplexity4.681580543518066
INFO:root:current mean train loss 3915.048614027139
INFO:root:current train perplexity4.684406757354736
INFO:root:current mean train loss 3919.470918222874
INFO:root:current train perplexity4.688791275024414
INFO:root:current mean train loss 3923.806625551268
INFO:root:current train perplexity4.69417667388916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.86s/it]
INFO:root:final mean train loss: 3919.6876543106573
INFO:root:final train perplexity: 4.694680690765381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 4169.359889253657
INFO:root:eval perplexity: 5.3976664543151855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.38s/it]
INFO:root:eval mean loss: 5121.140074384974
INFO:root:eval perplexity: 8.118167877197266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:25:25<7:10:09, 174.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3859.5396321614585
INFO:root:current train perplexity4.609536170959473
INFO:root:current mean train loss 3917.1115489130434
INFO:root:current train perplexity4.64570951461792
INFO:root:current mean train loss 3915.319786746003
INFO:root:current train perplexity4.658426761627197
INFO:root:current mean train loss 3915.9133409288193
INFO:root:current train perplexity4.662235260009766
INFO:root:current mean train loss 3918.463064759036
INFO:root:current train perplexity4.664437294006348
INFO:root:current mean train loss 3916.6846878792476
INFO:root:current train perplexity4.667661190032959
INFO:root:current mean train loss 3917.5943835746953
INFO:root:current train perplexity4.671189308166504
INFO:root:current mean train loss 3915.06102696132
INFO:root:current train perplexity4.672754764556885
INFO:root:current mean train loss 3912.51143836273
INFO:root:current train perplexity4.6776227951049805
INFO:root:current mean train loss 3913.843838851178
INFO:root:current train perplexity4.67688512802124

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.37s/it]
INFO:root:final mean train loss: 3908.302045576034
INFO:root:final train perplexity: 4.673641204833984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.53s/it]
INFO:root:eval mean loss: 4165.810887979277
INFO:root:eval perplexity: 5.389925479888916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it]
INFO:root:eval mean loss: 5128.134756967531
INFO:root:eval perplexity: 8.141422271728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:28:14<7:03:29, 172.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3893.8631538722825
INFO:root:current train perplexity4.638095378875732
INFO:root:current mean train loss 3892.3352924129827
INFO:root:current train perplexity4.651836395263672
INFO:root:current mean train loss 3893.799266045404
INFO:root:current train perplexity4.638092041015625
INFO:root:current mean train loss 3890.3428558255127
INFO:root:current train perplexity4.6392669677734375
INFO:root:current mean train loss 3895.0701930269283
INFO:root:current train perplexity4.641608238220215
INFO:root:current mean train loss 3895.7959796621058
INFO:root:current train perplexity4.643481254577637
INFO:root:current mean train loss 3895.374504273049
INFO:root:current train perplexity4.644330024719238
INFO:root:current mean train loss 3895.1881871731284
INFO:root:current train perplexity4.647843360900879
INFO:root:current mean train loss 3896.282657294198
INFO:root:current train perplexity4.645503997802734
INFO:root:current mean train loss 3896.220976625982
INFO:root:current train perplexity4.647029876708984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.09s/it]
INFO:root:final mean train loss: 3896.51749444777
INFO:root:final train perplexity: 4.651961326599121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4162.450882715536
INFO:root:eval perplexity: 5.382606506347656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.80s/it]
INFO:root:eval mean loss: 5116.450648963874
INFO:root:eval perplexity: 8.102615356445312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:31:51<7:33:02, 186.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.9891790574598
INFO:root:current train perplexity4.630845546722412
INFO:root:current mean train loss 3850.835846180224
INFO:root:current train perplexity4.601128578186035
INFO:root:current mean train loss 3865.4985467819943
INFO:root:current train perplexity4.616512775421143
INFO:root:current mean train loss 3878.5460961102717
INFO:root:current train perplexity4.626574516296387
INFO:root:current mean train loss 3880.926780470563
INFO:root:current train perplexity4.630836486816406
INFO:root:current mean train loss 3888.686660450506
INFO:root:current train perplexity4.635776996612549
INFO:root:current mean train loss 3887.266426291972
INFO:root:current train perplexity4.637880802154541
INFO:root:current mean train loss 3888.735984123846
INFO:root:current train perplexity4.6374921798706055
INFO:root:current mean train loss 3890.3550874088073
INFO:root:current train perplexity4.637075424194336
INFO:root:current mean train loss 3891.3472080906786
INFO:root:current train perplexity4.637628078460693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.78s/it]
INFO:root:final mean train loss: 3887.3994119090416
INFO:root:final train perplexity: 4.635256767272949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 4160.732113669104
INFO:root:eval perplexity: 5.3788676261901855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 5121.439276512633
INFO:root:eval perplexity: 8.119163513183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:34:41<7:18:22, 181.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3871.9518103966348
INFO:root:current train perplexity4.585148334503174
INFO:root:current mean train loss 3882.7748531643433
INFO:root:current train perplexity4.6047773361206055
INFO:root:current mean train loss 3868.6515490160828
INFO:root:current train perplexity4.58535623550415
INFO:root:current mean train loss 3875.4159580106934
INFO:root:current train perplexity4.589334964752197
INFO:root:current mean train loss 3876.3847300327448
INFO:root:current train perplexity4.5957746505737305
INFO:root:current mean train loss 3874.613683017596
INFO:root:current train perplexity4.59945011138916
INFO:root:current mean train loss 3877.9753528768097
INFO:root:current train perplexity4.607161521911621
INFO:root:current mean train loss 3877.813403881935
INFO:root:current train perplexity4.609658718109131
INFO:root:current mean train loss 3878.465482473089
INFO:root:current train perplexity4.611135482788086
INFO:root:current mean train loss 3876.230670770517
INFO:root:current train perplexity4.610095500946045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 146.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 146.00s/it]
INFO:root:final mean train loss: 3875.2555321724185
INFO:root:final train perplexity: 4.613101959228516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4162.409577931073
INFO:root:eval perplexity: 5.3825178146362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 5128.164346464982
INFO:root:eval perplexity: 8.141520500183105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:37:32<7:07:45, 178.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3861.7129633477393
INFO:root:current train perplexity4.611800670623779
INFO:root:current mean train loss 3850.9426153273807
INFO:root:current train perplexity4.557402610778809
INFO:root:current mean train loss 3862.323393416308
INFO:root:current train perplexity4.580832004547119
INFO:root:current mean train loss 3861.162035499595
INFO:root:current train perplexity4.581040859222412
INFO:root:current mean train loss 3865.2741376974973
INFO:root:current train perplexity4.584335803985596
INFO:root:current mean train loss 3868.7183152779367
INFO:root:current train perplexity4.589752197265625
INFO:root:current mean train loss 3870.7172036502607
INFO:root:current train perplexity4.5910868644714355
INFO:root:current mean train loss 3872.980076556225
INFO:root:current train perplexity4.595658302307129
INFO:root:current mean train loss 3867.925520391363
INFO:root:current train perplexity4.591018199920654
INFO:root:current mean train loss 3867.8255513401696
INFO:root:current train perplexity4.591751575469971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.17s/it]
INFO:root:final mean train loss: 3864.602516605008
INFO:root:final train perplexity: 4.593754291534424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 4156.107704108488
INFO:root:eval perplexity: 5.368818759918213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.55s/it]
INFO:root:eval mean loss: 5120.897334538453
INFO:root:eval perplexity: 8.117361068725586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:40:26<7:01:47, 176.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3851.7219460227275
INFO:root:current train perplexity4.549050807952881
INFO:root:current mean train loss 3842.5103988155242
INFO:root:current train perplexity4.553424835205078
INFO:root:current mean train loss 3847.4591595818015
INFO:root:current train perplexity4.561689376831055
INFO:root:current mean train loss 3850.448899647887
INFO:root:current train perplexity4.566780090332031
INFO:root:current mean train loss 3848.1733055030904
INFO:root:current train perplexity4.561882972717285
INFO:root:current mean train loss 3848.1819934192004
INFO:root:current train perplexity4.560983657836914
INFO:root:current mean train loss 3850.1774127057492
INFO:root:current train perplexity4.568315029144287
INFO:root:current mean train loss 3852.5188990712954
INFO:root:current train perplexity4.5677876472473145
INFO:root:current mean train loss 3851.6305498446636
INFO:root:current train perplexity4.570045471191406
INFO:root:current mean train loss 3856.6195803337696
INFO:root:current train perplexity4.575984477996826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.47s/it]
INFO:root:final mean train loss: 3853.984616187311
INFO:root:final train perplexity: 4.574550151824951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 4153.426200271499
INFO:root:eval perplexity: 5.363000392913818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it]
INFO:root:eval mean loss: 5117.00573124446
INFO:root:eval perplexity: 8.104453086853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:43:18<6:55:06, 175.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3825.8334147135415
INFO:root:current train perplexity4.535438060760498
INFO:root:current mean train loss 3840.5318685894363
INFO:root:current train perplexity4.529716968536377
INFO:root:current mean train loss 3829.165127250178
INFO:root:current train perplexity4.525246620178223
INFO:root:current mean train loss 3836.165857572529
INFO:root:current train perplexity4.539984703063965
INFO:root:current mean train loss 3835.317323227423
INFO:root:current train perplexity4.543810844421387
INFO:root:current mean train loss 3839.264035700905
INFO:root:current train perplexity4.547563552856445
INFO:root:current mean train loss 3841.58227686357
INFO:root:current train perplexity4.552677631378174
INFO:root:current mean train loss 3842.8578791187133
INFO:root:current train perplexity4.552403926849365
INFO:root:current mean train loss 3844.4045280023356
INFO:root:current train perplexity4.553649425506592
INFO:root:current mean train loss 3847.2478640864324
INFO:root:current train perplexity4.5544538497924805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.64s/it]
INFO:root:final mean train loss: 3843.8594492020147
INFO:root:final train perplexity: 4.556313514709473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it]
INFO:root:eval mean loss: 4152.293898562168
INFO:root:eval perplexity: 5.3605451583862305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.44s/it]
INFO:root:eval mean loss: 5120.286389073582
INFO:root:eval perplexity: 8.115333557128906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:46:09<6:49:01, 174.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3806.79355675066
INFO:root:current train perplexity4.485357284545898
INFO:root:current mean train loss 3815.5976748103985
INFO:root:current train perplexity4.511031150817871
INFO:root:current mean train loss 3811.682318092712
INFO:root:current train perplexity4.5130534172058105
INFO:root:current mean train loss 3812.2347145594676
INFO:root:current train perplexity4.51363468170166
INFO:root:current mean train loss 3818.02166216743
INFO:root:current train perplexity4.520938873291016
INFO:root:current mean train loss 3822.2028932588114
INFO:root:current train perplexity4.523190021514893
INFO:root:current mean train loss 3823.5502136503355
INFO:root:current train perplexity4.526683807373047
INFO:root:current mean train loss 3825.894491351532
INFO:root:current train perplexity4.529450416564941
INFO:root:current mean train loss 3829.717953669902
INFO:root:current train perplexity4.534486293792725
INFO:root:current mean train loss 3833.9926591867275
INFO:root:current train perplexity4.536158084869385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.10s/it]
INFO:root:final mean train loss: 3833.1351964396813
INFO:root:final train perplexity: 4.537075996398926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 4150.996848681294
INFO:root:eval perplexity: 5.3577351570129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 5125.437510388962
INFO:root:eval perplexity: 8.132447242736816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:48:56<6:41:36, 172.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.7418197438687
INFO:root:current train perplexity4.476431846618652
INFO:root:current mean train loss 3801.0248805211245
INFO:root:current train perplexity4.500214576721191
INFO:root:current mean train loss 3800.3386624243954
INFO:root:current train perplexity4.501495838165283
INFO:root:current mean train loss 3809.700387919484
INFO:root:current train perplexity4.504587650299072
INFO:root:current mean train loss 3819.876535180715
INFO:root:current train perplexity4.512279510498047
INFO:root:current mean train loss 3821.8645200844667
INFO:root:current train perplexity4.509700775146484
INFO:root:current mean train loss 3825.423866957382
INFO:root:current train perplexity4.513049125671387
INFO:root:current mean train loss 3825.618702488166
INFO:root:current train perplexity4.513372421264648
INFO:root:current mean train loss 3825.7984273344177
INFO:root:current train perplexity4.517843723297119
INFO:root:current mean train loss 3826.2085337497606
INFO:root:current train perplexity4.520507335662842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.51s/it]
INFO:root:final mean train loss: 3823.7063567869127
INFO:root:final train perplexity: 4.520229816436768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 4150.246573373781
INFO:root:eval perplexity: 5.356109142303467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 5131.492937236813
INFO:root:eval perplexity: 8.152609825134277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:51:49<6:39:01, 172.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3835.832556012033
INFO:root:current train perplexity4.525369167327881
INFO:root:current mean train loss 3825.835741665274
INFO:root:current train perplexity4.516493797302246
INFO:root:current mean train loss 3818.89723806348
INFO:root:current train perplexity4.505558013916016
INFO:root:current mean train loss 3817.0228653151244
INFO:root:current train perplexity4.505073547363281
INFO:root:current mean train loss 3813.1511611468495
INFO:root:current train perplexity4.499818801879883
INFO:root:current mean train loss 3814.5115357485092
INFO:root:current train perplexity4.493844032287598
INFO:root:current mean train loss 3814.825221965407
INFO:root:current train perplexity4.496222496032715
INFO:root:current mean train loss 3815.8480043132545
INFO:root:current train perplexity4.501003265380859
INFO:root:current mean train loss 3815.8524011657096
INFO:root:current train perplexity4.50164794921875
INFO:root:current mean train loss 3817.753572319054
INFO:root:current train perplexity4.504064559936523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.92s/it]
INFO:root:final mean train loss: 3814.1102272156745
INFO:root:final train perplexity: 4.503149032592773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 4148.513936793551
INFO:root:eval perplexity: 5.352357864379883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it]
INFO:root:eval mean loss: 5119.221946337544
INFO:root:eval perplexity: 8.11180305480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:54:41<6:36:01, 172.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3782.5263954564143
INFO:root:current train perplexity4.4819416999816895
INFO:root:current mean train loss 3783.238158553686
INFO:root:current train perplexity4.474566459655762
INFO:root:current mean train loss 3800.9077189817267
INFO:root:current train perplexity4.477088928222656
INFO:root:current mean train loss 3802.513150217563
INFO:root:current train perplexity4.475666046142578
INFO:root:current mean train loss 3802.030449021465
INFO:root:current train perplexity4.4775567054748535
INFO:root:current mean train loss 3802.469777442227
INFO:root:current train perplexity4.483017921447754
INFO:root:current mean train loss 3802.3668098724147
INFO:root:current train perplexity4.481900215148926
INFO:root:current mean train loss 3804.312434895833
INFO:root:current train perplexity4.482388496398926
INFO:root:current mean train loss 3806.9640428596367
INFO:root:current train perplexity4.484261512756348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.57s/it]
INFO:root:final mean train loss: 3803.932326470652
INFO:root:final train perplexity: 4.485102653503418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4149.347166237256
INFO:root:eval perplexity: 5.354162216186523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it]
INFO:root:eval mean loss: 5126.804424312943
INFO:root:eval perplexity: 8.136991500854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:57:29<6:30:08, 170.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3626.3861490885415
INFO:root:current train perplexity4.539810657501221
INFO:root:current mean train loss 3777.9571070995144
INFO:root:current train perplexity4.4429473876953125
INFO:root:current mean train loss 3779.0417456415485
INFO:root:current train perplexity4.445908546447754
INFO:root:current mean train loss 3783.228016063325
INFO:root:current train perplexity4.447626113891602
INFO:root:current mean train loss 3787.8553518290555
INFO:root:current train perplexity4.45470666885376
INFO:root:current mean train loss 3795.054174464929
INFO:root:current train perplexity4.463232040405273
INFO:root:current mean train loss 3797.3171957594836
INFO:root:current train perplexity4.469736099243164
INFO:root:current mean train loss 3795.8536444673496
INFO:root:current train perplexity4.46696662902832
INFO:root:current mean train loss 3794.1868223045417
INFO:root:current train perplexity4.463587284088135
INFO:root:current mean train loss 3795.8498137718025
INFO:root:current train perplexity4.467657089233398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.78s/it]
INFO:root:final mean train loss: 3795.4000301361084
INFO:root:final train perplexity: 4.470030307769775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 4147.146420309729
INFO:root:eval perplexity: 5.349399089813232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
INFO:root:eval mean loss: 5129.682615456006
INFO:root:eval perplexity: 8.146574974060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [3:00:20<6:27:28, 170.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3754.992986505682
INFO:root:current train perplexity4.445802211761475
INFO:root:current mean train loss 3769.3602921769425
INFO:root:current train perplexity4.421916484832764
INFO:root:current mean train loss 3762.636032610708
INFO:root:current train perplexity4.423664569854736
INFO:root:current mean train loss 3762.2537759369975
INFO:root:current train perplexity4.422969341278076
INFO:root:current mean train loss 3768.4379704607663
INFO:root:current train perplexity4.431448936462402
INFO:root:current mean train loss 3776.06305134693
INFO:root:current train perplexity4.437801361083984
INFO:root:current mean train loss 3779.5570733652567
INFO:root:current train perplexity4.436630725860596
INFO:root:current mean train loss 3782.507919976815
INFO:root:current train perplexity4.44316291809082
INFO:root:current mean train loss 3782.267160286298
INFO:root:current train perplexity4.447810649871826
INFO:root:current mean train loss 3786.441349703708
INFO:root:current train perplexity4.449653148651123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.50s/it]
INFO:root:final mean train loss: 3785.696941006568
INFO:root:final train perplexity: 4.452950954437256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.44s/it]
INFO:root:eval mean loss: 4147.903422470634
INFO:root:eval perplexity: 5.351036548614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 5132.535724179965
INFO:root:eval perplexity: 8.156084060668945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [3:03:11<6:24:23, 170.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3743.691162109375
INFO:root:current train perplexity4.404194355010986
INFO:root:current mean train loss 3756.140963514312
INFO:root:current train perplexity4.407447338104248
INFO:root:current mean train loss 3757.6877185002854
INFO:root:current train perplexity4.415415287017822
INFO:root:current mean train loss 3767.3607495346787
INFO:root:current train perplexity4.433673858642578
INFO:root:current mean train loss 3770.521346281138
INFO:root:current train perplexity4.43801212310791
INFO:root:current mean train loss 3768.883452251927
INFO:root:current train perplexity4.433867931365967
INFO:root:current mean train loss 3769.113720624243
INFO:root:current train perplexity4.430685520172119
INFO:root:current mean train loss 3773.9137966278035
INFO:root:current train perplexity4.431054592132568
INFO:root:current mean train loss 3778.236089946295
INFO:root:current train perplexity4.43470573425293
INFO:root:current mean train loss 3778.4408850270333
INFO:root:current train perplexity4.436098098754883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.59s/it]
INFO:root:final mean train loss: 3775.7552860629175
INFO:root:final train perplexity: 4.435519695281982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 4144.715680061503
INFO:root:eval perplexity: 5.344144344329834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it]
INFO:root:eval mean loss: 5131.626636261635
INFO:root:eval perplexity: 8.153055191040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [3:06:05<6:24:06, 171.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.3715368200233
INFO:root:current train perplexity4.400071620941162
INFO:root:current mean train loss 3773.3789120171014
INFO:root:current train perplexity4.405389785766602
INFO:root:current mean train loss 3769.95900050764
INFO:root:current train perplexity4.404519557952881
INFO:root:current mean train loss 3767.9750297149753
INFO:root:current train perplexity4.41376256942749
INFO:root:current mean train loss 3768.48315829918
INFO:root:current train perplexity4.413445472717285
INFO:root:current mean train loss 3767.164574871027
INFO:root:current train perplexity4.412527084350586
INFO:root:current mean train loss 3767.6854444683263
INFO:root:current train perplexity4.414844036102295
INFO:root:current mean train loss 3770.3319177430794
INFO:root:current train perplexity4.414498329162598
INFO:root:current mean train loss 3772.7207302845377
INFO:root:current train perplexity4.416111469268799
INFO:root:current mean train loss 3770.7745367912285
INFO:root:current train perplexity4.418917655944824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.21s/it]
INFO:root:final mean train loss: 3766.7425185172788
INFO:root:final train perplexity: 4.419775485992432
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 4143.239607574246
INFO:root:eval perplexity: 5.3409552574157715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.20s/it]
INFO:root:eval mean loss: 5132.582585328014
INFO:root:eval perplexity: 8.156241416931152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [3:08:56<6:20:23, 171.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3765.7623046875
INFO:root:current train perplexity4.389167308807373
INFO:root:current mean train loss 3770.4858380353007
INFO:root:current train perplexity4.407224178314209
INFO:root:current mean train loss 3771.447175241024
INFO:root:current train perplexity4.399150848388672
INFO:root:current mean train loss 3755.0695662313433
INFO:root:current train perplexity4.388484001159668
INFO:root:current mean train loss 3752.2195088002873
INFO:root:current train perplexity4.393260478973389
INFO:root:current mean train loss 3754.916205917786
INFO:root:current train perplexity4.39324426651001
INFO:root:current mean train loss 3752.7893523929624
INFO:root:current train perplexity4.394397735595703
INFO:root:current mean train loss 3753.1728877683886
INFO:root:current train perplexity4.3958420753479
INFO:root:current mean train loss 3755.7084668553516
INFO:root:current train perplexity4.401427268981934
INFO:root:current mean train loss 3760.5072738239473
INFO:root:current train perplexity4.405262470245361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it]
INFO:root:final mean train loss: 3758.283879003217
INFO:root:final train perplexity: 4.405051231384277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4137.981904158355
INFO:root:eval perplexity: 5.329611301422119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 5123.818987907247
INFO:root:eval perplexity: 8.127066612243652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [3:11:47<6:17:15, 171.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3723.189947083939
INFO:root:current train perplexity4.383279800415039
INFO:root:current mean train loss 3728.1758068591566
INFO:root:current train perplexity4.381597995758057
INFO:root:current mean train loss 3726.305393799833
INFO:root:current train perplexity4.361879348754883
INFO:root:current mean train loss 3738.580353583956
INFO:root:current train perplexity4.362965106964111
INFO:root:current mean train loss 3742.586161800755
INFO:root:current train perplexity4.366570472717285
INFO:root:current mean train loss 3748.9344556608253
INFO:root:current train perplexity4.375208377838135
INFO:root:current mean train loss 3750.774929681425
INFO:root:current train perplexity4.381730079650879
INFO:root:current mean train loss 3749.5749183131097
INFO:root:current train perplexity4.3836846351623535
INFO:root:current mean train loss 3750.447954895092
INFO:root:current train perplexity4.387817859649658
INFO:root:current mean train loss 3752.3658697102
INFO:root:current train perplexity4.3881754875183105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.98s/it]
INFO:root:final mean train loss: 3749.1696230365383
INFO:root:final train perplexity: 4.3892388343811035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 4140.822504571143
INFO:root:eval perplexity: 5.335737705230713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5132.318511746454
INFO:root:eval perplexity: 8.155363082885742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [3:14:37<6:13:05, 170.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.3467897901346
INFO:root:current train perplexity4.329177379608154
INFO:root:current mean train loss 3723.9356163984894
INFO:root:current train perplexity4.337551116943359
INFO:root:current mean train loss 3721.2417527156995
INFO:root:current train perplexity4.339147567749023
INFO:root:current mean train loss 3733.175421646857
INFO:root:current train perplexity4.3482513427734375
INFO:root:current mean train loss 3737.9101091541365
INFO:root:current train perplexity4.354734897613525
INFO:root:current mean train loss 3735.4946240322993
INFO:root:current train perplexity4.356515407562256
INFO:root:current mean train loss 3741.2479726202478
INFO:root:current train perplexity4.363080024719238
INFO:root:current mean train loss 3741.159017468896
INFO:root:current train perplexity4.365451335906982
INFO:root:current mean train loss 3742.075315804935
INFO:root:current train perplexity4.370018482208252
INFO:root:current mean train loss 3743.8398789206262
INFO:root:current train perplexity4.374208927154541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.69s/it]
INFO:root:final mean train loss: 3740.929352852606
INFO:root:final train perplexity: 4.374992370605469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 4144.337956421764
INFO:root:eval perplexity: 5.34332799911499
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 5145.62178288453
INFO:root:eval perplexity: 8.199845314025879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [3:17:26<6:09:01, 170.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3716.5908865201272
INFO:root:current train perplexity4.356376647949219
INFO:root:current mean train loss 3731.589653351022
INFO:root:current train perplexity4.355533123016357
INFO:root:current mean train loss 3738.38937507541
INFO:root:current train perplexity4.359821796417236
INFO:root:current mean train loss 3732.1969711601237
INFO:root:current train perplexity4.35221529006958
INFO:root:current mean train loss 3730.814774922556
INFO:root:current train perplexity4.3481316566467285
INFO:root:current mean train loss 3730.7177310732054
INFO:root:current train perplexity4.352148532867432
INFO:root:current mean train loss 3730.6839627394725
INFO:root:current train perplexity4.352648735046387
INFO:root:current mean train loss 3732.779627542408
INFO:root:current train perplexity4.354751110076904
INFO:root:current mean train loss 3733.7135849620745
INFO:root:current train perplexity4.358128547668457
INFO:root:current mean train loss 3734.5131189308527
INFO:root:current train perplexity4.360184669494629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.47s/it]
INFO:root:final mean train loss: 3732.4244736702212
INFO:root:final train perplexity: 4.360337734222412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 4142.952872201906
INFO:root:eval perplexity: 5.340335845947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 5140.963877576462
INFO:root:eval perplexity: 8.184243202209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [3:20:13<6:04:09, 169.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3727.133894735308
INFO:root:current train perplexity4.345932483673096
INFO:root:current mean train loss 3734.5093665208647
INFO:root:current train perplexity4.340703964233398
INFO:root:current mean train loss 3729.981098760826
INFO:root:current train perplexity4.341525077819824
INFO:root:current mean train loss 3730.5575213939032
INFO:root:current train perplexity4.343084335327148
INFO:root:current mean train loss 3728.221156379651
INFO:root:current train perplexity4.344570636749268
INFO:root:current mean train loss 3728.540165653935
INFO:root:current train perplexity4.345847129821777
INFO:root:current mean train loss 3727.3602670100495
INFO:root:current train perplexity4.343430042266846
INFO:root:current mean train loss 3725.2563486111676
INFO:root:current train perplexity4.341623783111572
INFO:root:current mean train loss 3726.9187059589462
INFO:root:current train perplexity4.3457841873168945
INFO:root:current mean train loss 3726.799032375016
INFO:root:current train perplexity4.345484733581543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.44s/it]
INFO:root:final mean train loss: 3723.6192767850816
INFO:root:final train perplexity: 4.345216274261475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 4138.097124681405
INFO:root:eval perplexity: 5.329861164093018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 5137.765668287345
INFO:root:eval perplexity: 8.173545837402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [3:23:03<6:01:39, 169.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3713.945732421875
INFO:root:current train perplexity4.323770999908447
INFO:root:current mean train loss 3710.384760044643
INFO:root:current train perplexity4.306495666503906
INFO:root:current mean train loss 3711.793193359375
INFO:root:current train perplexity4.308822154998779
INFO:root:current mean train loss 3719.5880462239584
INFO:root:current train perplexity4.318476676940918
INFO:root:current mean train loss 3719.2570497532893
INFO:root:current train perplexity4.3222174644470215
INFO:root:current mean train loss 3718.6382939877717
INFO:root:current train perplexity4.324261665344238
INFO:root:current mean train loss 3719.4075824652778
INFO:root:current train perplexity4.325259208679199
INFO:root:current mean train loss 3717.4193079007055
INFO:root:current train perplexity4.324717998504639
INFO:root:current mean train loss 3717.9739227120535
INFO:root:current train perplexity4.326475620269775
INFO:root:current mean train loss 3716.572380809295
INFO:root:current train perplexity4.329273700714111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.08s/it]
INFO:root:final mean train loss: 3714.815620360836
INFO:root:final train perplexity: 4.330150127410889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it]
INFO:root:eval mean loss: 4139.066444342863
INFO:root:eval perplexity: 5.3319501876831055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it]
INFO:root:eval mean loss: 5139.9917026817375
INFO:root:eval perplexity: 8.180989265441895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [3:25:52<5:58:24, 169.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3677.5770043062876
INFO:root:current train perplexity4.264629364013672
INFO:root:current mean train loss 3697.1023696315747
INFO:root:current train perplexity4.301609039306641
INFO:root:current mean train loss 3694.5212583508173
INFO:root:current train perplexity4.295602321624756
INFO:root:current mean train loss 3703.9802112230745
INFO:root:current train perplexity4.298653602600098
INFO:root:current mean train loss 3706.7186569940477
INFO:root:current train perplexity4.304862022399902
INFO:root:current mean train loss 3705.5516606587694
INFO:root:current train perplexity4.3046112060546875
INFO:root:current mean train loss 3705.4837726911373
INFO:root:current train perplexity4.30712366104126
INFO:root:current mean train loss 3707.454299868295
INFO:root:current train perplexity4.312589645385742
INFO:root:current mean train loss 3711.0937195861056
INFO:root:current train perplexity4.317108631134033
INFO:root:current mean train loss 3710.4413349698784
INFO:root:current train perplexity4.318558692932129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.41s/it]
INFO:root:final mean train loss: 3708.3829806543167
INFO:root:final train perplexity: 4.319174766540527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it]
INFO:root:eval mean loss: 4142.294618863586
INFO:root:eval perplexity: 5.338913917541504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 5144.464450700909
INFO:root:eval perplexity: 8.195966720581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [3:28:46<5:58:37, 170.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.5226031292927
INFO:root:current train perplexity4.289412021636963
INFO:root:current mean train loss 3675.800469363547
INFO:root:current train perplexity4.282853126525879
INFO:root:current mean train loss 3678.8139514202103
INFO:root:current train perplexity4.27807092666626
INFO:root:current mean train loss 3682.120709743646
INFO:root:current train perplexity4.282467842102051
INFO:root:current mean train loss 3686.179623357147
INFO:root:current train perplexity4.286465167999268
INFO:root:current mean train loss 3690.5587850141446
INFO:root:current train perplexity4.289789199829102
INFO:root:current mean train loss 3692.422655472707
INFO:root:current train perplexity4.294295310974121
INFO:root:current mean train loss 3695.0408177815857
INFO:root:current train perplexity4.294122695922852
INFO:root:current mean train loss 3699.2456345135383
INFO:root:current train perplexity4.298811912536621
INFO:root:current mean train loss 3702.260164231994
INFO:root:current train perplexity4.303903579711914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.61s/it]
INFO:root:final mean train loss: 3699.366822211973
INFO:root:final train perplexity: 4.303838729858398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 4140.782581518728
INFO:root:eval perplexity: 5.335651874542236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it]
INFO:root:eval mean loss: 5148.898215868794
INFO:root:eval perplexity: 8.21083927154541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [3:31:35<5:55:02, 170.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.519494258996
INFO:root:current train perplexity4.268684387207031
INFO:root:current mean train loss 3672.511207158841
INFO:root:current train perplexity4.264494895935059
INFO:root:current mean train loss 3665.860365443405
INFO:root:current train perplexity4.256346225738525
INFO:root:current mean train loss 3677.8202696683115
INFO:root:current train perplexity4.266077518463135
INFO:root:current mean train loss 3678.785912156344
INFO:root:current train perplexity4.270319938659668
INFO:root:current mean train loss 3684.509385760121
INFO:root:current train perplexity4.2781901359558105
INFO:root:current mean train loss 3689.673217948073
INFO:root:current train perplexity4.284650802612305
INFO:root:current mean train loss 3689.87695984727
INFO:root:current train perplexity4.2867045402526855
INFO:root:current mean train loss 3694.7553029299047
INFO:root:current train perplexity4.287389278411865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.83s/it]
INFO:root:final mean train loss: 3691.2578427714684
INFO:root:final train perplexity: 4.290091037750244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 4141.169606743129
INFO:root:eval perplexity: 5.336486339569092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it]
INFO:root:eval mean loss: 5147.469683275155
INFO:root:eval perplexity: 8.20604419708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [3:34:29<5:54:25, 171.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3601.0630929129466
INFO:root:current train perplexity4.1870527267456055
INFO:root:current mean train loss 3698.8740964515187
INFO:root:current train perplexity4.267840385437012
INFO:root:current mean train loss 3692.771921941048
INFO:root:current train perplexity4.279688835144043
INFO:root:current mean train loss 3694.057782598738
INFO:root:current train perplexity4.277534484863281
INFO:root:current mean train loss 3693.423029119318
INFO:root:current train perplexity4.280825138092041
INFO:root:current mean train loss 3687.929111578526
INFO:root:current train perplexity4.273179054260254
INFO:root:current mean train loss 3685.363776368796
INFO:root:current train perplexity4.268043518066406
INFO:root:current mean train loss 3682.714583379376
INFO:root:current train perplexity4.2674880027771
INFO:root:current mean train loss 3686.495171642658
INFO:root:current train perplexity4.271546840667725
INFO:root:current mean train loss 3685.7560090356255
INFO:root:current train perplexity4.276219367980957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.48s/it]
INFO:root:final mean train loss: 3684.17069871964
INFO:root:final train perplexity: 4.278112888336182
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 4138.716388242465
INFO:root:eval perplexity: 5.33119535446167
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.54s/it]
INFO:root:eval mean loss: 5150.762376717642
INFO:root:eval perplexity: 8.21710205078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [3:37:19<5:50:19, 170.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.932649739583
INFO:root:current train perplexity4.2215189933776855
INFO:root:current mean train loss 3680.043410326087
INFO:root:current train perplexity4.2484450340271
INFO:root:current mean train loss 3676.7466603833577
INFO:root:current train perplexity4.246240139007568
INFO:root:current mean train loss 3677.207788473462
INFO:root:current train perplexity4.247380256652832
INFO:root:current mean train loss 3677.006623564571
INFO:root:current train perplexity4.252079963684082
INFO:root:current mean train loss 3674.934040314017
INFO:root:current train perplexity4.2553839683532715
INFO:root:current mean train loss 3669.927947551448
INFO:root:current train perplexity4.254971027374268
INFO:root:current mean train loss 3674.015769094187
INFO:root:current train perplexity4.257108211517334
INFO:root:current mean train loss 3675.692035024444
INFO:root:current train perplexity4.25917911529541
INFO:root:current mean train loss 3678.164511558658
INFO:root:current train perplexity4.2633209228515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.42s/it]
INFO:root:final mean train loss: 3676.0425861112535
INFO:root:final train perplexity: 4.264415740966797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4140.608415752438
INFO:root:eval perplexity: 5.335274696350098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.76s/it]
INFO:root:eval mean loss: 5158.710914990581
INFO:root:eval perplexity: 8.243852615356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:40:10<5:47:45, 171.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3600.3902640964675
INFO:root:current train perplexity4.204413890838623
INFO:root:current mean train loss 3637.2736895801577
INFO:root:current train perplexity4.216627597808838
INFO:root:current mean train loss 3644.778294037276
INFO:root:current train perplexity4.220495223999023
INFO:root:current mean train loss 3646.1134671899185
INFO:root:current train perplexity4.227646827697754
INFO:root:current mean train loss 3654.172476982676
INFO:root:current train perplexity4.230451583862305
INFO:root:current mean train loss 3658.3659341203097
INFO:root:current train perplexity4.236525535583496
INFO:root:current mean train loss 3660.8117879558336
INFO:root:current train perplexity4.244029521942139
INFO:root:current mean train loss 3666.469730276949
INFO:root:current train perplexity4.244595527648926
INFO:root:current mean train loss 3667.1206452194715
INFO:root:current train perplexity4.246975421905518
INFO:root:current mean train loss 3670.0940547128926
INFO:root:current train perplexity4.2495832443237305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.93s/it]
INFO:root:final mean train loss: 3668.4139706396286
INFO:root:final train perplexity: 4.25160026550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it]
INFO:root:eval mean loss: 4135.817457266733
INFO:root:eval perplexity: 5.324948787689209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 5148.815230565714
INFO:root:eval perplexity: 8.210561752319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:42:58<5:42:45, 169.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3640.2804073210687
INFO:root:current train perplexity4.165436267852783
INFO:root:current mean train loss 3654.8602006053197
INFO:root:current train perplexity4.209394454956055
INFO:root:current mean train loss 3651.3791535612827
INFO:root:current train perplexity4.210423469543457
INFO:root:current mean train loss 3647.371383620893
INFO:root:current train perplexity4.220658779144287
INFO:root:current mean train loss 3657.1605873196418
INFO:root:current train perplexity4.22847843170166
INFO:root:current mean train loss 3659.1539805496705
INFO:root:current train perplexity4.234614849090576
INFO:root:current mean train loss 3658.750215896147
INFO:root:current train perplexity4.229489803314209
INFO:root:current mean train loss 3657.516672366621
INFO:root:current train perplexity4.227806091308594
INFO:root:current mean train loss 3657.42675134909
INFO:root:current train perplexity4.229934215545654
INFO:root:current mean train loss 3662.459887773983
INFO:root:current train perplexity4.2353434562683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.76s/it]
INFO:root:final mean train loss: 3660.103150152391
INFO:root:final train perplexity: 4.237683296203613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4136.227436904366
INFO:root:eval perplexity: 5.325831890106201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it]
INFO:root:eval mean loss: 5152.595020916445
INFO:root:eval perplexity: 8.223259925842285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:45:47<5:39:42, 169.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.126727764423
INFO:root:current train perplexity4.209946632385254
INFO:root:current mean train loss 3641.862908891637
INFO:root:current train perplexity4.201333522796631
INFO:root:current mean train loss 3653.4523609113494
INFO:root:current train perplexity4.2130608558654785
INFO:root:current mean train loss 3644.6899774151916
INFO:root:current train perplexity4.220134735107422
INFO:root:current mean train loss 3642.6864917381477
INFO:root:current train perplexity4.2245988845825195
INFO:root:current mean train loss 3644.662889356737
INFO:root:current train perplexity4.222347259521484
INFO:root:current mean train loss 3646.7948019060545
INFO:root:current train perplexity4.2237868309021
INFO:root:current mean train loss 3648.49953781768
INFO:root:current train perplexity4.221746444702148
INFO:root:current mean train loss 3652.9160051493595
INFO:root:current train perplexity4.226109504699707
INFO:root:current mean train loss 3656.2463168305712
INFO:root:current train perplexity4.2271223068237305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.40s/it]
INFO:root:final mean train loss: 3653.267866011589
INFO:root:final train perplexity: 4.22627067565918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.31s/it]
INFO:root:eval mean loss: 4139.721634668661
INFO:root:eval perplexity: 5.3333611488342285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 5158.696723667443
INFO:root:eval perplexity: 8.243803024291992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:48:39<5:38:01, 170.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.5366834275264
INFO:root:current train perplexity4.1466827392578125
INFO:root:current mean train loss 3646.8061108232355
INFO:root:current train perplexity4.185174465179443
INFO:root:current mean train loss 3650.549243262905
INFO:root:current train perplexity4.2000322341918945
INFO:root:current mean train loss 3649.5079018540614
INFO:root:current train perplexity4.202743053436279
INFO:root:current mean train loss 3647.7344350793483
INFO:root:current train perplexity4.199814319610596
INFO:root:current mean train loss 3647.177849527251
INFO:root:current train perplexity4.19614315032959
INFO:root:current mean train loss 3648.675015999324
INFO:root:current train perplexity4.206137657165527
INFO:root:current mean train loss 3647.340150641629
INFO:root:current train perplexity4.207159519195557
INFO:root:current mean train loss 3649.681031282283
INFO:root:current train perplexity4.213026523590088
INFO:root:current mean train loss 3648.9686780726142
INFO:root:current train perplexity4.215697288513184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.57s/it]
INFO:root:final mean train loss: 3646.2113056798134
INFO:root:final train perplexity: 4.2145209312438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 4140.474848321143
INFO:root:eval perplexity: 5.334987163543701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 5164.42475447418
INFO:root:eval perplexity: 8.263138771057129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:51:29<5:34:54, 170.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.8199928977274
INFO:root:current train perplexity4.148021221160889
INFO:root:current mean train loss 3622.6784557711694
INFO:root:current train perplexity4.169486045837402
INFO:root:current mean train loss 3634.5420075061274
INFO:root:current train perplexity4.185346603393555
INFO:root:current mean train loss 3633.7186007647447
INFO:root:current train perplexity4.185482978820801
INFO:root:current mean train loss 3640.3452819153504
INFO:root:current train perplexity4.190987586975098
INFO:root:current mean train loss 3635.358644337697
INFO:root:current train perplexity4.190000534057617
INFO:root:current mean train loss 3637.155814274213
INFO:root:current train perplexity4.195501804351807
INFO:root:current mean train loss 3633.870292451366
INFO:root:current train perplexity4.19577169418335
INFO:root:current mean train loss 3635.65808119746
INFO:root:current train perplexity4.196580410003662
INFO:root:current mean train loss 3638.941068799084
INFO:root:current train perplexity4.198944568634033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.76s/it]
INFO:root:final mean train loss: 3637.932205630887
INFO:root:final train perplexity: 4.20077657699585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it]
INFO:root:eval mean loss: 4138.147741439495
INFO:root:eval perplexity: 5.3299689292907715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.40s/it]
INFO:root:eval mean loss: 5160.083717724956
INFO:root:eval perplexity: 8.248482704162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:54:25<5:35:18, 171.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3597.5581635974704
INFO:root:current train perplexity4.138482093811035
INFO:root:current mean train loss 3614.0344313171013
INFO:root:current train perplexity4.170629024505615
INFO:root:current mean train loss 3621.2892871465065
INFO:root:current train perplexity4.181674480438232
INFO:root:current mean train loss 3627.590005837853
INFO:root:current train perplexity4.183825492858887
INFO:root:current mean train loss 3627.175709536987
INFO:root:current train perplexity4.183724880218506
INFO:root:current mean train loss 3627.5285132833314
INFO:root:current train perplexity4.182417869567871
INFO:root:current mean train loss 3632.0741926052274
INFO:root:current train perplexity4.182662010192871
INFO:root:current mean train loss 3633.4147651642365
INFO:root:current train perplexity4.185623645782471
INFO:root:current mean train loss 3633.2611588956584
INFO:root:current train perplexity4.187527656555176
INFO:root:current mean train loss 3634.442123967663
INFO:root:current train perplexity4.189084053039551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.25s/it]
INFO:root:final mean train loss: 3631.565177363734
INFO:root:final train perplexity: 4.1902384757995605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.54s/it]
INFO:root:eval mean loss: 4138.986774850399
INFO:root:eval perplexity: 5.331777572631836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]
INFO:root:eval mean loss: 5159.586491578014
INFO:root:eval perplexity: 8.246803283691406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:57:17<5:32:22, 171.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3632.075693909551
INFO:root:current train perplexity4.1724748611450195
INFO:root:current mean train loss 3628.5754094709428
INFO:root:current train perplexity4.177770614624023
INFO:root:current mean train loss 3619.039721049066
INFO:root:current train perplexity4.170346260070801
INFO:root:current mean train loss 3615.3916996135868
INFO:root:current train perplexity4.167765140533447
INFO:root:current mean train loss 3620.5839646778795
INFO:root:current train perplexity4.166744232177734
INFO:root:current mean train loss 3621.846618545452
INFO:root:current train perplexity4.17054557800293
INFO:root:current mean train loss 3624.4395324434145
INFO:root:current train perplexity4.172664165496826
INFO:root:current mean train loss 3624.8173337310513
INFO:root:current train perplexity4.174007415771484
INFO:root:current mean train loss 3625.70777992923
INFO:root:current train perplexity4.175081729888916
INFO:root:current mean train loss 3626.872059249485
INFO:root:current train perplexity4.1771063804626465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.55s/it]
INFO:root:final mean train loss: 3624.220791109147
INFO:root:final train perplexity: 4.178114414215088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.10s/it]
INFO:root:eval mean loss: 4140.816631344193
INFO:root:eval perplexity: 5.335724353790283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it]
INFO:root:eval mean loss: 5169.788584607712
INFO:root:eval perplexity: 8.281281471252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [4:00:13<5:32:10, 173.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.979210962223
INFO:root:current train perplexity4.149540901184082
INFO:root:current mean train loss 3630.2809635780377
INFO:root:current train perplexity4.156107425689697
INFO:root:current mean train loss 3629.3902487259184
INFO:root:current train perplexity4.16461181640625
INFO:root:current mean train loss 3627.7841758224768
INFO:root:current train perplexity4.163247108459473
INFO:root:current mean train loss 3621.1718505349686
INFO:root:current train perplexity4.161566257476807
INFO:root:current mean train loss 3623.0215096745465
INFO:root:current train perplexity4.163000583648682
INFO:root:current mean train loss 3621.610759302513
INFO:root:current train perplexity4.160248756408691
INFO:root:current mean train loss 3621.9146905588095
INFO:root:current train perplexity4.1608500480651855
INFO:root:current mean train loss 3619.1333674408065
INFO:root:current train perplexity4.1637864112854
INFO:root:current mean train loss 3619.1178039613123
INFO:root:current train perplexity4.165446758270264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.48s/it]
INFO:root:final mean train loss: 3616.588356264176
INFO:root:final train perplexity: 4.165551662445068
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 4141.652180989583
INFO:root:eval perplexity: 5.337527275085449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it]
INFO:root:eval mean loss: 5175.468199384974
INFO:root:eval perplexity: 8.300538063049316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [4:03:05<5:28:20, 172.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.2037676230243
INFO:root:current train perplexity4.127285003662109
INFO:root:current mean train loss 3606.3877553684824
INFO:root:current train perplexity4.146493911743164
INFO:root:current mean train loss 3594.182654616725
INFO:root:current train perplexity4.137078762054443
INFO:root:current mean train loss 3600.451500550105
INFO:root:current train perplexity4.140427589416504
INFO:root:current mean train loss 3606.410413424827
INFO:root:current train perplexity4.145459175109863
INFO:root:current mean train loss 3603.960610176879
INFO:root:current train perplexity4.147353649139404
INFO:root:current mean train loss 3609.335504656796
INFO:root:current train perplexity4.1514201164245605
INFO:root:current mean train loss 3609.863306067344
INFO:root:current train perplexity4.151923656463623
INFO:root:current mean train loss 3612.010881735749
INFO:root:current train perplexity4.15520715713501
INFO:root:current mean train loss 3613.652225761066
INFO:root:current train perplexity4.156177520751953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.97s/it]
INFO:root:final mean train loss: 3610.678758682743
INFO:root:final train perplexity: 4.155850887298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 4143.419345287566
INFO:root:eval perplexity: 5.341341972351074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 5170.76742748504
INFO:root:eval perplexity: 8.284594535827637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [4:06:01<5:27:20, 173.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.2783819901315
INFO:root:current train perplexity4.0870161056518555
INFO:root:current mean train loss 3584.919767878606
INFO:root:current train perplexity4.0928215980529785
INFO:root:current mean train loss 3600.225385659428
INFO:root:current train perplexity4.111349105834961
INFO:root:current mean train loss 3601.8066344442245
INFO:root:current train perplexity4.119549751281738
INFO:root:current mean train loss 3602.3926456952336
INFO:root:current train perplexity4.123991012573242
INFO:root:current mean train loss 3603.427775817358
INFO:root:current train perplexity4.128907203674316
INFO:root:current mean train loss 3601.289796327001
INFO:root:current train perplexity4.130088806152344
INFO:root:current mean train loss 3602.6505576847485
INFO:root:current train perplexity4.135537147521973
INFO:root:current mean train loss 3605.1238213054294
INFO:root:current train perplexity4.14135217666626

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.84s/it]
INFO:root:final mean train loss: 3604.4602598990164
INFO:root:final train perplexity: 4.145667552947998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 4140.479388297872
INFO:root:eval perplexity: 5.334997177124023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.93s/it]
INFO:root:eval mean loss: 5170.212298454122
INFO:root:eval perplexity: 8.282716751098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [4:08:53<5:23:21, 173.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3534.736572265625
INFO:root:current train perplexity4.088841438293457
INFO:root:current mean train loss 3574.7438206348606
INFO:root:current train perplexity4.108402729034424
INFO:root:current mean train loss 3574.743203750385
INFO:root:current train perplexity4.100985050201416
INFO:root:current mean train loss 3579.990721044761
INFO:root:current train perplexity4.109962463378906
INFO:root:current mean train loss 3581.1253313769776
INFO:root:current train perplexity4.113016605377197
INFO:root:current mean train loss 3584.787583095179
INFO:root:current train perplexity4.1183600425720215
INFO:root:current mean train loss 3585.6971000304466
INFO:root:current train perplexity4.117188930511475
INFO:root:current mean train loss 3590.256195545875
INFO:root:current train perplexity4.121383190155029
INFO:root:current mean train loss 3592.968846683336
INFO:root:current train perplexity4.1244797706604
INFO:root:current mean train loss 3597.4128217897805
INFO:root:current train perplexity4.130307674407959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.60s/it]
INFO:root:final mean train loss: 3596.203082361529
INFO:root:final train perplexity: 4.1321845054626465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 4141.997549936281
INFO:root:eval perplexity: 5.338273525238037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 5172.303326545878
INFO:root:eval perplexity: 8.289799690246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [4:11:46<5:20:38, 173.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.0901100852275
INFO:root:current train perplexity4.143830299377441
INFO:root:current mean train loss 3585.2192052892738
INFO:root:current train perplexity4.091554641723633
INFO:root:current mean train loss 3589.598535619076
INFO:root:current train perplexity4.104079723358154
INFO:root:current mean train loss 3587.7151012359323
INFO:root:current train perplexity4.1148223876953125
INFO:root:current mean train loss 3589.0027229698903
INFO:root:current train perplexity4.11873722076416
INFO:root:current mean train loss 3592.271322410867
INFO:root:current train perplexity4.12524938583374
INFO:root:current mean train loss 3593.3652299796695
INFO:root:current train perplexity4.128461837768555
INFO:root:current mean train loss 3591.0689022530987
INFO:root:current train perplexity4.122045040130615
INFO:root:current mean train loss 3595.2660015966976
INFO:root:current train perplexity4.124645233154297
INFO:root:current mean train loss 3592.42650590011
INFO:root:current train perplexity4.123347282409668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.31s/it]
INFO:root:final mean train loss: 3591.4128787748277
INFO:root:final train perplexity: 4.124383449554443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 4145.925703332779
INFO:root:eval perplexity: 5.346758842468262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 5180.584560962434
INFO:root:eval perplexity: 8.317922592163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [4:14:42<5:19:14, 174.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3630.6959421258225
INFO:root:current train perplexity4.134792327880859
INFO:root:current mean train loss 3561.2483053768383
INFO:root:current train perplexity4.084336757659912
INFO:root:current mean train loss 3566.3765818974744
INFO:root:current train perplexity4.087091445922852
INFO:root:current mean train loss 3571.2551300144496
INFO:root:current train perplexity4.09752082824707
INFO:root:current mean train loss 3575.467558430601
INFO:root:current train perplexity4.098397731781006
INFO:root:current mean train loss 3578.2841942700807
INFO:root:current train perplexity4.10152530670166
INFO:root:current mean train loss 3582.89611007863
INFO:root:current train perplexity4.106813907623291
INFO:root:current mean train loss 3581.8305161519907
INFO:root:current train perplexity4.104658603668213
INFO:root:current mean train loss 3583.5642823159915
INFO:root:current train perplexity4.107285499572754
INFO:root:current mean train loss 3586.3436208897238
INFO:root:current train perplexity4.110182762145996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.59s/it]
INFO:root:final mean train loss: 3582.982684719947
INFO:root:final train perplexity: 4.110688209533691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 4148.491482782026
INFO:root:eval perplexity: 5.3523101806640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.17s/it]
INFO:root:eval mean loss: 5182.308668204233
INFO:root:eval perplexity: 8.323786735534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [4:17:29<5:12:11, 171.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.364935980903
INFO:root:current train perplexity4.106055736541748
INFO:root:current mean train loss 3569.4337206262303
INFO:root:current train perplexity4.083876609802246
INFO:root:current mean train loss 3578.5414866981
INFO:root:current train perplexity4.09224796295166
INFO:root:current mean train loss 3586.7523652522937
INFO:root:current train perplexity4.096040725708008
INFO:root:current mean train loss 3582.2300239223505
INFO:root:current train perplexity4.099794387817383
INFO:root:current mean train loss 3585.2672459640357
INFO:root:current train perplexity4.1028666496276855
INFO:root:current mean train loss 3583.451296086897
INFO:root:current train perplexity4.103569507598877
INFO:root:current mean train loss 3580.106855012036
INFO:root:current train perplexity4.099100112915039
INFO:root:current mean train loss 3583.869790977838
INFO:root:current train perplexity4.101996421813965
INFO:root:current mean train loss 3581.1528362451118
INFO:root:current train perplexity4.103287696838379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.46s/it]
INFO:root:final mean train loss: 3577.528553624307
INFO:root:final train perplexity: 4.1018524169921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4141.89791285738
INFO:root:eval perplexity: 5.338057518005371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it]
INFO:root:eval mean loss: 5178.0379491494905
INFO:root:eval perplexity: 8.3092622756958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [4:20:20<5:08:57, 171.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3560.9347237723214
INFO:root:current train perplexity4.0515289306640625
INFO:root:current mean train loss 3547.5182544849536
INFO:root:current train perplexity4.06579065322876
INFO:root:current mean train loss 3564.035679853723
INFO:root:current train perplexity4.074113368988037
INFO:root:current mean train loss 3568.9566821653452
INFO:root:current train perplexity4.082709789276123
INFO:root:current mean train loss 3568.8586566091954
INFO:root:current train perplexity4.083302974700928
INFO:root:current mean train loss 3572.8328325788552
INFO:root:current train perplexity4.084700584411621
INFO:root:current mean train loss 3572.647192190576
INFO:root:current train perplexity4.086423873901367
INFO:root:current mean train loss 3571.595498179741
INFO:root:current train perplexity4.085019588470459
INFO:root:current mean train loss 3571.8539009870883
INFO:root:current train perplexity4.0854973793029785
INFO:root:current mean train loss 3573.0841520095255
INFO:root:current train perplexity4.089145660400391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.58s/it]
INFO:root:final mean train loss: 3571.0523189421624
INFO:root:final train perplexity: 4.091384410858154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it]
INFO:root:eval mean loss: 4142.1112727171985
INFO:root:eval perplexity: 5.3385186195373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.75s/it]
INFO:root:eval mean loss: 5179.859842503324
INFO:root:eval perplexity: 8.315455436706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [4:23:11<5:05:36, 171.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3581.1079499000725
INFO:root:current train perplexity4.091048717498779
INFO:root:current mean train loss 3571.9712665264424
INFO:root:current train perplexity4.06226921081543
INFO:root:current mean train loss 3552.8307874389147
INFO:root:current train perplexity4.060953617095947
INFO:root:current mean train loss 3563.470895305667
INFO:root:current train perplexity4.074463844299316
INFO:root:current mean train loss 3561.028436596184
INFO:root:current train perplexity4.074232578277588
INFO:root:current mean train loss 3562.576555845707
INFO:root:current train perplexity4.0769267082214355
INFO:root:current mean train loss 3555.0537849770362
INFO:root:current train perplexity4.07176399230957
INFO:root:current mean train loss 3559.7713348676184
INFO:root:current train perplexity4.074411869049072
INFO:root:current mean train loss 3564.8821044053047
INFO:root:current train perplexity4.076320171356201
INFO:root:current mean train loss 3566.467751948983
INFO:root:current train perplexity4.079018592834473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.42s/it]
INFO:root:final mean train loss: 3564.658103942871
INFO:root:final train perplexity: 4.081076622009277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4148.180108252992
INFO:root:eval perplexity: 5.351635932922363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 5191.940116287124
INFO:root:eval perplexity: 8.356636047363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [4:25:59<5:00:56, 170.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3531.1013949525122
INFO:root:current train perplexity4.036764621734619
INFO:root:current mean train loss 3552.8538454573677
INFO:root:current train perplexity4.053403377532959
INFO:root:current mean train loss 3544.0361668560136
INFO:root:current train perplexity4.056057929992676
INFO:root:current mean train loss 3549.5219344005964
INFO:root:current train perplexity4.061469554901123
INFO:root:current mean train loss 3553.0316294735658
INFO:root:current train perplexity4.0648040771484375
INFO:root:current mean train loss 3553.878834026911
INFO:root:current train perplexity4.065125942230225
INFO:root:current mean train loss 3556.310824017737
INFO:root:current train perplexity4.066895008087158
INFO:root:current mean train loss 3560.006911357773
INFO:root:current train perplexity4.069762706756592
INFO:root:current mean train loss 3560.114618429146
INFO:root:current train perplexity4.069821834564209
INFO:root:current mean train loss 3562.0240407917654
INFO:root:current train perplexity4.070241451263428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.11s/it]
INFO:root:final mean train loss: 3558.0489607164936
INFO:root:final train perplexity: 4.070448875427246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 4146.429969733488
INFO:root:eval perplexity: 5.347849369049072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it]
INFO:root:eval mean loss: 5191.038143076795
INFO:root:eval perplexity: 8.353551864624023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [4:28:48<4:57:33, 170.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3532.971650721663
INFO:root:current train perplexity4.047459125518799
INFO:root:current mean train loss 3538.326457473467
INFO:root:current train perplexity4.03645658493042
INFO:root:current mean train loss 3535.0644380429535
INFO:root:current train perplexity4.042237281799316
INFO:root:current mean train loss 3541.6921556733114
INFO:root:current train perplexity4.042695045471191
INFO:root:current mean train loss 3547.0596910530703
INFO:root:current train perplexity4.046891212463379
INFO:root:current mean train loss 3547.9856922238373
INFO:root:current train perplexity4.04463005065918
INFO:root:current mean train loss 3549.2808821219414
INFO:root:current train perplexity4.051042556762695
INFO:root:current mean train loss 3551.349463984272
INFO:root:current train perplexity4.055662155151367
INFO:root:current mean train loss 3553.863374472497
INFO:root:current train perplexity4.058562278747559
INFO:root:current mean train loss 3554.550627739263
INFO:root:current train perplexity4.061159133911133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.27s/it]
INFO:root:final mean train loss: 3552.3192133749685
INFO:root:final train perplexity: 4.061257362365723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4147.171570257092
INFO:root:eval perplexity: 5.349453926086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.60s/it]
INFO:root:eval mean loss: 5191.513725551307
INFO:root:eval perplexity: 8.355177879333496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [4:31:41<4:56:17, 170.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3575.7653152693565
INFO:root:current train perplexity4.042341709136963
INFO:root:current mean train loss 3553.5643186283683
INFO:root:current train perplexity4.043860912322998
INFO:root:current mean train loss 3556.601089763284
INFO:root:current train perplexity4.054352283477783
INFO:root:current mean train loss 3554.1378483161616
INFO:root:current train perplexity4.0490193367004395
INFO:root:current mean train loss 3554.462796523688
INFO:root:current train perplexity4.049345970153809
INFO:root:current mean train loss 3551.075798128858
INFO:root:current train perplexity4.047494888305664
INFO:root:current mean train loss 3550.7051582851154
INFO:root:current train perplexity4.050188064575195
INFO:root:current mean train loss 3550.592503832403
INFO:root:current train perplexity4.051146507263184
INFO:root:current mean train loss 3549.5734423997083
INFO:root:current train perplexity4.052772045135498
INFO:root:current mean train loss 3550.312449253086
INFO:root:current train perplexity4.05189323425293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.38s/it]
INFO:root:final mean train loss: 3546.7942088342484
INFO:root:final train perplexity: 4.052414894104004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 4145.84235787899
INFO:root:eval perplexity: 5.346579551696777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 5193.510141359154
INFO:root:eval perplexity: 8.36199951171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [4:34:35<4:55:08, 171.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3549.8384016927084
INFO:root:current train perplexity4.053168773651123
INFO:root:current mean train loss 3549.883839285714
INFO:root:current train perplexity4.040417194366455
INFO:root:current mean train loss 3540.999527698864
INFO:root:current train perplexity4.026678085327148
INFO:root:current mean train loss 3539.139152994792
INFO:root:current train perplexity4.032984733581543
INFO:root:current mean train loss 3540.4833876439143
INFO:root:current train perplexity4.036749362945557
INFO:root:current mean train loss 3542.226133661685
INFO:root:current train perplexity4.038387775421143
INFO:root:current mean train loss 3543.4896473524304
INFO:root:current train perplexity4.039072513580322
INFO:root:current mean train loss 3543.380327620968
INFO:root:current train perplexity4.039758205413818
INFO:root:current mean train loss 3543.3086760602678
INFO:root:current train perplexity4.040988445281982
INFO:root:current mean train loss 3543.1945177283656
INFO:root:current train perplexity4.041620254516602

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.78s/it]
INFO:root:final mean train loss: 3540.328540802002
INFO:root:final train perplexity: 4.042090892791748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.56s/it]
INFO:root:eval mean loss: 4148.757663591534
INFO:root:eval perplexity: 5.352886199951172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5195.80142017121
INFO:root:eval perplexity: 8.369837760925293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [4:37:26<4:51:34, 171.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3533.5281791227408
INFO:root:current train perplexity4.001569747924805
INFO:root:current mean train loss 3533.6539433380294
INFO:root:current train perplexity4.006117343902588
INFO:root:current mean train loss 3531.0936067938383
INFO:root:current train perplexity4.014962673187256
INFO:root:current mean train loss 3536.7632741106395
INFO:root:current train perplexity4.0200653076171875
INFO:root:current mean train loss 3536.6602644199666
INFO:root:current train perplexity4.026515960693359
INFO:root:current mean train loss 3536.325938203527
INFO:root:current train perplexity4.029697895050049
INFO:root:current mean train loss 3538.1846510969526
INFO:root:current train perplexity4.029669284820557
INFO:root:current mean train loss 3535.855918367856
INFO:root:current train perplexity4.028929710388184
INFO:root:current mean train loss 3536.2131864692456
INFO:root:current train perplexity4.029587268829346
INFO:root:current mean train loss 3536.732367980274
INFO:root:current train perplexity4.031545162200928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.09s/it]
INFO:root:final mean train loss: 3533.6321945805703
INFO:root:final train perplexity: 4.031425952911377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 4147.2129754681955
INFO:root:eval perplexity: 5.349543571472168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.41s/it]
INFO:root:eval mean loss: 5193.519886206228
INFO:root:eval perplexity: 8.362034797668457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [4:40:15<4:47:44, 170.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3535.274408696772
INFO:root:current train perplexity4.013982772827148
INFO:root:current mean train loss 3519.7569164655597
INFO:root:current train perplexity4.006701469421387
INFO:root:current mean train loss 3518.580292901632
INFO:root:current train perplexity4.005577564239502
INFO:root:current mean train loss 3516.9359371253595
INFO:root:current train perplexity4.005178451538086
INFO:root:current mean train loss 3522.133692599605
INFO:root:current train perplexity4.012068271636963
INFO:root:current mean train loss 3525.3263569426817
INFO:root:current train perplexity4.011750221252441
INFO:root:current mean train loss 3530.4917469162674
INFO:root:current train perplexity4.0163893699646
INFO:root:current mean train loss 3531.103761000217
INFO:root:current train perplexity4.019822120666504
INFO:root:current mean train loss 3531.6656870900847
INFO:root:current train perplexity4.0219502449035645
INFO:root:current mean train loss 3531.677205691063
INFO:root:current train perplexity4.023897647857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.54s/it]
INFO:root:final mean train loss: 3528.9034751153763
INFO:root:final train perplexity: 4.023911476135254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4151.782287164783
INFO:root:eval perplexity: 5.35943603515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.68s/it]
INFO:root:eval mean loss: 5198.966064453125
INFO:root:eval perplexity: 8.38067626953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [4:43:07<4:45:07, 171.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.73138119476
INFO:root:current train perplexity3.9606375694274902
INFO:root:current mean train loss 3500.727294921875
INFO:root:current train perplexity3.98476505279541
INFO:root:current mean train loss 3520.318226281616
INFO:root:current train perplexity4.00202751159668
INFO:root:current mean train loss 3515.3455703467653
INFO:root:current train perplexity3.9966745376586914
INFO:root:current mean train loss 3515.852677523015
INFO:root:current train perplexity3.9986798763275146
INFO:root:current mean train loss 3516.303727648294
INFO:root:current train perplexity4.0000319480896
INFO:root:current mean train loss 3519.627131253353
INFO:root:current train perplexity4.005085468292236
INFO:root:current mean train loss 3523.0685772376605
INFO:root:current train perplexity4.009220123291016
INFO:root:current mean train loss 3526.2477633568546
INFO:root:current train perplexity4.012641906738281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.20s/it]
INFO:root:final mean train loss: 3522.6437036452753
INFO:root:final train perplexity: 4.013986110687256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 4148.2632320755765
INFO:root:eval perplexity: 5.351815223693848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it]
INFO:root:eval mean loss: 5199.1494175254875
INFO:root:eval perplexity: 8.381303787231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [4:45:55<4:41:01, 170.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3505.1831403459823
INFO:root:current train perplexity4.0297770500183105
INFO:root:current mean train loss 3498.1222482841704
INFO:root:current train perplexity4.0016584396362305
INFO:root:current mean train loss 3509.5119416610055
INFO:root:current train perplexity4.006378650665283
INFO:root:current mean train loss 3508.3279691317184
INFO:root:current train perplexity3.994706392288208
INFO:root:current mean train loss 3510.8617906125232
INFO:root:current train perplexity4.000599384307861
INFO:root:current mean train loss 3512.5589062692616
INFO:root:current train perplexity3.9982542991638184
INFO:root:current mean train loss 3516.0950849303695
INFO:root:current train perplexity4.003321170806885
INFO:root:current mean train loss 3518.297856742287
INFO:root:current train perplexity4.004383087158203
INFO:root:current mean train loss 3517.044507108213
INFO:root:current train perplexity4.003934860229492
INFO:root:current mean train loss 3519.30215511301
INFO:root:current train perplexity4.006419658660889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.67s/it]
INFO:root:final mean train loss: 3517.9578824812365
INFO:root:final train perplexity: 4.006572723388672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4149.163891082115
INFO:root:eval perplexity: 5.353765487670898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 5202.100310629987
INFO:root:eval perplexity: 8.391423225402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [4:48:42<4:36:13, 169.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3513.24951171875
INFO:root:current train perplexity3.9564051628112793
INFO:root:current mean train loss 3517.494970703125
INFO:root:current train perplexity3.9683759212493896
INFO:root:current mean train loss 3513.4290198037793
INFO:root:current train perplexity3.984006643295288
INFO:root:current mean train loss 3502.7691848028276
INFO:root:current train perplexity3.9760963916778564
INFO:root:current mean train loss 3506.544094150038
INFO:root:current train perplexity3.985543727874756
INFO:root:current mean train loss 3507.0891791186286
INFO:root:current train perplexity3.9864346981048584
INFO:root:current mean train loss 3508.3527363598832
INFO:root:current train perplexity3.9890635013580322
INFO:root:current mean train loss 3508.167059795673
INFO:root:current train perplexity3.9904823303222656
INFO:root:current mean train loss 3510.9359165308665
INFO:root:current train perplexity3.993891716003418
INFO:root:current mean train loss 3513.2765374188866
INFO:root:current train perplexity3.9951963424682617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.30s/it]
INFO:root:final mean train loss: 3511.456543460969
INFO:root:final train perplexity: 3.9963090419769287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.94s/it]
INFO:root:eval mean loss: 4151.298372742132
INFO:root:eval perplexity: 5.3583879470825195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.33s/it]
INFO:root:eval mean loss: 5209.000528105607
INFO:root:eval perplexity: 8.41513442993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [4:51:30<4:33:10, 168.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.2250233525815
INFO:root:current train perplexity3.8769071102142334
INFO:root:current mean train loss 3493.9926063103403
INFO:root:current train perplexity3.95937180519104
INFO:root:current mean train loss 3486.445389136071
INFO:root:current train perplexity3.956953763961792
INFO:root:current mean train loss 3498.9785299862133
INFO:root:current train perplexity3.969644069671631
INFO:root:current mean train loss 3501.88022045379
INFO:root:current train perplexity3.97428035736084
INFO:root:current mean train loss 3503.4182913143823
INFO:root:current train perplexity3.9782090187072754
INFO:root:current mean train loss 3506.703666576796
INFO:root:current train perplexity3.982691764831543
INFO:root:current mean train loss 3501.9106786366483
INFO:root:current train perplexity3.983494997024536
INFO:root:current mean train loss 3505.645506032617
INFO:root:current train perplexity3.9849987030029297
INFO:root:current mean train loss 3508.20751371208
INFO:root:current train perplexity3.9868083000183105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.71s/it]
INFO:root:final mean train loss: 3505.102008019724
INFO:root:final train perplexity: 3.9863030910491943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4151.223494292996
INFO:root:eval perplexity: 5.358225345611572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it]
INFO:root:eval mean loss: 5207.234465037677
INFO:root:eval perplexity: 8.409059524536133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [4:54:21<4:31:07, 169.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3458.5555695564517
INFO:root:current train perplexity3.9106240272521973
INFO:root:current mean train loss 3494.6267518487593
INFO:root:current train perplexity3.9696738719940186
INFO:root:current mean train loss 3490.5376357041396
INFO:root:current train perplexity3.9643890857696533
INFO:root:current mean train loss 3490.6485046202324
INFO:root:current train perplexity3.965160846710205
INFO:root:current mean train loss 3493.979510880402
INFO:root:current train perplexity3.969329357147217
INFO:root:current mean train loss 3496.9114197122176
INFO:root:current train perplexity3.973588228225708
INFO:root:current mean train loss 3501.770453645008
INFO:root:current train perplexity3.9774413108825684
INFO:root:current mean train loss 3501.326236333469
INFO:root:current train perplexity3.979673147201538
INFO:root:current mean train loss 3501.8107557606613
INFO:root:current train perplexity3.9814047813415527
INFO:root:current mean train loss 3503.595840273815
INFO:root:current train perplexity3.9809625148773193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.39s/it]
INFO:root:final mean train loss: 3501.0044158812493
INFO:root:final train perplexity: 3.9798638820648193
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it]
INFO:root:eval mean loss: 4154.154940990691
INFO:root:eval perplexity: 5.364580154418945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.22s/it]
INFO:root:eval mean loss: 5210.676544838763
INFO:root:eval perplexity: 8.420905113220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [4:57:08<4:27:21, 168.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.828863681891
INFO:root:current train perplexity3.9813644886016846
INFO:root:current mean train loss 3498.360388447055
INFO:root:current train perplexity3.973860263824463
INFO:root:current mean train loss 3499.2509898421154
INFO:root:current train perplexity3.9681432247161865
INFO:root:current mean train loss 3498.75271939528
INFO:root:current train perplexity3.9686665534973145
INFO:root:current mean train loss 3492.990762141408
INFO:root:current train perplexity3.9649605751037598
INFO:root:current mean train loss 3492.462078030786
INFO:root:current train perplexity3.9649269580841064
INFO:root:current mean train loss 3494.1706890649452
INFO:root:current train perplexity3.968202829360962
INFO:root:current mean train loss 3495.834955982007
INFO:root:current train perplexity3.969297170639038
INFO:root:current mean train loss 3496.2107463195584
INFO:root:current train perplexity3.970367670059204
INFO:root:current mean train loss 3494.771376994725
INFO:root:current train perplexity3.967902421951294

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.21s/it]
INFO:root:final mean train loss: 3494.5556184091874
INFO:root:final train perplexity: 3.9697508811950684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4152.946128033577
INFO:root:eval perplexity: 5.361958980560303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.65s/it]
INFO:root:eval mean loss: 5213.676752618018
INFO:root:eval perplexity: 8.431242942810059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [5:00:02<4:26:57, 170.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3473.613442278923
INFO:root:current train perplexity3.9261374473571777
INFO:root:current mean train loss 3485.0931022799746
INFO:root:current train perplexity3.9443423748016357
INFO:root:current mean train loss 3483.971110355516
INFO:root:current train perplexity3.949385404586792
INFO:root:current mean train loss 3487.550268343615
INFO:root:current train perplexity3.9494569301605225
INFO:root:current mean train loss 3487.5004915583054
INFO:root:current train perplexity3.9506731033325195
INFO:root:current mean train loss 3485.138561632341
INFO:root:current train perplexity3.950003147125244
INFO:root:current mean train loss 3489.341918001956
INFO:root:current train perplexity3.9519035816192627
INFO:root:current mean train loss 3491.47115610881
INFO:root:current train perplexity3.9551544189453125
INFO:root:current mean train loss 3493.1825399387544
INFO:root:current train perplexity3.959430456161499
INFO:root:current mean train loss 3492.632616053161
INFO:root:current train perplexity3.961214065551758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.95s/it]
INFO:root:final mean train loss: 3490.514341046733
INFO:root:final train perplexity: 3.9634265899658203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 4155.253873351618
INFO:root:eval perplexity: 5.3669657707214355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it]
INFO:root:eval mean loss: 5217.712435242132
INFO:root:eval perplexity: 8.445164680480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [5:02:51<4:23:12, 169.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3473.9988325639206
INFO:root:current train perplexity3.961270332336426
INFO:root:current mean train loss 3472.0661904611893
INFO:root:current train perplexity3.93676495552063
INFO:root:current mean train loss 3478.1780867034313
INFO:root:current train perplexity3.9384942054748535
INFO:root:current mean train loss 3480.5801496478875
INFO:root:current train perplexity3.9374632835388184
INFO:root:current mean train loss 3481.5929161658655
INFO:root:current train perplexity3.9379849433898926
INFO:root:current mean train loss 3488.251978198902
INFO:root:current train perplexity3.9468681812286377
INFO:root:current mean train loss 3485.9216860239744
INFO:root:current train perplexity3.948638677597046
INFO:root:current mean train loss 3485.7922001112374
INFO:root:current train perplexity3.952566385269165
INFO:root:current mean train loss 3486.0790433114034
INFO:root:current train perplexity3.9530093669891357
INFO:root:current mean train loss 3486.9299814913284
INFO:root:current train perplexity3.9524590969085693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.89s/it]
INFO:root:final mean train loss: 3483.8815746307373
INFO:root:final train perplexity: 3.953068256378174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4156.005866300975
INFO:root:eval perplexity: 5.368597984313965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.90s/it]
INFO:root:eval mean loss: 5221.158594442598
INFO:root:eval perplexity: 8.457077026367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [5:05:39<4:19:30, 169.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.8181656125994
INFO:root:current train perplexity3.927910804748535
INFO:root:current mean train loss 3471.5744613928296
INFO:root:current train perplexity3.9112980365753174
INFO:root:current mean train loss 3484.7964377747744
INFO:root:current train perplexity3.9237568378448486
INFO:root:current mean train loss 3482.259458263387
INFO:root:current train perplexity3.926107883453369
INFO:root:current mean train loss 3479.5251628307237
INFO:root:current train perplexity3.9259347915649414
INFO:root:current mean train loss 3481.9325837970414
INFO:root:current train perplexity3.931313991546631
INFO:root:current mean train loss 3482.4969373792187
INFO:root:current train perplexity3.9330296516418457
INFO:root:current mean train loss 3480.0574450411614
INFO:root:current train perplexity3.9360690116882324
INFO:root:current mean train loss 3481.8030271740113
INFO:root:current train perplexity3.9424846172332764
INFO:root:current mean train loss 3482.798587280147
INFO:root:current train perplexity3.9463860988616943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.85s/it]
INFO:root:final mean train loss: 3480.4385389512586
INFO:root:final train perplexity: 3.947702169418335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 4157.62764225953
INFO:root:eval perplexity: 5.372119903564453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 5222.696806779145
INFO:root:eval perplexity: 8.462397575378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [5:08:32<4:18:41, 170.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.9407357229315
INFO:root:current train perplexity3.918759346008301
INFO:root:current mean train loss 3458.3896612870067
INFO:root:current train perplexity3.915659189224243
INFO:root:current mean train loss 3456.5545658801316
INFO:root:current train perplexity3.9174323081970215
INFO:root:current mean train loss 3463.0570584937245
INFO:root:current train perplexity3.9230146408081055
INFO:root:current mean train loss 3469.159282319865
INFO:root:current train perplexity3.9310295581817627
INFO:root:current mean train loss 3473.0965257634634
INFO:root:current train perplexity3.9342305660247803
INFO:root:current mean train loss 3470.8901418125934
INFO:root:current train perplexity3.93536376953125
INFO:root:current mean train loss 3470.3614098218627
INFO:root:current train perplexity3.935666084289551
INFO:root:current mean train loss 3470.9457413578143
INFO:root:current train perplexity3.9354751110076904
INFO:root:current mean train loss 3475.7419762969876
INFO:root:current train perplexity3.937685251235962

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.22s/it]
INFO:root:final mean train loss: 3473.951060202814
INFO:root:final train perplexity: 3.9376120567321777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it]
INFO:root:eval mean loss: 4156.875109084109
INFO:root:eval perplexity: 5.370484828948975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.49s/it]
INFO:root:eval mean loss: 5221.66565547429
INFO:root:eval perplexity: 8.458830833435059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [5:11:26<4:17:09, 171.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3438.4879011323183
INFO:root:current train perplexity3.894488573074341
INFO:root:current mean train loss 3450.923328932437
INFO:root:current train perplexity3.9113316535949707
INFO:root:current mean train loss 3464.0007192960347
INFO:root:current train perplexity3.9123711585998535
INFO:root:current mean train loss 3465.816366955599
INFO:root:current train perplexity3.9160315990448
INFO:root:current mean train loss 3463.5349447294166
INFO:root:current train perplexity3.916743516921997
INFO:root:current mean train loss 3468.506045326668
INFO:root:current train perplexity3.9209864139556885
INFO:root:current mean train loss 3468.286758804883
INFO:root:current train perplexity3.924151659011841
INFO:root:current mean train loss 3468.8148470720676
INFO:root:current train perplexity3.9253928661346436
INFO:root:current mean train loss 3468.7132703067227
INFO:root:current train perplexity3.926866292953491
INFO:root:current mean train loss 3471.7595524071917
INFO:root:current train perplexity3.9293212890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.50s/it]
INFO:root:final mean train loss: 3468.962544533514
INFO:root:final train perplexity: 3.9298694133758545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it]
INFO:root:eval mean loss: 4158.586415392288
INFO:root:eval perplexity: 5.374202251434326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it]
INFO:root:eval mean loss: 5224.414252964318
INFO:root:eval perplexity: 8.468343734741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [5:14:15<4:13:25, 170.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3432.4755578753593
INFO:root:current train perplexity3.9068589210510254
INFO:root:current mean train loss 3448.6007687165775
INFO:root:current train perplexity3.91349196434021
INFO:root:current mean train loss 3454.1403315208513
INFO:root:current train perplexity3.916276216506958
INFO:root:current mean train loss 3454.6258699481186
INFO:root:current train perplexity3.9173245429992676
INFO:root:current mean train loss 3459.5180999943855
INFO:root:current train perplexity3.9212794303894043
INFO:root:current mean train loss 3458.627617753141
INFO:root:current train perplexity3.9191172122955322
INFO:root:current mean train loss 3459.18356994007
INFO:root:current train perplexity3.918853759765625
INFO:root:current mean train loss 3462.937430201219
INFO:root:current train perplexity3.9195914268493652
INFO:root:current mean train loss 3466.225076737775
INFO:root:current train perplexity3.922186851501465
INFO:root:current mean train loss 3466.7608624026407
INFO:root:current train perplexity3.9224319458007812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:19<00:00, 139.14s/it]
INFO:root:final mean train loss: 3463.9463084436234
INFO:root:final train perplexity: 3.9220991134643555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 4159.912888547207
INFO:root:eval perplexity: 5.377087116241455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it]
INFO:root:eval mean loss: 5224.631541583555
INFO:root:eval perplexity: 8.469094276428223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [5:16:59<4:07:23, 168.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3430.3873663651316
INFO:root:current train perplexity3.8920998573303223
INFO:root:current mean train loss 3454.5099884815704
INFO:root:current train perplexity3.9016239643096924
INFO:root:current mean train loss 3459.622280521716
INFO:root:current train perplexity3.8985164165496826
INFO:root:current mean train loss 3457.3617212223103
INFO:root:current train perplexity3.9025766849517822
INFO:root:current mean train loss 3455.5481292416353
INFO:root:current train perplexity3.90669322013855
INFO:root:current mean train loss 3457.30148659073
INFO:root:current train perplexity3.910740375518799
INFO:root:current mean train loss 3460.2363347993482
INFO:root:current train perplexity3.9105446338653564
INFO:root:current mean train loss 3458.0123768548547
INFO:root:current train perplexity3.910377264022827
INFO:root:current mean train loss 3460.7116156380935
INFO:root:current train perplexity3.91528582572937

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.84s/it]
INFO:root:final mean train loss: 3459.724596638833
INFO:root:final train perplexity: 3.91557240486145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it]
INFO:root:eval mean loss: 4165.625509059176
INFO:root:eval perplexity: 5.389521598815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it]
INFO:root:eval mean loss: 5238.919795475953
INFO:root:eval perplexity: 8.518719673156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [5:19:54<4:07:23, 170.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.3346354166665
INFO:root:current train perplexity3.8941051959991455
INFO:root:current mean train loss 3436.9316951418386
INFO:root:current train perplexity3.8877484798431396
INFO:root:current mean train loss 3442.789503877386
INFO:root:current train perplexity3.908334255218506
INFO:root:current mean train loss 3448.1166250902434
INFO:root:current train perplexity3.907400608062744
INFO:root:current mean train loss 3448.1726728491394
INFO:root:current train perplexity3.9005227088928223
INFO:root:current mean train loss 3449.912353030256
INFO:root:current train perplexity3.9003818035125732
INFO:root:current mean train loss 3453.318089322269
INFO:root:current train perplexity3.9011263847351074
INFO:root:current mean train loss 3454.2106787734488
INFO:root:current train perplexity3.9017863273620605
INFO:root:current mean train loss 3453.0305905466803
INFO:root:current train perplexity3.901857376098633
INFO:root:current mean train loss 3454.079597684368
INFO:root:current train perplexity3.9029645919799805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.19s/it]
INFO:root:final mean train loss: 3453.9010741941393
INFO:root:final train perplexity: 3.906586170196533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4161.7600063026375
INFO:root:eval perplexity: 5.381104469299316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it]
INFO:root:eval mean loss: 5235.288283327793
INFO:root:eval perplexity: 8.50607967376709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [5:22:43<4:03:41, 170.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3463.9127974076705
INFO:root:current train perplexity3.885814905166626
INFO:root:current mean train loss 3456.3438093855575
INFO:root:current train perplexity3.905587673187256
INFO:root:current mean train loss 3448.2986198533767
INFO:root:current train perplexity3.902230978012085
INFO:root:current mean train loss 3447.857326102793
INFO:root:current train perplexity3.901308059692383
INFO:root:current mean train loss 3447.1706768694876
INFO:root:current train perplexity3.8970694541931152
INFO:root:current mean train loss 3452.8484240268776
INFO:root:current train perplexity3.8999061584472656
INFO:root:current mean train loss 3448.856548802552
INFO:root:current train perplexity3.8957571983337402
INFO:root:current mean train loss 3450.46393792304
INFO:root:current train perplexity3.8948869705200195
INFO:root:current mean train loss 3451.322971254624
INFO:root:current train perplexity3.8972339630126953
INFO:root:current mean train loss 3450.988399970414
INFO:root:current train perplexity3.898805856704712

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.29s/it]
INFO:root:final mean train loss: 3449.6478385925293
INFO:root:final train perplexity: 3.900036334991455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 4163.303548177083
INFO:root:eval perplexity: 5.384462833404541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 5237.858131787456
INFO:root:eval perplexity: 8.515024185180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [5:25:37<4:02:37, 171.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.77099609375
INFO:root:current train perplexity3.902862787246704
INFO:root:current mean train loss 3450.3065195804884
INFO:root:current train perplexity3.8853633403778076
INFO:root:current mean train loss 3446.104540123787
INFO:root:current train perplexity3.8793554306030273
INFO:root:current mean train loss 3441.500149239567
INFO:root:current train perplexity3.8831660747528076
INFO:root:current mean train loss 3444.0015062136413
INFO:root:current train perplexity3.889840602874756
INFO:root:current mean train loss 3444.7692066699783
INFO:root:current train perplexity3.8900816440582275
INFO:root:current mean train loss 3444.1872250952897
INFO:root:current train perplexity3.8888275623321533
INFO:root:current mean train loss 3447.5846298705883
INFO:root:current train perplexity3.8909683227539062
INFO:root:current mean train loss 3445.6085498702687
INFO:root:current train perplexity3.8904521465301514
INFO:root:current mean train loss 3446.680857196596
INFO:root:current train perplexity3.8911914825439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.44s/it]
INFO:root:final mean train loss: 3444.8380020510767
INFO:root:final train perplexity: 3.8926427364349365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.31s/it]
INFO:root:eval mean loss: 4165.400104928524
INFO:root:eval perplexity: 5.3890299797058105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.58s/it]
INFO:root:eval mean loss: 5243.287777731604
INFO:root:eval perplexity: 8.533949851989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [5:28:29<4:00:15, 171.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3397.4498878761574
INFO:root:current train perplexity3.8823001384735107
INFO:root:current mean train loss 3418.790788785679
INFO:root:current train perplexity3.8617472648620605
INFO:root:current mean train loss 3428.276736087211
INFO:root:current train perplexity3.873135805130005
INFO:root:current mean train loss 3431.4605305989585
INFO:root:current train perplexity3.8770651817321777
INFO:root:current mean train loss 3438.1045745206384
INFO:root:current train perplexity3.8786771297454834
INFO:root:current mean train loss 3444.3188786950013
INFO:root:current train perplexity3.8801236152648926
INFO:root:current mean train loss 3442.5433592971244
INFO:root:current train perplexity3.880608558654785
INFO:root:current mean train loss 3441.4438976933243
INFO:root:current train perplexity3.881072998046875
INFO:root:current mean train loss 3441.224442875227
INFO:root:current train perplexity3.883399486541748
INFO:root:current mean train loss 3442.243297852616
INFO:root:current train perplexity3.8843088150024414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.21s/it]
INFO:root:final mean train loss: 3439.9522222703504
INFO:root:final train perplexity: 3.885146379470825
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it]
INFO:root:eval mean loss: 4166.330398451352
INFO:root:eval perplexity: 5.391057968139648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.87s/it]
INFO:root:eval mean loss: 5241.98013110871
INFO:root:eval perplexity: 8.529389381408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [5:31:20<3:57:09, 171.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3438.9023088727677
INFO:root:current train perplexity3.8584024906158447
INFO:root:current mean train loss 3416.539995659722
INFO:root:current train perplexity3.839498281478882
INFO:root:current mean train loss 3426.4696268284574
INFO:root:current train perplexity3.8514697551727295
INFO:root:current mean train loss 3436.6058739505597
INFO:root:current train perplexity3.8680214881896973
INFO:root:current mean train loss 3431.8558453439296
INFO:root:current train perplexity3.8668596744537354
INFO:root:current mean train loss 3435.659819472839
INFO:root:current train perplexity3.8688392639160156
INFO:root:current mean train loss 3436.7320235605316
INFO:root:current train perplexity3.86899733543396
INFO:root:current mean train loss 3435.1318203257865
INFO:root:current train perplexity3.8713576793670654
INFO:root:current mean train loss 3436.8554213837947
INFO:root:current train perplexity3.8743414878845215
INFO:root:current mean train loss 3436.2438500062667
INFO:root:current train perplexity3.8753368854522705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.74s/it]
INFO:root:final mean train loss: 3434.2152299573345
INFO:root:final train perplexity: 3.8763628005981445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4169.309488932292
INFO:root:eval perplexity: 5.397556304931641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.73s/it]
INFO:root:eval mean loss: 5248.775920462101
INFO:root:eval perplexity: 8.553125381469727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [5:34:15<3:55:35, 172.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.3835676326307
INFO:root:current train perplexity3.8440206050872803
INFO:root:current mean train loss 3426.015681340144
INFO:root:current train perplexity3.849651575088501
INFO:root:current mean train loss 3424.6625916280864
INFO:root:current train perplexity3.8533778190612793
INFO:root:current mean train loss 3416.4288767822977
INFO:root:current train perplexity3.8477067947387695
INFO:root:current mean train loss 3421.898835399619
INFO:root:current train perplexity3.85134220123291
INFO:root:current mean train loss 3424.311339095592
INFO:root:current train perplexity3.8545289039611816
INFO:root:current mean train loss 3427.6730334339763
INFO:root:current train perplexity3.859746217727661
INFO:root:current mean train loss 3433.4075702651835
INFO:root:current train perplexity3.863701581954956
INFO:root:current mean train loss 3432.9132556485392
INFO:root:current train perplexity3.8668150901794434
INFO:root:current mean train loss 3433.7620066443533
INFO:root:current train perplexity3.869161605834961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.89s/it]
INFO:root:final mean train loss: 3431.1823571728123
INFO:root:final train perplexity: 3.871727466583252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4170.748112671764
INFO:root:eval perplexity: 5.400698184967041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.56s/it]
INFO:root:eval mean loss: 5247.81506953679
INFO:root:eval perplexity: 8.549765586853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [5:37:05<3:51:36, 171.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3402.1932684206495
INFO:root:current train perplexity3.8174028396606445
INFO:root:current mean train loss 3423.671454625414
INFO:root:current train perplexity3.8378045558929443
INFO:root:current mean train loss 3419.205243479208
INFO:root:current train perplexity3.848513126373291
INFO:root:current mean train loss 3417.2912882834758
INFO:root:current train perplexity3.8483364582061768
INFO:root:current mean train loss 3423.2290602047533
INFO:root:current train perplexity3.855700731277466
INFO:root:current mean train loss 3421.4259505090176
INFO:root:current train perplexity3.859215259552002
INFO:root:current mean train loss 3424.1307779947915
INFO:root:current train perplexity3.8609018325805664
INFO:root:current mean train loss 3427.679036349971
INFO:root:current train perplexity3.861212968826294
INFO:root:current mean train loss 3426.2703279345073
INFO:root:current train perplexity3.8607425689697266
INFO:root:current mean train loss 3427.8017077521195
INFO:root:current train perplexity3.8630099296569824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.29s/it]
INFO:root:final mean train loss: 3425.8615152912757
INFO:root:final train perplexity: 3.8636081218719482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.57s/it]
INFO:root:eval mean loss: 4169.643464649823
INFO:root:eval perplexity: 5.39828634262085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.26s/it]
INFO:root:eval mean loss: 5243.817057291667
INFO:root:eval perplexity: 8.535799026489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [5:39:53<3:47:23, 170.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3389.3195138704978
INFO:root:current train perplexity3.843316078186035
INFO:root:current mean train loss 3399.0525178729363
INFO:root:current train perplexity3.8437087535858154
INFO:root:current mean train loss 3403.9103212098817
INFO:root:current train perplexity3.841508150100708
INFO:root:current mean train loss 3405.0367122214484
INFO:root:current train perplexity3.8428266048431396
INFO:root:current mean train loss 3411.374676606754
INFO:root:current train perplexity3.840672492980957
INFO:root:current mean train loss 3412.2929320633943
INFO:root:current train perplexity3.8445980548858643
INFO:root:current mean train loss 3413.7224950949594
INFO:root:current train perplexity3.8480985164642334
INFO:root:current mean train loss 3417.8988144865775
INFO:root:current train perplexity3.851952314376831
INFO:root:current mean train loss 3422.580411793328
INFO:root:current train perplexity3.8550848960876465
INFO:root:current mean train loss 3424.177182703744
INFO:root:current train perplexity3.8562684059143066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.04s/it]
INFO:root:final mean train loss: 3421.577159266318
INFO:root:final train perplexity: 3.8570830821990967
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.43s/it]
INFO:root:eval mean loss: 4171.1940848709
INFO:root:eval perplexity: 5.401671409606934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it]
INFO:root:eval mean loss: 5252.80305816434
INFO:root:eval perplexity: 8.567221641540527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [5:42:41<3:43:39, 169.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3422.9882994694494
INFO:root:current train perplexity3.8503804206848145
INFO:root:current mean train loss 3421.312320183851
INFO:root:current train perplexity3.8435349464416504
INFO:root:current mean train loss 3415.7666939153205
INFO:root:current train perplexity3.840488910675049
INFO:root:current mean train loss 3418.700293101797
INFO:root:current train perplexity3.8415491580963135
INFO:root:current mean train loss 3421.254247628647
INFO:root:current train perplexity3.841768264770508
INFO:root:current mean train loss 3422.789623119213
INFO:root:current train perplexity3.8460988998413086
INFO:root:current mean train loss 3420.2395345296104
INFO:root:current train perplexity3.8478641510009766
INFO:root:current mean train loss 3422.2793322069547
INFO:root:current train perplexity3.8479084968566895
INFO:root:current mean train loss 3420.8236102287883
INFO:root:current train perplexity3.849156379699707
INFO:root:current mean train loss 3418.140751488576
INFO:root:current train perplexity3.8485403060913086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.41s/it]
INFO:root:final mean train loss: 3416.784853227677
INFO:root:final train perplexity: 3.849797487258911
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it]
INFO:root:eval mean loss: 4170.854447168661
INFO:root:eval perplexity: 5.400929927825928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 5252.143880208333
INFO:root:eval perplexity: 8.564909934997559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [5:45:34<3:42:04, 170.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3412.519150390625
INFO:root:current train perplexity3.8318288326263428
INFO:root:current mean train loss 3410.9225223214285
INFO:root:current train perplexity3.8417654037475586
INFO:root:current mean train loss 3408.176273082386
INFO:root:current train perplexity3.837127685546875
INFO:root:current mean train loss 3413.933217447917
INFO:root:current train perplexity3.844855785369873
INFO:root:current mean train loss 3412.8432730263157
INFO:root:current train perplexity3.8427987098693848
INFO:root:current mean train loss 3409.610712890625
INFO:root:current train perplexity3.8398780822753906
INFO:root:current mean train loss 3413.3406344039354
INFO:root:current train perplexity3.8433420658111572
INFO:root:current mean train loss 3413.3709737273184
INFO:root:current train perplexity3.843200445175171
INFO:root:current mean train loss 3413.128309709821
INFO:root:current train perplexity3.841749906539917
INFO:root:current mean train loss 3415.3359352463945
INFO:root:current train perplexity3.844599485397339

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.87s/it]
INFO:root:final mean train loss: 3413.656277256627
INFO:root:final train perplexity: 3.845048189163208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 4175.981329302415
INFO:root:eval perplexity: 5.412137031555176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.52s/it]
INFO:root:eval mean loss: 5264.205078125
INFO:root:eval perplexity: 8.607257843017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [5:48:24<3:38:58, 170.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.505288733057
INFO:root:current train perplexity3.8166446685791016
INFO:root:current mean train loss 3394.218755336407
INFO:root:current train perplexity3.8218154907226562
INFO:root:current mean train loss 3406.8974307434296
INFO:root:current train perplexity3.833610773086548
INFO:root:current mean train loss 3406.239236776885
INFO:root:current train perplexity3.833510637283325
INFO:root:current mean train loss 3406.334029867042
INFO:root:current train perplexity3.834393262863159
INFO:root:current mean train loss 3406.1336672015705
INFO:root:current train perplexity3.834059953689575
INFO:root:current mean train loss 3410.276272104914
INFO:root:current train perplexity3.836503744125366
INFO:root:current mean train loss 3411.6283830469747
INFO:root:current train perplexity3.835754632949829
INFO:root:current mean train loss 3411.5188707155116
INFO:root:current train perplexity3.8372936248779297
INFO:root:current mean train loss 3412.0165124002574
INFO:root:current train perplexity3.838228702545166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.11s/it]
INFO:root:final mean train loss: 3409.3863957928074
INFO:root:final train perplexity: 3.8385770320892334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4173.252998947251
INFO:root:eval perplexity: 5.406169891357422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.83s/it]
INFO:root:eval mean loss: 5262.835220661569
INFO:root:eval perplexity: 8.602437019348145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [5:51:15<3:36:09, 170.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.580346411401
INFO:root:current train perplexity3.8304545879364014
INFO:root:current mean train loss 3397.64669016893
INFO:root:current train perplexity3.8170623779296875
INFO:root:current mean train loss 3394.9127587387243
INFO:root:current train perplexity3.8153445720672607
INFO:root:current mean train loss 3398.7872305087117
INFO:root:current train perplexity3.8183767795562744
INFO:root:current mean train loss 3400.1141538911343
INFO:root:current train perplexity3.81900954246521
INFO:root:current mean train loss 3400.692503436971
INFO:root:current train perplexity3.8204519748687744
INFO:root:current mean train loss 3403.332892278514
INFO:root:current train perplexity3.8242344856262207
INFO:root:current mean train loss 3406.47497913539
INFO:root:current train perplexity3.826551914215088
INFO:root:current mean train loss 3406.0436874715033
INFO:root:current train perplexity3.8277924060821533
INFO:root:current mean train loss 3407.366325740256
INFO:root:current train perplexity3.8316030502319336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.94s/it]
INFO:root:final mean train loss: 3404.7526601975965
INFO:root:final train perplexity: 3.8315656185150146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 4175.524074689716
INFO:root:eval perplexity: 5.411137104034424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.67s/it]
INFO:root:eval mean loss: 5258.911830604499
INFO:root:eval perplexity: 8.58864688873291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [5:54:05<3:33:07, 170.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3407.9313175702337
INFO:root:current train perplexity3.7905704975128174
INFO:root:current mean train loss 3405.6568658723304
INFO:root:current train perplexity3.8096067905426025
INFO:root:current mean train loss 3399.9102730129075
INFO:root:current train perplexity3.8116390705108643
INFO:root:current mean train loss 3404.7342936197915
INFO:root:current train perplexity3.8172361850738525
INFO:root:current mean train loss 3400.671550620773
INFO:root:current train perplexity3.818406820297241
INFO:root:current mean train loss 3401.697220383582
INFO:root:current train perplexity3.8230013847351074
INFO:root:current mean train loss 3404.2706964189915
INFO:root:current train perplexity3.822733163833618
INFO:root:current mean train loss 3402.9346503686247
INFO:root:current train perplexity3.822798728942871
INFO:root:current mean train loss 3401.4585650723025
INFO:root:current train perplexity3.8224997520446777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.66s/it]
INFO:root:final mean train loss: 3401.2301695423744
INFO:root:final train perplexity: 3.826244592666626
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4174.758295586768
INFO:root:eval perplexity: 5.409462928771973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 5263.996635707557
INFO:root:eval perplexity: 8.606523513793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [5:56:54<3:29:47, 170.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.232491629464
INFO:root:current train perplexity3.8334479331970215
INFO:root:current mean train loss 3382.6841847072137
INFO:root:current train perplexity3.7916085720062256
INFO:root:current mean train loss 3386.9383220580467
INFO:root:current train perplexity3.8059067726135254
INFO:root:current mean train loss 3393.440175208673
INFO:root:current train perplexity3.8078179359436035
INFO:root:current mean train loss 3394.81561624213
INFO:root:current train perplexity3.8120803833007812
INFO:root:current mean train loss 3397.859950439935
INFO:root:current train perplexity3.8120148181915283
INFO:root:current mean train loss 3393.2454200505817
INFO:root:current train perplexity3.8093247413635254
INFO:root:current mean train loss 3399.0990320014143
INFO:root:current train perplexity3.8151111602783203
INFO:root:current mean train loss 3400.978847801464
INFO:root:current train perplexity3.8180928230285645
INFO:root:current mean train loss 3398.9378178942425
INFO:root:current train perplexity3.8183038234710693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.55s/it]
INFO:root:final mean train loss: 3395.918031446395
INFO:root:final train perplexity: 3.8182337284088135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it]
INFO:root:eval mean loss: 4176.256370165669
INFO:root:eval perplexity: 5.4127397537231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.22s/it]
INFO:root:eval mean loss: 5269.194741107048
INFO:root:eval perplexity: 8.624837875366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [5:59:42<3:26:13, 169.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3415.320833333333
INFO:root:current train perplexity3.7493488788604736
INFO:root:current mean train loss 3372.1030018682063
INFO:root:current train perplexity3.7764415740966797
INFO:root:current mean train loss 3377.241340388808
INFO:root:current train perplexity3.782435655593872
INFO:root:current mean train loss 3378.2052742125497
INFO:root:current train perplexity3.7894785404205322
INFO:root:current mean train loss 3383.839380176958
INFO:root:current train perplexity3.800623655319214
INFO:root:current mean train loss 3384.9723737105583
INFO:root:current train perplexity3.804311513900757
INFO:root:current mean train loss 3386.2577898723325
INFO:root:current train perplexity3.8067498207092285
INFO:root:current mean train loss 3390.2530683184004
INFO:root:current train perplexity3.8112592697143555
INFO:root:current mean train loss 3390.6298720283744
INFO:root:current train perplexity3.8093674182891846
INFO:root:current mean train loss 3393.6161991974045
INFO:root:current train perplexity3.81191086769104

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.13s/it]
INFO:root:final mean train loss: 3391.335495610391
INFO:root:final train perplexity: 3.811336040496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4178.821560907026
INFO:root:eval perplexity: 5.418356895446777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.33s/it]
INFO:root:eval mean loss: 5274.407926085993
INFO:root:eval perplexity: 8.643242835998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [6:02:38<3:25:33, 171.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.1550611413045
INFO:root:current train perplexity3.7706093788146973
INFO:root:current mean train loss 3352.990784187627
INFO:root:current train perplexity3.766737222671509
INFO:root:current mean train loss 3363.4860303391256
INFO:root:current train perplexity3.775897741317749
INFO:root:current mean train loss 3371.31735786934
INFO:root:current train perplexity3.7819125652313232
INFO:root:current mean train loss 3374.122031642472
INFO:root:current train perplexity3.78780198097229
INFO:root:current mean train loss 3377.800531507678
INFO:root:current train perplexity3.7917234897613525
INFO:root:current mean train loss 3380.5036421235454
INFO:root:current train perplexity3.792980670928955
INFO:root:current mean train loss 3386.41895746888
INFO:root:current train perplexity3.800173282623291
INFO:root:current mean train loss 3389.095169753379
INFO:root:current train perplexity3.8032100200653076
INFO:root:current mean train loss 3390.663213165713
INFO:root:current train perplexity3.8070068359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.45s/it]
INFO:root:final mean train loss: 3388.0264910421065
INFO:root:final train perplexity: 3.806363821029663
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4178.8278773963875
INFO:root:eval perplexity: 5.418371200561523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]
INFO:root:eval mean loss: 5272.403654490802
INFO:root:eval perplexity: 8.636163711547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [6:05:26<3:21:34, 170.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.5526319934474
INFO:root:current train perplexity3.753405809402466
INFO:root:current mean train loss 3371.9153391131917
INFO:root:current train perplexity3.781482219696045
INFO:root:current mean train loss 3382.582060842803
INFO:root:current train perplexity3.781677722930908
INFO:root:current mean train loss 3384.8797021041823
INFO:root:current train perplexity3.785170555114746
INFO:root:current mean train loss 3388.3708943590486
INFO:root:current train perplexity3.7884533405303955
INFO:root:current mean train loss 3387.688713346722
INFO:root:current train perplexity3.789747714996338
INFO:root:current mean train loss 3385.9644610953596
INFO:root:current train perplexity3.793881416320801
INFO:root:current mean train loss 3385.6499434234993
INFO:root:current train perplexity3.7939746379852295
INFO:root:current mean train loss 3387.0619159427647
INFO:root:current train perplexity3.7989249229431152
INFO:root:current mean train loss 3387.7161588576632
INFO:root:current train perplexity3.8013675212860107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.25s/it]
INFO:root:final mean train loss: 3384.4369716029014
INFO:root:final train perplexity: 3.800977945327759
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 4181.738373019171
INFO:root:eval perplexity: 5.424751281738281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.32s/it]
INFO:root:eval mean loss: 5270.1226953817595
INFO:root:eval perplexity: 8.6281099319458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [6:08:14<3:17:58, 169.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3375.482935196314
INFO:root:current train perplexity3.7898237705230713
INFO:root:current mean train loss 3386.224098260454
INFO:root:current train perplexity3.8005452156066895
INFO:root:current mean train loss 3381.8759346806355
INFO:root:current train perplexity3.7956488132476807
INFO:root:current mean train loss 3379.041794858499
INFO:root:current train perplexity3.7898945808410645
INFO:root:current mean train loss 3377.0034563416502
INFO:root:current train perplexity3.78753662109375
INFO:root:current mean train loss 3377.4990193609406
INFO:root:current train perplexity3.788910388946533
INFO:root:current mean train loss 3380.1021711322624
INFO:root:current train perplexity3.7885589599609375
INFO:root:current mean train loss 3379.93605431749
INFO:root:current train perplexity3.7911205291748047
INFO:root:current mean train loss 3378.720752593303
INFO:root:current train perplexity3.790431022644043
INFO:root:current mean train loss 3381.9081134247704
INFO:root:current train perplexity3.793900966644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.69s/it]
INFO:root:final mean train loss: 3379.608067727858
INFO:root:final train perplexity: 3.7937426567077637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it]
INFO:root:eval mean loss: 4184.423857560395
INFO:root:eval perplexity: 5.430645942687988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]
INFO:root:eval mean loss: 5284.169923606494
INFO:root:eval perplexity: 8.677814483642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [6:11:07<3:16:15, 170.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.4430373171544
INFO:root:current train perplexity3.784780263900757
INFO:root:current mean train loss 3363.1314057849704
INFO:root:current train perplexity3.795978307723999
INFO:root:current mean train loss 3364.260725384299
INFO:root:current train perplexity3.7855193614959717
INFO:root:current mean train loss 3368.190132075153
INFO:root:current train perplexity3.7853267192840576
INFO:root:current mean train loss 3367.807600802223
INFO:root:current train perplexity3.7849860191345215
INFO:root:current mean train loss 3374.6042837529994
INFO:root:current train perplexity3.7880711555480957
INFO:root:current mean train loss 3378.171573880651
INFO:root:current train perplexity3.787160873413086
INFO:root:current mean train loss 3376.960699895938
INFO:root:current train perplexity3.7885141372680664
INFO:root:current mean train loss 3377.2733939755203
INFO:root:current train perplexity3.7875194549560547
INFO:root:current mean train loss 3377.9732007325765
INFO:root:current train perplexity3.789668321609497

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.56s/it]
INFO:root:final mean train loss: 3377.829846474432
INFO:root:final train perplexity: 3.7910821437835693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.63s/it]
INFO:root:eval mean loss: 4180.875836311503
INFO:root:eval perplexity: 5.422861576080322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.04s/it]
INFO:root:eval mean loss: 5272.386460757425
INFO:root:eval perplexity: 8.636101722717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [6:13:59<3:13:57, 171.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3364.986110617898
INFO:root:current train perplexity3.770045757293701
INFO:root:current mean train loss 3355.1145303049393
INFO:root:current train perplexity3.7747366428375244
INFO:root:current mean train loss 3361.8340973498775
INFO:root:current train perplexity3.776674509048462
INFO:root:current mean train loss 3359.5764792858713
INFO:root:current train perplexity3.7739109992980957
INFO:root:current mean train loss 3359.5363758799795
INFO:root:current train perplexity3.7736105918884277
INFO:root:current mean train loss 3364.8659940702423
INFO:root:current train perplexity3.7740533351898193
INFO:root:current mean train loss 3366.9962633438695
INFO:root:current train perplexity3.7767229080200195
INFO:root:current mean train loss 3371.4348235073467
INFO:root:current train perplexity3.778057813644409
INFO:root:current mean train loss 3373.7090154993602
INFO:root:current train perplexity3.7811574935913086
INFO:root:current mean train loss 3373.8912298552027
INFO:root:current train perplexity3.780756950378418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.72s/it]
INFO:root:final mean train loss: 3371.9483990207796
INFO:root:final train perplexity: 3.7822964191436768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 4183.973038910129
INFO:root:eval perplexity: 5.429656028747559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.91s/it]
INFO:root:eval mean loss: 5280.571212876773
INFO:root:eval perplexity: 8.665054321289062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [6:16:49<3:10:42, 170.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.1618458581347
INFO:root:current train perplexity3.7704179286956787
INFO:root:current mean train loss 3344.7638725795628
INFO:root:current train perplexity3.7517552375793457
INFO:root:current mean train loss 3345.969500987702
INFO:root:current train perplexity3.7564949989318848
INFO:root:current mean train loss 3351.0802341597796
INFO:root:current train perplexity3.7619056701660156
INFO:root:current mean train loss 3354.7157628366294
INFO:root:current train perplexity3.762800455093384
INFO:root:current mean train loss 3357.860466044072
INFO:root:current train perplexity3.7644541263580322
INFO:root:current mean train loss 3364.271569805807
INFO:root:current train perplexity3.768176794052124
INFO:root:current mean train loss 3365.827332102924
INFO:root:current train perplexity3.768838882446289
INFO:root:current mean train loss 3369.1925573603166
INFO:root:current train perplexity3.773712158203125
INFO:root:current mean train loss 3369.864070714077
INFO:root:current train perplexity3.7761895656585693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.06s/it]
INFO:root:final mean train loss: 3368.6804110004055
INFO:root:final train perplexity: 3.7774226665496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.89s/it]
INFO:root:eval mean loss: 4184.381229914672
INFO:root:eval perplexity: 5.430552959442139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 5278.7198633505095
INFO:root:eval perplexity: 8.65849494934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [6:19:38<3:07:18, 170.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.0262124504843
INFO:root:current train perplexity3.75181245803833
INFO:root:current mean train loss 3366.3831437317253
INFO:root:current train perplexity3.7663211822509766
INFO:root:current mean train loss 3367.9262334957334
INFO:root:current train perplexity3.767573833465576
INFO:root:current mean train loss 3364.107549538831
INFO:root:current train perplexity3.764622449874878
INFO:root:current mean train loss 3363.4439181512075
INFO:root:current train perplexity3.760481595993042
INFO:root:current mean train loss 3362.9496587162052
INFO:root:current train perplexity3.760978937149048
INFO:root:current mean train loss 3365.459574169267
INFO:root:current train perplexity3.7621865272521973
INFO:root:current mean train loss 3365.672648586961
INFO:root:current train perplexity3.765861749649048
INFO:root:current mean train loss 3367.017392286614
INFO:root:current train perplexity3.768730640411377
INFO:root:current mean train loss 3367.1304090600056
INFO:root:current train perplexity3.770956039428711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.63s/it]
INFO:root:final mean train loss: 3364.997134054861
INFO:root:final train perplexity: 3.771937847137451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 4185.102372839096
INFO:root:eval perplexity: 5.432136535644531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]
INFO:root:eval mean loss: 5286.666493517288
INFO:root:eval perplexity: 8.686676025390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [6:22:32<3:05:32, 171.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.761483880538
INFO:root:current train perplexity3.7720558643341064
INFO:root:current mean train loss 3353.3173991794692
INFO:root:current train perplexity3.7570574283599854
INFO:root:current mean train loss 3353.2799365409387
INFO:root:current train perplexity3.7558019161224365
INFO:root:current mean train loss 3355.1543967214297
INFO:root:current train perplexity3.7553741931915283
INFO:root:current mean train loss 3359.033182737474
INFO:root:current train perplexity3.7586562633514404
INFO:root:current mean train loss 3361.2650498569733
INFO:root:current train perplexity3.7598941326141357
INFO:root:current mean train loss 3361.9341600555736
INFO:root:current train perplexity3.760246753692627
INFO:root:current mean train loss 3361.804559004934
INFO:root:current train perplexity3.7656095027923584
INFO:root:current mean train loss 3361.5530268438033
INFO:root:current train perplexity3.765113592147827
INFO:root:current mean train loss 3364.4965930038625
INFO:root:current train perplexity3.7678964138031006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.55s/it]
INFO:root:final mean train loss: 3362.2748795170937
INFO:root:final train perplexity: 3.767888307571411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 4186.606720620013
INFO:root:eval perplexity: 5.4354424476623535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 5291.808853474069
INFO:root:eval perplexity: 8.704961776733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [6:25:23<3:02:27, 171.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3338.1858780082616
INFO:root:current train perplexity3.7670493125915527
INFO:root:current mean train loss 3340.6367996950203
INFO:root:current train perplexity3.7598299980163574
INFO:root:current mean train loss 3349.7074582834275
INFO:root:current train perplexity3.762702703475952
INFO:root:current mean train loss 3351.78778565084
INFO:root:current train perplexity3.7581374645233154
INFO:root:current mean train loss 3350.574559644507
INFO:root:current train perplexity3.757049798965454
INFO:root:current mean train loss 3358.5859212794135
INFO:root:current train perplexity3.7603399753570557
INFO:root:current mean train loss 3356.655569817822
INFO:root:current train perplexity3.7596278190612793
INFO:root:current mean train loss 3357.610038863961
INFO:root:current train perplexity3.7603812217712402
INFO:root:current mean train loss 3360.279804973753
INFO:root:current train perplexity3.7608180046081543
INFO:root:current mean train loss 3361.05518369665
INFO:root:current train perplexity3.761608362197876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.28s/it]
INFO:root:final mean train loss: 3358.08923450593
INFO:root:final train perplexity: 3.7616710662841797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.57s/it]
INFO:root:eval mean loss: 4189.124636386303
INFO:root:eval perplexity: 5.44097900390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 5288.636375914229
INFO:root:eval perplexity: 8.693676948547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [6:28:16<3:00:18, 171.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3332.6272255345393
INFO:root:current train perplexity3.728766918182373
INFO:root:current mean train loss 3327.7561786358174
INFO:root:current train perplexity3.745436906814575
INFO:root:current mean train loss 3335.0430184057204
INFO:root:current train perplexity3.742046594619751
INFO:root:current mean train loss 3342.2588255290743
INFO:root:current train perplexity3.742382287979126
INFO:root:current mean train loss 3350.7285210503474
INFO:root:current train perplexity3.746248722076416
INFO:root:current mean train loss 3351.727565323004
INFO:root:current train perplexity3.7483572959899902
INFO:root:current mean train loss 3354.9706648353194
INFO:root:current train perplexity3.750293016433716
INFO:root:current mean train loss 3355.2985508181014
INFO:root:current train perplexity3.7532811164855957
INFO:root:current mean train loss 3355.2374997272173
INFO:root:current train perplexity3.7542924880981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.98s/it]
INFO:root:final mean train loss: 3354.483500388361
INFO:root:final train perplexity: 3.75632381439209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4185.930347199135
INFO:root:eval perplexity: 5.433955669403076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.41s/it]
INFO:root:eval mean loss: 5288.08125554078
INFO:root:eval perplexity: 8.691705703735352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [6:31:07<2:57:07, 171.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.2979329427085
INFO:root:current train perplexity3.6552579402923584
INFO:root:current mean train loss 3363.0882248369235
INFO:root:current train perplexity3.7476415634155273
INFO:root:current mean train loss 3349.0705710725833
INFO:root:current train perplexity3.740272283554077
INFO:root:current mean train loss 3340.829219201217
INFO:root:current train perplexity3.7355051040649414
INFO:root:current mean train loss 3340.270710758181
INFO:root:current train perplexity3.7404720783233643
INFO:root:current mean train loss 3341.400895408797
INFO:root:current train perplexity3.738776206970215
INFO:root:current mean train loss 3345.6501080210924
INFO:root:current train perplexity3.7414305210113525
INFO:root:current mean train loss 3348.4646138480175
INFO:root:current train perplexity3.743069887161255
INFO:root:current mean train loss 3351.447178670805
INFO:root:current train perplexity3.7481279373168945
INFO:root:current mean train loss 3354.380155611936
INFO:root:current train perplexity3.7508344650268555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.93s/it]
INFO:root:final mean train loss: 3350.3586149523335
INFO:root:final train perplexity: 3.750215768814087
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4188.390614611038
INFO:root:eval perplexity: 5.439363956451416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.37s/it]
INFO:root:eval mean loss: 5289.753610164561
INFO:root:eval perplexity: 8.697651863098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [6:33:55<2:53:22, 170.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.7231001420455
INFO:root:current train perplexity3.647632122039795
INFO:root:current mean train loss 3338.112823761261
INFO:root:current train perplexity3.7205376625061035
INFO:root:current mean train loss 3340.3740627776956
INFO:root:current train perplexity3.726689338684082
INFO:root:current mean train loss 3343.9828238042605
INFO:root:current train perplexity3.7274558544158936
INFO:root:current mean train loss 3343.8296819162483
INFO:root:current train perplexity3.7326066493988037
INFO:root:current mean train loss 3341.2207666684503
INFO:root:current train perplexity3.73569917678833
INFO:root:current mean train loss 3346.0678367302576
INFO:root:current train perplexity3.7399826049804688
INFO:root:current mean train loss 3345.8534442027076
INFO:root:current train perplexity3.740419864654541
INFO:root:current mean train loss 3348.027471088452
INFO:root:current train perplexity3.744208812713623
INFO:root:current mean train loss 3348.6665020303067
INFO:root:current train perplexity3.7447993755340576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.73s/it]
INFO:root:final mean train loss: 3347.4993676216372
INFO:root:final train perplexity: 3.745987892150879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.61s/it]
INFO:root:eval mean loss: 4190.729457557624
INFO:root:eval perplexity: 5.444511890411377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 5294.76737727172
INFO:root:eval perplexity: 8.715500831604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [6:36:42<2:49:27, 169.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.2506296258225
INFO:root:current train perplexity3.68764591217041
INFO:root:current mean train loss 3347.3849851464024
INFO:root:current train perplexity3.7304089069366455
INFO:root:current mean train loss 3341.4984593500285
INFO:root:current train perplexity3.7321441173553467
INFO:root:current mean train loss 3342.848299893466
INFO:root:current train perplexity3.7329440116882324
INFO:root:current mean train loss 3345.3280160398645
INFO:root:current train perplexity3.735217809677124
INFO:root:current mean train loss 3347.0239850523844
INFO:root:current train perplexity3.7369766235351562
INFO:root:current mean train loss 3348.4137347441692
INFO:root:current train perplexity3.738251209259033
INFO:root:current mean train loss 3347.6384246783728
INFO:root:current train perplexity3.736970901489258
INFO:root:current mean train loss 3348.0420851934523
INFO:root:current train perplexity3.7377424240112305
INFO:root:current mean train loss 3347.2588217385573
INFO:root:current train perplexity3.7397007942199707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.73s/it]
INFO:root:final mean train loss: 3345.142556344309
INFO:root:final train perplexity: 3.742506504058838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.98s/it]
INFO:root:eval mean loss: 4189.48157344304
INFO:root:eval perplexity: 5.441765308380127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.47s/it]
INFO:root:eval mean loss: 5295.263851950354
INFO:root:eval perplexity: 8.717269897460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [6:39:36<2:48:03, 170.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.0483127170137
INFO:root:current train perplexity3.691561222076416
INFO:root:current mean train loss 3313.8414892962596
INFO:root:current train perplexity3.704007387161255
INFO:root:current mean train loss 3327.847716478524
INFO:root:current train perplexity3.704453468322754
INFO:root:current mean train loss 3334.9684901806195
INFO:root:current train perplexity3.719597816467285
INFO:root:current mean train loss 3337.6862678617167
INFO:root:current train perplexity3.723889112472534
INFO:root:current mean train loss 3340.4334992439517
INFO:root:current train perplexity3.7299211025238037
INFO:root:current mean train loss 3339.197260563073
INFO:root:current train perplexity3.7326126098632812
INFO:root:current mean train loss 3341.4956981548744
INFO:root:current train perplexity3.73451566696167
INFO:root:current mean train loss 3344.9630208136523
INFO:root:current train perplexity3.7380034923553467
INFO:root:current mean train loss 3344.0190553469693
INFO:root:current train perplexity3.736938714981079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.94s/it]
INFO:root:final mean train loss: 3340.9237910239926
INFO:root:final train perplexity: 3.7362821102142334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.25s/it]
INFO:root:eval mean loss: 4194.83926889406
INFO:root:eval perplexity: 5.4535675048828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.42s/it]
INFO:root:eval mean loss: 5301.572546126995
INFO:root:eval perplexity: 8.739789009094238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [6:42:25<2:44:34, 170.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3329.240938895089
INFO:root:current train perplexity3.72912335395813
INFO:root:current mean train loss 3331.380032913773
INFO:root:current train perplexity3.707902193069458
INFO:root:current mean train loss 3331.894892785904
INFO:root:current train perplexity3.7106423377990723
INFO:root:current mean train loss 3337.0433710354478
INFO:root:current train perplexity3.7147271633148193
INFO:root:current mean train loss 3336.2442315463363
INFO:root:current train perplexity3.7196848392486572
INFO:root:current mean train loss 3338.6216796875
INFO:root:current train perplexity3.7199251651763916
INFO:root:current mean train loss 3338.891199787771
INFO:root:current train perplexity3.7227118015289307
INFO:root:current mean train loss 3336.829196893601
INFO:root:current train perplexity3.724522113800049
INFO:root:current mean train loss 3336.768261426366
INFO:root:current train perplexity3.7271740436553955
INFO:root:current mean train loss 3339.8937403388204
INFO:root:current train perplexity3.729640007019043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.89s/it]
INFO:root:final mean train loss: 3336.575957575152
INFO:root:final train perplexity: 3.729879140853882
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 4197.162644406582
INFO:root:eval perplexity: 5.458693027496338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 5306.404887314384
INFO:root:eval perplexity: 8.757075309753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [6:45:14<2:41:17, 169.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.4124102925143
INFO:root:current train perplexity3.7148847579956055
INFO:root:current mean train loss 3317.5333192198427
INFO:root:current train perplexity3.7212655544281006
INFO:root:current mean train loss 3321.5122894161523
INFO:root:current train perplexity3.7137410640716553
INFO:root:current mean train loss 3320.849374487518
INFO:root:current train perplexity3.7151899337768555
INFO:root:current mean train loss 3320.9166014522784
INFO:root:current train perplexity3.7175378799438477
INFO:root:current mean train loss 3328.270715534358
INFO:root:current train perplexity3.721989154815674
INFO:root:current mean train loss 3333.0464064626262
INFO:root:current train perplexity3.722618341445923
INFO:root:current mean train loss 3337.7645866630214
INFO:root:current train perplexity3.7275006771087646
INFO:root:current mean train loss 3336.428618552139
INFO:root:current train perplexity3.726947069168091
INFO:root:current mean train loss 3337.8652791643194
INFO:root:current train perplexity3.7270498275756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.41s/it]
INFO:root:final mean train loss: 3335.1732482910156
INFO:root:final train perplexity: 3.7278149127960205
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.70s/it]
INFO:root:eval mean loss: 4193.389546279366
INFO:root:eval perplexity: 5.450371265411377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 5299.992658466312
INFO:root:eval perplexity: 8.734143257141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [6:48:03<2:38:16, 169.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.244619332108
INFO:root:current train perplexity3.721825361251831
INFO:root:current mean train loss 3310.185215425807
INFO:root:current train perplexity3.71454119682312
INFO:root:current mean train loss 3316.267848527764
INFO:root:current train perplexity3.7049291133880615
INFO:root:current mean train loss 3321.7364081140936
INFO:root:current train perplexity3.7021782398223877
INFO:root:current mean train loss 3324.5592482201014
INFO:root:current train perplexity3.7098519802093506
INFO:root:current mean train loss 3327.9527607829514
INFO:root:current train perplexity3.7139198780059814
INFO:root:current mean train loss 3330.7686690698206
INFO:root:current train perplexity3.7153806686401367
INFO:root:current mean train loss 3332.270728221746
INFO:root:current train perplexity3.7171647548675537
INFO:root:current mean train loss 3333.6791602021517
INFO:root:current train perplexity3.719268321990967
INFO:root:current mean train loss 3334.2153959545053
INFO:root:current train perplexity3.722003698348999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.87s/it]
INFO:root:final mean train loss: 3331.295556099184
INFO:root:final train perplexity: 3.7221169471740723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4195.205945603391
INFO:root:eval perplexity: 5.454375267028809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.17s/it]
INFO:root:eval mean loss: 5305.988250083112
INFO:root:eval perplexity: 8.75558090209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [6:50:51<2:35:03, 169.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.341081005032
INFO:root:current train perplexity3.685654878616333
INFO:root:current mean train loss 3329.704374877162
INFO:root:current train perplexity3.695493221282959
INFO:root:current mean train loss 3326.841065395753
INFO:root:current train perplexity3.6930603981018066
INFO:root:current mean train loss 3330.452472144847
INFO:root:current train perplexity3.7026326656341553
INFO:root:current mean train loss 3328.124848941313
INFO:root:current train perplexity3.70499587059021
INFO:root:current mean train loss 3328.485587404964
INFO:root:current train perplexity3.7102205753326416
INFO:root:current mean train loss 3326.108164670073
INFO:root:current train perplexity3.7102391719818115
INFO:root:current mean train loss 3328.0697473417945
INFO:root:current train perplexity3.7146127223968506
INFO:root:current mean train loss 3328.417871548494
INFO:root:current train perplexity3.7168378829956055
INFO:root:current mean train loss 3330.2444494285223
INFO:root:current train perplexity3.717905282974243

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.27s/it]
INFO:root:final mean train loss: 3329.0094721394203
INFO:root:final train perplexity: 3.7187607288360596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.27s/it]
INFO:root:eval mean loss: 4196.9192448609265
INFO:root:eval perplexity: 5.458156108856201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 5305.53524282469
INFO:root:eval perplexity: 8.753958702087402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [6:53:44<2:33:10, 170.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.9728603078356
INFO:root:current train perplexity3.6833159923553467
INFO:root:current mean train loss 3325.1893259379676
INFO:root:current train perplexity3.6958353519439697
INFO:root:current mean train loss 3329.4158940118796
INFO:root:current train perplexity3.703970432281494
INFO:root:current mean train loss 3324.143887304155
INFO:root:current train perplexity3.7049269676208496
INFO:root:current mean train loss 3322.7186229632293
INFO:root:current train perplexity3.7022078037261963
INFO:root:current mean train loss 3324.046936573385
INFO:root:current train perplexity3.703536033630371
INFO:root:current mean train loss 3323.494876341126
INFO:root:current train perplexity3.7054755687713623
INFO:root:current mean train loss 3324.9622104052924
INFO:root:current train perplexity3.709543466567993
INFO:root:current mean train loss 3327.4883688252417
INFO:root:current train perplexity3.7118046283721924
INFO:root:current mean train loss 3328.2399147451847
INFO:root:current train perplexity3.712172031402588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.63s/it]
INFO:root:final mean train loss: 3324.852892598798
INFO:root:final train perplexity: 3.712667226791382
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 4198.741278465758
INFO:root:eval perplexity: 5.462177753448486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it]
INFO:root:eval mean loss: 5311.6864749556735
INFO:root:eval perplexity: 8.776007652282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [6:56:32<2:29:47, 169.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.3166796875
INFO:root:current train perplexity3.7279775142669678
INFO:root:current mean train loss 3340.0797991071427
INFO:root:current train perplexity3.7131309509277344
INFO:root:current mean train loss 3333.3804554332387
INFO:root:current train perplexity3.711905002593994
INFO:root:current mean train loss 3327.1851920572917
INFO:root:current train perplexity3.707134485244751
INFO:root:current mean train loss 3321.024881270559
INFO:root:current train perplexity3.7081081867218018
INFO:root:current mean train loss 3322.8976728091034
INFO:root:current train perplexity3.7049648761749268
INFO:root:current mean train loss 3321.240785228588
INFO:root:current train perplexity3.704807758331299
INFO:root:current mean train loss 3321.039380355343
INFO:root:current train perplexity3.7050695419311523
INFO:root:current mean train loss 3322.3661623883927
INFO:root:current train perplexity3.7068662643432617
INFO:root:current mean train loss 3324.550721404247
INFO:root:current train perplexity3.7086095809936523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.18s/it]
INFO:root:final mean train loss: 3322.0524533794774
INFO:root:final train perplexity: 3.7085676193237305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 4201.22453665226
INFO:root:eval perplexity: 5.467666149139404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.92s/it]
INFO:root:eval mean loss: 5315.938954454788
INFO:root:eval perplexity: 8.791280746459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [6:59:26<2:28:14, 171.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.976768401732
INFO:root:current train perplexity3.7012462615966797
INFO:root:current mean train loss 3310.181199037312
INFO:root:current train perplexity3.69403076171875
INFO:root:current mean train loss 3313.0476867891452
INFO:root:current train perplexity3.6905901432037354
INFO:root:current mean train loss 3312.539516996777
INFO:root:current train perplexity3.688922166824341
INFO:root:current mean train loss 3314.988571893601
INFO:root:current train perplexity3.6916825771331787
INFO:root:current mean train loss 3311.99947109844
INFO:root:current train perplexity3.6882925033569336
INFO:root:current mean train loss 3316.552049136965
INFO:root:current train perplexity3.693403720855713
INFO:root:current mean train loss 3318.6907471014924
INFO:root:current train perplexity3.6979663372039795
INFO:root:current mean train loss 3320.2222990249857
INFO:root:current train perplexity3.702366590499878
INFO:root:current mean train loss 3322.689540548703
INFO:root:current train perplexity3.7048492431640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.67s/it]
INFO:root:final mean train loss: 3319.565551634758
INFO:root:final train perplexity: 3.704930543899536
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it]
INFO:root:eval mean loss: 4197.733867672318
INFO:root:eval perplexity: 5.459954261779785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 5309.9596319536795
INFO:root:eval perplexity: 8.769810676574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [7:02:15<2:24:46, 170.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.1319030091004
INFO:root:current train perplexity3.691896677017212
INFO:root:current mean train loss 3323.0754202797775
INFO:root:current train perplexity3.696828603744507
INFO:root:current mean train loss 3317.524449299291
INFO:root:current train perplexity3.7002711296081543
INFO:root:current mean train loss 3317.2098373061863
INFO:root:current train perplexity3.701261520385742
INFO:root:current mean train loss 3314.0179440873217
INFO:root:current train perplexity3.696730375289917
INFO:root:current mean train loss 3312.4241891722186
INFO:root:current train perplexity3.6963486671447754
INFO:root:current mean train loss 3315.967590067045
INFO:root:current train perplexity3.6985011100769043
INFO:root:current mean train loss 3315.551980656408
INFO:root:current train perplexity3.699439764022827
INFO:root:current mean train loss 3316.9439567112095
INFO:root:current train perplexity3.6987087726593018
INFO:root:current mean train loss 3319.955718409041
INFO:root:current train perplexity3.701725721359253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.29s/it]
INFO:root:final mean train loss: 3317.2875908267115
INFO:root:final train perplexity: 3.7016022205352783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4202.799461851729
INFO:root:eval perplexity: 5.471149444580078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.74s/it]
INFO:root:eval mean loss: 5316.701455839982
INFO:root:eval perplexity: 8.794022560119629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [7:05:03<2:21:25, 169.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.4005780460857
INFO:root:current train perplexity3.709557056427002
INFO:root:current mean train loss 3324.6652660274026
INFO:root:current train perplexity3.703681707382202
INFO:root:current mean train loss 3318.5588681020067
INFO:root:current train perplexity3.699324607849121
INFO:root:current mean train loss 3313.8927653606675
INFO:root:current train perplexity3.6935248374938965
INFO:root:current mean train loss 3312.956762157127
INFO:root:current train perplexity3.6913156509399414
INFO:root:current mean train loss 3310.984635851419
INFO:root:current train perplexity3.689817190170288
INFO:root:current mean train loss 3317.14875114561
INFO:root:current train perplexity3.692065477371216
INFO:root:current mean train loss 3316.56828543003
INFO:root:current train perplexity3.6941919326782227
INFO:root:current mean train loss 3317.3745861286848
INFO:root:current train perplexity3.6959896087646484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.51s/it]
INFO:root:final mean train loss: 3313.642832540697
INFO:root:final train perplexity: 3.696284532546997
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it]
INFO:root:eval mean loss: 4204.044667345413
INFO:root:eval perplexity: 5.473904132843018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 5319.259945700354
INFO:root:eval perplexity: 8.803230285644531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [7:07:52<2:18:27, 169.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.17919921875
INFO:root:current train perplexity3.604818344116211
INFO:root:current mean train loss 3287.5386198525116
INFO:root:current train perplexity3.6657350063323975
INFO:root:current mean train loss 3290.5786274343295
INFO:root:current train perplexity3.670064687728882
INFO:root:current mean train loss 3294.2948980176097
INFO:root:current train perplexity3.6764042377471924
INFO:root:current mean train loss 3303.2929231610874
INFO:root:current train perplexity3.6839449405670166
INFO:root:current mean train loss 3307.764922433586
INFO:root:current train perplexity3.6878268718719482
INFO:root:current mean train loss 3306.5529950061778
INFO:root:current train perplexity3.685598611831665
INFO:root:current mean train loss 3308.47422434417
INFO:root:current train perplexity3.6866397857666016
INFO:root:current mean train loss 3310.3235465313273
INFO:root:current train perplexity3.6893703937530518
INFO:root:current mean train loss 3312.132981002791
INFO:root:current train perplexity3.690484046936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.56s/it]
INFO:root:final mean train loss: 3311.0180512089883
INFO:root:final train perplexity: 3.692458152770996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4201.902002645723
INFO:root:eval perplexity: 5.469164848327637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.77s/it]
INFO:root:eval mean loss: 5315.832618226396
INFO:root:eval perplexity: 8.790899276733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [7:10:43<2:15:51, 169.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.226285807292
INFO:root:current train perplexity3.653958320617676
INFO:root:current mean train loss 3302.1123768682064
INFO:root:current train perplexity3.668887138366699
INFO:root:current mean train loss 3301.37401321766
INFO:root:current train perplexity3.6645383834838867
INFO:root:current mean train loss 3306.38246062748
INFO:root:current train perplexity3.6751489639282227
INFO:root:current mean train loss 3307.358534332643
INFO:root:current train perplexity3.6783595085144043
INFO:root:current mean train loss 3306.359076816596
INFO:root:current train perplexity3.679551601409912
INFO:root:current mean train loss 3307.9944046144565
INFO:root:current train perplexity3.6839523315429688
INFO:root:current mean train loss 3307.630402507649
INFO:root:current train perplexity3.6847965717315674
INFO:root:current mean train loss 3310.7660350963383
INFO:root:current train perplexity3.6880433559417725
INFO:root:current mean train loss 3311.3464294100067
INFO:root:current train perplexity3.6886403560638428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:21<00:00, 141.20s/it]
INFO:root:final mean train loss: 3308.909102962863
INFO:root:final train perplexity: 3.689387559890747
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.42s/it]
INFO:root:eval mean loss: 4201.895152856272
INFO:root:eval perplexity: 5.469149589538574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5318.054727324357
INFO:root:eval perplexity: 8.798890113830566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [7:13:30<2:12:19, 168.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.9364491338315
INFO:root:current train perplexity3.6881163120269775
INFO:root:current mean train loss 3293.9157000285823
INFO:root:current train perplexity3.677694797515869
INFO:root:current mean train loss 3295.530980678952
INFO:root:current train perplexity3.6734824180603027
INFO:root:current mean train loss 3296.6009600848975
INFO:root:current train perplexity3.6775875091552734
INFO:root:current mean train loss 3295.4695401383347
INFO:root:current train perplexity3.67824387550354
INFO:root:current mean train loss 3301.97508551924
INFO:root:current train perplexity3.6781933307647705
INFO:root:current mean train loss 3301.6917656030546
INFO:root:current train perplexity3.6787612438201904
INFO:root:current mean train loss 3307.2213203989454
INFO:root:current train perplexity3.6831958293914795
INFO:root:current mean train loss 3308.6074375973003
INFO:root:current train perplexity3.685802936553955
INFO:root:current mean train loss 3308.1872696137766
INFO:root:current train perplexity3.6835172176361084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.12s/it]
INFO:root:final mean train loss: 3305.7155167364303
INFO:root:final train perplexity: 3.684741735458374
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 4200.91281236148
INFO:root:eval perplexity: 5.466977119445801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.79s/it]
INFO:root:eval mean loss: 5317.65498600953
INFO:root:eval perplexity: 8.797453880310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [7:16:21<2:10:01, 169.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.2692634828627
INFO:root:current train perplexity3.6318416595458984
INFO:root:current mean train loss 3281.9295775435353
INFO:root:current train perplexity3.667473793029785
INFO:root:current mean train loss 3301.4241895799514
INFO:root:current train perplexity3.6725094318389893
INFO:root:current mean train loss 3303.3842057980078
INFO:root:current train perplexity3.6696512699127197
INFO:root:current mean train loss 3308.000761310905
INFO:root:current train perplexity3.6718156337738037
INFO:root:current mean train loss 3306.649848550053
INFO:root:current train perplexity3.669431686401367
INFO:root:current mean train loss 3312.0713575456866
INFO:root:current train perplexity3.674898862838745
INFO:root:current mean train loss 3310.2239601145693
INFO:root:current train perplexity3.676772117614746
INFO:root:current mean train loss 3309.022994168829
INFO:root:current train perplexity3.6794655323028564
INFO:root:current mean train loss 3307.002163699567
INFO:root:current train perplexity3.678549289703369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.68s/it]
INFO:root:final mean train loss: 3302.294777224141
INFO:root:final train perplexity: 3.679771661758423
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.92s/it]
INFO:root:eval mean loss: 4203.569980053191
INFO:root:eval perplexity: 5.4728546142578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.34s/it]
INFO:root:eval mean loss: 5320.547830784574
INFO:root:eval perplexity: 8.807865142822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_from_scratch_final/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [7:19:16<2:08:24, 171.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][Aslurmstepd: error: *** JOB 26260757 ON ga010 CANCELLED AT 2022-10-25T09:47:30 ***
