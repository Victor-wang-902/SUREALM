INFO:root:Output: alll12_minil12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.weight', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11508.488340435606
INFO:root:current train perplexity9153.337890625
INFO:root:current mean train loss 9536.565029738536
INFO:root:current train perplexity1906.41162109375
INFO:root:current mean train loss 8366.81977522732
INFO:root:current train perplexity754.8018798828125
INFO:root:current mean train loss 7575.591902118577
INFO:root:current train perplexity397.41046142578125
INFO:root:current mean train loss 6984.157801931989
INFO:root:current train perplexity249.05279541015625
INFO:root:current mean train loss 6527.7361145529
INFO:root:current train perplexity173.72764587402344
INFO:root:current mean train loss 6168.220701727915
INFO:root:current train perplexity130.4787139892578
INFO:root:current mean train loss 5882.4877636352085
INFO:root:current train perplexity103.57386016845703
INFO:root:current mean train loss 5640.777645734845
INFO:root:current train perplexity85.65298461914062
INFO:root:current mean train loss 5433.8980606583145
INFO:root:current train perplexity72.83902740478516
INFO:root:current mean train loss 5258.1179072594405
INFO:root:current train perplexity63.287925720214844
INFO:root:current mean train loss 5105.007178833924
INFO:root:current train perplexity56.089542388916016
INFO:root:current mean train loss 4969.807493331709
INFO:root:current train perplexity50.39524459838867
INFO:root:current mean train loss 4849.919294334122
INFO:root:current train perplexity45.8563232421875
INFO:root:current mean train loss 4741.362437262863
INFO:root:current train perplexity42.121543884277344
INFO:root:current mean train loss 4644.648555982255
INFO:root:current train perplexity38.99053192138672
INFO:root:current mean train loss 4555.97258009077
INFO:root:current train perplexity36.350337982177734
INFO:root:current mean train loss 4476.568052265365
INFO:root:current train perplexity34.1326904296875
INFO:root:current mean train loss 4403.217691543041
INFO:root:current train perplexity32.204124450683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.80s/it]
INFO:root:final mean train loss: 4343.972841417675
INFO:root:final train perplexity: 30.750871658325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.78s/it]
INFO:root:eval mean loss: 2825.82635887633
INFO:root:eval perplexity: 9.829246520996094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.94s/it]
INFO:root:eval mean loss: 3119.8226344331783
INFO:root:eval perplexity: 12.826030731201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/1
  1%|          | 1/100 [06:17<10:22:57, 377.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2979.519561767578
INFO:root:current train perplexity10.484466552734375
INFO:root:current mean train loss 3016.601956071525
INFO:root:current train perplexity10.653092384338379
INFO:root:current mean train loss 2995.361420808015
INFO:root:current train perplexity10.511344909667969
INFO:root:current mean train loss 2979.689860283574
INFO:root:current train perplexity10.386518478393555
INFO:root:current mean train loss 2958.6937572772686
INFO:root:current train perplexity10.224591255187988
INFO:root:current mean train loss 2942.98077960347
INFO:root:current train perplexity10.129508972167969
INFO:root:current mean train loss 2930.583566640879
INFO:root:current train perplexity10.044401168823242
INFO:root:current mean train loss 2915.716759367362
INFO:root:current train perplexity9.940103530883789
INFO:root:current mean train loss 2900.9373593797873
INFO:root:current train perplexity9.837411880493164
INFO:root:current mean train loss 2893.0900212583583
INFO:root:current train perplexity9.76328182220459
INFO:root:current mean train loss 2879.158007283849
INFO:root:current train perplexity9.660717010498047
INFO:root:current mean train loss 2867.5719256657426
INFO:root:current train perplexity9.5787353515625
INFO:root:current mean train loss 2856.683242597078
INFO:root:current train perplexity9.50541877746582
INFO:root:current mean train loss 2847.423191429996
INFO:root:current train perplexity9.43192195892334
INFO:root:current mean train loss 2840.391502251059
INFO:root:current train perplexity9.369322776794434
INFO:root:current mean train loss 2829.8782659445087
INFO:root:current train perplexity9.302634239196777
INFO:root:current mean train loss 2820.230372211721
INFO:root:current train perplexity9.237987518310547
INFO:root:current mean train loss 2811.709168049561
INFO:root:current train perplexity9.168850898742676
INFO:root:current mean train loss 2801.7507419670205
INFO:root:current train perplexity9.100090980529785
INFO:root:current mean train loss 2794.3537452395126
INFO:root:current train perplexity9.0513916015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.93s/it]
INFO:root:final mean train loss: 2788.290129430235
INFO:root:final train perplexity: 9.016114234924316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it]
INFO:root:eval mean loss: 2479.8997581968915
INFO:root:eval perplexity: 7.430531024932861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.45s/it]
INFO:root:eval mean loss: 2815.035257542387
INFO:root:eval perplexity: 9.996281623840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/2
  2%|â–         | 2/100 [12:55<10:36:00, 389.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2591.783757990057
INFO:root:current train perplexity7.771490573883057
INFO:root:current mean train loss 2606.7950540413535
INFO:root:current train perplexity7.814860820770264
INFO:root:current mean train loss 2598.4356694692196
INFO:root:current train perplexity7.796548366546631
INFO:root:current mean train loss 2600.174663921734
INFO:root:current train perplexity7.761717319488525
INFO:root:current mean train loss 2598.4006268719327
INFO:root:current train perplexity7.758914470672607
INFO:root:current mean train loss 2594.233144219776
INFO:root:current train perplexity7.724667549133301
INFO:root:current mean train loss 2588.239365033817
INFO:root:current train perplexity7.698341369628906
INFO:root:current mean train loss 2586.635752512683
INFO:root:current train perplexity7.6781325340271
INFO:root:current mean train loss 2583.1367632990696
INFO:root:current train perplexity7.656576156616211
INFO:root:current mean train loss 2577.033188209656
INFO:root:current train perplexity7.624866008758545
INFO:root:current mean train loss 2570.4897134786424
INFO:root:current train perplexity7.5929975509643555
INFO:root:current mean train loss 2564.310255112947
INFO:root:current train perplexity7.558034420013428
INFO:root:current mean train loss 2560.7367309669316
INFO:root:current train perplexity7.539266586303711
INFO:root:current mean train loss 2556.3055767909264
INFO:root:current train perplexity7.509519100189209
INFO:root:current mean train loss 2552.6480389187077
INFO:root:current train perplexity7.48500919342041
INFO:root:current mean train loss 2547.533071021511
INFO:root:current train perplexity7.456023693084717
INFO:root:current mean train loss 2543.833494822963
INFO:root:current train perplexity7.4295125007629395
INFO:root:current mean train loss 2540.4497634526697
INFO:root:current train perplexity7.409039497375488
INFO:root:current mean train loss 2537.667277018229
INFO:root:current train perplexity7.393627166748047
INFO:root:current mean train loss 2534.4525339725533
INFO:root:current train perplexity7.373773574829102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.98s/it]
INFO:root:final mean train loss: 2532.2853118080834
INFO:root:final train perplexity: 7.3677520751953125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it]
INFO:root:eval mean loss: 2358.302655159159
INFO:root:eval perplexity: 6.734587669372559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]
INFO:root:eval mean loss: 2718.134697663869
INFO:root:eval perplexity: 9.234675407409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/3
  3%|â–Ž         | 3/100 [19:18<10:24:38, 386.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2415.3096508789063
INFO:root:current train perplexity6.799723148345947
INFO:root:current mean train loss 2425.420342610677
INFO:root:current train perplexity6.84293794631958
INFO:root:current mean train loss 2435.0269858398437
INFO:root:current train perplexity6.827607154846191
INFO:root:current mean train loss 2437.724495326451
INFO:root:current train perplexity6.802850246429443
INFO:root:current mean train loss 2437.061882595486
INFO:root:current train perplexity6.801875591278076
INFO:root:current mean train loss 2430.4545374644886
INFO:root:current train perplexity6.782264709472656
INFO:root:current mean train loss 2425.5168169696512
INFO:root:current train perplexity6.769988059997559
INFO:root:current mean train loss 2420.162600748698
INFO:root:current train perplexity6.757266998291016
INFO:root:current mean train loss 2418.765501637178
INFO:root:current train perplexity6.737118721008301
INFO:root:current mean train loss 2414.5529038599916
INFO:root:current train perplexity6.71436071395874
INFO:root:current mean train loss 2409.024717843192
INFO:root:current train perplexity6.701562881469727
INFO:root:current mean train loss 2408.7925158160665
INFO:root:current train perplexity6.6975417137146
INFO:root:current mean train loss 2408.456769042969
INFO:root:current train perplexity6.690123081207275
INFO:root:current mean train loss 2405.961626790365
INFO:root:current train perplexity6.674440383911133
INFO:root:current mean train loss 2404.362699521821
INFO:root:current train perplexity6.657951354980469
INFO:root:current mean train loss 2402.481097766507
INFO:root:current train perplexity6.652278423309326
INFO:root:current mean train loss 2400.4768042732007
INFO:root:current train perplexity6.637810707092285
INFO:root:current mean train loss 2398.1517138671875
INFO:root:current train perplexity6.623624801635742
INFO:root:current mean train loss 2394.8767962151605
INFO:root:current train perplexity6.611122131347656
INFO:root:current mean train loss 2392.4052294921876
INFO:root:current train perplexity6.59541130065918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.10s/it]
INFO:root:final mean train loss: 2390.805861695752
INFO:root:final train perplexity: 6.589868068695068
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.57s/it]
INFO:root:eval mean loss: 2228.1938091305133
INFO:root:eval perplexity: 6.06195592880249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it]
INFO:root:eval mean loss: 2600.286733207973
INFO:root:eval perplexity: 8.386187553405762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/4
  4%|â–         | 4/100 [25:40<10:15:32, 384.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2338.6841949918376
INFO:root:current train perplexity6.260512828826904
INFO:root:current mean train loss 2318.082406963417
INFO:root:current train perplexity6.181918144226074
INFO:root:current mean train loss 2317.141035558579
INFO:root:current train perplexity6.204962730407715
INFO:root:current mean train loss 2311.505825448101
INFO:root:current train perplexity6.184787750244141
INFO:root:current mean train loss 2314.763199800087
INFO:root:current train perplexity6.210174560546875
INFO:root:current mean train loss 2315.4984494702107
INFO:root:current train perplexity6.200379371643066
INFO:root:current mean train loss 2311.926847489341
INFO:root:current train perplexity6.192574501037598
INFO:root:current mean train loss 2314.2181897816167
INFO:root:current train perplexity6.192601203918457
INFO:root:current mean train loss 2311.2627979529357
INFO:root:current train perplexity6.185824394226074
INFO:root:current mean train loss 2309.6711019300997
INFO:root:current train perplexity6.174829483032227
INFO:root:current mean train loss 2308.7129098450678
INFO:root:current train perplexity6.168911457061768
INFO:root:current mean train loss 2305.559249080341
INFO:root:current train perplexity6.152340888977051
INFO:root:current mean train loss 2305.653982401835
INFO:root:current train perplexity6.147388935089111
INFO:root:current mean train loss 2302.799756288005
INFO:root:current train perplexity6.140448570251465
INFO:root:current mean train loss 2299.9171742528333
INFO:root:current train perplexity6.125119209289551
INFO:root:current mean train loss 2299.266831758909
INFO:root:current train perplexity6.119466304779053
INFO:root:current mean train loss 2295.792389227233
INFO:root:current train perplexity6.110254287719727
INFO:root:current mean train loss 2295.8969832260054
INFO:root:current train perplexity6.104858875274658
INFO:root:current mean train loss 2294.1268874149496
INFO:root:current train perplexity6.100560188293457
INFO:root:current mean train loss 2292.6643713062404
INFO:root:current train perplexity6.095083713531494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it]
INFO:root:final mean train loss: 2291.443151800066
INFO:root:final train perplexity: 6.0931782722473145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.65s/it]
INFO:root:eval mean loss: 2158.4690850440493
INFO:root:eval perplexity: 5.729584693908691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.54s/it]
INFO:root:eval mean loss: 2540.510385932652
INFO:root:eval perplexity: 7.986071586608887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/5
  5%|â–Œ         | 5/100 [31:56<10:04:12, 381.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2236.631032307943
INFO:root:current train perplexity5.886384010314941
INFO:root:current mean train loss 2252.4608983578887
INFO:root:current train perplexity5.878413677215576
INFO:root:current mean train loss 2240.832869838661
INFO:root:current train perplexity5.844536781311035
INFO:root:current mean train loss 2239.712519645691
INFO:root:current train perplexity5.849778652191162
INFO:root:current mean train loss 2235.241742599109
INFO:root:current train perplexity5.843442440032959
INFO:root:current mean train loss 2238.5312934770977
INFO:root:current train perplexity5.840223789215088
INFO:root:current mean train loss 2232.8713173671076
INFO:root:current train perplexity5.825992107391357
INFO:root:current mean train loss 2229.709817224619
INFO:root:current train perplexity5.812132358551025
INFO:root:current mean train loss 2229.400309014644
INFO:root:current train perplexity5.805757999420166
INFO:root:current mean train loss 2225.8874582430212
INFO:root:current train perplexity5.79530668258667
INFO:root:current mean train loss 2225.0407331966385
INFO:root:current train perplexity5.788283348083496
INFO:root:current mean train loss 2224.276950629982
INFO:root:current train perplexity5.780525207519531
INFO:root:current mean train loss 2223.5967218987294
INFO:root:current train perplexity5.772312164306641
INFO:root:current mean train loss 2222.4310966888606
INFO:root:current train perplexity5.767320156097412
INFO:root:current mean train loss 2219.681987752169
INFO:root:current train perplexity5.763001918792725
INFO:root:current mean train loss 2217.7527342516964
INFO:root:current train perplexity5.755741596221924
INFO:root:current mean train loss 2217.7815960591875
INFO:root:current train perplexity5.752746105194092
INFO:root:current mean train loss 2217.3710579636922
INFO:root:current train perplexity5.74742317199707
INFO:root:current mean train loss 2216.6153568340715
INFO:root:current train perplexity5.744992256164551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:43<00:00, 343.92s/it]
INFO:root:final mean train loss: 2216.392625032503
INFO:root:final train perplexity: 5.742991924285889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.10s/it]
INFO:root:eval mean loss: 2100.8121610600897
INFO:root:eval perplexity: 5.468550682067871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.90s/it]
INFO:root:eval mean loss: 2491.609366342531
INFO:root:eval perplexity: 7.672991752624512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/6
  6%|â–Œ         | 6/100 [38:29<10:04:03, 385.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2240.537841796875
INFO:root:current train perplexity5.820749759674072
INFO:root:current mean train loss 2156.5090718788674
INFO:root:current train perplexity5.508024215698242
INFO:root:current mean train loss 2159.476716150692
INFO:root:current train perplexity5.521346569061279
INFO:root:current mean train loss 2161.763122355819
INFO:root:current train perplexity5.510836601257324
INFO:root:current mean train loss 2163.279433861635
INFO:root:current train perplexity5.517031192779541
INFO:root:current mean train loss 2168.393457957133
INFO:root:current train perplexity5.518598556518555
INFO:root:current mean train loss 2170.6684820140263
INFO:root:current train perplexity5.525102615356445
INFO:root:current mean train loss 2172.3677114794154
INFO:root:current train perplexity5.531391143798828
INFO:root:current mean train loss 2170.6404217018767
INFO:root:current train perplexity5.523924350738525
INFO:root:current mean train loss 2170.7470812866345
INFO:root:current train perplexity5.524499893188477
INFO:root:current mean train loss 2168.5041206352244
INFO:root:current train perplexity5.523991584777832
INFO:root:current mean train loss 2169.037064804368
INFO:root:current train perplexity5.523094654083252
INFO:root:current mean train loss 2167.79016072625
INFO:root:current train perplexity5.520901679992676
INFO:root:current mean train loss 2166.294439035778
INFO:root:current train perplexity5.515347003936768
INFO:root:current mean train loss 2166.4712794084026
INFO:root:current train perplexity5.514997959136963
INFO:root:current mean train loss 2166.1428730130433
INFO:root:current train perplexity5.5166401863098145
INFO:root:current mean train loss 2165.3288810582253
INFO:root:current train perplexity5.514081954956055
INFO:root:current mean train loss 2162.6154767932926
INFO:root:current train perplexity5.5067644119262695
INFO:root:current mean train loss 2161.9091344787835
INFO:root:current train perplexity5.50278902053833
INFO:root:current mean train loss 2162.53040835056
INFO:root:current train perplexity5.5002899169921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.28s/it]
INFO:root:final mean train loss: 2161.122656163818
INFO:root:final train perplexity: 5.4980387687683105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.22s/it]
INFO:root:eval mean loss: 2075.601101489777
INFO:root:eval perplexity: 5.358179569244385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it]
INFO:root:eval mean loss: 2472.887701805602
INFO:root:eval perplexity: 7.556403636932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/7
  7%|â–‹         | 7/100 [44:46<9:53:21, 382.81s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2229.5860460069443
INFO:root:current train perplexity5.455246448516846
INFO:root:current mean train loss 2141.6973163152147
INFO:root:current train perplexity5.3892645835876465
INFO:root:current mean train loss 2133.5701473131094
INFO:root:current train perplexity5.338169097900391
INFO:root:current mean train loss 2121.9427670652763
INFO:root:current train perplexity5.317631721496582
INFO:root:current mean train loss 2132.7157058350776
INFO:root:current train perplexity5.352999687194824
INFO:root:current mean train loss 2129.833823656944
INFO:root:current train perplexity5.338143825531006
INFO:root:current mean train loss 2130.351616621789
INFO:root:current train perplexity5.3386054039001465
INFO:root:current mean train loss 2131.839064574175
INFO:root:current train perplexity5.344968795776367
INFO:root:current mean train loss 2125.848061708483
INFO:root:current train perplexity5.336559772491455
INFO:root:current mean train loss 2127.6588235826016
INFO:root:current train perplexity5.338987827301025
INFO:root:current mean train loss 2125.913617866681
INFO:root:current train perplexity5.335169792175293
INFO:root:current mean train loss 2124.296091806483
INFO:root:current train perplexity5.334065914154053
INFO:root:current mean train loss 2122.0573169225936
INFO:root:current train perplexity5.329569339752197
INFO:root:current mean train loss 2122.8395972013113
INFO:root:current train perplexity5.328871250152588
INFO:root:current mean train loss 2122.989569358664
INFO:root:current train perplexity5.3302435874938965
INFO:root:current mean train loss 2122.1735538286653
INFO:root:current train perplexity5.328311443328857
INFO:root:current mean train loss 2120.757091017677
INFO:root:current train perplexity5.3224897384643555
INFO:root:current mean train loss 2121.284140181625
INFO:root:current train perplexity5.322932243347168
INFO:root:current mean train loss 2119.9297225498917
INFO:root:current train perplexity5.3197126388549805
INFO:root:current mean train loss 2118.670013968713
INFO:root:current train perplexity5.3162617683410645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.19s/it]
INFO:root:final mean train loss: 2117.8205168431177
INFO:root:final train perplexity: 5.313446044921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.64s/it]
INFO:root:eval mean loss: 2037.438030702848
INFO:root:eval perplexity: 5.19533109664917
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.68s/it]
INFO:root:eval mean loss: 2438.6712810976287
INFO:root:eval perplexity: 7.3478827476501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/8
  8%|â–Š         | 8/100 [51:05<9:45:02, 381.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2033.1387765066963
INFO:root:current train perplexity4.998199939727783
INFO:root:current mean train loss 2067.60870135272
INFO:root:current train perplexity5.124403476715088
INFO:root:current mean train loss 2065.1664052111037
INFO:root:current train perplexity5.137444972991943
INFO:root:current mean train loss 2079.7269298041047
INFO:root:current train perplexity5.160374641418457
INFO:root:current mean train loss 2086.388649144666
INFO:root:current train perplexity5.1832170486450195
INFO:root:current mean train loss 2085.102200459988
INFO:root:current train perplexity5.174515724182129
INFO:root:current mean train loss 2086.418830931656
INFO:root:current train perplexity5.1743927001953125
INFO:root:current mean train loss 2085.3784357395302
INFO:root:current train perplexity5.1756815910339355
INFO:root:current mean train loss 2084.825453926132
INFO:root:current train perplexity5.179165363311768
INFO:root:current mean train loss 2087.798448075075
INFO:root:current train perplexity5.180211067199707
INFO:root:current mean train loss 2087.7122182357716
INFO:root:current train perplexity5.178463935852051
INFO:root:current mean train loss 2088.6434811226595
INFO:root:current train perplexity5.184510231018066
INFO:root:current mean train loss 2085.8657877933642
INFO:root:current train perplexity5.1811323165893555
INFO:root:current mean train loss 2083.8363215414324
INFO:root:current train perplexity5.176421165466309
INFO:root:current mean train loss 2084.0665076491723
INFO:root:current train perplexity5.1745381355285645
INFO:root:current mean train loss 2084.6734923719973
INFO:root:current train perplexity5.176085472106934
INFO:root:current mean train loss 2085.68368535873
INFO:root:current train perplexity5.178174018859863
INFO:root:current mean train loss 2085.4739035482708
INFO:root:current train perplexity5.17825984954834
INFO:root:current mean train loss 2084.7107977344813
INFO:root:current train perplexity5.176100730895996
INFO:root:current mean train loss 2084.991924307574
INFO:root:current train perplexity5.174846649169922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.51s/it]
INFO:root:final mean train loss: 2083.9919408662595
INFO:root:final train perplexity: 5.1735615730285645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.47s/it]
INFO:root:eval mean loss: 2004.1033801356107
INFO:root:eval perplexity: 5.057139873504639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.76s/it]
INFO:root:eval mean loss: 2416.2249236411235
INFO:root:eval perplexity: 7.214226722717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/9
  9%|â–‰         | 9/100 [57:28<9:39:25, 382.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2014.2481055626502
INFO:root:current train perplexity5.01093053817749
INFO:root:current mean train loss 2052.248270938271
INFO:root:current train perplexity5.080833435058594
INFO:root:current mean train loss 2062.99800085643
INFO:root:current train perplexity5.077396392822266
INFO:root:current mean train loss 2057.3377470536666
INFO:root:current train perplexity5.070065021514893
INFO:root:current mean train loss 2055.8552572874896
INFO:root:current train perplexity5.0686845779418945
INFO:root:current mean train loss 2051.7744251195936
INFO:root:current train perplexity5.053514003753662
INFO:root:current mean train loss 2052.822076341126
INFO:root:current train perplexity5.057173252105713
INFO:root:current mean train loss 2052.2306359473696
INFO:root:current train perplexity5.053067684173584
INFO:root:current mean train loss 2055.983273931512
INFO:root:current train perplexity5.058380126953125
INFO:root:current mean train loss 2053.9146805450696
INFO:root:current train perplexity5.053645610809326
INFO:root:current mean train loss 2054.1147971497744
INFO:root:current train perplexity5.052008152008057
INFO:root:current mean train loss 2055.5038618511626
INFO:root:current train perplexity5.055071830749512
INFO:root:current mean train loss 2053.365607313455
INFO:root:current train perplexity5.052884101867676
INFO:root:current mean train loss 2053.8393542047083
INFO:root:current train perplexity5.048407077789307
INFO:root:current mean train loss 2054.075371860473
INFO:root:current train perplexity5.047881126403809
INFO:root:current mean train loss 2053.8741624183263
INFO:root:current train perplexity5.04856014251709
INFO:root:current mean train loss 2055.0519839972617
INFO:root:current train perplexity5.050968647003174
INFO:root:current mean train loss 2055.1673117162973
INFO:root:current train perplexity5.050971031188965
INFO:root:current mean train loss 2054.0104464372344
INFO:root:current train perplexity5.048266887664795
INFO:root:current mean train loss 2054.1507894797405
INFO:root:current train perplexity5.047975540161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.56s/it]
INFO:root:final mean train loss: 2052.2466001601997
INFO:root:final train perplexity: 5.045643329620361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.00s/it]
INFO:root:eval mean loss: 1979.3069483980219
INFO:root:eval perplexity: 4.9567341804504395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.54s/it]
INFO:root:eval mean loss: 2392.7094955985426
INFO:root:eval perplexity: 7.076813220977783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:04:04<9:39:15, 386.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2037.5260646654212
INFO:root:current train perplexity4.972537994384766
INFO:root:current mean train loss 2046.9638722436669
INFO:root:current train perplexity4.982423305511475
INFO:root:current mean train loss 2043.3756280494888
INFO:root:current train perplexity4.969972610473633
INFO:root:current mean train loss 2036.9020704977559
INFO:root:current train perplexity4.953564643859863
INFO:root:current mean train loss 2034.7418879201925
INFO:root:current train perplexity4.9518327713012695
INFO:root:current mean train loss 2030.5560502251758
INFO:root:current train perplexity4.950131416320801
INFO:root:current mean train loss 2028.2257620179955
INFO:root:current train perplexity4.942152976989746
INFO:root:current mean train loss 2029.730553357902
INFO:root:current train perplexity4.9492597579956055
INFO:root:current mean train loss 2029.5176771578772
INFO:root:current train perplexity4.952650547027588
INFO:root:current mean train loss 2029.41422148115
INFO:root:current train perplexity4.9531097412109375
INFO:root:current mean train loss 2028.4589415533283
INFO:root:current train perplexity4.950706958770752
INFO:root:current mean train loss 2030.0682832507418
INFO:root:current train perplexity4.950819969177246
INFO:root:current mean train loss 2029.7894102416703
INFO:root:current train perplexity4.953212738037109
INFO:root:current mean train loss 2029.5745368104856
INFO:root:current train perplexity4.949438095092773
INFO:root:current mean train loss 2029.960269728025
INFO:root:current train perplexity4.95238733291626
INFO:root:current mean train loss 2029.1097946604625
INFO:root:current train perplexity4.9501261711120605
INFO:root:current mean train loss 2028.65173252076
INFO:root:current train perplexity4.949620723724365
INFO:root:current mean train loss 2028.6201684584114
INFO:root:current train perplexity4.947784423828125
INFO:root:current mean train loss 2027.842465485909
INFO:root:current train perplexity4.944672584533691
INFO:root:current mean train loss 2028.1461900795337
INFO:root:current train perplexity4.948922157287598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.89s/it]
INFO:root:final mean train loss: 2027.5020940321838
INFO:root:final train perplexity: 4.948132038116455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.03s/it]
INFO:root:eval mean loss: 1965.4309411015072
INFO:root:eval perplexity: 4.901421070098877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.74s/it]
INFO:root:eval mean loss: 2384.2794544409353
INFO:root:eval perplexity: 7.028189182281494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:10:28<9:31:49, 385.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2019.7815211096474
INFO:root:current train perplexity4.860438346862793
INFO:root:current mean train loss 2001.048820249496
INFO:root:current train perplexity4.843832492828369
INFO:root:current mean train loss 2000.1357302365602
INFO:root:current train perplexity4.842152118682861
INFO:root:current mean train loss 2002.3342022673453
INFO:root:current train perplexity4.85089635848999
INFO:root:current mean train loss 1996.9236646110628
INFO:root:current train perplexity4.853390693664551
INFO:root:current mean train loss 2000.0198618397371
INFO:root:current train perplexity4.852305889129639
INFO:root:current mean train loss 2000.9332257596118
INFO:root:current train perplexity4.842705249786377
INFO:root:current mean train loss 2000.573438959874
INFO:root:current train perplexity4.838073253631592
INFO:root:current mean train loss 2000.7561577997144
INFO:root:current train perplexity4.838887691497803
INFO:root:current mean train loss 2003.3252454529427
INFO:root:current train perplexity4.845407962799072
INFO:root:current mean train loss 2005.3789466028934
INFO:root:current train perplexity4.8544697761535645
INFO:root:current mean train loss 2005.86448116206
INFO:root:current train perplexity4.855342864990234
INFO:root:current mean train loss 2006.1363156142168
INFO:root:current train perplexity4.856401443481445
INFO:root:current mean train loss 2005.9264218108822
INFO:root:current train perplexity4.858438014984131
INFO:root:current mean train loss 2004.8803187661665
INFO:root:current train perplexity4.860670566558838
INFO:root:current mean train loss 2006.4067194242346
INFO:root:current train perplexity4.862761974334717
INFO:root:current mean train loss 2005.2947928540648
INFO:root:current train perplexity4.862270832061768
INFO:root:current mean train loss 2005.502347563843
INFO:root:current train perplexity4.862607479095459
INFO:root:current mean train loss 2004.8120710710705
INFO:root:current train perplexity4.86181640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.06s/it]
INFO:root:final mean train loss: 2005.4098029047686
INFO:root:final train perplexity: 4.862666130065918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it]
INFO:root:eval mean loss: 1959.6742246370789
INFO:root:eval perplexity: 4.8786540031433105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.72s/it]
INFO:root:eval mean loss: 2375.662953911098
INFO:root:eval perplexity: 6.978838920593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:17:08<9:32:00, 390.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2040.3162434895833
INFO:root:current train perplexity4.656729221343994
INFO:root:current mean train loss 1987.0847890909436
INFO:root:current train perplexity4.7951531410217285
INFO:root:current mean train loss 1977.8435082647013
INFO:root:current train perplexity4.759403705596924
INFO:root:current mean train loss 1982.9723432182086
INFO:root:current train perplexity4.766897678375244
INFO:root:current mean train loss 1980.1240537279002
INFO:root:current train perplexity4.7595038414001465
INFO:root:current mean train loss 1982.8148016199677
INFO:root:current train perplexity4.772096633911133
INFO:root:current mean train loss 1986.875486459305
INFO:root:current train perplexity4.789462566375732
INFO:root:current mean train loss 1984.7559415076569
INFO:root:current train perplexity4.780433177947998
INFO:root:current mean train loss 1984.9020187358929
INFO:root:current train perplexity4.781149387359619
INFO:root:current mean train loss 1985.1871200003893
INFO:root:current train perplexity4.784045219421387
INFO:root:current mean train loss 1983.8503270705462
INFO:root:current train perplexity4.778446197509766
INFO:root:current mean train loss 1983.903771186891
INFO:root:current train perplexity4.783672332763672
INFO:root:current mean train loss 1982.8508222648131
INFO:root:current train perplexity4.783155918121338
INFO:root:current mean train loss 1983.1375979747756
INFO:root:current train perplexity4.783592224121094
INFO:root:current mean train loss 1984.0011098566688
INFO:root:current train perplexity4.781473159790039
INFO:root:current mean train loss 1983.7825887937665
INFO:root:current train perplexity4.77999210357666
INFO:root:current mean train loss 1985.0031271474627
INFO:root:current train perplexity4.785120964050293
INFO:root:current mean train loss 1985.5858430980027
INFO:root:current train perplexity4.786585807800293
INFO:root:current mean train loss 1985.8223453803123
INFO:root:current train perplexity4.786423683166504
INFO:root:current mean train loss 1987.2155167724482
INFO:root:current train perplexity4.789986610412598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.74s/it]
INFO:root:final mean train loss: 1986.1615700618343
INFO:root:final train perplexity: 4.7894062995910645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.07s/it]
INFO:root:eval mean loss: 1940.8097395660184
INFO:root:eval perplexity: 4.804787635803223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.01s/it]
INFO:root:eval mean loss: 2365.4167238059617
INFO:root:eval perplexity: 6.920601844787598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:23:27<9:20:44, 386.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.7822631835938
INFO:root:current train perplexity4.6920905113220215
INFO:root:current mean train loss 1957.5068471272787
INFO:root:current train perplexity4.671618938446045
INFO:root:current mean train loss 1959.3421564275568
INFO:root:current train perplexity4.7071990966796875
INFO:root:current mean train loss 1958.760924911499
INFO:root:current train perplexity4.689634323120117
INFO:root:current mean train loss 1960.0010463169642
INFO:root:current train perplexity4.6919426918029785
INFO:root:current mean train loss 1965.056884765625
INFO:root:current train perplexity4.69990348815918
INFO:root:current mean train loss 1962.1263024114794
INFO:root:current train perplexity4.693088054656982
INFO:root:current mean train loss 1959.9403106689454
INFO:root:current train perplexity4.690751075744629
INFO:root:current mean train loss 1959.0724130025724
INFO:root:current train perplexity4.695261001586914
INFO:root:current mean train loss 1958.2686986508577
INFO:root:current train perplexity4.696205139160156
INFO:root:current mean train loss 1960.0351458381203
INFO:root:current train perplexity4.699404239654541
INFO:root:current mean train loss 1961.352247946603
INFO:root:current train perplexity4.704690456390381
INFO:root:current mean train loss 1961.306689152952
INFO:root:current train perplexity4.700520038604736
INFO:root:current mean train loss 1963.2652280865293
INFO:root:current train perplexity4.701634883880615
INFO:root:current mean train loss 1964.0736978020466
INFO:root:current train perplexity4.708088397979736
INFO:root:current mean train loss 1963.2305680124384
INFO:root:current train perplexity4.709489345550537
INFO:root:current mean train loss 1964.0203398527922
INFO:root:current train perplexity4.711427688598633
INFO:root:current mean train loss 1966.04619779365
INFO:root:current train perplexity4.7134199142456055
INFO:root:current mean train loss 1965.3924789931748
INFO:root:current train perplexity4.713189601898193
INFO:root:current mean train loss 1966.3128257115682
INFO:root:current train perplexity4.717230796813965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.74s/it]
INFO:root:final mean train loss: 1967.177433662203
INFO:root:final train perplexity: 4.71823263168335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.62s/it]
INFO:root:eval mean loss: 1936.5476251696864
INFO:root:eval perplexity: 4.788255214691162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.82s/it]
INFO:root:eval mean loss: 2359.8550389066654
INFO:root:eval perplexity: 6.889195442199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [1:30:03<9:18:31, 389.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.2095914273648
INFO:root:current train perplexity4.617839336395264
INFO:root:current mean train loss 1960.1743253164918
INFO:root:current train perplexity4.633203506469727
INFO:root:current mean train loss 1951.3808228054127
INFO:root:current train perplexity4.633186340332031
INFO:root:current mean train loss 1947.0068920825993
INFO:root:current train perplexity4.617526531219482
INFO:root:current mean train loss 1947.2382144884332
INFO:root:current train perplexity4.620349407196045
INFO:root:current mean train loss 1950.6368176337728
INFO:root:current train perplexity4.633856296539307
INFO:root:current mean train loss 1947.8702043805804
INFO:root:current train perplexity4.632376194000244
INFO:root:current mean train loss 1946.8101399187478
INFO:root:current train perplexity4.633152008056641
INFO:root:current mean train loss 1946.6717666388981
INFO:root:current train perplexity4.630321979522705
INFO:root:current mean train loss 1944.0680321171292
INFO:root:current train perplexity4.626519680023193
INFO:root:current mean train loss 1944.221569153244
INFO:root:current train perplexity4.631471157073975
INFO:root:current mean train loss 1944.9508099585325
INFO:root:current train perplexity4.635017395019531
INFO:root:current mean train loss 1945.1958443989365
INFO:root:current train perplexity4.6358323097229
INFO:root:current mean train loss 1946.4662505258975
INFO:root:current train perplexity4.63950777053833
INFO:root:current mean train loss 1945.4532042565077
INFO:root:current train perplexity4.636430740356445
INFO:root:current mean train loss 1947.765863501723
INFO:root:current train perplexity4.642467498779297
INFO:root:current mean train loss 1948.3329163156927
INFO:root:current train perplexity4.644759654998779
INFO:root:current mean train loss 1948.9876834076579
INFO:root:current train perplexity4.647782802581787
INFO:root:current mean train loss 1949.2005400597952
INFO:root:current train perplexity4.649617671966553
INFO:root:current mean train loss 1949.523660969968
INFO:root:current train perplexity4.651967525482178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.92s/it]
INFO:root:final mean train loss: 1950.0669146916268
INFO:root:final train perplexity: 4.654991626739502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.74s/it]
INFO:root:eval mean loss: 1919.1242307838818
INFO:root:eval perplexity: 4.721256256103516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.87s/it]
INFO:root:eval mean loss: 2344.5861435477614
INFO:root:eval perplexity: 6.8037028312683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [1:36:24<9:08:17, 387.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1908.5746708622685
INFO:root:current train perplexity4.557583808898926
INFO:root:current mean train loss 1923.7863222592837
INFO:root:current train perplexity4.592723846435547
INFO:root:current mean train loss 1933.2270017608882
INFO:root:current train perplexity4.606497764587402
INFO:root:current mean train loss 1929.4264416021142
INFO:root:current train perplexity4.594782829284668
INFO:root:current mean train loss 1932.398346619459
INFO:root:current train perplexity4.593359470367432
INFO:root:current mean train loss 1935.3953128084809
INFO:root:current train perplexity4.6014909744262695
INFO:root:current mean train loss 1938.417563528825
INFO:root:current train perplexity4.605701446533203
INFO:root:current mean train loss 1935.2927699405254
INFO:root:current train perplexity4.594619274139404
INFO:root:current mean train loss 1935.3255023464944
INFO:root:current train perplexity4.597390651702881
INFO:root:current mean train loss 1934.821824303713
INFO:root:current train perplexity4.597929000854492
INFO:root:current mean train loss 1938.4209075869826
INFO:root:current train perplexity4.603209495544434
INFO:root:current mean train loss 1935.3596219966896
INFO:root:current train perplexity4.597632884979248
INFO:root:current mean train loss 1936.45345373321
INFO:root:current train perplexity4.60096549987793
INFO:root:current mean train loss 1937.679075345331
INFO:root:current train perplexity4.599645137786865
INFO:root:current mean train loss 1938.1158186166126
INFO:root:current train perplexity4.601339340209961
INFO:root:current mean train loss 1936.9262146231752
INFO:root:current train perplexity4.6002044677734375
INFO:root:current mean train loss 1936.014087903024
INFO:root:current train perplexity4.599308967590332
INFO:root:current mean train loss 1936.3175207505612
INFO:root:current train perplexity4.6016130447387695
INFO:root:current mean train loss 1936.7028053390684
INFO:root:current train perplexity4.602340221405029
INFO:root:current mean train loss 1935.5184621039775
INFO:root:current train perplexity4.600207805633545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.94s/it]
INFO:root:final mean train loss: 1935.0821823450995
INFO:root:final train perplexity: 4.6003031730651855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.10s/it]
INFO:root:eval mean loss: 1917.3368430712544
INFO:root:eval perplexity: 4.7144365310668945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it]
INFO:root:eval mean loss: 2348.638708669243
INFO:root:eval perplexity: 6.826289653778076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [1:42:41<8:57:21, 383.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1949.404795472051
INFO:root:current train perplexity4.575335502624512
INFO:root:current mean train loss 1928.5119193450748
INFO:root:current train perplexity4.55413293838501
INFO:root:current mean train loss 1926.473759837696
INFO:root:current train perplexity4.56084680557251
INFO:root:current mean train loss 1927.1997228247137
INFO:root:current train perplexity4.560835838317871
INFO:root:current mean train loss 1925.2424383791135
INFO:root:current train perplexity4.564688205718994
INFO:root:current mean train loss 1923.0699978108582
INFO:root:current train perplexity4.556448459625244
INFO:root:current mean train loss 1922.3473684478624
INFO:root:current train perplexity4.548432350158691
INFO:root:current mean train loss 1922.8802498150737
INFO:root:current train perplexity4.551484107971191
INFO:root:current mean train loss 1922.1380103688289
INFO:root:current train perplexity4.55036735534668
INFO:root:current mean train loss 1921.7801747503781
INFO:root:current train perplexity4.551903247833252
INFO:root:current mean train loss 1921.2513550830488
INFO:root:current train perplexity4.553096294403076
INFO:root:current mean train loss 1920.2254246712546
INFO:root:current train perplexity4.548844814300537
INFO:root:current mean train loss 1919.6788516401025
INFO:root:current train perplexity4.544731616973877
INFO:root:current mean train loss 1921.3076780891001
INFO:root:current train perplexity4.549137115478516
INFO:root:current mean train loss 1921.9712063434738
INFO:root:current train perplexity4.55120849609375
INFO:root:current mean train loss 1921.73991369761
INFO:root:current train perplexity4.553134441375732
INFO:root:current mean train loss 1921.4963626553383
INFO:root:current train perplexity4.552820682525635
INFO:root:current mean train loss 1920.8954124170666
INFO:root:current train perplexity4.5502448081970215
INFO:root:current mean train loss 1920.816386807481
INFO:root:current train perplexity4.550100326538086
INFO:root:current mean train loss 1922.0673652234748
INFO:root:current train perplexity4.551224231719971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.47s/it]
INFO:root:final mean train loss: 1921.7599083173775
INFO:root:final train perplexity: 4.552221775054932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.86s/it]
INFO:root:eval mean loss: 1902.0230907683676
INFO:root:eval perplexity: 4.65640926361084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.55s/it]
INFO:root:eval mean loss: 2330.774703654837
INFO:root:eval perplexity: 6.7272844314575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [1:49:14<8:54:53, 386.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1923.6002114035866
INFO:root:current train perplexity4.532339572906494
INFO:root:current mean train loss 1896.9007230718084
INFO:root:current train perplexity4.481120586395264
INFO:root:current mean train loss 1901.6916012234158
INFO:root:current train perplexity4.496434211730957
INFO:root:current mean train loss 1909.4374546955542
INFO:root:current train perplexity4.502652645111084
INFO:root:current mean train loss 1905.1284034603932
INFO:root:current train perplexity4.491734981536865
INFO:root:current mean train loss 1909.004539645448
INFO:root:current train perplexity4.5006632804870605
INFO:root:current mean train loss 1905.6018062857695
INFO:root:current train perplexity4.496126174926758
INFO:root:current mean train loss 1904.899346830881
INFO:root:current train perplexity4.496641159057617
INFO:root:current mean train loss 1906.6831425847233
INFO:root:current train perplexity4.502873420715332
INFO:root:current mean train loss 1906.1447844099903
INFO:root:current train perplexity4.501256465911865
INFO:root:current mean train loss 1905.8730873781092
INFO:root:current train perplexity4.499969482421875
INFO:root:current mean train loss 1906.7395685369318
INFO:root:current train perplexity4.501833438873291
INFO:root:current mean train loss 1907.9179623052942
INFO:root:current train perplexity4.5050578117370605
INFO:root:current mean train loss 1907.3153767434596
INFO:root:current train perplexity4.5050435066223145
INFO:root:current mean train loss 1906.8645460887622
INFO:root:current train perplexity4.504104137420654
INFO:root:current mean train loss 1906.1304275166779
INFO:root:current train perplexity4.501858234405518
INFO:root:current mean train loss 1906.42069385402
INFO:root:current train perplexity4.5032806396484375
INFO:root:current mean train loss 1907.4450484922268
INFO:root:current train perplexity4.503072738647461
INFO:root:current mean train loss 1909.7118346004163
INFO:root:current train perplexity4.506650924682617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.63s/it]
INFO:root:final mean train loss: 1908.3285768694548
INFO:root:final train perplexity: 4.504256248474121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.88s/it]
INFO:root:eval mean loss: 1897.7021194349788
INFO:root:eval perplexity: 4.64016580581665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.05s/it]
INFO:root:eval mean loss: 2332.77258517218
INFO:root:eval perplexity: 6.738286018371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [1:55:50<8:52:13, 389.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.4176513671875
INFO:root:current train perplexity4.249316692352295
INFO:root:current mean train loss 1860.1688104538691
INFO:root:current train perplexity4.404134273529053
INFO:root:current mean train loss 1869.5984946646342
INFO:root:current train perplexity4.39645528793335
INFO:root:current mean train loss 1881.6942614946208
INFO:root:current train perplexity4.417273044586182
INFO:root:current mean train loss 1877.5114824459877
INFO:root:current train perplexity4.415612697601318
INFO:root:current mean train loss 1882.0265963412749
INFO:root:current train perplexity4.421859264373779
INFO:root:current mean train loss 1880.9341403425233
INFO:root:current train perplexity4.419398784637451
INFO:root:current mean train loss 1882.983461810173
INFO:root:current train perplexity4.423246383666992
INFO:root:current mean train loss 1884.819078907463
INFO:root:current train perplexity4.429251194000244
INFO:root:current mean train loss 1889.6890649279178
INFO:root:current train perplexity4.43927526473999
INFO:root:current mean train loss 1889.442147660137
INFO:root:current train perplexity4.4384260177612305
INFO:root:current mean train loss 1890.5080047193155
INFO:root:current train perplexity4.441448211669922
INFO:root:current mean train loss 1890.174361486158
INFO:root:current train perplexity4.441650867462158
INFO:root:current mean train loss 1889.8645464783883
INFO:root:current train perplexity4.440894603729248
INFO:root:current mean train loss 1890.8733508778637
INFO:root:current train perplexity4.441125392913818
INFO:root:current mean train loss 1891.9131694806374
INFO:root:current train perplexity4.4424357414245605
INFO:root:current mean train loss 1892.9551192714418
INFO:root:current train perplexity4.445139408111572
INFO:root:current mean train loss 1894.1941544429299
INFO:root:current train perplexity4.449849605560303
INFO:root:current mean train loss 1894.2608080581285
INFO:root:current train perplexity4.4517717361450195
INFO:root:current mean train loss 1895.123681576546
INFO:root:current train perplexity4.454969882965088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.17s/it]
INFO:root:final mean train loss: 1894.5160667430976
INFO:root:final train perplexity: 4.455455303192139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.28s/it]
INFO:root:eval mean loss: 1893.978545493268
INFO:root:eval perplexity: 4.626212120056152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it]
INFO:root:eval mean loss: 2326.650671559868
INFO:root:eval perplexity: 6.704633712768555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:02:12<8:42:39, 387.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1861.217118696733
INFO:root:current train perplexity4.441686153411865
INFO:root:current mean train loss 1874.3287343509862
INFO:root:current train perplexity4.422229290008545
INFO:root:current mean train loss 1891.3750274933136
INFO:root:current train perplexity4.451181411743164
INFO:root:current mean train loss 1879.6294134862674
INFO:root:current train perplexity4.419320583343506
INFO:root:current mean train loss 1874.7384522062907
INFO:root:current train perplexity4.402563571929932
INFO:root:current mean train loss 1879.9665316877695
INFO:root:current train perplexity4.412285804748535
INFO:root:current mean train loss 1878.83367664791
INFO:root:current train perplexity4.407484531402588
INFO:root:current mean train loss 1882.6451700057348
INFO:root:current train perplexity4.420562744140625
INFO:root:current mean train loss 1881.0234608151327
INFO:root:current train perplexity4.420337677001953
INFO:root:current mean train loss 1881.1300468527572
INFO:root:current train perplexity4.415591239929199
INFO:root:current mean train loss 1881.6880380888042
INFO:root:current train perplexity4.413239002227783
INFO:root:current mean train loss 1882.87556922627
INFO:root:current train perplexity4.413110256195068
INFO:root:current mean train loss 1883.443225117635
INFO:root:current train perplexity4.412877082824707
INFO:root:current mean train loss 1882.6316186671177
INFO:root:current train perplexity4.410604000091553
INFO:root:current mean train loss 1881.3331926348508
INFO:root:current train perplexity4.40616512298584
INFO:root:current mean train loss 1881.0881370113339
INFO:root:current train perplexity4.4057722091674805
INFO:root:current mean train loss 1881.9815411173754
INFO:root:current train perplexity4.407467365264893
INFO:root:current mean train loss 1881.5406543053816
INFO:root:current train perplexity4.407090663909912
INFO:root:current mean train loss 1882.027722556557
INFO:root:current train perplexity4.4082159996032715
INFO:root:current mean train loss 1882.1854710415175
INFO:root:current train perplexity4.410372734069824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.20s/it]
INFO:root:final mean train loss: 1881.7877966130075
INFO:root:final train perplexity: 4.410953998565674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.55s/it]
INFO:root:eval mean loss: 1903.4141231022827
INFO:root:eval perplexity: 4.66165018081665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.53s/it]
INFO:root:eval mean loss: 2341.693753722712
INFO:root:eval perplexity: 6.787627220153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:08:45<8:38:47, 389.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.0192651993189
INFO:root:current train perplexity4.2888898849487305
INFO:root:current mean train loss 1856.1926866709757
INFO:root:current train perplexity4.3299407958984375
INFO:root:current mean train loss 1867.5941540067665
INFO:root:current train perplexity4.342108249664307
INFO:root:current mean train loss 1866.5066767779774
INFO:root:current train perplexity4.335049629211426
INFO:root:current mean train loss 1869.5698606451986
INFO:root:current train perplexity4.358686923980713
INFO:root:current mean train loss 1864.1136422520003
INFO:root:current train perplexity4.3508100509643555
INFO:root:current mean train loss 1868.022910247946
INFO:root:current train perplexity4.358265399932861
INFO:root:current mean train loss 1867.5996956005793
INFO:root:current train perplexity4.353343963623047
INFO:root:current mean train loss 1869.1078526857216
INFO:root:current train perplexity4.358097076416016
INFO:root:current mean train loss 1870.4539169620275
INFO:root:current train perplexity4.361773490905762
INFO:root:current mean train loss 1871.343887108811
INFO:root:current train perplexity4.363832473754883
INFO:root:current mean train loss 1870.8662993554174
INFO:root:current train perplexity4.365196704864502
INFO:root:current mean train loss 1869.0771426246279
INFO:root:current train perplexity4.363101482391357
INFO:root:current mean train loss 1870.2962988354182
INFO:root:current train perplexity4.362575054168701
INFO:root:current mean train loss 1871.7196433443091
INFO:root:current train perplexity4.364799976348877
INFO:root:current mean train loss 1871.4597416233908
INFO:root:current train perplexity4.367486953735352
INFO:root:current mean train loss 1872.1949065920055
INFO:root:current train perplexity4.368133068084717
INFO:root:current mean train loss 1872.7884974246604
INFO:root:current train perplexity4.369640350341797
INFO:root:current mean train loss 1871.4742809335066
INFO:root:current train perplexity4.367560386657715
INFO:root:current mean train loss 1869.8053112610398
INFO:root:current train perplexity4.36784029006958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.90s/it]
INFO:root:final mean train loss: 1869.8178910694517
INFO:root:final train perplexity: 4.369510650634766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it]
INFO:root:eval mean loss: 1892.1080400182846
INFO:root:eval perplexity: 4.619220733642578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.65s/it]
INFO:root:eval mean loss: 2331.9863411112033
INFO:root:eval perplexity: 6.733953475952148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [2:15:12<8:31:25, 388.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.2574855259486
INFO:root:current train perplexity4.3639116287231445
INFO:root:current mean train loss 1871.863514435597
INFO:root:current train perplexity4.340429782867432
INFO:root:current mean train loss 1864.8852519989014
INFO:root:current train perplexity4.334981918334961
INFO:root:current mean train loss 1862.3765659975202
INFO:root:current train perplexity4.329069137573242
INFO:root:current mean train loss 1857.3262784188255
INFO:root:current train perplexity4.33367919921875
INFO:root:current mean train loss 1857.1365518912994
INFO:root:current train perplexity4.3309783935546875
INFO:root:current mean train loss 1856.3397324724895
INFO:root:current train perplexity4.326671600341797
INFO:root:current mean train loss 1859.6308348317625
INFO:root:current train perplexity4.3289361000061035
INFO:root:current mean train loss 1854.0240468533239
INFO:root:current train perplexity4.315230369567871
INFO:root:current mean train loss 1856.2060377049147
INFO:root:current train perplexity4.319512844085693
INFO:root:current mean train loss 1855.6268813393333
INFO:root:current train perplexity4.319382190704346
INFO:root:current mean train loss 1855.0835931375366
INFO:root:current train perplexity4.319343566894531
INFO:root:current mean train loss 1856.2375746805956
INFO:root:current train perplexity4.321767330169678
INFO:root:current mean train loss 1855.947232586796
INFO:root:current train perplexity4.319235324859619
INFO:root:current mean train loss 1855.9035084483387
INFO:root:current train perplexity4.317842483520508
INFO:root:current mean train loss 1857.199009520229
INFO:root:current train perplexity4.321048736572266
INFO:root:current mean train loss 1858.9865617982432
INFO:root:current train perplexity4.324347496032715
INFO:root:current mean train loss 1858.286755329384
INFO:root:current train perplexity4.324793338775635
INFO:root:current mean train loss 1859.0284217966014
INFO:root:current train perplexity4.327934265136719
INFO:root:current mean train loss 1858.9661777862987
INFO:root:current train perplexity4.329903602600098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.75s/it]
INFO:root:final mean train loss: 1858.095240852175
INFO:root:final train perplexity: 4.329299449920654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 1878.1882419450908
INFO:root:eval perplexity: 4.567509651184082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.19s/it]
INFO:root:eval mean loss: 2317.5641206781916
INFO:root:eval perplexity: 6.654994487762451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:21:36<8:23:03, 386.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1862.9863899962543
INFO:root:current train perplexity4.3069257736206055
INFO:root:current mean train loss 1860.163728041456
INFO:root:current train perplexity4.3067498207092285
INFO:root:current mean train loss 1865.3523637820513
INFO:root:current train perplexity4.307858943939209
INFO:root:current mean train loss 1857.6632724792644
INFO:root:current train perplexity4.291877746582031
INFO:root:current mean train loss 1852.9531448719113
INFO:root:current train perplexity4.283313751220703
INFO:root:current mean train loss 1848.2771843981784
INFO:root:current train perplexity4.276905059814453
INFO:root:current mean train loss 1844.7344987027536
INFO:root:current train perplexity4.2667083740234375
INFO:root:current mean train loss 1846.342967360325
INFO:root:current train perplexity4.273057460784912
INFO:root:current mean train loss 1843.7795257743146
INFO:root:current train perplexity4.273712635040283
INFO:root:current mean train loss 1845.3038483136481
INFO:root:current train perplexity4.280332088470459
INFO:root:current mean train loss 1846.6778747615476
INFO:root:current train perplexity4.281723499298096
INFO:root:current mean train loss 1846.147253116175
INFO:root:current train perplexity4.2810821533203125
INFO:root:current mean train loss 1847.464140095677
INFO:root:current train perplexity4.285348892211914
INFO:root:current mean train loss 1847.161659590797
INFO:root:current train perplexity4.282594203948975
INFO:root:current mean train loss 1846.668237586452
INFO:root:current train perplexity4.281610012054443
INFO:root:current mean train loss 1847.1059070545932
INFO:root:current train perplexity4.281569480895996
INFO:root:current mean train loss 1847.475255990128
INFO:root:current train perplexity4.284251689910889
INFO:root:current mean train loss 1847.701520942391
INFO:root:current train perplexity4.288547039031982
INFO:root:current mean train loss 1848.399434787732
INFO:root:current train perplexity4.293651103973389
INFO:root:current mean train loss 1848.1074544188339
INFO:root:current train perplexity4.293398857116699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.06s/it]
INFO:root:final mean train loss: 1847.3103370531844
INFO:root:final train perplexity: 4.292632102966309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.46s/it]
INFO:root:eval mean loss: 1872.3536675635805
INFO:root:eval perplexity: 4.546009540557861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it]
INFO:root:eval mean loss: 2312.584088697501
INFO:root:eval perplexity: 6.627944469451904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:27:53<8:12:50, 384.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.5574924045138
INFO:root:current train perplexity4.174675941467285
INFO:root:current mean train loss 1825.149597810444
INFO:root:current train perplexity4.220730304718018
INFO:root:current mean train loss 1825.8153400289602
INFO:root:current train perplexity4.229626178741455
INFO:root:current mean train loss 1830.3596116286058
INFO:root:current train perplexity4.234473705291748
INFO:root:current mean train loss 1830.0332838408801
INFO:root:current train perplexity4.234783172607422
INFO:root:current mean train loss 1834.609805556475
INFO:root:current train perplexity4.241953372955322
INFO:root:current mean train loss 1833.4631204356317
INFO:root:current train perplexity4.241176128387451
INFO:root:current mean train loss 1832.823145303847
INFO:root:current train perplexity4.244452953338623
INFO:root:current mean train loss 1833.1195515493328
INFO:root:current train perplexity4.244386196136475
INFO:root:current mean train loss 1830.4944977114899
INFO:root:current train perplexity4.239261150360107
INFO:root:current mean train loss 1830.2793205051248
INFO:root:current train perplexity4.234222412109375
INFO:root:current mean train loss 1830.8490898068212
INFO:root:current train perplexity4.237861156463623
INFO:root:current mean train loss 1830.9565061583999
INFO:root:current train perplexity4.240451812744141
INFO:root:current mean train loss 1831.0883774133038
INFO:root:current train perplexity4.241653919219971
INFO:root:current mean train loss 1831.8237443962353
INFO:root:current train perplexity4.243878364562988
INFO:root:current mean train loss 1831.5090196141657
INFO:root:current train perplexity4.244187831878662
INFO:root:current mean train loss 1831.133163614668
INFO:root:current train perplexity4.243759632110596
INFO:root:current mean train loss 1832.7714612566558
INFO:root:current train perplexity4.244658470153809
INFO:root:current mean train loss 1833.340251813616
INFO:root:current train perplexity4.245798587799072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.57s/it]
INFO:root:final mean train loss: 1834.19579499476
INFO:root:final train perplexity: 4.248462677001953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.75s/it]
INFO:root:eval mean loss: 1875.5272818490969
INFO:root:eval perplexity: 4.557692050933838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.62s/it]
INFO:root:eval mean loss: 2321.078706781915
INFO:root:eval perplexity: 6.674149990081787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:34:29<8:11:06, 387.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1798.6361781529017
INFO:root:current train perplexity4.115732192993164
INFO:root:current mean train loss 1808.420761536215
INFO:root:current train perplexity4.156078815460205
INFO:root:current mean train loss 1814.3463630123415
INFO:root:current train perplexity4.166934013366699
INFO:root:current mean train loss 1811.040901904774
INFO:root:current train perplexity4.167788982391357
INFO:root:current mean train loss 1804.3150178876497
INFO:root:current train perplexity4.1536054611206055
INFO:root:current mean train loss 1805.7527430908685
INFO:root:current train perplexity4.160948276519775
INFO:root:current mean train loss 1811.524265848628
INFO:root:current train perplexity4.174722671508789
INFO:root:current mean train loss 1813.7471352324965
INFO:root:current train perplexity4.1846723556518555
INFO:root:current mean train loss 1816.3371520012874
INFO:root:current train perplexity4.191582679748535
INFO:root:current mean train loss 1818.7173038638282
INFO:root:current train perplexity4.199533462524414
INFO:root:current mean train loss 1819.8996872963473
INFO:root:current train perplexity4.203109264373779
INFO:root:current mean train loss 1820.2942087505999
INFO:root:current train perplexity4.2031331062316895
INFO:root:current mean train loss 1820.4618514597466
INFO:root:current train perplexity4.202097415924072
INFO:root:current mean train loss 1819.1313050670667
INFO:root:current train perplexity4.199714660644531
INFO:root:current mean train loss 1820.1137972942208
INFO:root:current train perplexity4.203493595123291
INFO:root:current mean train loss 1821.9343772032598
INFO:root:current train perplexity4.207446575164795
INFO:root:current mean train loss 1822.950277427004
INFO:root:current train perplexity4.211137771606445
INFO:root:current mean train loss 1822.8441277243062
INFO:root:current train perplexity4.2113566398620605
INFO:root:current mean train loss 1823.6105334857714
INFO:root:current train perplexity4.214160442352295
INFO:root:current mean train loss 1823.8762658313738
INFO:root:current train perplexity4.213830471038818

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.90s/it]
INFO:root:final mean train loss: 1824.0998153494154
INFO:root:final train perplexity: 4.21476936340332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.93s/it]
INFO:root:eval mean loss: 1860.447598504682
INFO:root:eval perplexity: 4.50244665145874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.89s/it]
INFO:root:eval mean loss: 2307.1234208776596
INFO:root:eval perplexity: 6.5984110832214355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:40:58<8:04:52, 387.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.148173014323
INFO:root:current train perplexity4.142481803894043
INFO:root:current mean train loss 1820.3754213394657
INFO:root:current train perplexity4.178272724151611
INFO:root:current mean train loss 1815.0460379464287
INFO:root:current train perplexity4.159842014312744
INFO:root:current mean train loss 1812.9465384777682
INFO:root:current train perplexity4.158804416656494
INFO:root:current mean train loss 1819.2999233029923
INFO:root:current train perplexity4.1832780838012695
INFO:root:current mean train loss 1815.1800849273914
INFO:root:current train perplexity4.177144527435303
INFO:root:current mean train loss 1814.037238292205
INFO:root:current train perplexity4.1729559898376465
INFO:root:current mean train loss 1809.4714658958478
INFO:root:current train perplexity4.172396659851074
INFO:root:current mean train loss 1811.3625049776244
INFO:root:current train perplexity4.17453670501709
INFO:root:current mean train loss 1810.4735112706305
INFO:root:current train perplexity4.173559665679932
INFO:root:current mean train loss 1812.980669260025
INFO:root:current train perplexity4.176427841186523
INFO:root:current mean train loss 1812.8477056645838
INFO:root:current train perplexity4.1736226081848145
INFO:root:current mean train loss 1814.5586016287211
INFO:root:current train perplexity4.1771135330200195
INFO:root:current mean train loss 1815.2848370601043
INFO:root:current train perplexity4.177417278289795
INFO:root:current mean train loss 1814.9224640921261
INFO:root:current train perplexity4.180254936218262
INFO:root:current mean train loss 1814.2149595726194
INFO:root:current train perplexity4.176827907562256
INFO:root:current mean train loss 1815.2435058443416
INFO:root:current train perplexity4.179557800292969
INFO:root:current mean train loss 1815.8639340146235
INFO:root:current train perplexity4.181016445159912
INFO:root:current mean train loss 1814.661399774384
INFO:root:current train perplexity4.180546283721924
INFO:root:current mean train loss 1814.306877088646
INFO:root:current train perplexity4.1793951988220215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.02s/it]
INFO:root:final mean train loss: 1813.7849865027047
INFO:root:final train perplexity: 4.180621147155762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.19s/it]
INFO:root:eval mean loss: 1865.5939867817763
INFO:root:eval perplexity: 4.521224498748779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.71s/it]
INFO:root:eval mean loss: 2310.7396798641125
INFO:root:eval perplexity: 6.617954730987549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:47:34<8:01:31, 390.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.2876423161204
INFO:root:current train perplexity4.137669563293457
INFO:root:current mean train loss 1783.837933046598
INFO:root:current train perplexity4.097211837768555
INFO:root:current mean train loss 1790.6499742689964
INFO:root:current train perplexity4.116046905517578
INFO:root:current mean train loss 1788.852538346545
INFO:root:current train perplexity4.119833469390869
INFO:root:current mean train loss 1791.6708757396189
INFO:root:current train perplexity4.124470233917236
INFO:root:current mean train loss 1793.1219924672914
INFO:root:current train perplexity4.121355056762695
INFO:root:current mean train loss 1797.1629303502218
INFO:root:current train perplexity4.134375095367432
INFO:root:current mean train loss 1798.5094231362284
INFO:root:current train perplexity4.133555889129639
INFO:root:current mean train loss 1800.2634419589774
INFO:root:current train perplexity4.135161876678467
INFO:root:current mean train loss 1800.6524289786878
INFO:root:current train perplexity4.135045528411865
INFO:root:current mean train loss 1800.4309062096618
INFO:root:current train perplexity4.135956287384033
INFO:root:current mean train loss 1800.360259662063
INFO:root:current train perplexity4.13748836517334
INFO:root:current mean train loss 1798.670448518395
INFO:root:current train perplexity4.133337497711182
INFO:root:current mean train loss 1800.939500915391
INFO:root:current train perplexity4.138179302215576
INFO:root:current mean train loss 1799.9449063896056
INFO:root:current train perplexity4.135879039764404
INFO:root:current mean train loss 1801.2940406873581
INFO:root:current train perplexity4.138799667358398
INFO:root:current mean train loss 1801.746074037244
INFO:root:current train perplexity4.138809680938721
INFO:root:current mean train loss 1802.4655193786796
INFO:root:current train perplexity4.1405487060546875
INFO:root:current mean train loss 1802.372403502788
INFO:root:current train perplexity4.1409525871276855
INFO:root:current mean train loss 1803.0525817399416
INFO:root:current train perplexity4.143143177032471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.84s/it]
INFO:root:final mean train loss: 1802.5669424852456
INFO:root:final train perplexity: 4.143797874450684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it]
INFO:root:eval mean loss: 1857.5392659505208
INFO:root:eval perplexity: 4.491868019104004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.43s/it]
INFO:root:eval mean loss: 2303.2351589338155
INFO:root:eval perplexity: 6.577462196350098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:54:01<7:53:38, 389.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1776.212939032193
INFO:root:current train perplexity4.022878646850586
INFO:root:current mean train loss 1779.506988139092
INFO:root:current train perplexity4.065694808959961
INFO:root:current mean train loss 1782.920467879421
INFO:root:current train perplexity4.088228702545166
INFO:root:current mean train loss 1778.2329265232192
INFO:root:current train perplexity4.078807353973389
INFO:root:current mean train loss 1781.757003584283
INFO:root:current train perplexity4.087852954864502
INFO:root:current mean train loss 1784.0027131111392
INFO:root:current train perplexity4.091940402984619
INFO:root:current mean train loss 1784.3499754004204
INFO:root:current train perplexity4.092966079711914
INFO:root:current mean train loss 1787.0008559415712
INFO:root:current train perplexity4.0949296951293945
INFO:root:current mean train loss 1787.454939693282
INFO:root:current train perplexity4.098257541656494
INFO:root:current mean train loss 1806.132836200499
INFO:root:current train perplexity4.152533054351807
INFO:root:current mean train loss 1973.4622147385248
INFO:root:current train perplexity4.73965311050415
INFO:root:current mean train loss 1979.3630115989988
INFO:root:current train perplexity4.763197898864746
INFO:root:current mean train loss 1977.5913887448455
INFO:root:current train perplexity4.758942604064941
INFO:root:current mean train loss 1975.6877570847523
INFO:root:current train perplexity4.753990650177002
INFO:root:current mean train loss 1974.4623170284904
INFO:root:current train perplexity4.750850200653076
INFO:root:current mean train loss 1972.9728978834041
INFO:root:current train perplexity4.741908073425293
INFO:root:current mean train loss 1970.1721962996644
INFO:root:current train perplexity4.732877254486084
INFO:root:current mean train loss 1968.136772077645
INFO:root:current train perplexity4.724315166473389
INFO:root:current mean train loss 1966.0781583755213
INFO:root:current train perplexity4.716750144958496
INFO:root:current mean train loss 1964.984193951896
INFO:root:current train perplexity4.707245826721191

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.33s/it]
INFO:root:final mean train loss: 1963.4361660909724
INFO:root:final train perplexity: 4.70433235168457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.46s/it]
INFO:root:eval mean loss: 1925.4582497887577
INFO:root:eval perplexity: 4.745502948760986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.52s/it]
INFO:root:eval mean loss: 2370.7370891165224
INFO:root:eval perplexity: 6.950780868530273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [3:00:36<7:49:25, 391.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.1789404296876
INFO:root:current train perplexity4.541148662567139
INFO:root:current mean train loss 1916.7588448660715
INFO:root:current train perplexity4.523869514465332
INFO:root:current mean train loss 1917.3986785333807
INFO:root:current train perplexity4.526360988616943
INFO:root:current mean train loss 1925.5696126302084
INFO:root:current train perplexity4.552563667297363
INFO:root:current mean train loss 1930.8314612458882
INFO:root:current train perplexity4.575589656829834
INFO:root:current mean train loss 1937.5217624830163
INFO:root:current train perplexity4.5964579582214355
INFO:root:current mean train loss 1937.8385944733795
INFO:root:current train perplexity4.606309413909912
INFO:root:current mean train loss 1944.2326252205141
INFO:root:current train perplexity4.627112865447998
INFO:root:current mean train loss 1949.6767367466518
INFO:root:current train perplexity4.6414103507995605
INFO:root:current mean train loss 1952.7170163511619
INFO:root:current train perplexity4.656009197235107
INFO:root:current mean train loss 1955.7094794694767
INFO:root:current train perplexity4.661076545715332
INFO:root:current mean train loss 1954.0634368766623
INFO:root:current train perplexity4.662683010101318
INFO:root:current mean train loss 1955.2221236404719
INFO:root:current train perplexity4.669488906860352
INFO:root:current mean train loss 1955.7515001775569
INFO:root:current train perplexity4.673588752746582
INFO:root:current mean train loss 1957.4811174192266
INFO:root:current train perplexity4.678994178771973
INFO:root:current mean train loss 1958.137601453993
INFO:root:current train perplexity4.6797943115234375
INFO:root:current mean train loss 1958.97050351271
INFO:root:current train perplexity4.681492328643799
INFO:root:current mean train loss 1959.4336531690142
INFO:root:current train perplexity4.684272289276123
INFO:root:current mean train loss 1959.8651781901042
INFO:root:current train perplexity4.687283992767334
INFO:root:current mean train loss 1960.4312648956686
INFO:root:current train perplexity4.690858364105225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.24s/it]
INFO:root:final mean train loss: 1959.8082678598162
INFO:root:final train perplexity: 4.690892219543457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.40s/it]
INFO:root:eval mean loss: 1942.9479201296542
INFO:root:eval perplexity: 4.813104152679443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.68s/it]
INFO:root:eval mean loss: 2387.8569612976507
INFO:root:eval perplexity: 7.048783779144287
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:06:54<7:38:06, 387.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.5405140752378
INFO:root:current train perplexity4.7147674560546875
INFO:root:current mean train loss 1968.8775698343914
INFO:root:current train perplexity4.705602169036865
INFO:root:current mean train loss 1962.1064762481271
INFO:root:current train perplexity4.6969523429870605
INFO:root:current mean train loss 1959.1545749586455
INFO:root:current train perplexity4.696030139923096
INFO:root:current mean train loss 1963.0984447448234
INFO:root:current train perplexity4.709717750549316
INFO:root:current mean train loss 1966.6289922353383
INFO:root:current train perplexity4.708034992218018
INFO:root:current mean train loss 1965.0555760378093
INFO:root:current train perplexity4.710790634155273
INFO:root:current mean train loss 1964.9643087676077
INFO:root:current train perplexity4.7095465660095215
INFO:root:current mean train loss 1966.035355914334
INFO:root:current train perplexity4.710912704467773
INFO:root:current mean train loss 1967.8378741356635
INFO:root:current train perplexity4.720070838928223
INFO:root:current mean train loss 1968.1359353537089
INFO:root:current train perplexity4.718203544616699
INFO:root:current mean train loss 1970.2583747198119
INFO:root:current train perplexity4.723721027374268
INFO:root:current mean train loss 1970.3454913915864
INFO:root:current train perplexity4.7254228591918945
INFO:root:current mean train loss 1971.2058519385328
INFO:root:current train perplexity4.72800874710083
INFO:root:current mean train loss 1969.6604486623974
INFO:root:current train perplexity4.725379943847656
INFO:root:current mean train loss 1970.2799125172985
INFO:root:current train perplexity4.731178283691406
INFO:root:current mean train loss 1970.915061788356
INFO:root:current train perplexity4.7320170402526855
INFO:root:current mean train loss 1971.045736176627
INFO:root:current train perplexity4.729365348815918
INFO:root:current mean train loss 1970.4048759992731
INFO:root:current train perplexity4.727179050445557

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.10s/it]
INFO:root:final mean train loss: 1971.6831968214196
INFO:root:final train perplexity: 4.735029697418213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.10s/it]
INFO:root:eval mean loss: 1982.4656623136912
INFO:root:eval perplexity: 4.9694132804870605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.73s/it]
INFO:root:eval mean loss: 2436.945240210134
INFO:root:eval perplexity: 7.337518692016602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:13:30<7:34:53, 389.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2033.4459499782986
INFO:root:current train perplexity4.829230308532715
INFO:root:current mean train loss 1983.2439177626864
INFO:root:current train perplexity4.779918193817139
INFO:root:current mean train loss 1962.9483227889505
INFO:root:current train perplexity4.710709095001221
INFO:root:current mean train loss 1971.0483153506775
INFO:root:current train perplexity4.727984428405762
INFO:root:current mean train loss 1965.5018820914197
INFO:root:current train perplexity4.704552173614502
INFO:root:current mean train loss 1963.8753026576314
INFO:root:current train perplexity4.693839073181152
INFO:root:current mean train loss 1961.4303225061576
INFO:root:current train perplexity4.695511341094971
INFO:root:current mean train loss 1967.3718633611381
INFO:root:current train perplexity4.711559772491455
INFO:root:current mean train loss 1967.598425790907
INFO:root:current train perplexity4.71915340423584
INFO:root:current mean train loss 1971.077419167698
INFO:root:current train perplexity4.727690696716309
INFO:root:current mean train loss 1969.7106700099496
INFO:root:current train perplexity4.723151206970215
INFO:root:current mean train loss 1968.2058330016484
INFO:root:current train perplexity4.726503849029541
INFO:root:current mean train loss 1968.0973692989428
INFO:root:current train perplexity4.725949287414551
INFO:root:current mean train loss 1968.1760244580787
INFO:root:current train perplexity4.728497505187988
INFO:root:current mean train loss 1969.2746927709425
INFO:root:current train perplexity4.730368137359619
INFO:root:current mean train loss 1976.6478658161707
INFO:root:current train perplexity4.758245944976807
INFO:root:current mean train loss 1982.587025359671
INFO:root:current train perplexity4.778798580169678
INFO:root:current mean train loss 1986.6091225023085
INFO:root:current train perplexity4.789724349975586
INFO:root:current mean train loss 1988.7764439791063
INFO:root:current train perplexity4.797331809997559
INFO:root:current mean train loss 1990.1645849916308
INFO:root:current train perplexity4.80155611038208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.00s/it]
INFO:root:final mean train loss: 1989.7895485959268
INFO:root:final train perplexity: 4.803129196166992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it]
INFO:root:eval mean loss: 1963.07150246911
INFO:root:eval perplexity: 4.892077445983887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.91s/it]
INFO:root:eval mean loss: 2412.7989973785184
INFO:root:eval perplexity: 7.194042682647705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:20:14<7:33:13, 394.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2044.7969970703125
INFO:root:current train perplexity5.008566856384277
INFO:root:current mean train loss 2025.4495626782614
INFO:root:current train perplexity4.88417911529541
INFO:root:current mean train loss 2017.7987114560287
INFO:root:current train perplexity4.877124786376953
INFO:root:current mean train loss 2003.8668965532736
INFO:root:current train perplexity4.845571994781494
INFO:root:current mean train loss 2077.648515728158
INFO:root:current train perplexity5.118241786956787
INFO:root:current mean train loss 2217.8814137970085
INFO:root:current train perplexity5.717231273651123
INFO:root:current mean train loss 2436.1012912543056
INFO:root:current train perplexity6.8065714836120605
INFO:root:current mean train loss 3279.362039865541
INFO:root:current train perplexity13.243928909301758
INFO:root:current mean train loss 4037.442767200978
INFO:root:current train perplexity23.997785568237305
INFO:root:current mean train loss 4604.207594539897
INFO:root:current train perplexity37.644718170166016
INFO:root:current mean train loss 5057.441874186198
INFO:root:current train perplexity53.82872009277344
INFO:root:current mean train loss 5411.492663314033
INFO:root:current train perplexity71.40039825439453
INFO:root:current mean train loss 5692.816756828769
INFO:root:current train perplexity89.19476318359375
INFO:root:current mean train loss 5901.864239492747
INFO:root:current train perplexity105.089599609375
INFO:root:current mean train loss 5941.2490269472355
INFO:root:current train perplexity108.5501708984375
INFO:root:current mean train loss 5773.080520889862
INFO:root:current train perplexity95.08841705322266
INFO:root:current mean train loss 5626.43461167827
INFO:root:current train perplexity84.56826782226562
INFO:root:current mean train loss 5473.163393942257
INFO:root:current train perplexity74.81262969970703
INFO:root:current mean train loss 5324.305126445056
INFO:root:current train perplexity66.59857940673828
INFO:root:current mean train loss 5160.183029666002
INFO:root:current train perplexity58.54256820678711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.34s/it]
INFO:root:final mean train loss: 5081.57654337996
INFO:root:final train perplexity: 55.0167121887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.69s/it]
INFO:root:eval mean loss: 2022.2892802353447
INFO:root:eval perplexity: 5.1320695877075195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.62s/it]
INFO:root:eval mean loss: 2468.5550796833445
INFO:root:eval perplexity: 7.529677867889404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:26:39<7:23:31, 391.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2819.6585948855377
INFO:root:current train perplexity9.229089736938477
INFO:root:current mean train loss 2716.3327431845496
INFO:root:current train perplexity8.478737831115723
INFO:root:current mean train loss 2845.9858569235466
INFO:root:current train perplexity9.29512882232666
INFO:root:current mean train loss 2983.462793111106
INFO:root:current train perplexity10.422353744506836
INFO:root:current mean train loss 3034.7730456625636
INFO:root:current train perplexity10.939485549926758
INFO:root:current mean train loss 3141.224957826168
INFO:root:current train perplexity11.910133361816406
INFO:root:current mean train loss 3192.788396903553
INFO:root:current train perplexity12.413152694702148
INFO:root:current mean train loss 3237.712077370563
INFO:root:current train perplexity12.874347686767578
INFO:root:current mean train loss 3314.5635530193504
INFO:root:current train perplexity13.678961753845215
INFO:root:current mean train loss 3359.54300525459
INFO:root:current train perplexity14.146675109863281
INFO:root:current mean train loss 3402.7076515497665
INFO:root:current train perplexity14.652920722961426
INFO:root:current mean train loss 3466.3141318760936
INFO:root:current train perplexity15.416808128356934
INFO:root:current mean train loss 3522.275445816887
INFO:root:current train perplexity16.096595764160156
INFO:root:current mean train loss 3516.6081544786625
INFO:root:current train perplexity16.00893211364746
INFO:root:current mean train loss 3492.5104862036014
INFO:root:current train perplexity15.708866119384766
INFO:root:current mean train loss 3459.939366892569
INFO:root:current train perplexity15.320798873901367
INFO:root:current mean train loss 3419.4276114874183
INFO:root:current train perplexity14.830276489257812
INFO:root:current mean train loss 3397.9501111309078
INFO:root:current train perplexity14.572834968566895
INFO:root:current mean train loss 3379.943598746736
INFO:root:current train perplexity14.358463287353516
INFO:root:current mean train loss 3358.5323608838216
INFO:root:current train perplexity14.11793041229248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.06s/it]
INFO:root:final mean train loss: 3350.648802910678
INFO:root:final train perplexity: 14.048604011535645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.89s/it]
INFO:root:eval mean loss: 2574.1347526387967
INFO:root:eval perplexity: 8.018962860107422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it]
INFO:root:eval mean loss: 2920.891628833527
INFO:root:eval perplexity: 10.900245666503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:32:52<7:10:46, 385.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2939.3632771809894
INFO:root:current train perplexity10.215261459350586
INFO:root:current mean train loss 2940.80167388916
INFO:root:current train perplexity10.260354042053223
INFO:root:current mean train loss 2916.6266808143027
INFO:root:current train perplexity10.021681785583496
INFO:root:current mean train loss 2958.4186713324652
INFO:root:current train perplexity10.380508422851562
INFO:root:current mean train loss 2982.8152359672213
INFO:root:current train perplexity10.584687232971191
INFO:root:current mean train loss 2997.320078386579
INFO:root:current train perplexity10.701421737670898
INFO:root:current mean train loss 3018.3883733575994
INFO:root:current train perplexity10.90032958984375
INFO:root:current mean train loss 3050.016516434519
INFO:root:current train perplexity11.12264347076416
INFO:root:current mean train loss 3072.4226020280703
INFO:root:current train perplexity11.323960304260254
INFO:root:current mean train loss 3109.750746409098
INFO:root:current train perplexity11.652685165405273
INFO:root:current mean train loss 3156.7268213811913
INFO:root:current train perplexity12.075919151306152
INFO:root:current mean train loss 3206.591736681708
INFO:root:current train perplexity12.547222137451172
INFO:root:current mean train loss 3258.223177083333
INFO:root:current train perplexity13.071621894836426
INFO:root:current mean train loss 3320.212023746266
INFO:root:current train perplexity13.70831298828125
INFO:root:current mean train loss 3387.4139285570955
INFO:root:current train perplexity14.430914878845215
INFO:root:current mean train loss 3460.821364495693
INFO:root:current train perplexity15.278729438781738
INFO:root:current mean train loss 3539.0060298322196
INFO:root:current train perplexity16.253129959106445
INFO:root:current mean train loss 3616.3002659190784
INFO:root:current train perplexity17.27983856201172
INFO:root:current mean train loss 3686.2248549594674
INFO:root:current train perplexity18.28070068359375
INFO:root:current mean train loss 3764.14357486647
INFO:root:current train perplexity19.4522647857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.58s/it]
INFO:root:final mean train loss: 3782.675695191353
INFO:root:final train perplexity: 19.751819610595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.18s/it]
INFO:root:eval mean loss: 4406.669089026485
INFO:root:eval perplexity: 35.29902648925781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.64s/it]
INFO:root:eval mean loss: 4876.794917546265
INFO:root:eval perplexity: 53.967220306396484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:39:17<7:03:58, 385.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5335.084605823864
INFO:root:current train perplexity65.94193267822266
INFO:root:current mean train loss 5407.7817079360875
INFO:root:current train perplexity71.62846374511719
INFO:root:current mean train loss 5453.237479199572
INFO:root:current train perplexity74.15284729003906
INFO:root:current mean train loss 5467.2283576135615
INFO:root:current train perplexity74.95420837402344
INFO:root:current mean train loss 5510.2705804916795
INFO:root:current train perplexity77.26005554199219
INFO:root:current mean train loss 5552.711220144606
INFO:root:current train perplexity80.16905975341797
INFO:root:current mean train loss 5615.553721034897
INFO:root:current train perplexity84.33197021484375
INFO:root:current mean train loss 5682.341316763192
INFO:root:current train perplexity88.55961608886719
INFO:root:current mean train loss 5700.192106657996
INFO:root:current train perplexity89.63835906982422
INFO:root:current mean train loss 5735.713048054472
INFO:root:current train perplexity92.02400207519531
INFO:root:current mean train loss 5771.348344014769
INFO:root:current train perplexity94.79275512695312
INFO:root:current mean train loss 5817.50934372013
INFO:root:current train perplexity98.70616149902344
INFO:root:current mean train loss 5850.5904475057505
INFO:root:current train perplexity101.23026275634766
INFO:root:current mean train loss 5901.290768470293
INFO:root:current train perplexity105.37214660644531
INFO:root:current mean train loss 5948.016839256622
INFO:root:current train perplexity109.10912322998047
INFO:root:current mean train loss 5990.248481900464
INFO:root:current train perplexity112.56096649169922
INFO:root:current mean train loss 6034.187129639982
INFO:root:current train perplexity116.48632049560547
INFO:root:current mean train loss 6071.195855462155
INFO:root:current train perplexity119.92192840576172
INFO:root:current mean train loss 6106.987894162893
INFO:root:current train perplexity123.20779418945312
INFO:root:current mean train loss 6134.70904439136
INFO:root:current train perplexity126.0798568725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 339.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 339.00s/it]
INFO:root:final mean train loss: 6134.6478588510145
INFO:root:final train perplexity: 126.23583984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it]
INFO:root:eval mean loss: 6019.671412691157
INFO:root:eval perplexity: 130.10693359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.84s/it]
INFO:root:eval mean loss: 6272.201395237699
INFO:root:eval perplexity: 168.94590759277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:45:48<6:59:23, 387.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6658.882106050532
INFO:root:current train perplexity181.35910034179688
INFO:root:current mean train loss 6710.55946711904
INFO:root:current train perplexity193.15695190429688
INFO:root:current mean train loss 6744.290049027423
INFO:root:current train perplexity201.6688995361328
INFO:root:current mean train loss 6756.068553943925
INFO:root:current train perplexity205.40322875976562
INFO:root:current mean train loss 6758.348287852669
INFO:root:current train perplexity206.31248474121094
INFO:root:current mean train loss 6778.1833775581335
INFO:root:current train perplexity209.8338165283203
INFO:root:current mean train loss 6798.445242142471
INFO:root:current train perplexity212.87332153320312
INFO:root:current mean train loss 6806.185049984257
INFO:root:current train perplexity212.54257202148438
INFO:root:current mean train loss 6812.125499204768
INFO:root:current train perplexity212.9243927001953
INFO:root:current mean train loss 6801.540842221297
INFO:root:current train perplexity211.4209747314453
INFO:root:current mean train loss 6791.102937185786
INFO:root:current train perplexity210.80831909179688
INFO:root:current mean train loss 6775.619331602675
INFO:root:current train perplexity208.75100708007812
INFO:root:current mean train loss 6773.302203454043
INFO:root:current train perplexity208.38641357421875
INFO:root:current mean train loss 6778.620486375762
INFO:root:current train perplexity208.96702575683594
INFO:root:current mean train loss 6781.180418287734
INFO:root:current train perplexity209.13658142089844
INFO:root:current mean train loss 6782.435856875392
INFO:root:current train perplexity209.13807678222656
INFO:root:current mean train loss 6784.415293003339
INFO:root:current train perplexity209.0791473388672
INFO:root:current mean train loss 6781.018559314469
INFO:root:current train perplexity208.5642547607422
INFO:root:current mean train loss 6771.560708002657
INFO:root:current train perplexity207.8430938720703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.07s/it]
INFO:root:final mean train loss: 6766.268888457159
INFO:root:final train perplexity: 207.73983764648438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.65s/it]
INFO:root:eval mean loss: 6133.463221340315
INFO:root:eval perplexity: 142.6487579345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it]
INFO:root:eval mean loss: 6253.1521844525705
INFO:root:eval perplexity: 166.33425903320312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:52:06<6:50:11, 384.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6738.022993607955
INFO:root:current train perplexity186.1566925048828
INFO:root:current mean train loss 6547.955020938908
INFO:root:current train perplexity174.8179168701172
INFO:root:current mean train loss 6547.487695775326
INFO:root:current train perplexity175.1904296875
INFO:root:current mean train loss 6594.809980091942
INFO:root:current train perplexity181.153564453125
INFO:root:current mean train loss 6603.085629799651
INFO:root:current train perplexity180.61949157714844
INFO:root:current mean train loss 6600.479834271037
INFO:root:current train perplexity180.48716735839844
INFO:root:current mean train loss 6589.604623248261
INFO:root:current train perplexity178.86651611328125
INFO:root:current mean train loss 6573.043993385197
INFO:root:current train perplexity177.53025817871094
INFO:root:current mean train loss 6572.6760654284835
INFO:root:current train perplexity177.4839630126953
INFO:root:current mean train loss 6594.16790550391
INFO:root:current train perplexity179.8016815185547
INFO:root:current mean train loss 6592.502339016908
INFO:root:current train perplexity179.7991943359375
INFO:root:current mean train loss 6587.804833852526
INFO:root:current train perplexity179.85003662109375
INFO:root:current mean train loss 6590.229338163192
INFO:root:current train perplexity180.2079315185547
INFO:root:current mean train loss 6586.380435899957
INFO:root:current train perplexity179.6374053955078
INFO:root:current mean train loss 6579.3771559122515
INFO:root:current train perplexity178.9315185546875
INFO:root:current mean train loss 6579.631899598258
INFO:root:current train perplexity178.97836303710938
INFO:root:current mean train loss 6571.587139562966
INFO:root:current train perplexity178.02964782714844
INFO:root:current mean train loss 6572.28542964184
INFO:root:current train perplexity177.91542053222656
INFO:root:current mean train loss 6578.326295630435
INFO:root:current train perplexity178.57037353515625
INFO:root:current mean train loss 6573.576220422063
INFO:root:current train perplexity178.0859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.33s/it]
INFO:root:final mean train loss: 6562.477139671583
INFO:root:final train perplexity: 176.8964080810547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.59s/it]
INFO:root:eval mean loss: 5835.230456629543
INFO:root:eval perplexity: 112.0776596069336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it]
INFO:root:eval mean loss: 6014.6754522661795
INFO:root:eval perplexity: 136.86119079589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:58:26<6:42:13, 383.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6185.795706612723
INFO:root:current train perplexity144.16152954101562
INFO:root:current mean train loss 6411.055358886719
INFO:root:current train perplexity153.0894012451172
INFO:root:current mean train loss 6326.108779639529
INFO:root:current train perplexity145.998779296875
INFO:root:current mean train loss 6252.734123416063
INFO:root:current train perplexity139.75572204589844
INFO:root:current mean train loss 6241.086844471013
INFO:root:current train perplexity138.96746826171875
INFO:root:current mean train loss 6246.484515565814
INFO:root:current train perplexity138.30178833007812
INFO:root:current mean train loss 6250.502100853404
INFO:root:current train perplexity138.42237854003906
INFO:root:current mean train loss 6235.606363485148
INFO:root:current train perplexity137.03176879882812
INFO:root:current mean train loss 6224.724891846882
INFO:root:current train perplexity135.36834716796875
INFO:root:current mean train loss 6222.834071718413
INFO:root:current train perplexity134.50242614746094
INFO:root:current mean train loss 6217.778035798426
INFO:root:current train perplexity133.4762725830078
INFO:root:current mean train loss 6206.622991900072
INFO:root:current train perplexity132.7244415283203
INFO:root:current mean train loss 6190.99039501476
INFO:root:current train perplexity131.68209838867188
INFO:root:current mean train loss 6168.275584025555
INFO:root:current train perplexity129.07276916503906
INFO:root:current mean train loss 6158.233474688704
INFO:root:current train perplexity127.95490264892578
INFO:root:current mean train loss 6143.259813877925
INFO:root:current train perplexity126.3165283203125
INFO:root:current mean train loss 6121.668318464949
INFO:root:current train perplexity124.3629150390625
INFO:root:current mean train loss 6102.652216593425
INFO:root:current train perplexity122.27918243408203
INFO:root:current mean train loss 6080.721583527079
INFO:root:current train perplexity120.61854553222656
INFO:root:current mean train loss 6065.366307682021
INFO:root:current train perplexity119.3179931640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.70s/it]
INFO:root:final mean train loss: 6051.0368617871045
INFO:root:final train perplexity: 118.18031311035156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it]
INFO:root:eval mean loss: 5099.925991626496
INFO:root:eval perplexity: 61.83816909790039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.45s/it]
INFO:root:eval mean loss: 5398.621904089096
INFO:root:eval perplexity: 82.69351196289062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:04:22<6:27:35, 375.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5810.012923177083
INFO:root:current train perplexity97.8223648071289
INFO:root:current mean train loss 5800.044150727371
INFO:root:current train perplexity97.053466796875
INFO:root:current mean train loss 5756.042071906888
INFO:root:current train perplexity93.07940673828125
INFO:root:current mean train loss 5662.178553838316
INFO:root:current train perplexity85.88957977294922
INFO:root:current mean train loss 5578.849028923806
INFO:root:current train perplexity81.25463104248047
INFO:root:current mean train loss 5439.1906451584
INFO:root:current train perplexity73.1442642211914
INFO:root:current mean train loss 5270.040210907219
INFO:root:current train perplexity63.70985794067383
INFO:root:current mean train loss 5097.059362219484
INFO:root:current train perplexity55.69762420654297
INFO:root:current mean train loss 4960.317791350777
INFO:root:current train perplexity49.97763442993164
INFO:root:current mean train loss 4827.148404172867
INFO:root:current train perplexity45.031986236572266
INFO:root:current mean train loss 4725.460798958957
INFO:root:current train perplexity41.60795211791992
INFO:root:current mean train loss 4627.266768516307
INFO:root:current train perplexity38.501407623291016
INFO:root:current mean train loss 4527.240260651983
INFO:root:current train perplexity35.64661407470703
INFO:root:current mean train loss 4431.904956508481
INFO:root:current train perplexity32.99964904785156
INFO:root:current mean train loss 4342.128066372459
INFO:root:current train perplexity30.725778579711914
INFO:root:current mean train loss 4247.016733351032
INFO:root:current train perplexity28.50038719177246
INFO:root:current mean train loss 4160.416666419311
INFO:root:current train perplexity26.58125877380371
INFO:root:current mean train loss 4080.7700682194663
INFO:root:current train perplexity24.951351165771484
INFO:root:current mean train loss 4007.679913512026
INFO:root:current train perplexity23.553895950317383
INFO:root:current mean train loss 3940.8081510332986
INFO:root:current train perplexity22.346242904663086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.03s/it]
INFO:root:final mean train loss: 3916.281033991565
INFO:root:final train perplexity: 21.946653366088867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.10s/it]
INFO:root:eval mean loss: 2329.519003577266
INFO:root:eval perplexity: 6.5796284675598145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it]
INFO:root:eval mean loss: 2746.136726541722
INFO:root:eval perplexity: 9.448593139648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:10:33<6:20:08, 373.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2696.0360107421875
INFO:root:current train perplexity8.347147941589355
INFO:root:current mean train loss 2705.743078161169
INFO:root:current train perplexity8.346593856811523
INFO:root:current mean train loss 2707.7603107481514
INFO:root:current train perplexity8.4298095703125
INFO:root:current mean train loss 2699.1429780570184
INFO:root:current train perplexity8.380758285522461
INFO:root:current mean train loss 2704.208752388562
INFO:root:current train perplexity8.400215148925781
INFO:root:current mean train loss 2687.986838126946
INFO:root:current train perplexity8.31999683380127
INFO:root:current mean train loss 2679.2285761069675
INFO:root:current train perplexity8.261595726013184
INFO:root:current mean train loss 2668.760513425812
INFO:root:current train perplexity8.17398452758789
INFO:root:current mean train loss 2656.2672535482525
INFO:root:current train perplexity8.087204933166504
INFO:root:current mean train loss 2650.167892107101
INFO:root:current train perplexity8.040907859802246
INFO:root:current mean train loss 2643.457166423905
INFO:root:current train perplexity7.9988250732421875
INFO:root:current mean train loss 2644.94332848974
INFO:root:current train perplexity8.01107406616211
INFO:root:current mean train loss 2639.4217722752205
INFO:root:current train perplexity7.981095790863037
INFO:root:current mean train loss 2629.537326986394
INFO:root:current train perplexity7.916755199432373
INFO:root:current mean train loss 2619.34554231281
INFO:root:current train perplexity7.85723876953125
INFO:root:current mean train loss 2613.106794955636
INFO:root:current train perplexity7.819365501403809
INFO:root:current mean train loss 2607.7642942720086
INFO:root:current train perplexity7.793822288513184
INFO:root:current mean train loss 2599.5663691162385
INFO:root:current train perplexity7.746011257171631
INFO:root:current mean train loss 2591.925142314841
INFO:root:current train perplexity7.70768928527832
INFO:root:current mean train loss 2579.185233735406
INFO:root:current train perplexity7.637758731842041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.98s/it]
INFO:root:final mean train loss: 2576.0493027095054
INFO:root:final train perplexity: 7.626487731933594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.85s/it]
INFO:root:eval mean loss: 2319.3624358481547
INFO:root:eval perplexity: 6.525803565979004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.88s/it]
INFO:root:eval mean loss: 2767.701383117243
INFO:root:eval perplexity: 9.616711616516113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:16:31<6:09:08, 369.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2387.5398752719543
INFO:root:current train perplexity6.600948333740234
INFO:root:current mean train loss 2361.9745009438284
INFO:root:current train perplexity6.491934299468994
INFO:root:current mean train loss 2342.2608734459004
INFO:root:current train perplexity6.373748302459717
INFO:root:current mean train loss 2321.026989456217
INFO:root:current train perplexity6.2588043212890625
INFO:root:current mean train loss 2299.3310531584357
INFO:root:current train perplexity6.156503677368164
INFO:root:current mean train loss 2285.459582076789
INFO:root:current train perplexity6.085361480712891
INFO:root:current mean train loss 2273.9628368709155
INFO:root:current train perplexity6.030848979949951
INFO:root:current mean train loss 2268.1406223360777
INFO:root:current train perplexity5.991231918334961
INFO:root:current mean train loss 2267.8415670384047
INFO:root:current train perplexity5.977602958679199
INFO:root:current mean train loss 2260.5934049861544
INFO:root:current train perplexity5.948394298553467
INFO:root:current mean train loss 2252.9035199919267
INFO:root:current train perplexity5.914775371551514
INFO:root:current mean train loss 2251.2115182399343
INFO:root:current train perplexity5.895199775695801
INFO:root:current mean train loss 2244.6291660431125
INFO:root:current train perplexity5.864405632019043
INFO:root:current mean train loss 2241.0713416439107
INFO:root:current train perplexity5.848140716552734
INFO:root:current mean train loss 2236.50345296389
INFO:root:current train perplexity5.826896667480469
INFO:root:current mean train loss 2231.987546431558
INFO:root:current train perplexity5.806196212768555
INFO:root:current mean train loss 2226.53646303487
INFO:root:current train perplexity5.7847466468811035
INFO:root:current mean train loss 2224.499125128452
INFO:root:current train perplexity5.774359703063965
INFO:root:current mean train loss 2223.136252686976
INFO:root:current train perplexity5.770686626434326
INFO:root:current mean train loss 2222.5495361821586
INFO:root:current train perplexity5.768546104431152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.39s/it]
INFO:root:final mean train loss: 2222.0217009374605
INFO:root:final train perplexity: 5.768545150756836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it]
INFO:root:eval mean loss: 2064.303379356438
INFO:root:eval perplexity: 5.309445381164551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.63s/it]
INFO:root:eval mean loss: 2517.658664135223
INFO:root:eval perplexity: 7.838210105895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:22:38<6:02:12, 368.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2192.557441711426
INFO:root:current train perplexity5.614710330963135
INFO:root:current mean train loss 2198.05054396026
INFO:root:current train perplexity5.639466762542725
INFO:root:current mean train loss 2207.1867861361116
INFO:root:current train perplexity5.64390754699707
INFO:root:current mean train loss 2201.146538628472
INFO:root:current train perplexity5.621420860290527
INFO:root:current mean train loss 2191.5615192536384
INFO:root:current train perplexity5.611435413360596
INFO:root:current mean train loss 2192.0083759487075
INFO:root:current train perplexity5.60276985168457
INFO:root:current mean train loss 2192.0374234955884
INFO:root:current train perplexity5.59985876083374
INFO:root:current mean train loss 2187.7506401023675
INFO:root:current train perplexity5.580430507659912
INFO:root:current mean train loss 2187.6514239992416
INFO:root:current train perplexity5.588034629821777
INFO:root:current mean train loss 2186.23662643739
INFO:root:current train perplexity5.58625602722168
INFO:root:current mean train loss 2187.7609874419054
INFO:root:current train perplexity5.595207214355469
INFO:root:current mean train loss 2190.842495207005
INFO:root:current train perplexity5.608667850494385
INFO:root:current mean train loss 2193.161100976261
INFO:root:current train perplexity5.617051124572754
INFO:root:current mean train loss 2193.1667748918508
INFO:root:current train perplexity5.6176300048828125
INFO:root:current mean train loss 2188.899743391231
INFO:root:current train perplexity5.605188846588135
INFO:root:current mean train loss 2187.879275673314
INFO:root:current train perplexity5.601419448852539
INFO:root:current mean train loss 2184.469919456626
INFO:root:current train perplexity5.591502666473389
INFO:root:current mean train loss 2183.3701255475494
INFO:root:current train perplexity5.592679023742676
INFO:root:current mean train loss 2181.948465403625
INFO:root:current train perplexity5.58478307723999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.92s/it]
INFO:root:final mean train loss: 2180.9723664330404
INFO:root:final train perplexity: 5.584786415100098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.47s/it]
INFO:root:eval mean loss: 2031.968308036209
INFO:root:eval perplexity: 5.172399044036865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it]
INFO:root:eval mean loss: 2488.91754453402
INFO:root:eval perplexity: 7.656117916107178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:28:32<5:51:51, 364.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2103.504169170673
INFO:root:current train perplexity5.337538242340088
INFO:root:current mean train loss 2153.918292830476
INFO:root:current train perplexity5.397220134735107
INFO:root:current mean train loss 2145.6258928898915
INFO:root:current train perplexity5.448300361633301
INFO:root:current mean train loss 2153.7543196510583
INFO:root:current train perplexity5.481449127197266
INFO:root:current mean train loss 2160.8876731447676
INFO:root:current train perplexity5.497036933898926
INFO:root:current mean train loss 2157.479077433982
INFO:root:current train perplexity5.489360332489014
INFO:root:current mean train loss 2161.4377098892487
INFO:root:current train perplexity5.503262042999268
INFO:root:current mean train loss 2162.683337796119
INFO:root:current train perplexity5.506158828735352
INFO:root:current mean train loss 2161.8135373724344
INFO:root:current train perplexity5.503267765045166
INFO:root:current mean train loss 2158.282311864646
INFO:root:current train perplexity5.492396354675293
INFO:root:current mean train loss 2157.202442105172
INFO:root:current train perplexity5.484226226806641
INFO:root:current mean train loss 2157.9015346640203
INFO:root:current train perplexity5.483786582946777
INFO:root:current mean train loss 2158.7526747789248
INFO:root:current train perplexity5.480714321136475
INFO:root:current mean train loss 2156.0547675476305
INFO:root:current train perplexity5.47275447845459
INFO:root:current mean train loss 2156.4348891812356
INFO:root:current train perplexity5.4768195152282715
INFO:root:current mean train loss 2157.6508779380783
INFO:root:current train perplexity5.4810638427734375
INFO:root:current mean train loss 2160.84422306976
INFO:root:current train perplexity5.49464750289917
INFO:root:current mean train loss 2163.2141237988226
INFO:root:current train perplexity5.503394603729248
INFO:root:current mean train loss 2166.321462842686
INFO:root:current train perplexity5.5173492431640625
INFO:root:current mean train loss 2168.162461675154
INFO:root:current train perplexity5.52385139465332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.63s/it]
INFO:root:final mean train loss: 2167.204420927493
INFO:root:final train perplexity: 5.524473190307617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it]
INFO:root:eval mean loss: 2132.5676161312886
INFO:root:eval perplexity: 5.610811233520508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.53s/it]
INFO:root:eval mean loss: 2570.8520581400985
INFO:root:eval perplexity: 8.18671989440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:34:19<5:40:59, 358.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2200.804333496094
INFO:root:current train perplexity5.602891445159912
INFO:root:current mean train loss 2170.0583439753605
INFO:root:current train perplexity5.5302910804748535
INFO:root:current mean train loss 2174.9100373641304
INFO:root:current train perplexity5.534583568572998
INFO:root:current mean train loss 2179.92421911991
INFO:root:current train perplexity5.561761856079102
INFO:root:current mean train loss 2179.2500269690227
INFO:root:current train perplexity5.55709171295166
INFO:root:current mean train loss 2177.923393278302
INFO:root:current train perplexity5.550606727600098
INFO:root:current mean train loss 2174.6871870737227
INFO:root:current train perplexity5.53936243057251
INFO:root:current mean train loss 2173.359174169253
INFO:root:current train perplexity5.541488170623779
INFO:root:current mean train loss 2173.0701486610506
INFO:root:current train perplexity5.54075813293457
INFO:root:current mean train loss 2172.870922982821
INFO:root:current train perplexity5.543652057647705
INFO:root:current mean train loss 2173.6668685764944
INFO:root:current train perplexity5.5574469566345215
INFO:root:current mean train loss 2173.792842034534
INFO:root:current train perplexity5.556968688964844
INFO:root:current mean train loss 2272.451287891419
INFO:root:current train perplexity6.004348278045654
INFO:root:current mean train loss 2559.2808660750998
INFO:root:current train perplexity7.538062572479248
INFO:root:current mean train loss 2637.635290185888
INFO:root:current train perplexity8.012439727783203
INFO:root:current mean train loss 2632.302993594899
INFO:root:current train perplexity7.964512825012207
INFO:root:current mean train loss 2619.282240117547
INFO:root:current train perplexity7.8867292404174805
INFO:root:current mean train loss 2630.9274321627754
INFO:root:current train perplexity7.949019432067871
INFO:root:current mean train loss 2651.0699470228183
INFO:root:current train perplexity8.074393272399902
INFO:root:current mean train loss 2660.235456871863
INFO:root:current train perplexity8.141231536865234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.25s/it]
INFO:root:final mean train loss: 2659.575686363878
INFO:root:final train perplexity: 8.145790100097656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.95s/it]
INFO:root:eval mean loss: 2249.719541292664
INFO:root:eval perplexity: 6.1684088706970215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.39s/it]
INFO:root:eval mean loss: 2698.1413059099345
INFO:root:eval perplexity: 9.0849027633667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:40:10<5:32:45, 356.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2591.668472614694
INFO:root:current train perplexity7.81338357925415
INFO:root:current mean train loss 2560.0912604299533
INFO:root:current train perplexity7.516049861907959
INFO:root:current mean train loss 2525.006388181617
INFO:root:current train perplexity7.323638916015625
INFO:root:current mean train loss 2492.955125264544
INFO:root:current train perplexity7.15839147567749
INFO:root:current mean train loss 2466.1618996434563
INFO:root:current train perplexity7.005591869354248
INFO:root:current mean train loss 2439.6311369901164
INFO:root:current train perplexity6.880800724029541
INFO:root:current mean train loss 2418.095506529535
INFO:root:current train perplexity6.7457122802734375
INFO:root:current mean train loss 2393.9150542600087
INFO:root:current train perplexity6.618991374969482
INFO:root:current mean train loss 2373.4401473548646
INFO:root:current train perplexity6.51100492477417
INFO:root:current mean train loss 2354.0842784007473
INFO:root:current train perplexity6.4172844886779785
INFO:root:current mean train loss 2339.0528834943216
INFO:root:current train perplexity6.3394060134887695
INFO:root:current mean train loss 2325.873858158341
INFO:root:current train perplexity6.267655372619629
INFO:root:current mean train loss 2311.887027107245
INFO:root:current train perplexity6.198296546936035
INFO:root:current mean train loss 2301.9624491056516
INFO:root:current train perplexity6.146409034729004
INFO:root:current mean train loss 2292.620335091866
INFO:root:current train perplexity6.095583438873291
INFO:root:current mean train loss 2284.8010776275655
INFO:root:current train perplexity6.057486534118652
INFO:root:current mean train loss 2276.7614255440762
INFO:root:current train perplexity6.02026891708374
INFO:root:current mean train loss 2270.897832319132
INFO:root:current train perplexity5.987811088562012
INFO:root:current mean train loss 2314.0204149544657
INFO:root:current train perplexity6.1973748207092285
INFO:root:current mean train loss 2378.1530427545786
INFO:root:current train perplexity6.519497871398926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.90s/it]
INFO:root:final mean train loss: 2392.012929788456
INFO:root:final train perplexity: 6.59614372253418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it]
INFO:root:eval mean loss: 2521.9453081712654
INFO:root:eval perplexity: 7.687543869018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.86s/it]
INFO:root:eval mean loss: 2974.3481181259694
INFO:root:eval perplexity: 11.387353897094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:46:18<5:30:09, 360.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2836.650302886963
INFO:root:current train perplexity9.233222961425781
INFO:root:current mean train loss 2639.785750226277
INFO:root:current train perplexity7.920546054840088
INFO:root:current mean train loss 2543.4907439260774
INFO:root:current train perplexity7.39816951751709
INFO:root:current mean train loss 2492.3604286948403
INFO:root:current train perplexity7.113211631774902
INFO:root:current mean train loss 2451.990880505792
INFO:root:current train perplexity6.920375823974609
INFO:root:current mean train loss 2433.8901596610426
INFO:root:current train perplexity6.816314220428467
INFO:root:current mean train loss 2420.2310035429805
INFO:root:current train perplexity6.725377559661865
INFO:root:current mean train loss 2402.38366299774
INFO:root:current train perplexity6.653537273406982
INFO:root:current mean train loss 2389.358576597991
INFO:root:current train perplexity6.572616100311279
INFO:root:current mean train loss 2376.093678074754
INFO:root:current train perplexity6.496978759765625
INFO:root:current mean train loss 2363.872068132673
INFO:root:current train perplexity6.441428184509277
INFO:root:current mean train loss 2360.647084134551
INFO:root:current train perplexity6.42330265045166
INFO:root:current mean train loss 2355.918243504778
INFO:root:current train perplexity6.403941631317139
INFO:root:current mean train loss 2352.210420938531
INFO:root:current train perplexity6.39249849319458
INFO:root:current mean train loss 2348.4206636355875
INFO:root:current train perplexity6.3776421546936035
INFO:root:current mean train loss 2344.205571557555
INFO:root:current train perplexity6.359534740447998
INFO:root:current mean train loss 2342.479297858018
INFO:root:current train perplexity6.347742557525635
INFO:root:current mean train loss 2338.1768018934463
INFO:root:current train perplexity6.3218607902526855
INFO:root:current mean train loss 2333.831127510562
INFO:root:current train perplexity6.29758358001709
INFO:root:current mean train loss 2328.7829474858986
INFO:root:current train perplexity6.272392272949219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.98s/it]
INFO:root:final mean train loss: 2327.724408940841
INFO:root:final train perplexity: 6.270044803619385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.86s/it]
INFO:root:eval mean loss: 2096.328143180685
INFO:root:eval perplexity: 5.44875431060791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.85s/it]
INFO:root:eval mean loss: 2550.929674080923
INFO:root:eval perplexity: 8.054415702819824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:52:13<5:22:44, 358.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2317.156121901524
INFO:root:current train perplexity6.229846477508545
INFO:root:current mean train loss 2255.9746120726863
INFO:root:current train perplexity5.9255194664001465
INFO:root:current mean train loss 2208.191027441059
INFO:root:current train perplexity5.732804298400879
INFO:root:current mean train loss 2190.8307352541624
INFO:root:current train perplexity5.635507583618164
INFO:root:current mean train loss 2175.5594609314094
INFO:root:current train perplexity5.592889785766602
INFO:root:current mean train loss 2166.638028116932
INFO:root:current train perplexity5.537055015563965
INFO:root:current mean train loss 2159.6590543906595
INFO:root:current train perplexity5.50206995010376
INFO:root:current mean train loss 2153.602783984625
INFO:root:current train perplexity5.476907253265381
INFO:root:current mean train loss 2146.2416174690516
INFO:root:current train perplexity5.453485012054443
INFO:root:current mean train loss 2143.458450177394
INFO:root:current train perplexity5.437600135803223
INFO:root:current mean train loss 2141.19309479522
INFO:root:current train perplexity5.427063941955566
INFO:root:current mean train loss 2138.1762314940993
INFO:root:current train perplexity5.410943508148193
INFO:root:current mean train loss 2136.7230560993607
INFO:root:current train perplexity5.400197982788086
INFO:root:current mean train loss 2135.0732099241663
INFO:root:current train perplexity5.387673854827881
INFO:root:current mean train loss 2135.252453275342
INFO:root:current train perplexity5.382748603820801
INFO:root:current mean train loss 2140.951514691058
INFO:root:current train perplexity5.403697490692139
INFO:root:current mean train loss 2145.8414551362193
INFO:root:current train perplexity5.4222798347473145
INFO:root:current mean train loss 2151.218642117534
INFO:root:current train perplexity5.4448747634887695
INFO:root:current mean train loss 2212.7361125388343
INFO:root:current train perplexity5.723003387451172
INFO:root:current mean train loss 2244.2028515279926
INFO:root:current train perplexity5.86783504486084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.06s/it]
INFO:root:final mean train loss: 2244.027777182713
INFO:root:final train perplexity: 5.869532585144043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it]
INFO:root:eval mean loss: 2326.7596851105386
INFO:root:eval perplexity: 6.5649614334106445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.12s/it]
INFO:root:eval mean loss: 2758.739053063359
INFO:root:eval perplexity: 9.546481132507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:58:12<5:16:41, 358.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2728.258447763871
INFO:root:current train perplexity8.510651588439941
INFO:root:current mean train loss 2778.7521097202493
INFO:root:current train perplexity8.927326202392578
INFO:root:current mean train loss 2839.8194481766463
INFO:root:current train perplexity9.384285926818848
INFO:root:current mean train loss 2897.6000810939463
INFO:root:current train perplexity9.872529029846191
INFO:root:current mean train loss 2938.0602958709837
INFO:root:current train perplexity10.205733299255371
INFO:root:current mean train loss 2959.089819662547
INFO:root:current train perplexity10.363558769226074
INFO:root:current mean train loss 2959.0473237570513
INFO:root:current train perplexity10.349346160888672
INFO:root:current mean train loss 2957.9860325863488
INFO:root:current train perplexity10.336698532104492
INFO:root:current mean train loss 2963.1931532963877
INFO:root:current train perplexity10.36300277709961
INFO:root:current mean train loss 2964.399713489479
INFO:root:current train perplexity10.350252151489258
INFO:root:current mean train loss 2966.5323515233663
INFO:root:current train perplexity10.36296558380127
INFO:root:current mean train loss 2971.337180823834
INFO:root:current train perplexity10.382533073425293
INFO:root:current mean train loss 2973.736583551016
INFO:root:current train perplexity10.393387794494629
INFO:root:current mean train loss 2979.1567361856223
INFO:root:current train perplexity10.451088905334473
INFO:root:current mean train loss 2988.9193581350655
INFO:root:current train perplexity10.540712356567383
INFO:root:current mean train loss 3001.9612542105856
INFO:root:current train perplexity10.650839805603027
INFO:root:current mean train loss 3016.463324700705
INFO:root:current train perplexity10.785470008850098
INFO:root:current mean train loss 3033.035916915062
INFO:root:current train perplexity10.914803504943848
INFO:root:current mean train loss 3041.9125498057165
INFO:root:current train perplexity11.002371788024902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.50s/it]
INFO:root:final mean train loss: 3045.2322562213385
INFO:root:final train perplexity: 11.04141902923584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.96s/it]
INFO:root:eval mean loss: 2802.575010042664
INFO:root:eval perplexity: 9.646141052246094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it]
INFO:root:eval mean loss: 3230.265680840675
INFO:root:eval perplexity: 14.0384521484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:04:04<5:09:02, 356.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3128.7683919270835
INFO:root:current train perplexity11.848040580749512
INFO:root:current mean train loss 3170.6027704653534
INFO:root:current train perplexity12.08355712890625
INFO:root:current mean train loss 3161.864101108285
INFO:root:current train perplexity12.157261848449707
INFO:root:current mean train loss 3181.3799889942957
INFO:root:current train perplexity12.296953201293945
INFO:root:current mean train loss 3194.6784020849022
INFO:root:current train perplexity12.405999183654785
INFO:root:current mean train loss 3199.507946658829
INFO:root:current train perplexity12.463929176330566
INFO:root:current mean train loss 3208.199264799289
INFO:root:current train perplexity12.554715156555176
INFO:root:current mean train loss 3223.6478030758303
INFO:root:current train perplexity12.70274543762207
INFO:root:current mean train loss 3230.8255646688076
INFO:root:current train perplexity12.807967185974121
INFO:root:current mean train loss 3244.59457634264
INFO:root:current train perplexity12.9529447555542
INFO:root:current mean train loss 3255.732220549184
INFO:root:current train perplexity13.082247734069824
INFO:root:current mean train loss 3267.5592552287694
INFO:root:current train perplexity13.188314437866211
INFO:root:current mean train loss 3277.0412302276236
INFO:root:current train perplexity13.27272891998291
INFO:root:current mean train loss 3287.4329925885218
INFO:root:current train perplexity13.385222434997559
INFO:root:current mean train loss 3301.371146373951
INFO:root:current train perplexity13.515420913696289
INFO:root:current mean train loss 3314.6268694887067
INFO:root:current train perplexity13.664772987365723
INFO:root:current mean train loss 3326.798315354102
INFO:root:current train perplexity13.794507026672363
INFO:root:current mean train loss 3337.580322123269
INFO:root:current train perplexity13.911176681518555
INFO:root:current mean train loss 3347.6336766098484
INFO:root:current train perplexity14.026976585388184
INFO:root:current mean train loss 3358.1745078940926
INFO:root:current train perplexity14.124408721923828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.10s/it]
INFO:root:final mean train loss: 3368.871232256406
INFO:root:final train perplexity: 14.251959800720215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 3232.8848366162456
INFO:root:eval perplexity: 13.661303520202637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.90s/it]
INFO:root:eval mean loss: 3650.721419963431
INFO:root:eval perplexity: 19.799575805664062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:09:52<5:01:02, 354.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3662.529609680176
INFO:root:current train perplexity18.379690170288086
INFO:root:current mean train loss 3618.461181640625
INFO:root:current train perplexity17.2818660736084
INFO:root:current mean train loss 3593.0741429822197
INFO:root:current train perplexity16.830522537231445
INFO:root:current mean train loss 3647.246541586267
INFO:root:current train perplexity17.602930068969727
INFO:root:current mean train loss 3709.845292833116
INFO:root:current train perplexity18.477142333984375
INFO:root:current mean train loss 3758.572928292411
INFO:root:current train perplexity19.127445220947266
INFO:root:current mean train loss 3816.4844503281993
INFO:root:current train perplexity20.03327751159668
INFO:root:current mean train loss 3882.765444229209
INFO:root:current train perplexity21.13219451904297
INFO:root:current mean train loss 3961.61565223107
INFO:root:current train perplexity22.50974464416504
INFO:root:current mean train loss 4051.590898898538
INFO:root:current train perplexity24.175296783447266
INFO:root:current mean train loss 4140.347393656886
INFO:root:current train perplexity25.988340377807617
INFO:root:current mean train loss 4228.759106100238
INFO:root:current train perplexity27.904075622558594
INFO:root:current mean train loss 4314.620813146814
INFO:root:current train perplexity29.861135482788086
INFO:root:current mean train loss 4395.075014956363
INFO:root:current train perplexity31.864978790283203
INFO:root:current mean train loss 4473.0282429103745
INFO:root:current train perplexity33.90739059448242
INFO:root:current mean train loss 4540.108499153476
INFO:root:current train perplexity35.763938903808594
INFO:root:current mean train loss 4598.164708754595
INFO:root:current train perplexity37.566768646240234
INFO:root:current mean train loss 4650.796567709837
INFO:root:current train perplexity39.133705139160156
INFO:root:current mean train loss 4686.012858694818
INFO:root:current train perplexity40.21432113647461
INFO:root:current mean train loss 4723.401655809233
INFO:root:current train perplexity41.41911315917969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.01s/it]
INFO:root:final mean train loss: 4741.377464305976
INFO:root:final train perplexity: 42.070037841796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.82s/it]
INFO:root:eval mean loss: 4496.289627832723
INFO:root:eval perplexity: 37.95248031616211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it]
INFO:root:eval mean loss: 4906.525922193595
INFO:root:eval perplexity: 55.29549789428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:16:03<4:59:10, 359.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5451.960239955357
INFO:root:current train perplexity75.44855499267578
INFO:root:current mean train loss 5506.769426384229
INFO:root:current train perplexity76.14229583740234
INFO:root:current mean train loss 5185.622221307103
INFO:root:current train perplexity59.38595962524414
INFO:root:current mean train loss 4925.170503195514
INFO:root:current train perplexity48.72011184692383
INFO:root:current mean train loss 4686.9966875174
INFO:root:current train perplexity40.364131927490234
INFO:root:current mean train loss 4672.904155015512
INFO:root:current train perplexity40.014034271240234
INFO:root:current mean train loss 4606.37843038268
INFO:root:current train perplexity37.81385803222656
INFO:root:current mean train loss 4512.583956342832
INFO:root:current train perplexity35.05483627319336
INFO:root:current mean train loss 4411.51503175841
INFO:root:current train perplexity32.33871078491211
INFO:root:current mean train loss 4295.708180434585
INFO:root:current train perplexity29.55845069885254
INFO:root:current mean train loss 4159.279956450339
INFO:root:current train perplexity26.59791374206543
INFO:root:current mean train loss 4030.597994944653
INFO:root:current train perplexity24.040334701538086
INFO:root:current mean train loss 3917.9824230478134
INFO:root:current train perplexity21.973194122314453
INFO:root:current mean train loss 3813.744400510795
INFO:root:current train perplexity20.263818740844727
INFO:root:current mean train loss 3721.378232546557
INFO:root:current train perplexity18.845685958862305
INFO:root:current mean train loss 3641.0255059968126
INFO:root:current train perplexity17.69453239440918
INFO:root:current mean train loss 3568.7302300873635
INFO:root:current train perplexity16.710411071777344
INFO:root:current mean train loss 3507.1997936460343
INFO:root:current train perplexity15.910446166992188
INFO:root:current mean train loss 3448.40075643982
INFO:root:current train perplexity15.176533699035645
INFO:root:current mean train loss 3395.908578605515
INFO:root:current train perplexity14.553474426269531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.98s/it]
INFO:root:final mean train loss: 3378.1512624150987
INFO:root:final train perplexity: 14.35665225982666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.85s/it]
INFO:root:eval mean loss: 2208.0489229242853
INFO:root:eval perplexity: 5.963993072509766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.15s/it]
INFO:root:eval mean loss: 2645.919539647745
INFO:root:eval perplexity: 8.705070495605469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:21:53<4:51:01, 356.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2377.9940167051373
INFO:root:current train perplexity6.576577186584473
INFO:root:current mean train loss 2384.7885095067772
INFO:root:current train perplexity6.531566143035889
INFO:root:current mean train loss 2382.874791654429
INFO:root:current train perplexity6.54432487487793
INFO:root:current mean train loss 2375.900381619813
INFO:root:current train perplexity6.523872375488281
INFO:root:current mean train loss 2385.9265372476866
INFO:root:current train perplexity6.54115629196167
INFO:root:current mean train loss 2385.4080758785612
INFO:root:current train perplexity6.542255401611328
INFO:root:current mean train loss 2385.5973595055016
INFO:root:current train perplexity6.554095268249512
INFO:root:current mean train loss 2385.87507728995
INFO:root:current train perplexity6.548491954803467
INFO:root:current mean train loss 2385.435057325121
INFO:root:current train perplexity6.546144008636475
INFO:root:current mean train loss 2387.810327249531
INFO:root:current train perplexity6.558974266052246
INFO:root:current mean train loss 2390.3502951902924
INFO:root:current train perplexity6.559494972229004
INFO:root:current mean train loss 2390.5465651131003
INFO:root:current train perplexity6.56488037109375
INFO:root:current mean train loss 2390.8602714357785
INFO:root:current train perplexity6.570219039916992
INFO:root:current mean train loss 2389.9960184167107
INFO:root:current train perplexity6.565375328063965
INFO:root:current mean train loss 2389.858150050227
INFO:root:current train perplexity6.565009117126465
INFO:root:current mean train loss 2389.0091486476545
INFO:root:current train perplexity6.560122013092041
INFO:root:current mean train loss 2386.514194300767
INFO:root:current train perplexity6.5571417808532715
INFO:root:current mean train loss 2387.6442772939818
INFO:root:current train perplexity6.559219837188721
INFO:root:current mean train loss 2386.8554823569802
INFO:root:current train perplexity6.557391166687012
INFO:root:current mean train loss 2385.532754519706
INFO:root:current train perplexity6.559314250946045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:19<00:00, 319.69s/it]
INFO:root:final mean train loss: 2384.8339611674824
INFO:root:final train perplexity: 6.558903217315674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it]
INFO:root:eval mean loss: 2187.816772028064
INFO:root:eval perplexity: 5.867201328277588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it]
INFO:root:eval mean loss: 2627.5932197300253
INFO:root:eval perplexity: 8.575573921203613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:27:56<4:46:43, 358.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2336.363581278238
INFO:root:current train perplexity6.433043956756592
INFO:root:current mean train loss 2366.703201710852
INFO:root:current train perplexity6.547515392303467
INFO:root:current mean train loss 2377.219014413786
INFO:root:current train perplexity6.581631660461426
INFO:root:current mean train loss 2384.888758885954
INFO:root:current train perplexity6.5871734619140625
INFO:root:current mean train loss 2394.109983329694
INFO:root:current train perplexity6.635750770568848
INFO:root:current mean train loss 2394.2289392068906
INFO:root:current train perplexity6.621270656585693
INFO:root:current mean train loss 2392.7966076249086
INFO:root:current train perplexity6.615241527557373
INFO:root:current mean train loss 2398.1331528314076
INFO:root:current train perplexity6.624703407287598
INFO:root:current mean train loss 2409.9334918634536
INFO:root:current train perplexity6.685213088989258
INFO:root:current mean train loss 2408.7978695688025
INFO:root:current train perplexity6.679640769958496
INFO:root:current mean train loss 2407.647475815876
INFO:root:current train perplexity6.668667316436768
INFO:root:current mean train loss 2405.5229349789333
INFO:root:current train perplexity6.6578779220581055
INFO:root:current mean train loss 2403.8421156088634
INFO:root:current train perplexity6.644114971160889
INFO:root:current mean train loss 2403.5701268789826
INFO:root:current train perplexity6.648915767669678
INFO:root:current mean train loss 2405.0309918661496
INFO:root:current train perplexity6.655698299407959
INFO:root:current mean train loss 2403.5477923395056
INFO:root:current train perplexity6.646932125091553
INFO:root:current mean train loss 2400.370636584712
INFO:root:current train perplexity6.633405685424805
INFO:root:current mean train loss 2399.3516245963397
INFO:root:current train perplexity6.6265082359313965
INFO:root:current mean train loss 2397.9131757885107
INFO:root:current train perplexity6.614753246307373
INFO:root:current mean train loss 2393.9500916173706
INFO:root:current train perplexity6.606229305267334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.54s/it]
INFO:root:final mean train loss: 2393.9500916173706
INFO:root:final train perplexity: 6.606229305267334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.60s/it]
INFO:root:eval mean loss: 2179.8085041451964
INFO:root:eval perplexity: 5.829324722290039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.31s/it]
INFO:root:eval mean loss: 2620.8764709039783
INFO:root:eval perplexity: 8.528597831726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:33:45<4:38:28, 355.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2315.5193530273436
INFO:root:current train perplexity6.318291664123535
INFO:root:current mean train loss 2329.379892578125
INFO:root:current train perplexity6.338489532470703
INFO:root:current mean train loss 2345.207303059896
INFO:root:current train perplexity6.383293628692627
INFO:root:current mean train loss 2343.3416552734375
INFO:root:current train perplexity6.393125057220459
INFO:root:current mean train loss 2347.494565917969
INFO:root:current train perplexity6.398918151855469
INFO:root:current mean train loss 2353.9466841634116
INFO:root:current train perplexity6.408975124359131
INFO:root:current mean train loss 2355.2938174874444
INFO:root:current train perplexity6.413722515106201
INFO:root:current mean train loss 2355.2965815734865
INFO:root:current train perplexity6.415053367614746
INFO:root:current mean train loss 2351.472457682292
INFO:root:current train perplexity6.393113613128662
INFO:root:current mean train loss 2345.5341462402343
INFO:root:current train perplexity6.358922958374023
INFO:root:current mean train loss 2338.1789499733663
INFO:root:current train perplexity6.326359748840332
INFO:root:current mean train loss 2334.700335184733
INFO:root:current train perplexity6.305939197540283
INFO:root:current mean train loss 2328.1904553222657
INFO:root:current train perplexity6.273462772369385
INFO:root:current mean train loss 2322.935752040318
INFO:root:current train perplexity6.245510578155518
INFO:root:current mean train loss 2317.2644209798177
INFO:root:current train perplexity6.2189812660217285
INFO:root:current mean train loss 2312.6055101776124
INFO:root:current train perplexity6.195839881896973
INFO:root:current mean train loss 2308.7982341452207
INFO:root:current train perplexity6.171300411224365
INFO:root:current mean train loss 2303.026376953125
INFO:root:current train perplexity6.141965389251709
INFO:root:current mean train loss 2298.809774940892
INFO:root:current train perplexity6.121603488922119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.02s/it]
INFO:root:final mean train loss: 2293.3027887310695
INFO:root:final train perplexity: 6.102120399475098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 2127.885737425892
INFO:root:eval perplexity: 5.589607238769531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.74s/it]
INFO:root:eval mean loss: 2572.6418240594526
INFO:root:eval perplexity: 8.198715209960938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:39:49<4:34:31, 358.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2158.8595904181984
INFO:root:current train perplexity5.607391834259033
INFO:root:current mean train loss 2195.914740668403
INFO:root:current train perplexity5.621461868286133
INFO:root:current mean train loss 2192.119241318944
INFO:root:current train perplexity5.611441612243652
INFO:root:current mean train loss 2185.0320397987725
INFO:root:current train perplexity5.594265937805176
INFO:root:current mean train loss 2176.906985056486
INFO:root:current train perplexity5.571465015411377
INFO:root:current mean train loss 2180.836498267877
INFO:root:current train perplexity5.575778961181641
INFO:root:current mean train loss 2180.928935095789
INFO:root:current train perplexity5.567296504974365
INFO:root:current mean train loss 2179.0835224827297
INFO:root:current train perplexity5.559469699859619
INFO:root:current mean train loss 2178.130470154481
INFO:root:current train perplexity5.552209377288818
INFO:root:current mean train loss 2177.1123628605933
INFO:root:current train perplexity5.546362400054932
INFO:root:current mean train loss 2174.1245127990182
INFO:root:current train perplexity5.540914058685303
INFO:root:current mean train loss 2175.915462319725
INFO:root:current train perplexity5.548791408538818
INFO:root:current mean train loss 2175.437415242881
INFO:root:current train perplexity5.550164699554443
INFO:root:current mean train loss 2175.167104896308
INFO:root:current train perplexity5.5504374504089355
INFO:root:current mean train loss 2173.766149721435
INFO:root:current train perplexity5.545844554901123
INFO:root:current mean train loss 2171.6099514744355
INFO:root:current train perplexity5.538781642913818
INFO:root:current mean train loss 2168.017817358655
INFO:root:current train perplexity5.5276288986206055
INFO:root:current mean train loss 2165.4435472082937
INFO:root:current train perplexity5.518333911895752
INFO:root:current mean train loss 2165.806308475509
INFO:root:current train perplexity5.520195484161377
INFO:root:current mean train loss 2169.4520579513687
INFO:root:current train perplexity5.532006740570068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.11s/it]
INFO:root:final mean train loss: 2170.6754896478465
INFO:root:final train perplexity: 5.539615154266357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.58s/it]
INFO:root:eval mean loss: 2107.4520986570533
INFO:root:eval perplexity: 5.497994899749756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.81s/it]
INFO:root:eval mean loss: 2553.1073391961713
INFO:root:eval perplexity: 8.068771362304688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:45:41<4:27:20, 356.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2146.518518784467
INFO:root:current train perplexity5.519082546234131
INFO:root:current mean train loss 2151.1703254358094
INFO:root:current train perplexity5.494271755218506
INFO:root:current mean train loss 2151.6705572666265
INFO:root:current train perplexity5.458882808685303
INFO:root:current mean train loss 2145.9727794167525
INFO:root:current train perplexity5.419034481048584
INFO:root:current mean train loss 2134.8535679408483
INFO:root:current train perplexity5.38511323928833
INFO:root:current mean train loss 2130.891357879067
INFO:root:current train perplexity5.359323024749756
INFO:root:current mean train loss 2125.2998293326104
INFO:root:current train perplexity5.34406852722168
INFO:root:current mean train loss 2124.69394810648
INFO:root:current train perplexity5.346644878387451
INFO:root:current mean train loss 2125.1775741028273
INFO:root:current train perplexity5.347498893737793
INFO:root:current mean train loss 2125.706701503321
INFO:root:current train perplexity5.346528053283691
INFO:root:current mean train loss 2124.6444964233633
INFO:root:current train perplexity5.342456817626953
INFO:root:current mean train loss 2122.4753799034806
INFO:root:current train perplexity5.331204891204834
INFO:root:current mean train loss 2119.9237893473965
INFO:root:current train perplexity5.322016716003418
INFO:root:current mean train loss 2118.2060139668934
INFO:root:current train perplexity5.3148274421691895
INFO:root:current mean train loss 2116.4465062182653
INFO:root:current train perplexity5.30722713470459
INFO:root:current mean train loss 2113.4247777906517
INFO:root:current train perplexity5.29267692565918
INFO:root:current mean train loss 2108.0415064462686
INFO:root:current train perplexity5.2715864181518555
INFO:root:current mean train loss 2104.027006191091
INFO:root:current train perplexity5.253043174743652
INFO:root:current mean train loss 2097.9428186447826
INFO:root:current train perplexity5.232011795043945
INFO:root:current mean train loss 2093.4317252663077
INFO:root:current train perplexity5.213198184967041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.16s/it]
INFO:root:final mean train loss: 2091.7039678576493
INFO:root:final train perplexity: 5.2051239013671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.50s/it]
INFO:root:eval mean loss: 1989.98285994293
INFO:root:eval perplexity: 4.999718189239502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.73s/it]
INFO:root:eval mean loss: 2445.408807416334
INFO:root:eval perplexity: 7.388482570648193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:51:31<4:19:53, 354.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.6250694125306
INFO:root:current train perplexity4.8165082931518555
INFO:root:current mean train loss 1975.625637837593
INFO:root:current train perplexity4.786938190460205
INFO:root:current mean train loss 1987.3020296742716
INFO:root:current train perplexity4.799846172332764
INFO:root:current mean train loss 1993.7910058871973
INFO:root:current train perplexity4.8055925369262695
INFO:root:current mean train loss 1993.0189544610068
INFO:root:current train perplexity4.802077770233154
INFO:root:current mean train loss 1985.8701455450318
INFO:root:current train perplexity4.778136253356934
INFO:root:current mean train loss 1986.2435192102294
INFO:root:current train perplexity4.778145790100098
INFO:root:current mean train loss 1983.0502996330413
INFO:root:current train perplexity4.764191627502441
INFO:root:current mean train loss 1980.0224587858493
INFO:root:current train perplexity4.758509159088135
INFO:root:current mean train loss 1976.7653981879682
INFO:root:current train perplexity4.747373580932617
INFO:root:current mean train loss 1974.5199666844449
INFO:root:current train perplexity4.740472793579102
INFO:root:current mean train loss 1974.5568237834966
INFO:root:current train perplexity4.735634803771973
INFO:root:current mean train loss 1971.2970230261103
INFO:root:current train perplexity4.725450038909912
INFO:root:current mean train loss 1971.144399421291
INFO:root:current train perplexity4.72477388381958
INFO:root:current mean train loss 1970.5921703209801
INFO:root:current train perplexity4.720987319946289
INFO:root:current mean train loss 1969.630895815074
INFO:root:current train perplexity4.716064929962158
INFO:root:current mean train loss 1967.9607442281667
INFO:root:current train perplexity4.711096286773682
INFO:root:current mean train loss 1967.4287291330177
INFO:root:current train perplexity4.70996618270874
INFO:root:current mean train loss 1964.8078194509515
INFO:root:current train perplexity4.703631401062012
INFO:root:current mean train loss 1962.2737045405402
INFO:root:current train perplexity4.697976112365723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.44s/it]
INFO:root:final mean train loss: 1961.017178518629
INFO:root:final train perplexity: 4.695365905761719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.71s/it]
INFO:root:eval mean loss: 1930.0456594913564
INFO:root:eval perplexity: 4.763142108917236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.02s/it]
INFO:root:eval mean loss: 2381.4658142522717
INFO:root:eval perplexity: 7.01203727722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:57:22<4:13:20, 353.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1918.4881537942326
INFO:root:current train perplexity4.551212310791016
INFO:root:current mean train loss 1923.601597377232
INFO:root:current train perplexity4.547814846038818
INFO:root:current mean train loss 1922.2169271440648
INFO:root:current train perplexity4.55884313583374
INFO:root:current mean train loss 1923.0273984826129
INFO:root:current train perplexity4.563824653625488
INFO:root:current mean train loss 1922.884792751736
INFO:root:current train perplexity4.557991981506348
INFO:root:current mean train loss 1923.2622278777646
INFO:root:current train perplexity4.550498962402344
INFO:root:current mean train loss 1921.6893213694682
INFO:root:current train perplexity4.544361114501953
INFO:root:current mean train loss 1916.7060030301411
INFO:root:current train perplexity4.5366950035095215
INFO:root:current mean train loss 1914.3731579758605
INFO:root:current train perplexity4.529699802398682
INFO:root:current mean train loss 1915.5657945112748
INFO:root:current train perplexity4.534169673919678
INFO:root:current mean train loss 1917.591051994638
INFO:root:current train perplexity4.536841869354248
INFO:root:current mean train loss 1916.1503282311844
INFO:root:current train perplexity4.535398483276367
INFO:root:current mean train loss 1914.9914837665738
INFO:root:current train perplexity4.530856609344482
INFO:root:current mean train loss 1913.5206612034847
INFO:root:current train perplexity4.527194976806641
INFO:root:current mean train loss 1913.3425974832894
INFO:root:current train perplexity4.524805545806885
INFO:root:current mean train loss 1912.696155003139
INFO:root:current train perplexity4.520885467529297
INFO:root:current mean train loss 1912.084078269611
INFO:root:current train perplexity4.517846584320068
INFO:root:current mean train loss 1911.56147842062
INFO:root:current train perplexity4.513277530670166
INFO:root:current mean train loss 1911.049866114745
INFO:root:current train perplexity4.5109543800354
INFO:root:current mean train loss 1910.2566728669453
INFO:root:current train perplexity4.50837516784668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.20s/it]
INFO:root:final mean train loss: 1909.4423903841835
INFO:root:final train perplexity: 4.508213996887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.27s/it]
INFO:root:eval mean loss: 1904.9337149545656
INFO:root:eval perplexity: 4.667382717132568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it]
INFO:root:eval mean loss: 2355.927453873005
INFO:root:eval perplexity: 6.867103099822998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:03:32<4:10:53, 358.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1883.405602309283
INFO:root:current train perplexity4.412374019622803
INFO:root:current mean train loss 1878.7114567937078
INFO:root:current train perplexity4.416288375854492
INFO:root:current mean train loss 1885.4127282929003
INFO:root:current train perplexity4.435623645782471
INFO:root:current mean train loss 1884.5754454773742
INFO:root:current train perplexity4.437191486358643
INFO:root:current mean train loss 1882.8329081427191
INFO:root:current train perplexity4.425163745880127
INFO:root:current mean train loss 1882.706109775641
INFO:root:current train perplexity4.42081880569458
INFO:root:current mean train loss 1879.9207033032048
INFO:root:current train perplexity4.412025451660156
INFO:root:current mean train loss 1878.6584553518112
INFO:root:current train perplexity4.410900115966797
INFO:root:current mean train loss 1880.0220161050054
INFO:root:current train perplexity4.406704425811768
INFO:root:current mean train loss 1878.8633137194638
INFO:root:current train perplexity4.401594638824463
INFO:root:current mean train loss 1876.432308467742
INFO:root:current train perplexity4.395762920379639
INFO:root:current mean train loss 1877.3232101504814
INFO:root:current train perplexity4.396781921386719
INFO:root:current mean train loss 1878.667777712336
INFO:root:current train perplexity4.396642208099365
INFO:root:current mean train loss 1877.45180919661
INFO:root:current train perplexity4.394495487213135
INFO:root:current mean train loss 1876.4522950862795
INFO:root:current train perplexity4.391833305358887
INFO:root:current mean train loss 1877.6287541434592
INFO:root:current train perplexity4.39373779296875
INFO:root:current mean train loss 1877.430097612783
INFO:root:current train perplexity4.394911289215088
INFO:root:current mean train loss 1876.9393932866114
INFO:root:current train perplexity4.3916168212890625
INFO:root:current mean train loss 1876.0199402017365
INFO:root:current train perplexity4.3905181884765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.03s/it]
INFO:root:final mean train loss: 1875.0299659532786
INFO:root:final train perplexity: 4.387507915496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.35s/it]
INFO:root:eval mean loss: 1887.9750777440713
INFO:root:eval perplexity: 4.603806495666504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.49s/it]
INFO:root:eval mean loss: 2339.9008291258033
INFO:root:eval perplexity: 6.777681827545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:09:27<4:04:03, 357.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1896.240234375
INFO:root:current train perplexity4.317100524902344
INFO:root:current mean train loss 1831.9838567995557
INFO:root:current train perplexity4.250333309173584
INFO:root:current mean train loss 1841.821275163405
INFO:root:current train perplexity4.283411026000977
INFO:root:current mean train loss 1843.0746569096648
INFO:root:current train perplexity4.279078960418701
INFO:root:current mean train loss 1842.4624078095849
INFO:root:current train perplexity4.275961399078369
INFO:root:current mean train loss 1841.6509251081611
INFO:root:current train perplexity4.277210712432861
INFO:root:current mean train loss 1845.6898246080773
INFO:root:current train perplexity4.290298938751221
INFO:root:current mean train loss 1847.8467287242922
INFO:root:current train perplexity4.296391487121582
INFO:root:current mean train loss 1848.210078746006
INFO:root:current train perplexity4.293553352355957
INFO:root:current mean train loss 1849.5197831046025
INFO:root:current train perplexity4.295774936676025
INFO:root:current mean train loss 1850.0635121358846
INFO:root:current train perplexity4.301242828369141
INFO:root:current mean train loss 1852.9444378473797
INFO:root:current train perplexity4.306149482727051
INFO:root:current mean train loss 1852.0770746062876
INFO:root:current train perplexity4.301624298095703
INFO:root:current mean train loss 1851.0364679902013
INFO:root:current train perplexity4.303013801574707
INFO:root:current mean train loss 1849.855004586779
INFO:root:current train perplexity4.302012920379639
INFO:root:current mean train loss 1849.4284911784287
INFO:root:current train perplexity4.30052375793457
INFO:root:current mean train loss 1847.9284261067708
INFO:root:current train perplexity4.298244476318359
INFO:root:current mean train loss 1847.0976809222607
INFO:root:current train perplexity4.293994426727295
INFO:root:current mean train loss 1847.0846461424155
INFO:root:current train perplexity4.292144298553467
INFO:root:current mean train loss 1846.5006643911015
INFO:root:current train perplexity4.2903666496276855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.04s/it]
INFO:root:final mean train loss: 1846.6646544763794
INFO:root:final train perplexity: 4.290447235107422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.43s/it]
INFO:root:eval mean loss: 1883.1545695852726
INFO:root:eval perplexity: 4.585893630981445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it]
INFO:root:eval mean loss: 2337.7822248310063
INFO:root:eval perplexity: 6.765948295593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:15:38<4:00:57, 361.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1842.1594431023848
INFO:root:current train perplexity4.307613849639893
INFO:root:current mean train loss 1834.2975233061975
INFO:root:current train perplexity4.2567572593688965
INFO:root:current mean train loss 1841.7461255217252
INFO:root:current train perplexity4.259256362915039
INFO:root:current mean train loss 1833.8364701704545
INFO:root:current train perplexity4.241715908050537
INFO:root:current mean train loss 1827.5418377787514
INFO:root:current train perplexity4.227933406829834
INFO:root:current mean train loss 1830.5114480314458
INFO:root:current train perplexity4.231996536254883
INFO:root:current mean train loss 1828.3600429356195
INFO:root:current train perplexity4.2345685958862305
INFO:root:current mean train loss 1829.2470518067084
INFO:root:current train perplexity4.2375054359436035
INFO:root:current mean train loss 1827.8885183555594
INFO:root:current train perplexity4.232618808746338
INFO:root:current mean train loss 1827.1018262993914
INFO:root:current train perplexity4.230833053588867
INFO:root:current mean train loss 1827.0170908021037
INFO:root:current train perplexity4.230223655700684
INFO:root:current mean train loss 1826.030697683653
INFO:root:current train perplexity4.226771354675293
INFO:root:current mean train loss 1826.1700533584458
INFO:root:current train perplexity4.225430488586426
INFO:root:current mean train loss 1826.1274598232267
INFO:root:current train perplexity4.225403785705566
INFO:root:current mean train loss 1825.6668188459357
INFO:root:current train perplexity4.221837043762207
INFO:root:current mean train loss 1825.5033880739795
INFO:root:current train perplexity4.219997406005859
INFO:root:current mean train loss 1826.1362981766813
INFO:root:current train perplexity4.221582412719727
INFO:root:current mean train loss 1825.570221746155
INFO:root:current train perplexity4.2193756103515625
INFO:root:current mean train loss 1824.6752353225716
INFO:root:current train perplexity4.217886447906494
INFO:root:current mean train loss 1824.1778762284637
INFO:root:current train perplexity4.214541912078857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.57s/it]
INFO:root:final mean train loss: 1823.660714369258
INFO:root:final train perplexity: 4.2133097648620605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it]
INFO:root:eval mean loss: 1870.0133965674868
INFO:root:eval perplexity: 4.537413597106934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.84s/it]
INFO:root:eval mean loss: 2324.029380419576
INFO:root:eval perplexity: 6.690275192260742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:21:30<3:53:11, 358.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.9717610677083
INFO:root:current train perplexity4.128998756408691
INFO:root:current mean train loss 1798.7723891314338
INFO:root:current train perplexity4.146242141723633
INFO:root:current mean train loss 1808.7413392147776
INFO:root:current train perplexity4.181856155395508
INFO:root:current mean train loss 1812.8352595738002
INFO:root:current train perplexity4.181632041931152
INFO:root:current mean train loss 1809.5148808190581
INFO:root:current train perplexity4.176223278045654
INFO:root:current mean train loss 1808.0415218979565
INFO:root:current train perplexity4.168750762939453
INFO:root:current mean train loss 1807.0906164781102
INFO:root:current train perplexity4.1643500328063965
INFO:root:current mean train loss 1809.9550568953805
INFO:root:current train perplexity4.1678690910339355
INFO:root:current mean train loss 1810.2995421487178
INFO:root:current train perplexity4.171992778778076
INFO:root:current mean train loss 1809.6866169464895
INFO:root:current train perplexity4.167907238006592
INFO:root:current mean train loss 1806.4568131494707
INFO:root:current train perplexity4.156688690185547
INFO:root:current mean train loss 1805.6440381332181
INFO:root:current train perplexity4.1548261642456055
INFO:root:current mean train loss 1806.162049623755
INFO:root:current train perplexity4.1599650382995605
INFO:root:current mean train loss 1807.6547619482715
INFO:root:current train perplexity4.162890434265137
INFO:root:current mean train loss 1806.6553558944659
INFO:root:current train perplexity4.162692070007324
INFO:root:current mean train loss 1807.6691663265228
INFO:root:current train perplexity4.165555953979492
INFO:root:current mean train loss 1808.0322058195006
INFO:root:current train perplexity4.164988040924072
INFO:root:current mean train loss 1808.2166702340826
INFO:root:current train perplexity4.164721488952637
INFO:root:current mean train loss 1808.909686186215
INFO:root:current train perplexity4.1639227867126465
INFO:root:current mean train loss 1808.8345906281274
INFO:root:current train perplexity4.162124156951904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.09s/it]
INFO:root:final mean train loss: 1807.6549879296283
INFO:root:final train perplexity: 4.160459518432617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.67s/it]
INFO:root:eval mean loss: 1861.9725497631316
INFO:root:eval perplexity: 4.508001804351807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.57s/it]
INFO:root:eval mean loss: 2318.662021934563
INFO:root:eval perplexity: 6.660971164703369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:27:38<3:48:52, 361.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1801.0660653744103
INFO:root:current train perplexity4.115832805633545
INFO:root:current mean train loss 1803.0054835899202
INFO:root:current train perplexity4.141555309295654
INFO:root:current mean train loss 1811.8734487902977
INFO:root:current train perplexity4.161545276641846
INFO:root:current mean train loss 1807.2120316373052
INFO:root:current train perplexity4.150966644287109
INFO:root:current mean train loss 1806.7822791093233
INFO:root:current train perplexity4.150123119354248
INFO:root:current mean train loss 1804.570096172864
INFO:root:current train perplexity4.144296646118164
INFO:root:current mean train loss 1802.8240288213055
INFO:root:current train perplexity4.134430408477783
INFO:root:current mean train loss 1802.1042044387555
INFO:root:current train perplexity4.126461982727051
INFO:root:current mean train loss 1800.3580166278941
INFO:root:current train perplexity4.122697353363037
INFO:root:current mean train loss 1796.9246301000542
INFO:root:current train perplexity4.115411758422852
INFO:root:current mean train loss 1797.3505954434502
INFO:root:current train perplexity4.11881685256958
INFO:root:current mean train loss 1796.4017592311836
INFO:root:current train perplexity4.118253231048584
INFO:root:current mean train loss 1796.2947476836841
INFO:root:current train perplexity4.118300914764404
INFO:root:current mean train loss 1796.6268154462884
INFO:root:current train perplexity4.121509552001953
INFO:root:current mean train loss 1795.6542110141195
INFO:root:current train perplexity4.1194167137146
INFO:root:current mean train loss 1794.3663477851587
INFO:root:current train perplexity4.119084358215332
INFO:root:current mean train loss 1794.7818682532707
INFO:root:current train perplexity4.117777347564697
INFO:root:current mean train loss 1794.5212344546626
INFO:root:current train perplexity4.117336273193359
INFO:root:current mean train loss 1794.320857764963
INFO:root:current train perplexity4.117101192474365
INFO:root:current mean train loss 1794.1278148676515
INFO:root:current train perplexity4.1158647537231445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.83s/it]
INFO:root:final mean train loss: 1793.9457030572858
INFO:root:final train perplexity: 4.115718841552734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it]
INFO:root:eval mean loss: 1849.1726879363364
INFO:root:eval perplexity: 4.461577415466309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.26s/it]
INFO:root:eval mean loss: 2305.316311017841
INFO:root:eval perplexity: 6.5886664390563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:33:30<3:41:12, 358.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1807.7677437918526
INFO:root:current train perplexity4.127740383148193
INFO:root:current mean train loss 1799.3093520220589
INFO:root:current train perplexity4.09798002243042
INFO:root:current mean train loss 1788.5124199761285
INFO:root:current train perplexity4.079995632171631
INFO:root:current mean train loss 1781.4145920212204
INFO:root:current train perplexity4.075440406799316
INFO:root:current mean train loss 1786.8338111390458
INFO:root:current train perplexity4.089743614196777
INFO:root:current mean train loss 1788.0281078673245
INFO:root:current train perplexity4.0968017578125
INFO:root:current mean train loss 1785.628311931553
INFO:root:current train perplexity4.088200569152832
INFO:root:current mean train loss 1785.4654453822545
INFO:root:current train perplexity4.086813926696777
INFO:root:current mean train loss 1784.1399801320042
INFO:root:current train perplexity4.086759090423584
INFO:root:current mean train loss 1782.2267308815237
INFO:root:current train perplexity4.079781532287598
INFO:root:current mean train loss 1780.9249288113317
INFO:root:current train perplexity4.079676151275635
INFO:root:current mean train loss 1781.5851773253873
INFO:root:current train perplexity4.083266735076904
INFO:root:current mean train loss 1780.8274231437624
INFO:root:current train perplexity4.082170009613037
INFO:root:current mean train loss 1782.3836746549955
INFO:root:current train perplexity4.084170341491699
INFO:root:current mean train loss 1782.660521215322
INFO:root:current train perplexity4.0831499099731445
INFO:root:current mean train loss 1782.3016194143113
INFO:root:current train perplexity4.082669258117676
INFO:root:current mean train loss 1782.603451592908
INFO:root:current train perplexity4.081599235534668
INFO:root:current mean train loss 1782.8020922989494
INFO:root:current train perplexity4.079792022705078
INFO:root:current mean train loss 1783.370768664355
INFO:root:current train perplexity4.079883575439453
INFO:root:current mean train loss 1784.4394042349104
INFO:root:current train perplexity4.0828471183776855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.27s/it]
INFO:root:final mean train loss: 1783.6586730310669
INFO:root:final train perplexity: 4.08246374130249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.77s/it]
INFO:root:eval mean loss: 1846.3107511912676
INFO:root:eval perplexity: 4.4512619972229
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.57s/it]
INFO:root:eval mean loss: 2303.993276176723
INFO:root:eval perplexity: 6.581540584564209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:39:34<3:36:09, 360.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1774.8737596533765
INFO:root:current train perplexity4.017425060272217
INFO:root:current mean train loss 1770.110315659467
INFO:root:current train perplexity4.034372329711914
INFO:root:current mean train loss 1773.8098978182165
INFO:root:current train perplexity4.052766799926758
INFO:root:current mean train loss 1772.1972268274587
INFO:root:current train perplexity4.046345233917236
INFO:root:current mean train loss 1771.238416605172
INFO:root:current train perplexity4.0488810539245605
INFO:root:current mean train loss 1774.925015763083
INFO:root:current train perplexity4.049348831176758
INFO:root:current mean train loss 1771.4495677253913
INFO:root:current train perplexity4.045384407043457
INFO:root:current mean train loss 1771.0442220258894
INFO:root:current train perplexity4.045709133148193
INFO:root:current mean train loss 1770.9579596449585
INFO:root:current train perplexity4.0446600914001465
INFO:root:current mean train loss 1770.3561149682196
INFO:root:current train perplexity4.0458197593688965
INFO:root:current mean train loss 1771.1567780355192
INFO:root:current train perplexity4.050210952758789
INFO:root:current mean train loss 1772.5311892219422
INFO:root:current train perplexity4.053233623504639
INFO:root:current mean train loss 1772.8839829332994
INFO:root:current train perplexity4.054043769836426
INFO:root:current mean train loss 1771.3908146622375
INFO:root:current train perplexity4.050900459289551
INFO:root:current mean train loss 1772.3801289233252
INFO:root:current train perplexity4.051057815551758
INFO:root:current mean train loss 1772.585775893367
INFO:root:current train perplexity4.050507545471191
INFO:root:current mean train loss 1772.4234446925245
INFO:root:current train perplexity4.047790050506592
INFO:root:current mean train loss 1771.2308652906627
INFO:root:current train perplexity4.046145915985107
INFO:root:current mean train loss 1772.2198023146652
INFO:root:current train perplexity4.046518802642822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.28s/it]
INFO:root:final mean train loss: 1772.2942803133274
INFO:root:final train perplexity: 4.046036720275879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.80s/it]
INFO:root:eval mean loss: 1840.6590814252272
INFO:root:eval perplexity: 4.430963516235352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 2298.9998376724566
INFO:root:eval perplexity: 6.554718971252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [6:45:29<3:29:08, 358.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1691.4606323242188
INFO:root:current train perplexity3.908902168273926
INFO:root:current mean train loss 1739.2759375939002
INFO:root:current train perplexity3.9615182876586914
INFO:root:current mean train loss 1746.09616986443
INFO:root:current train perplexity3.9843122959136963
INFO:root:current mean train loss 1748.2064714933697
INFO:root:current train perplexity3.996410608291626
INFO:root:current mean train loss 1754.8120183661433
INFO:root:current train perplexity4.009003162384033
INFO:root:current mean train loss 1758.6292848132905
INFO:root:current train perplexity4.015692234039307
INFO:root:current mean train loss 1762.499792035842
INFO:root:current train perplexity4.020106792449951
INFO:root:current mean train loss 1764.4152471368964
INFO:root:current train perplexity4.025330066680908
INFO:root:current mean train loss 1765.7321722685401
INFO:root:current train perplexity4.0278239250183105
INFO:root:current mean train loss 1766.6042060514467
INFO:root:current train perplexity4.031071662902832
INFO:root:current mean train loss 1767.0349781294742
INFO:root:current train perplexity4.032129287719727
INFO:root:current mean train loss 1767.7584788004558
INFO:root:current train perplexity4.031282424926758
INFO:root:current mean train loss 1767.548011653051
INFO:root:current train perplexity4.028804779052734
INFO:root:current mean train loss 1767.577961646706
INFO:root:current train perplexity4.028767108917236
INFO:root:current mean train loss 1767.7237914865173
INFO:root:current train perplexity4.029392242431641
INFO:root:current mean train loss 1767.9427704506732
INFO:root:current train perplexity4.0286173820495605
INFO:root:current mean train loss 1767.1638198814487
INFO:root:current train perplexity4.026407718658447
INFO:root:current mean train loss 1765.919103058291
INFO:root:current train perplexity4.023561000823975
INFO:root:current mean train loss 1764.5759676575924
INFO:root:current train perplexity4.019959449768066
INFO:root:current mean train loss 1764.5579562147125
INFO:root:current train perplexity4.020142078399658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.20s/it]
INFO:root:final mean train loss: 1763.8336210573075
INFO:root:final train perplexity: 4.019129276275635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.62s/it]
INFO:root:eval mean loss: 1837.8618709483046
INFO:root:eval perplexity: 4.420950889587402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.45s/it]
INFO:root:eval mean loss: 2295.9946795524434
INFO:root:eval perplexity: 6.538630485534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:51:18<3:21:38, 355.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.7872953869048
INFO:root:current train perplexity4.088027000427246
INFO:root:current mean train loss 1768.6596901633523
INFO:root:current train perplexity4.030416965484619
INFO:root:current mean train loss 1776.321015647094
INFO:root:current train perplexity4.038137912750244
INFO:root:current mean train loss 1765.5302848459405
INFO:root:current train perplexity4.018538475036621
INFO:root:current mean train loss 1760.3404581609077
INFO:root:current train perplexity4.007017135620117
INFO:root:current mean train loss 1758.3697207518594
INFO:root:current train perplexity4.002655029296875
INFO:root:current mean train loss 1757.298754411043
INFO:root:current train perplexity4.001169681549072
INFO:root:current mean train loss 1757.8248402758213
INFO:root:current train perplexity3.9990103244781494
INFO:root:current mean train loss 1756.1238762394373
INFO:root:current train perplexity3.9939796924591064
INFO:root:current mean train loss 1755.0354198741602
INFO:root:current train perplexity3.9947497844696045
INFO:root:current mean train loss 1753.6999021524548
INFO:root:current train perplexity3.993720769882202
INFO:root:current mean train loss 1754.5740815434044
INFO:root:current train perplexity3.9920666217803955
INFO:root:current mean train loss 1752.445911254383
INFO:root:current train perplexity3.988210916519165
INFO:root:current mean train loss 1752.4214395758422
INFO:root:current train perplexity3.989736318588257
INFO:root:current mean train loss 1753.1983114265372
INFO:root:current train perplexity3.989758253097534
INFO:root:current mean train loss 1755.8680380596134
INFO:root:current train perplexity3.992785692214966
INFO:root:current mean train loss 1756.3560751103678
INFO:root:current train perplexity3.9925026893615723
INFO:root:current mean train loss 1756.00108877356
INFO:root:current train perplexity3.993090867996216
INFO:root:current mean train loss 1756.1241336426585
INFO:root:current train perplexity3.9938931465148926
INFO:root:current mean train loss 1755.3972235962106
INFO:root:current train perplexity3.9911739826202393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.46s/it]
INFO:root:final mean train loss: 1755.369975172265
INFO:root:final train perplexity: 3.9923911094665527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.45s/it]
INFO:root:eval mean loss: 1839.9809133110316
INFO:root:eval perplexity: 4.428533554077148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.56s/it]
INFO:root:eval mean loss: 2296.8881745034078
INFO:root:eval perplexity: 6.543409824371338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:57:12<3:15:21, 355.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.245441637541
INFO:root:current train perplexity3.9188153743743896
INFO:root:current mean train loss 1736.2144368489583
INFO:root:current train perplexity3.9380271434783936
INFO:root:current mean train loss 1735.6783026687237
INFO:root:current train perplexity3.9302732944488525
INFO:root:current mean train loss 1742.2541164420766
INFO:root:current train perplexity3.9487247467041016
INFO:root:current mean train loss 1741.3195639135631
INFO:root:current train perplexity3.949765205383301
INFO:root:current mean train loss 1742.8710746906947
INFO:root:current train perplexity3.951841354370117
INFO:root:current mean train loss 1744.676220358726
INFO:root:current train perplexity3.9579594135284424
INFO:root:current mean train loss 1745.023184427401
INFO:root:current train perplexity3.9653778076171875
INFO:root:current mean train loss 1746.9867531860643
INFO:root:current train perplexity3.970767021179199
INFO:root:current mean train loss 1746.8078615884028
INFO:root:current train perplexity3.96901273727417
INFO:root:current mean train loss 1744.0149232721053
INFO:root:current train perplexity3.9614038467407227
INFO:root:current mean train loss 1744.3656212885476
INFO:root:current train perplexity3.9608707427978516
INFO:root:current mean train loss 1746.08548501158
INFO:root:current train perplexity3.9633126258850098
INFO:root:current mean train loss 1747.5244594055084
INFO:root:current train perplexity3.9672985076904297
INFO:root:current mean train loss 1748.239758572426
INFO:root:current train perplexity3.9674856662750244
INFO:root:current mean train loss 1748.8657877392516
INFO:root:current train perplexity3.969048261642456
INFO:root:current mean train loss 1749.350100190066
INFO:root:current train perplexity3.9704575538635254
INFO:root:current mean train loss 1748.0556309813048
INFO:root:current train perplexity3.9687488079071045
INFO:root:current mean train loss 1747.0716471044232
INFO:root:current train perplexity3.9670422077178955
INFO:root:current mean train loss 1748.262095038982
INFO:root:current train perplexity3.968553304672241

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.93s/it]
INFO:root:final mean train loss: 1748.0095699616172
INFO:root:final train perplexity: 3.969282865524292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it]
INFO:root:eval mean loss: 1827.552857743933
INFO:root:eval perplexity: 4.3842453956604
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it]
INFO:root:eval mean loss: 2285.8757839338155
INFO:root:eval perplexity: 6.4847412109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:03:19<3:11:16, 358.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1762.9730113636363
INFO:root:current train perplexity3.991175889968872
INFO:root:current mean train loss 1753.4323935231855
INFO:root:current train perplexity3.969326972961426
INFO:root:current mean train loss 1742.2701052198222
INFO:root:current train perplexity3.9379990100860596
INFO:root:current mean train loss 1738.2166490151849
INFO:root:current train perplexity3.9304840564727783
INFO:root:current mean train loss 1742.784889305031
INFO:root:current train perplexity3.9366748332977295
INFO:root:current mean train loss 1742.0874155405406
INFO:root:current train perplexity3.9317803382873535
INFO:root:current mean train loss 1740.5243857347327
INFO:root:current train perplexity3.9342076778411865
INFO:root:current mean train loss 1741.3222918175704
INFO:root:current train perplexity3.9375534057617188
INFO:root:current mean train loss 1741.8621185124268
INFO:root:current train perplexity3.940857410430908
INFO:root:current mean train loss 1741.6069762864038
INFO:root:current train perplexity3.940309762954712
INFO:root:current mean train loss 1742.5850625277697
INFO:root:current train perplexity3.941556930541992
INFO:root:current mean train loss 1740.3656975023673
INFO:root:current train perplexity3.93696665763855
INFO:root:current mean train loss 1741.7220457039032
INFO:root:current train perplexity3.943681478500366
INFO:root:current mean train loss 1741.4068613425393
INFO:root:current train perplexity3.945047378540039
INFO:root:current mean train loss 1740.8749005819104
INFO:root:current train perplexity3.9421255588531494
INFO:root:current mean train loss 1741.2862323527934
INFO:root:current train perplexity3.942610740661621
INFO:root:current mean train loss 1740.4476395068211
INFO:root:current train perplexity3.9414870738983154
INFO:root:current mean train loss 1741.843616035657
INFO:root:current train perplexity3.9444708824157715
INFO:root:current mean train loss 1740.4530794621799
INFO:root:current train perplexity3.9438929557800293
INFO:root:current mean train loss 1741.4780014311261
INFO:root:current train perplexity3.9478139877319336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.82s/it]
INFO:root:final mean train loss: 1741.1175518641853
INFO:root:final train perplexity: 3.9477670192718506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it]
INFO:root:eval mean loss: 1823.7212706220912
INFO:root:eval perplexity: 4.370680332183838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.47s/it]
INFO:root:eval mean loss: 2282.186119999446
INFO:root:eval perplexity: 6.465204238891602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:09:13<3:04:34, 357.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1759.9151577419705
INFO:root:current train perplexity3.9721949100494385
INFO:root:current mean train loss 1752.694281999455
INFO:root:current train perplexity3.9589786529541016
INFO:root:current mean train loss 1746.2381923899932
INFO:root:current train perplexity3.9500572681427
INFO:root:current mean train loss 1742.3153689804897
INFO:root:current train perplexity3.9401655197143555
INFO:root:current mean train loss 1735.6039095086567
INFO:root:current train perplexity3.9282689094543457
INFO:root:current mean train loss 1733.98546915121
INFO:root:current train perplexity3.9260289669036865
INFO:root:current mean train loss 1734.554300580706
INFO:root:current train perplexity3.926830768585205
INFO:root:current mean train loss 1735.6274439362046
INFO:root:current train perplexity3.9285106658935547
INFO:root:current mean train loss 1733.9828247630269
INFO:root:current train perplexity3.9254491329193115
INFO:root:current mean train loss 1735.5511345255031
INFO:root:current train perplexity3.9273386001586914
INFO:root:current mean train loss 1732.8675581519283
INFO:root:current train perplexity3.925351142883301
INFO:root:current mean train loss 1733.386561579265
INFO:root:current train perplexity3.925647497177124
INFO:root:current mean train loss 1732.481993669234
INFO:root:current train perplexity3.9260222911834717
INFO:root:current mean train loss 1733.2560855431736
INFO:root:current train perplexity3.927114486694336
INFO:root:current mean train loss 1733.6262438400931
INFO:root:current train perplexity3.9274978637695312
INFO:root:current mean train loss 1733.0135487952002
INFO:root:current train perplexity3.9251513481140137
INFO:root:current mean train loss 1733.088890258205
INFO:root:current train perplexity3.9235408306121826
INFO:root:current mean train loss 1735.052894402842
INFO:root:current train perplexity3.927438735961914
INFO:root:current mean train loss 1735.683322091388
INFO:root:current train perplexity3.928753614425659
INFO:root:current mean train loss 1735.5345478792945
INFO:root:current train perplexity3.929002046585083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.80s/it]
INFO:root:final mean train loss: 1735.0611647674668
INFO:root:final train perplexity: 3.928955554962158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.05s/it]
INFO:root:eval mean loss: 1820.7555074488862
INFO:root:eval perplexity: 4.360209941864014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.57s/it]
INFO:root:eval mean loss: 2279.991155096825
INFO:root:eval perplexity: 6.453608512878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:15:10<2:58:41, 357.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1703.2659788667486
INFO:root:current train perplexity3.877467155456543
INFO:root:current mean train loss 1711.522484188988
INFO:root:current train perplexity3.884812593460083
INFO:root:current mean train loss 1726.736370786251
INFO:root:current train perplexity3.8990330696105957
INFO:root:current mean train loss 1722.410780095196
INFO:root:current train perplexity3.8945610523223877
INFO:root:current mean train loss 1721.8299168623785
INFO:root:current train perplexity3.892876625061035
INFO:root:current mean train loss 1724.1976649959545
INFO:root:current train perplexity3.90086030960083
INFO:root:current mean train loss 1725.8381202376634
INFO:root:current train perplexity3.9044508934020996
INFO:root:current mean train loss 1726.125255125406
INFO:root:current train perplexity3.900153160095215
INFO:root:current mean train loss 1727.070222697993
INFO:root:current train perplexity3.903745412826538
INFO:root:current mean train loss 1728.252209978711
INFO:root:current train perplexity3.9071855545043945
INFO:root:current mean train loss 1725.4912980344998
INFO:root:current train perplexity3.9008285999298096
INFO:root:current mean train loss 1725.3015179838626
INFO:root:current train perplexity3.8999011516571045
INFO:root:current mean train loss 1723.8963176055506
INFO:root:current train perplexity3.8959035873413086
INFO:root:current mean train loss 1724.2098046804692
INFO:root:current train perplexity3.89790678024292
INFO:root:current mean train loss 1725.3330404410992
INFO:root:current train perplexity3.900068998336792
INFO:root:current mean train loss 1726.1050716565794
INFO:root:current train perplexity3.9026403427124023
INFO:root:current mean train loss 1726.2635658494532
INFO:root:current train perplexity3.9028687477111816
INFO:root:current mean train loss 1727.0321998148406
INFO:root:current train perplexity3.902618408203125
INFO:root:current mean train loss 1727.684933227733
INFO:root:current train perplexity3.904907464981079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.93s/it]
INFO:root:final mean train loss: 1727.192255755957
INFO:root:final train perplexity: 3.9046483039855957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it]
INFO:root:eval mean loss: 1828.5345381067154
INFO:root:eval perplexity: 4.3877272605896
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it]
INFO:root:eval mean loss: 2289.77382665323
INFO:root:eval perplexity: 6.505445957183838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:21:16<2:53:52, 359.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.0481770833333
INFO:root:current train perplexity3.8566038608551025
INFO:root:current mean train loss 1702.6486206054688
INFO:root:current train perplexity3.8446407318115234
INFO:root:current mean train loss 1715.5784918035117
INFO:root:current train perplexity3.8512818813323975
INFO:root:current mean train loss 1717.3191703846253
INFO:root:current train perplexity3.8581085205078125
INFO:root:current mean train loss 1722.7654238545836
INFO:root:current train perplexity3.8715884685516357
INFO:root:current mean train loss 1720.6212148553298
INFO:root:current train perplexity3.8764145374298096
INFO:root:current mean train loss 1720.8784010481127
INFO:root:current train perplexity3.875906229019165
INFO:root:current mean train loss 1717.5595443768811
INFO:root:current train perplexity3.869976282119751
INFO:root:current mean train loss 1715.45263747601
INFO:root:current train perplexity3.8713977336883545
INFO:root:current mean train loss 1715.823934592948
INFO:root:current train perplexity3.8755767345428467
INFO:root:current mean train loss 1717.608449037222
INFO:root:current train perplexity3.876943588256836
INFO:root:current mean train loss 1719.506573144178
INFO:root:current train perplexity3.8807499408721924
INFO:root:current mean train loss 1719.8838275257826
INFO:root:current train perplexity3.881063222885132
INFO:root:current mean train loss 1720.334729508638
INFO:root:current train perplexity3.8836591243743896
INFO:root:current mean train loss 1720.9960861965737
INFO:root:current train perplexity3.885091781616211
INFO:root:current mean train loss 1721.1365096255602
INFO:root:current train perplexity3.884687900543213
INFO:root:current mean train loss 1720.870092864648
INFO:root:current train perplexity3.883755922317505
INFO:root:current mean train loss 1721.6388261443985
INFO:root:current train perplexity3.8837127685546875
INFO:root:current mean train loss 1721.1621196489134
INFO:root:current train perplexity3.8826963901519775
INFO:root:current mean train loss 1721.656700942849
INFO:root:current train perplexity3.8843231201171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.82s/it]
INFO:root:final mean train loss: 1721.3866586074405
INFO:root:final train perplexity: 3.8868114948272705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.29s/it]
INFO:root:eval mean loss: 1818.0712085480386
INFO:root:eval perplexity: 4.350754737854004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it]
INFO:root:eval mean loss: 2279.297295320119
INFO:root:eval perplexity: 6.449946403503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:27:07<2:46:45, 357.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1762.0266750169837
INFO:root:current train perplexity3.931612968444824
INFO:root:current mean train loss 1734.4587620680895
INFO:root:current train perplexity3.8991847038269043
INFO:root:current mean train loss 1722.1291673600406
INFO:root:current train perplexity3.8721625804901123
INFO:root:current mean train loss 1718.7731396937886
INFO:root:current train perplexity3.8644487857818604
INFO:root:current mean train loss 1717.3556040950982
INFO:root:current train perplexity3.8576362133026123
INFO:root:current mean train loss 1715.1177243292902
INFO:root:current train perplexity3.8557047843933105
INFO:root:current mean train loss 1715.9745735180704
INFO:root:current train perplexity3.8606417179107666
INFO:root:current mean train loss 1713.956794875951
INFO:root:current train perplexity3.859952449798584
INFO:root:current mean train loss 1712.482018434842
INFO:root:current train perplexity3.857733726501465
INFO:root:current mean train loss 1714.8165738156401
INFO:root:current train perplexity3.865309476852417
INFO:root:current mean train loss 1712.8909535039788
INFO:root:current train perplexity3.863856792449951
INFO:root:current mean train loss 1713.0057337175813
INFO:root:current train perplexity3.8629868030548096
INFO:root:current mean train loss 1713.0864396551449
INFO:root:current train perplexity3.8629298210144043
INFO:root:current mean train loss 1713.3804998996127
INFO:root:current train perplexity3.8634750843048096
INFO:root:current mean train loss 1714.3541810497463
INFO:root:current train perplexity3.8665597438812256
INFO:root:current mean train loss 1716.5634949972812
INFO:root:current train perplexity3.870457887649536
INFO:root:current mean train loss 1715.4245999583623
INFO:root:current train perplexity3.8691108226776123
INFO:root:current mean train loss 1715.975260676441
INFO:root:current train perplexity3.8705053329467773
INFO:root:current mean train loss 1716.312062676242
INFO:root:current train perplexity3.8723578453063965
INFO:root:current mean train loss 1717.1073018994978
INFO:root:current train perplexity3.8735430240631104

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.83s/it]
INFO:root:final mean train loss: 1716.9541939616624
INFO:root:final train perplexity: 3.8732476234436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.15s/it]
INFO:root:eval mean loss: 1818.8808944377492
INFO:root:eval perplexity: 4.353603839874268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it]
INFO:root:eval mean loss: 2279.231620193373
INFO:root:eval perplexity: 6.449599742889404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:33:17<2:42:26, 360.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.8418670654296
INFO:root:current train perplexity3.8637030124664307
INFO:root:current mean train loss 1707.2373726981027
INFO:root:current train perplexity3.83345890045166
INFO:root:current mean train loss 1719.0439137776693
INFO:root:current train perplexity3.8524882793426514
INFO:root:current mean train loss 1714.2995092055378
INFO:root:current train perplexity3.8549492359161377
INFO:root:current mean train loss 1715.4902304909447
INFO:root:current train perplexity3.858522415161133
INFO:root:current mean train loss 1716.5466787832754
INFO:root:current train perplexity3.857142448425293
INFO:root:current mean train loss 1716.2022741317749
INFO:root:current train perplexity3.860347270965576
INFO:root:current mean train loss 1715.1924535802893
INFO:root:current train perplexity3.8593904972076416
INFO:root:current mean train loss 1715.6241266159784
INFO:root:current train perplexity3.860269784927368
INFO:root:current mean train loss 1715.4081332592255
INFO:root:current train perplexity3.8596646785736084
INFO:root:current mean train loss 1712.9983162513147
INFO:root:current train perplexity3.8555490970611572
INFO:root:current mean train loss 1712.5882693642063
INFO:root:current train perplexity3.854769229888916
INFO:root:current mean train loss 1713.2236158801663
INFO:root:current train perplexity3.8568785190582275
INFO:root:current mean train loss 1713.4347306436566
INFO:root:current train perplexity3.8583004474639893
INFO:root:current mean train loss 1713.1019225226507
INFO:root:current train perplexity3.8575050830841064
INFO:root:current mean train loss 1712.1931279170049
INFO:root:current train perplexity3.8553082942962646
INFO:root:current mean train loss 1710.7341616002525
INFO:root:current train perplexity3.8530595302581787
INFO:root:current mean train loss 1711.654016464058
INFO:root:current train perplexity3.853337526321411
INFO:root:current mean train loss 1712.2647713702659
INFO:root:current train perplexity3.855116605758667
INFO:root:current mean train loss 1712.238998570393
INFO:root:current train perplexity3.8559465408325195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.11s/it]
INFO:root:final mean train loss: 1711.8562104671937
INFO:root:final train perplexity: 3.857706069946289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it]
INFO:root:eval mean loss: 1809.9842511981938
INFO:root:eval perplexity: 4.322392463684082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it]
INFO:root:eval mean loss: 2273.104000010389
INFO:root:eval perplexity: 6.417361259460449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:39:08<2:35:09, 358.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1656.9710736191064
INFO:root:current train perplexity3.7561147212982178
INFO:root:current mean train loss 1701.2772566679937
INFO:root:current train perplexity3.830634117126465
INFO:root:current mean train loss 1709.7055189080738
INFO:root:current train perplexity3.844507932662964
INFO:root:current mean train loss 1699.8252042027748
INFO:root:current train perplexity3.826916456222534
INFO:root:current mean train loss 1704.4852847844297
INFO:root:current train perplexity3.8325438499450684
INFO:root:current mean train loss 1699.2683936072851
INFO:root:current train perplexity3.8286349773406982
INFO:root:current mean train loss 1702.1946746501023
INFO:root:current train perplexity3.8332149982452393
INFO:root:current mean train loss 1704.397605261053
INFO:root:current train perplexity3.8392629623413086
INFO:root:current mean train loss 1704.8041883933781
INFO:root:current train perplexity3.8430612087249756
INFO:root:current mean train loss 1706.4934362652657
INFO:root:current train perplexity3.8441903591156006
INFO:root:current mean train loss 1706.0016753775055
INFO:root:current train perplexity3.8411920070648193
INFO:root:current mean train loss 1705.9462132037665
INFO:root:current train perplexity3.8421218395233154
INFO:root:current mean train loss 1706.8092454714536
INFO:root:current train perplexity3.8434836864471436
INFO:root:current mean train loss 1706.2372320030397
INFO:root:current train perplexity3.840876579284668
INFO:root:current mean train loss 1706.999858827401
INFO:root:current train perplexity3.842374563217163
INFO:root:current mean train loss 1707.4635534268123
INFO:root:current train perplexity3.8448827266693115
INFO:root:current mean train loss 1706.6824842877754
INFO:root:current train perplexity3.8426544666290283
INFO:root:current mean train loss 1707.2616316263961
INFO:root:current train perplexity3.8431766033172607
INFO:root:current mean train loss 1708.511102087856
INFO:root:current train perplexity3.845705986022949
INFO:root:current mean train loss 1707.5817688955112
INFO:root:current train perplexity3.843369245529175

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.75s/it]
INFO:root:final mean train loss: 1706.9227342014053
INFO:root:final train perplexity: 3.842725992202759
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.30s/it]
INFO:root:eval mean loss: 1812.5206878878546
INFO:root:eval perplexity: 4.331267833709717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.28s/it]
INFO:root:eval mean loss: 2274.842312427277
INFO:root:eval perplexity: 6.4264912605285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [7:45:06<2:29:07, 357.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.0099668760558
INFO:root:current train perplexity3.81579852104187
INFO:root:current mean train loss 1694.8310785403196
INFO:root:current train perplexity3.8091249465942383
INFO:root:current mean train loss 1692.6409769545508
INFO:root:current train perplexity3.813526153564453
INFO:root:current mean train loss 1694.8502451850768
INFO:root:current train perplexity3.817089796066284
INFO:root:current mean train loss 1696.1544519094475
INFO:root:current train perplexity3.8166232109069824
INFO:root:current mean train loss 1700.2538345815412
INFO:root:current train perplexity3.821150779724121
INFO:root:current mean train loss 1700.3466570483472
INFO:root:current train perplexity3.821612596511841
INFO:root:current mean train loss 1701.341312694303
INFO:root:current train perplexity3.8211753368377686
INFO:root:current mean train loss 1700.1811716180098
INFO:root:current train perplexity3.8219821453094482
INFO:root:current mean train loss 1702.1963048539367
INFO:root:current train perplexity3.824127674102783
INFO:root:current mean train loss 1703.6302719826583
INFO:root:current train perplexity3.8255937099456787
INFO:root:current mean train loss 1703.0764368112489
INFO:root:current train perplexity3.827439308166504
INFO:root:current mean train loss 1702.436734233958
INFO:root:current train perplexity3.8283584117889404
INFO:root:current mean train loss 1704.4675182803403
INFO:root:current train perplexity3.8316843509674072
INFO:root:current mean train loss 1704.1384267405867
INFO:root:current train perplexity3.831474781036377
INFO:root:current mean train loss 1703.7959864615182
INFO:root:current train perplexity3.8318169116973877
INFO:root:current mean train loss 1704.414242615694
INFO:root:current train perplexity3.832137107849121
INFO:root:current mean train loss 1704.708299363748
INFO:root:current train perplexity3.832101583480835
INFO:root:current mean train loss 1704.2974453562733
INFO:root:current train perplexity3.831973075866699
INFO:root:current mean train loss 1702.9780101524902
INFO:root:current train perplexity3.82954740524292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.30s/it]
INFO:root:final mean train loss: 1702.6006893248373
INFO:root:final train perplexity: 3.8296496868133545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it]
INFO:root:eval mean loss: 1810.578954818401
INFO:root:eval perplexity: 4.324471473693848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.84s/it]
INFO:root:eval mean loss: 2272.6269102705287
INFO:root:eval perplexity: 6.414856433868408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [7:50:58<2:22:28, 356.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.1332591968578
INFO:root:current train perplexity3.829145669937134
INFO:root:current mean train loss 1695.762887045975
INFO:root:current train perplexity3.8348443508148193
INFO:root:current mean train loss 1691.7168677680681
INFO:root:current train perplexity3.834376811981201
INFO:root:current mean train loss 1688.7495841492168
INFO:root:current train perplexity3.810520648956299
INFO:root:current mean train loss 1687.734393646178
INFO:root:current train perplexity3.8092453479766846
INFO:root:current mean train loss 1686.5999662912436
INFO:root:current train perplexity3.80247163772583
INFO:root:current mean train loss 1690.6529427954843
INFO:root:current train perplexity3.8051705360412598
INFO:root:current mean train loss 1691.422719461125
INFO:root:current train perplexity3.809520959854126
INFO:root:current mean train loss 1693.1489948311237
INFO:root:current train perplexity3.812528371810913
INFO:root:current mean train loss 1693.8747790170125
INFO:root:current train perplexity3.8113210201263428
INFO:root:current mean train loss 1694.1604311599522
INFO:root:current train perplexity3.813018798828125
INFO:root:current mean train loss 1695.9105430622244
INFO:root:current train perplexity3.8151485919952393
INFO:root:current mean train loss 1695.6616321566676
INFO:root:current train perplexity3.814298629760742
INFO:root:current mean train loss 1696.6072922575654
INFO:root:current train perplexity3.8134188652038574
INFO:root:current mean train loss 1696.6888606214109
INFO:root:current train perplexity3.8126587867736816
INFO:root:current mean train loss 1698.1132482580238
INFO:root:current train perplexity3.8171119689941406
INFO:root:current mean train loss 1698.142008704169
INFO:root:current train perplexity3.8179233074188232
INFO:root:current mean train loss 1699.0279033241293
INFO:root:current train perplexity3.817671298980713
INFO:root:current mean train loss 1698.5056221415794
INFO:root:current train perplexity3.8174386024475098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:16<00:00, 316.55s/it]
INFO:root:final mean train loss: 1698.4025042635349
INFO:root:final train perplexity: 3.816990375518799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.95s/it]
INFO:root:eval mean loss: 1807.3667091748393
INFO:root:eval perplexity: 4.3132524490356445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.03s/it]
INFO:root:eval mean loss: 2269.5931959219856
INFO:root:eval perplexity: 6.398961067199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [7:56:56<2:16:43, 356.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.0988006591797
INFO:root:current train perplexity3.6750423908233643
INFO:root:current mean train loss 1692.0542794686776
INFO:root:current train perplexity3.782540798187256
INFO:root:current mean train loss 1692.1246584378755
INFO:root:current train perplexity3.801919937133789
INFO:root:current mean train loss 1685.1437508719307
INFO:root:current train perplexity3.7915802001953125
INFO:root:current mean train loss 1686.9325358072917
INFO:root:current train perplexity3.790773868560791
INFO:root:current mean train loss 1687.5810825618232
INFO:root:current train perplexity3.7920117378234863
INFO:root:current mean train loss 1685.3081536543996
INFO:root:current train perplexity3.7883553504943848
INFO:root:current mean train loss 1683.901332014698
INFO:root:current train perplexity3.7848775386810303
INFO:root:current mean train loss 1689.7875588294303
INFO:root:current train perplexity3.7943997383117676
INFO:root:current mean train loss 1691.080632818953
INFO:root:current train perplexity3.79612398147583
INFO:root:current mean train loss 1692.548303755503
INFO:root:current train perplexity3.8005995750427246
INFO:root:current mean train loss 1693.4212849200417
INFO:root:current train perplexity3.801936388015747
INFO:root:current mean train loss 1693.0123495139824
INFO:root:current train perplexity3.8003313541412354
INFO:root:current mean train loss 1694.5571617569763
INFO:root:current train perplexity3.803199291229248
INFO:root:current mean train loss 1694.1840854991567
INFO:root:current train perplexity3.802936315536499
INFO:root:current mean train loss 1695.0817179793705
INFO:root:current train perplexity3.8052268028259277
INFO:root:current mean train loss 1696.178215140727
INFO:root:current train perplexity3.8060975074768066
INFO:root:current mean train loss 1695.2695640546096
INFO:root:current train perplexity3.8042829036712646
INFO:root:current mean train loss 1694.8445768103136
INFO:root:current train perplexity3.8047192096710205
INFO:root:current mean train loss 1694.2511866027703
INFO:root:current train perplexity3.803766965866089

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.81s/it]
INFO:root:final mean train loss: 1693.9477943808997
INFO:root:final train perplexity: 3.8036046028137207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.31s/it]
INFO:root:eval mean loss: 1802.8722928094526
INFO:root:eval perplexity: 4.29760217666626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.15s/it]
INFO:root:eval mean loss: 2264.950600049174
INFO:root:eval perplexity: 6.374711036682129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:03:08<2:12:31, 361.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.877705078125
INFO:root:current train perplexity3.852881908416748
INFO:root:current mean train loss 1679.85624609375
INFO:root:current train perplexity3.8074941635131836
INFO:root:current mean train loss 1681.9249110243056
INFO:root:current train perplexity3.789198398590088
INFO:root:current mean train loss 1684.646543719952
INFO:root:current train perplexity3.7911033630371094
INFO:root:current mean train loss 1687.704373851103
INFO:root:current train perplexity3.8002331256866455
INFO:root:current mean train loss 1688.5891250465029
INFO:root:current train perplexity3.7972474098205566
INFO:root:current mean train loss 1684.524291015625
INFO:root:current train perplexity3.796025514602661
INFO:root:current mean train loss 1683.6380633755389
INFO:root:current train perplexity3.78942608833313
INFO:root:current mean train loss 1686.0622323330965
INFO:root:current train perplexity3.788581132888794
INFO:root:current mean train loss 1686.4505507020692
INFO:root:current train perplexity3.7894198894500732
INFO:root:current mean train loss 1684.7745277963033
INFO:root:current train perplexity3.7885308265686035
INFO:root:current mean train loss 1686.5277019314235
INFO:root:current train perplexity3.7888760566711426
INFO:root:current mean train loss 1688.8293836694834
INFO:root:current train perplexity3.7922370433807373
INFO:root:current mean train loss 1689.2581779739091
INFO:root:current train perplexity3.7923102378845215
INFO:root:current mean train loss 1690.0717399945177
INFO:root:current train perplexity3.793177843093872
INFO:root:current mean train loss 1689.9622455334272
INFO:root:current train perplexity3.7915267944335938
INFO:root:current mean train loss 1689.933872971755
INFO:root:current train perplexity3.792933225631714
INFO:root:current mean train loss 1689.573587381114
INFO:root:current train perplexity3.7893006801605225
INFO:root:current mean train loss 1691.106425313035
INFO:root:current train perplexity3.792177677154541
INFO:root:current mean train loss 1690.998083337561
INFO:root:current train perplexity3.7927560806274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.83s/it]
INFO:root:final mean train loss: 1690.3288516969435
INFO:root:final train perplexity: 3.792764186859131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it]
INFO:root:eval mean loss: 1802.092975156527
INFO:root:eval perplexity: 4.294894695281982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 2266.414835179106
INFO:root:eval perplexity: 6.382349967956543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:09:03<2:05:46, 359.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.1849743071057
INFO:root:current train perplexity3.7542450428009033
INFO:root:current mean train loss 1704.453437052982
INFO:root:current train perplexity3.8049473762512207
INFO:root:current mean train loss 1697.529778094331
INFO:root:current train perplexity3.7935965061187744
INFO:root:current mean train loss 1691.9643311974598
INFO:root:current train perplexity3.786156177520752
INFO:root:current mean train loss 1688.5841685851774
INFO:root:current train perplexity3.786641836166382
INFO:root:current mean train loss 1685.1512117843347
INFO:root:current train perplexity3.776034355163574
INFO:root:current mean train loss 1688.146688205802
INFO:root:current train perplexity3.781085968017578
INFO:root:current mean train loss 1689.7322591694217
INFO:root:current train perplexity3.7862093448638916
INFO:root:current mean train loss 1687.0033399713295
INFO:root:current train perplexity3.7818334102630615
INFO:root:current mean train loss 1687.2722188702562
INFO:root:current train perplexity3.784951686859131
INFO:root:current mean train loss 1689.6167987962601
INFO:root:current train perplexity3.788140296936035
INFO:root:current mean train loss 1685.7813779493556
INFO:root:current train perplexity3.781299114227295
INFO:root:current mean train loss 1685.9894149706558
INFO:root:current train perplexity3.7823445796966553
INFO:root:current mean train loss 1684.7190542661665
INFO:root:current train perplexity3.7792558670043945
INFO:root:current mean train loss 1685.4675954958932
INFO:root:current train perplexity3.7814581394195557
INFO:root:current mean train loss 1686.6453203530318
INFO:root:current train perplexity3.7825872898101807
INFO:root:current mean train loss 1686.657961586361
INFO:root:current train perplexity3.7813892364501953
INFO:root:current mean train loss 1685.8682234859357
INFO:root:current train perplexity3.7799465656280518
INFO:root:current mean train loss 1687.0611406589305
INFO:root:current train perplexity3.7815001010894775
INFO:root:current mean train loss 1686.5073454647672
INFO:root:current train perplexity3.780684232711792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.59s/it]
INFO:root:final mean train loss: 1686.5867656759704
INFO:root:final train perplexity: 3.7815871238708496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.83s/it]
INFO:root:eval mean loss: 1801.1627102033467
INFO:root:eval perplexity: 4.2916646003723145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.36s/it]
INFO:root:eval mean loss: 2265.165323893229
INFO:root:eval perplexity: 6.375831604003906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:15:12<2:00:45, 362.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.7214976165253
INFO:root:current train perplexity3.7638680934906006
INFO:root:current mean train loss 1672.4115412490173
INFO:root:current train perplexity3.734606981277466
INFO:root:current mean train loss 1668.9400545215974
INFO:root:current train perplexity3.7358248233795166
INFO:root:current mean train loss 1675.137324681189
INFO:root:current train perplexity3.745077610015869
INFO:root:current mean train loss 1676.572934485209
INFO:root:current train perplexity3.752305746078491
INFO:root:current mean train loss 1678.599989125042
INFO:root:current train perplexity3.7504489421844482
INFO:root:current mean train loss 1680.3920187132492
INFO:root:current train perplexity3.754815101623535
INFO:root:current mean train loss 1678.9102080374053
INFO:root:current train perplexity3.7537782192230225
INFO:root:current mean train loss 1677.5059720662198
INFO:root:current train perplexity3.754122734069824
INFO:root:current mean train loss 1679.7375476825225
INFO:root:current train perplexity3.7601189613342285
INFO:root:current mean train loss 1680.4772204578317
INFO:root:current train perplexity3.761767625808716
INFO:root:current mean train loss 1679.783306342348
INFO:root:current train perplexity3.7599782943725586
INFO:root:current mean train loss 1681.5630001101445
INFO:root:current train perplexity3.7630162239074707
INFO:root:current mean train loss 1682.2398530736928
INFO:root:current train perplexity3.7648074626922607
INFO:root:current mean train loss 1682.567627789796
INFO:root:current train perplexity3.7650110721588135
INFO:root:current mean train loss 1682.1120288352158
INFO:root:current train perplexity3.7657463550567627
INFO:root:current mean train loss 1683.6243739021766
INFO:root:current train perplexity3.7683982849121094
INFO:root:current mean train loss 1683.4192522579192
INFO:root:current train perplexity3.7700140476226807
INFO:root:current mean train loss 1682.7473445931323
INFO:root:current train perplexity3.7692883014678955
INFO:root:current mean train loss 1682.8148620823563
INFO:root:current train perplexity3.7700796127319336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.50s/it]
INFO:root:final mean train loss: 1682.851840559305
INFO:root:final train perplexity: 3.7704646587371826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it]
INFO:root:eval mean loss: 1802.0911497291943
INFO:root:eval perplexity: 4.294888019561768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.06s/it]
INFO:root:eval mean loss: 2267.511859866744
INFO:root:eval perplexity: 6.3880791664123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:21:08<1:54:11, 360.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1680.7256774902344
INFO:root:current train perplexity3.7815911769866943
INFO:root:current mean train loss 1683.0271863070402
INFO:root:current train perplexity3.7671844959259033
INFO:root:current mean train loss 1676.355420983356
INFO:root:current train perplexity3.7515735626220703
INFO:root:current mean train loss 1678.6557055534201
INFO:root:current train perplexity3.760127067565918
INFO:root:current mean train loss 1677.826861982586
INFO:root:current train perplexity3.7496864795684814
INFO:root:current mean train loss 1681.3518564436172
INFO:root:current train perplexity3.753746747970581
INFO:root:current mean train loss 1681.845220080494
INFO:root:current train perplexity3.7578423023223877
INFO:root:current mean train loss 1681.5651168036707
INFO:root:current train perplexity3.7568554878234863
INFO:root:current mean train loss 1680.4022085808183
INFO:root:current train perplexity3.7539114952087402
INFO:root:current mean train loss 1680.4335073252194
INFO:root:current train perplexity3.7528979778289795
INFO:root:current mean train loss 1679.9149331018384
INFO:root:current train perplexity3.754392147064209
INFO:root:current mean train loss 1680.0833197353647
INFO:root:current train perplexity3.755640983581543
INFO:root:current mean train loss 1681.404885701625
INFO:root:current train perplexity3.7591891288757324
INFO:root:current mean train loss 1680.5380830986555
INFO:root:current train perplexity3.757542610168457
INFO:root:current mean train loss 1678.442823621962
INFO:root:current train perplexity3.755091428756714
INFO:root:current mean train loss 1678.8069552503866
INFO:root:current train perplexity3.756228446960449
INFO:root:current mean train loss 1677.724469168943
INFO:root:current train perplexity3.754263401031494
INFO:root:current mean train loss 1677.3645085515202
INFO:root:current train perplexity3.754406452178955
INFO:root:current mean train loss 1678.1364874280591
INFO:root:current train perplexity3.7558815479278564
INFO:root:current mean train loss 1678.7206904608229
INFO:root:current train perplexity3.75709867477417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.31s/it]
INFO:root:final mean train loss: 1678.4410331137422
INFO:root:final train perplexity: 3.757370948791504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.13s/it]
INFO:root:eval mean loss: 1798.353065869487
INFO:root:eval perplexity: 4.281923294067383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.72s/it]
INFO:root:eval mean loss: 2263.4281880263743
INFO:root:eval perplexity: 6.366779327392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:27:22<1:49:20, 364.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1675.7109375
INFO:root:current train perplexity3.7490592002868652
INFO:root:current mean train loss 1683.9871206332982
INFO:root:current train perplexity3.7791941165924072
INFO:root:current mean train loss 1680.607454788156
INFO:root:current train perplexity3.7676708698272705
INFO:root:current mean train loss 1681.7899337652075
INFO:root:current train perplexity3.7637574672698975
INFO:root:current mean train loss 1681.9015018857758
INFO:root:current train perplexity3.7624025344848633
INFO:root:current mean train loss 1685.7201147996152
INFO:root:current train perplexity3.770927667617798
INFO:root:current mean train loss 1683.5294983878969
INFO:root:current train perplexity3.772916555404663
INFO:root:current mean train loss 1682.7401395511506
INFO:root:current train perplexity3.771634817123413
INFO:root:current mean train loss 1681.1473220534715
INFO:root:current train perplexity3.7650160789489746
INFO:root:current mean train loss 1682.8403760404865
INFO:root:current train perplexity3.767212390899658
INFO:root:current mean train loss 1682.5561973522915
INFO:root:current train perplexity3.764878273010254
INFO:root:current mean train loss 1681.7476833244382
INFO:root:current train perplexity3.764760732650757
INFO:root:current mean train loss 1679.6578070809467
INFO:root:current train perplexity3.7606756687164307
INFO:root:current mean train loss 1678.5862018834407
INFO:root:current train perplexity3.7580716609954834
INFO:root:current mean train loss 1677.641717255395
INFO:root:current train perplexity3.7545151710510254
INFO:root:current mean train loss 1677.7412584476028
INFO:root:current train perplexity3.7510986328125
INFO:root:current mean train loss 1677.3593530807
INFO:root:current train perplexity3.752619743347168
INFO:root:current mean train loss 1677.073173084674
INFO:root:current train perplexity3.752440929412842
INFO:root:current mean train loss 1677.0738218441504
INFO:root:current train perplexity3.75144624710083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.98s/it]
INFO:root:final mean train loss: 1675.7997573798675
INFO:root:final train perplexity: 3.7495527267456055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.97s/it]
INFO:root:eval mean loss: 1799.644278451906
INFO:root:eval perplexity: 4.286397457122803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.78s/it]
INFO:root:eval mean loss: 2266.246587225731
INFO:root:eval perplexity: 6.381471157073975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:33:14<1:42:11, 360.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1651.2508911132813
INFO:root:current train perplexity3.7154347896575928
INFO:root:current mean train loss 1660.465537331321
INFO:root:current train perplexity3.708871841430664
INFO:root:current mean train loss 1665.8994902111235
INFO:root:current train perplexity3.7158701419830322
INFO:root:current mean train loss 1668.1880205708164
INFO:root:current train perplexity3.719343423843384
INFO:root:current mean train loss 1665.7439834222562
INFO:root:current train perplexity3.717576503753662
INFO:root:current mean train loss 1667.4132623410692
INFO:root:current train perplexity3.7219159603118896
INFO:root:current mean train loss 1665.4997140352843
INFO:root:current train perplexity3.7225921154022217
INFO:root:current mean train loss 1663.8178286270356
INFO:root:current train perplexity3.720700263977051
INFO:root:current mean train loss 1663.0712513864776
INFO:root:current train perplexity3.7196502685546875
INFO:root:current mean train loss 1663.9475504110148
INFO:root:current train perplexity3.7231650352478027
INFO:root:current mean train loss 1667.3697953328049
INFO:root:current train perplexity3.7270724773406982
INFO:root:current mean train loss 1667.4158170133023
INFO:root:current train perplexity3.7274177074432373
INFO:root:current mean train loss 1668.6893887606534
INFO:root:current train perplexity3.729757785797119
INFO:root:current mean train loss 1668.973499746541
INFO:root:current train perplexity3.7324469089508057
INFO:root:current mean train loss 1668.880375595634
INFO:root:current train perplexity3.733084201812744
INFO:root:current mean train loss 1669.5787780357512
INFO:root:current train perplexity3.7334606647491455
INFO:root:current mean train loss 1670.5058395101416
INFO:root:current train perplexity3.7358691692352295
INFO:root:current mean train loss 1669.416566226357
INFO:root:current train perplexity3.734356164932251
INFO:root:current mean train loss 1671.1603225623705
INFO:root:current train perplexity3.7373342514038086
INFO:root:current mean train loss 1672.222033180117
INFO:root:current train perplexity3.7380940914154053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.29s/it]
INFO:root:final mean train loss: 1672.5869783910307
INFO:root:final train perplexity: 3.7400641441345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.23s/it]
INFO:root:eval mean loss: 1796.057272620235
INFO:root:eval perplexity: 4.273980617523193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.15s/it]
INFO:root:eval mean loss: 2262.1037056564437
INFO:root:eval perplexity: 6.3598856925964355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [8:39:30<1:37:24, 365.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1662.6347565827546
INFO:root:current train perplexity3.749892473220825
INFO:root:current mean train loss 1673.2358706016241
INFO:root:current train perplexity3.7428557872772217
INFO:root:current mean train loss 1677.8208448771338
INFO:root:current train perplexity3.7441468238830566
INFO:root:current mean train loss 1669.4093017578125
INFO:root:current train perplexity3.733966827392578
INFO:root:current mean train loss 1668.893102998756
INFO:root:current train perplexity3.7287001609802246
INFO:root:current mean train loss 1668.9144592864238
INFO:root:current train perplexity3.7253146171569824
INFO:root:current mean train loss 1669.8488802628465
INFO:root:current train perplexity3.7269492149353027
INFO:root:current mean train loss 1673.866153512401
INFO:root:current train perplexity3.7360880374908447
INFO:root:current mean train loss 1672.6588117052884
INFO:root:current train perplexity3.732966661453247
INFO:root:current mean train loss 1669.9742007620769
INFO:root:current train perplexity3.726522445678711
INFO:root:current mean train loss 1668.4800874437074
INFO:root:current train perplexity3.722158908843994
INFO:root:current mean train loss 1671.457518989678
INFO:root:current train perplexity3.726804494857788
INFO:root:current mean train loss 1670.567247609929
INFO:root:current train perplexity3.7262020111083984
INFO:root:current mean train loss 1670.4217947849943
INFO:root:current train perplexity3.7265889644622803
INFO:root:current mean train loss 1670.311745165776
INFO:root:current train perplexity3.725513219833374
INFO:root:current mean train loss 1669.4031224578678
INFO:root:current train perplexity3.7253143787384033
INFO:root:current mean train loss 1668.854172868969
INFO:root:current train perplexity3.7246930599212646
INFO:root:current mean train loss 1669.514188005528
INFO:root:current train perplexity3.728224754333496
INFO:root:current mean train loss 1670.0517598837532
INFO:root:current train perplexity3.7305853366851807
INFO:root:current mean train loss 1670.630470865801
INFO:root:current train perplexity3.7319984436035156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.42s/it]
INFO:root:final mean train loss: 1669.888370577398
INFO:root:final train perplexity: 3.732111930847168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.86s/it]
INFO:root:eval mean loss: 1792.1135327494737
INFO:root:eval perplexity: 4.26037073135376
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.23s/it]
INFO:root:eval mean loss: 2257.930021678302
INFO:root:eval perplexity: 6.338214874267578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [8:45:43<1:31:52, 367.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1649.509815562855
INFO:root:current train perplexity3.6792047023773193
INFO:root:current mean train loss 1657.7384728325737
INFO:root:current train perplexity3.709660053253174
INFO:root:current mean train loss 1664.8254079349706
INFO:root:current train perplexity3.729222059249878
INFO:root:current mean train loss 1669.1909005808275
INFO:root:current train perplexity3.7328073978424072
INFO:root:current mean train loss 1669.8550684473537
INFO:root:current train perplexity3.7321813106536865
INFO:root:current mean train loss 1671.0677959217744
INFO:root:current train perplexity3.7343688011169434
INFO:root:current mean train loss 1670.8153889342125
INFO:root:current train perplexity3.73010516166687
INFO:root:current mean train loss 1672.8093967232653
INFO:root:current train perplexity3.731823205947876
INFO:root:current mean train loss 1673.6993140631942
INFO:root:current train perplexity3.732862949371338
INFO:root:current mean train loss 1672.6790823209083
INFO:root:current train perplexity3.729393243789673
INFO:root:current mean train loss 1670.6563618977864
INFO:root:current train perplexity3.7263007164001465
INFO:root:current mean train loss 1668.9639918187281
INFO:root:current train perplexity3.7232747077941895
INFO:root:current mean train loss 1669.8699779449169
INFO:root:current train perplexity3.724210500717163
INFO:root:current mean train loss 1669.5730193001884
INFO:root:current train perplexity3.7233726978302
INFO:root:current mean train loss 1670.8037708736854
INFO:root:current train perplexity3.726518392562866
INFO:root:current mean train loss 1669.9822114143965
INFO:root:current train perplexity3.724841833114624
INFO:root:current mean train loss 1668.8308769281764
INFO:root:current train perplexity3.7233359813690186
INFO:root:current mean train loss 1668.0424610802886
INFO:root:current train perplexity3.723381519317627
INFO:root:current mean train loss 1667.3438081886143
INFO:root:current train perplexity3.723130941390991
INFO:root:current mean train loss 1666.9742419709885
INFO:root:current train perplexity3.7230448722839355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.07s/it]
INFO:root:final mean train loss: 1666.7873143029226
INFO:root:final train perplexity: 3.7229959964752197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.85s/it]
INFO:root:eval mean loss: 1790.3574166805186
INFO:root:eval perplexity: 4.254324913024902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.67s/it]
INFO:root:eval mean loss: 2256.9516398111978
INFO:root:eval perplexity: 6.3331451416015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [8:51:50<1:25:46, 367.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1661.6809822457735
INFO:root:current train perplexity3.702601432800293
INFO:root:current mean train loss 1659.6866295855978
INFO:root:current train perplexity3.7145941257476807
INFO:root:current mean train loss 1662.291329920977
INFO:root:current train perplexity3.7213265895843506
INFO:root:current mean train loss 1663.3674559870585
INFO:root:current train perplexity3.722034215927124
INFO:root:current mean train loss 1660.4560287376287
INFO:root:current train perplexity3.713139772415161
INFO:root:current mean train loss 1658.8412367876838
INFO:root:current train perplexity3.71337628364563
INFO:root:current mean train loss 1660.1406052397526
INFO:root:current train perplexity3.711667060852051
INFO:root:current mean train loss 1662.1006571585497
INFO:root:current train perplexity3.7163100242614746
INFO:root:current mean train loss 1661.584309328724
INFO:root:current train perplexity3.7141284942626953
INFO:root:current mean train loss 1661.0983198247268
INFO:root:current train perplexity3.713853597640991
INFO:root:current mean train loss 1660.860514016111
INFO:root:current train perplexity3.7117905616760254
INFO:root:current mean train loss 1661.9235503388109
INFO:root:current train perplexity3.71220326423645
INFO:root:current mean train loss 1661.9600050802935
INFO:root:current train perplexity3.7126553058624268
INFO:root:current mean train loss 1663.2821032365046
INFO:root:current train perplexity3.7130730152130127
INFO:root:current mean train loss 1664.2615320935467
INFO:root:current train perplexity3.7147841453552246
INFO:root:current mean train loss 1663.4406710129224
INFO:root:current train perplexity3.711249828338623
INFO:root:current mean train loss 1662.6774622338999
INFO:root:current train perplexity3.7104668617248535
INFO:root:current mean train loss 1662.534863447615
INFO:root:current train perplexity3.7101235389709473
INFO:root:current mean train loss 1663.5686971837638
INFO:root:current train perplexity3.7147271633148193
INFO:root:current mean train loss 1665.1981986754406
INFO:root:current train perplexity3.716524600982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.49s/it]
INFO:root:final mean train loss: 1664.464831684553
INFO:root:final train perplexity: 3.7161829471588135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 1796.8543805061502
INFO:root:eval perplexity: 4.276736736297607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.54s/it]
INFO:root:eval mean loss: 2264.329943934231
INFO:root:eval perplexity: 6.371477127075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [8:57:45<1:18:48, 363.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1652.8985986954126
INFO:root:current train perplexity3.6735312938690186
INFO:root:current mean train loss 1672.6286353636324
INFO:root:current train perplexity3.718341112136841
INFO:root:current mean train loss 1662.1993232562388
INFO:root:current train perplexity3.6979596614837646
INFO:root:current mean train loss 1663.3841197503307
INFO:root:current train perplexity3.698685646057129
INFO:root:current mean train loss 1664.4906930324921
INFO:root:current train perplexity3.705690622329712
INFO:root:current mean train loss 1665.3090695707856
INFO:root:current train perplexity3.707561492919922
INFO:root:current mean train loss 1666.1054979172427
INFO:root:current train perplexity3.710329294204712
INFO:root:current mean train loss 1665.6567883332161
INFO:root:current train perplexity3.710170030593872
INFO:root:current mean train loss 1664.4065943828748
INFO:root:current train perplexity3.71274995803833
INFO:root:current mean train loss 1664.9415195831737
INFO:root:current train perplexity3.7152085304260254
INFO:root:current mean train loss 1662.6368165874305
INFO:root:current train perplexity3.712151527404785
INFO:root:current mean train loss 1664.2419725816399
INFO:root:current train perplexity3.7129902839660645
INFO:root:current mean train loss 1663.7850263473201
INFO:root:current train perplexity3.7128207683563232
INFO:root:current mean train loss 1663.5893218949848
INFO:root:current train perplexity3.7113311290740967
INFO:root:current mean train loss 1664.5704401039463
INFO:root:current train perplexity3.712212324142456
INFO:root:current mean train loss 1662.4456403415618
INFO:root:current train perplexity3.707153558731079
INFO:root:current mean train loss 1663.6533424277413
INFO:root:current train perplexity3.7103111743927
INFO:root:current mean train loss 1663.0390951802412
INFO:root:current train perplexity3.7088735103607178
INFO:root:current mean train loss 1662.679798780285
INFO:root:current train perplexity3.7090799808502197
INFO:root:current mean train loss 1661.950463089591
INFO:root:current train perplexity3.707596778869629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.10s/it]
INFO:root:final mean train loss: 1661.5864821071884
INFO:root:final train perplexity: 3.707756757736206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it]
INFO:root:eval mean loss: 1792.0045018838653
INFO:root:eval perplexity: 4.259995460510254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.64s/it]
INFO:root:eval mean loss: 2257.4487270057625
INFO:root:eval perplexity: 6.335720062255859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:03:48<1:12:42, 363.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1660.288021689967
INFO:root:current train perplexity3.7028534412384033
INFO:root:current mean train loss 1653.4247295673076
INFO:root:current train perplexity3.685810089111328
INFO:root:current mean train loss 1656.6428942664195
INFO:root:current train perplexity3.688462734222412
INFO:root:current mean train loss 1651.1757212964794
INFO:root:current train perplexity3.684852361679077
INFO:root:current mean train loss 1658.0709677339805
INFO:root:current train perplexity3.698568105697632
INFO:root:current mean train loss 1659.0303388836003
INFO:root:current train perplexity3.6991870403289795
INFO:root:current mean train loss 1659.5526730763827
INFO:root:current train perplexity3.7024986743927
INFO:root:current mean train loss 1659.5813860431408
INFO:root:current train perplexity3.7008111476898193
INFO:root:current mean train loss 1662.9250537382159
INFO:root:current train perplexity3.70302152633667
INFO:root:current mean train loss 1662.2972639074278
INFO:root:current train perplexity3.707056760787964
INFO:root:current mean train loss 1663.0675070009274
INFO:root:current train perplexity3.706115245819092
INFO:root:current mean train loss 1662.6703419194562
INFO:root:current train perplexity3.708200216293335
INFO:root:current mean train loss 1662.342026687681
INFO:root:current train perplexity3.7065622806549072
INFO:root:current mean train loss 1662.3209861181115
INFO:root:current train perplexity3.704596519470215
INFO:root:current mean train loss 1661.5232102614182
INFO:root:current train perplexity3.703827381134033
INFO:root:current mean train loss 1660.2652826673932
INFO:root:current train perplexity3.7033209800720215
INFO:root:current mean train loss 1659.9842573227784
INFO:root:current train perplexity3.701267719268799
INFO:root:current mean train loss 1658.9000001360114
INFO:root:current train perplexity3.69865083694458
INFO:root:current mean train loss 1658.7249922699539
INFO:root:current train perplexity3.698638677597046

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:18<00:00, 318.21s/it]
INFO:root:final mean train loss: 1658.4098041051575
INFO:root:final train perplexity: 3.698479413986206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.36s/it]
INFO:root:eval mean loss: 1802.1460246633976
INFO:root:eval perplexity: 4.295078277587891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.65s/it]
INFO:root:eval mean loss: 2269.9150710951353
INFO:root:eval perplexity: 6.400646209716797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:09:50<1:06:32, 362.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.2345174153645
INFO:root:current train perplexity3.766263484954834
INFO:root:current mean train loss 1652.9343403407506
INFO:root:current train perplexity3.6656720638275146
INFO:root:current mean train loss 1653.6177529389004
INFO:root:current train perplexity3.667827844619751
INFO:root:current mean train loss 1651.9727419339692
INFO:root:current train perplexity3.6742799282073975
INFO:root:current mean train loss 1653.5893812457334
INFO:root:current train perplexity3.6822216510772705
INFO:root:current mean train loss 1658.2450904846191
INFO:root:current train perplexity3.696296215057373
INFO:root:current mean train loss 1662.0223520316329
INFO:root:current train perplexity3.7020103931427
INFO:root:current mean train loss 1660.3522136559648
INFO:root:current train perplexity3.700961112976074
INFO:root:current mean train loss 1659.5550722018838
INFO:root:current train perplexity3.704686164855957
INFO:root:current mean train loss 1660.4240003886976
INFO:root:current train perplexity3.7074813842773438
INFO:root:current mean train loss 1661.3635019897943
INFO:root:current train perplexity3.7075629234313965
INFO:root:current mean train loss 1660.846711083282
INFO:root:current train perplexity3.703582763671875
INFO:root:current mean train loss 1660.6588236490886
INFO:root:current train perplexity3.701706886291504
INFO:root:current mean train loss 1660.335847249845
INFO:root:current train perplexity3.7010254859924316
INFO:root:current mean train loss 1659.6104119060396
INFO:root:current train perplexity3.6989128589630127
INFO:root:current mean train loss 1659.314983226635
INFO:root:current train perplexity3.6983864307403564
INFO:root:current mean train loss 1658.6924168134742
INFO:root:current train perplexity3.698451280593872
INFO:root:current mean train loss 1658.5587757859275
INFO:root:current train perplexity3.6983439922332764
INFO:root:current mean train loss 1657.9670901266945
INFO:root:current train perplexity3.695706844329834
INFO:root:current mean train loss 1657.3824900862562
INFO:root:current train perplexity3.694633722305298

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.34s/it]
INFO:root:final mean train loss: 1656.8885933572574
INFO:root:final train perplexity: 3.694044828414917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.83s/it]
INFO:root:eval mean loss: 1787.9986879605774
INFO:root:eval perplexity: 4.246216297149658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.35s/it]
INFO:root:eval mean loss: 2255.9120444439827
INFO:root:eval perplexity: 6.327763557434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:16:04<1:01:02, 366.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1603.044778758082
INFO:root:current train perplexity3.6118030548095703
INFO:root:current mean train loss 1653.5701327065165
INFO:root:current train perplexity3.694871187210083
INFO:root:current mean train loss 1651.953185235569
INFO:root:current train perplexity3.6967813968658447
INFO:root:current mean train loss 1650.6846560214428
INFO:root:current train perplexity3.6937222480773926
INFO:root:current mean train loss 1654.4939112807765
INFO:root:current train perplexity3.691340208053589
INFO:root:current mean train loss 1655.3902350211188
INFO:root:current train perplexity3.684784173965454
INFO:root:current mean train loss 1655.6783489961124
INFO:root:current train perplexity3.6851601600646973
INFO:root:current mean train loss 1655.1703259294088
INFO:root:current train perplexity3.6856937408447266
INFO:root:current mean train loss 1654.409291008557
INFO:root:current train perplexity3.6833314895629883
INFO:root:current mean train loss 1654.9504179035757
INFO:root:current train perplexity3.6836295127868652
INFO:root:current mean train loss 1655.187428228825
INFO:root:current train perplexity3.685635566711426
INFO:root:current mean train loss 1654.3905783991986
INFO:root:current train perplexity3.685481071472168
INFO:root:current mean train loss 1656.107848177507
INFO:root:current train perplexity3.6904382705688477
INFO:root:current mean train loss 1655.2306794567696
INFO:root:current train perplexity3.689319372177124
INFO:root:current mean train loss 1656.6509927758977
INFO:root:current train perplexity3.693114995956421
INFO:root:current mean train loss 1657.0657194947166
INFO:root:current train perplexity3.69287109375
INFO:root:current mean train loss 1657.6386595106037
INFO:root:current train perplexity3.6927108764648438
INFO:root:current mean train loss 1656.7514882129076
INFO:root:current train perplexity3.6901466846466064
INFO:root:current mean train loss 1655.53553968026
INFO:root:current train perplexity3.6883342266082764
INFO:root:current mean train loss 1655.2152367923593
INFO:root:current train perplexity3.6878018379211426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.75s/it]
INFO:root:final mean train loss: 1654.751252190248
INFO:root:final train perplexity: 3.68782377243042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.77s/it]
INFO:root:eval mean loss: 1786.866868905142
INFO:root:eval perplexity: 4.2423319816589355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.62s/it]
INFO:root:eval mean loss: 2254.8622029622397
INFO:root:eval perplexity: 6.322332382202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:22:02<54:34, 363.85s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1618.209942361583
INFO:root:current train perplexity3.5922467708587646
INFO:root:current mean train loss 1632.453099080961
INFO:root:current train perplexity3.6416220664978027
INFO:root:current mean train loss 1639.032274695916
INFO:root:current train perplexity3.6503560543060303
INFO:root:current mean train loss 1639.7778958888412
INFO:root:current train perplexity3.657456398010254
INFO:root:current mean train loss 1642.952017335079
INFO:root:current train perplexity3.659411668777466
INFO:root:current mean train loss 1646.0335543566134
INFO:root:current train perplexity3.6712303161621094
INFO:root:current mean train loss 1647.4995867371929
INFO:root:current train perplexity3.671614646911621
INFO:root:current mean train loss 1650.5271115545931
INFO:root:current train perplexity3.6769299507141113
INFO:root:current mean train loss 1648.574097112561
INFO:root:current train perplexity3.674483060836792
INFO:root:current mean train loss 1648.6205414657109
INFO:root:current train perplexity3.6753671169281006
INFO:root:current mean train loss 1651.8755326280175
INFO:root:current train perplexity3.679537534713745
INFO:root:current mean train loss 1650.3220475814314
INFO:root:current train perplexity3.6771228313446045
INFO:root:current mean train loss 1651.9123156013304
INFO:root:current train perplexity3.6800029277801514
INFO:root:current mean train loss 1652.796448116671
INFO:root:current train perplexity3.681420087814331
INFO:root:current mean train loss 1654.0112180591125
INFO:root:current train perplexity3.6831438541412354
INFO:root:current mean train loss 1653.363697047067
INFO:root:current train perplexity3.6819326877593994
INFO:root:current mean train loss 1654.0263599196442
INFO:root:current train perplexity3.683997631072998
INFO:root:current mean train loss 1653.2202205068058
INFO:root:current train perplexity3.682668924331665
INFO:root:current mean train loss 1652.5065141638593
INFO:root:current train perplexity3.6811251640319824
INFO:root:current mean train loss 1652.7720232156908
INFO:root:current train perplexity3.6814780235290527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.55s/it]
INFO:root:final mean train loss: 1652.59659452145
INFO:root:final train perplexity: 3.6815619468688965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it]
INFO:root:eval mean loss: 1785.8554626897717
INFO:root:eval perplexity: 4.238862991333008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.50s/it]
INFO:root:eval mean loss: 2253.6554058967754
INFO:root:eval perplexity: 6.31609582901001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:27:54<48:02, 360.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1630.3766372922867
INFO:root:current train perplexity3.648590564727783
INFO:root:current mean train loss 1640.227245494632
INFO:root:current train perplexity3.6762309074401855
INFO:root:current mean train loss 1647.5845181425261
INFO:root:current train perplexity3.683245897293091
INFO:root:current mean train loss 1647.6751682081826
INFO:root:current train perplexity3.6795830726623535
INFO:root:current mean train loss 1647.2647581162257
INFO:root:current train perplexity3.674670457839966
INFO:root:current mean train loss 1644.8598773746253
INFO:root:current train perplexity3.6690948009490967
INFO:root:current mean train loss 1647.792821087269
INFO:root:current train perplexity3.6762173175811768
INFO:root:current mean train loss 1649.2860569785182
INFO:root:current train perplexity3.677004814147949
INFO:root:current mean train loss 1650.5475859216576
INFO:root:current train perplexity3.678164005279541
INFO:root:current mean train loss 1650.335085416261
INFO:root:current train perplexity3.6753389835357666
INFO:root:current mean train loss 1652.4171140281412
INFO:root:current train perplexity3.6776838302612305
INFO:root:current mean train loss 1652.9575087202077
INFO:root:current train perplexity3.678877353668213
INFO:root:current mean train loss 1653.4120044119284
INFO:root:current train perplexity3.6802608966827393
INFO:root:current mean train loss 1653.2009796791888
INFO:root:current train perplexity3.6786441802978516
INFO:root:current mean train loss 1652.1253495232666
INFO:root:current train perplexity3.6776938438415527
INFO:root:current mean train loss 1652.0968991485224
INFO:root:current train perplexity3.676790952682495
INFO:root:current mean train loss 1651.5336031750319
INFO:root:current train perplexity3.677612781524658
INFO:root:current mean train loss 1651.0491906662116
INFO:root:current train perplexity3.676103353500366
INFO:root:current mean train loss 1651.7453809851802
INFO:root:current train perplexity3.6775686740875244
INFO:root:current mean train loss 1651.306938431789
INFO:root:current train perplexity3.6760683059692383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.81s/it]
INFO:root:final mean train loss: 1650.7708273006099
INFO:root:final train perplexity: 3.676264524459839
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it]
INFO:root:eval mean loss: 1785.1084157524378
INFO:root:eval perplexity: 4.236302852630615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.59s/it]
INFO:root:eval mean loss: 2253.8930447625776
INFO:root:eval perplexity: 6.317323207855225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:34:00<42:14, 362.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.3347183227538
INFO:root:current train perplexity3.6360297203063965
INFO:root:current mean train loss 1656.084996202257
INFO:root:current train perplexity3.6768484115600586
INFO:root:current mean train loss 1653.8732700892858
INFO:root:current train perplexity3.674217700958252
INFO:root:current mean train loss 1652.45888671875
INFO:root:current train perplexity3.6680474281311035
INFO:root:current mean train loss 1649.1896827697753
INFO:root:current train perplexity3.6674067974090576
INFO:root:current mean train loss 1648.819381608634
INFO:root:current train perplexity3.6677286624908447
INFO:root:current mean train loss 1649.186907599954
INFO:root:current train perplexity3.6672940254211426
INFO:root:current mean train loss 1648.5469646747297
INFO:root:current train perplexity3.6647090911865234
INFO:root:current mean train loss 1647.5806974931197
INFO:root:current train perplexity3.665637254714966
INFO:root:current mean train loss 1649.703811583227
INFO:root:current train perplexity3.6700327396392822
INFO:root:current mean train loss 1648.6499768292463
INFO:root:current train perplexity3.668004035949707
INFO:root:current mean train loss 1648.887962729244
INFO:root:current train perplexity3.667917251586914
INFO:root:current mean train loss 1648.0724782943726
INFO:root:current train perplexity3.666848659515381
INFO:root:current mean train loss 1648.3817644644475
INFO:root:current train perplexity3.6660168170928955
INFO:root:current mean train loss 1647.9988243309226
INFO:root:current train perplexity3.6668434143066406
INFO:root:current mean train loss 1649.9536675948132
INFO:root:current train perplexity3.671604633331299
INFO:root:current mean train loss 1650.0928392682756
INFO:root:current train perplexity3.672074794769287
INFO:root:current mean train loss 1649.8276556465064
INFO:root:current train perplexity3.671417713165283
INFO:root:current mean train loss 1649.5256593095496
INFO:root:current train perplexity3.670872926712036
INFO:root:current mean train loss 1649.337528483073
INFO:root:current train perplexity3.6708567142486572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.27s/it]
INFO:root:final mean train loss: 1648.937262907812
INFO:root:final train perplexity: 3.670952081680298
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.39s/it]
INFO:root:eval mean loss: 1784.1487266594636
INFO:root:eval perplexity: 4.233015537261963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.59s/it]
INFO:root:eval mean loss: 2253.31566690215
INFO:root:eval perplexity: 6.314341068267822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [9:39:56<36:00, 360.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1640.504149132168
INFO:root:current train perplexity3.6641173362731934
INFO:root:current mean train loss 1646.194418350452
INFO:root:current train perplexity3.6722593307495117
INFO:root:current mean train loss 1642.3218969479956
INFO:root:current train perplexity3.6642889976501465
INFO:root:current mean train loss 1638.2347694992718
INFO:root:current train perplexity3.6489956378936768
INFO:root:current mean train loss 1637.7738260618398
INFO:root:current train perplexity3.65360164642334
INFO:root:current mean train loss 1639.7208202879633
INFO:root:current train perplexity3.659468650817871
INFO:root:current mean train loss 1640.205118231315
INFO:root:current train perplexity3.6589748859405518
INFO:root:current mean train loss 1644.7617323814402
INFO:root:current train perplexity3.66650652885437
INFO:root:current mean train loss 1647.0880445397418
INFO:root:current train perplexity3.669715166091919
INFO:root:current mean train loss 1645.739232345474
INFO:root:current train perplexity3.6657652854919434
INFO:root:current mean train loss 1646.6561646509301
INFO:root:current train perplexity3.666116237640381
INFO:root:current mean train loss 1647.6534259639986
INFO:root:current train perplexity3.66717791557312
INFO:root:current mean train loss 1647.4642744336388
INFO:root:current train perplexity3.666508674621582
INFO:root:current mean train loss 1647.225814699188
INFO:root:current train perplexity3.663719415664673
INFO:root:current mean train loss 1646.8449622226224
INFO:root:current train perplexity3.6616203784942627
INFO:root:current mean train loss 1647.4784352894344
INFO:root:current train perplexity3.6626393795013428
INFO:root:current mean train loss 1646.1256309244025
INFO:root:current train perplexity3.6617801189422607
INFO:root:current mean train loss 1647.1487213117782
INFO:root:current train perplexity3.664783477783203
INFO:root:current mean train loss 1647.640615090233
INFO:root:current train perplexity3.665668249130249

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.94s/it]
INFO:root:final mean train loss: 1646.721315846561
INFO:root:final train perplexity: 3.6645426750183105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it]
INFO:root:eval mean loss: 1783.415085379959
INFO:root:eval perplexity: 4.230504989624023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it]
INFO:root:eval mean loss: 2251.4548621211493
INFO:root:eval perplexity: 6.3047404289245605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [9:45:47<29:47, 357.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.6697910853795
INFO:root:current train perplexity3.8037896156311035
INFO:root:current mean train loss 1644.9757326360334
INFO:root:current train perplexity3.6852810382843018
INFO:root:current mean train loss 1651.4908932124342
INFO:root:current train perplexity3.669433832168579
INFO:root:current mean train loss 1651.2642180813345
INFO:root:current train perplexity3.6764166355133057
INFO:root:current mean train loss 1650.8887273078956
INFO:root:current train perplexity3.66823148727417
INFO:root:current mean train loss 1648.7105394652845
INFO:root:current train perplexity3.6624186038970947
INFO:root:current mean train loss 1647.689346561991
INFO:root:current train perplexity3.6649537086486816
INFO:root:current mean train loss 1646.571006112406
INFO:root:current train perplexity3.6611573696136475
INFO:root:current mean train loss 1647.3775487801367
INFO:root:current train perplexity3.6624538898468018
INFO:root:current mean train loss 1646.3285366200253
INFO:root:current train perplexity3.6597042083740234
INFO:root:current mean train loss 1645.3151028424325
INFO:root:current train perplexity3.659191846847534
INFO:root:current mean train loss 1646.1232821397764
INFO:root:current train perplexity3.658294200897217
INFO:root:current mean train loss 1644.9581654782744
INFO:root:current train perplexity3.6567654609680176
INFO:root:current mean train loss 1645.474920589267
INFO:root:current train perplexity3.658721923828125
INFO:root:current mean train loss 1647.2820469965523
INFO:root:current train perplexity3.660651683807373
INFO:root:current mean train loss 1647.396596124969
INFO:root:current train perplexity3.6629669666290283
INFO:root:current mean train loss 1647.0772586335627
INFO:root:current train perplexity3.663127899169922
INFO:root:current mean train loss 1645.855549228094
INFO:root:current train perplexity3.661177396774292
INFO:root:current mean train loss 1645.8992395705925
INFO:root:current train perplexity3.6610565185546875
INFO:root:current mean train loss 1646.4590987920014
INFO:root:current train perplexity3.662559986114502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.27s/it]
INFO:root:final mean train loss: 1646.0263073219535
INFO:root:final train perplexity: 3.662534713745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it]
INFO:root:eval mean loss: 1784.1833374889184
INFO:root:eval perplexity: 4.233134746551514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it]
INFO:root:eval mean loss: 2252.383408133865
INFO:root:eval perplexity: 6.3095293045043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [9:51:58<24:05, 361.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1645.598365045363
INFO:root:current train perplexity3.612593650817871
INFO:root:current mean train loss 1644.6417506560115
INFO:root:current train perplexity3.6421329975128174
INFO:root:current mean train loss 1646.3526479217396
INFO:root:current train perplexity3.648498058319092
INFO:root:current mean train loss 1646.8099675020062
INFO:root:current train perplexity3.653684377670288
INFO:root:current mean train loss 1644.8688851553436
INFO:root:current train perplexity3.6413888931274414
INFO:root:current mean train loss 1642.0637119673963
INFO:root:current train perplexity3.64273738861084
INFO:root:current mean train loss 1645.2964172846919
INFO:root:current train perplexity3.651491641998291
INFO:root:current mean train loss 1647.3000229445431
INFO:root:current train perplexity3.6529953479766846
INFO:root:current mean train loss 1646.5097375679245
INFO:root:current train perplexity3.6515707969665527
INFO:root:current mean train loss 1645.9543997234996
INFO:root:current train perplexity3.6547794342041016
INFO:root:current mean train loss 1647.1870975586885
INFO:root:current train perplexity3.657623529434204
INFO:root:current mean train loss 1647.094358085005
INFO:root:current train perplexity3.659658908843994
INFO:root:current mean train loss 1646.0165952160337
INFO:root:current train perplexity3.6593997478485107
INFO:root:current mean train loss 1644.8382458303497
INFO:root:current train perplexity3.658191680908203
INFO:root:current mean train loss 1644.36484171976
INFO:root:current train perplexity3.6563870906829834
INFO:root:current mean train loss 1643.8307421364714
INFO:root:current train perplexity3.655402183532715
INFO:root:current mean train loss 1644.6839764265835
INFO:root:current train perplexity3.6565048694610596
INFO:root:current mean train loss 1645.7959017519452
INFO:root:current train perplexity3.6584205627441406
INFO:root:current mean train loss 1645.2299973359204
INFO:root:current train perplexity3.6580848693847656
INFO:root:current mean train loss 1645.0539730315008
INFO:root:current train perplexity3.6590609550476074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.15s/it]
INFO:root:final mean train loss: 1644.766089919836
INFO:root:final train perplexity: 3.658895969390869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.30s/it]
INFO:root:eval mean loss: 1782.057233228751
INFO:root:eval perplexity: 4.2258620262146
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.23s/it]
INFO:root:eval mean loss: 2250.5060238669103
INFO:root:eval perplexity: 6.299848556518555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [9:57:54<17:59, 359.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1668.2426096598308
INFO:root:current train perplexity3.6885247230529785
INFO:root:current mean train loss 1660.2927823453335
INFO:root:current train perplexity3.6720991134643555
INFO:root:current mean train loss 1658.4756661691974
INFO:root:current train perplexity3.6841650009155273
INFO:root:current mean train loss 1652.488915805159
INFO:root:current train perplexity3.6824533939361572
INFO:root:current mean train loss 1648.8340034484863
INFO:root:current train perplexity3.6748948097229004
INFO:root:current mean train loss 1648.7363256746835
INFO:root:current train perplexity3.669205904006958
INFO:root:current mean train loss 1644.4491356743706
INFO:root:current train perplexity3.66247296333313
INFO:root:current mean train loss 1645.6074063714175
INFO:root:current train perplexity3.6660218238830566
INFO:root:current mean train loss 1647.3365597994823
INFO:root:current train perplexity3.6657555103302
INFO:root:current mean train loss 1645.8547521663618
INFO:root:current train perplexity3.659871816635132
INFO:root:current mean train loss 1644.332107427466
INFO:root:current train perplexity3.656498670578003
INFO:root:current mean train loss 1645.0115833880593
INFO:root:current train perplexity3.658428430557251
INFO:root:current mean train loss 1645.4815431252505
INFO:root:current train perplexity3.6581437587738037
INFO:root:current mean train loss 1645.4630802505449
INFO:root:current train perplexity3.65639328956604
INFO:root:current mean train loss 1643.885436084389
INFO:root:current train perplexity3.6552464962005615
INFO:root:current mean train loss 1642.7153232781461
INFO:root:current train perplexity3.654115676879883
INFO:root:current mean train loss 1642.4415058024879
INFO:root:current train perplexity3.654170036315918
INFO:root:current mean train loss 1643.1126698509233
INFO:root:current train perplexity3.654047727584839
INFO:root:current mean train loss 1643.7461759228727
INFO:root:current train perplexity3.654958963394165
INFO:root:current mean train loss 1643.9538692027882
INFO:root:current train perplexity3.6540637016296387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.35s/it]
INFO:root:final mean train loss: 1643.111395100542
INFO:root:final train perplexity: 3.6541242599487305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.13s/it]
INFO:root:eval mean loss: 1780.7366242104388
INFO:root:eval perplexity: 4.22135066986084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 2249.49938748407
INFO:root:eval perplexity: 6.29466438293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:03:50<11:57, 358.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.6722036508413
INFO:root:current train perplexity3.578744888305664
INFO:root:current mean train loss 1633.2662227746212
INFO:root:current train perplexity3.6166625022888184
INFO:root:current mean train loss 1637.0512216244103
INFO:root:current train perplexity3.628882646560669
INFO:root:current mean train loss 1637.9055466743364
INFO:root:current train perplexity3.6279046535491943
INFO:root:current mean train loss 1640.4175791750672
INFO:root:current train perplexity3.638355016708374
INFO:root:current mean train loss 1638.586571617464
INFO:root:current train perplexity3.6437828540802
INFO:root:current mean train loss 1639.3558988413417
INFO:root:current train perplexity3.647935152053833
INFO:root:current mean train loss 1638.9859338299123
INFO:root:current train perplexity3.6467981338500977
INFO:root:current mean train loss 1640.7418856405798
INFO:root:current train perplexity3.6509556770324707
INFO:root:current mean train loss 1641.3520515402363
INFO:root:current train perplexity3.652189016342163
INFO:root:current mean train loss 1641.9530678046142
INFO:root:current train perplexity3.6512582302093506
INFO:root:current mean train loss 1641.9697723519648
INFO:root:current train perplexity3.6517348289489746
INFO:root:current mean train loss 1641.4156487385746
INFO:root:current train perplexity3.650567054748535
INFO:root:current mean train loss 1640.14187664549
INFO:root:current train perplexity3.6491353511810303
INFO:root:current mean train loss 1641.3503807927154
INFO:root:current train perplexity3.650150775909424
INFO:root:current mean train loss 1641.4903470852885
INFO:root:current train perplexity3.6519651412963867
INFO:root:current mean train loss 1642.897682643581
INFO:root:current train perplexity3.6537859439849854
INFO:root:current mean train loss 1642.9791061963306
INFO:root:current train perplexity3.6543526649475098
INFO:root:current mean train loss 1642.5498075019898
INFO:root:current train perplexity3.652486801147461
INFO:root:current mean train loss 1642.6296491705432
INFO:root:current train perplexity3.6516213417053223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.55s/it]
INFO:root:final mean train loss: 1642.2815636708408
INFO:root:final train perplexity: 3.651733636856079
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.09s/it]
INFO:root:eval mean loss: 1780.8126445797318
INFO:root:eval perplexity: 4.221611022949219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.12s/it]
INFO:root:eval mean loss: 2249.691976777205
INFO:root:eval perplexity: 6.295657157897949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:10:08<06:04, 364.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.705536633003
INFO:root:current train perplexity3.6562843322753906
INFO:root:current mean train loss 1636.297123835637
INFO:root:current train perplexity3.6562085151672363
INFO:root:current mean train loss 1645.7092778631982
INFO:root:current train perplexity3.663327217102051
INFO:root:current mean train loss 1647.1527713156495
INFO:root:current train perplexity3.6581876277923584
INFO:root:current mean train loss 1644.3070638189672
INFO:root:current train perplexity3.655106782913208
INFO:root:current mean train loss 1642.4078075500697
INFO:root:current train perplexity3.6515872478485107
INFO:root:current mean train loss 1639.5229613899835
INFO:root:current train perplexity3.647636890411377
INFO:root:current mean train loss 1638.6556908492846
INFO:root:current train perplexity3.645974636077881
INFO:root:current mean train loss 1641.7147385646967
INFO:root:current train perplexity3.651566505432129
INFO:root:current mean train loss 1642.2060055858976
INFO:root:current train perplexity3.6482601165771484
INFO:root:current mean train loss 1641.7462267637693
INFO:root:current train perplexity3.6481475830078125
INFO:root:current mean train loss 1641.5112230329948
INFO:root:current train perplexity3.6451640129089355
INFO:root:current mean train loss 1642.3346947061477
INFO:root:current train perplexity3.646559238433838
INFO:root:current mean train loss 1642.9078648259429
INFO:root:current train perplexity3.6483957767486572
INFO:root:current mean train loss 1643.3074783963552
INFO:root:current train perplexity3.650489568710327
INFO:root:current mean train loss 1643.1115627746967
INFO:root:current train perplexity3.651341438293457
INFO:root:current mean train loss 1644.4597114263618
INFO:root:current train perplexity3.6543378829956055
INFO:root:current mean train loss 1643.5892405911327
INFO:root:current train perplexity3.6519899368286133
INFO:root:current mean train loss 1642.4883123837674
INFO:root:current train perplexity3.651278257369995
INFO:root:current mean train loss 1643.067347829686
INFO:root:current train perplexity3.6525230407714844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:17<00:00, 317.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:17<00:00, 317.34s/it]
INFO:root:final mean train loss: 1642.5276913702999
INFO:root:final train perplexity: 3.652442455291748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.99s/it]
INFO:root:eval mean loss: 1779.2534915572362
INFO:root:eval perplexity: 4.216290473937988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.54s/it]
INFO:root:eval mean loss: 2247.931093472961
INFO:root:eval perplexity: 6.286596298217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_minil12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:16:14<00:00, 364.76s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:16:14<00:00, 369.74s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 1779.2534915572362
INFO:root:eval perplexity: 4.216290473937988
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 2247.931093472961
INFO:root:eval perplexity: 6.286596298217773
INFO:root:evalaution complete
INFO:root:save model final: alll12_minil12_not_concat_100e/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x154b7becaf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x154b7bec28e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x154b7bde7e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154b7becba3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x154b7bde5948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154b7becba3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x154b7bda0b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x154b7b80546a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x154c78021a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x154c78021be0]
python(+0x24a989) [0x55858e69f989]
python(+0x24a9bd) [0x55858e69f9bd]
python(+0x24aa14) [0x55858e69fa14]
python(+0x108f75) [0x55858e55df75]
python(Py_RunMain+0x313) [0x55858e6a2983]
python(Py_BytesMain+0x39) [0x55858e6a2bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x154c77fff0b3]
python(+0x1d6e13) [0x55858e62be13]
/opt/slurm/data/slurmd/job29854657/slurm_script: line 241: 2774322 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path microsoft/MiniLM-L12-H384-uncased --data_config data_config.json --data_folder fast_processed_data_allminil12_final --output alll12_minil12_not_concat_100e --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self
"
