INFO:root:Output: alll12_fair_baseline
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
Some weights of BertLMHeadModelBaseline were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.11.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23399.217250631315
INFO:root:current train perplexity10238.9609375
INFO:root:current mean train loss 19242.73355056533
INFO:root:current train perplexity1970.198974609375
INFO:root:current mean train loss 16920.51464190531
INFO:root:current train perplexity789.3796997070312
INFO:root:current mean train loss 15383.910643307487
INFO:root:current train perplexity429.7855224609375
INFO:root:current mean train loss 14265.065826966433
INFO:root:current train perplexity276.6948547363281
INFO:root:current mean train loss 13399.49233096828
INFO:root:current train perplexity198.02645874023438
INFO:root:current mean train loss 12732.998637143464
INFO:root:current train perplexity151.5165252685547
INFO:root:current mean train loss 12187.126686678661
INFO:root:current train perplexity122.0374526977539
INFO:root:current mean train loss 11728.371584746941
INFO:root:current train perplexity101.82894134521484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.74s/it]
INFO:root:final mean train loss: 11353.038740219608
INFO:root:final train perplexity: 88.15552520751953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 7174.739590259309
INFO:root:eval perplexity: 18.196949005126953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 7654.115310560727
INFO:root:eval perplexity: 22.871070861816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/1
  0%|          | 1/200 [03:54<12:57:32, 234.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7584.323172433035
INFO:root:current train perplexity20.211332321166992
INFO:root:current mean train loss 7606.598984192465
INFO:root:current train perplexity20.130266189575195
INFO:root:current mean train loss 7490.598484205163
INFO:root:current train perplexity19.25419807434082
INFO:root:current mean train loss 7392.024658998372
INFO:root:current train perplexity18.49098014831543
INFO:root:current mean train loss 7297.313974441416
INFO:root:current train perplexity17.858957290649414
INFO:root:current mean train loss 7236.02817777675
INFO:root:current train perplexity17.32852554321289
INFO:root:current mean train loss 7174.4391667524715
INFO:root:current train perplexity16.882164001464844
INFO:root:current mean train loss 7109.8190127187945
INFO:root:current train perplexity16.467256546020508
INFO:root:current mean train loss 7043.3796347390025
INFO:root:current train perplexity16.079933166503906
INFO:root:current mean train loss 6988.53931336997
INFO:root:current train perplexity15.699718475341797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.43s/it]
INFO:root:final mean train loss: 6935.545223236084
INFO:root:final train perplexity: 15.429373741149902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 5996.52596548094
INFO:root:eval perplexity: 11.300186157226562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 6610.321545323582
INFO:root:eval perplexity: 14.925204277038574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/2
  1%|          | 2/200 [07:47<12:51:00, 233.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6348.85498046875
INFO:root:current train perplexity12.420150756835938
INFO:root:current mean train loss 6376.236018172554
INFO:root:current train perplexity12.237422943115234
INFO:root:current mean train loss 6343.361200944767
INFO:root:current train perplexity12.073236465454102
INFO:root:current mean train loss 6298.406626674107
INFO:root:current train perplexity11.924783706665039
INFO:root:current mean train loss 6272.79671498494
INFO:root:current train perplexity11.811938285827637
INFO:root:current mean train loss 6234.430128375303
INFO:root:current train perplexity11.662315368652344
INFO:root:current mean train loss 6204.042285950203
INFO:root:current train perplexity11.54831314086914
INFO:root:current mean train loss 6179.013727190778
INFO:root:current train perplexity11.423065185546875
INFO:root:current mean train loss 6153.032932323619
INFO:root:current train perplexity11.309476852416992
INFO:root:current mean train loss 6124.368331092042
INFO:root:current train perplexity11.184078216552734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.38s/it]
INFO:root:final mean train loss: 6104.0868882210025
INFO:root:final train perplexity: 11.114370346069336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 5510.451469691932
INFO:root:eval perplexity: 9.283744812011719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 6195.974869099069
INFO:root:eval perplexity: 12.599021911621094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/3
  2%|â–         | 3/200 [11:40<12:46:01, 233.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5856.728876528533
INFO:root:current train perplexity9.873032569885254
INFO:root:current mean train loss 5838.096453410823
INFO:root:current train perplexity9.911090850830078
INFO:root:current mean train loss 5835.030422330437
INFO:root:current train perplexity9.900899887084961
INFO:root:current mean train loss 5807.594248863196
INFO:root:current train perplexity9.81050968170166
INFO:root:current mean train loss 5790.792848699763
INFO:root:current train perplexity9.753421783447266
INFO:root:current mean train loss 5778.501026977772
INFO:root:current train perplexity9.702165603637695
INFO:root:current mean train loss 5757.727954454253
INFO:root:current train perplexity9.658482551574707
INFO:root:current mean train loss 5743.594029596732
INFO:root:current train perplexity9.597038269042969
INFO:root:current mean train loss 5725.649907683399
INFO:root:current train perplexity9.539956092834473
INFO:root:current mean train loss 5710.451935773293
INFO:root:current train perplexity9.490253448486328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.07s/it]
INFO:root:final mean train loss: 5694.549886641964
INFO:root:final train perplexity: 9.45614242553711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 5236.213558981604
INFO:root:eval perplexity: 8.309266090393066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5957.982044409353
INFO:root:eval perplexity: 11.43067741394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/4
  2%|â–         | 4/200 [15:33<12:41:24, 233.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5563.456322454637
INFO:root:current train perplexity8.94519329071045
INFO:root:current mean train loss 5508.640285812261
INFO:root:current train perplexity8.87803840637207
INFO:root:current mean train loss 5510.5309667546
INFO:root:current train perplexity8.846475601196289
INFO:root:current mean train loss 5510.968834084687
INFO:root:current train perplexity8.801746368408203
INFO:root:current mean train loss 5486.834281195621
INFO:root:current train perplexity8.736577987670898
INFO:root:current mean train loss 5475.540376537489
INFO:root:current train perplexity8.68519115447998
INFO:root:current mean train loss 5468.067828533578
INFO:root:current train perplexity8.647486686706543
INFO:root:current mean train loss 5463.254378500128
INFO:root:current train perplexity8.62034797668457
INFO:root:current mean train loss 5455.3194452278885
INFO:root:current train perplexity8.597273826599121
INFO:root:current mean train loss 5445.603887998456
INFO:root:current train perplexity8.557950973510742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.58s/it]
INFO:root:final mean train loss: 5435.159447700747
INFO:root:final train perplexity: 8.536299705505371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 5058.827030695922
INFO:root:eval perplexity: 7.734114170074463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5806.439390791224
INFO:root:eval perplexity: 10.743841171264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/5
  2%|â–Ž         | 5/200 [19:26<12:37:28, 233.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5283.272924178686
INFO:root:current train perplexity8.037605285644531
INFO:root:current mean train loss 5285.704891945818
INFO:root:current train perplexity8.065555572509766
INFO:root:current mean train loss 5293.3201081982215
INFO:root:current train perplexity8.061912536621094
INFO:root:current mean train loss 5284.866385220778
INFO:root:current train perplexity8.043770790100098
INFO:root:current mean train loss 5279.858442927819
INFO:root:current train perplexity8.0545654296875
INFO:root:current mean train loss 5278.033842691906
INFO:root:current train perplexity8.035262107849121
INFO:root:current mean train loss 5276.463404122653
INFO:root:current train perplexity8.020886421203613
INFO:root:current mean train loss 5272.253226356352
INFO:root:current train perplexity7.9962873458862305
INFO:root:current mean train loss 5268.121403363379
INFO:root:current train perplexity7.980555534362793
INFO:root:current mean train loss 5265.4057138786275
INFO:root:current train perplexity7.967832565307617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.61s/it]
INFO:root:final mean train loss: 5255.254509833551
INFO:root:final train perplexity: 7.951415538787842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4933.651346409574
INFO:root:eval perplexity: 7.352380275726318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5698.945547983156
INFO:root:eval perplexity: 10.281820297241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/6
  3%|â–Ž         | 6/200 [23:19<12:33:43, 233.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5146.482899767288
INFO:root:current train perplexity7.655300140380859
INFO:root:current mean train loss 5173.582599250638
INFO:root:current train perplexity7.692935943603516
INFO:root:current mean train loss 5163.789525082237
INFO:root:current train perplexity7.655178070068359
INFO:root:current mean train loss 5155.832025621397
INFO:root:current train perplexity7.631613254547119
INFO:root:current mean train loss 5147.660747212318
INFO:root:current train perplexity7.60763692855835
INFO:root:current mean train loss 5145.677526386826
INFO:root:current train perplexity7.5966644287109375
INFO:root:current mean train loss 5137.069963835491
INFO:root:current train perplexity7.572315692901611
INFO:root:current mean train loss 5133.973371349984
INFO:root:current train perplexity7.5655107498168945
INFO:root:current mean train loss 5128.660563823605
INFO:root:current train perplexity7.553143501281738
INFO:root:current mean train loss 5125.603630605696
INFO:root:current train perplexity7.544177055358887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.22s/it]
INFO:root:final mean train loss: 5117.93161318379
INFO:root:final train perplexity: 7.532085418701172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4836.814702460107
INFO:root:eval perplexity: 7.070037841796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5619.704309341755
INFO:root:eval perplexity: 9.953998565673828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/7
  4%|â–Ž         | 7/200 [27:12<12:29:32, 233.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5045.958895596591
INFO:root:current train perplexity7.214567184448242
INFO:root:current mean train loss 5006.52267515121
INFO:root:current train perplexity7.232540607452393
INFO:root:current mean train loss 5020.615052466299
INFO:root:current train perplexity7.249410629272461
INFO:root:current mean train loss 5034.736500055018
INFO:root:current train perplexity7.285791873931885
INFO:root:current mean train loss 5033.577097999657
INFO:root:current train perplexity7.272531032562256
INFO:root:current mean train loss 5030.792166385135
INFO:root:current train perplexity7.258848667144775
INFO:root:current mean train loss 5028.560900972089
INFO:root:current train perplexity7.250264644622803
INFO:root:current mean train loss 5021.583893186052
INFO:root:current train perplexity7.238162517547607
INFO:root:current mean train loss 5014.50595760234
INFO:root:current train perplexity7.223501205444336
INFO:root:current mean train loss 5013.000894244928
INFO:root:current train perplexity7.218453407287598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.87s/it]
INFO:root:final mean train loss: 5007.6761708413405
INFO:root:final train perplexity: 7.211472034454346
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4754.589781416224
INFO:root:eval perplexity: 6.838829517364502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5547.2153874390515
INFO:root:eval perplexity: 9.663275718688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/8
  4%|â–         | 8/200 [31:05<12:26:12, 233.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4961.073893229167
INFO:root:current train perplexity7.017916679382324
INFO:root:current mean train loss 4942.7574110908745
INFO:root:current train perplexity7.008176326751709
INFO:root:current mean train loss 4942.154319153992
INFO:root:current train perplexity7.018568515777588
INFO:root:current mean train loss 4946.44658499053
INFO:root:current train perplexity7.014560222625732
INFO:root:current mean train loss 4944.673027681223
INFO:root:current train perplexity7.007898330688477
INFO:root:current mean train loss 4941.265495774589
INFO:root:current train perplexity6.992894649505615
INFO:root:current mean train loss 4936.536851609634
INFO:root:current train perplexity6.986979961395264
INFO:root:current mean train loss 4933.646582927179
INFO:root:current train perplexity6.982200622558594
INFO:root:current mean train loss 4923.8706886406435
INFO:root:current train perplexity6.969815731048584
INFO:root:current mean train loss 4922.770388150636
INFO:root:current train perplexity6.962812423706055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it]
INFO:root:final mean train loss: 4918.306177323864
INFO:root:final train perplexity: 6.961632251739502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4703.505606576906
INFO:root:eval perplexity: 6.699009418487549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5505.928884086879
INFO:root:eval perplexity: 9.501503944396973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/9
  4%|â–         | 9/200 [34:58<12:21:48, 233.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4825.024936729754
INFO:root:current train perplexity6.734699249267578
INFO:root:current mean train loss 4833.903608712537
INFO:root:current train perplexity6.76373291015625
INFO:root:current mean train loss 4844.926406466213
INFO:root:current train perplexity6.767087459564209
INFO:root:current mean train loss 4845.723657818818
INFO:root:current train perplexity6.760228157043457
INFO:root:current mean train loss 4852.475274930334
INFO:root:current train perplexity6.759606838226318
INFO:root:current mean train loss 4849.7188560365585
INFO:root:current train perplexity6.761073589324951
INFO:root:current mean train loss 4849.9290420373045
INFO:root:current train perplexity6.7643141746521
INFO:root:current mean train loss 4853.380223532749
INFO:root:current train perplexity6.763688564300537
INFO:root:current mean train loss 4849.237545184235
INFO:root:current train perplexity6.760357856750488
INFO:root:current mean train loss 4845.032211979435
INFO:root:current train perplexity6.752868175506592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.20s/it]
INFO:root:final mean train loss: 4840.925511883152
INFO:root:final train perplexity: 6.752313137054443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4642.484205313608
INFO:root:eval perplexity: 6.535731792449951
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5454.764724623227
INFO:root:eval perplexity: 9.304779052734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/10
  5%|â–Œ         | 10/200 [38:51<12:17:37, 232.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4765.657170935522
INFO:root:current train perplexity6.580442428588867
INFO:root:current mean train loss 4776.876177057874
INFO:root:current train perplexity6.588823318481445
INFO:root:current mean train loss 4790.634661493335
INFO:root:current train perplexity6.615742206573486
INFO:root:current mean train loss 4789.659499840246
INFO:root:current train perplexity6.616766452789307
INFO:root:current mean train loss 4793.029145497619
INFO:root:current train perplexity6.602701187133789
INFO:root:current mean train loss 4787.252463754183
INFO:root:current train perplexity6.591856479644775
INFO:root:current mean train loss 4790.872292160461
INFO:root:current train perplexity6.5948381423950195
INFO:root:current mean train loss 4789.0701294728815
INFO:root:current train perplexity6.590827465057373
INFO:root:current mean train loss 4786.285525655041
INFO:root:current train perplexity6.590736389160156
INFO:root:current mean train loss 4779.55847754006
INFO:root:current train perplexity6.581081867218018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it]
INFO:root:final mean train loss: 4775.564782419512
INFO:root:final train perplexity: 6.580419540405273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 4604.355965688719
INFO:root:eval perplexity: 6.435737133026123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5423.91539921321
INFO:root:eval perplexity: 9.188138961791992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/11
  6%|â–Œ         | 11/200 [42:43<12:13:34, 232.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4712.720147494612
INFO:root:current train perplexity6.396842956542969
INFO:root:current mean train loss 4731.430382060495
INFO:root:current train perplexity6.433618068695068
INFO:root:current mean train loss 4739.076643142966
INFO:root:current train perplexity6.455740451812744
INFO:root:current mean train loss 4728.289594941053
INFO:root:current train perplexity6.448455810546875
INFO:root:current mean train loss 4729.800666950077
INFO:root:current train perplexity6.455478191375732
INFO:root:current mean train loss 4729.288315521188
INFO:root:current train perplexity6.448651313781738
INFO:root:current mean train loss 4727.754292184089
INFO:root:current train perplexity6.442210674285889
INFO:root:current mean train loss 4722.1841434541775
INFO:root:current train perplexity6.440034866333008
INFO:root:current mean train loss 4724.22303333304
INFO:root:current train perplexity6.438284397125244
INFO:root:current mean train loss 4720.914385052558
INFO:root:current train perplexity6.430699825286865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.29s/it]
INFO:root:final mean train loss: 4717.024814359604
INFO:root:final train perplexity: 6.43018102645874
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4565.355191710993
INFO:root:eval perplexity: 6.335037708282471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5392.817895334663
INFO:root:eval perplexity: 9.072043418884277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/12
  6%|â–Œ         | 12/200 [46:36<12:09:42, 232.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4648.322589432566
INFO:root:current train perplexity6.254016876220703
INFO:root:current mean train loss 4668.521096254007
INFO:root:current train perplexity6.285407066345215
INFO:root:current mean train loss 4682.916924324682
INFO:root:current train perplexity6.31835412979126
INFO:root:current mean train loss 4685.309424446203
INFO:root:current train perplexity6.321855545043945
INFO:root:current mean train loss 4682.586627012311
INFO:root:current train perplexity6.3228607177734375
INFO:root:current mean train loss 4683.963958688944
INFO:root:current train perplexity6.328421115875244
INFO:root:current mean train loss 4682.442062092514
INFO:root:current train perplexity6.322820663452148
INFO:root:current mean train loss 4673.307047526042
INFO:root:current train perplexity6.315442085266113
INFO:root:current mean train loss 4672.368661891149
INFO:root:current train perplexity6.3120856285095215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.43s/it]
INFO:root:final mean train loss: 4666.0671154145275
INFO:root:final train perplexity: 6.302198886871338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4533.134568234707
INFO:root:eval perplexity: 6.253032684326172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5364.917296930408
INFO:root:eval perplexity: 8.969128608703613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/13
  6%|â–‹         | 13/200 [50:29<12:05:55, 232.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4702.265462239583
INFO:root:current train perplexity6.151620864868164
INFO:root:current mean train loss 4633.982658904733
INFO:root:current train perplexity6.229725360870361
INFO:root:current mean train loss 4636.681582897168
INFO:root:current train perplexity6.208516597747803
INFO:root:current mean train loss 4628.00982122138
INFO:root:current train perplexity6.206604480743408
INFO:root:current mean train loss 4626.351730914625
INFO:root:current train perplexity6.201984405517578
INFO:root:current mean train loss 4625.012097337848
INFO:root:current train perplexity6.202469348907471
INFO:root:current mean train loss 4625.088885002073
INFO:root:current train perplexity6.201640605926514
INFO:root:current mean train loss 4622.750495226929
INFO:root:current train perplexity6.199591636657715
INFO:root:current mean train loss 4623.021528764205
INFO:root:current train perplexity6.195333003997803
INFO:root:current mean train loss 4623.689940865518
INFO:root:current train perplexity6.187601089477539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.26s/it]
INFO:root:final mean train loss: 4618.75328833057
INFO:root:final train perplexity: 6.1856489181518555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4505.468001994681
INFO:root:eval perplexity: 6.18346643447876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5343.985545489805
INFO:root:eval perplexity: 8.892687797546387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/14
  7%|â–‹         | 14/200 [54:22<12:01:57, 232.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4705.177112926136
INFO:root:current train perplexity6.367706298828125
INFO:root:current mean train loss 4595.32884642455
INFO:root:current train perplexity6.108249664306641
INFO:root:current mean train loss 4592.4816362281545
INFO:root:current train perplexity6.114905834197998
INFO:root:current mean train loss 4573.516764846262
INFO:root:current train perplexity6.102538108825684
INFO:root:current mean train loss 4578.846954122947
INFO:root:current train perplexity6.105050563812256
INFO:root:current mean train loss 4582.751728572957
INFO:root:current train perplexity6.104703903198242
INFO:root:current mean train loss 4585.4610597701
INFO:root:current train perplexity6.099791049957275
INFO:root:current mean train loss 4586.416403296963
INFO:root:current train perplexity6.093403339385986
INFO:root:current mean train loss 4582.341522329685
INFO:root:current train perplexity6.095263957977295
INFO:root:current mean train loss 4582.204444056154
INFO:root:current train perplexity6.088242053985596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.60s/it]
INFO:root:final mean train loss: 4576.91467875819
INFO:root:final train perplexity: 6.084383010864258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4475.815765597296
INFO:root:eval perplexity: 6.109766006469727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5322.962111452793
INFO:root:eval perplexity: 8.816563606262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/15
  8%|â–Š         | 15/200 [58:15<11:58:20, 232.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4513.502107319079
INFO:root:current train perplexity6.092830181121826
INFO:root:current mean train loss 4523.109861229648
INFO:root:current train perplexity6.004659175872803
INFO:root:current mean train loss 4520.679800094535
INFO:root:current train perplexity5.978072643280029
INFO:root:current mean train loss 4534.793667497306
INFO:root:current train perplexity5.990765571594238
INFO:root:current mean train loss 4545.842866082749
INFO:root:current train perplexity5.991436004638672
INFO:root:current mean train loss 4540.858068683015
INFO:root:current train perplexity5.986149311065674
INFO:root:current mean train loss 4537.974023279736
INFO:root:current train perplexity5.98582124710083
INFO:root:current mean train loss 4541.140084427156
INFO:root:current train perplexity5.990133285522461
INFO:root:current mean train loss 4542.183558276576
INFO:root:current train perplexity5.9940185546875
INFO:root:current mean train loss 4543.482753683096
INFO:root:current train perplexity5.996925354003906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.13s/it]
INFO:root:final mean train loss: 4538.802966579314
INFO:root:final train perplexity: 5.993579864501953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4452.040631233378
INFO:root:eval perplexity: 6.051309108734131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5303.517430948027
INFO:root:eval perplexity: 8.746740341186523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/16
  8%|â–Š         | 16/200 [1:02:08<11:54:19, 232.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4444.452573423033
INFO:root:current train perplexity5.873420238494873
INFO:root:current mean train loss 4488.972994586614
INFO:root:current train perplexity5.896952152252197
INFO:root:current mean train loss 4494.849346950716
INFO:root:current train perplexity5.882813930511475
INFO:root:current mean train loss 4494.399445420011
INFO:root:current train perplexity5.886659145355225
INFO:root:current mean train loss 4491.789575938597
INFO:root:current train perplexity5.881503582000732
INFO:root:current mean train loss 4491.221401728534
INFO:root:current train perplexity5.89086389541626
INFO:root:current mean train loss 4490.200269683886
INFO:root:current train perplexity5.896526336669922
INFO:root:current mean train loss 4498.168739455275
INFO:root:current train perplexity5.900859355926514
INFO:root:current mean train loss 4504.01245678091
INFO:root:current train perplexity5.903988361358643
INFO:root:current mean train loss 4504.759670549741
INFO:root:current train perplexity5.906888484954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.23s/it]
INFO:root:final mean train loss: 4502.781882562945
INFO:root:final train perplexity: 5.909008026123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4436.742208277926
INFO:root:eval perplexity: 6.013989448547363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5291.512033881871
INFO:root:eval perplexity: 8.703906059265137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/17
  8%|â–Š         | 17/200 [1:06:01<11:50:21, 232.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4514.576199776786
INFO:root:current train perplexity5.954309940338135
INFO:root:current mean train loss 4491.449477358217
INFO:root:current train perplexity5.870767116546631
INFO:root:current mean train loss 4475.647701961436
INFO:root:current train perplexity5.8363142013549805
INFO:root:current mean train loss 4478.665204495102
INFO:root:current train perplexity5.835166931152344
INFO:root:current mean train loss 4475.03178823186
INFO:root:current train perplexity5.835376262664795
INFO:root:current mean train loss 4483.140807078709
INFO:root:current train perplexity5.837754726409912
INFO:root:current mean train loss 4478.979528712475
INFO:root:current train perplexity5.834936141967773
INFO:root:current mean train loss 4477.750927734375
INFO:root:current train perplexity5.831265926361084
INFO:root:current mean train loss 4473.429504760011
INFO:root:current train perplexity5.828294277191162
INFO:root:current mean train loss 4471.430352554729
INFO:root:current train perplexity5.828861236572266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.44s/it]
INFO:root:final mean train loss: 4469.085327763712
INFO:root:final train perplexity: 5.8309712409973145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4413.417144558954
INFO:root:eval perplexity: 5.957530975341797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5275.372264239805
INFO:root:eval perplexity: 8.646652221679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/18
  9%|â–‰         | 18/200 [1:09:54<11:46:42, 232.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4434.993277616279
INFO:root:current train perplexity5.706532001495361
INFO:root:current mean train loss 4433.7651264750875
INFO:root:current train perplexity5.736152172088623
INFO:root:current mean train loss 4438.834262675218
INFO:root:current train perplexity5.754714488983154
INFO:root:current mean train loss 4440.466403972303
INFO:root:current train perplexity5.752721309661865
INFO:root:current mean train loss 4439.365940894822
INFO:root:current train perplexity5.755954742431641
INFO:root:current mean train loss 4436.574433216074
INFO:root:current train perplexity5.756143569946289
INFO:root:current mean train loss 4439.326683317336
INFO:root:current train perplexity5.749362468719482
INFO:root:current mean train loss 4442.594468949781
INFO:root:current train perplexity5.755305290222168
INFO:root:current mean train loss 4438.936436265106
INFO:root:current train perplexity5.755120754241943
INFO:root:current mean train loss 4437.15652650285
INFO:root:current train perplexity5.753985404968262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.54s/it]
INFO:root:final mean train loss: 4437.009722309728
INFO:root:final train perplexity: 5.757646560668945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it]
INFO:root:eval mean loss: 4398.644858502327
INFO:root:eval perplexity: 5.922051429748535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 5264.818624293551
INFO:root:eval perplexity: 8.609416961669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/19
 10%|â–‰         | 19/200 [1:13:47<11:42:54, 233.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4468.164895450368
INFO:root:current train perplexity5.75832462310791
INFO:root:current mean train loss 4446.319940630174
INFO:root:current train perplexity5.724270820617676
INFO:root:current mean train loss 4427.646453249502
INFO:root:current train perplexity5.706496715545654
INFO:root:current mean train loss 4421.736588959001
INFO:root:current train perplexity5.696499347686768
INFO:root:current mean train loss 4417.252718568113
INFO:root:current train perplexity5.695279121398926
INFO:root:current mean train loss 4418.4910239550245
INFO:root:current train perplexity5.704720497131348
INFO:root:current mean train loss 4417.960678733439
INFO:root:current train perplexity5.70368766784668
INFO:root:current mean train loss 4414.361324874126
INFO:root:current train perplexity5.696223735809326
INFO:root:current mean train loss 4413.444729546122
INFO:root:current train perplexity5.693431377410889
INFO:root:current mean train loss 4414.007663089018
INFO:root:current train perplexity5.6930131912231445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it]
INFO:root:final mean train loss: 4407.95634091285
INFO:root:final train perplexity: 5.692027568817139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4383.721456324801
INFO:root:eval perplexity: 5.886422157287598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5252.504178094526
INFO:root:eval perplexity: 8.566171646118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/20
 10%|â–ˆ         | 20/200 [1:17:40<11:38:53, 232.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4387.654888605667
INFO:root:current train perplexity5.606882572174072
INFO:root:current mean train loss 4376.901049344045
INFO:root:current train perplexity5.625418663024902
INFO:root:current mean train loss 4378.302821096767
INFO:root:current train perplexity5.630119800567627
INFO:root:current mean train loss 4375.759818669481
INFO:root:current train perplexity5.633146286010742
INFO:root:current mean train loss 4375.306984230324
INFO:root:current train perplexity5.623530864715576
INFO:root:current mean train loss 4376.996568928891
INFO:root:current train perplexity5.621468544006348
INFO:root:current mean train loss 4378.184752584408
INFO:root:current train perplexity5.623655319213867
INFO:root:current mean train loss 4382.464784242733
INFO:root:current train perplexity5.627720355987549
INFO:root:current mean train loss 4384.703486237177
INFO:root:current train perplexity5.6291279792785645
INFO:root:current mean train loss 4384.3487702848015
INFO:root:current train perplexity5.631532192230225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.40s/it]
INFO:root:final mean train loss: 4380.435334420973
INFO:root:final train perplexity: 5.630558013916016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4372.07655972961
INFO:root:eval perplexity: 5.858768463134766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5244.272327612478
INFO:root:eval perplexity: 8.537386894226074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/21
 10%|â–ˆ         | 21/200 [1:21:33<11:35:05, 232.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4356.576131792211
INFO:root:current train perplexity5.607488632202148
INFO:root:current mean train loss 4357.033575914577
INFO:root:current train perplexity5.565334796905518
INFO:root:current mean train loss 4345.638693820225
INFO:root:current train perplexity5.554357051849365
INFO:root:current mean train loss 4361.840381923748
INFO:root:current train perplexity5.574516296386719
INFO:root:current mean train loss 4357.818588877643
INFO:root:current train perplexity5.569418907165527
INFO:root:current mean train loss 4359.94904436384
INFO:root:current train perplexity5.571279048919678
INFO:root:current mean train loss 4363.386168244003
INFO:root:current train perplexity5.568094253540039
INFO:root:current mean train loss 4361.566764025831
INFO:root:current train perplexity5.569438457489014
INFO:root:current mean train loss 4361.518434729131
INFO:root:current train perplexity5.575911998748779
INFO:root:current mean train loss 4358.305154573584
INFO:root:current train perplexity5.5723795890808105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.38s/it]
INFO:root:final mean train loss: 4354.100578800325
INFO:root:final train perplexity: 5.572359085083008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4360.000682208555
INFO:root:eval perplexity: 5.830229759216309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5240.390573055186
INFO:root:eval perplexity: 8.523847579956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/22
 11%|â–ˆ         | 22/200 [1:25:26<11:31:11, 232.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4326.472880859375
INFO:root:current train perplexity5.479159832000732
INFO:root:current mean train loss 4307.519654017857
INFO:root:current train perplexity5.465445041656494
INFO:root:current mean train loss 4324.31810546875
INFO:root:current train perplexity5.482836723327637
INFO:root:current mean train loss 4317.680856770833
INFO:root:current train perplexity5.481125354766846
INFO:root:current mean train loss 4321.080281147204
INFO:root:current train perplexity5.489647388458252
INFO:root:current mean train loss 4333.8276031759515
INFO:root:current train perplexity5.51138973236084
INFO:root:current mean train loss 4333.661365017361
INFO:root:current train perplexity5.513498306274414
INFO:root:current mean train loss 4334.612286731351
INFO:root:current train perplexity5.517208576202393
INFO:root:current mean train loss 4335.814374720982
INFO:root:current train perplexity5.519108772277832
INFO:root:current mean train loss 4335.059928385416
INFO:root:current train perplexity5.520529747009277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.25s/it]
INFO:root:final mean train loss: 4329.903860215218
INFO:root:final train perplexity: 5.519418239593506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4345.527253712323
INFO:root:eval perplexity: 5.796206951141357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5223.538679839871
INFO:root:eval perplexity: 8.465311050415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/23
 12%|â–ˆâ–        | 23/200 [1:29:19<11:27:12, 232.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4281.327892625188
INFO:root:current train perplexity5.4556965827941895
INFO:root:current mean train loss 4306.576468045594
INFO:root:current train perplexity5.481310844421387
INFO:root:current mean train loss 4307.569574039311
INFO:root:current train perplexity5.478346347808838
INFO:root:current mean train loss 4303.622808471361
INFO:root:current train perplexity5.469468593597412
INFO:root:current mean train loss 4305.26980622412
INFO:root:current train perplexity5.465828895568848
INFO:root:current mean train loss 4305.030030134407
INFO:root:current train perplexity5.465621471405029
INFO:root:current mean train loss 4306.779070964495
INFO:root:current train perplexity5.464365482330322
INFO:root:current mean train loss 4307.034790818567
INFO:root:current train perplexity5.462419033050537
INFO:root:current mean train loss 4307.167627284913
INFO:root:current train perplexity5.4643049240112305
INFO:root:current mean train loss 4307.24236805975
INFO:root:current train perplexity5.463564395904541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it]
INFO:root:final mean train loss: 4304.0529934667775
INFO:root:final train perplexity: 5.463411331176758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4335.255149462544
INFO:root:eval perplexity: 5.772181034088135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5221.233530031029
INFO:root:eval perplexity: 8.457334518432617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/24
 12%|â–ˆâ–        | 24/200 [1:33:12<11:23:09, 232.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4298.324028266656
INFO:root:current train perplexity5.397975921630859
INFO:root:current mean train loss 4279.535213770043
INFO:root:current train perplexity5.392369747161865
INFO:root:current mean train loss 4268.592505805681
INFO:root:current train perplexity5.39321756362915
INFO:root:current mean train loss 4270.661100968071
INFO:root:current train perplexity5.398014545440674
INFO:root:current mean train loss 4269.356218574974
INFO:root:current train perplexity5.393564701080322
INFO:root:current mean train loss 4269.350857342561
INFO:root:current train perplexity5.402481555938721
INFO:root:current mean train loss 4275.505376746789
INFO:root:current train perplexity5.406590938568115
INFO:root:current mean train loss 4279.725953537354
INFO:root:current train perplexity5.408545970916748
INFO:root:current mean train loss 4281.926908242582
INFO:root:current train perplexity5.410890579223633
INFO:root:current mean train loss 4285.32526503177
INFO:root:current train perplexity5.415914535522461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.23s/it]
INFO:root:final mean train loss: 4281.931641486383
INFO:root:final train perplexity: 5.415937900543213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4325.740966796875
INFO:root:eval perplexity: 5.750015735626221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5215.586034463652
INFO:root:eval perplexity: 8.437826156616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/25
 12%|â–ˆâ–Ž        | 25/200 [1:37:05<11:19:10, 232.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4269.411638356219
INFO:root:current train perplexity5.32432222366333
INFO:root:current mean train loss 4262.137566494583
INFO:root:current train perplexity5.338483810424805
INFO:root:current mean train loss 4261.625684246969
INFO:root:current train perplexity5.352682113647461
INFO:root:current mean train loss 4256.271611034422
INFO:root:current train perplexity5.348330020904541
INFO:root:current mean train loss 4259.481430145447
INFO:root:current train perplexity5.35506534576416
INFO:root:current mean train loss 4261.083631410424
INFO:root:current train perplexity5.355728626251221
INFO:root:current mean train loss 4266.375385246222
INFO:root:current train perplexity5.361785888671875
INFO:root:current mean train loss 4268.900672349226
INFO:root:current train perplexity5.367180824279785
INFO:root:current mean train loss 4265.533480397055
INFO:root:current train perplexity5.368852138519287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.12s/it]
INFO:root:final mean train loss: 4260.1635982759535
INFO:root:final train perplexity: 5.369622707366943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4317.44710113309
INFO:root:eval perplexity: 5.730764389038086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5210.436590965758
INFO:root:eval perplexity: 8.420077323913574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/26
 13%|â–ˆâ–Ž        | 26/200 [1:40:57<11:15:09, 232.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4170.986328125
INFO:root:current train perplexity5.395882606506348
INFO:root:current mean train loss 4204.81091650847
INFO:root:current train perplexity5.310490131378174
INFO:root:current mean train loss 4217.038976402098
INFO:root:current train perplexity5.309739112854004
INFO:root:current mean train loss 4210.01059029545
INFO:root:current train perplexity5.300482273101807
INFO:root:current mean train loss 4215.850639924371
INFO:root:current train perplexity5.3091888427734375
INFO:root:current mean train loss 4221.592668943386
INFO:root:current train perplexity5.3167619705200195
INFO:root:current mean train loss 4222.000773447153
INFO:root:current train perplexity5.309442520141602
INFO:root:current mean train loss 4229.465556143366
INFO:root:current train perplexity5.313517093658447
INFO:root:current mean train loss 4231.847344645485
INFO:root:current train perplexity5.313671588897705
INFO:root:current mean train loss 4236.200913468164
INFO:root:current train perplexity5.316023826599121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.49s/it]
INFO:root:final mean train loss: 4239.334638410999
INFO:root:final train perplexity: 5.325678825378418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4308.139567057292
INFO:root:eval perplexity: 5.709236145019531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5205.293865663785
INFO:root:eval perplexity: 8.402392387390137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/27
 14%|â–ˆâ–Ž        | 27/200 [1:44:50<11:11:32, 232.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4283.5400390625
INFO:root:current train perplexity5.273718357086182
INFO:root:current mean train loss 4212.11073157269
INFO:root:current train perplexity5.263769149780273
INFO:root:current mean train loss 4203.345378361192
INFO:root:current train perplexity5.245546817779541
INFO:root:current mean train loss 4209.665251426091
INFO:root:current train perplexity5.256361484527588
INFO:root:current mean train loss 4211.842872858622
INFO:root:current train perplexity5.256309509277344
INFO:root:current mean train loss 4215.547819800516
INFO:root:current train perplexity5.269913196563721
INFO:root:current mean train loss 4213.631925257241
INFO:root:current train perplexity5.269721031188965
INFO:root:current mean train loss 4216.147316160402
INFO:root:current train perplexity5.272714138031006
INFO:root:current mean train loss 4216.636409605061
INFO:root:current train perplexity5.270457744598389
INFO:root:current mean train loss 4223.02830563738
INFO:root:current train perplexity5.279989242553711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.86s/it]
INFO:root:final mean train loss: 4218.454949532786
INFO:root:final train perplexity: 5.28198766708374
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4302.790799188276
INFO:root:eval perplexity: 5.696900844573975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5201.341705105829
INFO:root:eval perplexity: 8.388822555541992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/28
 14%|â–ˆâ–        | 28/200 [1:48:44<11:08:04, 233.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4244.393416694973
INFO:root:current train perplexity5.201072692871094
INFO:root:current mean train loss 4197.104825647866
INFO:root:current train perplexity5.227390289306641
INFO:root:current mean train loss 4178.175115610987
INFO:root:current train perplexity5.214503288269043
INFO:root:current mean train loss 4181.04694529436
INFO:root:current train perplexity5.212346076965332
INFO:root:current mean train loss 4190.841389396794
INFO:root:current train perplexity5.228512287139893
INFO:root:current mean train loss 4191.190200017925
INFO:root:current train perplexity5.230844020843506
INFO:root:current mean train loss 4197.448387182735
INFO:root:current train perplexity5.232706069946289
INFO:root:current mean train loss 4199.306877336727
INFO:root:current train perplexity5.23680305480957
INFO:root:current mean train loss 4201.5156202536455
INFO:root:current train perplexity5.243410587310791
INFO:root:current mean train loss 4201.325789661346
INFO:root:current train perplexity5.242241859436035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.36s/it]
INFO:root:final mean train loss: 4199.35578192434
INFO:root:final train perplexity: 5.242336750030518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.00s/it]
INFO:root:eval mean loss: 4294.679829482491
INFO:root:eval perplexity: 5.678246021270752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5200.521494763962
INFO:root:eval perplexity: 8.386009216308594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/29
 14%|â–ˆâ–        | 29/200 [1:52:37<11:04:05, 233.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4105.6382702242945
INFO:root:current train perplexity5.127617359161377
INFO:root:current mean train loss 4166.888589873569
INFO:root:current train perplexity5.164125442504883
INFO:root:current mean train loss 4180.507733233563
INFO:root:current train perplexity5.188833713531494
INFO:root:current mean train loss 4182.6624966071095
INFO:root:current train perplexity5.1892547607421875
INFO:root:current mean train loss 4175.724809898855
INFO:root:current train perplexity5.178178787231445
INFO:root:current mean train loss 4180.322002633592
INFO:root:current train perplexity5.193604469299316
INFO:root:current mean train loss 4180.642015943814
INFO:root:current train perplexity5.194844722747803
INFO:root:current mean train loss 4180.079715754852
INFO:root:current train perplexity5.193989276885986
INFO:root:current mean train loss 4180.243636772808
INFO:root:current train perplexity5.192693710327148
INFO:root:current mean train loss 4181.317131591534
INFO:root:current train perplexity5.199121952056885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it]
INFO:root:final mean train loss: 4179.435029798939
INFO:root:final train perplexity: 5.201297760009766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4285.078829717974
INFO:root:eval perplexity: 5.656243801116943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5187.613748753324
INFO:root:eval perplexity: 8.341863632202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/30
 15%|â–ˆâ–Œ        | 30/200 [1:56:30<11:00:06, 232.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4222.5005446213945
INFO:root:current train perplexity5.197405815124512
INFO:root:current mean train loss 4160.711350255733
INFO:root:current train perplexity5.140106201171875
INFO:root:current mean train loss 4162.172305055243
INFO:root:current train perplexity5.136629104614258
INFO:root:current mean train loss 4164.7163885336
INFO:root:current train perplexity5.150238037109375
INFO:root:current mean train loss 4159.803094190454
INFO:root:current train perplexity5.150984287261963
INFO:root:current mean train loss 4160.97981468866
INFO:root:current train perplexity5.155388832092285
INFO:root:current mean train loss 4157.587463856489
INFO:root:current train perplexity5.149118423461914
INFO:root:current mean train loss 4160.87353515625
INFO:root:current train perplexity5.158017635345459
INFO:root:current mean train loss 4161.970653656697
INFO:root:current train perplexity5.15941047668457
INFO:root:current mean train loss 4161.056190823849
INFO:root:current train perplexity5.15991735458374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.08s/it]
INFO:root:final mean train loss: 4160.800453432144
INFO:root:final train perplexity: 5.1631975173950195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4280.396905127992
INFO:root:eval perplexity: 5.645545482635498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 5190.044920143506
INFO:root:eval perplexity: 8.35015869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/31
 16%|â–ˆâ–Œ        | 31/200 [2:00:22<10:55:59, 232.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4112.656717503324
INFO:root:current train perplexity5.1207594871521
INFO:root:current mean train loss 4128.559962266157
INFO:root:current train perplexity5.113868236541748
INFO:root:current mean train loss 4132.922018321419
INFO:root:current train perplexity5.106987953186035
INFO:root:current mean train loss 4135.023752701729
INFO:root:current train perplexity5.101513862609863
INFO:root:current mean train loss 4141.394195351824
INFO:root:current train perplexity5.109672546386719
INFO:root:current mean train loss 4139.144349148766
INFO:root:current train perplexity5.108933925628662
INFO:root:current mean train loss 4136.0955163404415
INFO:root:current train perplexity5.1149420738220215
INFO:root:current mean train loss 4139.5483114097015
INFO:root:current train perplexity5.119647026062012
INFO:root:current mean train loss 4143.2538200657655
INFO:root:current train perplexity5.1257758140563965
INFO:root:current mean train loss 4145.1013116564645
INFO:root:current train perplexity5.1277923583984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.44s/it]
INFO:root:final mean train loss: 4143.739761352539
INFO:root:final train perplexity: 5.128561496734619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4276.675175227172
INFO:root:eval perplexity: 5.63705587387085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5186.6466731078235
INFO:root:eval perplexity: 8.3385648727417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/32
 16%|â–ˆâ–Œ        | 32/200 [2:04:15<10:52:10, 232.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4112.25703568892
INFO:root:current train perplexity5.046279430389404
INFO:root:current mean train loss 4124.0239005796375
INFO:root:current train perplexity5.066459655761719
INFO:root:current mean train loss 4124.153964652267
INFO:root:current train perplexity5.071441173553467
INFO:root:current mean train loss 4122.007818001761
INFO:root:current train perplexity5.074986934661865
INFO:root:current mean train loss 4116.533918376545
INFO:root:current train perplexity5.075167179107666
INFO:root:current mean train loss 4121.504972550676
INFO:root:current train perplexity5.080410003662109
INFO:root:current mean train loss 4123.700549409589
INFO:root:current train perplexity5.085299015045166
INFO:root:current mean train loss 4122.668380393729
INFO:root:current train perplexity5.084066867828369
INFO:root:current mean train loss 4126.051570209704
INFO:root:current train perplexity5.086983680725098
INFO:root:current mean train loss 4126.064104170076
INFO:root:current train perplexity5.0898661613464355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:final mean train loss: 4125.813642009612
INFO:root:final train perplexity: 5.092418193817139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4269.636862463985
INFO:root:eval perplexity: 5.621034145355225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5179.225880291445
INFO:root:eval perplexity: 8.313301086425781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/33
 16%|â–ˆâ–‹        | 33/200 [2:08:08<10:48:25, 232.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4108.6387455047125
INFO:root:current train perplexity5.03993034362793
INFO:root:current mean train loss 4106.054665033072
INFO:root:current train perplexity5.032422065734863
INFO:root:current mean train loss 4101.594158448194
INFO:root:current train perplexity5.0273118019104
INFO:root:current mean train loss 4100.560433211734
INFO:root:current train perplexity5.033373832702637
INFO:root:current mean train loss 4109.7565127016405
INFO:root:current train perplexity5.045947551727295
INFO:root:current mean train loss 4106.667281426926
INFO:root:current train perplexity5.0517754554748535
INFO:root:current mean train loss 4106.742383769914
INFO:root:current train perplexity5.0559234619140625
INFO:root:current mean train loss 4105.599932869328
INFO:root:current train perplexity5.054284572601318
INFO:root:current mean train loss 4104.397755999692
INFO:root:current train perplexity5.053110599517822
INFO:root:current mean train loss 4111.070126669181
INFO:root:current train perplexity5.057734489440918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:27<00:00, 207.93s/it]
INFO:root:final mean train loss: 4108.603470340852
INFO:root:final train perplexity: 5.057958602905273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4265.803865040448
INFO:root:eval perplexity: 5.612329959869385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5179.315143991024
INFO:root:eval perplexity: 8.313604354858398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/34
 17%|â–ˆâ–‹        | 34/200 [2:12:01<10:44:14, 232.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4082.3200064645685
INFO:root:current train perplexity4.989063262939453
INFO:root:current mean train loss 4074.9406966716924
INFO:root:current train perplexity5.005702972412109
INFO:root:current mean train loss 4079.1407655385146
INFO:root:current train perplexity5.012570381164551
INFO:root:current mean train loss 4087.8609536883
INFO:root:current train perplexity5.021662712097168
INFO:root:current mean train loss 4087.4724318064955
INFO:root:current train perplexity5.022533416748047
INFO:root:current mean train loss 4093.551920715439
INFO:root:current train perplexity5.027336120605469
INFO:root:current mean train loss 4094.9256411693136
INFO:root:current train perplexity5.028571128845215
INFO:root:current mean train loss 4094.8800123241936
INFO:root:current train perplexity5.029409408569336
INFO:root:current mean train loss 4096.036603715198
INFO:root:current train perplexity5.026285648345947
INFO:root:current mean train loss 4095.857190808847
INFO:root:current train perplexity5.027372360229492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it]
INFO:root:final mean train loss: 4092.7634960912887
INFO:root:final train perplexity: 5.026448726654053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4259.949483668551
INFO:root:eval perplexity: 5.599059104919434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5180.630476714871
INFO:root:eval perplexity: 8.318078994750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/35
 18%|â–ˆâ–Š        | 35/200 [2:15:54<10:40:17, 232.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4064.2355060818827
INFO:root:current train perplexity4.946235179901123
INFO:root:current mean train loss 4071.4567939289454
INFO:root:current train perplexity4.957025527954102
INFO:root:current mean train loss 4065.6531593021955
INFO:root:current train perplexity4.970081329345703
INFO:root:current mean train loss 4067.208634590411
INFO:root:current train perplexity4.973585605621338
INFO:root:current mean train loss 4071.3515507771726
INFO:root:current train perplexity4.983315944671631
INFO:root:current mean train loss 4070.632877435503
INFO:root:current train perplexity4.979928970336914
INFO:root:current mean train loss 4069.03623205081
INFO:root:current train perplexity4.981203079223633
INFO:root:current mean train loss 4072.960424146542
INFO:root:current train perplexity4.9888997077941895
INFO:root:current mean train loss 4078.4499264522897
INFO:root:current train perplexity4.992660999298096
INFO:root:current mean train loss 4078.892992590494
INFO:root:current train perplexity4.993511199951172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.53s/it]
INFO:root:final mean train loss: 4077.178970829133
INFO:root:final train perplexity: 4.995637893676758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4257.5742672318265
INFO:root:eval perplexity: 5.59368371963501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5177.6528458832
INFO:root:eval perplexity: 8.307954788208008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/36
 18%|â–ˆâ–Š        | 36/200 [2:19:47<10:36:36, 232.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4030.3291885551366
INFO:root:current train perplexity4.917420387268066
INFO:root:current mean train loss 4029.1134979737635
INFO:root:current train perplexity4.906223773956299
INFO:root:current mean train loss 4035.6628571088304
INFO:root:current train perplexity4.928592205047607
INFO:root:current mean train loss 4048.888856084464
INFO:root:current train perplexity4.946995735168457
INFO:root:current mean train loss 4052.722969070842
INFO:root:current train perplexity4.949652671813965
INFO:root:current mean train loss 4060.9620962321655
INFO:root:current train perplexity4.960899353027344
INFO:root:current mean train loss 4059.189376720001
INFO:root:current train perplexity4.957859039306641
INFO:root:current mean train loss 4058.9076683112294
INFO:root:current train perplexity4.960421085357666
INFO:root:current mean train loss 4061.7152255121723
INFO:root:current train perplexity4.961457252502441
INFO:root:current mean train loss 4065.035312579154
INFO:root:current train perplexity4.966011047363281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.34s/it]
INFO:root:final mean train loss: 4061.9090881347656
INFO:root:final train perplexity: 4.965632915496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4255.421779767841
INFO:root:eval perplexity: 5.588816165924072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5175.988653521165
INFO:root:eval perplexity: 8.3023042678833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/37
 18%|â–ˆâ–Š        | 37/200 [2:23:40<10:32:47, 232.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4030.224056846217
INFO:root:current train perplexity4.9048027992248535
INFO:root:current mean train loss 4037.7218549679487
INFO:root:current train perplexity4.930049896240234
INFO:root:current mean train loss 4047.715360997087
INFO:root:current train perplexity4.924615383148193
INFO:root:current mean train loss 4049.5691684384888
INFO:root:current train perplexity4.9379472732543945
INFO:root:current mean train loss 4044.6970397332702
INFO:root:current train perplexity4.927576065063477
INFO:root:current mean train loss 4043.5544540277047
INFO:root:current train perplexity4.921635627746582
INFO:root:current mean train loss 4043.3391485639613
INFO:root:current train perplexity4.9259796142578125
INFO:root:current mean train loss 4044.04572769261
INFO:root:current train perplexity4.931487560272217
INFO:root:current mean train loss 4044.002970604923
INFO:root:current train perplexity4.93148136138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.75s/it]
INFO:root:final mean train loss: 4046.177452333512
INFO:root:final train perplexity: 4.934908390045166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4251.120465217753
INFO:root:eval perplexity: 5.579104423522949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5176.565095509198
INFO:root:eval perplexity: 8.3042573928833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/38
 19%|â–ˆâ–‰        | 38/200 [2:27:33<10:29:13, 233.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4163.370361328125
INFO:root:current train perplexity4.819478511810303
INFO:root:current mean train loss 4031.569049131523
INFO:root:current train perplexity4.868438243865967
INFO:root:current mean train loss 4022.1223240744303
INFO:root:current train perplexity4.878063678741455
INFO:root:current mean train loss 4023.862875154703
INFO:root:current train perplexity4.878946304321289
INFO:root:current mean train loss 4022.799534497131
INFO:root:current train perplexity4.885505676269531
INFO:root:current mean train loss 4029.0833854296097
INFO:root:current train perplexity4.896057605743408
INFO:root:current mean train loss 4030.8729501094786
INFO:root:current train perplexity4.898727893829346
INFO:root:current mean train loss 4032.85570455581
INFO:root:current train perplexity4.900154113769531
INFO:root:current mean train loss 4030.661540220268
INFO:root:current train perplexity4.900479316711426
INFO:root:current mean train loss 4033.4602605031837
INFO:root:current train perplexity4.903707981109619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.25s/it]
INFO:root:final mean train loss: 4031.255065979496
INFO:root:final train perplexity: 4.905940055847168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 4248.668903756649
INFO:root:eval perplexity: 5.573576927185059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5174.581454662566
INFO:root:eval perplexity: 8.297527313232422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/39
 20%|â–ˆâ–‰        | 39/200 [2:31:26<10:25:08, 232.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3999.458806818182
INFO:root:current train perplexity4.849545478820801
INFO:root:current mean train loss 4010.664988474803
INFO:root:current train perplexity4.862152576446533
INFO:root:current mean train loss 4008.797113355302
INFO:root:current train perplexity4.855227947235107
INFO:root:current mean train loss 4006.593722524367
INFO:root:current train perplexity4.852706432342529
INFO:root:current mean train loss 4013.9641047939476
INFO:root:current train perplexity4.867516994476318
INFO:root:current mean train loss 4016.5042206228595
INFO:root:current train perplexity4.870112419128418
INFO:root:current mean train loss 4011.952153631981
INFO:root:current train perplexity4.8721489906311035
INFO:root:current mean train loss 4016.4383234166226
INFO:root:current train perplexity4.870948314666748
INFO:root:current mean train loss 4016.832157083269
INFO:root:current train perplexity4.87316370010376
INFO:root:current mean train loss 4019.6525015972315
INFO:root:current train perplexity4.876532554626465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.49s/it]
INFO:root:final mean train loss: 4016.6909415337345
INFO:root:final train perplexity: 4.87783145904541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4243.559106272163
INFO:root:eval perplexity: 5.56207275390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5170.3119978668
INFO:root:eval perplexity: 8.283052444458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/40
 20%|â–ˆâ–ˆ        | 40/200 [2:35:19<10:21:19, 233.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4003.2965923108554
INFO:root:current train perplexity4.883331775665283
INFO:root:current mean train loss 3976.8908568310135
INFO:root:current train perplexity4.839526653289795
INFO:root:current mean train loss 3982.5500566317064
INFO:root:current train perplexity4.82094144821167
INFO:root:current mean train loss 3989.668347588901
INFO:root:current train perplexity4.8175835609436035
INFO:root:current mean train loss 3991.5729257952344
INFO:root:current train perplexity4.825361728668213
INFO:root:current mean train loss 3996.8776958958033
INFO:root:current train perplexity4.830449104309082
INFO:root:current mean train loss 4001.202960136056
INFO:root:current train perplexity4.844066143035889
INFO:root:current mean train loss 4005.304805325865
INFO:root:current train perplexity4.8494553565979
INFO:root:current mean train loss 4005.9175690032625
INFO:root:current train perplexity4.849300861358643
INFO:root:current mean train loss 4006.306699866958
INFO:root:current train perplexity4.849785804748535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.27s/it]
INFO:root:final mean train loss: 4002.208145018547
INFO:root:final train perplexity: 4.850039005279541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4243.902355870457
INFO:root:eval perplexity: 5.562844753265381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5173.135721409574
INFO:root:eval perplexity: 8.292622566223145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/41
 20%|â–ˆâ–ˆ        | 41/200 [2:39:12<10:17:21, 232.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3965.767180266204
INFO:root:current train perplexity4.772414684295654
INFO:root:current mean train loss 3964.5033218503936
INFO:root:current train perplexity4.779677391052246
INFO:root:current mean train loss 3976.338048724876
INFO:root:current train perplexity4.7940826416015625
INFO:root:current mean train loss 3972.5427544736717
INFO:root:current train perplexity4.798938751220703
INFO:root:current mean train loss 3981.410132807926
INFO:root:current train perplexity4.806168079376221
INFO:root:current mean train loss 3979.4880144093927
INFO:root:current train perplexity4.80826473236084
INFO:root:current mean train loss 3986.7810961953
INFO:root:current train perplexity4.817564010620117
INFO:root:current mean train loss 3991.8652384048314
INFO:root:current train perplexity4.820477485656738
INFO:root:current mean train loss 3992.569659490251
INFO:root:current train perplexity4.821203231811523
INFO:root:current mean train loss 3991.8415680096246
INFO:root:current train perplexity4.8213419914245605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.25s/it]
INFO:root:final mean train loss: 3987.8256295111873
INFO:root:final train perplexity: 4.822597503662109
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 12.00s/it]
INFO:root:eval mean loss: 4239.564608959441
INFO:root:eval perplexity: 5.55309534072876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 5174.313273977726
INFO:root:eval perplexity: 8.296616554260254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/42
 21%|â–ˆâ–ˆ        | 42/200 [2:43:05<10:13:21, 232.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3949.2430385044645
INFO:root:current train perplexity4.756711483001709
INFO:root:current mean train loss 3955.4317545572917
INFO:root:current train perplexity4.771961688995361
INFO:root:current mean train loss 3964.2622724817156
INFO:root:current train perplexity4.764654159545898
INFO:root:current mean train loss 3963.9799061333956
INFO:root:current train perplexity4.765829563140869
INFO:root:current mean train loss 3964.290823118714
INFO:root:current train perplexity4.780750274658203
INFO:root:current mean train loss 3966.788859886098
INFO:root:current train perplexity4.785303592681885
INFO:root:current mean train loss 3969.69280265748
INFO:root:current train perplexity4.7883148193359375
INFO:root:current mean train loss 3971.979070339073
INFO:root:current train perplexity4.787106513977051
INFO:root:current mean train loss 3975.034520607223
INFO:root:current train perplexity4.791764259338379
INFO:root:current mean train loss 3977.8084013097427
INFO:root:current train perplexity4.794734954833984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.15s/it]
INFO:root:final mean train loss: 3974.3785351168726
INFO:root:final train perplexity: 4.7970805168151855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4237.367468001995
INFO:root:eval perplexity: 5.548162937164307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5173.669464760638
INFO:root:eval perplexity: 8.294431686401367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/43
 22%|â–ˆâ–ˆâ–       | 43/200 [2:46:57<10:09:23, 232.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3933.6407215207123
INFO:root:current train perplexity4.779205322265625
INFO:root:current mean train loss 3932.437639996722
INFO:root:current train perplexity4.7296881675720215
INFO:root:current mean train loss 3943.058998641654
INFO:root:current train perplexity4.746088027954102
INFO:root:current mean train loss 3950.6208396444517
INFO:root:current train perplexity4.749705791473389
INFO:root:current mean train loss 3959.084894804599
INFO:root:current train perplexity4.7605299949646
INFO:root:current mean train loss 3962.503353224275
INFO:root:current train perplexity4.7701826095581055
INFO:root:current mean train loss 3963.3043909621647
INFO:root:current train perplexity4.769700527191162
INFO:root:current mean train loss 3962.2489600200834
INFO:root:current train perplexity4.765268325805664
INFO:root:current mean train loss 3964.477302162107
INFO:root:current train perplexity4.7706804275512695
INFO:root:current mean train loss 3965.1801895028334
INFO:root:current train perplexity4.772841930389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.14s/it]
INFO:root:final mean train loss: 3961.4296859618157
INFO:root:final train perplexity: 4.772634983062744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.99s/it]
INFO:root:eval mean loss: 4235.396079205452
INFO:root:eval perplexity: 5.543743133544922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5175.846929022607
INFO:root:eval perplexity: 8.301820755004883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/44
 22%|â–ˆâ–ˆâ–       | 44/200 [2:50:50<10:05:25, 232.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3915.915388518689
INFO:root:current train perplexity4.709728240966797
INFO:root:current mean train loss 3931.1550422314776
INFO:root:current train perplexity4.725333213806152
INFO:root:current mean train loss 3949.0241037801916
INFO:root:current train perplexity4.743849277496338
INFO:root:current mean train loss 3952.546077891293
INFO:root:current train perplexity4.744950294494629
INFO:root:current mean train loss 3953.7793066189715
INFO:root:current train perplexity4.749546051025391
INFO:root:current mean train loss 3950.174934511825
INFO:root:current train perplexity4.7450480461120605
INFO:root:current mean train loss 3952.6188878588227
INFO:root:current train perplexity4.749253749847412
INFO:root:current mean train loss 3951.1069212404295
INFO:root:current train perplexity4.746208190917969
INFO:root:current mean train loss 3951.5171308685553
INFO:root:current train perplexity4.7469096183776855
INFO:root:current mean train loss 3950.257429730629
INFO:root:current train perplexity4.748181343078613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.19s/it]
INFO:root:final mean train loss: 3948.5445953492194
INFO:root:final train perplexity: 4.748434543609619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4234.151157676751
INFO:root:eval perplexity: 5.540951728820801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5173.440819273604
INFO:root:eval perplexity: 8.293656349182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:54:43<10:01:34, 232.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3889.739067465572
INFO:root:current train perplexity4.662974834442139
INFO:root:current mean train loss 3907.7447978085693
INFO:root:current train perplexity4.66981315612793
INFO:root:current mean train loss 3899.544210190939
INFO:root:current train perplexity4.674498558044434
INFO:root:current mean train loss 3906.6363834816766
INFO:root:current train perplexity4.686708450317383
INFO:root:current mean train loss 3916.324629906216
INFO:root:current train perplexity4.694028854370117
INFO:root:current mean train loss 3921.6787939191076
INFO:root:current train perplexity4.703474998474121
INFO:root:current mean train loss 3930.3276867323834
INFO:root:current train perplexity4.712366580963135
INFO:root:current mean train loss 3932.578009202075
INFO:root:current train perplexity4.714595794677734
INFO:root:current mean train loss 3932.4629369520335
INFO:root:current train perplexity4.715991020202637
INFO:root:current mean train loss 3936.208769510884
INFO:root:current train perplexity4.719481945037842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it]
INFO:root:final mean train loss: 3934.4998643321373
INFO:root:final train perplexity: 4.722196102142334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4234.360116079344
INFO:root:eval perplexity: 5.5414204597473145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5177.253838721742
INFO:root:eval perplexity: 8.306598663330078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [2:58:38<9:59:11, 233.45s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3908.0093575093283
INFO:root:current train perplexity4.685004711151123
INFO:root:current mean train loss 3900.581480106194
INFO:root:current train perplexity4.681715488433838
INFO:root:current mean train loss 3910.447281169534
INFO:root:current train perplexity4.675374507904053
INFO:root:current mean train loss 3907.415351722156
INFO:root:current train perplexity4.677062511444092
INFO:root:current mean train loss 3917.941363381625
INFO:root:current train perplexity4.691888809204102
INFO:root:current mean train loss 3918.2885987619875
INFO:root:current train perplexity4.6918840408325195
INFO:root:current mean train loss 3917.5134105310626
INFO:root:current train perplexity4.695385932922363
INFO:root:current mean train loss 3919.7329999185135
INFO:root:current train perplexity4.696201801300049
INFO:root:current mean train loss 3922.932224366079
INFO:root:current train perplexity4.6982879638671875
INFO:root:current mean train loss 3923.9945486200877
INFO:root:current train perplexity4.699941635131836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.07s/it]
INFO:root:final mean train loss: 3922.6029932575843
INFO:root:final train perplexity: 4.7000837326049805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4235.499251994681
INFO:root:eval perplexity: 5.543973445892334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5183.316395861038
INFO:root:eval perplexity: 8.327216148376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:02:33<9:56:18, 233.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3936.59228515625
INFO:root:current train perplexity4.674211502075195
INFO:root:current mean train loss 3902.1764899553573
INFO:root:current train perplexity4.6491804122924805
INFO:root:current mean train loss 3890.1979536576705
INFO:root:current train perplexity4.635843276977539
INFO:root:current mean train loss 3895.2343404947915
INFO:root:current train perplexity4.647815227508545
INFO:root:current mean train loss 3901.7533938116776
INFO:root:current train perplexity4.653702259063721
INFO:root:current mean train loss 3903.9281627887226
INFO:root:current train perplexity4.659666538238525
INFO:root:current mean train loss 3908.377800564236
INFO:root:current train perplexity4.670690536499023
INFO:root:current mean train loss 3909.278757560484
INFO:root:current train perplexity4.6697187423706055
INFO:root:current mean train loss 3911.577021205357
INFO:root:current train perplexity4.671901702880859
INFO:root:current mean train loss 3912.253155799279
INFO:root:current train perplexity4.676316261291504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.52s/it]
INFO:root:final mean train loss: 3909.912661952357
INFO:root:final train perplexity: 4.676610469818115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4231.656970301418
INFO:root:eval perplexity: 5.535366535186768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5179.566932624113
INFO:root:eval perplexity: 8.314458847045898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/48
 24%|â–ˆâ–ˆâ–       | 48/200 [3:06:27<9:52:43, 233.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3858.465290850904
INFO:root:current train perplexity4.600279808044434
INFO:root:current mean train loss 3872.760908950222
INFO:root:current train perplexity4.614284515380859
INFO:root:current mean train loss 3868.866069456714
INFO:root:current train perplexity4.6201605796813965
INFO:root:current mean train loss 3876.134109696271
INFO:root:current train perplexity4.624516010284424
INFO:root:current mean train loss 3884.6950627992364
INFO:root:current train perplexity4.633868217468262
INFO:root:current mean train loss 3889.2994508301617
INFO:root:current train perplexity4.636554718017578
INFO:root:current mean train loss 3894.8456602306005
INFO:root:current train perplexity4.643341064453125
INFO:root:current mean train loss 3896.6501355713203
INFO:root:current train perplexity4.646285533905029
INFO:root:current mean train loss 3900.930903226306
INFO:root:current train perplexity4.651760578155518
INFO:root:current mean train loss 3901.259496399733
INFO:root:current train perplexity4.655580043792725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it]
INFO:root:final mean train loss: 3898.4903088846513
INFO:root:final train perplexity: 4.655583381652832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4227.460123697917
INFO:root:eval perplexity: 5.525980472564697
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5178.200416943706
INFO:root:eval perplexity: 8.309815406799316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/49
 24%|â–ˆâ–ˆâ–       | 49/200 [3:10:21<9:48:52, 233.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.845233623798
INFO:root:current train perplexity4.5924811363220215
INFO:root:current mean train loss 3869.051405022906
INFO:root:current train perplexity4.592265605926514
INFO:root:current mean train loss 3866.7925870180948
INFO:root:current train perplexity4.602614402770996
INFO:root:current mean train loss 3868.6652619735055
INFO:root:current train perplexity4.610621929168701
INFO:root:current mean train loss 3873.2032811306644
INFO:root:current train perplexity4.616870403289795
INFO:root:current mean train loss 3877.588064952147
INFO:root:current train perplexity4.618423938751221
INFO:root:current mean train loss 3879.5428980870115
INFO:root:current train perplexity4.620659828186035
INFO:root:current mean train loss 3882.517719485817
INFO:root:current train perplexity4.62309455871582
INFO:root:current mean train loss 3888.6975125056993
INFO:root:current train perplexity4.629756927490234
INFO:root:current mean train loss 3889.4990052070193
INFO:root:current train perplexity4.633429527282715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it]
INFO:root:final mean train loss: 3886.4285481360653
INFO:root:final train perplexity: 4.633481502532959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 4228.713401415669
INFO:root:eval perplexity: 5.528782367706299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5181.868801252216
INFO:root:eval perplexity: 8.322288513183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:14:15<9:45:17, 234.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3873.180205374053
INFO:root:current train perplexity4.596851348876953
INFO:root:current mean train loss 3875.397145640311
INFO:root:current train perplexity4.591261863708496
INFO:root:current mean train loss 3878.5419464621655
INFO:root:current train perplexity4.591686725616455
INFO:root:current mean train loss 3869.3808061413297
INFO:root:current train perplexity4.58978796005249
INFO:root:current mean train loss 3869.869468429046
INFO:root:current train perplexity4.5922956466674805
INFO:root:current mean train loss 3872.427994003678
INFO:root:current train perplexity4.593835353851318
INFO:root:current mean train loss 3876.4528427888054
INFO:root:current train perplexity4.600951671600342
INFO:root:current mean train loss 3873.910113471918
INFO:root:current train perplexity4.60231351852417
INFO:root:current mean train loss 3876.3348851697197
INFO:root:current train perplexity4.607831954956055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.80s/it]
INFO:root:final mean train loss: 3873.8499658646124
INFO:root:final train perplexity: 4.610543727874756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4227.804332543772
INFO:root:eval perplexity: 5.526749610900879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5184.128095910904
INFO:root:eval perplexity: 8.329980850219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:18:10<9:41:38, 234.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3806.528878348214
INFO:root:current train perplexity4.536111831665039
INFO:root:current mean train loss 3859.6377614814546
INFO:root:current train perplexity4.5981059074401855
INFO:root:current mean train loss 3849.91307886096
INFO:root:current train perplexity4.570507526397705
INFO:root:current mean train loss 3848.4312008537763
INFO:root:current train perplexity4.5658063888549805
INFO:root:current mean train loss 3859.37533231918
INFO:root:current train perplexity4.5672383308410645
INFO:root:current mean train loss 3861.102169240015
INFO:root:current train perplexity4.571506977081299
INFO:root:current mean train loss 3863.17770541598
INFO:root:current train perplexity4.576137542724609
INFO:root:current mean train loss 3862.850787603872
INFO:root:current train perplexity4.577825546264648
INFO:root:current mean train loss 3863.7037833023546
INFO:root:current train perplexity4.583968162536621
INFO:root:current mean train loss 3864.057633876275
INFO:root:current train perplexity4.585899829864502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it]
INFO:root:final mean train loss: 3861.2550578578825
INFO:root:final train perplexity: 4.587690830230713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4227.429732518839
INFO:root:eval perplexity: 5.525913715362549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5185.888105676529
INFO:root:eval perplexity: 8.335978507995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:22:04<9:37:40, 234.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3938.2667154947917
INFO:root:current train perplexity4.574994087219238
INFO:root:current mean train loss 3851.098615828804
INFO:root:current train perplexity4.540003776550293
INFO:root:current mean train loss 3847.0972735737646
INFO:root:current train perplexity4.542386054992676
INFO:root:current mean train loss 3841.486328125
INFO:root:current train perplexity4.539770603179932
INFO:root:current mean train loss 3847.052804381589
INFO:root:current train perplexity4.544581890106201
INFO:root:current mean train loss 3853.6536659018507
INFO:root:current train perplexity4.555808067321777
INFO:root:current mean train loss 3856.200920191819
INFO:root:current train perplexity4.5580902099609375
INFO:root:current mean train loss 3854.899296601836
INFO:root:current train perplexity4.561508655548096
INFO:root:current mean train loss 3856.500647347105
INFO:root:current train perplexity4.567088603973389
INFO:root:current mean train loss 3854.919139824539
INFO:root:current train perplexity4.56854772567749

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.04s/it]
INFO:root:final mean train loss: 3851.0036319609612
INFO:root:final train perplexity: 4.569173336029053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4226.80208160184
INFO:root:eval perplexity: 5.524511337280273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5186.458767938276
INFO:root:eval perplexity: 8.33792495727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [3:25:58<9:33:25, 234.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3809.110064962636
INFO:root:current train perplexity4.4687676429748535
INFO:root:current mean train loss 3829.990299876143
INFO:root:current train perplexity4.5182342529296875
INFO:root:current mean train loss 3812.03703383373
INFO:root:current train perplexity4.510670185089111
INFO:root:current mean train loss 3820.1575273921244
INFO:root:current train perplexity4.516481876373291
INFO:root:current mean train loss 3824.421258588209
INFO:root:current train perplexity4.52461051940918
INFO:root:current mean train loss 3828.3256807929015
INFO:root:current train perplexity4.532289028167725
INFO:root:current mean train loss 3828.96261670157
INFO:root:current train perplexity4.532954216003418
INFO:root:current mean train loss 3831.6158540126858
INFO:root:current train perplexity4.536311149597168
INFO:root:current mean train loss 3834.8197417508354
INFO:root:current train perplexity4.540122032165527
INFO:root:current mean train loss 3838.262941304679
INFO:root:current train perplexity4.543849945068359

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.45s/it]
INFO:root:final mean train loss: 3838.9863629494944
INFO:root:final train perplexity: 4.547561168670654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 4227.711159131206
INFO:root:eval perplexity: 5.526541233062744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5188.045737408577
INFO:root:eval perplexity: 8.343335151672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:29:52<9:29:35, 234.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3830.263734879032
INFO:root:current train perplexity4.502590179443359
INFO:root:current mean train loss 3802.1320670324426
INFO:root:current train perplexity4.502448558807373
INFO:root:current mean train loss 3806.5394630597266
INFO:root:current train perplexity4.499419689178467
INFO:root:current mean train loss 3811.022635745138
INFO:root:current train perplexity4.504491329193115
INFO:root:current mean train loss 3811.8191744988035
INFO:root:current train perplexity4.50093936920166
INFO:root:current mean train loss 3815.5334146215864
INFO:root:current train perplexity4.507295608520508
INFO:root:current mean train loss 3819.079948123019
INFO:root:current train perplexity4.513979911804199
INFO:root:current mean train loss 3824.8072862116323
INFO:root:current train perplexity4.522372722625732
INFO:root:current mean train loss 3828.976852472078
INFO:root:current train perplexity4.525693893432617
INFO:root:current mean train loss 3829.8658805216164
INFO:root:current train perplexity4.526455879211426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.64s/it]
INFO:root:final mean train loss: 3827.9593043173513
INFO:root:final train perplexity: 4.527820587158203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4225.959261414007
INFO:root:eval perplexity: 5.522627830505371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5193.530723625887
INFO:root:eval perplexity: 8.36207103729248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:33:46<9:25:53, 234.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3762.652600410657
INFO:root:current train perplexity4.460366725921631
INFO:root:current mean train loss 3786.051541774393
INFO:root:current train perplexity4.483410358428955
INFO:root:current mean train loss 3794.5184372139774
INFO:root:current train perplexity4.472186088562012
INFO:root:current mean train loss 3803.409209935011
INFO:root:current train perplexity4.4821858406066895
INFO:root:current mean train loss 3805.2509576541142
INFO:root:current train perplexity4.485660076141357
INFO:root:current mean train loss 3812.35057325487
INFO:root:current train perplexity4.495501518249512
INFO:root:current mean train loss 3816.649723154465
INFO:root:current train perplexity4.498994827270508
INFO:root:current mean train loss 3817.5779591561654
INFO:root:current train perplexity4.501324653625488
INFO:root:current mean train loss 3816.429706123361
INFO:root:current train perplexity4.504610538482666
INFO:root:current mean train loss 3818.309829273163
INFO:root:current train perplexity4.506917953491211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.06s/it]
INFO:root:final mean train loss: 3816.293755931239
INFO:root:final train perplexity: 4.507030010223389
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4227.547482754322
INFO:root:eval perplexity: 5.526176929473877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5191.80356029754
INFO:root:eval perplexity: 8.356167793273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:37:41<9:22:24, 234.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3782.420368600399
INFO:root:current train perplexity4.472908020019531
INFO:root:current mean train loss 3787.1693140146685
INFO:root:current train perplexity4.455846309661865
INFO:root:current mean train loss 3801.3259475028467
INFO:root:current train perplexity4.462568283081055
INFO:root:current mean train loss 3799.639479579431
INFO:root:current train perplexity4.467692852020264
INFO:root:current mean train loss 3799.882771536808
INFO:root:current train perplexity4.479215145111084
INFO:root:current mean train loss 3802.0393762675676
INFO:root:current train perplexity4.484086036682129
INFO:root:current mean train loss 3801.6152438085637
INFO:root:current train perplexity4.485293865203857
INFO:root:current mean train loss 3806.372294843436
INFO:root:current train perplexity4.487010955810547
INFO:root:current mean train loss 3807.569899738046
INFO:root:current train perplexity4.4848551750183105
INFO:root:current mean train loss 3809.3686837958685
INFO:root:current train perplexity4.489560604095459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it]
INFO:root:final mean train loss: 3805.882423954625
INFO:root:final train perplexity: 4.488554000854492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4228.038401069371
INFO:root:eval perplexity: 5.527272701263428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5198.225404130651
INFO:root:eval perplexity: 8.378137588500977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:41:35<9:18:15, 234.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3823.68583984375
INFO:root:current train perplexity4.474692344665527
INFO:root:current mean train loss 3791.6893113659276
INFO:root:current train perplexity4.444156646728516
INFO:root:current mean train loss 3783.7381673177083
INFO:root:current train perplexity4.4417724609375
INFO:root:current mean train loss 3779.5480510013203
INFO:root:current train perplexity4.438426971435547
INFO:root:current mean train loss 3788.834439925309
INFO:root:current train perplexity4.447466850280762
INFO:root:current mean train loss 3794.0936892947634
INFO:root:current train perplexity4.453786373138428
INFO:root:current mean train loss 3794.0910145067987
INFO:root:current train perplexity4.459105014801025
INFO:root:current mean train loss 3791.108227054015
INFO:root:current train perplexity4.458570957183838
INFO:root:current mean train loss 3795.9127869723134
INFO:root:current train perplexity4.462960243225098
INFO:root:current mean train loss 3800.594078758999
INFO:root:current train perplexity4.469309329986572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it]
INFO:root:final mean train loss: 3795.2620552432154
INFO:root:final train perplexity: 4.469786643981934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4225.524793259641
INFO:root:eval perplexity: 5.521658897399902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5198.731611535904
INFO:root:eval perplexity: 8.379873275756836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:45:29<9:14:12, 234.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3742.3136276971727
INFO:root:current train perplexity4.399331092834473
INFO:root:current mean train loss 3771.443548097201
INFO:root:current train perplexity4.41921329498291
INFO:root:current mean train loss 3770.214490070996
INFO:root:current train perplexity4.417013168334961
INFO:root:current mean train loss 3782.0235753755596
INFO:root:current train perplexity4.433963775634766
INFO:root:current mean train loss 3781.375880593615
INFO:root:current train perplexity4.435747146606445
INFO:root:current mean train loss 3783.769251984347
INFO:root:current train perplexity4.442689895629883
INFO:root:current mean train loss 3785.63978542138
INFO:root:current train perplexity4.4413933753967285
INFO:root:current mean train loss 3785.0284908589656
INFO:root:current train perplexity4.4455342292785645
INFO:root:current mean train loss 3783.5766307349
INFO:root:current train perplexity4.449028968811035
INFO:root:current mean train loss 3786.4553608008014
INFO:root:current train perplexity4.450319766998291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it]
INFO:root:final mean train loss: 3785.0795856598884
INFO:root:final train perplexity: 4.45186710357666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4225.120395958001
INFO:root:eval perplexity: 5.520755290985107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5198.565296362478
INFO:root:eval perplexity: 8.379302024841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [3:49:23<9:10:11, 234.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3746.761278609155
INFO:root:current train perplexity4.380158424377441
INFO:root:current mean train loss 3741.4327728093017
INFO:root:current train perplexity4.401011943817139
INFO:root:current mean train loss 3759.587560900023
INFO:root:current train perplexity4.4104132652282715
INFO:root:current mean train loss 3765.5583377642774
INFO:root:current train perplexity4.417975902557373
INFO:root:current mean train loss 3767.3341087778663
INFO:root:current train perplexity4.421416759490967
INFO:root:current mean train loss 3765.02459663351
INFO:root:current train perplexity4.423918724060059
INFO:root:current mean train loss 3768.5624305054257
INFO:root:current train perplexity4.424414157867432
INFO:root:current mean train loss 3771.728453244062
INFO:root:current train perplexity4.426308631896973
INFO:root:current mean train loss 3774.8204100441303
INFO:root:current train perplexity4.429695129394531
INFO:root:current mean train loss 3778.3291935866696
INFO:root:current train perplexity4.434115886688232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it]
INFO:root:final mean train loss: 3774.746220434866
INFO:root:final train perplexity: 4.433753967285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4227.023402870124
INFO:root:eval perplexity: 5.5250043869018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5204.122506648936
INFO:root:eval perplexity: 8.39836597442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [3:53:17<9:06:18, 234.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3732.5698767553404
INFO:root:current train perplexity4.380214214324951
INFO:root:current mean train loss 3750.179021909916
INFO:root:current train perplexity4.391354560852051
INFO:root:current mean train loss 3754.120385829693
INFO:root:current train perplexity4.40552282333374
INFO:root:current mean train loss 3758.2824011327093
INFO:root:current train perplexity4.403534412384033
INFO:root:current mean train loss 3762.2884391513894
INFO:root:current train perplexity4.412096977233887
INFO:root:current mean train loss 3765.178546068788
INFO:root:current train perplexity4.408689498901367
INFO:root:current mean train loss 3769.5707871180043
INFO:root:current train perplexity4.409093856811523
INFO:root:current mean train loss 3768.5258033762234
INFO:root:current train perplexity4.412684440612793
INFO:root:current mean train loss 3767.873313513225
INFO:root:current train perplexity4.413867950439453
INFO:root:current mean train loss 3767.19955615783
INFO:root:current train perplexity4.41461706161499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it]
INFO:root:final mean train loss: 3764.421000142251
INFO:root:final train perplexity: 4.41572904586792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4228.811059397163
INFO:root:eval perplexity: 5.5289998054504395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5210.9250973099515
INFO:root:eval perplexity: 8.421757698059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [3:57:11<9:02:09, 234.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.3971326104524
INFO:root:current train perplexity4.351771831512451
INFO:root:current mean train loss 3728.8039354946523
INFO:root:current train perplexity4.368180274963379
INFO:root:current mean train loss 3735.9169556089396
INFO:root:current train perplexity4.368622779846191
INFO:root:current mean train loss 3745.723458065851
INFO:root:current train perplexity4.383234024047852
INFO:root:current mean train loss 3751.6221770926913
INFO:root:current train perplexity4.389259338378906
INFO:root:current mean train loss 3753.1464444474022
INFO:root:current train perplexity4.386809825897217
INFO:root:current mean train loss 3757.2699605394832
INFO:root:current train perplexity4.391823768615723
INFO:root:current mean train loss 3756.2231535275373
INFO:root:current train perplexity4.392301559448242
INFO:root:current mean train loss 3756.5797310434577
INFO:root:current train perplexity4.395149230957031
INFO:root:current mean train loss 3756.921001090346
INFO:root:current train perplexity4.397089958190918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it]
INFO:root:final mean train loss: 3753.599777283207
INFO:root:final train perplexity: 4.396917343139648
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4233.131996966423
INFO:root:eval perplexity: 5.538669586181641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5211.192550767398
INFO:root:eval perplexity: 8.42268180847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:01:05<8:58:08, 233.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3713.376326069079
INFO:root:current train perplexity4.333930015563965
INFO:root:current mean train loss 3714.128754757612
INFO:root:current train perplexity4.35751485824585
INFO:root:current mean train loss 3736.3126655190677
INFO:root:current train perplexity4.368307590484619
INFO:root:current mean train loss 3735.2431313043908
INFO:root:current train perplexity4.366269111633301
INFO:root:current mean train loss 3735.959494357639
INFO:root:current train perplexity4.36786413192749
INFO:root:current mean train loss 3742.881859736082
INFO:root:current train perplexity4.3748250007629395
INFO:root:current mean train loss 3746.806460066322
INFO:root:current train perplexity4.377993106842041
INFO:root:current mean train loss 3745.105784443789
INFO:root:current train perplexity4.3762125968933105
INFO:root:current mean train loss 3745.029063372905
INFO:root:current train perplexity4.3780927658081055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it]
INFO:root:final mean train loss: 3743.1558641003026
INFO:root:final train perplexity: 4.378838062286377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4228.734033895723
INFO:root:eval perplexity: 5.5288286209106445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5210.522895542443
INFO:root:eval perplexity: 8.420376777648926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:05:00<8:54:53, 234.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3633.794189453125
INFO:root:current train perplexity4.220218181610107
INFO:root:current mean train loss 3698.989464028368
INFO:root:current train perplexity4.318678379058838
INFO:root:current mean train loss 3708.4432727832514
INFO:root:current train perplexity4.3218302726745605
INFO:root:current mean train loss 3711.2744769105816
INFO:root:current train perplexity4.3270792961120605
INFO:root:current mean train loss 3719.0511671496974
INFO:root:current train perplexity4.3371076583862305
INFO:root:current mean train loss 3722.9310509016213
INFO:root:current train perplexity4.347649097442627
INFO:root:current mean train loss 3723.653817905913
INFO:root:current train perplexity4.349921703338623
INFO:root:current mean train loss 3726.697410789696
INFO:root:current train perplexity4.3549675941467285
INFO:root:current mean train loss 3733.6987335091067
INFO:root:current train perplexity4.359818458557129
INFO:root:current mean train loss 3737.1860381302777
INFO:root:current train perplexity4.361588478088379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.37s/it]
INFO:root:final mean train loss: 3734.213682051628
INFO:root:final train perplexity: 4.36341667175293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4230.138990469858
INFO:root:eval perplexity: 5.531970500946045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5217.961417123781
INFO:root:eval perplexity: 8.446026802062988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:08:54<8:50:52, 234.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3700.4084028764205
INFO:root:current train perplexity4.341431617736816
INFO:root:current mean train loss 3732.1630595439187
INFO:root:current train perplexity4.331610679626465
INFO:root:current mean train loss 3723.035009302799
INFO:root:current train perplexity4.32705545425415
INFO:root:current mean train loss 3723.0030874761355
INFO:root:current train perplexity4.326460361480713
INFO:root:current mean train loss 3720.5307005350896
INFO:root:current train perplexity4.329781532287598
INFO:root:current mean train loss 3719.6839807439455
INFO:root:current train perplexity4.331325054168701
INFO:root:current mean train loss 3727.600112040968
INFO:root:current train perplexity4.336638450622559
INFO:root:current mean train loss 3729.090457020262
INFO:root:current train perplexity4.342844486236572
INFO:root:current mean train loss 3730.7006781750924
INFO:root:current train perplexity4.342878341674805
INFO:root:current mean train loss 3728.446842197791
INFO:root:current train perplexity4.34590482711792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.31s/it]
INFO:root:final mean train loss: 3724.936144059704
INFO:root:final train perplexity: 4.347474575042725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4230.172668024158
INFO:root:eval perplexity: 5.532045841217041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5219.027400889295
INFO:root:eval perplexity: 8.449707984924316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:12:48<8:46:46, 234.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3654.070865028783
INFO:root:current train perplexity4.262846946716309
INFO:root:current mean train loss 3683.4431788340335
INFO:root:current train perplexity4.300144672393799
INFO:root:current mean train loss 3699.8404591181506
INFO:root:current train perplexity4.304126262664795
INFO:root:current mean train loss 3703.263536411393
INFO:root:current train perplexity4.314485549926758
INFO:root:current mean train loss 3705.227881092445
INFO:root:current train perplexity4.318718910217285
INFO:root:current mean train loss 3708.0552778593146
INFO:root:current train perplexity4.315152168273926
INFO:root:current mean train loss 3709.5278576679875
INFO:root:current train perplexity4.320133686065674
INFO:root:current mean train loss 3707.9030001113742
INFO:root:current train perplexity4.32130765914917
INFO:root:current mean train loss 3709.5762562361683
INFO:root:current train perplexity4.323581695556641
INFO:root:current mean train loss 3714.194870177758
INFO:root:current train perplexity4.326695442199707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.72s/it]
INFO:root:final mean train loss: 3713.8373681345292
INFO:root:final train perplexity: 4.328479290008545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4231.501942736038
INFO:root:eval perplexity: 5.535019397735596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5221.807414602726
INFO:root:eval perplexity: 8.459321022033691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:16:41<8:42:19, 233.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3654.551115813079
INFO:root:current train perplexity4.257696151733398
INFO:root:current mean train loss 3686.073678564838
INFO:root:current train perplexity4.3014936447143555
INFO:root:current mean train loss 3689.638961187018
INFO:root:current train perplexity4.3052592277526855
INFO:root:current mean train loss 3694.172294593368
INFO:root:current train perplexity4.314468860626221
INFO:root:current mean train loss 3703.8259717597334
INFO:root:current train perplexity4.318615913391113
INFO:root:current mean train loss 3703.0119730824536
INFO:root:current train perplexity4.310914993286133
INFO:root:current mean train loss 3705.4235357013804
INFO:root:current train perplexity4.315361499786377
INFO:root:current mean train loss 3705.158070812199
INFO:root:current train perplexity4.313737869262695
INFO:root:current mean train loss 3708.1147452081127
INFO:root:current train perplexity4.314722061157227
INFO:root:current mean train loss 3707.091554841306
INFO:root:current train perplexity4.314486980438232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.40s/it]
INFO:root:final mean train loss: 3704.5803817010697
INFO:root:final train perplexity: 4.312700271606445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4233.359536028923
INFO:root:eval perplexity: 5.539179801940918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5226.35659595246
INFO:root:eval perplexity: 8.475069046020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:20:35<8:38:33, 233.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3734.4275530133928
INFO:root:current train perplexity4.267395496368408
INFO:root:current mean train loss 3689.078889973958
INFO:root:current train perplexity4.2756476402282715
INFO:root:current mean train loss 3682.5515791223406
INFO:root:current train perplexity4.262279510498047
INFO:root:current mean train loss 3688.0212190998136
INFO:root:current train perplexity4.274461269378662
INFO:root:current mean train loss 3687.978243983477
INFO:root:current train perplexity4.277471542358398
INFO:root:current mean train loss 3691.397693213347
INFO:root:current train perplexity4.283565521240234
INFO:root:current mean train loss 3696.3816852239174
INFO:root:current train perplexity4.287912368774414
INFO:root:current mean train loss 3695.2465089551447
INFO:root:current train perplexity4.287852764129639
INFO:root:current mean train loss 3696.7375578920282
INFO:root:current train perplexity4.293614387512207
INFO:root:current mean train loss 3695.7409696691175
INFO:root:current train perplexity4.294225692749023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.66s/it]
INFO:root:final mean train loss: 3695.018108183338
INFO:root:final train perplexity: 4.2964606285095215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4235.568956740359
INFO:root:eval perplexity: 5.544130802154541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5227.450827307735
INFO:root:eval perplexity: 8.478862762451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [4:24:30<8:34:57, 234.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.6723008266713
INFO:root:current train perplexity4.210665225982666
INFO:root:current mean train loss 3653.273020924388
INFO:root:current train perplexity4.233985900878906
INFO:root:current mean train loss 3673.0737515673227
INFO:root:current train perplexity4.249264717102051
INFO:root:current mean train loss 3673.952453791226
INFO:root:current train perplexity4.2550153732299805
INFO:root:current mean train loss 3678.9893454385933
INFO:root:current train perplexity4.256383419036865
INFO:root:current mean train loss 3682.421370532631
INFO:root:current train perplexity4.260585308074951
INFO:root:current mean train loss 3685.1714387362704
INFO:root:current train perplexity4.269522190093994
INFO:root:current mean train loss 3686.3679803820028
INFO:root:current train perplexity4.273583889007568
INFO:root:current mean train loss 3686.225248542686
INFO:root:current train perplexity4.275787353515625
INFO:root:current mean train loss 3688.403693384229
INFO:root:current train perplexity4.280033111572266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.04s/it]
INFO:root:final mean train loss: 3686.6008967122725
INFO:root:final train perplexity: 4.282216548919678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4232.958387009641
INFO:root:eval perplexity: 5.538281440734863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5229.352004030918
INFO:root:eval perplexity: 8.485457420349121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [4:28:23<8:30:49, 233.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3619.0743815104165
INFO:root:current train perplexity4.171533107757568
INFO:root:current mean train loss 3645.9397587049875
INFO:root:current train perplexity4.212990760803223
INFO:root:current mean train loss 3651.0226301823955
INFO:root:current train perplexity4.231747150421143
INFO:root:current mean train loss 3662.402259587562
INFO:root:current train perplexity4.240650653839111
INFO:root:current mean train loss 3669.7887447382554
INFO:root:current train perplexity4.246881008148193
INFO:root:current mean train loss 3673.6773701579514
INFO:root:current train perplexity4.252207279205322
INFO:root:current mean train loss 3672.2531562019967
INFO:root:current train perplexity4.254082679748535
INFO:root:current mean train loss 3673.4776726734144
INFO:root:current train perplexity4.256119728088379
INFO:root:current mean train loss 3677.3295100892333
INFO:root:current train perplexity4.261256694793701
INFO:root:current mean train loss 3678.8434678648296
INFO:root:current train perplexity4.265052318572998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.00s/it]
INFO:root:final mean train loss: 3677.1390435618737
INFO:root:final train perplexity: 4.266260623931885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4236.095761995789
INFO:root:eval perplexity: 5.545310974121094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5234.887563718971
INFO:root:eval perplexity: 8.504688262939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [4:32:17<8:26:43, 233.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3631.3330947100108
INFO:root:current train perplexity4.217952251434326
INFO:root:current mean train loss 3664.3353064195167
INFO:root:current train perplexity4.24295711517334
INFO:root:current mean train loss 3669.0560627941
INFO:root:current train perplexity4.25928258895874
INFO:root:current mean train loss 3669.5957065252874
INFO:root:current train perplexity4.253305435180664
INFO:root:current mean train loss 3674.58457531233
INFO:root:current train perplexity4.255054950714111
INFO:root:current mean train loss 3673.4795100940573
INFO:root:current train perplexity4.252420902252197
INFO:root:current mean train loss 3670.552046409688
INFO:root:current train perplexity4.254887580871582
INFO:root:current mean train loss 3670.116231202137
INFO:root:current train perplexity4.256806373596191
INFO:root:current mean train loss 3670.163664030668
INFO:root:current train perplexity4.254550457000732
INFO:root:current mean train loss 3670.1045130629236
INFO:root:current train perplexity4.252850532531738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it]
INFO:root:final mean train loss: 3669.3869476933633
INFO:root:final train perplexity: 4.253232955932617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4237.00875270113
INFO:root:eval perplexity: 5.547359466552734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5236.659200465426
INFO:root:eval perplexity: 8.510852813720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [4:36:11<8:23:05, 233.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3615.2061093458487
INFO:root:current train perplexity4.199202060699463
INFO:root:current mean train loss 3637.81624397689
INFO:root:current train perplexity4.208415508270264
INFO:root:current mean train loss 3646.4841985238177
INFO:root:current train perplexity4.219104766845703
INFO:root:current mean train loss 3651.1829797396545
INFO:root:current train perplexity4.220803737640381
INFO:root:current mean train loss 3649.423821328794
INFO:root:current train perplexity4.219111442565918
INFO:root:current mean train loss 3652.1260557897926
INFO:root:current train perplexity4.2209858894348145
INFO:root:current mean train loss 3652.5264085486556
INFO:root:current train perplexity4.224330902099609
INFO:root:current mean train loss 3657.542115690189
INFO:root:current train perplexity4.229722499847412
INFO:root:current mean train loss 3660.05230438338
INFO:root:current train perplexity4.230271816253662
INFO:root:current mean train loss 3661.6588598052126
INFO:root:current train perplexity4.235164165496826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.02s/it]
INFO:root:final mean train loss: 3659.2767968946887
INFO:root:final train perplexity: 4.236301898956299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4238.907200590093
INFO:root:eval perplexity: 5.551618576049805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5239.862356632314
INFO:root:eval perplexity: 8.522004127502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [4:40:06<8:19:38, 234.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3667.891331380208
INFO:root:current train perplexity4.182179927825928
INFO:root:current mean train loss 3651.2578306361606
INFO:root:current train perplexity4.205941200256348
INFO:root:current mean train loss 3661.710549538352
INFO:root:current train perplexity4.217960357666016
INFO:root:current mean train loss 3654.948453776042
INFO:root:current train perplexity4.212646007537842
INFO:root:current mean train loss 3652.948715049342
INFO:root:current train perplexity4.213596343994141
INFO:root:current mean train loss 3654.032146314538
INFO:root:current train perplexity4.216499328613281
INFO:root:current mean train loss 3649.929176070602
INFO:root:current train perplexity4.212813377380371
INFO:root:current mean train loss 3652.424008001512
INFO:root:current train perplexity4.216527462005615
INFO:root:current mean train loss 3651.068285435268
INFO:root:current train perplexity4.215015411376953
INFO:root:current mean train loss 3651.6096211438303
INFO:root:current train perplexity4.219164848327637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it]
INFO:root:final mean train loss: 3650.1788672170333
INFO:root:final train perplexity: 4.221122741699219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4240.66879467254
INFO:root:eval perplexity: 5.555575370788574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5246.036375221631
INFO:root:eval perplexity: 8.543548583984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [4:44:00<8:15:47, 234.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3639.2106668862953
INFO:root:current train perplexity4.1704559326171875
INFO:root:current mean train loss 3639.3596031314037
INFO:root:current train perplexity4.190545558929443
INFO:root:current mean train loss 3641.7608612384056
INFO:root:current train perplexity4.193822383880615
INFO:root:current mean train loss 3637.480524207531
INFO:root:current train perplexity4.191443920135498
INFO:root:current mean train loss 3639.911148481981
INFO:root:current train perplexity4.194065570831299
INFO:root:current mean train loss 3640.091019226388
INFO:root:current train perplexity4.2014312744140625
INFO:root:current mean train loss 3642.715469293329
INFO:root:current train perplexity4.2015275955200195
INFO:root:current mean train loss 3643.352153675766
INFO:root:current train perplexity4.204396724700928
INFO:root:current mean train loss 3643.4739004547705
INFO:root:current train perplexity4.206110000610352
INFO:root:current mean train loss 3646.038638793076
INFO:root:current train perplexity4.209499835968018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.41s/it]
INFO:root:final mean train loss: 3643.592372094431
INFO:root:final train perplexity: 4.21016788482666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4242.209701213431
INFO:root:eval perplexity: 5.559039115905762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5247.730998587101
INFO:root:eval perplexity: 8.549469947814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [4:47:54<8:11:46, 234.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3643.185283954327
INFO:root:current train perplexity4.184225559234619
INFO:root:current mean train loss 3636.716178214987
INFO:root:current train perplexity4.174671649932861
INFO:root:current mean train loss 3635.4316808956187
INFO:root:current train perplexity4.17897891998291
INFO:root:current mean train loss 3639.7516390515107
INFO:root:current train perplexity4.1790771484375
INFO:root:current mean train loss 3643.0710205575356
INFO:root:current train perplexity4.184295177459717
INFO:root:current mean train loss 3640.3419030410587
INFO:root:current train perplexity4.186887741088867
INFO:root:current mean train loss 3642.034552788079
INFO:root:current train perplexity4.189250946044922
INFO:root:current mean train loss 3637.168271533759
INFO:root:current train perplexity4.185831069946289
INFO:root:current mean train loss 3636.2742093789457
INFO:root:current train perplexity4.188351154327393
INFO:root:current mean train loss 3635.7534125488773
INFO:root:current train perplexity4.192443370819092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.25s/it]
INFO:root:final mean train loss: 3632.925131274808
INFO:root:final train perplexity: 4.1924872398376465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4244.5852085411125
INFO:root:eval perplexity: 5.564380168914795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5253.402700437721
INFO:root:eval perplexity: 8.569319725036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [4:51:48<8:07:45, 234.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.072729245581
INFO:root:current train perplexity4.153517246246338
INFO:root:current mean train loss 3603.3913267509424
INFO:root:current train perplexity4.150473594665527
INFO:root:current mean train loss 3599.6849083533652
INFO:root:current train perplexity4.156793594360352
INFO:root:current mean train loss 3611.4217709801846
INFO:root:current train perplexity4.168071746826172
INFO:root:current mean train loss 3611.20331581131
INFO:root:current train perplexity4.170775890350342
INFO:root:current mean train loss 3618.5529381651713
INFO:root:current train perplexity4.177628993988037
INFO:root:current mean train loss 3621.557804047635
INFO:root:current train perplexity4.178469657897949
INFO:root:current mean train loss 3623.8176737034573
INFO:root:current train perplexity4.179748058319092
INFO:root:current mean train loss 3625.593726645057
INFO:root:current train perplexity4.180044174194336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it]
INFO:root:final mean train loss: 3625.7526301722373
INFO:root:final train perplexity: 4.18064022064209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4245.470275446033
INFO:root:eval perplexity: 5.566373348236084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5257.803082405253
INFO:root:eval perplexity: 8.584754943847656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [4:55:43<8:04:07, 234.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.423583984375
INFO:root:current train perplexity4.037134647369385
INFO:root:current mean train loss 3602.8594753942757
INFO:root:current train perplexity4.133836269378662
INFO:root:current mean train loss 3610.6446975486865
INFO:root:current train perplexity4.143802165985107
INFO:root:current mean train loss 3610.5536743561684
INFO:root:current train perplexity4.149580001831055
INFO:root:current mean train loss 3608.185108981496
INFO:root:current train perplexity4.147998332977295
INFO:root:current mean train loss 3617.8887850368283
INFO:root:current train perplexity4.153723239898682
INFO:root:current mean train loss 3616.127854072282
INFO:root:current train perplexity4.156918525695801
INFO:root:current mean train loss 3617.4079544952265
INFO:root:current train perplexity4.161883354187012
INFO:root:current mean train loss 3616.48270322665
INFO:root:current train perplexity4.160637855529785
INFO:root:current mean train loss 3616.781195626895
INFO:root:current train perplexity4.163905143737793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.94s/it]
INFO:root:final mean train loss: 3617.9980087895547
INFO:root:final train perplexity: 4.1678690910339355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4245.8742641151375
INFO:root:eval perplexity: 5.567281723022461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5257.407891456117
INFO:root:eval perplexity: 8.583367347717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [4:59:37<8:00:28, 234.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3625.736149088542
INFO:root:current train perplexity4.210760593414307
INFO:root:current mean train loss 3626.9191852072013
INFO:root:current train perplexity4.144302845001221
INFO:root:current mean train loss 3624.4560932957847
INFO:root:current train perplexity4.142580986022949
INFO:root:current mean train loss 3614.729814608135
INFO:root:current train perplexity4.137509346008301
INFO:root:current mean train loss 3607.7581866528612
INFO:root:current train perplexity4.135711193084717
INFO:root:current mean train loss 3604.2761367945996
INFO:root:current train perplexity4.140338897705078
INFO:root:current mean train loss 3606.8660116552337
INFO:root:current train perplexity4.141720294952393
INFO:root:current mean train loss 3607.973662177666
INFO:root:current train perplexity4.1458964347839355
INFO:root:current mean train loss 3605.2945195671973
INFO:root:current train perplexity4.145938873291016
INFO:root:current mean train loss 3607.360640795765
INFO:root:current train perplexity4.148857593536377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.30s/it]
INFO:root:final mean train loss: 3608.331961724066
INFO:root:final train perplexity: 4.152005195617676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4250.392763394836
INFO:root:eval perplexity: 5.577462196350098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5263.875460577349
INFO:root:eval perplexity: 8.606098175048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:03:31<7:56:21, 234.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3627.5338612432065
INFO:root:current train perplexity4.1396050453186035
INFO:root:current mean train loss 3586.2980877635923
INFO:root:current train perplexity4.1165571212768555
INFO:root:current mean train loss 3584.7657027308715
INFO:root:current train perplexity4.1151041984558105
INFO:root:current mean train loss 3590.868018938661
INFO:root:current train perplexity4.112407207489014
INFO:root:current mean train loss 3588.511914408799
INFO:root:current train perplexity4.111550331115723
INFO:root:current mean train loss 3590.200791893224
INFO:root:current train perplexity4.117873668670654
INFO:root:current mean train loss 3590.1370040379215
INFO:root:current train perplexity4.120885372161865
INFO:root:current mean train loss 3594.444589533087
INFO:root:current train perplexity4.125387191772461
INFO:root:current mean train loss 3596.352927373652
INFO:root:current train perplexity4.128416538238525
INFO:root:current mean train loss 3602.157342681389
INFO:root:current train perplexity4.136315822601318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.45s/it]
INFO:root:final mean train loss: 3598.82836784855
INFO:root:final train perplexity: 4.1364665031433105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4250.083740234375
INFO:root:eval perplexity: 5.576766490936279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5267.916914270279
INFO:root:eval perplexity: 8.620333671569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:07:26<7:52:20, 234.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3606.1360729586695
INFO:root:current train perplexity4.130900859832764
INFO:root:current mean train loss 3572.2083637732585
INFO:root:current train perplexity4.100625991821289
INFO:root:current mean train loss 3586.9586070667615
INFO:root:current train perplexity4.113437175750732
INFO:root:current mean train loss 3585.4628780860553
INFO:root:current train perplexity4.114678859710693
INFO:root:current mean train loss 3582.525833590125
INFO:root:current train perplexity4.112656116485596
INFO:root:current mean train loss 3587.0797457075387
INFO:root:current train perplexity4.115108966827393
INFO:root:current mean train loss 3589.134185645924
INFO:root:current train perplexity4.120587348937988
INFO:root:current mean train loss 3592.673525537577
INFO:root:current train perplexity4.122128963470459
INFO:root:current mean train loss 3595.130560001598
INFO:root:current train perplexity4.123738765716553
INFO:root:current mean train loss 3594.9325550378458
INFO:root:current train perplexity4.123795509338379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it]
INFO:root:final mean train loss: 3592.4469266091623
INFO:root:final train perplexity: 4.126065254211426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4250.083035516401
INFO:root:eval perplexity: 5.576764106750488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5269.391655238807
INFO:root:eval perplexity: 8.625531196594238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:11:21<7:49:00, 234.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3557.777118389423
INFO:root:current train perplexity4.085634231567383
INFO:root:current mean train loss 3570.1410974735836
INFO:root:current train perplexity4.092612266540527
INFO:root:current mean train loss 3576.2112357805963
INFO:root:current train perplexity4.0937981605529785
INFO:root:current mean train loss 3577.940951817155
INFO:root:current train perplexity4.097173690795898
INFO:root:current mean train loss 3576.133541028972
INFO:root:current train perplexity4.104709148406982
INFO:root:current mean train loss 3580.853928716373
INFO:root:current train perplexity4.106808662414551
INFO:root:current mean train loss 3583.5085040407375
INFO:root:current train perplexity4.109130859375
INFO:root:current mean train loss 3584.1437588538142
INFO:root:current train perplexity4.106845855712891
INFO:root:current mean train loss 3583.0586676614644
INFO:root:current train perplexity4.109231948852539
INFO:root:current mean train loss 3587.2883201981
INFO:root:current train perplexity4.112951278686523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.71s/it]
INFO:root:final mean train loss: 3585.14422065981
INFO:root:final train perplexity: 4.114194869995117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4254.841989070811
INFO:root:eval perplexity: 5.587507247924805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5275.347574869792
INFO:root:eval perplexity: 8.646565437316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [5:15:15<7:45:01, 234.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.032943400931
INFO:root:current train perplexity4.101424694061279
INFO:root:current mean train loss 3552.867200786565
INFO:root:current train perplexity4.073933124542236
INFO:root:current mean train loss 3552.8908632100834
INFO:root:current train perplexity4.077184200286865
INFO:root:current mean train loss 3560.936396090373
INFO:root:current train perplexity4.088019847869873
INFO:root:current mean train loss 3565.134229826447
INFO:root:current train perplexity4.085742950439453
INFO:root:current mean train loss 3570.8000631105747
INFO:root:current train perplexity4.09306001663208
INFO:root:current mean train loss 3571.954510601816
INFO:root:current train perplexity4.095239639282227
INFO:root:current mean train loss 3573.5640056972684
INFO:root:current train perplexity4.09451150894165
INFO:root:current mean train loss 3573.5714441364744
INFO:root:current train perplexity4.094560623168945
INFO:root:current mean train loss 3577.8972420616915
INFO:root:current train perplexity4.096992492675781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.62s/it]
INFO:root:final mean train loss: 3576.043431620444
INFO:root:final train perplexity: 4.099449634552002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4257.025974138409
INFO:root:eval perplexity: 5.592442989349365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5276.3771418578235
INFO:root:eval perplexity: 8.650206565856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [5:19:09<7:41:02, 234.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.9461159446023
INFO:root:current train perplexity4.10361385345459
INFO:root:current mean train loss 3557.811814831149
INFO:root:current train perplexity4.076297760009766
INFO:root:current mean train loss 3561.224809474571
INFO:root:current train perplexity4.079849720001221
INFO:root:current mean train loss 3561.328261168574
INFO:root:current train perplexity4.077528476715088
INFO:root:current mean train loss 3560.2516783997253
INFO:root:current train perplexity4.078564643859863
INFO:root:current mean train loss 3560.009713717624
INFO:root:current train perplexity4.077393054962158
INFO:root:current mean train loss 3565.438142593034
INFO:root:current train perplexity4.082321643829346
INFO:root:current mean train loss 3566.2223551971233
INFO:root:current train perplexity4.08342981338501
INFO:root:current mean train loss 3568.3708144873904
INFO:root:current train perplexity4.085623741149902
INFO:root:current mean train loss 3571.259187612484
INFO:root:current train perplexity4.087791442871094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.48s/it]
INFO:root:final mean train loss: 3569.7327920236894
INFO:root:final train perplexity: 4.0892558097839355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4257.303813095634
INFO:root:eval perplexity: 5.593072414398193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5280.002540101396
INFO:root:eval perplexity: 8.663040161132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [5:23:04<7:36:56, 234.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.3772243923613
INFO:root:current train perplexity4.034364700317383
INFO:root:current mean train loss 3553.8527187979294
INFO:root:current train perplexity4.042065620422363
INFO:root:current mean train loss 3544.1827536463284
INFO:root:current train perplexity4.038663387298584
INFO:root:current mean train loss 3540.3140576575415
INFO:root:current train perplexity4.044534206390381
INFO:root:current mean train loss 3546.3645741934397
INFO:root:current train perplexity4.053828239440918
INFO:root:current mean train loss 3550.9844847115064
INFO:root:current train perplexity4.060197353363037
INFO:root:current mean train loss 3552.753230168269
INFO:root:current train perplexity4.05960750579834
INFO:root:current mean train loss 3556.5026029934265
INFO:root:current train perplexity4.064752101898193
INFO:root:current mean train loss 3560.3670500117687
INFO:root:current train perplexity4.070164203643799
INFO:root:current mean train loss 3562.6908264477056
INFO:root:current train perplexity4.074078559875488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.86s/it]
INFO:root:final mean train loss: 3562.097212883734
INFO:root:final train perplexity: 4.076955318450928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4258.9466180463205
INFO:root:eval perplexity: 5.596789360046387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5279.048474900266
INFO:root:eval perplexity: 8.659659385681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [5:26:58<7:33:10, 234.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3542.8912336322624
INFO:root:current train perplexity4.065984725952148
INFO:root:current mean train loss 3540.126103629843
INFO:root:current train perplexity4.062280178070068
INFO:root:current mean train loss 3536.1698750288283
INFO:root:current train perplexity4.04908561706543
INFO:root:current mean train loss 3539.379220145089
INFO:root:current train perplexity4.048980236053467
INFO:root:current mean train loss 3539.0782307424365
INFO:root:current train perplexity4.044244766235352
INFO:root:current mean train loss 3542.9351560789733
INFO:root:current train perplexity4.052041530609131
INFO:root:current mean train loss 3546.959633476155
INFO:root:current train perplexity4.056406497955322
INFO:root:current mean train loss 3549.1615615627024
INFO:root:current train perplexity4.055589199066162
INFO:root:current mean train loss 3552.283660573335
INFO:root:current train perplexity4.058032512664795
INFO:root:current mean train loss 3556.1788643111163
INFO:root:current train perplexity4.062849998474121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it]
INFO:root:final mean train loss: 3553.3936942315872
INFO:root:final train perplexity: 4.062979698181152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4262.612815478169
INFO:root:eval perplexity: 5.605091571807861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5289.220010527482
INFO:root:eval perplexity: 8.695754051208496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [5:30:53<7:29:34, 234.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3521.4289210838606
INFO:root:current train perplexity4.018695831298828
INFO:root:current mean train loss 3545.721323705918
INFO:root:current train perplexity4.034290313720703
INFO:root:current mean train loss 3546.0726007714493
INFO:root:current train perplexity4.040384769439697
INFO:root:current mean train loss 3542.868457804255
INFO:root:current train perplexity4.036646366119385
INFO:root:current mean train loss 3537.299372981635
INFO:root:current train perplexity4.032254695892334
INFO:root:current mean train loss 3535.405995317897
INFO:root:current train perplexity4.033113479614258
INFO:root:current mean train loss 3537.6406167301407
INFO:root:current train perplexity4.038640975952148
INFO:root:current mean train loss 3541.284570187139
INFO:root:current train perplexity4.0410847663879395
INFO:root:current mean train loss 3544.305191057398
INFO:root:current train perplexity4.045589923858643
INFO:root:current mean train loss 3547.148825780851
INFO:root:current train perplexity4.050084590911865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.38s/it]
INFO:root:final mean train loss: 3545.799216731902
INFO:root:final train perplexity: 4.050824165344238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4264.626047553746
INFO:root:eval perplexity: 5.609656810760498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5292.249276235594
INFO:root:eval perplexity: 8.706531524658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [5:34:47<7:25:25, 234.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3508.2953371946837
INFO:root:current train perplexity3.9925343990325928
INFO:root:current mean train loss 3539.2913602941176
INFO:root:current train perplexity4.0184197425842285
INFO:root:current mean train loss 3526.3947430653852
INFO:root:current train perplexity4.019453048706055
INFO:root:current mean train loss 3526.197884493096
INFO:root:current train perplexity4.0246124267578125
INFO:root:current mean train loss 3534.711931608541
INFO:root:current train perplexity4.032261848449707
INFO:root:current mean train loss 3536.352816060211
INFO:root:current train perplexity4.031659126281738
INFO:root:current mean train loss 3539.8170928288755
INFO:root:current train perplexity4.0347900390625
INFO:root:current mean train loss 3542.1639905297016
INFO:root:current train perplexity4.03895902633667
INFO:root:current mean train loss 3540.53778977593
INFO:root:current train perplexity4.036900043487549
INFO:root:current mean train loss 3540.4942499564654
INFO:root:current train perplexity4.037369251251221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.26s/it]
INFO:root:final mean train loss: 3537.579666568387
INFO:root:final train perplexity: 4.0377092361450195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4268.962959884751
INFO:root:eval perplexity: 5.619503021240234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5302.762643367686
INFO:root:eval perplexity: 8.744040489196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [5:38:41<7:21:14, 234.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.058642578125
INFO:root:current train perplexity3.9774715900421143
INFO:root:current mean train loss 3543.0457431891027
INFO:root:current train perplexity3.9986608028411865
INFO:root:current mean train loss 3538.3226918365995
INFO:root:current train perplexity4.006495475769043
INFO:root:current mean train loss 3537.837364022943
INFO:root:current train perplexity4.013111114501953
INFO:root:current mean train loss 3537.98151386916
INFO:root:current train perplexity4.01753044128418
INFO:root:current mean train loss 3535.675185464811
INFO:root:current train perplexity4.020440101623535
INFO:root:current mean train loss 3535.280157514613
INFO:root:current train perplexity4.022054672241211
INFO:root:current mean train loss 3534.664885514937
INFO:root:current train perplexity4.024295806884766
INFO:root:current mean train loss 3534.5742111120812
INFO:root:current train perplexity4.02412748336792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.37s/it]
INFO:root:final mean train loss: 3530.328386675927
INFO:root:final train perplexity: 4.026175022125244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4266.953701587434
INFO:root:eval perplexity: 5.6149396896362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5300.654861341977
INFO:root:eval perplexity: 8.736507415771484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [5:42:35<7:17:10, 234.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3469.97021484375
INFO:root:current train perplexity3.9934868812561035
INFO:root:current mean train loss 3527.8614964161106
INFO:root:current train perplexity4.000906944274902
INFO:root:current mean train loss 3539.6318792333745
INFO:root:current train perplexity4.011194705963135
INFO:root:current mean train loss 3537.6071769286305
INFO:root:current train perplexity4.009932518005371
INFO:root:current mean train loss 3531.5174684737517
INFO:root:current train perplexity4.003259658813477
INFO:root:current mean train loss 3527.1938855150347
INFO:root:current train perplexity4.004391670227051
INFO:root:current mean train loss 3527.7897714390288
INFO:root:current train perplexity4.008955955505371
INFO:root:current mean train loss 3526.2970798975375
INFO:root:current train perplexity4.008634567260742
INFO:root:current mean train loss 3525.1038290857527
INFO:root:current train perplexity4.009055137634277
INFO:root:current mean train loss 3527.6715684047963
INFO:root:current train perplexity4.012617588043213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.13s/it]
INFO:root:final mean train loss: 3523.7094133438604
INFO:root:final train perplexity: 4.015674114227295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4270.20020916445
INFO:root:eval perplexity: 5.622315883636475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5305.78976548648
INFO:root:eval perplexity: 8.754873275756836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [5:46:30<7:13:37, 234.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3506.8125443892045
INFO:root:current train perplexity4.037477016448975
INFO:root:current mean train loss 3512.9071385838965
INFO:root:current train perplexity3.9942333698272705
INFO:root:current mean train loss 3516.6883724266886
INFO:root:current train perplexity3.9903228282928467
INFO:root:current mean train loss 3516.1175054323253
INFO:root:current train perplexity3.993058919906616
INFO:root:current mean train loss 3513.7089701186133
INFO:root:current train perplexity3.9910268783569336
INFO:root:current mean train loss 3508.802962271435
INFO:root:current train perplexity3.98671555519104
INFO:root:current mean train loss 3512.1556090809127
INFO:root:current train perplexity3.9920856952667236
INFO:root:current mean train loss 3512.7415687357156
INFO:root:current train perplexity3.9945521354675293
INFO:root:current mean train loss 3513.2504988175283
INFO:root:current train perplexity3.9963414669036865
INFO:root:current mean train loss 3516.3465923221393
INFO:root:current train perplexity4.000258445739746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.70s/it]
INFO:root:final mean train loss: 3515.675298690796
INFO:root:final train perplexity: 4.002965927124023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4270.055149808843
INFO:root:eval perplexity: 5.621986389160156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5307.769427360372
INFO:root:eval perplexity: 8.761964797973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [5:50:24<7:09:39, 234.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3458.6863692434213
INFO:root:current train perplexity3.925175428390503
INFO:root:current mean train loss 3471.9703010110293
INFO:root:current train perplexity3.951429605484009
INFO:root:current mean train loss 3499.7349179063212
INFO:root:current train perplexity3.9710118770599365
INFO:root:current mean train loss 3504.7847062353057
INFO:root:current train perplexity3.973189115524292
INFO:root:current mean train loss 3513.248701218489
INFO:root:current train perplexity3.9818575382232666
INFO:root:current mean train loss 3509.927265380389
INFO:root:current train perplexity3.9810588359832764
INFO:root:current mean train loss 3508.1327935682552
INFO:root:current train perplexity3.983873128890991
INFO:root:current mean train loss 3508.945583125978
INFO:root:current train perplexity3.986154317855835
INFO:root:current mean train loss 3508.393057165274
INFO:root:current train perplexity3.987464189529419
INFO:root:current mean train loss 3510.4958873329538
INFO:root:current train perplexity3.990541696548462

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it]
INFO:root:final mean train loss: 3509.499324490947
INFO:root:final train perplexity: 3.993224620819092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4273.260903216423
INFO:root:eval perplexity: 5.629278182983398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5309.814747478945
INFO:root:eval perplexity: 8.769291877746582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [5:54:18<7:05:36, 234.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.18298791956
INFO:root:current train perplexity3.9836113452911377
INFO:root:current mean train loss 3487.8974974624753
INFO:root:current train perplexity3.9581165313720703
INFO:root:current mean train loss 3491.182102018516
INFO:root:current train perplexity3.971162796020508
INFO:root:current mean train loss 3492.8039879288513
INFO:root:current train perplexity3.968318223953247
INFO:root:current mean train loss 3492.43415292923
INFO:root:current train perplexity3.96945858001709
INFO:root:current mean train loss 3496.671998228475
INFO:root:current train perplexity3.9725708961486816
INFO:root:current mean train loss 3499.811279296875
INFO:root:current train perplexity3.9759252071380615
INFO:root:current mean train loss 3500.336683690466
INFO:root:current train perplexity3.977482557296753
INFO:root:current mean train loss 3504.0948487804185
INFO:root:current train perplexity3.9811038970947266
INFO:root:current mean train loss 3506.4127793790453
INFO:root:current train perplexity3.983388662338257

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.16s/it]
INFO:root:final mean train loss: 3502.3627694037655
INFO:root:final train perplexity: 3.981997013092041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 4277.120633172651
INFO:root:eval perplexity: 5.638071060180664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5316.5145410848845
INFO:root:eval perplexity: 8.793350219726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [5:58:12<7:01:32, 234.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3473.9977678571427
INFO:root:current train perplexity3.9696576595306396
INFO:root:current mean train loss 3476.8232548466435
INFO:root:current train perplexity3.9567792415618896
INFO:root:current mean train loss 3487.4796926944814
INFO:root:current train perplexity3.9703402519226074
INFO:root:current mean train loss 3486.7935211637127
INFO:root:current train perplexity3.961097002029419
INFO:root:current mean train loss 3490.677282574533
INFO:root:current train perplexity3.9654974937438965
INFO:root:current mean train loss 3490.8336037894273
INFO:root:current train perplexity3.9664576053619385
INFO:root:current mean train loss 3491.4576087290848
INFO:root:current train perplexity3.967235565185547
INFO:root:current mean train loss 3489.5318943983843
INFO:root:current train perplexity3.9645752906799316
INFO:root:current mean train loss 3491.3941929617326
INFO:root:current train perplexity3.9651429653167725
INFO:root:current mean train loss 3495.425624321106
INFO:root:current train perplexity3.9688291549682617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it]
INFO:root:final mean train loss: 3494.8699019647415
INFO:root:final train perplexity: 3.9702436923980713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4280.186495733599
INFO:root:eval perplexity: 5.645066738128662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5323.9154788619235
INFO:root:eval perplexity: 8.820003509521484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:02:07<6:57:45, 234.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3468.2273971202762
INFO:root:current train perplexity3.929999589920044
INFO:root:current mean train loss 3482.3328387920674
INFO:root:current train perplexity3.931962728500366
INFO:root:current mean train loss 3478.04388904964
INFO:root:current train perplexity3.9287269115448
INFO:root:current mean train loss 3486.3070271216748
INFO:root:current train perplexity3.9379971027374268
INFO:root:current mean train loss 3486.3387272061937
INFO:root:current train perplexity3.9424846172332764
INFO:root:current mean train loss 3482.789454114152
INFO:root:current train perplexity3.9425015449523926
INFO:root:current mean train loss 3482.9263971070664
INFO:root:current train perplexity3.9457881450653076
INFO:root:current mean train loss 3487.919776967846
INFO:root:current train perplexity3.9503142833709717
INFO:root:current mean train loss 3486.906980105001
INFO:root:current train perplexity3.951204538345337
INFO:root:current mean train loss 3489.0474725361214
INFO:root:current train perplexity3.9562389850616455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.16s/it]
INFO:root:final mean train loss: 3487.346966343541
INFO:root:final train perplexity: 3.9584765434265137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4279.549565741357
INFO:root:eval perplexity: 5.643611907958984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5323.103207419104
INFO:root:eval perplexity: 8.817073822021484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [6:06:02<6:54:10, 234.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.7850748697915
INFO:root:current train perplexity3.9130451679229736
INFO:root:current mean train loss 3470.093843775869
INFO:root:current train perplexity3.9296257495880127
INFO:root:current mean train loss 3473.3144346442355
INFO:root:current train perplexity3.924633026123047
INFO:root:current mean train loss 3471.0326369413283
INFO:root:current train perplexity3.929515838623047
INFO:root:current mean train loss 3474.7660044735658
INFO:root:current train perplexity3.9371371269226074
INFO:root:current mean train loss 3476.3773988699522
INFO:root:current train perplexity3.9340152740478516
INFO:root:current mean train loss 3479.8155459449404
INFO:root:current train perplexity3.936558485031128
INFO:root:current mean train loss 3479.2640015136067
INFO:root:current train perplexity3.9385290145874023
INFO:root:current mean train loss 3482.4566930105207
INFO:root:current train perplexity3.943351984024048
INFO:root:current mean train loss 3482.376403487694
INFO:root:current train perplexity3.946472644805908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.29s/it]
INFO:root:final mean train loss: 3481.1765379751882
INFO:root:final train perplexity: 3.9488518238067627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4282.596792234596
INFO:root:eval perplexity: 5.650570869445801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5328.91367464539
INFO:root:eval perplexity: 8.838048934936523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [6:09:55<6:49:59, 234.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.571682170286
INFO:root:current train perplexity3.899458408355713
INFO:root:current mean train loss 3456.155534468357
INFO:root:current train perplexity3.9029645919799805
INFO:root:current mean train loss 3466.184924740589
INFO:root:current train perplexity3.916539192199707
INFO:root:current mean train loss 3471.2306489652246
INFO:root:current train perplexity3.9219260215759277
INFO:root:current mean train loss 3470.043203316483
INFO:root:current train perplexity3.922717571258545
INFO:root:current mean train loss 3471.60464286463
INFO:root:current train perplexity3.9250733852386475
INFO:root:current mean train loss 3472.310902527504
INFO:root:current train perplexity3.9296844005584717
INFO:root:current mean train loss 3473.496308297822
INFO:root:current train perplexity3.932379961013794
INFO:root:current mean train loss 3474.8295986544126
INFO:root:current train perplexity3.935589551925659
INFO:root:current mean train loss 3478.3992857550184
INFO:root:current train perplexity3.9405508041381836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.63s/it]
INFO:root:final mean train loss: 3476.700015098818
INFO:root:final train perplexity: 3.9418835639953613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4284.020788314495
INFO:root:eval perplexity: 5.653824329376221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5330.719179410461
INFO:root:eval perplexity: 8.844575881958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [6:13:50<6:46:05, 234.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3458.172654792444
INFO:root:current train perplexity3.900736093521118
INFO:root:current mean train loss 3463.883381186845
INFO:root:current train perplexity3.9044556617736816
INFO:root:current mean train loss 3470.1999401992625
INFO:root:current train perplexity3.9169070720672607
INFO:root:current mean train loss 3469.8764641785165
INFO:root:current train perplexity3.9199941158294678
INFO:root:current mean train loss 3468.123844122223
INFO:root:current train perplexity3.926508665084839
INFO:root:current mean train loss 3466.0058477492557
INFO:root:current train perplexity3.9253995418548584
INFO:root:current mean train loss 3466.537425257098
INFO:root:current train perplexity3.926246166229248
INFO:root:current mean train loss 3469.9323504471563
INFO:root:current train perplexity3.927661180496216
INFO:root:current mean train loss 3471.2976772567945
INFO:root:current train perplexity3.9282915592193604
INFO:root:current mean train loss 3471.218847959217
INFO:root:current train perplexity3.927781581878662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.93s/it]
INFO:root:final mean train loss: 3468.240376564764
INFO:root:final train perplexity: 3.9287495613098145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4287.412590730275
INFO:root:eval perplexity: 5.661583423614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5333.140690796764
INFO:root:eval perplexity: 8.853339195251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [6:17:44<6:42:24, 234.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3417.5000553385416
INFO:root:current train perplexity3.903268337249756
INFO:root:current mean train loss 3437.981900111607
INFO:root:current train perplexity3.908184766769409
INFO:root:current mean train loss 3447.1327583451703
INFO:root:current train perplexity3.9068071842193604
INFO:root:current mean train loss 3453.140360026042
INFO:root:current train perplexity3.9130311012268066
INFO:root:current mean train loss 3457.5527796052634
INFO:root:current train perplexity3.91422963142395
INFO:root:current mean train loss 3456.129826766304
INFO:root:current train perplexity3.9124364852905273
INFO:root:current mean train loss 3457.9658582899306
INFO:root:current train perplexity3.912788152694702
INFO:root:current mean train loss 3463.1569707661292
INFO:root:current train perplexity3.91702938079834
INFO:root:current mean train loss 3463.919200613839
INFO:root:current train perplexity3.9174206256866455
INFO:root:current mean train loss 3466.031547726362
INFO:root:current train perplexity3.9213006496429443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.29s/it]
INFO:root:final mean train loss: 3463.3562579616423
INFO:root:final train perplexity: 3.921186923980713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4287.943974055297
INFO:root:eval perplexity: 5.662800312042236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5339.712118378768
INFO:root:eval perplexity: 8.87716007232666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [6:21:40<6:38:50, 234.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3456.779335113893
INFO:root:current train perplexity3.8890814781188965
INFO:root:current mean train loss 3447.1605644851434
INFO:root:current train perplexity3.887272834777832
INFO:root:current mean train loss 3452.8926324743265
INFO:root:current train perplexity3.8946478366851807
INFO:root:current mean train loss 3449.8669573831185
INFO:root:current train perplexity3.896479368209839
INFO:root:current mean train loss 3451.6649480784163
INFO:root:current train perplexity3.8975493907928467
INFO:root:current mean train loss 3449.320494244479
INFO:root:current train perplexity3.9005050659179688
INFO:root:current mean train loss 3451.458660164829
INFO:root:current train perplexity3.904022216796875
INFO:root:current mean train loss 3453.2824909702267
INFO:root:current train perplexity3.9065945148468018
INFO:root:current mean train loss 3455.993553913328
INFO:root:current train perplexity3.906158208847046
INFO:root:current mean train loss 3458.972452840873
INFO:root:current train perplexity3.9104104042053223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it]
INFO:root:final mean train loss: 3456.2291366823256
INFO:root:final train perplexity: 3.9101760387420654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4292.008004695811
INFO:root:eval perplexity: 5.672115325927734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5342.267515791224
INFO:root:eval perplexity: 8.886441230773926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [6:25:33<6:34:34, 234.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3440.695553957761
INFO:root:current train perplexity3.8927907943725586
INFO:root:current mean train loss 3439.3905444719403
INFO:root:current train perplexity3.887726068496704
INFO:root:current mean train loss 3441.4783042042527
INFO:root:current train perplexity3.888427972793579
INFO:root:current mean train loss 3434.696227246843
INFO:root:current train perplexity3.881028175354004
INFO:root:current mean train loss 3435.9650804321536
INFO:root:current train perplexity3.887955665588379
INFO:root:current mean train loss 3440.9928872871724
INFO:root:current train perplexity3.8905012607574463
INFO:root:current mean train loss 3443.4849466635765
INFO:root:current train perplexity3.8918654918670654
INFO:root:current mean train loss 3447.6316242049224
INFO:root:current train perplexity3.8967065811157227
INFO:root:current mean train loss 3451.021606582316
INFO:root:current train perplexity3.8986384868621826
INFO:root:current mean train loss 3452.1883541226507
INFO:root:current train perplexity3.899813175201416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.69s/it]
INFO:root:final mean train loss: 3449.4939778850926
INFO:root:final train perplexity: 3.8997998237609863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4295.501167026818
INFO:root:eval perplexity: 5.680134296417236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5346.997801002881
INFO:root:eval perplexity: 8.903647422790527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [6:29:28<6:30:43, 234.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3417.0848844894253
INFO:root:current train perplexity3.8612797260284424
INFO:root:current mean train loss 3440.2835674956814
INFO:root:current train perplexity3.8743295669555664
INFO:root:current mean train loss 3442.0904479776336
INFO:root:current train perplexity3.8859524726867676
INFO:root:current mean train loss 3440.282553918977
INFO:root:current train perplexity3.881911277770996
INFO:root:current mean train loss 3440.1296000203533
INFO:root:current train perplexity3.8824546337127686
INFO:root:current mean train loss 3440.1693891674927
INFO:root:current train perplexity3.8815083503723145
INFO:root:current mean train loss 3442.1001081343884
INFO:root:current train perplexity3.884841203689575
INFO:root:current mean train loss 3441.3786355258526
INFO:root:current train perplexity3.8851020336151123
INFO:root:current mean train loss 3443.840708697598
INFO:root:current train perplexity3.8879940509796143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it]
INFO:root:final mean train loss: 3442.744038981776
INFO:root:final train perplexity: 3.889427900314331
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 4295.995716284353
INFO:root:eval perplexity: 5.681268215179443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5349.151017425754
INFO:root:eval perplexity: 8.911487579345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [6:33:23<6:26:55, 234.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.876883370536
INFO:root:current train perplexity3.8694028854370117
INFO:root:current mean train loss 3392.331727785485
INFO:root:current train perplexity3.8548457622528076
INFO:root:current mean train loss 3415.3362936858393
INFO:root:current train perplexity3.851221799850464
INFO:root:current mean train loss 3421.3380417218036
INFO:root:current train perplexity3.8517038822174072
INFO:root:current mean train loss 3421.685977570255
INFO:root:current train perplexity3.856632947921753
INFO:root:current mean train loss 3423.9777480507273
INFO:root:current train perplexity3.8584985733032227
INFO:root:current mean train loss 3427.607458878192
INFO:root:current train perplexity3.8647375106811523
INFO:root:current mean train loss 3432.9013074472905
INFO:root:current train perplexity3.871415376663208
INFO:root:current mean train loss 3434.673609699311
INFO:root:current train perplexity3.873626708984375
INFO:root:current mean train loss 3436.9278237406975
INFO:root:current train perplexity3.875926971435547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it]
INFO:root:final mean train loss: 3436.5104038484633
INFO:root:final train perplexity: 3.8798744678497314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4297.662746564716
INFO:root:eval perplexity: 5.685098171234131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5353.302703208112
INFO:root:eval perplexity: 8.926630020141602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [6:37:18<6:23:14, 234.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3417.150569661458
INFO:root:current train perplexity3.7930028438568115
INFO:root:current mean train loss 3413.3091096297553
INFO:root:current train perplexity3.8317489624023438
INFO:root:current mean train loss 3407.225792605378
INFO:root:current train perplexity3.845810890197754
INFO:root:current mean train loss 3412.4985700334823
INFO:root:current train perplexity3.8450074195861816
INFO:root:current mean train loss 3417.2540027296686
INFO:root:current train perplexity3.8503541946411133
INFO:root:current mean train loss 3422.279910307949
INFO:root:current train perplexity3.856083631515503
INFO:root:current mean train loss 3424.7508328569616
INFO:root:current train perplexity3.861002206802368
INFO:root:current mean train loss 3423.6801313920455
INFO:root:current train perplexity3.8597235679626465
INFO:root:current mean train loss 3424.2928713933093
INFO:root:current train perplexity3.86301589012146
INFO:root:current mean train loss 3430.2294009349384
INFO:root:current train perplexity3.869013547897339

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it]
INFO:root:final mean train loss: 3429.945597125638
INFO:root:final train perplexity: 3.869838237762451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4302.338313109486
INFO:root:eval perplexity: 5.695858478546143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5360.859381925975
INFO:root:eval perplexity: 8.95425796508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [6:41:12<6:19:12, 234.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.3197393002715
INFO:root:current train perplexity3.8331048488616943
INFO:root:current mean train loss 3415.8004557291665
INFO:root:current train perplexity3.843538761138916
INFO:root:current mean train loss 3411.6007643900643
INFO:root:current train perplexity3.841052770614624
INFO:root:current mean train loss 3420.133487477022
INFO:root:current train perplexity3.845548391342163
INFO:root:current mean train loss 3424.9987723709
INFO:root:current train perplexity3.85111665725708
INFO:root:current mean train loss 3425.513310098739
INFO:root:current train perplexity3.85194993019104
INFO:root:current mean train loss 3425.4796070080506
INFO:root:current train perplexity3.8561525344848633
INFO:root:current mean train loss 3421.850292496002
INFO:root:current train perplexity3.8557608127593994
INFO:root:current mean train loss 3423.913212902491
INFO:root:current train perplexity3.8581342697143555
INFO:root:current mean train loss 3427.6833906080715
INFO:root:current train perplexity3.8618648052215576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.33s/it]
INFO:root:final mean train loss: 3424.8803354693996
INFO:root:final train perplexity: 3.8621132373809814
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4306.013124722961
INFO:root:eval perplexity: 5.704329013824463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5362.948526152482
INFO:root:eval perplexity: 8.961910247802734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [6:45:06<6:15:03, 234.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3406.1163605720767
INFO:root:current train perplexity3.848365545272827
INFO:root:current mean train loss 3417.638198503101
INFO:root:current train perplexity3.8433802127838135
INFO:root:current mean train loss 3419.6893368675596
INFO:root:current train perplexity3.847134828567505
INFO:root:current mean train loss 3419.1675896313254
INFO:root:current train perplexity3.8588812351226807
INFO:root:current mean train loss 3417.976405026465
INFO:root:current train perplexity3.855030059814453
INFO:root:current mean train loss 3418.5253961423023
INFO:root:current train perplexity3.852233409881592
INFO:root:current mean train loss 3421.1757862798386
INFO:root:current train perplexity3.8515877723693848
INFO:root:current mean train loss 3419.7928645477086
INFO:root:current train perplexity3.8514657020568848
INFO:root:current mean train loss 3421.199965861443
INFO:root:current train perplexity3.852196216583252
INFO:root:current mean train loss 3421.9743893599793
INFO:root:current train perplexity3.852325201034546

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.47s/it]
INFO:root:final mean train loss: 3418.735678211335
INFO:root:final train perplexity: 3.8527615070343018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 4304.529965231604
INFO:root:eval perplexity: 5.70090913772583
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5364.30595149047
INFO:root:eval perplexity: 8.966885566711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [6:49:00<6:11:06, 234.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.9132299178686
INFO:root:current train perplexity3.82173752784729
INFO:root:current mean train loss 3396.357239208633
INFO:root:current train perplexity3.8232717514038086
INFO:root:current mean train loss 3399.0959135558314
INFO:root:current train perplexity3.8291101455688477
INFO:root:current mean train loss 3395.6750891581396
INFO:root:current train perplexity3.8306450843811035
INFO:root:current mean train loss 3394.1247819974374
INFO:root:current train perplexity3.8288211822509766
INFO:root:current mean train loss 3402.339260801977
INFO:root:current train perplexity3.833273410797119
INFO:root:current mean train loss 3407.514693903438
INFO:root:current train perplexity3.8356544971466064
INFO:root:current mean train loss 3409.0288611219767
INFO:root:current train perplexity3.8357157707214355
INFO:root:current mean train loss 3409.449615951374
INFO:root:current train perplexity3.8379647731781006
INFO:root:current mean train loss 3412.2540209102935
INFO:root:current train perplexity3.8404362201690674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.45s/it]
INFO:root:final mean train loss: 3411.495107527702
INFO:root:final train perplexity: 3.841770887374878
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4308.667741924313
INFO:root:eval perplexity: 5.710455894470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5364.9420538286795
INFO:root:eval perplexity: 8.969216346740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [6:52:56<6:07:35, 234.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3378.4390895113033
INFO:root:current train perplexity3.7668087482452393
INFO:root:current mean train loss 3387.0219427614797
INFO:root:current train perplexity3.7961511611938477
INFO:root:current mean train loss 3382.4211751961034
INFO:root:current train perplexity3.8024239540100098
INFO:root:current mean train loss 3388.10566434393
INFO:root:current train perplexity3.8128533363342285
INFO:root:current mean train loss 3392.7226966670164
INFO:root:current train perplexity3.813534736633301
INFO:root:current mean train loss 3396.4685674524394
INFO:root:current train perplexity3.81881046295166
INFO:root:current mean train loss 3401.427355145745
INFO:root:current train perplexity3.82267165184021
INFO:root:current mean train loss 3403.9303372343543
INFO:root:current train perplexity3.828007936477661
INFO:root:current mean train loss 3403.566567088806
INFO:root:current train perplexity3.827949047088623
INFO:root:current mean train loss 3406.3949862745017
INFO:root:current train perplexity3.831571102142334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it]
INFO:root:final mean train loss: 3406.4983253479004
INFO:root:final train perplexity: 3.834205389022827
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4310.346823401485
INFO:root:eval perplexity: 5.7143330574035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5370.333804299646
INFO:root:eval perplexity: 8.98901653289795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [6:56:50<6:03:33, 234.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3407.904141512784
INFO:root:current train perplexity3.784092664718628
INFO:root:current mean train loss 3400.5277327998992
INFO:root:current train perplexity3.789583444595337
INFO:root:current mean train loss 3398.453219784007
INFO:root:current train perplexity3.802027463912964
INFO:root:current mean train loss 3399.5020886058537
INFO:root:current train perplexity3.8096981048583984
INFO:root:current mean train loss 3403.931478580014
INFO:root:current train perplexity3.8154854774475098
INFO:root:current mean train loss 3402.7682929511543
INFO:root:current train perplexity3.8174195289611816
INFO:root:current mean train loss 3402.6187503727338
INFO:root:current train perplexity3.8202602863311768
INFO:root:current mean train loss 3403.3689152395486
INFO:root:current train perplexity3.821423053741455
INFO:root:current mean train loss 3401.773198499178
INFO:root:current train perplexity3.8233561515808105
INFO:root:current mean train loss 3402.2802281884
INFO:root:current train perplexity3.826692819595337

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.46s/it]
INFO:root:final mean train loss: 3401.70145059401
INFO:root:final train perplexity: 3.8269553184509277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4310.452886053857
INFO:root:eval perplexity: 5.714579105377197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5376.714251579122
INFO:root:eval perplexity: 9.012499809265137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [7:00:44<5:59:28, 234.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.937065972222
INFO:root:current train perplexity3.8484315872192383
INFO:root:current mean train loss 3399.7312940351803
INFO:root:current train perplexity3.7994375228881836
INFO:root:current mean train loss 3385.0232434871077
INFO:root:current train perplexity3.7994580268859863
INFO:root:current mean train loss 3380.97556777828
INFO:root:current train perplexity3.80469012260437
INFO:root:current mean train loss 3383.5665417665023
INFO:root:current train perplexity3.8083388805389404
INFO:root:current mean train loss 3389.0014739502385
INFO:root:current train perplexity3.812840223312378
INFO:root:current mean train loss 3391.3372789846107
INFO:root:current train perplexity3.8148794174194336
INFO:root:current mean train loss 3393.9912723726247
INFO:root:current train perplexity3.81482195854187
INFO:root:current mean train loss 3395.5163511981277
INFO:root:current train perplexity3.8165810108184814
INFO:root:current mean train loss 3398.268422603112
INFO:root:current train perplexity3.8171324729919434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.75s/it]
INFO:root:final mean train loss: 3395.3149434981806
INFO:root:final train perplexity: 3.8173253536224365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4314.789524808843
INFO:root:eval perplexity: 5.724609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5380.767654310727
INFO:root:eval perplexity: 9.027449607849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [7:04:39<5:55:34, 234.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.957976865097
INFO:root:current train perplexity3.7861268520355225
INFO:root:current mean train loss 3387.2260613692433
INFO:root:current train perplexity3.7795374393463135
INFO:root:current mean train loss 3391.023234800219
INFO:root:current train perplexity3.7905921936035156
INFO:root:current mean train loss 3391.4070719181686
INFO:root:current train perplexity3.8023550510406494
INFO:root:current mean train loss 3390.0231850658506
INFO:root:current train perplexity3.799226999282837
INFO:root:current mean train loss 3391.5001958255802
INFO:root:current train perplexity3.800264358520508
INFO:root:current mean train loss 3390.2471871070466
INFO:root:current train perplexity3.7999393939971924
INFO:root:current mean train loss 3392.8197878034816
INFO:root:current train perplexity3.8037123680114746
INFO:root:current mean train loss 3392.8246349943493
INFO:root:current train perplexity3.806250810623169
INFO:root:current mean train loss 3391.315978312468
INFO:root:current train perplexity3.807015895843506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.10s/it]
INFO:root:final mean train loss: 3388.7255938130043
INFO:root:final train perplexity: 3.8074142932891846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4316.658997880651
INFO:root:eval perplexity: 5.728938579559326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5387.491879294104
INFO:root:eval perplexity: 9.05230712890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [7:08:34<5:51:53, 234.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.1178519333466
INFO:root:current train perplexity3.761190891265869
INFO:root:current mean train loss 3364.9947243802376
INFO:root:current train perplexity3.7703630924224854
INFO:root:current mean train loss 3368.7166831177196
INFO:root:current train perplexity3.77755069732666
INFO:root:current mean train loss 3370.097617599769
INFO:root:current train perplexity3.7828569412231445
INFO:root:current mean train loss 3375.722081321764
INFO:root:current train perplexity3.7884469032287598
INFO:root:current mean train loss 3377.8839501362804
INFO:root:current train perplexity3.7881059646606445
INFO:root:current mean train loss 3380.4517845636965
INFO:root:current train perplexity3.7935595512390137
INFO:root:current mean train loss 3385.850884296775
INFO:root:current train perplexity3.797001600265503
INFO:root:current mean train loss 3386.979545792893
INFO:root:current train perplexity3.798614740371704
INFO:root:current mean train loss 3387.8452515022504
INFO:root:current train perplexity3.7996981143951416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.91s/it]
INFO:root:final mean train loss: 3384.00590625886
INFO:root:final train perplexity: 3.8003313541412354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4317.09884751773
INFO:root:eval perplexity: 5.72995662689209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5386.774985455452
INFO:root:eval perplexity: 9.049650192260742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [7:12:28<5:47:59, 234.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.806632206358
INFO:root:current train perplexity3.7675726413726807
INFO:root:current mean train loss 3367.77583582261
INFO:root:current train perplexity3.7846200466156006
INFO:root:current mean train loss 3370.7748700185102
INFO:root:current train perplexity3.776099920272827
INFO:root:current mean train loss 3373.6982623748386
INFO:root:current train perplexity3.773613691329956
INFO:root:current mean train loss 3377.2843932478822
INFO:root:current train perplexity3.7846782207489014
INFO:root:current mean train loss 3376.3185007852426
INFO:root:current train perplexity3.7855634689331055
INFO:root:current mean train loss 3378.304300855167
INFO:root:current train perplexity3.788102388381958
INFO:root:current mean train loss 3377.3305260780653
INFO:root:current train perplexity3.7881574630737305
INFO:root:current mean train loss 3380.460798502237
INFO:root:current train perplexity3.7916502952575684
INFO:root:current mean train loss 3381.0591087457256
INFO:root:current train perplexity3.792062520980835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.32s/it]
INFO:root:final mean train loss: 3378.882714548419
INFO:root:final train perplexity: 3.7926578521728516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4323.737320270944
INFO:root:eval perplexity: 5.745358467102051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5394.520265403369
INFO:root:eval perplexity: 9.078359603881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [7:16:22<5:43:46, 234.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.2172568873357
INFO:root:current train perplexity3.7605807781219482
INFO:root:current mean train loss 3363.2005709134614
INFO:root:current train perplexity3.7638440132141113
INFO:root:current mean train loss 3366.482817465572
INFO:root:current train perplexity3.7716307640075684
INFO:root:current mean train loss 3368.5119159167325
INFO:root:current train perplexity3.7711021900177
INFO:root:current mean train loss 3369.3571639244
INFO:root:current train perplexity3.774021863937378
INFO:root:current mean train loss 3372.3187623096114
INFO:root:current train perplexity3.7793970108032227
INFO:root:current mean train loss 3376.4424158329584
INFO:root:current train perplexity3.7818546295166016
INFO:root:current mean train loss 3377.110037097091
INFO:root:current train perplexity3.783722400665283
INFO:root:current mean train loss 3375.3856371661136
INFO:root:current train perplexity3.78361177444458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it]
INFO:root:final mean train loss: 3373.5913477251606
INFO:root:final train perplexity: 3.784748077392578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4323.602604859264
INFO:root:eval perplexity: 5.7450456619262695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5395.184798869681
INFO:root:eval perplexity: 9.080827713012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [7:20:16<5:39:37, 234.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.1358235677085
INFO:root:current train perplexity3.624603033065796
INFO:root:current mean train loss 3365.0955917210254
INFO:root:current train perplexity3.752319574356079
INFO:root:current mean train loss 3362.856018367072
INFO:root:current train perplexity3.7582521438598633
INFO:root:current mean train loss 3363.685109355662
INFO:root:current train perplexity3.762535810470581
INFO:root:current mean train loss 3363.1218655493954
INFO:root:current train perplexity3.7589125633239746
INFO:root:current mean train loss 3364.289592037618
INFO:root:current train perplexity3.761835813522339
INFO:root:current mean train loss 3364.8217400950975
INFO:root:current train perplexity3.7665514945983887
INFO:root:current mean train loss 3367.6523142308633
INFO:root:current train perplexity3.7682602405548096
INFO:root:current mean train loss 3367.423372071529
INFO:root:current train perplexity3.7701122760772705
INFO:root:current mean train loss 3368.3861547662304
INFO:root:current train perplexity3.7734193801879883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.60s/it]
INFO:root:final mean train loss: 3367.772919562555
INFO:root:final train perplexity: 3.7760698795318604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4326.593370802859
INFO:root:eval perplexity: 5.751997947692871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5398.220893589318
INFO:root:eval perplexity: 9.092105865478516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [7:24:10<5:35:45, 234.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.712002840909
INFO:root:current train perplexity3.720313549041748
INFO:root:current mean train loss 3352.878809473536
INFO:root:current train perplexity3.7473983764648438
INFO:root:current mean train loss 3350.390824015107
INFO:root:current train perplexity3.7439467906951904
INFO:root:current mean train loss 3355.48801041876
INFO:root:current train perplexity3.7495737075805664
INFO:root:current mean train loss 3357.8449516946093
INFO:root:current train perplexity3.7526605129241943
INFO:root:current mean train loss 3359.427278582131
INFO:root:current train perplexity3.7538440227508545
INFO:root:current mean train loss 3359.7334711602393
INFO:root:current train perplexity3.758004903793335
INFO:root:current mean train loss 3361.5135904947915
INFO:root:current train perplexity3.760124444961548
INFO:root:current mean train loss 3362.7302670555255
INFO:root:current train perplexity3.7625672817230225
INFO:root:current mean train loss 3364.5364790580406
INFO:root:current train perplexity3.7655794620513916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.43s/it]
INFO:root:final mean train loss: 3361.720913302514
INFO:root:final train perplexity: 3.7670650482177734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4329.510617519947
INFO:root:eval perplexity: 5.758788108825684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5403.291022550975
INFO:root:eval perplexity: 9.11097526550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [7:28:04<5:31:47, 234.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.8710680509867
INFO:root:current train perplexity3.6824898719787598
INFO:root:current mean train loss 3338.016542066045
INFO:root:current train perplexity3.732562303543091
INFO:root:current mean train loss 3349.734221157962
INFO:root:current train perplexity3.7457826137542725
INFO:root:current mean train loss 3350.0353368681426
INFO:root:current train perplexity3.74621844291687
INFO:root:current mean train loss 3352.409187262269
INFO:root:current train perplexity3.7493765354156494
INFO:root:current mean train loss 3353.08735953682
INFO:root:current train perplexity3.7525532245635986
INFO:root:current mean train loss 3354.580438616973
INFO:root:current train perplexity3.7542660236358643
INFO:root:current mean train loss 3355.8218184300026
INFO:root:current train perplexity3.756091594696045
INFO:root:current mean train loss 3357.6329478355847
INFO:root:current train perplexity3.759335517883301
INFO:root:current mean train loss 3360.2887806357962
INFO:root:current train perplexity3.7611708641052246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.88s/it]
INFO:root:final mean train loss: 3357.453369817426
INFO:root:final train perplexity: 3.7607274055480957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4332.275110123005
INFO:root:eval perplexity: 5.765229225158691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5406.433552194149
INFO:root:eval perplexity: 9.12269115447998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [7:31:58<5:27:35, 233.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.1171422887733
INFO:root:current train perplexity3.726933717727661
INFO:root:current mean train loss 3345.0948572834645
INFO:root:current train perplexity3.7257277965545654
INFO:root:current mean train loss 3354.163166600702
INFO:root:current train perplexity3.7367238998413086
INFO:root:current mean train loss 3344.920704319572
INFO:root:current train perplexity3.7392055988311768
INFO:root:current mean train loss 3345.517023519833
INFO:root:current train perplexity3.741865873336792
INFO:root:current mean train loss 3349.8311413180445
INFO:root:current train perplexity3.7492098808288574
INFO:root:current mean train loss 3347.141510837196
INFO:root:current train perplexity3.7467079162597656
INFO:root:current mean train loss 3350.256646871239
INFO:root:current train perplexity3.748298168182373
INFO:root:current mean train loss 3351.9922282393063
INFO:root:current train perplexity3.7508349418640137
INFO:root:current mean train loss 3355.28718338095
INFO:root:current train perplexity3.7527034282684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:final mean train loss: 3351.9136861370457
INFO:root:final train perplexity: 3.7525179386138916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4332.886365525266
INFO:root:eval perplexity: 5.7666544914245605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5409.629841256649
INFO:root:eval perplexity: 9.134625434875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [7:35:51<5:23:16, 233.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.0741768973216
INFO:root:current train perplexity3.69486927986145
INFO:root:current mean train loss 3323.950557002315
INFO:root:current train perplexity3.7075424194335938
INFO:root:current mean train loss 3336.645472490027
INFO:root:current train perplexity3.715951681137085
INFO:root:current mean train loss 3346.1054257520987
INFO:root:current train perplexity3.7361886501312256
INFO:root:current mean train loss 3344.786581806753
INFO:root:current train perplexity3.7339043617248535
INFO:root:current mean train loss 3346.905382958528
INFO:root:current train perplexity3.737578868865967
INFO:root:current mean train loss 3345.3034879429133
INFO:root:current train perplexity3.738032579421997
INFO:root:current mean train loss 3345.3796556122447
INFO:root:current train perplexity3.738429546356201
INFO:root:current mean train loss 3345.77200569564
INFO:root:current train perplexity3.7391650676727295
INFO:root:current mean train loss 3348.9685405873997
INFO:root:current train perplexity3.743640184402466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.23s/it]
INFO:root:final mean train loss: 3347.3807810506514
INFO:root:final train perplexity: 3.74581241607666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4335.47684992797
INFO:root:eval perplexity: 5.772698402404785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5412.216938857491
INFO:root:eval perplexity: 9.144292831420898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [7:39:45<5:19:27, 233.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.4036496184594
INFO:root:current train perplexity3.7203001976013184
INFO:root:current mean train loss 3351.013519927338
INFO:root:current train perplexity3.72776198387146
INFO:root:current mean train loss 3343.930591724537
INFO:root:current train perplexity3.7246153354644775
INFO:root:current mean train loss 3341.1368660885114
INFO:root:current train perplexity3.7236523628234863
INFO:root:current mean train loss 3336.697608964976
INFO:root:current train perplexity3.7297213077545166
INFO:root:current mean train loss 3338.8046780580976
INFO:root:current train perplexity3.7273402214050293
INFO:root:current mean train loss 3340.7614453732504
INFO:root:current train perplexity3.7309927940368652
INFO:root:current mean train loss 3342.8331060602077
INFO:root:current train perplexity3.731595516204834
INFO:root:current mean train loss 3343.2909614680643
INFO:root:current train perplexity3.7343385219573975
INFO:root:current mean train loss 3343.508749968932
INFO:root:current train perplexity3.7363717555999756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it]
INFO:root:final mean train loss: 3341.9572982172813
INFO:root:final train perplexity: 3.7378060817718506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4337.241148603724
INFO:root:eval perplexity: 5.776817798614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5418.264257119902
INFO:root:eval perplexity: 9.1669340133667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [7:43:39<5:15:47, 233.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3366.0591107536766
INFO:root:current train perplexity3.7205092906951904
INFO:root:current mean train loss 3342.810873473717
INFO:root:current train perplexity3.716115713119507
INFO:root:current mean train loss 3335.3140193133713
INFO:root:current train perplexity3.7230780124664307
INFO:root:current mean train loss 3336.1432639445334
INFO:root:current train perplexity3.718459367752075
INFO:root:current mean train loss 3333.5424523194984
INFO:root:current train perplexity3.7158498764038086
INFO:root:current mean train loss 3334.679070723684
INFO:root:current train perplexity3.717974901199341
INFO:root:current mean train loss 3336.0613715527793
INFO:root:current train perplexity3.720154285430908
INFO:root:current mean train loss 3335.836424155813
INFO:root:current train perplexity3.723003387451172
INFO:root:current mean train loss 3336.8058998834094
INFO:root:current train perplexity3.725341320037842
INFO:root:current mean train loss 3338.7682656208926
INFO:root:current train perplexity3.7285757064819336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.98s/it]
INFO:root:final mean train loss: 3336.4124701715286
INFO:root:final train perplexity: 3.7296383380889893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4338.777774891955
INFO:root:eval perplexity: 5.78040885925293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5420.088531277704
INFO:root:eval perplexity: 9.173772811889648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [7:47:33<5:11:45, 233.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.244724079714
INFO:root:current train perplexity3.704798460006714
INFO:root:current mean train loss 3320.684954181407
INFO:root:current train perplexity3.7155632972717285
INFO:root:current mean train loss 3318.092483108108
INFO:root:current train perplexity3.7082679271698
INFO:root:current mean train loss 3316.721209767801
INFO:root:current train perplexity3.708988904953003
INFO:root:current mean train loss 3320.167393237677
INFO:root:current train perplexity3.711779832839966
INFO:root:current mean train loss 3326.644958823653
INFO:root:current train perplexity3.7160496711730957
INFO:root:current mean train loss 3327.5438397281628
INFO:root:current train perplexity3.7193756103515625
INFO:root:current mean train loss 3330.997308019907
INFO:root:current train perplexity3.719550371170044
INFO:root:current mean train loss 3333.5189986312207
INFO:root:current train perplexity3.723480224609375
INFO:root:current mean train loss 3335.476884541596
INFO:root:current train perplexity3.7236328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.28s/it]
INFO:root:final mean train loss: 3332.4628138388357
INFO:root:final train perplexity: 3.7238314151763916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4342.330012328236
INFO:root:eval perplexity: 5.788716793060303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5424.360032967642
INFO:root:eval perplexity: 9.189810752868652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [7:51:26<5:07:51, 233.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3287.6323934526586
INFO:root:current train perplexity3.687042713165283
INFO:root:current mean train loss 3313.89111328125
INFO:root:current train perplexity3.691182851791382
INFO:root:current mean train loss 3315.8405350245785
INFO:root:current train perplexity3.6949164867401123
INFO:root:current mean train loss 3316.493344340727
INFO:root:current train perplexity3.6951398849487305
INFO:root:current mean train loss 3318.9709686998126
INFO:root:current train perplexity3.7030715942382812
INFO:root:current mean train loss 3326.325255163553
INFO:root:current train perplexity3.7077653408050537
INFO:root:current mean train loss 3326.8034891245784
INFO:root:current train perplexity3.7119503021240234
INFO:root:current mean train loss 3327.440996908613
INFO:root:current train perplexity3.713798999786377
INFO:root:current mean train loss 3328.316026945015
INFO:root:current train perplexity3.7145562171936035
INFO:root:current mean train loss 3328.7490370709993
INFO:root:current train perplexity3.7153263092041016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.34s/it]
INFO:root:final mean train loss: 3326.611951581893
INFO:root:final train perplexity: 3.715245246887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4346.728188372673
INFO:root:eval perplexity: 5.799023151397705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5434.045718362146
INFO:root:eval perplexity: 9.226277351379395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [7:55:20<5:04:02, 233.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.1978157552085
INFO:root:current train perplexity3.6929636001586914
INFO:root:current mean train loss 3298.782537667411
INFO:root:current train perplexity3.687596082687378
INFO:root:current mean train loss 3309.786700106534
INFO:root:current train perplexity3.693964719772339
INFO:root:current mean train loss 3314.0333528645833
INFO:root:current train perplexity3.6951234340667725
INFO:root:current mean train loss 3313.852409025493
INFO:root:current train perplexity3.694622278213501
INFO:root:current mean train loss 3316.573861667799
INFO:root:current train perplexity3.696772575378418
INFO:root:current mean train loss 3319.041748046875
INFO:root:current train perplexity3.701582908630371
INFO:root:current mean train loss 3321.4901984627018
INFO:root:current train perplexity3.7042644023895264
INFO:root:current mean train loss 3322.7864481026786
INFO:root:current train perplexity3.706831455230713
INFO:root:current mean train loss 3323.8193144030447
INFO:root:current train perplexity3.707491159439087

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.21s/it]
INFO:root:final mean train loss: 3321.499850303896
INFO:root:final train perplexity: 3.7077598571777344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4346.769749418218
INFO:root:eval perplexity: 5.79911994934082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5432.204340508643
INFO:root:eval perplexity: 9.21933364868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [7:59:14<5:00:08, 233.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3322.814123682229
INFO:root:current train perplexity3.6827809810638428
INFO:root:current mean train loss 3319.977194864242
INFO:root:current train perplexity3.676055431365967
INFO:root:current mean train loss 3308.8465269917733
INFO:root:current train perplexity3.673112630844116
INFO:root:current mean train loss 3309.7185160584613
INFO:root:current train perplexity3.6780898571014404
INFO:root:current mean train loss 3311.7896255903856
INFO:root:current train perplexity3.683439016342163
INFO:root:current mean train loss 3311.278716883978
INFO:root:current train perplexity3.6884524822235107
INFO:root:current mean train loss 3312.635185990117
INFO:root:current train perplexity3.691138744354248
INFO:root:current mean train loss 3314.2997707011295
INFO:root:current train perplexity3.6962928771972656
INFO:root:current mean train loss 3315.681987343396
INFO:root:current train perplexity3.6989026069641113
INFO:root:current mean train loss 3318.4271653758424
INFO:root:current train perplexity3.7002408504486084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.85s/it]
INFO:root:final mean train loss: 3316.379347770445
INFO:root:final train perplexity: 3.7002768516540527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4349.050923232491
INFO:root:eval perplexity: 5.804471015930176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5436.192625221631
INFO:root:eval perplexity: 9.234382629394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [8:03:09<4:56:27, 234.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3318.7898861392514
INFO:root:current train perplexity3.6886918544769287
INFO:root:current mean train loss 3316.734029879745
INFO:root:current train perplexity3.691448211669922
INFO:root:current mean train loss 3313.064448091173
INFO:root:current train perplexity3.6871047019958496
INFO:root:current mean train loss 3306.9759562070412
INFO:root:current train perplexity3.6806766986846924
INFO:root:current mean train loss 3305.1429793907523
INFO:root:current train perplexity3.6838598251342773
INFO:root:current mean train loss 3309.7273746496935
INFO:root:current train perplexity3.6865084171295166
INFO:root:current mean train loss 3313.873969380314
INFO:root:current train perplexity3.690972089767456
INFO:root:current mean train loss 3315.678638096555
INFO:root:current train perplexity3.6934165954589844
INFO:root:current mean train loss 3315.626619109936
INFO:root:current train perplexity3.6927034854888916
INFO:root:current mean train loss 3314.729207644188
INFO:root:current train perplexity3.6940414905548096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.11s/it]
INFO:root:final mean train loss: 3312.107489309003
INFO:root:final train perplexity: 3.694045305252075
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4353.202752728835
INFO:root:eval perplexity: 5.814225196838379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5442.980631510417
INFO:root:eval perplexity: 9.260051727294922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [8:07:02<4:52:24, 233.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3315.7714991714015
INFO:root:current train perplexity3.6920628547668457
INFO:root:current mean train loss 3303.790066052921
INFO:root:current train perplexity3.6821913719177246
INFO:root:current mean train loss 3305.8378016239026
INFO:root:current train perplexity3.678755044937134
INFO:root:current mean train loss 3304.05430079104
INFO:root:current train perplexity3.679504632949829
INFO:root:current mean train loss 3309.5401780122747
INFO:root:current train perplexity3.6814053058624268
INFO:root:current mean train loss 3310.278220455316
INFO:root:current train perplexity3.684185028076172
INFO:root:current mean train loss 3308.563364446419
INFO:root:current train perplexity3.6861588954925537
INFO:root:current mean train loss 3307.343653443758
INFO:root:current train perplexity3.6840994358062744
INFO:root:current mean train loss 3309.339090688873
INFO:root:current train perplexity3.686033248901367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it]
INFO:root:final mean train loss: 3308.231077194214
INFO:root:final train perplexity: 3.6884002685546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4353.148489444814
INFO:root:eval perplexity: 5.814096927642822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5440.143388464096
INFO:root:eval perplexity: 9.24931526184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [8:10:56<4:48:25, 233.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.5027204241073
INFO:root:current train perplexity3.6225996017456055
INFO:root:current mean train loss 3277.691155264311
INFO:root:current train perplexity3.6534388065338135
INFO:root:current mean train loss 3284.9943104619565
INFO:root:current train perplexity3.6560723781585693
INFO:root:current mean train loss 3290.4350577985037
INFO:root:current train perplexity3.6629438400268555
INFO:root:current mean train loss 3293.3817135672602
INFO:root:current train perplexity3.6680383682250977
INFO:root:current mean train loss 3296.6027475691876
INFO:root:current train perplexity3.671476364135742
INFO:root:current mean train loss 3297.9261657614293
INFO:root:current train perplexity3.674207925796509
INFO:root:current mean train loss 3299.435207080976
INFO:root:current train perplexity3.6750690937042236
INFO:root:current mean train loss 3300.812339357284
INFO:root:current train perplexity3.6785888671875
INFO:root:current mean train loss 3302.1272290281318
INFO:root:current train perplexity3.6799256801605225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.52s/it]
INFO:root:final mean train loss: 3302.981140936575
INFO:root:final train perplexity: 3.6807684898376465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4357.35409048094
INFO:root:eval perplexity: 5.82399320602417
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5448.343085106383
INFO:root:eval perplexity: 9.280379295349121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [8:14:50<4:44:39, 233.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3208.0861653645834
INFO:root:current train perplexity3.6510345935821533
INFO:root:current mean train loss 3282.1220979110053
INFO:root:current train perplexity3.6500484943389893
INFO:root:current mean train loss 3289.4833200853923
INFO:root:current train perplexity3.6594045162200928
INFO:root:current mean train loss 3291.1271484375
INFO:root:current train perplexity3.6627705097198486
INFO:root:current mean train loss 3294.957719550075
INFO:root:current train perplexity3.6683614253997803
INFO:root:current mean train loss 3300.6337222201155
INFO:root:current train perplexity3.667968273162842
INFO:root:current mean train loss 3301.903837573044
INFO:root:current train perplexity3.6748178005218506
INFO:root:current mean train loss 3303.7786436707825
INFO:root:current train perplexity3.6758885383605957
INFO:root:current mean train loss 3301.535755967216
INFO:root:current train perplexity3.675337791442871
INFO:root:current mean train loss 3301.830152567879
INFO:root:current train perplexity3.676107168197632

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.42s/it]
INFO:root:final mean train loss: 3299.8520300465248
INFO:root:final train perplexity: 3.6762278079986572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4357.183252645723
INFO:root:eval perplexity: 5.82358980178833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5449.46561945922
INFO:root:eval perplexity: 9.284639358520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [8:18:44<4:40:45, 233.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.5769361413045
INFO:root:current train perplexity3.663968801498413
INFO:root:current mean train loss 3295.657244426448
INFO:root:current train perplexity3.6597654819488525
INFO:root:current mean train loss 3297.3299303268636
INFO:root:current train perplexity3.6538946628570557
INFO:root:current mean train loss 3295.7753528323337
INFO:root:current train perplexity3.654019355773926
INFO:root:current mean train loss 3293.150156873338
INFO:root:current train perplexity3.654876708984375
INFO:root:current mean train loss 3295.2880583958236
INFO:root:current train perplexity3.6575419902801514
INFO:root:current mean train loss 3296.9712635119886
INFO:root:current train perplexity3.6598329544067383
INFO:root:current mean train loss 3297.015816800657
INFO:root:current train perplexity3.6626808643341064
INFO:root:current mean train loss 3298.8533474260516
INFO:root:current train perplexity3.66630482673645
INFO:root:current mean train loss 3298.782245342548
INFO:root:current train perplexity3.6693813800811768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.62s/it]
INFO:root:final mean train loss: 3294.9471356791832
INFO:root:final train perplexity: 3.6691205501556396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4361.053447750443
INFO:root:eval perplexity: 5.832712173461914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5451.945925448803
INFO:root:eval perplexity: 9.294063568115234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [8:22:38<4:36:36, 233.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.1189201108873
INFO:root:current train perplexity3.6168177127838135
INFO:root:current mean train loss 3261.0935468600906
INFO:root:current train perplexity3.6487863063812256
INFO:root:current mean train loss 3275.2640269886365
INFO:root:current train perplexity3.650852680206299
INFO:root:current mean train loss 3275.864040224934
INFO:root:current train perplexity3.6538212299346924
INFO:root:current mean train loss 3279.348651505402
INFO:root:current train perplexity3.6542396545410156
INFO:root:current mean train loss 3281.824465649276
INFO:root:current train perplexity3.655898094177246
INFO:root:current mean train loss 3284.96908506463
INFO:root:current train perplexity3.6572890281677246
INFO:root:current mean train loss 3288.28419338075
INFO:root:current train perplexity3.6590821743011475
INFO:root:current mean train loss 3291.8737173068967
INFO:root:current train perplexity3.6599621772766113
INFO:root:current mean train loss 3291.0766735302263
INFO:root:current train perplexity3.6605262756347656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.14s/it]
INFO:root:final mean train loss: 3289.6058667705906
INFO:root:final train perplexity: 3.6613965034484863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4364.029866536458
INFO:root:eval perplexity: 5.839736461639404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5458.725222323803
INFO:root:eval perplexity: 9.319860458374023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [8:26:31<4:32:41, 233.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.2738193609775
INFO:root:current train perplexity3.648991584777832
INFO:root:current mean train loss 3252.3119010650853
INFO:root:current train perplexity3.6380770206451416
INFO:root:current mean train loss 3273.1605382943253
INFO:root:current train perplexity3.646794319152832
INFO:root:current mean train loss 3276.351575463219
INFO:root:current train perplexity3.6398348808288574
INFO:root:current mean train loss 3278.5761991253203
INFO:root:current train perplexity3.644763469696045
INFO:root:current mean train loss 3282.9904305028117
INFO:root:current train perplexity3.6456868648529053
INFO:root:current mean train loss 3283.9148193741444
INFO:root:current train perplexity3.645578145980835
INFO:root:current mean train loss 3286.081532066665
INFO:root:current train perplexity3.6483893394470215
INFO:root:current mean train loss 3286.3728047713053
INFO:root:current train perplexity3.651367425918579
INFO:root:current mean train loss 3288.902580090605
INFO:root:current train perplexity3.6547176837921143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.68s/it]
INFO:root:final mean train loss: 3286.1829210712062
INFO:root:final train perplexity: 3.6564555168151855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4364.60111058012
INFO:root:eval perplexity: 5.841084957122803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5459.0649448692375
INFO:root:eval perplexity: 9.321154594421387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [8:30:26<4:29:00, 233.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3284.419475149601
INFO:root:current train perplexity3.649404525756836
INFO:root:current mean train loss 3282.2450690237033
INFO:root:current train perplexity3.633141040802002
INFO:root:current mean train loss 3280.3130920657263
INFO:root:current train perplexity3.639239549636841
INFO:root:current mean train loss 3279.3672444895983
INFO:root:current train perplexity3.641265630722046
INFO:root:current mean train loss 3275.5454243568233
INFO:root:current train perplexity3.6411702632904053
INFO:root:current mean train loss 3282.2110106975547
INFO:root:current train perplexity3.6464834213256836
INFO:root:current mean train loss 3285.3745596412527
INFO:root:current train perplexity3.650352716445923
INFO:root:current mean train loss 3287.9334741308985
INFO:root:current train perplexity3.6518423557281494
INFO:root:current mean train loss 3286.514923996458
INFO:root:current train perplexity3.653378963470459
INFO:root:current mean train loss 3286.411106000858
INFO:root:current train perplexity3.6522269248962402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it]
INFO:root:final mean train loss: 3282.8409689011114
INFO:root:final train perplexity: 3.651637315750122
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4367.108652967087
INFO:root:eval perplexity: 5.847010612487793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it]
INFO:root:eval mean loss: 5462.333406056073
INFO:root:eval perplexity: 9.333622932434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [8:34:20<4:25:17, 234.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.582998934659
INFO:root:current train perplexity3.5754213333129883
INFO:root:current mean train loss 3253.5835653981853
INFO:root:current train perplexity3.5886313915252686
INFO:root:current mean train loss 3271.105107804841
INFO:root:current train perplexity3.6058216094970703
INFO:root:current mean train loss 3273.2026401573503
INFO:root:current train perplexity3.613410234451294
INFO:root:current mean train loss 3273.2898367745534
INFO:root:current train perplexity3.6223831176757812
INFO:root:current mean train loss 3273.6683140660193
INFO:root:current train perplexity3.628283739089966
INFO:root:current mean train loss 3274.3316905713264
INFO:root:current train perplexity3.6333086490631104
INFO:root:current mean train loss 3275.7342514745446
INFO:root:current train perplexity3.6356005668640137
INFO:root:current mean train loss 3279.2825380916483
INFO:root:current train perplexity3.6408016681671143
INFO:root:current mean train loss 3278.9007620766524
INFO:root:current train perplexity3.6432759761810303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it]
INFO:root:final mean train loss: 3277.9890162560246
INFO:root:final train perplexity: 3.644653797149658
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4368.089229069703
INFO:root:eval perplexity: 5.849329471588135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5463.651356798538
INFO:root:eval perplexity: 9.338653564453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [8:38:14<4:21:17, 233.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.515807136657
INFO:root:current train perplexity3.619464874267578
INFO:root:current mean train loss 3265.339798816143
INFO:root:current train perplexity3.637669801712036
INFO:root:current mean train loss 3270.1414307568916
INFO:root:current train perplexity3.6412408351898193
INFO:root:current mean train loss 3270.4963842975208
INFO:root:current train perplexity3.639572858810425
INFO:root:current mean train loss 3264.2155387334637
INFO:root:current train perplexity3.6343235969543457
INFO:root:current mean train loss 3268.209591040603
INFO:root:current train perplexity3.633904218673706
INFO:root:current mean train loss 3269.2865831654176
INFO:root:current train perplexity3.635204553604126
INFO:root:current mean train loss 3270.8934718140767
INFO:root:current train perplexity3.6354386806488037
INFO:root:current mean train loss 3270.3505624569993
INFO:root:current train perplexity3.634909152984619
INFO:root:current mean train loss 3274.1521452431366
INFO:root:current train perplexity3.6370949745178223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.84s/it]
INFO:root:final mean train loss: 3272.189798293575
INFO:root:final train perplexity: 3.636324882507324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4371.354471409574
INFO:root:eval perplexity: 5.857057094573975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5466.251582585328
INFO:root:eval perplexity: 9.348588943481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [8:42:07<4:17:13, 233.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.5509738116198
INFO:root:current train perplexity3.6141998767852783
INFO:root:current mean train loss 3262.5835988898025
INFO:root:current train perplexity3.608091354370117
INFO:root:current mean train loss 3266.122078420491
INFO:root:current train perplexity3.6190078258514404
INFO:root:current mean train loss 3272.2765731605878
INFO:root:current train perplexity3.6256120204925537
INFO:root:current mean train loss 3267.8924418001925
INFO:root:current train perplexity3.6235578060150146
INFO:root:current mean train loss 3269.4038132969845
INFO:root:current train perplexity3.6232872009277344
INFO:root:current mean train loss 3271.24522561359
INFO:root:current train perplexity3.6265664100646973
INFO:root:current mean train loss 3272.9579096496027
INFO:root:current train perplexity3.6303598880767822
INFO:root:current mean train loss 3271.549008357402
INFO:root:current train perplexity3.6316490173339844
INFO:root:current mean train loss 3271.3417682117342
INFO:root:current train perplexity3.6332757472991943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.05s/it]
INFO:root:final mean train loss: 3270.204328660042
INFO:root:final train perplexity: 3.633477210998535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4374.204404573914
INFO:root:eval perplexity: 5.863811492919922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5473.261459025931
INFO:root:eval perplexity: 9.375425338745117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [8:46:01<4:13:15, 233.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.1207043611553
INFO:root:current train perplexity3.6149940490722656
INFO:root:current mean train loss 3258.7454445268854
INFO:root:current train perplexity3.6075947284698486
INFO:root:current mean train loss 3263.9096478424617
INFO:root:current train perplexity3.614576816558838
INFO:root:current mean train loss 3259.8300562232025
INFO:root:current train perplexity3.6129515171051025
INFO:root:current mean train loss 3261.665936113648
INFO:root:current train perplexity3.615685224533081
INFO:root:current mean train loss 3260.019516070272
INFO:root:current train perplexity3.617020845413208
INFO:root:current mean train loss 3262.795219230371
INFO:root:current train perplexity3.619945526123047
INFO:root:current mean train loss 3263.9934345289435
INFO:root:current train perplexity3.621875762939453
INFO:root:current mean train loss 3267.0268213057275
INFO:root:current train perplexity3.6257827281951904
INFO:root:current mean train loss 3267.788991676775
INFO:root:current train perplexity3.626434564590454

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.25s/it]
INFO:root:final mean train loss: 3265.3799540612004
INFO:root:final train perplexity: 3.626568555831909
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4377.455914436503
INFO:root:eval perplexity: 5.871527194976807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 5478.560436059397
INFO:root:eval perplexity: 9.395759582519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [8:49:56<4:09:46, 234.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.628314138829
INFO:root:current train perplexity3.611567497253418
INFO:root:current mean train loss 3257.0561706216577
INFO:root:current train perplexity3.611125946044922
INFO:root:current mean train loss 3260.168760718369
INFO:root:current train perplexity3.6123201847076416
INFO:root:current mean train loss 3258.2420695302408
INFO:root:current train perplexity3.613565683364868
INFO:root:current mean train loss 3261.300916605172
INFO:root:current train perplexity3.6146531105041504
INFO:root:current mean train loss 3264.3478571357273
INFO:root:current train perplexity3.6180472373962402
INFO:root:current mean train loss 3264.049327778157
INFO:root:current train perplexity3.621109962463379
INFO:root:current mean train loss 3263.1695834284665
INFO:root:current train perplexity3.622044563293457
INFO:root:current mean train loss 3263.4127005971673
INFO:root:current train perplexity3.6217265129089355
INFO:root:current mean train loss 3264.225836014675
INFO:root:current train perplexity3.6213128566741943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.49s/it]
INFO:root:final mean train loss: 3261.782422158026
INFO:root:final train perplexity: 3.621425151824951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4377.160495622784
INFO:root:eval perplexity: 5.870825290679932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5475.365577210771
INFO:root:eval perplexity: 9.383493423461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [8:53:52<4:06:32, 234.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.2809339021383
INFO:root:current train perplexity3.5951778888702393
INFO:root:current mean train loss 3245.062322215545
INFO:root:current train perplexity3.5969371795654297
INFO:root:current mean train loss 3255.404582395392
INFO:root:current train perplexity3.603313446044922
INFO:root:current mean train loss 3247.7234133949764
INFO:root:current train perplexity3.6068196296691895
INFO:root:current mean train loss 3246.440798611111
INFO:root:current train perplexity3.6037185192108154
INFO:root:current mean train loss 3252.1459308528097
INFO:root:current train perplexity3.6070618629455566
INFO:root:current mean train loss 3255.1568858194696
INFO:root:current train perplexity3.6133103370666504
INFO:root:current mean train loss 3257.5425059576455
INFO:root:current train perplexity3.614107608795166
INFO:root:current mean train loss 3258.726806367842
INFO:root:current train perplexity3.6145079135894775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.23s/it]
INFO:root:final mean train loss: 3257.6781445780107
INFO:root:final train perplexity: 3.6155660152435303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 4379.62219324856
INFO:root:eval perplexity: 5.876671314239502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5478.294949578901
INFO:root:eval perplexity: 9.394742012023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [8:57:48<4:02:59, 235.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3233.9407552083335
INFO:root:current train perplexity3.6345276832580566
INFO:root:current mean train loss 3250.746845134254
INFO:root:current train perplexity3.581681966781616
INFO:root:current mean train loss 3247.923765586515
INFO:root:current train perplexity3.592885732650757
INFO:root:current mean train loss 3250.723131639336
INFO:root:current train perplexity3.5976641178131104
INFO:root:current mean train loss 3258.080304697193
INFO:root:current train perplexity3.5989229679107666
INFO:root:current mean train loss 3256.6094696469618
INFO:root:current train perplexity3.5999231338500977
INFO:root:current mean train loss 3256.125028341366
INFO:root:current train perplexity3.6011524200439453
INFO:root:current mean train loss 3254.7473568217683
INFO:root:current train perplexity3.6015830039978027
INFO:root:current mean train loss 3254.090100660122
INFO:root:current train perplexity3.603952169418335
INFO:root:current mean train loss 3254.6438085613063
INFO:root:current train perplexity3.6073620319366455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.20s/it]
INFO:root:final mean train loss: 3252.710587470762
INFO:root:final train perplexity: 3.608485698699951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 4380.1377801556955
INFO:root:eval perplexity: 5.877898216247559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5481.341073110594
INFO:root:eval perplexity: 9.406448364257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [9:01:44<3:59:20, 235.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.3248180042615
INFO:root:current train perplexity3.5376715660095215
INFO:root:current mean train loss 3236.3660547754785
INFO:root:current train perplexity3.585946559906006
INFO:root:current mean train loss 3233.965890893439
INFO:root:current train perplexity3.585655450820923
INFO:root:current mean train loss 3242.6737237175944
INFO:root:current train perplexity3.588200569152832
INFO:root:current mean train loss 3245.087262749962
INFO:root:current train perplexity3.5932116508483887
INFO:root:current mean train loss 3245.37262165943
INFO:root:current train perplexity3.5953917503356934
INFO:root:current mean train loss 3248.1705292297465
INFO:root:current train perplexity3.5970675945281982
INFO:root:current mean train loss 3250.5248635422163
INFO:root:current train perplexity3.5996129512786865
INFO:root:current mean train loss 3251.221422301268
INFO:root:current train perplexity3.6010353565216064
INFO:root:current mean train loss 3251.104091539603
INFO:root:current train perplexity3.601937770843506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.21s/it]
INFO:root:final mean train loss: 3249.813746236986
INFO:root:final train perplexity: 3.6043646335601807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4383.218370802859
INFO:root:eval perplexity: 5.885223388671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5486.499400903147
INFO:root:eval perplexity: 9.426310539245605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [9:05:39<3:55:17, 235.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.1357678865133
INFO:root:current train perplexity3.5646867752075195
INFO:root:current mean train loss 3256.640083377101
INFO:root:current train perplexity3.6017394065856934
INFO:root:current mean train loss 3259.516647269192
INFO:root:current train perplexity3.596820592880249
INFO:root:current mean train loss 3254.751213815145
INFO:root:current train perplexity3.5914900302886963
INFO:root:current mean train loss 3253.524844658972
INFO:root:current train perplexity3.5932676792144775
INFO:root:current mean train loss 3252.188910276674
INFO:root:current train perplexity3.5903663635253906
INFO:root:current mean train loss 3248.1543911393123
INFO:root:current train perplexity3.589921236038208
INFO:root:current mean train loss 3249.0367073409247
INFO:root:current train perplexity3.594350814819336
INFO:root:current mean train loss 3248.8939350579976
INFO:root:current train perplexity3.597043514251709
INFO:root:current mean train loss 3248.21875
INFO:root:current train perplexity3.596954822540283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.22s/it]
INFO:root:final mean train loss: 3245.7681819546606
INFO:root:final train perplexity: 3.598616361618042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4386.729755374557
INFO:root:eval perplexity: 5.893587112426758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5488.981327570922
INFO:root:eval perplexity: 9.435884475708008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [9:09:35<3:51:36, 235.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.1787380642363
INFO:root:current train perplexity3.568664312362671
INFO:root:current mean train loss 3242.43571412094
INFO:root:current train perplexity3.578913450241089
INFO:root:current mean train loss 3235.311722406732
INFO:root:current train perplexity3.5838704109191895
INFO:root:current mean train loss 3239.0669243955467
INFO:root:current train perplexity3.584367036819458
INFO:root:current mean train loss 3239.2575249057745
INFO:root:current train perplexity3.587082624435425
INFO:root:current mean train loss 3243.212232788781
INFO:root:current train perplexity3.5915029048919678
INFO:root:current mean train loss 3242.3799933961322
INFO:root:current train perplexity3.592355489730835
INFO:root:current mean train loss 3243.0830974762507
INFO:root:current train perplexity3.595582962036133
INFO:root:current mean train loss 3245.346530310044
INFO:root:current train perplexity3.5965301990509033
INFO:root:current mean train loss 3245.673068049656
INFO:root:current train perplexity3.597069263458252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.42s/it]
INFO:root:final mean train loss: 3243.5222960441342
INFO:root:final train perplexity: 3.5954294204711914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4385.6115168578235
INFO:root:eval perplexity: 5.890921592712402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5490.934172068927
INFO:root:eval perplexity: 9.443422317504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [9:13:32<3:47:53, 235.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.0799246651786
INFO:root:current train perplexity3.572254180908203
INFO:root:current mean train loss 3226.189456741898
INFO:root:current train perplexity3.5770392417907715
INFO:root:current mean train loss 3229.1076421210105
INFO:root:current train perplexity3.5776655673980713
INFO:root:current mean train loss 3232.7881136310634
INFO:root:current train perplexity3.5748400688171387
INFO:root:current mean train loss 3239.801998585668
INFO:root:current train perplexity3.5780670642852783
INFO:root:current mean train loss 3234.864772561332
INFO:root:current train perplexity3.5755202770233154
INFO:root:current mean train loss 3239.3292276697834
INFO:root:current train perplexity3.5810651779174805
INFO:root:current mean train loss 3237.2125415205146
INFO:root:current train perplexity3.5835137367248535
INFO:root:current mean train loss 3238.2085648039856
INFO:root:current train perplexity3.5846140384674072
INFO:root:current mean train loss 3240.3435826265877
INFO:root:current train perplexity3.5884671211242676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.77s/it]
INFO:root:final mean train loss: 3239.018684571789
INFO:root:final train perplexity: 3.5890467166900635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4387.110587045656
INFO:root:eval perplexity: 5.894493579864502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5490.935401429521
INFO:root:eval perplexity: 9.443426132202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [9:17:27<3:43:52, 235.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.1655670875725
INFO:root:current train perplexity3.5743277072906494
INFO:root:current mean train loss 3245.130584503387
INFO:root:current train perplexity3.5769309997558594
INFO:root:current mean train loss 3237.7737861287937
INFO:root:current train perplexity3.5764963626861572
INFO:root:current mean train loss 3236.213745473078
INFO:root:current train perplexity3.575941801071167
INFO:root:current mean train loss 3236.677372297369
INFO:root:current train perplexity3.580559730529785
INFO:root:current mean train loss 3234.819361115907
INFO:root:current train perplexity3.580655336380005
INFO:root:current mean train loss 3236.5392064024836
INFO:root:current train perplexity3.581544876098633
INFO:root:current mean train loss 3238.493356286276
INFO:root:current train perplexity3.585023880004883
INFO:root:current mean train loss 3238.782106374648
INFO:root:current train perplexity3.5844249725341797
INFO:root:current mean train loss 3238.016406353559
INFO:root:current train perplexity3.5848469734191895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.59s/it]
INFO:root:final mean train loss: 3235.279896151635
INFO:root:final train perplexity: 3.5837559700012207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4391.761304922983
INFO:root:eval perplexity: 5.905590057373047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5496.424046293218
INFO:root:eval perplexity: 9.464643478393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [9:21:21<3:39:32, 235.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.2292719822303
INFO:root:current train perplexity3.546767473220825
INFO:root:current mean train loss 3222.366372620033
INFO:root:current train perplexity3.569338798522949
INFO:root:current mean train loss 3230.0724971208915
INFO:root:current train perplexity3.5723721981048584
INFO:root:current mean train loss 3233.388957053508
INFO:root:current train perplexity3.57440185546875
INFO:root:current mean train loss 3237.194147012715
INFO:root:current train perplexity3.573014736175537
INFO:root:current mean train loss 3234.518527216141
INFO:root:current train perplexity3.5722806453704834
INFO:root:current mean train loss 3230.1159829229073
INFO:root:current train perplexity3.572504997253418
INFO:root:current mean train loss 3232.9846204409746
INFO:root:current train perplexity3.5749239921569824
INFO:root:current mean train loss 3231.2448744813087
INFO:root:current train perplexity3.574838638305664
INFO:root:current mean train loss 3233.7129173238695
INFO:root:current train perplexity3.5770251750946045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.82s/it]
INFO:root:final mean train loss: 3231.2805224387876
INFO:root:final train perplexity: 3.578106164932251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4392.555473598182
INFO:root:eval perplexity: 5.907486438751221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5498.67626953125
INFO:root:eval perplexity: 9.473366737365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [9:25:17<3:35:42, 235.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.378691075212
INFO:root:current train perplexity3.549957752227783
INFO:root:current mean train loss 3216.361212964328
INFO:root:current train perplexity3.5583760738372803
INFO:root:current mean train loss 3223.5563993122587
INFO:root:current train perplexity3.5622947216033936
INFO:root:current mean train loss 3228.6168671929404
INFO:root:current train perplexity3.569876194000244
INFO:root:current mean train loss 3231.084906684028
INFO:root:current train perplexity3.569889783859253
INFO:root:current mean train loss 3228.0449113931127
INFO:root:current train perplexity3.5707802772521973
INFO:root:current mean train loss 3229.008319304818
INFO:root:current train perplexity3.5724849700927734
INFO:root:current mean train loss 3229.709895318676
INFO:root:current train perplexity3.575023651123047
INFO:root:current mean train loss 3231.767887066629
INFO:root:current train perplexity3.5734057426452637
INFO:root:current mean train loss 3230.6711596348737
INFO:root:current train perplexity3.5744991302490234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.79s/it]
INFO:root:final mean train loss: 3229.1530272576115
INFO:root:final train perplexity: 3.575104236602783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4393.433533147717
INFO:root:eval perplexity: 5.9095845222473145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 5502.9682651817375
INFO:root:eval perplexity: 9.490007400512695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [9:29:12<3:31:52, 235.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.395748309235
INFO:root:current train perplexity3.547483444213867
INFO:root:current mean train loss 3213.4772335212388
INFO:root:current train perplexity3.5465712547302246
INFO:root:current mean train loss 3218.6909874619614
INFO:root:current train perplexity3.54878568649292
INFO:root:current mean train loss 3222.1878725306537
INFO:root:current train perplexity3.556528329849243
INFO:root:current mean train loss 3224.120571487721
INFO:root:current train perplexity3.5601789951324463
INFO:root:current mean train loss 3224.8119169904653
INFO:root:current train perplexity3.561288833618164
INFO:root:current mean train loss 3228.511585515836
INFO:root:current train perplexity3.567355155944824
INFO:root:current mean train loss 3228.436754845889
INFO:root:current train perplexity3.56831431388855
INFO:root:current mean train loss 3229.692945434148
INFO:root:current train perplexity3.569988489151001
INFO:root:current mean train loss 3229.405241878474
INFO:root:current train perplexity3.570610761642456

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.29s/it]
INFO:root:final mean train loss: 3226.1469145128804
INFO:root:final train perplexity: 3.570866584777832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4396.997633047983
INFO:root:eval perplexity: 5.918107509613037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5506.875844968971
INFO:root:eval perplexity: 9.5051851272583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [9:33:09<3:28:08, 235.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.455244140625
INFO:root:current train perplexity3.5416924953460693
INFO:root:current mean train loss 3209.380263671875
INFO:root:current train perplexity3.5479612350463867
INFO:root:current mean train loss 3209.9561150568184
INFO:root:current train perplexity3.548811435699463
INFO:root:current mean train loss 3214.1054986979166
INFO:root:current train perplexity3.5518572330474854
INFO:root:current mean train loss 3215.604683388158
INFO:root:current train perplexity3.5535311698913574
INFO:root:current mean train loss 3216.706153617527
INFO:root:current train perplexity3.5564587116241455
INFO:root:current mean train loss 3218.549283130787
INFO:root:current train perplexity3.5573179721832275
INFO:root:current mean train loss 3219.939006426411
INFO:root:current train perplexity3.558006525039673
INFO:root:current mean train loss 3222.695654575893
INFO:root:current train perplexity3.56044340133667
INFO:root:current mean train loss 3223.4696892528045
INFO:root:current train perplexity3.563469886779785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.69s/it]
INFO:root:final mean train loss: 3221.54014759679
INFO:root:final train perplexity: 3.564382553100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 4398.009452224624
INFO:root:eval perplexity: 5.920528888702393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 5506.050126745346
INFO:root:eval perplexity: 9.501975059509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [9:37:05<3:24:26, 235.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.7254123917546
INFO:root:current train perplexity3.5535173416137695
INFO:root:current mean train loss 3231.7440365650614
INFO:root:current train perplexity3.5583057403564453
INFO:root:current mean train loss 3225.8275012767776
INFO:root:current train perplexity3.5556037425994873
INFO:root:current mean train loss 3224.3856784432114
INFO:root:current train perplexity3.557816505432129
INFO:root:current mean train loss 3224.4826513570783
INFO:root:current train perplexity3.562623977661133
INFO:root:current mean train loss 3221.039076319281
INFO:root:current train perplexity3.5608997344970703
INFO:root:current mean train loss 3218.944400636553
INFO:root:current train perplexity3.5600638389587402
INFO:root:current mean train loss 3219.7705461640926
INFO:root:current train perplexity3.5605010986328125
INFO:root:current mean train loss 3222.1164133281427
INFO:root:current train perplexity3.5609734058380127
INFO:root:current mean train loss 3223.1975857646394
INFO:root:current train perplexity3.5622103214263916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.49s/it]
INFO:root:final mean train loss: 3220.2309281133835
INFO:root:final train perplexity: 3.5625414848327637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4397.683986799091
INFO:root:eval perplexity: 5.919750690460205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5506.834489971188
INFO:root:eval perplexity: 9.505022048950195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [9:41:01<3:20:35, 235.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.9526635473903
INFO:root:current train perplexity3.5443761348724365
INFO:root:current mean train loss 3217.630288009244
INFO:root:current train perplexity3.550994396209717
INFO:root:current mean train loss 3215.174592427781
INFO:root:current train perplexity3.554882764816284
INFO:root:current mean train loss 3214.6890316546114
INFO:root:current train perplexity3.554393768310547
INFO:root:current mean train loss 3212.6460975289588
INFO:root:current train perplexity3.557029962539673
INFO:root:current mean train loss 3213.990650364187
INFO:root:current train perplexity3.557471752166748
INFO:root:current mean train loss 3213.126353549543
INFO:root:current train perplexity3.5587494373321533
INFO:root:current mean train loss 3219.353045862634
INFO:root:current train perplexity3.5594561100006104
INFO:root:current mean train loss 3219.327374493634
INFO:root:current train perplexity3.5576012134552
INFO:root:current mean train loss 3218.9962524044527
INFO:root:current train perplexity3.557250738143921

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.99s/it]
INFO:root:final mean train loss: 3216.416259765625
INFO:root:final train perplexity: 3.5571846961975098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4400.977206615691
INFO:root:eval perplexity: 5.927638530731201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 5511.457194010417
INFO:root:eval perplexity: 9.523005485534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [9:44:57<3:16:37, 235.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.348050820707
INFO:root:current train perplexity3.5341203212738037
INFO:root:current mean train loss 3218.8542259638034
INFO:root:current train perplexity3.544130563735962
INFO:root:current mean train loss 3223.025931980299
INFO:root:current train perplexity3.5440707206726074
INFO:root:current mean train loss 3220.5466822574012
INFO:root:current train perplexity3.546600103378296
INFO:root:current mean train loss 3218.0222921428795
INFO:root:current train perplexity3.548199415206909
INFO:root:current mean train loss 3218.956009853662
INFO:root:current train perplexity3.548776865005493
INFO:root:current mean train loss 3215.3089891250893
INFO:root:current train perplexity3.548617362976074
INFO:root:current mean train loss 3214.343485692565
INFO:root:current train perplexity3.549983263015747
INFO:root:current mean train loss 3216.5435314411848
INFO:root:current train perplexity3.5520176887512207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it]
INFO:root:final mean train loss: 3212.943846671812
INFO:root:final train perplexity: 3.552314519882202
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4403.297150307513
INFO:root:eval perplexity: 5.933202266693115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5516.145448941711
INFO:root:eval perplexity: 9.541281700134277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [9:48:51<3:12:08, 235.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.1210588727677
INFO:root:current train perplexity3.527343511581421
INFO:root:current mean train loss 3186.7523683922313
INFO:root:current train perplexity3.5284292697906494
INFO:root:current mean train loss 3199.3392740885415
INFO:root:current train perplexity3.5311357975006104
INFO:root:current mean train loss 3207.4297924725165
INFO:root:current train perplexity3.539079189300537
INFO:root:current mean train loss 3209.2345405597357
INFO:root:current train perplexity3.5415759086608887
INFO:root:current mean train loss 3209.785591080344
INFO:root:current train perplexity3.5447051525115967
INFO:root:current mean train loss 3206.852927998224
INFO:root:current train perplexity3.5442190170288086
INFO:root:current mean train loss 3208.016933759503
INFO:root:current train perplexity3.5422210693359375
INFO:root:current mean train loss 3208.9574820176967
INFO:root:current train perplexity3.543592691421509
INFO:root:current mean train loss 3211.4449962208
INFO:root:current train perplexity3.5462052822113037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.46s/it]
INFO:root:final mean train loss: 3210.105345079976
INFO:root:final train perplexity: 3.5483386516571045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 4403.539081546432
INFO:root:eval perplexity: 5.933783531188965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it]
INFO:root:eval mean loss: 5519.950749390514
INFO:root:eval perplexity: 9.55613899230957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [9:52:46<3:08:13, 235.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3205.4650390625
INFO:root:current train perplexity3.5482285022735596
INFO:root:current mean train loss 3196.984192425272
INFO:root:current train perplexity3.525912284851074
INFO:root:current mean train loss 3194.114397483648
INFO:root:current train perplexity3.5237720012664795
INFO:root:current mean train loss 3202.5946041046627
INFO:root:current train perplexity3.5269410610198975
INFO:root:current mean train loss 3202.3485898672816
INFO:root:current train perplexity3.530479669570923
INFO:root:current mean train loss 3203.3731440571905
INFO:root:current train perplexity3.532517671585083
INFO:root:current mean train loss 3204.210659219385
INFO:root:current train perplexity3.535172462463379
INFO:root:current mean train loss 3206.2397098994757
INFO:root:current train perplexity3.5381417274475098
INFO:root:current mean train loss 3205.9924295437118
INFO:root:current train perplexity3.5398411750793457
INFO:root:current mean train loss 3209.0828127668206
INFO:root:current train perplexity3.5435168743133545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.66s/it]
INFO:root:final mean train loss: 3207.558930550852
INFO:root:final train perplexity: 3.5447754859924316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4406.476581546432
INFO:root:eval perplexity: 5.940835475921631
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5521.45293799867
INFO:root:eval perplexity: 9.562009811401367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [9:56:43<3:04:34, 235.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.857676630435
INFO:root:current train perplexity3.524064302444458
INFO:root:current mean train loss 3202.7788939437246
INFO:root:current train perplexity3.516418695449829
INFO:root:current mean train loss 3196.345823553111
INFO:root:current train perplexity3.526242256164551
INFO:root:current mean train loss 3198.763609895027
INFO:root:current train perplexity3.5270180702209473
INFO:root:current mean train loss 3200.60126122008
INFO:root:current train perplexity3.5280966758728027
INFO:root:current mean train loss 3201.615747863886
INFO:root:current train perplexity3.5279157161712646
INFO:root:current mean train loss 3204.5688680339586
INFO:root:current train perplexity3.5339150428771973
INFO:root:current mean train loss 3208.3230169567987
INFO:root:current train perplexity3.537781238555908
INFO:root:current mean train loss 3206.0489099996203
INFO:root:current train perplexity3.538623809814453
INFO:root:current mean train loss 3205.426521342599
INFO:root:current train perplexity3.5378401279449463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.48s/it]
INFO:root:final mean train loss: 3203.6027516395816
INFO:root:final train perplexity: 3.5392470359802246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4408.436964968418
INFO:root:eval perplexity: 5.945548057556152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5523.77707017398
INFO:root:eval perplexity: 9.571099281311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [10:00:39<3:00:46, 235.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.6617392263106
INFO:root:current train perplexity3.5683441162109375
INFO:root:current mean train loss 3203.9759195342317
INFO:root:current train perplexity3.5303077697753906
INFO:root:current mean train loss 3194.5967113940746
INFO:root:current train perplexity3.5313429832458496
INFO:root:current mean train loss 3194.958659837613
INFO:root:current train perplexity3.5246095657348633
INFO:root:current mean train loss 3194.6327377283933
INFO:root:current train perplexity3.523622751235962
INFO:root:current mean train loss 3197.2159577852813
INFO:root:current train perplexity3.527427911758423
INFO:root:current mean train loss 3200.7049918439234
INFO:root:current train perplexity3.531489372253418
INFO:root:current mean train loss 3202.37027015112
INFO:root:current train perplexity3.532738208770752
INFO:root:current mean train loss 3199.838756134364
INFO:root:current train perplexity3.5316321849823
INFO:root:current mean train loss 3200.997928082623
INFO:root:current train perplexity3.5331997871398926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.19s/it]
INFO:root:final mean train loss: 3200.0570013600013
INFO:root:final train perplexity: 3.534299373626709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4409.171852490581
INFO:root:eval perplexity: 5.9473137855529785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 5524.614843057402
INFO:root:eval perplexity: 9.574378967285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [10:04:35<2:56:54, 235.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3174.4119653946314
INFO:root:current train perplexity3.500497579574585
INFO:root:current mean train loss 3182.0755641580486
INFO:root:current train perplexity3.513108253479004
INFO:root:current mean train loss 3189.1604627026672
INFO:root:current train perplexity3.5211844444274902
INFO:root:current mean train loss 3191.926674991934
INFO:root:current train perplexity3.52957820892334
INFO:root:current mean train loss 3196.912282331115
INFO:root:current train perplexity3.5302789211273193
INFO:root:current mean train loss 3198.440564666918
INFO:root:current train perplexity3.5293972492218018
INFO:root:current mean train loss 3199.942634594459
INFO:root:current train perplexity3.5323424339294434
INFO:root:current mean train loss 3201.9798436971414
INFO:root:current train perplexity3.531496047973633
INFO:root:current mean train loss 3200.5563572007227
INFO:root:current train perplexity3.531691074371338
INFO:root:current mean train loss 3200.1342599237055
INFO:root:current train perplexity3.531832456588745

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.54s/it]
INFO:root:final mean train loss: 3197.854978807511
INFO:root:final train perplexity: 3.531230926513672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4410.979345010527
INFO:root:eval perplexity: 5.951663017272949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5528.024625304743
INFO:root:eval perplexity: 9.58774185180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [10:08:31<2:53:02, 235.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.7759516289893
INFO:root:current train perplexity3.5218305587768555
INFO:root:current mean train loss 3198.4795486554
INFO:root:current train perplexity3.512742757797241
INFO:root:current mean train loss 3193.453740787892
INFO:root:current train perplexity3.518904685974121
INFO:root:current mean train loss 3192.2466052492346
INFO:root:current train perplexity3.518831491470337
INFO:root:current mean train loss 3195.72537839066
INFO:root:current train perplexity3.5213863849639893
INFO:root:current mean train loss 3195.6220671882143
INFO:root:current train perplexity3.52384614944458
INFO:root:current mean train loss 3197.8760493896107
INFO:root:current train perplexity3.523332118988037
INFO:root:current mean train loss 3197.149727490692
INFO:root:current train perplexity3.5220866203308105
INFO:root:current mean train loss 3197.3985441493874
INFO:root:current train perplexity3.5265984535217285
INFO:root:current mean train loss 3197.321139536035
INFO:root:current train perplexity3.526925563812256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.78s/it]
INFO:root:final mean train loss: 3194.928449076991
INFO:root:final train perplexity: 3.5271553993225098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4410.849044908023
INFO:root:eval perplexity: 5.951347351074219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5528.134748310062
INFO:root:eval perplexity: 9.588173866271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [10:12:25<2:48:46, 235.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3174.962220348011
INFO:root:current train perplexity3.5052387714385986
INFO:root:current mean train loss 3174.1962181829635
INFO:root:current train perplexity3.495666980743408
INFO:root:current mean train loss 3188.775325520833
INFO:root:current train perplexity3.5084731578826904
INFO:root:current mean train loss 3188.119696302817
INFO:root:current train perplexity3.5113272666931152
INFO:root:current mean train loss 3190.212117960165
INFO:root:current train perplexity3.5121796131134033
INFO:root:current mean train loss 3187.746442585163
INFO:root:current train perplexity3.5100152492523193
INFO:root:current mean train loss 3188.744378429151
INFO:root:current train perplexity3.509956121444702
INFO:root:current mean train loss 3189.3677482150247
INFO:root:current train perplexity3.5154480934143066
INFO:root:current mean train loss 3190.695995237116
INFO:root:current train perplexity3.5191314220428467
INFO:root:current mean train loss 3194.6276423429317
INFO:root:current train perplexity3.523956298828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.13s/it]
INFO:root:final mean train loss: 3193.1985184454147
INFO:root:final train perplexity: 3.5247483253479004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4411.47264239805
INFO:root:eval perplexity: 5.952849388122559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5531.729596077128
INFO:root:eval perplexity: 9.602277755737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [10:16:19<2:44:28, 234.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.9796316964284
INFO:root:current train perplexity3.51645565032959
INFO:root:current mean train loss 3184.62063692245
INFO:root:current train perplexity3.4957492351531982
INFO:root:current mean train loss 3182.5201671295745
INFO:root:current train perplexity3.506350517272949
INFO:root:current mean train loss 3184.4029510750256
INFO:root:current train perplexity3.508915662765503
INFO:root:current mean train loss 3188.810850600702
INFO:root:current train perplexity3.511145830154419
INFO:root:current mean train loss 3191.5878468271258
INFO:root:current train perplexity3.519582986831665
INFO:root:current mean train loss 3191.7678867069662
INFO:root:current train perplexity3.5217678546905518
INFO:root:current mean train loss 3191.6262536605095
INFO:root:current train perplexity3.521212577819824
INFO:root:current mean train loss 3193.100695135972
INFO:root:current train perplexity3.5229268074035645
INFO:root:current mean train loss 3194.039698583934
INFO:root:current train perplexity3.522763967514038

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it]
INFO:root:final mean train loss: 3191.942353340887
INFO:root:final train perplexity: 3.5230023860931396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 4414.573952099956
INFO:root:eval perplexity: 5.960319995880127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5533.169239666445
INFO:root:eval perplexity: 9.607932090759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [10:20:13<2:40:18, 234.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3178.893369003081
INFO:root:current train perplexity3.4942667484283447
INFO:root:current mean train loss 3185.6150673314146
INFO:root:current train perplexity3.508953809738159
INFO:root:current mean train loss 3192.3883835908673
INFO:root:current train perplexity3.5115432739257812
INFO:root:current mean train loss 3195.478064853226
INFO:root:current train perplexity3.511120080947876
INFO:root:current mean train loss 3192.4921040464105
INFO:root:current train perplexity3.5133073329925537
INFO:root:current mean train loss 3190.097486078426
INFO:root:current train perplexity3.5144503116607666
INFO:root:current mean train loss 3191.40040044884
INFO:root:current train perplexity3.514369487762451
INFO:root:current mean train loss 3190.7592250957564
INFO:root:current train perplexity3.513634443283081
INFO:root:current mean train loss 3191.154432820124
INFO:root:current train perplexity3.516059637069702
INFO:root:current mean train loss 3189.074116417112
INFO:root:current train perplexity3.514816999435425

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.72s/it]
INFO:root:final mean train loss: 3186.6013453083656
INFO:root:final train perplexity: 3.5155868530273438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4416.973066614029
INFO:root:eval perplexity: 5.966105937957764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5537.90380859375
INFO:root:eval perplexity: 9.62655258178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [10:24:07<2:36:23, 234.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.3005340189875
INFO:root:current train perplexity3.500176191329956
INFO:root:current mean train loss 3188.271534839822
INFO:root:current train perplexity3.5060343742370605
INFO:root:current mean train loss 3178.8295005880377
INFO:root:current train perplexity3.506244659423828
INFO:root:current mean train loss 3178.585105875866
INFO:root:current train perplexity3.510093927383423
INFO:root:current mean train loss 3178.7470942678433
INFO:root:current train perplexity3.5059449672698975
INFO:root:current mean train loss 3180.0229142210437
INFO:root:current train perplexity3.5079197883605957
INFO:root:current mean train loss 3180.844219584177
INFO:root:current train perplexity3.5087153911590576
INFO:root:current mean train loss 3182.225084493341
INFO:root:current train perplexity3.511504650115967
INFO:root:current mean train loss 3185.1469948761023
INFO:root:current train perplexity3.511732816696167
INFO:root:current mean train loss 3187.7231465262703
INFO:root:current train perplexity3.5136544704437256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.29s/it]
INFO:root:final mean train loss: 3185.253091812134
INFO:root:final train perplexity: 3.5137171745300293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 4417.788032261193
INFO:root:eval perplexity: 5.968071460723877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5537.72643436946
INFO:root:eval perplexity: 9.6258544921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [10:28:04<2:32:46, 235.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.310269059806
INFO:root:current train perplexity3.4894909858703613
INFO:root:current mean train loss 3178.8275662182486
INFO:root:current train perplexity3.4897797107696533
INFO:root:current mean train loss 3179.892744855183
INFO:root:current train perplexity3.4967665672302246
INFO:root:current mean train loss 3185.2398855125566
INFO:root:current train perplexity3.500251054763794
INFO:root:current mean train loss 3184.1611954769314
INFO:root:current train perplexity3.5021238327026367
INFO:root:current mean train loss 3183.3464567584115
INFO:root:current train perplexity3.503645420074463
INFO:root:current mean train loss 3183.5929596524747
INFO:root:current train perplexity3.50563907623291
INFO:root:current mean train loss 3182.867413958267
INFO:root:current train perplexity3.5079030990600586
INFO:root:current mean train loss 3185.0397327169358
INFO:root:current train perplexity3.5084447860717773
INFO:root:current mean train loss 3184.9055044682436
INFO:root:current train perplexity3.509141683578491

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.25s/it]
INFO:root:final mean train loss: 3181.898781130391
INFO:root:final train perplexity: 3.5090701580047607
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4419.562657565935
INFO:root:eval perplexity: 5.972354888916016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5539.539935172872
INFO:root:eval perplexity: 9.632994651794434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [10:31:59<2:29:02, 235.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3170.669834498355
INFO:root:current train perplexity3.4864540100097656
INFO:root:current mean train loss 3172.279485927484
INFO:root:current train perplexity3.492050886154175
INFO:root:current mean train loss 3167.055965307203
INFO:root:current train perplexity3.493499994277954
INFO:root:current mean train loss 3176.926197216179
INFO:root:current train perplexity3.499096632003784
INFO:root:current mean train loss 3173.9611717763573
INFO:root:current train perplexity3.502115488052368
INFO:root:current mean train loss 3177.7923163405985
INFO:root:current train perplexity3.5029375553131104
INFO:root:current mean train loss 3180.6816915608138
INFO:root:current train perplexity3.5051300525665283
INFO:root:current mean train loss 3179.6825511620477
INFO:root:current train perplexity3.5051398277282715
INFO:root:current mean train loss 3180.055616871072
INFO:root:current train perplexity3.5050199031829834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.93s/it]
INFO:root:final mean train loss: 3179.5315165365896
INFO:root:final train perplexity: 3.5057945251464844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4421.134315436613
INFO:root:eval perplexity: 5.976152420043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5542.153171404034
INFO:root:eval perplexity: 9.643294334411621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [10:35:55<2:25:11, 235.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3157.22802734375
INFO:root:current train perplexity3.4660067558288574
INFO:root:current mean train loss 3157.366030794903
INFO:root:current train perplexity3.476910352706909
INFO:root:current mean train loss 3169.6295629040947
INFO:root:current train perplexity3.483822822570801
INFO:root:current mean train loss 3172.180986360355
INFO:root:current train perplexity3.4868505001068115
INFO:root:current mean train loss 3174.0813703134695
INFO:root:current train perplexity3.4887912273406982
INFO:root:current mean train loss 3174.182967138575
INFO:root:current train perplexity3.491772174835205
INFO:root:current mean train loss 3174.393263986059
INFO:root:current train perplexity3.4921886920928955
INFO:root:current mean train loss 3178.8332783467063
INFO:root:current train perplexity3.4963226318359375
INFO:root:current mean train loss 3179.899604692851
INFO:root:current train perplexity3.4994499683380127
INFO:root:current mean train loss 3178.8347749255954
INFO:root:current train perplexity3.49940824508667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.15s/it]
INFO:root:final mean train loss: 3176.3707773762367
INFO:root:final train perplexity: 3.50142502784729
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4421.32930241578
INFO:root:eval perplexity: 5.976622581481934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 5543.442393201462
INFO:root:eval perplexity: 9.64837646484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [10:39:51<2:21:21, 235.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3149.989812677557
INFO:root:current train perplexity3.4759268760681152
INFO:root:current mean train loss 3166.228863140484
INFO:root:current train perplexity3.486084461212158
INFO:root:current mean train loss 3168.5534089436464
INFO:root:current train perplexity3.496948719024658
INFO:root:current mean train loss 3174.885225645599
INFO:root:current train perplexity3.503365993499756
INFO:root:current mean train loss 3179.5260309743767
INFO:root:current train perplexity3.504258155822754
INFO:root:current mean train loss 3177.4514795590753
INFO:root:current train perplexity3.5029408931732178
INFO:root:current mean train loss 3175.499516913231
INFO:root:current train perplexity3.499589204788208
INFO:root:current mean train loss 3176.1581392569883
INFO:root:current train perplexity3.49971604347229
INFO:root:current mean train loss 3176.422597186633
INFO:root:current train perplexity3.4977128505706787
INFO:root:current mean train loss 3177.3400195526892
INFO:root:current train perplexity3.498995304107666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.14s/it]
INFO:root:final mean train loss: 3174.3041871593846
INFO:root:final train perplexity: 3.4985718727111816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 4422.651746384641
INFO:root:eval perplexity: 5.97982120513916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5545.044544409353
INFO:root:eval perplexity: 9.654702186584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [10:43:47<2:17:29, 235.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3179.7300318667762
INFO:root:current train perplexity3.4885292053222656
INFO:root:current mean train loss 3153.578467617516
INFO:root:current train perplexity3.4750216007232666
INFO:root:current mean train loss 3159.656506403396
INFO:root:current train perplexity3.4814963340759277
INFO:root:current mean train loss 3163.193921893368
INFO:root:current train perplexity3.481358528137207
INFO:root:current mean train loss 3169.2969524957116
INFO:root:current train perplexity3.486489772796631
INFO:root:current mean train loss 3173.2537571313524
INFO:root:current train perplexity3.492098808288574
INFO:root:current mean train loss 3174.895470343422
INFO:root:current train perplexity3.4956207275390625
INFO:root:current mean train loss 3176.231137674939
INFO:root:current train perplexity3.495225667953491
INFO:root:current mean train loss 3175.08448010865
INFO:root:current train perplexity3.4947803020477295
INFO:root:current mean train loss 3176.512410260388
INFO:root:current train perplexity3.4958486557006836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.25s/it]
INFO:root:final mean train loss: 3172.987295704503
INFO:root:final train perplexity: 3.4967539310455322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 4423.818104845413
INFO:root:eval perplexity: 5.982641696929932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.22s/it]
INFO:root:eval mean loss: 5545.335899407137
INFO:root:eval perplexity: 9.655851364135742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [10:47:43<2:13:37, 235.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3141.381103515625
INFO:root:current train perplexity3.458751916885376
INFO:root:current mean train loss 3161.970672367126
INFO:root:current train perplexity3.480252981185913
INFO:root:current mean train loss 3167.3781953383123
INFO:root:current train perplexity3.49211049079895
INFO:root:current mean train loss 3163.933340650086
INFO:root:current train perplexity3.4880731105804443
INFO:root:current mean train loss 3169.3234760364826
INFO:root:current train perplexity3.487452745437622
INFO:root:current mean train loss 3166.8321563315344
INFO:root:current train perplexity3.4885876178741455
INFO:root:current mean train loss 3167.1446099045556
INFO:root:current train perplexity3.4886462688446045
INFO:root:current mean train loss 3168.2069106908743
INFO:root:current train perplexity3.4878432750701904
INFO:root:current mean train loss 3169.4544564077614
INFO:root:current train perplexity3.4911048412323
INFO:root:current mean train loss 3171.6800680644046
INFO:root:current train perplexity3.491683006286621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.50s/it]
INFO:root:final mean train loss: 3168.9881457051924
INFO:root:final train perplexity: 3.4912421703338623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4425.325565852172
INFO:root:eval perplexity: 5.986289978027344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.23s/it]
INFO:root:eval mean loss: 5546.80576448914
INFO:root:eval perplexity: 9.661654472351074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [10:51:37<2:09:26, 235.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3188.2968191964287
INFO:root:current train perplexity3.479357957839966
INFO:root:current mean train loss 3171.1152705439813
INFO:root:current train perplexity3.481827974319458
INFO:root:current mean train loss 3169.2534761469415
INFO:root:current train perplexity3.479583501815796
INFO:root:current mean train loss 3167.582963357043
INFO:root:current train perplexity3.4822330474853516
INFO:root:current mean train loss 3168.8249382632903
INFO:root:current train perplexity3.480516195297241
INFO:root:current mean train loss 3170.413100083966
INFO:root:current train perplexity3.4816348552703857
INFO:root:current mean train loss 3170.3101858544537
INFO:root:current train perplexity3.4857711791992188
INFO:root:current mean train loss 3171.2992293792518
INFO:root:current train perplexity3.4896786212921143
INFO:root:current mean train loss 3170.388254350674
INFO:root:current train perplexity3.4909284114837646
INFO:root:current mean train loss 3171.074364189923
INFO:root:current train perplexity3.489396810531616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.35s/it]
INFO:root:final mean train loss: 3168.667396853047
INFO:root:final train perplexity: 3.490800380706787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 4426.9997073775485
INFO:root:eval perplexity: 5.990344047546387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 5551.254245622784
INFO:root:eval perplexity: 9.679247856140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [10:55:34<2:05:38, 235.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.360226653343
INFO:root:current train perplexity3.511364459991455
INFO:root:current mean train loss 3173.054499699519
INFO:root:current train perplexity3.489603281021118
INFO:root:current mean train loss 3169.2291104038068
INFO:root:current train perplexity3.483415126800537
INFO:root:current mean train loss 3166.3461380227313
INFO:root:current train perplexity3.4801149368286133
INFO:root:current mean train loss 3165.421140373695
INFO:root:current train perplexity3.479788064956665
INFO:root:current mean train loss 3164.1046032422596
INFO:root:current train perplexity3.4792728424072266
INFO:root:current mean train loss 3168.3922971544516
INFO:root:current train perplexity3.48007869720459
INFO:root:current mean train loss 3169.3625839870037
INFO:root:current train perplexity3.4823098182678223
INFO:root:current mean train loss 3168.4697720311574
INFO:root:current train perplexity3.4853436946868896
INFO:root:current mean train loss 3168.4527959408965
INFO:root:current train perplexity3.4871389865875244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.98s/it]
INFO:root:final mean train loss: 3166.285211009364
INFO:root:final train perplexity: 3.487520933151245
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.10s/it]
INFO:root:eval mean loss: 4427.508970869349
INFO:root:eval perplexity: 5.991576671600342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 5553.70565298094
INFO:root:eval perplexity: 9.688957214355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [10:59:29<2:01:44, 235.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3159.0398332184436
INFO:root:current train perplexity3.4627978801727295
INFO:root:current mean train loss 3158.791689841163
INFO:root:current train perplexity3.4708874225616455
INFO:root:current mean train loss 3151.525661027764
INFO:root:current train perplexity3.4699084758758545
INFO:root:current mean train loss 3153.670095068777
INFO:root:current train perplexity3.473708391189575
INFO:root:current mean train loss 3156.876973695607
INFO:root:current train perplexity3.473212718963623
INFO:root:current mean train loss 3160.783193820185
INFO:root:current train perplexity3.4785993099212646
INFO:root:current mean train loss 3162.818886658746
INFO:root:current train perplexity3.481222629547119
INFO:root:current mean train loss 3162.9024789863515
INFO:root:current train perplexity3.4797768592834473
INFO:root:current mean train loss 3163.1228747429495
INFO:root:current train perplexity3.481440305709839
INFO:root:current mean train loss 3165.757381210568
INFO:root:current train perplexity3.4824023246765137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.86s/it]
INFO:root:final mean train loss: 3163.085852899859
INFO:root:final train perplexity: 3.483121871948242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4427.772215065381
INFO:root:eval perplexity: 5.992216110229492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5552.400972406915
INFO:root:eval perplexity: 9.683786392211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [11:03:25<1:57:49, 235.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3155.6216275489937
INFO:root:current train perplexity3.457312822341919
INFO:root:current mean train loss 3147.717123931309
INFO:root:current train perplexity3.463712692260742
INFO:root:current mean train loss 3150.89444170035
INFO:root:current train perplexity3.4662253856658936
INFO:root:current mean train loss 3156.51715920961
INFO:root:current train perplexity3.470118284225464
INFO:root:current mean train loss 3162.543169806985
INFO:root:current train perplexity3.475022554397583
INFO:root:current mean train loss 3162.457122966514
INFO:root:current train perplexity3.4758477210998535
INFO:root:current mean train loss 3163.4978116256875
INFO:root:current train perplexity3.4784982204437256
INFO:root:current mean train loss 3163.6112644361415
INFO:root:current train perplexity3.480611562728882
INFO:root:current mean train loss 3163.473274417473
INFO:root:current train perplexity3.4803571701049805
INFO:root:current mean train loss 3164.2003348214284
INFO:root:current train perplexity3.4820427894592285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.76s/it]
INFO:root:final mean train loss: 3162.807809029856
INFO:root:final train perplexity: 3.482738971710205
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 4428.997650362921
INFO:root:eval perplexity: 5.995183944702148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5552.303229582225
INFO:root:eval perplexity: 9.683401107788086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [11:07:21<1:53:53, 235.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3149.5342343458487
INFO:root:current train perplexity3.4613280296325684
INFO:root:current mean train loss 3161.584409793694
INFO:root:current train perplexity3.4688124656677246
INFO:root:current mean train loss 3158.146894019195
INFO:root:current train perplexity3.4693281650543213
INFO:root:current mean train loss 3154.262279541681
INFO:root:current train perplexity3.469273567199707
INFO:root:current mean train loss 3154.3236928282254
INFO:root:current train perplexity3.467428684234619
INFO:root:current mean train loss 3158.1046467668375
INFO:root:current train perplexity3.469378709793091
INFO:root:current mean train loss 3161.9280385442044
INFO:root:current train perplexity3.472130537033081
INFO:root:current mean train loss 3161.0357342935135
INFO:root:current train perplexity3.4754221439361572
INFO:root:current mean train loss 3160.5254787634262
INFO:root:current train perplexity3.475698232650757
INFO:root:current mean train loss 3160.477351980594
INFO:root:current train perplexity3.475980758666992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.06s/it]
INFO:root:final mean train loss: 3159.311636094124
INFO:root:final train perplexity: 3.477938413619995
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4430.85048551086
INFO:root:eval perplexity: 5.999677658081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 5555.193317819149
INFO:root:eval perplexity: 9.694849014282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [11:11:16<1:49:59, 235.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3147.692041015625
INFO:root:current train perplexity3.496978282928467
INFO:root:current mean train loss 3153.08171875
INFO:root:current train perplexity3.4780006408691406
INFO:root:current mean train loss 3163.9101242897727
INFO:root:current train perplexity3.4781954288482666
INFO:root:current mean train loss 3167.1340182291665
INFO:root:current train perplexity3.475757360458374
INFO:root:current mean train loss 3164.8550560238486
INFO:root:current train perplexity3.4738619327545166
INFO:root:current mean train loss 3160.6824116847824
INFO:root:current train perplexity3.4698610305786133
INFO:root:current mean train loss 3163.5860850694444
INFO:root:current train perplexity3.4719455242156982
INFO:root:current mean train loss 3160.492303112399
INFO:root:current train perplexity3.472876787185669
INFO:root:current mean train loss 3160.765319754464
INFO:root:current train perplexity3.475895881652832
INFO:root:current mean train loss 3160.350419921875
INFO:root:current train perplexity3.4756758213043213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:30<00:00, 210.95s/it]
INFO:root:final mean train loss: 3157.9360569984683
INFO:root:final train perplexity: 3.4760520458221436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4432.1543003379875
INFO:root:eval perplexity: 6.002842426300049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 5557.30283480164
INFO:root:eval perplexity: 9.703215599060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [11:15:12<1:46:03, 235.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3147.847206207643
INFO:root:current train perplexity3.4588239192962646
INFO:root:current mean train loss 3150.9570179089824
INFO:root:current train perplexity3.452707290649414
INFO:root:current mean train loss 3153.5921471262145
INFO:root:current train perplexity3.461162567138672
INFO:root:current mean train loss 3154.574474364597
INFO:root:current train perplexity3.465303659439087
INFO:root:current mean train loss 3157.234305751003
INFO:root:current train perplexity3.469637155532837
INFO:root:current mean train loss 3154.8082754877787
INFO:root:current train perplexity3.4722790718078613
INFO:root:current mean train loss 3154.6962429510204
INFO:root:current train perplexity3.472698926925659
INFO:root:current mean train loss 3156.140047855304
INFO:root:current train perplexity3.4732251167297363
INFO:root:current mean train loss 3157.6364770977843
INFO:root:current train perplexity3.474235773086548
INFO:root:current mean train loss 3158.0312266538976
INFO:root:current train perplexity3.4737181663513184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:31<00:00, 211.36s/it]
INFO:root:final mean train loss: 3156.154866618495
INFO:root:final train perplexity: 3.4736101627349854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 4433.866112242354
INFO:root:eval perplexity: 6.006999492645264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 5560.265032829122
INFO:root:eval perplexity: 9.714977264404297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [11:19:08<1:42:12, 235.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3134.001652644231
INFO:root:current train perplexity3.456606388092041
INFO:root:current mean train loss 3135.3578705313316
INFO:root:current train perplexity3.4636342525482178
INFO:root:current mean train loss 3148.234073809332
INFO:root:current train perplexity3.465466022491455
INFO:root:current mean train loss 3146.269063573969
INFO:root:current train perplexity3.464230537414551
INFO:root:current mean train loss 3145.152991145303
INFO:root:current train perplexity3.4656853675842285
INFO:root:current mean train loss 3146.0120273338357
INFO:root:current train perplexity3.4665753841400146
INFO:root:current mean train loss 3148.975501848544
INFO:root:current train perplexity3.4657270908355713
INFO:root:current mean train loss 3152.4959455989256
INFO:root:current train perplexity3.4683878421783447
INFO:root:current mean train loss 3154.2526839028305
INFO:root:current train perplexity3.4703264236450195
INFO:root:current mean train loss 3155.6865724627114
INFO:root:current train perplexity3.4696664810180664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.98s/it]
INFO:root:final mean train loss: 3153.2972739435013
INFO:root:final train perplexity: 3.469696283340454
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4434.780302872895
INFO:root:eval perplexity: 6.009219646453857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5564.23898423648
INFO:root:eval perplexity: 9.730775833129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [11:23:03<1:38:06, 235.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3144.099710483744
INFO:root:current train perplexity3.450993299484253
INFO:root:current mean train loss 3151.6845641783134
INFO:root:current train perplexity3.462966203689575
INFO:root:current mean train loss 3152.2921759053615
INFO:root:current train perplexity3.4693105220794678
INFO:root:current mean train loss 3154.9032891065553
INFO:root:current train perplexity3.4686715602874756
INFO:root:current mean train loss 3154.852066437563
INFO:root:current train perplexity3.465266466140747
INFO:root:current mean train loss 3156.067540138512
INFO:root:current train perplexity3.4652388095855713
INFO:root:current mean train loss 3155.0452683521103
INFO:root:current train perplexity3.463143825531006
INFO:root:current mean train loss 3155.1687485333227
INFO:root:current train perplexity3.4672765731811523
INFO:root:current mean train loss 3154.0873333651975
INFO:root:current train perplexity3.4684853553771973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.27s/it]
INFO:root:final mean train loss: 3152.3283989198744
INFO:root:final train perplexity: 3.468370199203491
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4434.806218140514
INFO:root:eval perplexity: 6.009284019470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5563.148662594193
INFO:root:eval perplexity: 9.7264404296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [11:26:57<1:33:59, 235.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3095.736258370536
INFO:root:current train perplexity3.4691507816314697
INFO:root:current mean train loss 3129.6021876825353
INFO:root:current train perplexity3.458160638809204
INFO:root:current mean train loss 3137.458599883001
INFO:root:current train perplexity3.4628915786743164
INFO:root:current mean train loss 3140.9529341408793
INFO:root:current train perplexity3.45928955078125
INFO:root:current mean train loss 3146.651745695447
INFO:root:current train perplexity3.4630532264709473
INFO:root:current mean train loss 3150.9340252095662
INFO:root:current train perplexity3.4649503231048584
INFO:root:current mean train loss 3148.3783540175814
INFO:root:current train perplexity3.4667537212371826
INFO:root:current mean train loss 3148.6796357021303
INFO:root:current train perplexity3.4665720462799072
INFO:root:current mean train loss 3151.4397465777956
INFO:root:current train perplexity3.465916633605957
INFO:root:current mean train loss 3152.5663693731913
INFO:root:current train perplexity3.465374708175659

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.49s/it]
INFO:root:final mean train loss: 3150.054601054038
INFO:root:final train perplexity: 3.4652602672576904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4436.294745262633
INFO:root:eval perplexity: 6.012901306152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5564.058063912899
INFO:root:eval perplexity: 9.730055809020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [11:30:51<1:29:58, 234.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3138.0656901041666
INFO:root:current train perplexity3.484307050704956
INFO:root:current mean train loss 3161.8505010190215
INFO:root:current train perplexity3.466797113418579
INFO:root:current mean train loss 3163.632551326308
INFO:root:current train perplexity3.4704368114471436
INFO:root:current mean train loss 3159.828248232887
INFO:root:current train perplexity3.469454288482666
INFO:root:current mean train loss 3152.6034467949926
INFO:root:current train perplexity3.4686124324798584
INFO:root:current mean train loss 3154.4508367149574
INFO:root:current train perplexity3.468766689300537
INFO:root:current mean train loss 3153.567423304116
INFO:root:current train perplexity3.465512275695801
INFO:root:current mean train loss 3154.9185997596155
INFO:root:current train perplexity3.466798782348633
INFO:root:current mean train loss 3152.838011047738
INFO:root:current train perplexity3.4669315814971924
INFO:root:current mean train loss 3154.1278840612194
INFO:root:current train perplexity3.4660754203796387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it]
INFO:root:final mean train loss: 3150.4738045969316
INFO:root:final train perplexity: 3.4658331871032715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4436.420623129987
INFO:root:eval perplexity: 6.01320743560791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 5565.318504820479
INFO:root:eval perplexity: 9.735074996948242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [11:34:45<1:26:02, 234.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3144.050038213315
INFO:root:current train perplexity3.4426755905151367
INFO:root:current mean train loss 3146.2288411458335
INFO:root:current train perplexity3.4609460830688477
INFO:root:current mean train loss 3145.2703424975475
INFO:root:current train perplexity3.4605417251586914
INFO:root:current mean train loss 3142.779082968508
INFO:root:current train perplexity3.4590635299682617
INFO:root:current mean train loss 3144.11467452534
INFO:root:current train perplexity3.4639129638671875
INFO:root:current mean train loss 3145.827736615679
INFO:root:current train perplexity3.459348440170288
INFO:root:current mean train loss 3146.8531100302216
INFO:root:current train perplexity3.4609711170196533
INFO:root:current mean train loss 3148.7327065368904
INFO:root:current train perplexity3.4611432552337646
INFO:root:current mean train loss 3148.566913220022
INFO:root:current train perplexity3.4608287811279297
INFO:root:current mean train loss 3150.322747293557
INFO:root:current train perplexity3.4614222049713135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.18s/it]
INFO:root:final mean train loss: 3147.6104468684043
INFO:root:final train perplexity: 3.4619202613830566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4437.699360732491
INFO:root:eval perplexity: 6.0163164138793945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5568.1558690713655
INFO:root:eval perplexity: 9.746376037597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [11:38:39<1:22:01, 234.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3148.4306640625
INFO:root:current train perplexity3.4281253814697266
INFO:root:current mean train loss 3134.4788771767653
INFO:root:current train perplexity3.4346821308135986
INFO:root:current mean train loss 3133.7780074742964
INFO:root:current train perplexity3.448049783706665
INFO:root:current mean train loss 3135.9134554675697
INFO:root:current train perplexity3.451043128967285
INFO:root:current mean train loss 3143.0170365973026
INFO:root:current train perplexity3.4547698497772217
INFO:root:current mean train loss 3147.079507084216
INFO:root:current train perplexity3.4533157348632812
INFO:root:current mean train loss 3149.9000760666354
INFO:root:current train perplexity3.454629421234131
INFO:root:current mean train loss 3145.655928041638
INFO:root:current train perplexity3.4525554180145264
INFO:root:current mean train loss 3145.721053911891
INFO:root:current train perplexity3.454131603240967
INFO:root:current mean train loss 3146.0131935586733
INFO:root:current train perplexity3.4552090167999268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.35s/it]
INFO:root:final mean train loss: 3144.5283889155235
INFO:root:final train perplexity: 3.4577138423919678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4438.56043259641
INFO:root:eval perplexity: 6.0184125900268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5568.841041943706
INFO:root:eval perplexity: 9.749106407165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [11:42:33<1:18:04, 234.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3157.0383738982373
INFO:root:current train perplexity3.4754810333251953
INFO:root:current mean train loss 3147.3497340799236
INFO:root:current train perplexity3.463332414627075
INFO:root:current mean train loss 3150.0184668377356
INFO:root:current train perplexity3.464916944503784
INFO:root:current mean train loss 3153.0420829300333
INFO:root:current train perplexity3.463871717453003
INFO:root:current mean train loss 3151.3562773615463
INFO:root:current train perplexity3.463212251663208
INFO:root:current mean train loss 3151.6081262139087
INFO:root:current train perplexity3.463345527648926
INFO:root:current mean train loss 3152.799043610622
INFO:root:current train perplexity3.4629323482513428
INFO:root:current mean train loss 3150.371805028438
INFO:root:current train perplexity3.461378812789917
INFO:root:current mean train loss 3148.0812572165523
INFO:root:current train perplexity3.4604411125183105
INFO:root:current mean train loss 3146.8362900609027
INFO:root:current train perplexity3.457968235015869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.77s/it]
INFO:root:final mean train loss: 3144.0499259579565
INFO:root:final train perplexity: 3.4570600986480713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4438.499821656139
INFO:root:eval perplexity: 6.0182647705078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5568.864167774823
INFO:root:eval perplexity: 9.749199867248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [11:46:26<1:14:05, 233.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3126.726552111037
INFO:root:current train perplexity3.4371602535247803
INFO:root:current mean train loss 3142.6718368011266
INFO:root:current train perplexity3.440457820892334
INFO:root:current mean train loss 3139.044679711222
INFO:root:current train perplexity3.439589500427246
INFO:root:current mean train loss 3141.6636347262247
INFO:root:current train perplexity3.448129177093506
INFO:root:current mean train loss 3145.73298334382
INFO:root:current train perplexity3.447427749633789
INFO:root:current mean train loss 3140.970242962323
INFO:root:current train perplexity3.4454293251037598
INFO:root:current mean train loss 3140.387308536394
INFO:root:current train perplexity3.4491701126098633
INFO:root:current mean train loss 3142.79567815533
INFO:root:current train perplexity3.4505980014801025
INFO:root:current mean train loss 3145.3925934018043
INFO:root:current train perplexity3.45279860496521
INFO:root:current mean train loss 3144.2316559385727
INFO:root:current train perplexity3.454127550125122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.57s/it]
INFO:root:final mean train loss: 3142.2329448576897
INFO:root:final train perplexity: 3.454582929611206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4438.834152329898
INFO:root:eval perplexity: 6.019079208374023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.19s/it]
INFO:root:eval mean loss: 5570.560252521055
INFO:root:eval perplexity: 9.755961418151855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [11:50:21<1:10:12, 234.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3124.2421919389203
INFO:root:current train perplexity3.44527268409729
INFO:root:current mean train loss 3137.2644751764115
INFO:root:current train perplexity3.4350154399871826
INFO:root:current mean train loss 3140.431111174939
INFO:root:current train perplexity3.447533369064331
INFO:root:current mean train loss 3134.7845063545333
INFO:root:current train perplexity3.449827194213867
INFO:root:current mean train loss 3139.738937478537
INFO:root:current train perplexity3.449218988418579
INFO:root:current mean train loss 3141.1388271572355
INFO:root:current train perplexity3.4482972621917725
INFO:root:current mean train loss 3142.7197302898376
INFO:root:current train perplexity3.4503750801086426
INFO:root:current mean train loss 3142.7310663286426
INFO:root:current train perplexity3.4499661922454834
INFO:root:current mean train loss 3144.3748415227524
INFO:root:current train perplexity3.4531238079071045
INFO:root:current mean train loss 3144.1562921813647
INFO:root:current train perplexity3.4535281658172607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.22s/it]
INFO:root:final mean train loss: 3141.050982444517
INFO:root:final train perplexity: 3.452972650527954
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4440.116404864805
INFO:root:eval perplexity: 6.022199630737305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5571.139631122562
INFO:root:eval perplexity: 9.758271217346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [11:54:14<1:06:17, 233.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3117.4510711185517
INFO:root:current train perplexity3.4479422569274902
INFO:root:current mean train loss 3138.1802416842406
INFO:root:current train perplexity3.4517948627471924
INFO:root:current mean train loss 3137.389304041409
INFO:root:current train perplexity3.450023889541626
INFO:root:current mean train loss 3140.6425566029616
INFO:root:current train perplexity3.448732614517212
INFO:root:current mean train loss 3141.887111062365
INFO:root:current train perplexity3.444809913635254
INFO:root:current mean train loss 3140.8832396376833
INFO:root:current train perplexity3.4467737674713135
INFO:root:current mean train loss 3139.434584305477
INFO:root:current train perplexity3.4472944736480713
INFO:root:current mean train loss 3140.8404504218547
INFO:root:current train perplexity3.44773268699646
INFO:root:current mean train loss 3141.4802200830136
INFO:root:current train perplexity3.449307441711426
INFO:root:current mean train loss 3141.5793528017102
INFO:root:current train perplexity3.4500961303710938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.85s/it]
INFO:root:final mean train loss: 3139.4226579973774
INFO:root:final train perplexity: 3.4507551193237305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4440.878443941157
INFO:root:eval perplexity: 6.024056434631348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5571.877261330896
INFO:root:eval perplexity: 9.76121997833252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [11:58:08<1:02:21, 233.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3142.2970916318222
INFO:root:current train perplexity3.4490294456481934
INFO:root:current mean train loss 3144.468453033626
INFO:root:current train perplexity3.465376615524292
INFO:root:current mean train loss 3140.532164401234
INFO:root:current train perplexity3.4536561965942383
INFO:root:current mean train loss 3136.1132239986946
INFO:root:current train perplexity3.4508445262908936
INFO:root:current mean train loss 3137.3285427862925
INFO:root:current train perplexity3.4503915309906006
INFO:root:current mean train loss 3139.825914052238
INFO:root:current train perplexity3.4506711959838867
INFO:root:current mean train loss 3139.539573339698
INFO:root:current train perplexity3.4496970176696777
INFO:root:current mean train loss 3140.2654498900574
INFO:root:current train perplexity3.449791193008423
INFO:root:current mean train loss 3139.7506169385942
INFO:root:current train perplexity3.4481921195983887
INFO:root:current mean train loss 3141.0413608413523
INFO:root:current train perplexity3.4494571685791016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.83s/it]
INFO:root:final mean train loss: 3138.7242474094514
INFO:root:final train perplexity: 3.4498043060302734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4442.462059507979
INFO:root:eval perplexity: 6.027915000915527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5574.029057928857
INFO:root:eval perplexity: 9.769810676574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [12:02:01<58:25, 233.72s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3136.3865858633308
INFO:root:current train perplexity3.463791608810425
INFO:root:current mean train loss 3139.9487632026885
INFO:root:current train perplexity3.451910972595215
INFO:root:current mean train loss 3139.3131492915545
INFO:root:current train perplexity3.447415828704834
INFO:root:current mean train loss 3138.820068359375
INFO:root:current train perplexity3.4432289600372314
INFO:root:current mean train loss 3140.4967920227687
INFO:root:current train perplexity3.44587779045105
INFO:root:current mean train loss 3139.70017633784
INFO:root:current train perplexity3.446927547454834
INFO:root:current mean train loss 3140.3129318304723
INFO:root:current train perplexity3.445618152618408
INFO:root:current mean train loss 3139.8473265504654
INFO:root:current train perplexity3.4470114707946777
INFO:root:current mean train loss 3138.9180992916313
INFO:root:current train perplexity3.4460256099700928
INFO:root:current mean train loss 3139.147768669401
INFO:root:current train perplexity3.4473676681518555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it]
INFO:root:final mean train loss: 3136.7366590807515
INFO:root:final train perplexity: 3.4471001625061035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.05s/it]
INFO:root:eval mean loss: 4442.127129737367
INFO:root:eval perplexity: 6.027099132537842
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5574.345737754876
INFO:root:eval perplexity: 9.771076202392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [12:05:56<54:34, 233.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3147.752505949174
INFO:root:current train perplexity3.4358246326446533
INFO:root:current mean train loss 3145.622445009609
INFO:root:current train perplexity3.437511444091797
INFO:root:current mean train loss 3145.8541799937393
INFO:root:current train perplexity3.4432661533355713
INFO:root:current mean train loss 3142.6847324420623
INFO:root:current train perplexity3.4438562393188477
INFO:root:current mean train loss 3140.6644615470996
INFO:root:current train perplexity3.445645332336426
INFO:root:current mean train loss 3137.587908093324
INFO:root:current train perplexity3.4452900886535645
INFO:root:current mean train loss 3138.7756169970207
INFO:root:current train perplexity3.447179079055786
INFO:root:current mean train loss 3136.0234480473714
INFO:root:current train perplexity3.444180488586426
INFO:root:current mean train loss 3138.8585165167874
INFO:root:current train perplexity3.4446957111358643
INFO:root:current mean train loss 3138.973190539514
INFO:root:current train perplexity3.4465181827545166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.69s/it]
INFO:root:final mean train loss: 3136.3226188536614
INFO:root:final train perplexity: 3.446537494659424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4442.867641151374
INFO:root:eval perplexity: 6.028903484344482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5574.772156194592
INFO:root:eval perplexity: 9.772778511047363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [12:09:50<50:42, 234.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3134.2353798314143
INFO:root:current train perplexity3.4485809803009033
INFO:root:current mean train loss 3147.074918619792
INFO:root:current train perplexity3.443537473678589
INFO:root:current mean train loss 3147.5982661877647
INFO:root:current train perplexity3.441870927810669
INFO:root:current mean train loss 3141.850610042524
INFO:root:current train perplexity3.440977096557617
INFO:root:current mean train loss 3141.7454338304924
INFO:root:current train perplexity3.4430441856384277
INFO:root:current mean train loss 3141.077342929359
INFO:root:current train perplexity3.4451992511749268
INFO:root:current mean train loss 3138.3516141383766
INFO:root:current train perplexity3.4432437419891357
INFO:root:current mean train loss 3138.829125823015
INFO:root:current train perplexity3.445702075958252
INFO:root:current mean train loss 3139.310891399703
INFO:root:current train perplexity3.4468910694122314

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.12s/it]
INFO:root:final mean train loss: 3135.4951175566644
INFO:root:final train perplexity: 3.4454123973846436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4443.232569051973
INFO:root:eval perplexity: 6.029794216156006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5575.705646054965
INFO:root:eval perplexity: 9.776510238647461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [12:13:44<46:47, 233.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3079.8334147135415
INFO:root:current train perplexity3.4011003971099854
INFO:root:current mean train loss 3132.084041262136
INFO:root:current train perplexity3.4406135082244873
INFO:root:current mean train loss 3133.4677842614688
INFO:root:current train perplexity3.4395484924316406
INFO:root:current mean train loss 3131.242921533364
INFO:root:current train perplexity3.4381470680236816
INFO:root:current mean train loss 3129.323397880157
INFO:root:current train perplexity3.439188241958618
INFO:root:current mean train loss 3133.4866305099094
INFO:root:current train perplexity3.4409220218658447
INFO:root:current mean train loss 3131.4512824063277
INFO:root:current train perplexity3.439152956008911
INFO:root:current mean train loss 3131.8462077285963
INFO:root:current train perplexity3.4418997764587402
INFO:root:current mean train loss 3132.974574106865
INFO:root:current train perplexity3.4413182735443115
INFO:root:current mean train loss 3135.1688498732524
INFO:root:current train perplexity3.443356513977051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.24s/it]
INFO:root:final mean train loss: 3133.9829620853548
INFO:root:final train perplexity: 3.443356990814209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4442.773660862699
INFO:root:eval perplexity: 6.028674602508545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5575.717610677083
INFO:root:eval perplexity: 9.776556968688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [12:17:38<42:53, 233.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3134.2549937855115
INFO:root:current train perplexity3.4396629333496094
INFO:root:current mean train loss 3144.185929581926
INFO:root:current train perplexity3.4163386821746826
INFO:root:current mean train loss 3133.0022655324346
INFO:root:current train perplexity3.4305405616760254
INFO:root:current mean train loss 3129.3509337005125
INFO:root:current train perplexity3.4325075149536133
INFO:root:current mean train loss 3131.3388998583864
INFO:root:current train perplexity3.4292593002319336
INFO:root:current mean train loss 3129.3153107226944
INFO:root:current train perplexity3.430263042449951
INFO:root:current mean train loss 3130.007553575082
INFO:root:current train perplexity3.432921886444092
INFO:root:current mean train loss 3130.3271697268374
INFO:root:current train perplexity3.436504364013672
INFO:root:current mean train loss 3132.102156746108
INFO:root:current train perplexity3.438682794570923
INFO:root:current mean train loss 3133.3416875343028
INFO:root:current train perplexity3.4408891201019287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.62s/it]
INFO:root:final mean train loss: 3132.778135176628
INFO:root:final train perplexity: 3.441721200942993
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4443.530335771276
INFO:root:eval perplexity: 6.030519485473633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5575.842797678413
INFO:root:eval perplexity: 9.777060508728027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [12:21:32<39:00, 234.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3133.914422286184
INFO:root:current train perplexity3.4012224674224854
INFO:root:current mean train loss 3126.7980977547268
INFO:root:current train perplexity3.4256093502044678
INFO:root:current mean train loss 3121.677671946347
INFO:root:current train perplexity3.426607608795166
INFO:root:current mean train loss 3119.3235307173295
INFO:root:current train perplexity3.4303243160247803
INFO:root:current mean train loss 3126.076191103259
INFO:root:current train perplexity3.433598041534424
INFO:root:current mean train loss 3127.448510318822
INFO:root:current train perplexity3.4376649856567383
INFO:root:current mean train loss 3130.9401240187044
INFO:root:current train perplexity3.437669515609741
INFO:root:current mean train loss 3131.7049385675637
INFO:root:current train perplexity3.4382145404815674
INFO:root:current mean train loss 3132.399163363763
INFO:root:current train perplexity3.4408059120178223
INFO:root:current mean train loss 3134.4433646881803
INFO:root:current train perplexity3.4410409927368164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.63s/it]
INFO:root:final mean train loss: 3132.6787242889404
INFO:root:final train perplexity: 3.4415857791900635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4444.201682665669
INFO:root:eval perplexity: 6.0321574211120605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5576.1900487588655
INFO:root:eval perplexity: 9.778447151184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [12:25:26<35:06, 234.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3109.5017541956017
INFO:root:current train perplexity3.404832601547241
INFO:root:current mean train loss 3127.3221195250985
INFO:root:current train perplexity3.433648109436035
INFO:root:current mean train loss 3132.8570336161206
INFO:root:current train perplexity3.430569648742676
INFO:root:current mean train loss 3133.8174529935973
INFO:root:current train perplexity3.4378609657287598
INFO:root:current mean train loss 3134.146557560012
INFO:root:current train perplexity3.434610605239868
INFO:root:current mean train loss 3132.719614915649
INFO:root:current train perplexity3.4341893196105957
INFO:root:current mean train loss 3132.647120620265
INFO:root:current train perplexity3.4358866214752197
INFO:root:current mean train loss 3132.134848572365
INFO:root:current train perplexity3.436886787414551
INFO:root:current mean train loss 3133.618073137092
INFO:root:current train perplexity3.437818765640259
INFO:root:current mean train loss 3134.8282098039713
INFO:root:current train perplexity3.439544439315796

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.32s/it]
INFO:root:final mean train loss: 3131.324253697549
INFO:root:final train perplexity: 3.4397470951080322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4444.656904504654
INFO:root:eval perplexity: 6.033267498016357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.17s/it]
INFO:root:eval mean loss: 5577.102632563165
INFO:root:eval perplexity: 9.782098770141602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [12:29:20<31:12, 234.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3142.4136300223213
INFO:root:current train perplexity3.415935516357422
INFO:root:current mean train loss 3130.8376880787036
INFO:root:current train perplexity3.447597026824951
INFO:root:current mean train loss 3134.612538439162
INFO:root:current train perplexity3.4405786991119385
INFO:root:current mean train loss 3129.947183273088
INFO:root:current train perplexity3.433765172958374
INFO:root:current mean train loss 3136.841696412536
INFO:root:current train perplexity3.4375274181365967
INFO:root:current mean train loss 3133.988405373832
INFO:root:current train perplexity3.4398393630981445
INFO:root:current mean train loss 3131.561208938238
INFO:root:current train perplexity3.440264940261841
INFO:root:current mean train loss 3133.3552767591414
INFO:root:current train perplexity3.4392926692962646
INFO:root:current mean train loss 3133.9642031366952
INFO:root:current train perplexity3.438190460205078
INFO:root:current mean train loss 3134.2710399607286
INFO:root:current train perplexity3.439234972000122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.01s/it]
INFO:root:final mean train loss: 3130.8620217231014
INFO:root:final train perplexity: 3.439120054244995
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.07s/it]
INFO:root:eval mean loss: 4444.945021609043
INFO:root:eval perplexity: 6.033970355987549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5578.099463929521
INFO:root:eval perplexity: 9.78608512878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [12:33:14<27:17, 233.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3161.393918059593
INFO:root:current train perplexity3.4436287879943848
INFO:root:current mean train loss 3134.3460548240823
INFO:root:current train perplexity3.4466209411621094
INFO:root:current mean train loss 3135.920310691551
INFO:root:current train perplexity3.44112229347229
INFO:root:current mean train loss 3133.524302313001
INFO:root:current train perplexity3.4349942207336426
INFO:root:current mean train loss 3138.175910760264
INFO:root:current train perplexity3.4382946491241455
INFO:root:current mean train loss 3132.5911206549263
INFO:root:current train perplexity3.4393672943115234
INFO:root:current mean train loss 3133.663118590834
INFO:root:current train perplexity3.438934803009033
INFO:root:current mean train loss 3132.022742537117
INFO:root:current train perplexity3.439821243286133
INFO:root:current mean train loss 3132.878652262659
INFO:root:current train perplexity3.438164234161377
INFO:root:current mean train loss 3133.0407712254773
INFO:root:current train perplexity3.4382457733154297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.81s/it]
INFO:root:final mean train loss: 3129.7451739772673
INFO:root:final train perplexity: 3.437605142593384
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.09s/it]
INFO:root:eval mean loss: 4445.351986715979
INFO:root:eval perplexity: 6.034964084625244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5578.0908203125
INFO:root:eval perplexity: 9.786052703857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [12:37:07<23:22, 233.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3158.586042815564
INFO:root:current train perplexity3.455435037612915
INFO:root:current mean train loss 3153.2201356193086
INFO:root:current train perplexity3.450900077819824
INFO:root:current mean train loss 3145.464432309823
INFO:root:current train perplexity3.4465582370758057
INFO:root:current mean train loss 3137.554917033921
INFO:root:current train perplexity3.4473717212677
INFO:root:current mean train loss 3136.614410468057
INFO:root:current train perplexity3.4462153911590576
INFO:root:current mean train loss 3136.947472103278
INFO:root:current train perplexity3.4414162635803223
INFO:root:current mean train loss 3135.4624334707423
INFO:root:current train perplexity3.442805767059326
INFO:root:current mean train loss 3134.3245675687626
INFO:root:current train perplexity3.4407260417938232
INFO:root:current mean train loss 3131.573843789017
INFO:root:current train perplexity3.438222885131836
INFO:root:current mean train loss 3133.43076623702
INFO:root:current train perplexity3.4395751953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.76s/it]
INFO:root:final mean train loss: 3129.9903061159193
INFO:root:final train perplexity: 3.4379372596740723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.06s/it]
INFO:root:eval mean loss: 4445.2819754959
INFO:root:eval perplexity: 6.034794330596924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it]
INFO:root:eval mean loss: 5578.375699523493
INFO:root:eval perplexity: 9.787188529968262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [12:41:01<19:29, 233.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3122.0999404131358
INFO:root:current train perplexity3.4350507259368896
INFO:root:current mean train loss 3119.1864666249016
INFO:root:current train perplexity3.4404261112213135
INFO:root:current mean train loss 3129.467024990951
INFO:root:current train perplexity3.4434428215026855
INFO:root:current mean train loss 3125.879360528377
INFO:root:current train perplexity3.438361883163452
INFO:root:current mean train loss 3130.2699301725897
INFO:root:current train perplexity3.439415216445923
INFO:root:current mean train loss 3133.1526590801095
INFO:root:current train perplexity3.4403138160705566
INFO:root:current mean train loss 3132.0480971850106
INFO:root:current train perplexity3.4389781951904297
INFO:root:current mean train loss 3130.695484588583
INFO:root:current train perplexity3.436774969100952
INFO:root:current mean train loss 3129.9384614991086
INFO:root:current train perplexity3.435518264770508
INFO:root:current mean train loss 3130.524004445956
INFO:root:current train perplexity3.4359889030456543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it]
INFO:root:final mean train loss: 3128.8639087677
INFO:root:final train perplexity: 3.4364099502563477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4445.649093736148
INFO:root:eval perplexity: 6.035688400268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 5578.964608266844
INFO:root:eval perplexity: 9.789548873901367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [12:44:56<15:36, 234.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3146.4097408465486
INFO:root:current train perplexity3.4486656188964844
INFO:root:current mean train loss 3141.736098603574
INFO:root:current train perplexity3.440789222717285
INFO:root:current mean train loss 3128.1054102294006
INFO:root:current train perplexity3.4387032985687256
INFO:root:current mean train loss 3128.694693833021
INFO:root:current train perplexity3.432607650756836
INFO:root:current mean train loss 3130.677703007896
INFO:root:current train perplexity3.4361319541931152
INFO:root:current mean train loss 3129.253887734926
INFO:root:current train perplexity3.436203956604004
INFO:root:current mean train loss 3131.4865568924524
INFO:root:current train perplexity3.4388363361358643
INFO:root:current mean train loss 3131.7063838158
INFO:root:current train perplexity3.436006546020508
INFO:root:current mean train loss 3128.022749569727
INFO:root:current train perplexity3.4340691566467285
INFO:root:current mean train loss 3130.3678302942412
INFO:root:current train perplexity3.434328079223633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.47s/it]
INFO:root:final mean train loss: 3127.8972399311683
INFO:root:final train perplexity: 3.4350998401641846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]
INFO:root:eval mean loss: 4445.524833083999
INFO:root:eval perplexity: 6.035385608673096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.18s/it]
INFO:root:eval mean loss: 5578.740331338652
INFO:root:eval perplexity: 9.788647651672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [12:48:49<11:41, 233.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3143.7500846354164
INFO:root:current train perplexity3.45300555229187
INFO:root:current mean train loss 3130.081664341518
INFO:root:current train perplexity3.4324452877044678
INFO:root:current mean train loss 3127.7475150923296
INFO:root:current train perplexity3.4322712421417236
INFO:root:current mean train loss 3125.436150390625
INFO:root:current train perplexity3.4353132247924805
INFO:root:current mean train loss 3126.9641123560855
INFO:root:current train perplexity3.433917760848999
INFO:root:current mean train loss 3124.9988315217392
INFO:root:current train perplexity3.4344851970672607
INFO:root:current mean train loss 3126.5117885561344
INFO:root:current train perplexity3.4359636306762695
INFO:root:current mean train loss 3127.048742124496
INFO:root:current train perplexity3.437236785888672
INFO:root:current mean train loss 3127.932423270089
INFO:root:current train perplexity3.433978319168091
INFO:root:current mean train loss 3129.4347911658656
INFO:root:current train perplexity3.433469533920288

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:28<00:00, 208.93s/it]
INFO:root:final mean train loss: 3126.5376684127314
INFO:root:final train perplexity: 3.433258056640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.11s/it]
INFO:root:eval mean loss: 4446.13749445922
INFO:root:eval perplexity: 6.036882400512695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5579.135683316711
INFO:root:eval perplexity: 9.79023265838623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [12:52:42<07:47, 233.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3145.8365669710092
INFO:root:current train perplexity3.4568774700164795
INFO:root:current mean train loss 3132.9556811390025
INFO:root:current train perplexity3.4489357471466064
INFO:root:current mean train loss 3131.311798634883
INFO:root:current train perplexity3.4418418407440186
INFO:root:current mean train loss 3130.500403501346
INFO:root:current train perplexity3.438668727874756
INFO:root:current mean train loss 3132.7020620026206
INFO:root:current train perplexity3.4402215480804443
INFO:root:current mean train loss 3131.723503413781
INFO:root:current train perplexity3.4361584186553955
INFO:root:current mean train loss 3129.451730217103
INFO:root:current train perplexity3.436446189880371
INFO:root:current mean train loss 3129.5009725090795
INFO:root:current train perplexity3.4352893829345703
INFO:root:current mean train loss 3130.064268153224
INFO:root:current train perplexity3.4334630966186523
INFO:root:current mean train loss 3128.9858440659173
INFO:root:current train perplexity3.4333696365356445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.61s/it]
INFO:root:final mean train loss: 3126.6116515744116
INFO:root:final train perplexity: 3.4333574771881104
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4446.14187513852
INFO:root:eval perplexity: 6.036891460418701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.14s/it]
INFO:root:eval mean loss: 5579.219200188387
INFO:root:eval perplexity: 9.790568351745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [12:56:37<03:53, 233.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3127.674740298764
INFO:root:current train perplexity3.4334535598754883
INFO:root:current mean train loss 3128.5520415780434
INFO:root:current train perplexity3.4324235916137695
INFO:root:current mean train loss 3132.622322842837
INFO:root:current train perplexity3.429114818572998
INFO:root:current mean train loss 3131.106409721667
INFO:root:current train perplexity3.4337422847747803
INFO:root:current mean train loss 3133.0959084815745
INFO:root:current train perplexity3.433368444442749
INFO:root:current mean train loss 3133.5459269412277
INFO:root:current train perplexity3.433457612991333
INFO:root:current mean train loss 3127.487744564603
INFO:root:current train perplexity3.4323081970214844
INFO:root:current mean train loss 3129.8454086747392
INFO:root:current train perplexity3.4317452907562256
INFO:root:current mean train loss 3128.677307745423
INFO:root:current train perplexity3.4329073429107666
INFO:root:current mean train loss 3129.260987806272
INFO:root:current train perplexity3.4335711002349854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:29<00:00, 209.08s/it]
INFO:root:final mean train loss: 3126.779099126016
INFO:root:final train perplexity: 3.433584690093994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4446.127219775044
INFO:root:eval perplexity: 6.036855697631836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.12s/it]
INFO:root:eval mean loss: 5579.243001302083
INFO:root:eval perplexity: 9.790661811828613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_fair_baseline/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:00:30<00:00, 233.77s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:00:30<00:00, 234.15s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 4446.127219775044
INFO:root:eval perplexity: 6.036855697631836
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.13s/it]
INFO:root:eval mean loss: 5579.243001302083
INFO:root:eval perplexity: 9.790661811828613
INFO:root:evalaution complete
INFO:root:save model final: alll12_fair_baseline/final
