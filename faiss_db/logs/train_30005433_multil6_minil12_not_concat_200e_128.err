INFO:root:Output: multil6_minil12_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 22935.538135258837
INFO:root:current train perplexity8789.7939453125
INFO:root:current mean train loss 18956.039136110237
INFO:root:current train perplexity1788.44091796875
INFO:root:current mean train loss 16499.80351497178
INFO:root:current train perplexity676.62744140625
INFO:root:current mean train loss 14837.35003524436
INFO:root:current train perplexity348.0313415527344
INFO:root:current mean train loss 13613.946736245929
INFO:root:current train perplexity215.2132110595703
INFO:root:current mean train loss 12686.897885636217
INFO:root:current train perplexity148.9193878173828
INFO:root:current mean train loss 11954.822111945638
INFO:root:current train perplexity111.57929229736328
INFO:root:current mean train loss 11363.283835018383
INFO:root:current train perplexity88.34232330322266
INFO:root:current mean train loss 10877.33238863494
INFO:root:current train perplexity72.8941650390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.06s/it]
INFO:root:final mean train loss: 10488.220948496173
INFO:root:final train perplexity: 62.671485900878906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 6219.233924811613
INFO:root:eval perplexity: 12.365068435668945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 6739.260821836215
INFO:root:eval perplexity: 15.733247756958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/1
  0%|          | 1/200 [09:50<32:37:08, 590.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6550.008161272322
INFO:root:current train perplexity13.415528297424316
INFO:root:current mean train loss 6619.6745719553155
INFO:root:current train perplexity13.46516227722168
INFO:root:current mean train loss 6524.862599543328
INFO:root:current train perplexity12.978960990905762
INFO:root:current mean train loss 6449.793872149837
INFO:root:current train perplexity12.660968780517578
INFO:root:current mean train loss 6376.197755105958
INFO:root:current train perplexity12.333946228027344
INFO:root:current mean train loss 6320.485917853181
INFO:root:current train perplexity12.055218696594238
INFO:root:current mean train loss 6263.057197281713
INFO:root:current train perplexity11.804052352905273
INFO:root:current mean train loss 6221.078479297427
INFO:root:current train perplexity11.589460372924805
INFO:root:current mean train loss 6169.647747129608
INFO:root:current train perplexity11.381575584411621
INFO:root:current mean train loss 6122.593484594646
INFO:root:current train perplexity11.167757987976074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.91s/it]
INFO:root:final mean train loss: 6084.71543096727
INFO:root:final train perplexity: 11.029749870300293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 5336.2743067098845
INFO:root:eval perplexity: 8.652364730834961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 5956.748853751108
INFO:root:eval perplexity: 11.424915313720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/2
  1%|          | 2/200 [19:50<32:47:31, 596.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5613.989290364583
INFO:root:current train perplexity9.220476150512695
INFO:root:current mean train loss 5610.571025815218
INFO:root:current train perplexity9.17869758605957
INFO:root:current mean train loss 5600.569703851745
INFO:root:current train perplexity9.098986625671387
INFO:root:current mean train loss 5575.206201946925
INFO:root:current train perplexity9.010217666625977
INFO:root:current mean train loss 5557.950001176581
INFO:root:current train perplexity8.935711860656738
INFO:root:current mean train loss 5527.666380650789
INFO:root:current train perplexity8.841166496276855
INFO:root:current mean train loss 5501.696931370681
INFO:root:current train perplexity8.759255409240723
INFO:root:current mean train loss 5479.914369126966
INFO:root:current train perplexity8.678145408630371
INFO:root:current mean train loss 5458.385573835314
INFO:root:current train perplexity8.599089622497559
INFO:root:current mean train loss 5443.233471012637
INFO:root:current train perplexity8.547423362731934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.27s/it]
INFO:root:final mean train loss: 5426.966417620259
INFO:root:final train perplexity: 8.508750915527344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 4947.129913979388
INFO:root:eval perplexity: 7.392560958862305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 5619.240452543218
INFO:root:eval perplexity: 9.952109336853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/3
  2%|â–         | 3/200 [29:50<32:42:28, 597.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5167.194420855978
INFO:root:current train perplexity7.726207733154297
INFO:root:current mean train loss 5207.094480436992
INFO:root:current train perplexity7.79812479019165
INFO:root:current mean train loss 5207.586084203335
INFO:root:current train perplexity7.753695964813232
INFO:root:current mean train loss 5182.258320433437
INFO:root:current train perplexity7.7142415046691895
INFO:root:current mean train loss 5167.034253564569
INFO:root:current train perplexity7.674078464508057
INFO:root:current mean train loss 5146.649632528681
INFO:root:current train perplexity7.628891944885254
INFO:root:current mean train loss 5146.879091216894
INFO:root:current train perplexity7.617437839508057
INFO:root:current mean train loss 5137.0335171648085
INFO:root:current train perplexity7.579327583312988
INFO:root:current mean train loss 5128.091174509227
INFO:root:current train perplexity7.5507307052612305
INFO:root:current mean train loss 5114.664985631941
INFO:root:current train perplexity7.513946533203125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.10s/it]
INFO:root:final mean train loss: 5102.652519226074
INFO:root:final train perplexity: 7.486819267272949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.32s/it]
INFO:root:eval mean loss: 4735.882829814938
INFO:root:eval perplexity: 6.787292003631592
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 5437.976011884974
INFO:root:eval perplexity: 9.241122245788574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/4
  2%|â–         | 4/200 [39:49<32:34:33, 598.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5004.712292086693
INFO:root:current train perplexity7.106394290924072
INFO:root:current mean train loss 4960.245817927003
INFO:root:current train perplexity7.048062324523926
INFO:root:current mean train loss 4949.146585836039
INFO:root:current train perplexity7.041039943695068
INFO:root:current mean train loss 4941.488657418335
INFO:root:current train perplexity7.0157694816589355
INFO:root:current mean train loss 4940.408652887543
INFO:root:current train perplexity7.008512020111084
INFO:root:current mean train loss 4933.52145862759
INFO:root:current train perplexity6.987340450286865
INFO:root:current mean train loss 4925.101677799376
INFO:root:current train perplexity6.9568071365356445
INFO:root:current mean train loss 4913.526214891844
INFO:root:current train perplexity6.9308648109436035
INFO:root:current mean train loss 4904.108402550579
INFO:root:current train perplexity6.909960746765137
INFO:root:current mean train loss 4899.62840223466
INFO:root:current train perplexity6.895746231079102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.95s/it]
INFO:root:final mean train loss: 4890.122044101839
INFO:root:final train perplexity: 6.884652137756348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it]
INFO:root:eval mean loss: 4572.7713475869905
INFO:root:eval perplexity: 6.354063987731934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it]
INFO:root:eval mean loss: 5302.9138148963875
INFO:root:eval perplexity: 8.744582176208496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/5
  2%|â–Ž         | 5/200 [49:46<32:22:50, 597.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4801.4757236578525
INFO:root:current train perplexity6.707828521728516
INFO:root:current mean train loss 4797.929866653552
INFO:root:current train perplexity6.62173318862915
INFO:root:current mean train loss 4781.05045845319
INFO:root:current train perplexity6.6063551902771
INFO:root:current mean train loss 4777.343264599465
INFO:root:current train perplexity6.588327884674072
INFO:root:current mean train loss 4768.734490674829
INFO:root:current train perplexity6.561216831207275
INFO:root:current mean train loss 4759.836964793019
INFO:root:current train perplexity6.542071342468262
INFO:root:current mean train loss 4756.463651701878
INFO:root:current train perplexity6.521406173706055
INFO:root:current mean train loss 4747.135287273237
INFO:root:current train perplexity6.505352020263672
INFO:root:current mean train loss 4740.50731287014
INFO:root:current train perplexity6.4882731437683105
INFO:root:current mean train loss 4738.013508334581
INFO:root:current train perplexity6.476765155792236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.40s/it]
INFO:root:final mean train loss: 4733.412787160566
INFO:root:final train perplexity: 6.471890926361084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 4465.549972642398
INFO:root:eval perplexity: 6.084456443786621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 5210.777800864362
INFO:root:eval perplexity: 8.42125415802002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/6
  3%|â–Ž         | 6/200 [59:40<32:08:51, 596.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4603.734619140625
INFO:root:current train perplexity6.165503025054932
INFO:root:current mean train loss 4617.924464219282
INFO:root:current train perplexity6.196118354797363
INFO:root:current mean train loss 4637.345437239056
INFO:root:current train perplexity6.207050800323486
INFO:root:current mean train loss 4640.232566811509
INFO:root:current train perplexity6.214646339416504
INFO:root:current mean train loss 4638.542124362067
INFO:root:current train perplexity6.211278915405273
INFO:root:current mean train loss 4632.886748207553
INFO:root:current train perplexity6.202726364135742
INFO:root:current mean train loss 4624.847981896614
INFO:root:current train perplexity6.189182758331299
INFO:root:current mean train loss 4624.601410198084
INFO:root:current train perplexity6.189077854156494
INFO:root:current mean train loss 4615.423353679346
INFO:root:current train perplexity6.174234390258789
INFO:root:current mean train loss 4613.302253570073
INFO:root:current train perplexity6.161923408508301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.88s/it]
INFO:root:final mean train loss: 4606.734571764546
INFO:root:final train perplexity: 6.156387805938721
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.83s/it]
INFO:root:eval mean loss: 4362.831508338874
INFO:root:eval perplexity: 5.836906909942627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 5118.6127895057625
INFO:root:eval perplexity: 8.109784126281738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/7
  4%|â–Ž         | 7/200 [1:09:39<32:01:40, 597.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4564.798428622159
INFO:root:current train perplexity6.017117500305176
INFO:root:current mean train loss 4521.120430632561
INFO:root:current train perplexity5.931252479553223
INFO:root:current mean train loss 4538.249842026655
INFO:root:current train perplexity5.955438613891602
INFO:root:current mean train loss 4538.053254979093
INFO:root:current train perplexity5.954646587371826
INFO:root:current mean train loss 4528.359319196428
INFO:root:current train perplexity5.945906639099121
INFO:root:current mean train loss 4521.422501407657
INFO:root:current train perplexity5.938272953033447
INFO:root:current mean train loss 4517.469240890387
INFO:root:current train perplexity5.932353496551514
INFO:root:current mean train loss 4513.682965451676
INFO:root:current train perplexity5.9250569343566895
INFO:root:current mean train loss 4509.1228241502195
INFO:root:current train perplexity5.914121150970459
INFO:root:current mean train loss 4504.662857135553
INFO:root:current train perplexity5.906594753265381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.08s/it]
INFO:root:final mean train loss: 4499.08285239435
INFO:root:final train perplexity: 5.900389194488525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 4298.92664353391
INFO:root:eval perplexity: 5.688006401062012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 5064.630852449025
INFO:root:eval perplexity: 7.932728290557861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/8
  4%|â–         | 8/200 [1:19:31<31:46:07, 595.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4412.8375728546625
INFO:root:current train perplexity5.727554798126221
INFO:root:current mean train loss 4418.316611447949
INFO:root:current train perplexity5.725897312164307
INFO:root:current mean train loss 4428.271527076402
INFO:root:current train perplexity5.730558395385742
INFO:root:current mean train loss 4428.505381854769
INFO:root:current train perplexity5.728752136230469
INFO:root:current mean train loss 4431.922813596787
INFO:root:current train perplexity5.729863166809082
INFO:root:current mean train loss 4430.637808059502
INFO:root:current train perplexity5.729746341705322
INFO:root:current mean train loss 4423.187152384992
INFO:root:current train perplexity5.7239089012146
INFO:root:current mean train loss 4423.274571809981
INFO:root:current train perplexity5.720217704772949
INFO:root:current mean train loss 4424.971921282046
INFO:root:current train perplexity5.721712589263916
INFO:root:current mean train loss 4422.023153303073
INFO:root:current train perplexity5.715765476226807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.68s/it]
INFO:root:final mean train loss: 4417.6866581824515
INFO:root:final train perplexity: 5.713920593261719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it]
INFO:root:eval mean loss: 4222.360548952793
INFO:root:eval perplexity: 5.5145978927612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 5002.271574412677
INFO:root:eval perplexity: 7.733006000518799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/9
  4%|â–         | 9/200 [1:29:25<31:35:00, 595.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4352.889146401849
INFO:root:current train perplexity5.602456569671631
INFO:root:current mean train loss 4366.272739343476
INFO:root:current train perplexity5.598368167877197
INFO:root:current mean train loss 4353.655026594211
INFO:root:current train perplexity5.579979419708252
INFO:root:current mean train loss 4352.517156307909
INFO:root:current train perplexity5.574968338012695
INFO:root:current mean train loss 4356.113393730925
INFO:root:current train perplexity5.572004318237305
INFO:root:current mean train loss 4356.58309375342
INFO:root:current train perplexity5.567795276641846
INFO:root:current mean train loss 4352.870717533299
INFO:root:current train perplexity5.561316013336182
INFO:root:current mean train loss 4352.271267466663
INFO:root:current train perplexity5.559061527252197
INFO:root:current mean train loss 4356.542975196882
INFO:root:current train perplexity5.565256595611572
INFO:root:current mean train loss 4351.962240170008
INFO:root:current train perplexity5.5567851066589355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.26s/it]
INFO:root:final mean train loss: 4346.105674312961
INFO:root:final train perplexity: 5.554810523986816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 4171.288392411901
INFO:root:eval perplexity: 5.401877403259277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4961.93154019836
INFO:root:eval perplexity: 7.6064910888671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/10
  5%|â–Œ         | 10/200 [1:39:17<31:21:45, 594.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4325.728302388252
INFO:root:current train perplexity5.456699371337891
INFO:root:current mean train loss 4312.137852162622
INFO:root:current train perplexity5.436934947967529
INFO:root:current mean train loss 4296.357057851703
INFO:root:current train perplexity5.426374912261963
INFO:root:current mean train loss 4293.1273744125165
INFO:root:current train perplexity5.423892021179199
INFO:root:current mean train loss 4290.102158325451
INFO:root:current train perplexity5.427001953125
INFO:root:current mean train loss 4291.847121164588
INFO:root:current train perplexity5.423651695251465
INFO:root:current mean train loss 4289.512935497975
INFO:root:current train perplexity5.41937255859375
INFO:root:current mean train loss 4286.897399510591
INFO:root:current train perplexity5.416351318359375
INFO:root:current mean train loss 4284.752130606069
INFO:root:current train perplexity5.411995887756348
INFO:root:current mean train loss 4282.701942202263
INFO:root:current train perplexity5.410430908203125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.07s/it]
INFO:root:final mean train loss: 4278.953794787007
INFO:root:final train perplexity: 5.4095778465271
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it]
INFO:root:eval mean loss: 4137.013467558732
INFO:root:eval perplexity: 5.327524662017822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 4935.359196656139
INFO:root:eval perplexity: 7.52428674697876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/11
  6%|â–Œ         | 11/200 [1:49:14<31:14:38, 595.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4233.485155127514
INFO:root:current train perplexity5.294567584991455
INFO:root:current mean train loss 4235.207742782837
INFO:root:current train perplexity5.311229705810547
INFO:root:current mean train loss 4227.4100150397435
INFO:root:current train perplexity5.3120341300964355
INFO:root:current mean train loss 4226.852855751373
INFO:root:current train perplexity5.288681983947754
INFO:root:current mean train loss 4227.947801531218
INFO:root:current train perplexity5.286897659301758
INFO:root:current mean train loss 4232.6830355954535
INFO:root:current train perplexity5.2950520515441895
INFO:root:current mean train loss 4230.322634145856
INFO:root:current train perplexity5.295258522033691
INFO:root:current mean train loss 4229.825025003474
INFO:root:current train perplexity5.296870231628418
INFO:root:current mean train loss 4229.885356847168
INFO:root:current train perplexity5.301273345947266
INFO:root:current mean train loss 4229.215974415448
INFO:root:current train perplexity5.298024654388428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.85s/it]
INFO:root:final mean train loss: 4225.908101235666
INFO:root:final train perplexity: 5.297543048858643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 4063.441691946476
INFO:root:eval perplexity: 5.1713643074035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 4873.023243572695
INFO:root:eval perplexity: 7.334917068481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/12
  6%|â–Œ         | 12/200 [1:59:06<31:01:30, 594.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4175.389052220395
INFO:root:current train perplexity5.188440799713135
INFO:root:current mean train loss 4176.556892277644
INFO:root:current train perplexity5.183066368103027
INFO:root:current mean train loss 4182.210119835805
INFO:root:current train perplexity5.201855182647705
INFO:root:current mean train loss 4182.657752546479
INFO:root:current train perplexity5.201690673828125
INFO:root:current mean train loss 4180.245778093435
INFO:root:current train perplexity5.196608066558838
INFO:root:current mean train loss 4175.661353564863
INFO:root:current train perplexity5.196821689605713
INFO:root:current mean train loss 4177.546149603754
INFO:root:current train perplexity5.194403171539307
INFO:root:current mean train loss 4179.421383647798
INFO:root:current train perplexity5.196682453155518
INFO:root:current mean train loss 4181.040040153632
INFO:root:current train perplexity5.197714328765869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.92s/it]
INFO:root:final mean train loss: 4177.567402070568
INFO:root:final train perplexity: 5.1974663734436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 4031.6642252604165
INFO:root:eval perplexity: 5.105337619781494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 4849.8993586546985
INFO:root:eval perplexity: 7.265888214111328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/13
  6%|â–‹         | 13/200 [2:08:58<30:49:13, 593.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4148.856526692708
INFO:root:current train perplexity5.134510040283203
INFO:root:current mean train loss 4126.630380574939
INFO:root:current train perplexity5.111273765563965
INFO:root:current mean train loss 4130.580762440348
INFO:root:current train perplexity5.098382949829102
INFO:root:current mean train loss 4131.967730733034
INFO:root:current train perplexity5.0906853675842285
INFO:root:current mean train loss 4125.403599589989
INFO:root:current train perplexity5.0925469398498535
INFO:root:current mean train loss 4123.7754809036405
INFO:root:current train perplexity5.0911784172058105
INFO:root:current mean train loss 4127.124837239583
INFO:root:current train perplexity5.096247673034668
INFO:root:current mean train loss 4134.8745360286275
INFO:root:current train perplexity5.105714321136475
INFO:root:current mean train loss 4133.2842453592
INFO:root:current train perplexity5.1085944175720215
INFO:root:current mean train loss 4134.421404562915
INFO:root:current train perplexity5.107559680938721

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.07s/it]
INFO:root:final mean train loss: 4135.67825594256
INFO:root:final train perplexity: 5.112276077270508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 4008.708657122673
INFO:root:eval perplexity: 5.058166027069092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 4826.46536839262
INFO:root:eval perplexity: 7.196595191955566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/14
  7%|â–‹         | 14/200 [2:18:47<30:35:55, 592.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4140.406139026989
INFO:root:current train perplexity4.900027751922607
INFO:root:current mean train loss 4106.720529367258
INFO:root:current train perplexity5.02258825302124
INFO:root:current mean train loss 4103.394390088122
INFO:root:current train perplexity5.015142917633057
INFO:root:current mean train loss 4101.539750175844
INFO:root:current train perplexity5.01863431930542
INFO:root:current mean train loss 4097.118437309915
INFO:root:current train perplexity5.017656326293945
INFO:root:current mean train loss 4091.023869404354
INFO:root:current train perplexity5.0160346031188965
INFO:root:current mean train loss 4095.0618095335517
INFO:root:current train perplexity5.024270057678223
INFO:root:current mean train loss 4093.629599183588
INFO:root:current train perplexity5.022689342498779
INFO:root:current mean train loss 4099.904237570804
INFO:root:current train perplexity5.031651496887207
INFO:root:current mean train loss 4100.613004146371
INFO:root:current train perplexity5.0343708992004395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.07s/it]
INFO:root:final mean train loss: 4099.391723448231
INFO:root:final train perplexity: 5.039610385894775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3976.916974872562
INFO:root:eval perplexity: 4.993557453155518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 4808.383608987146
INFO:root:eval perplexity: 7.143580913543701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/15
  8%|â–Š         | 15/200 [2:28:38<30:24:13, 591.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4053.162713301809
INFO:root:current train perplexity5.0113067626953125
INFO:root:current mean train loss 4064.00799714417
INFO:root:current train perplexity4.987024784088135
INFO:root:current mean train loss 4064.8017901416238
INFO:root:current train perplexity4.972169876098633
INFO:root:current mean train loss 4078.650932479428
INFO:root:current train perplexity4.989745140075684
INFO:root:current mean train loss 4070.4792661097854
INFO:root:current train perplexity4.974786758422852
INFO:root:current mean train loss 4072.7523440322434
INFO:root:current train perplexity4.973662376403809
INFO:root:current mean train loss 4068.4576583640446
INFO:root:current train perplexity4.9697041511535645
INFO:root:current mean train loss 4071.564995735179
INFO:root:current train perplexity4.966951370239258
INFO:root:current mean train loss 4068.472138457246
INFO:root:current train perplexity4.968011856079102
INFO:root:current mean train loss 4068.42607214661
INFO:root:current train perplexity4.970807075500488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.69s/it]
INFO:root:final mean train loss: 4061.664989348381
INFO:root:final train perplexity: 4.965153694152832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3950.2146290447695
INFO:root:eval perplexity: 4.9399285316467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 4780.950865400599
INFO:root:eval perplexity: 7.063894271850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/16
  8%|â–Š         | 16/200 [2:38:29<30:14:11, 591.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4080.8857783564813
INFO:root:current train perplexity4.911193370819092
INFO:root:current mean train loss 4055.297467089075
INFO:root:current train perplexity4.939881801605225
INFO:root:current mean train loss 4039.761272413615
INFO:root:current train perplexity4.924256801605225
INFO:root:current mean train loss 4041.1551412879876
INFO:root:current train perplexity4.916256904602051
INFO:root:current mean train loss 4041.4338247401934
INFO:root:current train perplexity4.916603088378906
INFO:root:current mean train loss 4035.776300014083
INFO:root:current train perplexity4.9126973152160645
INFO:root:current mean train loss 4030.455353415944
INFO:root:current train perplexity4.901754379272461
INFO:root:current mean train loss 4034.889732728142
INFO:root:current train perplexity4.906796932220459
INFO:root:current mean train loss 4035.391944599267
INFO:root:current train perplexity4.910689353942871
INFO:root:current mean train loss 4032.321483426881
INFO:root:current train perplexity4.904553413391113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.00s/it]
INFO:root:final mean train loss: 4032.573058774394
INFO:root:final train perplexity: 4.908492088317871
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3946.654844027039
INFO:root:eval perplexity: 4.932822227478027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 4781.91039346465
INFO:root:eval perplexity: 7.066666603088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/17
  8%|â–Š         | 17/200 [2:48:20<30:03:26, 591.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4061.019356863839
INFO:root:current train perplexity4.909820556640625
INFO:root:current mean train loss 4004.797238498264
INFO:root:current train perplexity4.860748291015625
INFO:root:current mean train loss 4003.204262591423
INFO:root:current train perplexity4.8483357429504395
INFO:root:current mean train loss 4004.0326776760726
INFO:root:current train perplexity4.849039554595947
INFO:root:current mean train loss 4001.81693045079
INFO:root:current train perplexity4.850601673126221
INFO:root:current mean train loss 4001.3474244304907
INFO:root:current train perplexity4.84888219833374
INFO:root:current mean train loss 4006.583245417077
INFO:root:current train perplexity4.855140686035156
INFO:root:current mean train loss 4003.042451238308
INFO:root:current train perplexity4.8528923988342285
INFO:root:current mean train loss 4001.3340592252994
INFO:root:current train perplexity4.850302696228027
INFO:root:current mean train loss 4006.0387374143547
INFO:root:current train perplexity4.85368537902832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.20s/it]
INFO:root:final mean train loss: 4002.545052374563
INFO:root:final train perplexity: 4.85068416595459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3937.0812745872117
INFO:root:eval perplexity: 4.913763523101807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4780.859118738918
INFO:root:eval perplexity: 7.063628673553467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/18
  9%|â–‰         | 18/200 [2:58:11<29:53:55, 591.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3918.1752475472385
INFO:root:current train perplexity4.768120288848877
INFO:root:current mean train loss 3956.673764955747
INFO:root:current train perplexity4.769330024719238
INFO:root:current mean train loss 3956.5134659127443
INFO:root:current train perplexity4.775656223297119
INFO:root:current mean train loss 3958.949919141764
INFO:root:current train perplexity4.772610187530518
INFO:root:current mean train loss 3968.979116332181
INFO:root:current train perplexity4.7865519523620605
INFO:root:current mean train loss 3970.5502070923976
INFO:root:current train perplexity4.786489963531494
INFO:root:current mean train loss 3970.129753338234
INFO:root:current train perplexity4.7865142822265625
INFO:root:current mean train loss 3971.946849961621
INFO:root:current train perplexity4.784433841705322
INFO:root:current mean train loss 3975.405863661217
INFO:root:current train perplexity4.792353630065918
INFO:root:current mean train loss 3976.0688639668115
INFO:root:current train perplexity4.795133113861084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.94s/it]
INFO:root:final mean train loss: 3974.2473710583104
INFO:root:final train perplexity: 4.7968316078186035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3899.7447933981603
INFO:root:eval perplexity: 4.8401336669921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4741.033196199025
INFO:root:eval perplexity: 6.949526309967041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/19
 10%|â–‰         | 19/200 [3:08:04<29:45:14, 591.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3956.6265653722426
INFO:root:current train perplexity4.783254623413086
INFO:root:current mean train loss 3945.40471239911
INFO:root:current train perplexity4.7586259841918945
INFO:root:current mean train loss 3936.3607182597734
INFO:root:current train perplexity4.734760761260986
INFO:root:current mean train loss 3950.31268014935
INFO:root:current train perplexity4.752827167510986
INFO:root:current mean train loss 3945.7030963094167
INFO:root:current train perplexity4.7474751472473145
INFO:root:current mean train loss 3949.9333921456728
INFO:root:current train perplexity4.747828483581543
INFO:root:current mean train loss 3951.272527691772
INFO:root:current train perplexity4.74609375
INFO:root:current mean train loss 3948.567328522907
INFO:root:current train perplexity4.741366863250732
INFO:root:current mean train loss 3951.072006566264
INFO:root:current train perplexity4.745244979858398
INFO:root:current mean train loss 3951.579266633396
INFO:root:current train perplexity4.74761438369751

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.47s/it]
INFO:root:final mean train loss: 3948.840533225767
INFO:root:final train perplexity: 4.748989105224609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3889.6667082225176
INFO:root:eval perplexity: 4.820448875427246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4741.55096825133
INFO:root:eval perplexity: 6.950998783111572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/20
 10%|â–ˆ         | 20/200 [3:17:57<29:36:07, 592.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3921.490151615466
INFO:root:current train perplexity4.70188570022583
INFO:root:current mean train loss 3926.9084917944183
INFO:root:current train perplexity4.677379608154297
INFO:root:current mean train loss 3919.2170890896477
INFO:root:current train perplexity4.6903533935546875
INFO:root:current mean train loss 3926.818510347754
INFO:root:current train perplexity4.691658973693848
INFO:root:current mean train loss 3930.061710133272
INFO:root:current train perplexity4.700277328491211
INFO:root:current mean train loss 3934.584172175481
INFO:root:current train perplexity4.707710266113281
INFO:root:current mean train loss 3930.523054062144
INFO:root:current train perplexity4.702605247497559
INFO:root:current mean train loss 3931.663779438406
INFO:root:current train perplexity4.70361852645874
INFO:root:current mean train loss 3934.09952808953
INFO:root:current train perplexity4.707553386688232
INFO:root:current mean train loss 3928.993473629758
INFO:root:current train perplexity4.704370021820068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.68s/it]
INFO:root:final mean train loss: 3925.2417937863256
INFO:root:final train perplexity: 4.70497989654541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3880.0882646276596
INFO:root:eval perplexity: 4.801814556121826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 4738.762033881871
INFO:root:eval perplexity: 6.943074703216553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/21
 10%|â–ˆ         | 21/200 [3:27:50<29:27:45, 592.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3933.1504270638993
INFO:root:current train perplexity4.690852642059326
INFO:root:current mean train loss 3919.4717834838134
INFO:root:current train perplexity4.6781158447265625
INFO:root:current mean train loss 3907.2036809456927
INFO:root:current train perplexity4.677716255187988
INFO:root:current mean train loss 3909.353294767541
INFO:root:current train perplexity4.670601844787598
INFO:root:current mean train loss 3902.8957221543765
INFO:root:current train perplexity4.655496597290039
INFO:root:current mean train loss 3899.8673765259864
INFO:root:current train perplexity4.656347751617432
INFO:root:current mean train loss 3901.6909875140555
INFO:root:current train perplexity4.655509948730469
INFO:root:current mean train loss 3902.718042724291
INFO:root:current train perplexity4.654196739196777
INFO:root:current mean train loss 3906.571966573854
INFO:root:current train perplexity4.659928321838379
INFO:root:current mean train loss 3907.875751862235
INFO:root:current train perplexity4.666972637176514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.69s/it]
INFO:root:final mean train loss: 3904.6053333897744
INFO:root:final train perplexity: 4.666828632354736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 3871.159487893395
INFO:root:eval perplexity: 4.78450870513916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 4721.816257341534
INFO:root:eval perplexity: 6.895132064819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/22
 11%|â–ˆ         | 22/200 [3:37:46<29:20:14, 593.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3918.474814453125
INFO:root:current train perplexity4.6509270668029785
INFO:root:current mean train loss 3908.422779017857
INFO:root:current train perplexity4.623951435089111
INFO:root:current mean train loss 3891.0451091974433
INFO:root:current train perplexity4.612585544586182
INFO:root:current mean train loss 3883.0699381510417
INFO:root:current train perplexity4.604074954986572
INFO:root:current mean train loss 3877.8750719572367
INFO:root:current train perplexity4.608677387237549
INFO:root:current mean train loss 3883.1533440896737
INFO:root:current train perplexity4.614269256591797
INFO:root:current mean train loss 3884.857902199074
INFO:root:current train perplexity4.616329669952393
INFO:root:current mean train loss 3881.532092048891
INFO:root:current train perplexity4.611298084259033
INFO:root:current mean train loss 3884.180164620536
INFO:root:current train perplexity4.61843729019165
INFO:root:current mean train loss 3884.333056640625
INFO:root:current train perplexity4.62333345413208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.13s/it]
INFO:root:final mean train loss: 3880.5313625335693
INFO:root:final train perplexity: 4.622713565826416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 3859.112581726507
INFO:root:eval perplexity: 4.761257648468018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 4712.797799617686
INFO:root:eval perplexity: 6.8697509765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/23
 12%|â–ˆâ–        | 23/200 [3:47:42<29:12:59, 594.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3857.1915621470257
INFO:root:current train perplexity4.582645893096924
INFO:root:current mean train loss 3853.432194277237
INFO:root:current train perplexity4.580165386199951
INFO:root:current mean train loss 3866.882762464112
INFO:root:current train perplexity4.587716102600098
INFO:root:current mean train loss 3864.95306316804
INFO:root:current train perplexity4.590676307678223
INFO:root:current mean train loss 3859.673280198628
INFO:root:current train perplexity4.584115028381348
INFO:root:current mean train loss 3859.987352845599
INFO:root:current train perplexity4.582001209259033
INFO:root:current mean train loss 3860.680463173728
INFO:root:current train perplexity4.586568832397461
INFO:root:current mean train loss 3860.8897999730602
INFO:root:current train perplexity4.588845729827881
INFO:root:current mean train loss 3864.5335752804713
INFO:root:current train perplexity4.592612266540527
INFO:root:current mean train loss 3867.176310511111
INFO:root:current train perplexity4.593445301055908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it]
INFO:root:final mean train loss: 3865.0416567402503
INFO:root:final train perplexity: 4.594549655914307
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 3859.2752850038787
INFO:root:eval perplexity: 4.761570930480957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 4725.517630069814
INFO:root:eval perplexity: 6.905575752258301
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/24
 12%|â–ˆâ–        | 24/200 [3:57:34<29:01:32, 593.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.487787603022
INFO:root:current train perplexity4.545372486114502
INFO:root:current mean train loss 3815.7693510205336
INFO:root:current train perplexity4.504649639129639
INFO:root:current mean train loss 3827.181507228576
INFO:root:current train perplexity4.527510643005371
INFO:root:current mean train loss 3834.2215054797393
INFO:root:current train perplexity4.539320945739746
INFO:root:current mean train loss 3841.5625238671078
INFO:root:current train perplexity4.550717830657959
INFO:root:current mean train loss 3839.8897347748784
INFO:root:current train perplexity4.544234275817871
INFO:root:current mean train loss 3839.1487837486434
INFO:root:current train perplexity4.547073841094971
INFO:root:current mean train loss 3844.78344170996
INFO:root:current train perplexity4.552631855010986
INFO:root:current mean train loss 3844.202556160564
INFO:root:current train perplexity4.556105136871338
INFO:root:current mean train loss 3846.7792168087003
INFO:root:current train perplexity4.556377410888672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.07s/it]
INFO:root:final mean train loss: 3843.8623434497463
INFO:root:final train perplexity: 4.5563178062438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.71s/it]
INFO:root:eval mean loss: 3837.3850755623894
INFO:root:eval perplexity: 4.719607830047607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 4704.820127230164
INFO:root:eval perplexity: 6.847376346588135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/25
 12%|â–ˆâ–Ž        | 25/200 [4:07:27<28:50:43, 593.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3849.9834428267045
INFO:root:current train perplexity4.525624752044678
INFO:root:current mean train loss 3849.883867580088
INFO:root:current train perplexity4.542826175689697
INFO:root:current mean train loss 3833.458563865228
INFO:root:current train perplexity4.527446746826172
INFO:root:current mean train loss 3825.8955745075577
INFO:root:current train perplexity4.523357391357422
INFO:root:current mean train loss 3827.5562169260397
INFO:root:current train perplexity4.524747848510742
INFO:root:current mean train loss 3830.272281194569
INFO:root:current train perplexity4.520051956176758
INFO:root:current mean train loss 3831.3685433711107
INFO:root:current train perplexity4.524280071258545
INFO:root:current mean train loss 3832.3701147430384
INFO:root:current train perplexity4.52578592300415
INFO:root:current mean train loss 3831.1871898680824
INFO:root:current train perplexity4.52585506439209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.85s/it]
INFO:root:final mean train loss: 3826.3914116274927
INFO:root:final train perplexity: 4.525020599365234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 3871.6003227504434
INFO:root:eval perplexity: 4.785360813140869
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 4745.738882078346
INFO:root:eval perplexity: 6.962913513183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/26
 13%|â–ˆâ–Ž        | 26/200 [4:17:20<28:40:20, 593.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.8104422433034
INFO:root:current train perplexity4.4725799560546875
INFO:root:current mean train loss 3764.7681051949476
INFO:root:current train perplexity4.440639972686768
INFO:root:current mean train loss 3783.502200803895
INFO:root:current train perplexity4.463764667510986
INFO:root:current mean train loss 3792.484253327311
INFO:root:current train perplexity4.4691290855407715
INFO:root:current mean train loss 3800.2646370402717
INFO:root:current train perplexity4.47387170791626
INFO:root:current mean train loss 3801.837766387759
INFO:root:current train perplexity4.477895736694336
INFO:root:current mean train loss 3797.894322905941
INFO:root:current train perplexity4.472651958465576
INFO:root:current mean train loss 3798.3859493789782
INFO:root:current train perplexity4.473747730255127
INFO:root:current mean train loss 3801.958152421197
INFO:root:current train perplexity4.476655006408691
INFO:root:current mean train loss 3803.9981424316943
INFO:root:current train perplexity4.479313850402832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.44s/it]
INFO:root:final mean train loss: 3802.9522767836047
INFO:root:final train perplexity: 4.483368873596191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 3813.7607023631426
INFO:root:eval perplexity: 4.674736499786377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4692.588912206339
INFO:root:eval perplexity: 6.813214302062988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/27
 14%|â–ˆâ–Ž        | 27/200 [4:27:12<28:29:10, 592.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.708707682292
INFO:root:current train perplexity4.427404880523682
INFO:root:current mean train loss 3789.552443529212
INFO:root:current train perplexity4.453582286834717
INFO:root:current mean train loss 3770.453400935683
INFO:root:current train perplexity4.4382829666137695
INFO:root:current mean train loss 3773.572041635665
INFO:root:current train perplexity4.438294410705566
INFO:root:current mean train loss 3778.7221509083206
INFO:root:current train perplexity4.4404778480529785
INFO:root:current mean train loss 3782.328938011984
INFO:root:current train perplexity4.441131114959717
INFO:root:current mean train loss 3777.4264434070124
INFO:root:current train perplexity4.435603618621826
INFO:root:current mean train loss 3781.953883372487
INFO:root:current train perplexity4.446680068969727
INFO:root:current mean train loss 3784.735180514283
INFO:root:current train perplexity4.449793338775635
INFO:root:current mean train loss 3786.618378586066
INFO:root:current train perplexity4.453220367431641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it]
INFO:root:final mean train loss: 3785.232898712158
INFO:root:final train perplexity: 4.4521355628967285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3811.041311710439
INFO:root:eval perplexity: 4.669599533081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4691.8500941932625
INFO:root:eval perplexity: 6.8111572265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/28
 14%|â–ˆâ–        | 28/200 [4:37:03<28:18:16, 592.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3793.3597889775815
INFO:root:current train perplexity4.439718723297119
INFO:root:current mean train loss 3760.9754569200963
INFO:root:current train perplexity4.390774250030518
INFO:root:current mean train loss 3772.1117463389855
INFO:root:current train perplexity4.412903785705566
INFO:root:current mean train loss 3765.988356835333
INFO:root:current train perplexity4.41403865814209
INFO:root:current mean train loss 3773.384392199505
INFO:root:current train perplexity4.420149803161621
INFO:root:current mean train loss 3776.970113079589
INFO:root:current train perplexity4.420462608337402
INFO:root:current mean train loss 3769.088565048781
INFO:root:current train perplexity4.413558483123779
INFO:root:current mean train loss 3768.348539275912
INFO:root:current train perplexity4.415615558624268
INFO:root:current mean train loss 3769.115883439019
INFO:root:current train perplexity4.414947032928467
INFO:root:current mean train loss 3769.5715152166
INFO:root:current train perplexity4.4163594245910645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.08s/it]
INFO:root:final mean train loss: 3765.1650686571675
INFO:root:final train perplexity: 4.417026519775391
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3789.2204572528813
INFO:root:eval perplexity: 4.628576755523682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 4669.99365234375
INFO:root:eval perplexity: 6.750554084777832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/29
 14%|â–ˆâ–        | 29/200 [4:46:56<28:09:01, 592.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.1400815902216
INFO:root:current train perplexity4.4143242835998535
INFO:root:current mean train loss 3758.047903745229
INFO:root:current train perplexity4.384793758392334
INFO:root:current mean train loss 3746.082101004464
INFO:root:current train perplexity4.39035177230835
INFO:root:current mean train loss 3745.3095363835914
INFO:root:current train perplexity4.375504970550537
INFO:root:current mean train loss 3744.906170696781
INFO:root:current train perplexity4.378144264221191
INFO:root:current mean train loss 3751.9539999521835
INFO:root:current train perplexity4.389062404632568
INFO:root:current mean train loss 3753.84935633543
INFO:root:current train perplexity4.390200614929199
INFO:root:current mean train loss 3753.3137644547282
INFO:root:current train perplexity4.38953161239624
INFO:root:current mean train loss 3755.140100582412
INFO:root:current train perplexity4.395786285400391
INFO:root:current mean train loss 3755.299954685822
INFO:root:current train perplexity4.393558025360107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.93s/it]
INFO:root:final mean train loss: 3751.404111616073
INFO:root:final train perplexity: 4.393110752105713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3832.870041001773
INFO:root:eval perplexity: 4.710999965667725
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4711.01840404754
INFO:root:eval perplexity: 6.864753246307373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/30
 15%|â–ˆâ–Œ        | 30/200 [4:56:49<27:59:06, 592.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3745.0850986578525
INFO:root:current train perplexity4.353964328765869
INFO:root:current mean train loss 3720.1330777175135
INFO:root:current train perplexity4.338808536529541
INFO:root:current mean train loss 3723.341039936912
INFO:root:current train perplexity4.3297953605651855
INFO:root:current mean train loss 3725.7093552671
INFO:root:current train perplexity4.338619232177734
INFO:root:current mean train loss 3726.47997490746
INFO:root:current train perplexity4.344301223754883
INFO:root:current mean train loss 3728.8624256254348
INFO:root:current train perplexity4.353375434875488
INFO:root:current mean train loss 3729.8721792015112
INFO:root:current train perplexity4.3549323081970215
INFO:root:current mean train loss 3729.521316548968
INFO:root:current train perplexity4.355896949768066
INFO:root:current mean train loss 3734.030567919398
INFO:root:current train perplexity4.358086585998535
INFO:root:current mean train loss 3734.3732798355963
INFO:root:current train perplexity4.357783794403076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.28s/it]
INFO:root:final mean train loss: 3731.4560723458567
INFO:root:final train perplexity: 4.35867166519165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 38.00s/it]
INFO:root:eval mean loss: 3776.879978044659
INFO:root:eval perplexity: 4.605537414550781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 4662.846750678746
INFO:root:eval perplexity: 6.730856418609619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/31
 16%|â–ˆâ–Œ        | 31/200 [5:06:43<27:50:25, 593.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3748.461140084774
INFO:root:current train perplexity4.362015724182129
INFO:root:current mean train loss 3720.235163889775
INFO:root:current train perplexity4.32267951965332
INFO:root:current mean train loss 3721.164874984185
INFO:root:current train perplexity4.318309783935547
INFO:root:current mean train loss 3711.8585679991443
INFO:root:current train perplexity4.314008712768555
INFO:root:current mean train loss 3714.6227366470916
INFO:root:current train perplexity4.31959867477417
INFO:root:current mean train loss 3712.7056610274794
INFO:root:current train perplexity4.321487903594971
INFO:root:current mean train loss 3714.2844777881087
INFO:root:current train perplexity4.3256001472473145
INFO:root:current mean train loss 3715.5807134789156
INFO:root:current train perplexity4.328684329986572
INFO:root:current mean train loss 3717.4163635325967
INFO:root:current train perplexity4.330206394195557
INFO:root:current mean train loss 3718.6870697247064
INFO:root:current train perplexity4.3341546058654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.94s/it]
INFO:root:final mean train loss: 3718.992431456043
INFO:root:final train perplexity: 4.337291717529297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3791.5714016095967
INFO:root:eval perplexity: 4.632979393005371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 4684.459420711436
INFO:root:eval perplexity: 6.790603160858154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/32
 16%|â–ˆâ–Œ        | 32/200 [5:16:36<27:40:16, 592.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3741.3492320667615
INFO:root:current train perplexity4.363146781921387
INFO:root:current mean train loss 3727.1422820060484
INFO:root:current train perplexity4.324575901031494
INFO:root:current mean train loss 3710.049179496017
INFO:root:current train perplexity4.322117328643799
INFO:root:current mean train loss 3705.876473096391
INFO:root:current train perplexity4.317180156707764
INFO:root:current mean train loss 3709.0405021248284
INFO:root:current train perplexity4.315560340881348
INFO:root:current mean train loss 3704.5207677892736
INFO:root:current train perplexity4.312320232391357
INFO:root:current mean train loss 3705.868634079795
INFO:root:current train perplexity4.311307907104492
INFO:root:current mean train loss 3707.2302084411217
INFO:root:current train perplexity4.3154120445251465
INFO:root:current mean train loss 3707.287062545687
INFO:root:current train perplexity4.312984466552734
INFO:root:current mean train loss 3705.970071682755
INFO:root:current train perplexity4.309349060058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.47s/it]
INFO:root:final mean train loss: 3703.694871471774
INFO:root:final train perplexity: 4.311193466186523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3768.1920849955673
INFO:root:eval perplexity: 4.589385986328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 4658.625855357935
INFO:root:eval perplexity: 6.719247341156006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/33
 16%|â–ˆâ–‹        | 33/200 [5:26:27<27:28:54, 592.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3678.4994845920137
INFO:root:current train perplexity4.305475234985352
INFO:root:current mean train loss 3684.102612454467
INFO:root:current train perplexity4.29179048538208
INFO:root:current mean train loss 3677.138682086205
INFO:root:current train perplexity4.284492492675781
INFO:root:current mean train loss 3676.871913605157
INFO:root:current train perplexity4.275032997131348
INFO:root:current mean train loss 3674.6074403305547
INFO:root:current train perplexity4.266384601593018
INFO:root:current mean train loss 3681.7610895349967
INFO:root:current train perplexity4.272565841674805
INFO:root:current mean train loss 3687.8848506875706
INFO:root:current train perplexity4.2801923751831055
INFO:root:current mean train loss 3691.6654105530183
INFO:root:current train perplexity4.283206462860107
INFO:root:current mean train loss 3692.343245027792
INFO:root:current train perplexity4.283641338348389
INFO:root:current mean train loss 3690.130063065859
INFO:root:current train perplexity4.2835588455200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.19s/it]
INFO:root:final mean train loss: 3687.2143181831607
INFO:root:final train perplexity: 4.283252716064453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 3774.543238863032
INFO:root:eval perplexity: 4.601187229156494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 4667.329823595413
INFO:root:eval perplexity: 6.743206024169922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/34
 17%|â–ˆâ–‹        | 34/200 [5:36:20<27:19:27, 592.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3651.3846899757923
INFO:root:current train perplexity4.234677791595459
INFO:root:current mean train loss 3658.282721982365
INFO:root:current train perplexity4.24546480178833
INFO:root:current mean train loss 3663.7607557008187
INFO:root:current train perplexity4.243624687194824
INFO:root:current mean train loss 3663.1918833442132
INFO:root:current train perplexity4.2448201179504395
INFO:root:current mean train loss 3674.951654454452
INFO:root:current train perplexity4.257776737213135
INFO:root:current mean train loss 3669.1127266959006
INFO:root:current train perplexity4.2554402351379395
INFO:root:current mean train loss 3667.001645311336
INFO:root:current train perplexity4.250112056732178
INFO:root:current mean train loss 3672.076543944046
INFO:root:current train perplexity4.2545552253723145
INFO:root:current mean train loss 3671.6704146410375
INFO:root:current train perplexity4.253107070922852
INFO:root:current mean train loss 3673.3556927760524
INFO:root:current train perplexity4.254854679107666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.57s/it]
INFO:root:final mean train loss: 3669.644376139487
INFO:root:final train perplexity: 4.253664493560791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 3795.8917591284353
INFO:root:eval perplexity: 4.641080856323242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4692.08950610871
INFO:root:eval perplexity: 6.811823844909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/35
 18%|â–ˆâ–Š        | 35/200 [5:46:12<27:09:08, 592.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3680.4736111797865
INFO:root:current train perplexity4.2150726318359375
INFO:root:current mean train loss 3646.5960441035263
INFO:root:current train perplexity4.200964450836182
INFO:root:current mean train loss 3644.891318919411
INFO:root:current train perplexity4.208334922790527
INFO:root:current mean train loss 3664.6810731107767
INFO:root:current train perplexity4.2367143630981445
INFO:root:current mean train loss 3663.5630020428302
INFO:root:current train perplexity4.225822925567627
INFO:root:current mean train loss 3656.814145313849
INFO:root:current train perplexity4.22564697265625
INFO:root:current mean train loss 3656.911029978599
INFO:root:current train perplexity4.223899841308594
INFO:root:current mean train loss 3658.19366682295
INFO:root:current train perplexity4.223576068878174
INFO:root:current mean train loss 3658.7068762665317
INFO:root:current train perplexity4.223363399505615
INFO:root:current mean train loss 3656.9847949518003
INFO:root:current train perplexity4.225887775421143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.98s/it]
INFO:root:final mean train loss: 3653.0975104301206
INFO:root:final train perplexity: 4.225986480712891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3771.510406277704
INFO:root:eval perplexity: 4.595547676086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 4675.0144527787015
INFO:root:eval perplexity: 6.76442813873291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/36
 18%|â–ˆâ–Š        | 36/200 [5:56:04<26:59:16, 592.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3640.096084770115
INFO:root:current train perplexity4.207602500915527
INFO:root:current mean train loss 3644.7524192116475
INFO:root:current train perplexity4.197790145874023
INFO:root:current mean train loss 3643.3924939092444
INFO:root:current train perplexity4.194149494171143
INFO:root:current mean train loss 3638.9637605731186
INFO:root:current train perplexity4.193826675415039
INFO:root:current mean train loss 3647.104540815099
INFO:root:current train perplexity4.202550411224365
INFO:root:current mean train loss 3639.010201085365
INFO:root:current train perplexity4.197038650512695
INFO:root:current mean train loss 3641.87252625489
INFO:root:current train perplexity4.202704906463623
INFO:root:current mean train loss 3639.970191267273
INFO:root:current train perplexity4.200071811676025
INFO:root:current mean train loss 3641.098950167788
INFO:root:current train perplexity4.200008392333984
INFO:root:current mean train loss 3642.7766001970936
INFO:root:current train perplexity4.204135417938232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.50s/it]
INFO:root:final mean train loss: 3640.0436230321084
INFO:root:final train perplexity: 4.204277515411377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.28s/it]
INFO:root:eval mean loss: 3744.653387840758
INFO:root:eval perplexity: 4.545909881591797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it]
INFO:root:eval mean loss: 4645.04072819703
INFO:root:eval perplexity: 6.6820244789123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/37
 18%|â–ˆâ–Š        | 37/200 [6:06:01<26:52:57, 593.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3643.419734272204
INFO:root:current train perplexity4.185039520263672
INFO:root:current mean train loss 3615.8902719350963
INFO:root:current train perplexity4.173869609832764
INFO:root:current mean train loss 3621.3400969941736
INFO:root:current train perplexity4.170143127441406
INFO:root:current mean train loss 3622.5612681714792
INFO:root:current train perplexity4.170546531677246
INFO:root:current mean train loss 3629.4590149542296
INFO:root:current train perplexity4.173035144805908
INFO:root:current mean train loss 3630.1010639607407
INFO:root:current train perplexity4.180201530456543
INFO:root:current mean train loss 3630.6191845351846
INFO:root:current train perplexity4.181412696838379
INFO:root:current mean train loss 4863.629970334611
INFO:root:current train perplexity6.791904926300049
INFO:root:current mean train loss 5626.193545140101
INFO:root:current train perplexity9.17550277709961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.36s/it]
INFO:root:final mean train loss: 5514.2048679474865
INFO:root:final train perplexity: 8.8067045211792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 4081.62715397828
INFO:root:eval perplexity: 5.209533214569092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 4957.614792844082
INFO:root:eval perplexity: 7.593075275421143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/38
 19%|â–ˆâ–‰        | 38/200 [6:16:01<26:47:41, 595.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4323.671549479167
INFO:root:current train perplexity5.487410545349121
INFO:root:current mean train loss 4149.4071696753645
INFO:root:current train perplexity5.115128040313721
INFO:root:current mean train loss 4076.6698869977677
INFO:root:current train perplexity4.981786727905273
INFO:root:current mean train loss 4033.61275993322
INFO:root:current train perplexity4.9032487869262695
INFO:root:current mean train loss 4007.812547253024
INFO:root:current train perplexity4.856231212615967
INFO:root:current mean train loss 3978.399287866551
INFO:root:current train perplexity4.804537296295166
INFO:root:current mean train loss 3962.68879034191
INFO:root:current train perplexity4.775876045227051
INFO:root:current mean train loss 3954.8540226595837
INFO:root:current train perplexity4.757290840148926
INFO:root:current mean train loss 3945.6472052435206
INFO:root:current train perplexity4.736723899841309
INFO:root:current mean train loss 3941.107160160576
INFO:root:current train perplexity4.728334903717041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:50<00:00, 530.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:50<00:00, 530.15s/it]
INFO:root:final mean train loss: 3932.3394458524645
INFO:root:final train perplexity: 4.718173027038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 3879.3732615802305
INFO:root:eval perplexity: 4.8004255294799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 4781.141269115691
INFO:root:eval perplexity: 7.064442157745361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/39
 20%|â–ˆâ–‰        | 39/200 [6:26:08<26:47:19, 599.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.619806463068
INFO:root:current train perplexity4.549628257751465
INFO:root:current mean train loss 3838.2755973747185
INFO:root:current train perplexity4.517556190490723
INFO:root:current mean train loss 3827.3122061055983
INFO:root:current train perplexity4.51056432723999
INFO:root:current mean train loss 3828.8473116270598
INFO:root:current train perplexity4.518974781036377
INFO:root:current mean train loss 3840.5282086374696
INFO:root:current train perplexity4.529556751251221
INFO:root:current mean train loss 3849.348532002966
INFO:root:current train perplexity4.54518461227417
INFO:root:current mean train loss 3846.208363434687
INFO:root:current train perplexity4.541244983673096
INFO:root:current mean train loss 3845.158628911744
INFO:root:current train perplexity4.540704250335693
INFO:root:current mean train loss 3842.266672005048
INFO:root:current train perplexity4.539892196655273
INFO:root:current mean train loss 3841.236919315141
INFO:root:current train perplexity4.540103912353516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.91s/it]
INFO:root:final mean train loss: 3833.6164874415244
INFO:root:final train perplexity: 4.537937641143799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.76s/it]
INFO:root:eval mean loss: 3866.156021442819
INFO:root:eval perplexity: 4.774837017059326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4767.262906554743
INFO:root:eval perplexity: 7.024466037750244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/40
 20%|â–ˆâ–ˆ        | 40/200 [6:36:06<26:36:12, 598.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3766.4759328741775
INFO:root:current train perplexity4.494937419891357
INFO:root:current mean train loss 3799.9965553604256
INFO:root:current train perplexity4.497641086578369
INFO:root:current mean train loss 3806.5494356895692
INFO:root:current train perplexity4.502867221832275
INFO:root:current mean train loss 3802.74166477885
INFO:root:current train perplexity4.492680072784424
INFO:root:current mean train loss 3814.4503846817197
INFO:root:current train perplexity4.497649192810059
INFO:root:current mean train loss 3815.490286590047
INFO:root:current train perplexity4.504636764526367
INFO:root:current mean train loss 3817.3583582075426
INFO:root:current train perplexity4.499664306640625
INFO:root:current mean train loss 3817.663266241633
INFO:root:current train perplexity4.501556873321533
INFO:root:current mean train loss 3822.1487674922732
INFO:root:current train perplexity4.509322643280029
INFO:root:current mean train loss 3821.714892099939
INFO:root:current train perplexity4.511780738830566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.56s/it]
INFO:root:final mean train loss: 3819.3731702373875
INFO:root:final train perplexity: 4.512509346008301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 3838.1369403812055
INFO:root:eval perplexity: 4.721044063568115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 4746.071737519393
INFO:root:eval perplexity: 6.963860988616943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/41
 20%|â–ˆâ–ˆ        | 41/200 [6:46:03<26:25:41, 598.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3811.1491247106483
INFO:root:current train perplexity4.488430976867676
INFO:root:current mean train loss 3848.131259227362
INFO:root:current train perplexity4.529938697814941
INFO:root:current mean train loss 3846.032755713106
INFO:root:current train perplexity4.5335693359375
INFO:root:current mean train loss 3842.144486453555
INFO:root:current train perplexity4.526629447937012
INFO:root:current mean train loss 3842.617961660202
INFO:root:current train perplexity4.530970096588135
INFO:root:current mean train loss 3842.34879588176
INFO:root:current train perplexity4.53623104095459
INFO:root:current mean train loss 3845.2639241925835
INFO:root:current train perplexity4.541055202484131
INFO:root:current mean train loss 3843.1459947504727
INFO:root:current train perplexity4.542076110839844
INFO:root:current mean train loss 3841.3879444717354
INFO:root:current train perplexity4.5391740798950195
INFO:root:current mean train loss 3836.37027099346
INFO:root:current train perplexity4.536739826202393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.49s/it]
INFO:root:final mean train loss: 3832.406239724928
INFO:root:final train perplexity: 4.535771369934082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 3862.944484845966
INFO:root:eval perplexity: 4.768640041351318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 4773.8879359901375
INFO:root:eval perplexity: 7.04352331161499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/42
 21%|â–ˆâ–ˆ        | 42/200 [6:55:57<26:12:15, 597.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3832.9143415178573
INFO:root:current train perplexity4.470272541046143
INFO:root:current mean train loss 3783.475302010995
INFO:root:current train perplexity4.466856479644775
INFO:root:current mean train loss 3800.823914353391
INFO:root:current train perplexity4.480170249938965
INFO:root:current mean train loss 3809.2901702425374
INFO:root:current train perplexity4.499148368835449
INFO:root:current mean train loss 3806.41997575431
INFO:root:current train perplexity4.489272117614746
INFO:root:current mean train loss 3807.418007995035
INFO:root:current train perplexity4.4888505935668945
INFO:root:current mean train loss 3810.624366003322
INFO:root:current train perplexity4.490114212036133
INFO:root:current mean train loss 3807.178808261586
INFO:root:current train perplexity4.484371185302734
INFO:root:current mean train loss 3807.2171480281622
INFO:root:current train perplexity4.487381458282471
INFO:root:current mean train loss 3812.474652980866
INFO:root:current train perplexity4.49327278137207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.25s/it]
INFO:root:final mean train loss: 3808.2619213596467
INFO:root:final train perplexity: 4.492770671844482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 3833.629420503657
INFO:root:eval perplexity: 4.712446689605713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 4747.49864943484
INFO:root:eval perplexity: 6.967923164367676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:05:50<25:58:56, 595.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.3883312136627
INFO:root:current train perplexity4.394891262054443
INFO:root:current mean train loss 3780.170707222465
INFO:root:current train perplexity4.422788143157959
INFO:root:current mean train loss 3787.4304128890176
INFO:root:current train perplexity4.441174030303955
INFO:root:current mean train loss 3788.248587116208
INFO:root:current train perplexity4.445826053619385
INFO:root:current mean train loss 3790.9417969852216
INFO:root:current train perplexity4.447851181030273
INFO:root:current mean train loss 3777.0086276509264
INFO:root:current train perplexity4.438188552856445
INFO:root:current mean train loss 3778.60872345208
INFO:root:current train perplexity4.4390363693237305
INFO:root:current mean train loss 3782.8666009710423
INFO:root:current train perplexity4.4424357414245605
INFO:root:current mean train loss 3784.5026502145424
INFO:root:current train perplexity4.444424152374268
INFO:root:current mean train loss 3784.884498183573
INFO:root:current train perplexity4.4428534507751465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.62s/it]
INFO:root:final mean train loss: 3780.0934734344482
INFO:root:final train perplexity: 4.443117141723633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3858.584792982602
INFO:root:eval perplexity: 4.7602410316467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 4776.476929576685
INFO:root:eval perplexity: 7.050983428955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:15:42<25:46:16, 594.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3758.5604032628676
INFO:root:current train perplexity4.417906761169434
INFO:root:current mean train loss 3774.6818152421356
INFO:root:current train perplexity4.433018684387207
INFO:root:current mean train loss 3758.135411479084
INFO:root:current train perplexity4.414000511169434
INFO:root:current mean train loss 3757.79914669026
INFO:root:current train perplexity4.40893030166626
INFO:root:current mean train loss 3759.4804357287626
INFO:root:current train perplexity4.412464618682861
INFO:root:current mean train loss 3761.4027549342104
INFO:root:current train perplexity4.411698818206787
INFO:root:current mean train loss 3758.847173219086
INFO:root:current train perplexity4.404272556304932
INFO:root:current mean train loss 3758.0283443689664
INFO:root:current train perplexity4.401079177856445
INFO:root:current mean train loss 3760.0502657145084
INFO:root:current train perplexity4.401846408843994
INFO:root:current mean train loss 3759.5258054843584
INFO:root:current train perplexity4.399624824523926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.07s/it]
INFO:root:final mean train loss: 3755.880320641302
INFO:root:final train perplexity: 4.400874614715576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 3797.904430200022
INFO:root:eval perplexity: 4.644859313964844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 4719.96678302305
INFO:root:eval perplexity: 6.889918804168701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:25:29<25:30:20, 592.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3771.286161778337
INFO:root:current train perplexity4.36320686340332
INFO:root:current mean train loss 3714.1721759532234
INFO:root:current train perplexity4.311463832855225
INFO:root:current mean train loss 3703.5227522095197
INFO:root:current train perplexity4.307470321655273
INFO:root:current mean train loss 3713.6755765527073
INFO:root:current train perplexity4.321781158447266
INFO:root:current mean train loss 3724.8828454776008
INFO:root:current train perplexity4.33335542678833
INFO:root:current mean train loss 3727.055833956423
INFO:root:current train perplexity4.339954376220703
INFO:root:current mean train loss 3721.520338136618
INFO:root:current train perplexity4.338852405548096
INFO:root:current mean train loss 3722.4259108793435
INFO:root:current train perplexity4.342906951904297
INFO:root:current mean train loss 3723.2088331726573
INFO:root:current train perplexity4.343082904815674
INFO:root:current mean train loss 3726.6874401740906
INFO:root:current train perplexity4.345614433288574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.83s/it]
INFO:root:final mean train loss: 3724.0113575843075
INFO:root:final train perplexity: 4.345888137817383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.84s/it]
INFO:root:eval mean loss: 3813.152619057513
INFO:root:eval perplexity: 4.673588275909424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 4732.748273700687
INFO:root:eval perplexity: 6.926023483276367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [7:35:23<25:21:35, 592.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.033385319496
INFO:root:current train perplexity4.294410228729248
INFO:root:current mean train loss 3675.728765613305
INFO:root:current train perplexity4.272286415100098
INFO:root:current mean train loss 3680.7596366968046
INFO:root:current train perplexity4.285769939422607
INFO:root:current mean train loss 3683.4418772351837
INFO:root:current train perplexity4.2837324142456055
INFO:root:current mean train loss 3687.2137955659464
INFO:root:current train perplexity4.293642044067383
INFO:root:current mean train loss 3694.221892395558
INFO:root:current train perplexity4.3010358810424805
INFO:root:current mean train loss 3697.8877198363707
INFO:root:current train perplexity4.302058219909668
INFO:root:current mean train loss 3700.3739072558465
INFO:root:current train perplexity4.297749042510986
INFO:root:current mean train loss 3702.294523421731
INFO:root:current train perplexity4.298934459686279
INFO:root:current mean train loss 3698.5349966875647
INFO:root:current train perplexity4.297428607940674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.95s/it]
INFO:root:final mean train loss: 3696.4541309725855
INFO:root:final train perplexity: 4.298895359039307
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3784.640507258422
INFO:root:eval perplexity: 4.620013236999512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 4703.392313206449
INFO:root:eval perplexity: 6.843379497528076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:45:20<25:14:49, 594.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.794541015625
INFO:root:current train perplexity4.252804756164551
INFO:root:current mean train loss 3652.557861328125
INFO:root:current train perplexity4.229126453399658
INFO:root:current mean train loss 3653.1054838423297
INFO:root:current train perplexity4.238625526428223
INFO:root:current mean train loss 3661.783492838542
INFO:root:current train perplexity4.245194911956787
INFO:root:current mean train loss 3673.702493832237
INFO:root:current train perplexity4.257997035980225
INFO:root:current mean train loss 3678.8647715692937
INFO:root:current train perplexity4.25947904586792
INFO:root:current mean train loss 3681.077391854745
INFO:root:current train perplexity4.260454177856445
INFO:root:current mean train loss 3681.4354879662296
INFO:root:current train perplexity4.264509677886963
INFO:root:current mean train loss 3679.929515904018
INFO:root:current train perplexity4.264523506164551
INFO:root:current mean train loss 3678.093383163061
INFO:root:current train perplexity4.262489318847656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.15s/it]
INFO:root:final mean train loss: 3675.076786841116
INFO:root:final train perplexity: 4.262791156768799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3778.313374404366
INFO:root:eval perplexity: 4.608208179473877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 4696.731853945035
INFO:root:eval perplexity: 6.82476806640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/48
 24%|â–ˆâ–ˆâ–       | 48/200 [7:55:16<25:06:20, 594.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.576789580196
INFO:root:current train perplexity4.240221977233887
INFO:root:current mean train loss 3646.0288966444673
INFO:root:current train perplexity4.217464923858643
INFO:root:current mean train loss 3648.1905176816476
INFO:root:current train perplexity4.212026119232178
INFO:root:current mean train loss 3650.3341532973645
INFO:root:current train perplexity4.217952728271484
INFO:root:current mean train loss 3643.7845512058425
INFO:root:current train perplexity4.214808464050293
INFO:root:current mean train loss 3647.05626666689
INFO:root:current train perplexity4.216811180114746
INFO:root:current mean train loss 3648.9496426896503
INFO:root:current train perplexity4.218320846557617
INFO:root:current mean train loss 3651.8122639662156
INFO:root:current train perplexity4.223703861236572
INFO:root:current mean train loss 3651.2399551201515
INFO:root:current train perplexity4.221594333648682
INFO:root:current mean train loss 3652.8508896851954
INFO:root:current train perplexity4.220954895019531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.16s/it]
INFO:root:final mean train loss: 3649.911466475456
INFO:root:final train perplexity: 4.220677375793457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 3778.0501111619014
INFO:root:eval perplexity: 4.607717037200928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 4704.916524684176
INFO:root:eval perplexity: 6.847646713256836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:05:12<24:57:33, 595.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.59281368046
INFO:root:current train perplexity4.148867607116699
INFO:root:current mean train loss 3625.953482902487
INFO:root:current train perplexity4.159931659698486
INFO:root:current mean train loss 3631.446032337307
INFO:root:current train perplexity4.168633937835693
INFO:root:current mean train loss 3640.6834239130435
INFO:root:current train perplexity4.184511184692383
INFO:root:current mean train loss 3643.691583761615
INFO:root:current train perplexity4.190476894378662
INFO:root:current mean train loss 3638.4986822189617
INFO:root:current train perplexity4.1866021156311035
INFO:root:current mean train loss 3633.5484415984533
INFO:root:current train perplexity4.185609817504883
INFO:root:current mean train loss 3635.8672455258375
INFO:root:current train perplexity4.191030502319336
INFO:root:current mean train loss 3637.2761635999755
INFO:root:current train perplexity4.194399356842041
INFO:root:current mean train loss 3635.5479722778446
INFO:root:current train perplexity4.19210147857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.74s/it]
INFO:root:final mean train loss: 3632.7086361915835
INFO:root:final train perplexity: 4.192129135131836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3749.859449454233
INFO:root:eval perplexity: 4.555490016937256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4677.477206615691
INFO:root:eval perplexity: 6.771242141723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:15:08<24:48:26, 595.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.218535452178
INFO:root:current train perplexity4.154819011688232
INFO:root:current mean train loss 3610.109859600738
INFO:root:current train perplexity4.151004314422607
INFO:root:current mean train loss 3610.2554837740386
INFO:root:current train perplexity4.1552886962890625
INFO:root:current mean train loss 3616.4795270647323
INFO:root:current train perplexity4.1538262367248535
INFO:root:current mean train loss 3611.8356669393474
INFO:root:current train perplexity4.1546759605407715
INFO:root:current mean train loss 3612.9551510818815
INFO:root:current train perplexity4.158422946929932
INFO:root:current mean train loss 3616.692547668544
INFO:root:current train perplexity4.164877891540527
INFO:root:current mean train loss 3614.6868219674006
INFO:root:current train perplexity4.1620707511901855
INFO:root:current mean train loss 3615.1915952620966
INFO:root:current train perplexity4.161001682281494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it]
INFO:root:final mean train loss: 3615.3232378805837
INFO:root:final train perplexity: 4.163473606109619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 3745.1119047124334
INFO:root:eval perplexity: 4.5467529296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 4674.929890084774
INFO:root:eval perplexity: 6.764194011688232
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [8:25:01<24:36:33, 594.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.376953125
INFO:root:current train perplexity4.1706624031066895
INFO:root:current mean train loss 3575.730356947284
INFO:root:current train perplexity4.084897518157959
INFO:root:current mean train loss 3577.918656353789
INFO:root:current train perplexity4.09719705581665
INFO:root:current mean train loss 3588.8121262342224
INFO:root:current train perplexity4.112098693847656
INFO:root:current mean train loss 3590.669450989519
INFO:root:current train perplexity4.116436958312988
INFO:root:current mean train loss 3599.8327530780016
INFO:root:current train perplexity4.1221137046813965
INFO:root:current mean train loss 3604.9139655677254
INFO:root:current train perplexity4.133148193359375
INFO:root:current mean train loss 3602.9970955207964
INFO:root:current train perplexity4.131258010864258
INFO:root:current mean train loss 3601.554165940598
INFO:root:current train perplexity4.130890846252441
INFO:root:current mean train loss 3601.394801769656
INFO:root:current train perplexity4.129968166351318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.65s/it]
INFO:root:final mean train loss: 3593.5279227841284
INFO:root:final train perplexity: 4.1278252601623535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.90s/it]
INFO:root:eval mean loss: 3745.4533726036125
INFO:root:eval perplexity: 4.547379970550537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 4674.967160488697
INFO:root:eval perplexity: 6.764296531677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [8:34:56<24:27:03, 594.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.8244140625
INFO:root:current train perplexity4.091632843017578
INFO:root:current mean train loss 3543.531893257473
INFO:root:current train perplexity4.074026107788086
INFO:root:current mean train loss 3557.3793752271076
INFO:root:current train perplexity4.080378532409668
INFO:root:current mean train loss 3562.900010075645
INFO:root:current train perplexity4.079269886016846
INFO:root:current mean train loss 3569.623785768072
INFO:root:current train perplexity4.083375930786133
INFO:root:current mean train loss 3577.744295168386
INFO:root:current train perplexity4.0949554443359375
INFO:root:current mean train loss 3580.1875067486026
INFO:root:current train perplexity4.096939563751221
INFO:root:current mean train loss 3579.786596850415
INFO:root:current train perplexity4.098524570465088
INFO:root:current mean train loss 3579.6628813386696
INFO:root:current train perplexity4.0988688468933105
INFO:root:current mean train loss 3581.310530065318
INFO:root:current train perplexity4.100120544433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.53s/it]
INFO:root:final mean train loss: 3577.3981922518824
INFO:root:final train perplexity: 4.101640701293945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it]
INFO:root:eval mean loss: 3847.638377521055
INFO:root:eval perplexity: 4.739217281341553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 4777.39392869016
INFO:root:eval perplexity: 7.053627967834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [8:44:48<24:14:42, 593.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.7995923913045
INFO:root:current train perplexity4.02543306350708
INFO:root:current mean train loss 3528.067277613694
INFO:root:current train perplexity4.038849830627441
INFO:root:current mean train loss 3539.0620730276064
INFO:root:current train perplexity4.052161693572998
INFO:root:current mean train loss 3547.0455378954625
INFO:root:current train perplexity4.055270195007324
INFO:root:current mean train loss 3549.621286522976
INFO:root:current train perplexity4.0559186935424805
INFO:root:current mean train loss 3551.447936428209
INFO:root:current train perplexity4.061749458312988
INFO:root:current mean train loss 3558.6963059132977
INFO:root:current train perplexity4.068028926849365
INFO:root:current mean train loss 3558.919838131051
INFO:root:current train perplexity4.069830894470215
INFO:root:current mean train loss 3561.901431559937
INFO:root:current train perplexity4.072816371917725
INFO:root:current mean train loss 3564.373581180593
INFO:root:current train perplexity4.0739521980285645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.86s/it]
INFO:root:final mean train loss: 3560.9389978839504
INFO:root:final train perplexity: 4.075092315673828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3717.868659269725
INFO:root:eval perplexity: 4.496939182281494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 4650.488902856272
INFO:root:eval perplexity: 6.696926116943359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:54:39<24:03:12, 593.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3598.3585559475805
INFO:root:current train perplexity4.129859924316406
INFO:root:current mean train loss 3582.2733536348996
INFO:root:current train perplexity4.0893073081970215
INFO:root:current mean train loss 3559.1615006087663
INFO:root:current train perplexity4.064716815948486
INFO:root:current mean train loss 3564.248335270723
INFO:root:current train perplexity4.065689563751221
INFO:root:current mean train loss 3564.039585901247
INFO:root:current train perplexity4.065809726715088
INFO:root:current mean train loss 3554.844451157162
INFO:root:current train perplexity4.055414199829102
INFO:root:current mean train loss 3555.7733299388374
INFO:root:current train perplexity4.058780670166016
INFO:root:current mean train loss 3553.77888307167
INFO:root:current train perplexity4.056449890136719
INFO:root:current mean train loss 3546.4365440028955
INFO:root:current train perplexity4.0502028465271
INFO:root:current mean train loss 3548.8604100408666
INFO:root:current train perplexity4.05295991897583

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.75s/it]
INFO:root:final mean train loss: 3548.236328125
INFO:root:final train perplexity: 4.054720878601074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 3715.572888962766
INFO:root:eval perplexity: 4.492765426635742
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 4652.040568899601
INFO:root:eval perplexity: 6.701178550720215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:04:30<23:51:55, 592.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.1586225460737
INFO:root:current train perplexity4.004652976989746
INFO:root:current mean train loss 3529.2094146948066
INFO:root:current train perplexity4.010348320007324
INFO:root:current mean train loss 3523.869410303347
INFO:root:current train perplexity4.011838912963867
INFO:root:current mean train loss 3518.845472667773
INFO:root:current train perplexity4.009088039398193
INFO:root:current mean train loss 3526.5008291883187
INFO:root:current train perplexity4.018308162689209
INFO:root:current mean train loss 3532.042778963503
INFO:root:current train perplexity4.025813102722168
INFO:root:current mean train loss 3532.2739242529833
INFO:root:current train perplexity4.025149345397949
INFO:root:current mean train loss 3535.737654214944
INFO:root:current train perplexity4.030395030975342
INFO:root:current mean train loss 3533.5544675115466
INFO:root:current train perplexity4.028632164001465
INFO:root:current mean train loss 3532.137598332252
INFO:root:current train perplexity4.027276039123535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.43s/it]
INFO:root:final mean train loss: 3531.277713591053
INFO:root:final train perplexity: 4.027682781219482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.55s/it]
INFO:root:eval mean loss: 3703.175462655142
INFO:root:eval perplexity: 4.470299243927002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 4639.557752244016
INFO:root:eval perplexity: 6.667059421539307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:14:29<23:46:48, 594.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.081745553524
INFO:root:current train perplexity3.9903275966644287
INFO:root:current mean train loss 3513.4945242745534
INFO:root:current train perplexity3.9921936988830566
INFO:root:current mean train loss 3514.469048503922
INFO:root:current train perplexity3.991643190383911
INFO:root:current mean train loss 3510.497883645533
INFO:root:current train perplexity3.98547625541687
INFO:root:current mean train loss 3511.83229068355
INFO:root:current train perplexity3.987436056137085
INFO:root:current mean train loss 3511.98450577368
INFO:root:current train perplexity3.987679958343506
INFO:root:current mean train loss 3511.7106741149055
INFO:root:current train perplexity3.9886507987976074
INFO:root:current mean train loss 3514.900549790307
INFO:root:current train perplexity3.990880012512207
INFO:root:current mean train loss 3517.0668570598436
INFO:root:current train perplexity3.994673013687134
INFO:root:current mean train loss 3514.5146621011254
INFO:root:current train perplexity3.995346784591675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.08s/it]
INFO:root:final mean train loss: 3511.4960408364573
INFO:root:final train perplexity: 3.996371030807495
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3727.9821656139184
INFO:root:eval perplexity: 4.51536750793457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4665.045261247784
INFO:root:eval perplexity: 6.73690938949585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [9:24:26<23:38:25, 595.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3521.3489302201706
INFO:root:current train perplexity3.970710277557373
INFO:root:current mean train loss 3501.9436617943547
INFO:root:current train perplexity3.9794578552246094
INFO:root:current mean train loss 3500.8809991574753
INFO:root:current train perplexity3.976903200149536
INFO:root:current mean train loss 3495.661506244498
INFO:root:current train perplexity3.965670108795166
INFO:root:current mean train loss 3491.6883155906594
INFO:root:current train perplexity3.9657838344573975
INFO:root:current mean train loss 3499.8786027238175
INFO:root:current train perplexity3.9768428802490234
INFO:root:current mean train loss 3499.699915389432
INFO:root:current train perplexity3.975630521774292
INFO:root:current mean train loss 3497.587438237272
INFO:root:current train perplexity3.97521710395813
INFO:root:current mean train loss 3500.9568544978983
INFO:root:current train perplexity3.975468873977661
INFO:root:current mean train loss 3501.426924492801
INFO:root:current train perplexity3.9769809246063232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.36s/it]
INFO:root:final mean train loss: 3499.827647916732
INFO:root:final train perplexity: 3.9780163764953613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.94s/it]
INFO:root:eval mean loss: 3687.8382975260415
INFO:root:eval perplexity: 4.442660808563232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.52s/it]
INFO:root:eval mean loss: 4628.156804078014
INFO:root:eval perplexity: 6.636050224304199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [9:34:21<23:28:37, 595.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.5037899925596
INFO:root:current train perplexity3.9361488819122314
INFO:root:current mean train loss 3470.674943982458
INFO:root:current train perplexity3.94712233543396
INFO:root:current mean train loss 3475.054010775606
INFO:root:current train perplexity3.9471683502197266
INFO:root:current mean train loss 3479.4972969664686
INFO:root:current train perplexity3.9483261108398438
INFO:root:current mean train loss 3477.744107405001
INFO:root:current train perplexity3.942919969558716
INFO:root:current mean train loss 3476.253247547319
INFO:root:current train perplexity3.9423117637634277
INFO:root:current mean train loss 3480.8590940357512
INFO:root:current train perplexity3.944664478302002
INFO:root:current mean train loss 3480.2055593668088
INFO:root:current train perplexity3.9429728984832764
INFO:root:current mean train loss 3486.1119932172473
INFO:root:current train perplexity3.9529645442962646
INFO:root:current mean train loss 3484.9182113694997
INFO:root:current train perplexity3.9511263370513916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.68s/it]
INFO:root:final mean train loss: 3482.1464443206787
INFO:root:final train perplexity: 3.9503633975982666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3697.875446725399
INFO:root:eval perplexity: 4.460729598999023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4635.874541154145
INFO:root:eval perplexity: 6.6570258140563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [9:44:18<23:19:22, 595.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3448.6966948173417
INFO:root:current train perplexity3.9059135913848877
INFO:root:current mean train loss 3445.9427040501646
INFO:root:current train perplexity3.8925857543945312
INFO:root:current mean train loss 3448.688656740083
INFO:root:current train perplexity3.9000372886657715
INFO:root:current mean train loss 3458.080763824545
INFO:root:current train perplexity3.9099931716918945
INFO:root:current mean train loss 3463.868855535098
INFO:root:current train perplexity3.91878080368042
INFO:root:current mean train loss 3472.512074057985
INFO:root:current train perplexity3.9270894527435303
INFO:root:current mean train loss 3469.2914635193506
INFO:root:current train perplexity3.9266836643218994
INFO:root:current mean train loss 3471.016041084022
INFO:root:current train perplexity3.9311411380767822
INFO:root:current mean train loss 3468.391722651765
INFO:root:current train perplexity3.9262516498565674
INFO:root:current mean train loss 3468.1014040977407
INFO:root:current train perplexity3.9251415729522705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.32s/it]
INFO:root:final mean train loss: 3465.8690288297594
INFO:root:final train perplexity: 3.9250757694244385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 3685.03315291168
INFO:root:eval perplexity: 4.437624454498291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 4627.9222039838205
INFO:root:eval perplexity: 6.635413646697998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [9:54:09<23:06:22, 594.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.1379827185524
INFO:root:current train perplexity3.9164652824401855
INFO:root:current mean train loss 3456.3425783977827
INFO:root:current train perplexity3.9044923782348633
INFO:root:current mean train loss 3457.153058670755
INFO:root:current train perplexity3.9088234901428223
INFO:root:current mean train loss 3459.0436502824045
INFO:root:current train perplexity3.917388439178467
INFO:root:current mean train loss 3457.137694802812
INFO:root:current train perplexity3.913896083831787
INFO:root:current mean train loss 3455.66042189524
INFO:root:current train perplexity3.910555839538574
INFO:root:current mean train loss 3456.6752972834593
INFO:root:current train perplexity3.9104514122009277
INFO:root:current mean train loss 3457.145874806944
INFO:root:current train perplexity3.9098963737487793
INFO:root:current mean train loss 3457.543967254604
INFO:root:current train perplexity3.9093291759490967
INFO:root:current mean train loss 3457.06427781258
INFO:root:current train perplexity3.907823085784912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.54s/it]
INFO:root:final mean train loss: 3454.5758943250103
INFO:root:final train perplexity: 3.907626152038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3678.3848868295654
INFO:root:eval perplexity: 4.425711154937744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 4619.096376676086
INFO:root:eval perplexity: 6.611509799957275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:04:01<22:55:03, 593.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3429.2165387033046
INFO:root:current train perplexity3.884161949157715
INFO:root:current mean train loss 3445.214745832637
INFO:root:current train perplexity3.8932204246520996
INFO:root:current mean train loss 3443.619058961237
INFO:root:current train perplexity3.89311146736145
INFO:root:current mean train loss 3446.1650226602874
INFO:root:current train perplexity3.8939614295959473
INFO:root:current mean train loss 3442.234956525924
INFO:root:current train perplexity3.8881099224090576
INFO:root:current mean train loss 3438.2244317803716
INFO:root:current train perplexity3.880706548690796
INFO:root:current mean train loss 3441.6546813876002
INFO:root:current train perplexity3.8887457847595215
INFO:root:current mean train loss 3442.147004918798
INFO:root:current train perplexity3.8894097805023193
INFO:root:current mean train loss 3442.7938831075608
INFO:root:current train perplexity3.888744831085205
INFO:root:current mean train loss 3444.4327759902167
INFO:root:current train perplexity3.8872482776641846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.69s/it]
INFO:root:final mean train loss: 3440.5791844398746
INFO:root:final train perplexity: 3.886108160018921
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3673.541645888741
INFO:root:eval perplexity: 4.417051792144775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 4619.578748337766
INFO:root:eval perplexity: 6.612813472747803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:13:51<22:42:49, 592.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3450.302790912829
INFO:root:current train perplexity3.8949363231658936
INFO:root:current mean train loss 3445.9490559895835
INFO:root:current train perplexity3.8820502758026123
INFO:root:current mean train loss 3438.870185050318
INFO:root:current train perplexity3.87180757522583
INFO:root:current mean train loss 3429.567393319818
INFO:root:current train perplexity3.856797933578491
INFO:root:current mean train loss 3428.367257043087
INFO:root:current train perplexity3.855417490005493
INFO:root:current mean train loss 3426.6589827337184
INFO:root:current train perplexity3.856553792953491
INFO:root:current mean train loss 3427.32980658442
INFO:root:current train perplexity3.8610424995422363
INFO:root:current mean train loss 3426.428716158117
INFO:root:current train perplexity3.8624603748321533
INFO:root:current mean train loss 3428.3743976955307
INFO:root:current train perplexity3.8637924194335938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.57s/it]
INFO:root:final mean train loss: 3424.9311866760254
INFO:root:final train perplexity: 3.8621907234191895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3667.256718195922
INFO:root:eval perplexity: 4.405839920043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 4616.267207585328
INFO:root:eval perplexity: 6.603865146636963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [10:23:43<22:32:53, 592.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.285888671875
INFO:root:current train perplexity3.676935911178589
INFO:root:current mean train loss 3418.878887287621
INFO:root:current train perplexity3.831939458847046
INFO:root:current mean train loss 3414.250882754772
INFO:root:current train perplexity3.840078592300415
INFO:root:current mean train loss 3417.0247460292903
INFO:root:current train perplexity3.845421314239502
INFO:root:current mean train loss 3415.8659383238987
INFO:root:current train perplexity3.847424268722534
INFO:root:current mean train loss 3412.528094130529
INFO:root:current train perplexity3.8428146839141846
INFO:root:current mean train loss 3410.1765476815144
INFO:root:current train perplexity3.8434245586395264
INFO:root:current mean train loss 3413.235206745088
INFO:root:current train perplexity3.845964193344116
INFO:root:current mean train loss 3414.8246434877997
INFO:root:current train perplexity3.847658157348633
INFO:root:current mean train loss 3416.858711521491
INFO:root:current train perplexity3.8464927673339844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.79s/it]
INFO:root:final mean train loss: 3416.3509628542006
INFO:root:final train perplexity: 3.8491384983062744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3672.6065163037456
INFO:root:eval perplexity: 4.415382385253906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 4620.866825617797
INFO:root:eval perplexity: 6.616296768188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [10:33:34<22:21:56, 592.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3427.219637784091
INFO:root:current train perplexity3.838979721069336
INFO:root:current mean train loss 3412.433059279983
INFO:root:current train perplexity3.838367462158203
INFO:root:current mean train loss 3404.914173578199
INFO:root:current train perplexity3.826794147491455
INFO:root:current mean train loss 3404.5852647394995
INFO:root:current train perplexity3.832317590713501
INFO:root:current mean train loss 3399.078878212439
INFO:root:current train perplexity3.8225977420806885
INFO:root:current mean train loss 3399.69485527382
INFO:root:current train perplexity3.826033353805542
INFO:root:current mean train loss 3403.448212219338
INFO:root:current train perplexity3.8322672843933105
INFO:root:current mean train loss 3401.0265230803884
INFO:root:current train perplexity3.8296797275543213
INFO:root:current mean train loss 3404.14786252023
INFO:root:current train perplexity3.8306541442871094
INFO:root:current mean train loss 3403.151195940673
INFO:root:current train perplexity3.8297905921936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.79s/it]
INFO:root:final mean train loss: 3403.5511170048867
INFO:root:final train perplexity: 3.8297500610351562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 3694.35683316711
INFO:root:eval perplexity: 4.454386234283447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 4645.699959829344
INFO:root:eval perplexity: 6.683826923370361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [10:43:20<22:07:40, 590.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.4209112870067
INFO:root:current train perplexity3.7908248901367188
INFO:root:current mean train loss 3348.7300050879726
INFO:root:current train perplexity3.777191162109375
INFO:root:current mean train loss 3364.924500347817
INFO:root:current train perplexity3.783677577972412
INFO:root:current mean train loss 3383.1147705843455
INFO:root:current train perplexity3.803858518600464
INFO:root:current mean train loss 3391.364602173143
INFO:root:current train perplexity3.8105597496032715
INFO:root:current mean train loss 3391.5479677527396
INFO:root:current train perplexity3.810450553894043
INFO:root:current mean train loss 3394.2636785799928
INFO:root:current train perplexity3.810276746749878
INFO:root:current mean train loss 3396.4425047130344
INFO:root:current train perplexity3.8124680519104004
INFO:root:current mean train loss 3393.0074601505266
INFO:root:current train perplexity3.8081696033477783
INFO:root:current mean train loss 3390.3232041982624
INFO:root:current train perplexity3.8068385124206543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.22s/it]
INFO:root:final mean train loss: 3388.455333094443
INFO:root:final train perplexity: 3.8070080280303955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3672.393850772939
INFO:root:eval perplexity: 4.41500186920166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4623.0366695755765
INFO:root:eval perplexity: 6.622169494628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [10:53:12<21:58:56, 590.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.3087293836807
INFO:root:current train perplexity3.8546371459960938
INFO:root:current mean train loss 3428.0599643977607
INFO:root:current train perplexity3.8484346866607666
INFO:root:current mean train loss 3391.480894651707
INFO:root:current train perplexity3.8092143535614014
INFO:root:current mean train loss 3382.969156154434
INFO:root:current train perplexity3.8004209995269775
INFO:root:current mean train loss 3381.036346078198
INFO:root:current train perplexity3.7942514419555664
INFO:root:current mean train loss 3379.175031224057
INFO:root:current train perplexity3.7954561710357666
INFO:root:current mean train loss 3377.586667196222
INFO:root:current train perplexity3.7941339015960693
INFO:root:current mean train loss 3381.8030513884114
INFO:root:current train perplexity3.7968037128448486
INFO:root:current mean train loss 3384.702780782384
INFO:root:current train perplexity3.797456979751587
INFO:root:current mean train loss 3385.3382690824737
INFO:root:current train perplexity3.7990856170654297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.20s/it]
INFO:root:final mean train loss: 3382.175243808377
INFO:root:final train perplexity: 3.7975873947143555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 3655.50649829621
INFO:root:eval perplexity: 4.384955883026123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 4605.698777219082
INFO:root:eval perplexity: 6.575387001037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:03:02<21:49:10, 590.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3337.926297433036
INFO:root:current train perplexity3.724317789077759
INFO:root:current mean train loss 3345.6450321903935
INFO:root:current train perplexity3.7396607398986816
INFO:root:current mean train loss 3349.3678731715427
INFO:root:current train perplexity3.7471718788146973
INFO:root:current mean train loss 3356.1102087220147
INFO:root:current train perplexity3.7594265937805176
INFO:root:current mean train loss 3364.851520406789
INFO:root:current train perplexity3.770366668701172
INFO:root:current mean train loss 3358.9927049868575
INFO:root:current train perplexity3.762657880783081
INFO:root:current mean train loss 3362.77907464936
INFO:root:current train perplexity3.766695976257324
INFO:root:current mean train loss 3368.035233312075
INFO:root:current train perplexity3.7728374004364014
INFO:root:current mean train loss 3369.1778662401757
INFO:root:current train perplexity3.772770881652832
INFO:root:current mean train loss 3367.560953950117
INFO:root:current train perplexity3.7728846073150635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.42s/it]
INFO:root:final mean train loss: 3366.9354123761577
INFO:root:final train perplexity: 3.7748231887817383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 3649.9123154227614
INFO:root:eval perplexity: 4.375047206878662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4600.52839303524
INFO:root:eval perplexity: 6.561500072479248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [11:12:50<21:37:12, 589.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.797493868096
INFO:root:current train perplexity3.75390887260437
INFO:root:current mean train loss 3344.8116019722465
INFO:root:current train perplexity3.729382038116455
INFO:root:current mean train loss 3354.341465326003
INFO:root:current train perplexity3.7362585067749023
INFO:root:current mean train loss 3348.2883144189595
INFO:root:current train perplexity3.738469123840332
INFO:root:current mean train loss 3359.3916015625
INFO:root:current train perplexity3.7514774799346924
INFO:root:current mean train loss 3357.3236985461267
INFO:root:current train perplexity3.749070405960083
INFO:root:current mean train loss 3358.116136138584
INFO:root:current train perplexity3.754225254058838
INFO:root:current mean train loss 3357.3608158568513
INFO:root:current train perplexity3.7539281845092773
INFO:root:current mean train loss 3357.607315298784
INFO:root:current train perplexity3.753955364227295
INFO:root:current mean train loss 3357.72652366533
INFO:root:current train perplexity3.7572786808013916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.66s/it]
INFO:root:final mean train loss: 3356.113009360529
INFO:root:final train perplexity: 3.758739709854126
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3645.1829150044327
INFO:root:eval perplexity: 4.366689205169678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 4599.448146955341
INFO:root:eval perplexity: 6.558603763580322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [11:22:40<21:27:51, 589.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.9538286994484
INFO:root:current train perplexity3.7788562774658203
INFO:root:current mean train loss 3370.465369218233
INFO:root:current train perplexity3.7601218223571777
INFO:root:current mean train loss 3344.6586417999874
INFO:root:current train perplexity3.73431134223938
INFO:root:current mean train loss 3342.513798466435
INFO:root:current train perplexity3.733396530151367
INFO:root:current mean train loss 3343.4518718169693
INFO:root:current train perplexity3.7355053424835205
INFO:root:current mean train loss 3340.054982595565
INFO:root:current train perplexity3.7348759174346924
INFO:root:current mean train loss 3343.7378679735502
INFO:root:current train perplexity3.741342067718506
INFO:root:current mean train loss 3344.5223842168775
INFO:root:current train perplexity3.743978500366211
INFO:root:current mean train loss 3345.093257128562
INFO:root:current train perplexity3.740438222885132
INFO:root:current mean train loss 3348.8312993415648
INFO:root:current train perplexity3.744298219680786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.58s/it]
INFO:root:final mean train loss: 3347.0688140623033
INFO:root:final train perplexity: 3.745351552963257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3657.843930075355
INFO:root:eval perplexity: 4.389101982116699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4611.250948858599
INFO:root:eval perplexity: 6.590332508087158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [11:32:29<21:17:29, 589.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.364973682468
INFO:root:current train perplexity3.698596239089966
INFO:root:current mean train loss 3331.75125755454
INFO:root:current train perplexity3.7187631130218506
INFO:root:current mean train loss 3324.4127201978763
INFO:root:current train perplexity3.717142105102539
INFO:root:current mean train loss 3331.53240269738
INFO:root:current train perplexity3.722233533859253
INFO:root:current mean train loss 3333.8495359732433
INFO:root:current train perplexity3.723254680633545
INFO:root:current mean train loss 3331.8959537294554
INFO:root:current train perplexity3.7227559089660645
INFO:root:current mean train loss 3329.043691169148
INFO:root:current train perplexity3.7196316719055176
INFO:root:current mean train loss 3334.740042665102
INFO:root:current train perplexity3.72436261177063
INFO:root:current mean train loss 3335.024288723716
INFO:root:current train perplexity3.726182460784912
INFO:root:current mean train loss 3337.7397883537537
INFO:root:current train perplexity3.728302478790283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.24s/it]
INFO:root:final mean train loss: 3335.2441172445974
INFO:root:final train perplexity: 3.7279202938079834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3627.169222351507
INFO:root:eval perplexity: 4.334996700286865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 4585.030361743684
INFO:root:eval perplexity: 6.52004861831665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [11:42:19<21:07:44, 589.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3290.967379897388
INFO:root:current train perplexity3.668858289718628
INFO:root:current mean train loss 3320.8713744386228
INFO:root:current train perplexity3.6897943019866943
INFO:root:current mean train loss 3320.3796624458682
INFO:root:current train perplexity3.6958446502685547
INFO:root:current mean train loss 3317.8189148448146
INFO:root:current train perplexity3.6986184120178223
INFO:root:current mean train loss 3316.3515943898888
INFO:root:current train perplexity3.7028160095214844
INFO:root:current mean train loss 3326.4878213872353
INFO:root:current train perplexity3.711759090423584
INFO:root:current mean train loss 3329.280479511221
INFO:root:current train perplexity3.71673846244812
INFO:root:current mean train loss 3329.074021718648
INFO:root:current train perplexity3.7164249420166016
INFO:root:current mean train loss 3330.908285068393
INFO:root:current train perplexity3.7158143520355225
INFO:root:current mean train loss 3333.0383108902374
INFO:root:current train perplexity3.719395160675049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.22s/it]
INFO:root:final mean train loss: 3329.865753173828
INFO:root:final train perplexity: 3.720017433166504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3617.5098366162456
INFO:root:eval perplexity: 4.318097114562988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 4572.977426515404
INFO:root:eval perplexity: 6.487993240356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [11:52:05<20:55:33, 588.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.4530696614584
INFO:root:current train perplexity3.698498010635376
INFO:root:current mean train loss 3309.635475725446
INFO:root:current train perplexity3.67693829536438
INFO:root:current mean train loss 3310.4463245738634
INFO:root:current train perplexity3.675896406173706
INFO:root:current mean train loss 3308.1501979166665
INFO:root:current train perplexity3.6828365325927734
INFO:root:current mean train loss 3310.147458881579
INFO:root:current train perplexity3.688612222671509
INFO:root:current mean train loss 3309.660605044158
INFO:root:current train perplexity3.690058708190918
INFO:root:current mean train loss 3309.2142060908564
INFO:root:current train perplexity3.6889231204986572
INFO:root:current mean train loss 3314.860228704637
INFO:root:current train perplexity3.6949830055236816
INFO:root:current mean train loss 3314.4975044642856
INFO:root:current train perplexity3.696183443069458
INFO:root:current mean train loss 3316.7945294971955
INFO:root:current train perplexity3.6981356143951416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.14s/it]
INFO:root:final mean train loss: 3315.256262440835
INFO:root:final train perplexity: 3.6986382007598877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3633.5135922262853
INFO:root:eval perplexity: 4.346131801605225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 4588.147535391733
INFO:root:eval perplexity: 6.528364658355713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:01:55<20:47:07, 589.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3318.4196953830947
INFO:root:current train perplexity3.6866085529327393
INFO:root:current mean train loss 3327.5089158021688
INFO:root:current train perplexity3.6995792388916016
INFO:root:current mean train loss 3320.3502952117383
INFO:root:current train perplexity3.692263126373291
INFO:root:current mean train loss 3316.315014712182
INFO:root:current train perplexity3.690718173980713
INFO:root:current mean train loss 3317.823170411167
INFO:root:current train perplexity3.691396713256836
INFO:root:current mean train loss 3313.5840321143332
INFO:root:current train perplexity3.6888840198516846
INFO:root:current mean train loss 3314.243420356538
INFO:root:current train perplexity3.6907191276550293
INFO:root:current mean train loss 3312.865363149046
INFO:root:current train perplexity3.6894266605377197
INFO:root:current mean train loss 3312.4368720913258
INFO:root:current train perplexity3.6888961791992188
INFO:root:current mean train loss 3317.4744869321435
INFO:root:current train perplexity3.697518825531006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.81s/it]
INFO:root:final mean train loss: 3314.6466698800364
INFO:root:final train perplexity: 3.6977484226226807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 3623.22750270113
INFO:root:eval perplexity: 4.328091621398926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 4584.816395861038
INFO:root:eval perplexity: 6.519479274749756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [12:11:49<20:39:50, 590.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3290.582734160371
INFO:root:current train perplexity3.660538911819458
INFO:root:current mean train loss 3279.2861059698134
INFO:root:current train perplexity3.6458537578582764
INFO:root:current mean train loss 3283.981689453125
INFO:root:current train perplexity3.6596968173980713
INFO:root:current mean train loss 3293.3679873571373
INFO:root:current train perplexity3.6671969890594482
INFO:root:current mean train loss 3295.5552483770366
INFO:root:current train perplexity3.669675350189209
INFO:root:current mean train loss 3292.5262841549015
INFO:root:current train perplexity3.666294813156128
INFO:root:current mean train loss 3295.0999418443607
INFO:root:current train perplexity3.665788412094116
INFO:root:current mean train loss 3297.5694578534885
INFO:root:current train perplexity3.6705031394958496
INFO:root:current mean train loss 3300.2314551767677
INFO:root:current train perplexity3.672816276550293
INFO:root:current mean train loss 3301.090353957098
INFO:root:current train perplexity3.674375295639038

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.31s/it]
INFO:root:final mean train loss: 3298.5489179549677
INFO:root:final train perplexity: 3.6743381023406982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 3626.308491591866
INFO:root:eval perplexity: 4.333487510681152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 4590.877780779034
INFO:root:eval perplexity: 6.535658359527588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [12:21:36<20:28:02, 589.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.1465361624055
INFO:root:current train perplexity3.6368329524993896
INFO:root:current mean train loss 3273.738304559909
INFO:root:current train perplexity3.6442699432373047
INFO:root:current mean train loss 3280.8789756545257
INFO:root:current train perplexity3.64582896232605
INFO:root:current mean train loss 3288.1845874451756
INFO:root:current train perplexity3.6520018577575684
INFO:root:current mean train loss 3290.474520329722
INFO:root:current train perplexity3.654735565185547
INFO:root:current mean train loss 3289.9570426622495
INFO:root:current train perplexity3.6568455696105957
INFO:root:current mean train loss 3291.8699229926683
INFO:root:current train perplexity3.6601173877716064
INFO:root:current mean train loss 3292.8228645181475
INFO:root:current train perplexity3.661221981048584
INFO:root:current mean train loss 3292.848458193566
INFO:root:current train perplexity3.6606595516204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.15s/it]
INFO:root:final mean train loss: 3290.1846146737375
INFO:root:final train perplexity: 3.6622323989868164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 3629.509059175532
INFO:root:eval perplexity: 4.339100360870361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4587.858088500111
INFO:root:eval perplexity: 6.527592658996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [12:31:24<20:17:39, 589.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.198904854911
INFO:root:current train perplexity3.675889015197754
INFO:root:current mean train loss 3274.398035922897
INFO:root:current train perplexity3.6698834896087646
INFO:root:current mean train loss 3259.0231379264796
INFO:root:current train perplexity3.6354100704193115
INFO:root:current mean train loss 3259.0413838240534
INFO:root:current train perplexity3.632093667984009
INFO:root:current mean train loss 3268.723197318412
INFO:root:current train perplexity3.6420493125915527
INFO:root:current mean train loss 3271.7061977047892
INFO:root:current train perplexity3.640085220336914
INFO:root:current mean train loss 3275.5840483261686
INFO:root:current train perplexity3.642399787902832
INFO:root:current mean train loss 3277.5457824102723
INFO:root:current train perplexity3.6426172256469727
INFO:root:current mean train loss 3280.6092624593402
INFO:root:current train perplexity3.646918296813965
INFO:root:current mean train loss 3282.0122899367766
INFO:root:current train perplexity3.6472878456115723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it]
INFO:root:final mean train loss: 3279.703959065099
INFO:root:final train perplexity: 3.647120475769043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 3623.2260499778367
INFO:root:eval perplexity: 4.328089714050293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4583.705604499113
INFO:root:eval perplexity: 6.5165181159973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [12:41:11<20:06:29, 588.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.962190755208
INFO:root:current train perplexity3.621718645095825
INFO:root:current mean train loss 3271.633795431386
INFO:root:current train perplexity3.641833543777466
INFO:root:current mean train loss 3270.6728856286336
INFO:root:current train perplexity3.639768362045288
INFO:root:current mean train loss 3261.103464471726
INFO:root:current train perplexity3.6275761127471924
INFO:root:current mean train loss 3269.0692682840736
INFO:root:current train perplexity3.6323914527893066
INFO:root:current mean train loss 3272.5307304308253
INFO:root:current train perplexity3.6359591484069824
INFO:root:current mean train loss 3274.501226657774
INFO:root:current train perplexity3.637087106704712
INFO:root:current mean train loss 3275.41357421875
INFO:root:current train perplexity3.6358909606933594
INFO:root:current mean train loss 3279.110920724693
INFO:root:current train perplexity3.6401946544647217
INFO:root:current mean train loss 3276.8892658171108
INFO:root:current train perplexity3.6394262313842773

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.78s/it]
INFO:root:final mean train loss: 3274.54853580844
INFO:root:final train perplexity: 3.639709949493408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 3611.951840231605
INFO:root:eval perplexity: 4.308403015136719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 4576.27554126496
INFO:root:eval perplexity: 6.496748924255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [12:50:55<19:53:52, 587.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.0510466202445
INFO:root:current train perplexity3.639460802078247
INFO:root:current mean train loss 3247.3250484311484
INFO:root:current train perplexity3.6147944927215576
INFO:root:current mean train loss 3254.9230376786713
INFO:root:current train perplexity3.621799945831299
INFO:root:current mean train loss 3245.956191496952
INFO:root:current train perplexity3.614938974380493
INFO:root:current mean train loss 3253.69754554983
INFO:root:current train perplexity3.6150996685028076
INFO:root:current mean train loss 3248.33842745429
INFO:root:current train perplexity3.6109678745269775
INFO:root:current mean train loss 3258.939343398876
INFO:root:current train perplexity3.6182384490966797
INFO:root:current mean train loss 3261.1923946312027
INFO:root:current train perplexity3.61881947517395
INFO:root:current mean train loss 3263.160235454796
INFO:root:current train perplexity3.620893716812134
INFO:root:current mean train loss 3265.455591005468
INFO:root:current train perplexity3.6223158836364746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.42s/it]
INFO:root:final mean train loss: 3262.7480113737047
INFO:root:final train perplexity: 3.622804641723633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 3602.66669090758
INFO:root:eval perplexity: 4.292256832122803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 4566.944869237589
INFO:root:eval perplexity: 6.472009181976318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:00:46<19:46:22, 588.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.4515105216733
INFO:root:current train perplexity3.5681395530700684
INFO:root:current mean train loss 3262.5869867455867
INFO:root:current train perplexity3.603569746017456
INFO:root:current mean train loss 3250.748762386702
INFO:root:current train perplexity3.600210666656494
INFO:root:current mean train loss 3255.892747769543
INFO:root:current train perplexity3.6045987606048584
INFO:root:current mean train loss 3255.4837813587587
INFO:root:current train perplexity3.6106503009796143
INFO:root:current mean train loss 3261.3988664702506
INFO:root:current train perplexity3.6171600818634033
INFO:root:current mean train loss 3254.817221083845
INFO:root:current train perplexity3.6114776134490967
INFO:root:current mean train loss 3254.904367011158
INFO:root:current train perplexity3.611126661300659
INFO:root:current mean train loss 3257.4243087676746
INFO:root:current train perplexity3.6127848625183105
INFO:root:current mean train loss 3258.9907218695457
INFO:root:current train perplexity3.613698959350586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.98s/it]
INFO:root:final mean train loss: 3256.049510525119
INFO:root:final train perplexity: 3.6132431030273438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 3611.5218670351287
INFO:root:eval perplexity: 4.307653427124023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 4579.282088042996
INFO:root:eval perplexity: 6.504741191864014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [13:10:36<19:37:35, 588.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.9481670673076
INFO:root:current train perplexity3.563488721847534
INFO:root:current mean train loss 3220.4203082846225
INFO:root:current train perplexity3.5584070682525635
INFO:root:current mean train loss 3228.052989752223
INFO:root:current train perplexity3.569657564163208
INFO:root:current mean train loss 3240.0919682775625
INFO:root:current train perplexity3.5791428089141846
INFO:root:current mean train loss 3234.8828369696753
INFO:root:current train perplexity3.580331325531006
INFO:root:current mean train loss 3239.7478063579833
INFO:root:current train perplexity3.5863864421844482
INFO:root:current mean train loss 3243.5067667834264
INFO:root:current train perplexity3.5897488594055176
INFO:root:current mean train loss 3244.81538442733
INFO:root:current train perplexity3.5906999111175537
INFO:root:current mean train loss 3248.528748067826
INFO:root:current train perplexity3.596633195877075
INFO:root:current mean train loss 3246.931216043913
INFO:root:current train perplexity3.5978338718414307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.11s/it]
INFO:root:final mean train loss: 3246.3284458037347
INFO:root:final train perplexity: 3.599412202835083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 3623.166323830895
INFO:root:eval perplexity: 4.327985763549805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 4593.054644212655
INFO:root:eval perplexity: 6.541477680206299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [13:20:25<19:27:50, 588.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.9308354803857
INFO:root:current train perplexity3.636859893798828
INFO:root:current mean train loss 3249.3220596832484
INFO:root:current train perplexity3.6039164066314697
INFO:root:current mean train loss 3239.5807334498354
INFO:root:current train perplexity3.5801303386688232
INFO:root:current mean train loss 3245.5925103003424
INFO:root:current train perplexity3.5860209465026855
INFO:root:current mean train loss 3241.5872171901215
INFO:root:current train perplexity3.5825541019439697
INFO:root:current mean train loss 3242.9141361438815
INFO:root:current train perplexity3.5847413539886475
INFO:root:current mean train loss 3244.7766086867273
INFO:root:current train perplexity3.588870048522949
INFO:root:current mean train loss 3238.432612285078
INFO:root:current train perplexity3.5843071937561035
INFO:root:current mean train loss 3237.803311434659
INFO:root:current train perplexity3.5845541954040527
INFO:root:current mean train loss 3238.2657881900905
INFO:root:current train perplexity3.5854177474975586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.01s/it]
INFO:root:final mean train loss: 3237.5612164774248
INFO:root:final train perplexity: 3.5869834423065186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3616.96499438996
INFO:root:eval perplexity: 4.317145347595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 4588.160137203568
INFO:root:eval perplexity: 6.528398513793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [13:30:15<19:18:19, 588.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.8181107954547
INFO:root:current train perplexity3.598919630050659
INFO:root:current mean train loss 3272.4563130040324
INFO:root:current train perplexity3.637204170227051
INFO:root:current mean train loss 3271.6964776731006
INFO:root:current train perplexity3.6270925998687744
INFO:root:current mean train loss 3269.894988583847
INFO:root:current train perplexity3.63142728805542
INFO:root:current mean train loss 3267.3630687671703
INFO:root:current train perplexity3.6258411407470703
INFO:root:current mean train loss 3267.743290311796
INFO:root:current train perplexity3.62485408782959
INFO:root:current mean train loss 3261.2650908724954
INFO:root:current train perplexity3.6177139282226562
INFO:root:current mean train loss 3256.5429228321605
INFO:root:current train perplexity3.610555410385132
INFO:root:current mean train loss 3256.604044453582
INFO:root:current train perplexity3.6109161376953125
INFO:root:current mean train loss 3256.865050310864
INFO:root:current train perplexity3.6108360290527344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.30s/it]
INFO:root:final mean train loss: 3254.1602441110917
INFO:root:final train perplexity: 3.610551118850708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 3619.965761441711
INFO:root:eval perplexity: 4.322387218475342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 4593.489519268063
INFO:root:eval perplexity: 6.542642116546631
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [13:40:03<19:08:07, 588.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.2153049045137
INFO:root:current train perplexity3.5760793685913086
INFO:root:current mean train loss 3246.5979108751917
INFO:root:current train perplexity3.593169689178467
INFO:root:current mean train loss 3246.411039983365
INFO:root:current train perplexity3.594467878341675
INFO:root:current mean train loss 3240.0747500753273
INFO:root:current train perplexity3.5960633754730225
INFO:root:current mean train loss 3239.2039939929805
INFO:root:current train perplexity3.595327377319336
INFO:root:current mean train loss 3243.852436289271
INFO:root:current train perplexity3.5955729484558105
INFO:root:current mean train loss 3242.5762337386877
INFO:root:current train perplexity3.595097780227661
INFO:root:current mean train loss 3244.1235018788907
INFO:root:current train perplexity3.5951778888702393
INFO:root:current mean train loss 3241.6041385655053
INFO:root:current train perplexity3.5932655334472656
INFO:root:current mean train loss 3245.021643839645
INFO:root:current train perplexity3.594871997833252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.96s/it]
INFO:root:final mean train loss: 3244.14179143598
INFO:root:final train perplexity: 3.5963082313537598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 3634.590119057513
INFO:root:eval perplexity: 4.348024368286133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 4609.15816676363
INFO:root:eval perplexity: 6.584695339202881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [13:49:53<18:59:14, 589.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.4565979863555
INFO:root:current train perplexity3.5717437267303467
INFO:root:current mean train loss 3228.6714952256943
INFO:root:current train perplexity3.572601795196533
INFO:root:current mean train loss 3223.361336232991
INFO:root:current train perplexity3.560192823410034
INFO:root:current mean train loss 3235.893557319744
INFO:root:current train perplexity3.572567939758301
INFO:root:current mean train loss 3229.4346900502587
INFO:root:current train perplexity3.566448211669922
INFO:root:current mean train loss 3232.604889824595
INFO:root:current train perplexity3.5686423778533936
INFO:root:current mean train loss 3231.756949821279
INFO:root:current train perplexity3.5690910816192627
INFO:root:current mean train loss 3230.250663707847
INFO:root:current train perplexity3.569822072982788
INFO:root:current mean train loss 3231.8297414856306
INFO:root:current train perplexity3.5746777057647705
INFO:root:current mean train loss 3234.999867495253
INFO:root:current train perplexity3.5794155597686768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.62s/it]
INFO:root:final mean train loss: 3232.5465815759476
INFO:root:final train perplexity: 3.5798938274383545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 3603.4030294215427
INFO:root:eval perplexity: 4.293535232543945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 4577.45118572695
INFO:root:eval perplexity: 6.499873161315918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [13:59:41<18:48:31, 588.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.3127039655856
INFO:root:current train perplexity3.535764217376709
INFO:root:current mean train loss 3230.217961657647
INFO:root:current train perplexity3.5758697986602783
INFO:root:current mean train loss 3242.252899935596
INFO:root:current train perplexity3.589543104171753
INFO:root:current mean train loss 3245.498392150396
INFO:root:current train perplexity3.587494373321533
INFO:root:current mean train loss 3246.0568404227556
INFO:root:current train perplexity3.586182117462158
INFO:root:current mean train loss 3238.5654802865934
INFO:root:current train perplexity3.5808610916137695
INFO:root:current mean train loss 3240.10480176788
INFO:root:current train perplexity3.582322120666504
INFO:root:current mean train loss 3703.1473430981227
INFO:root:current train perplexity4.2981858253479
INFO:root:current mean train loss 4158.101663600327
INFO:root:current train perplexity5.147705078125
INFO:root:current mean train loss 4811.424375758108
INFO:root:current train perplexity6.667160987854004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.04s/it]
INFO:root:final mean train loss: 4876.696056489021
INFO:root:final train perplexity: 6.84827995300293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 9510.90107975953
INFO:root:eval perplexity: 46.80215072631836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 10192.313691267731
INFO:root:eval perplexity: 64.57178497314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [14:09:31<18:39:25, 589.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15744.473913433909
INFO:root:current train perplexity502.96063232421875
INFO:root:current mean train loss 19250.152385528076
INFO:root:current train perplexity2011.818603515625
INFO:root:current mean train loss 19237.52922201655
INFO:root:current train perplexity2013.801513671875
INFO:root:current mean train loss 18767.42048459706
INFO:root:current train perplexity1655.475830078125
INFO:root:current mean train loss 18567.081168987424
INFO:root:current train perplexity1529.52880859375
INFO:root:current mean train loss 18225.268245248615
INFO:root:current train perplexity1326.938232421875
INFO:root:current mean train loss 17714.763164403656
INFO:root:current train perplexity1082.2271728515625
INFO:root:current mean train loss 17212.94855984951
INFO:root:current train perplexity883.7312622070312
INFO:root:current mean train loss 16791.177420597873
INFO:root:current train perplexity750.7926635742188
INFO:root:current mean train loss 16458.260814415527
INFO:root:current train perplexity657.0985107421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.89s/it]
INFO:root:final mean train loss: 16431.31407879245
INFO:root:final train perplexity: 653.6871337890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 12993.529795545213
INFO:root:eval perplexity: 191.36878967285156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 13212.303018339982
INFO:root:eval perplexity: 222.00320434570312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [14:19:19<18:29:06, 588.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13311.327210115132
INFO:root:current train perplexity186.42860412597656
INFO:root:current mean train loss 13259.520292467949
INFO:root:current train perplexity183.37619018554688
INFO:root:current mean train loss 13221.044587526483
INFO:root:current train perplexity181.60572814941406
INFO:root:current mean train loss 13213.088639734968
INFO:root:current train perplexity181.24835205078125
INFO:root:current mean train loss 13177.901154119318
INFO:root:current train perplexity180.123046875
INFO:root:current mean train loss 13154.008373818277
INFO:root:current train perplexity178.51426696777344
INFO:root:current mean train loss 13140.099567221223
INFO:root:current train perplexity177.5537109375
INFO:root:current mean train loss 13134.630974842767
INFO:root:current train perplexity177.105712890625
INFO:root:current mean train loss 13135.58791572102
INFO:root:current train perplexity176.88426208496094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.22s/it]
INFO:root:final mean train loss: 13113.558542313114
INFO:root:final train perplexity: 176.5631103515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12580.27204537899
INFO:root:eval perplexity: 161.91845703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 12816.23769254211
INFO:root:eval perplexity: 188.80892944335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [14:29:08<18:19:02, 588.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12825.2763671875
INFO:root:current train perplexity163.6101531982422
INFO:root:current mean train loss 12988.448005157767
INFO:root:current train perplexity168.2736053466797
INFO:root:current mean train loss 13000.315088131158
INFO:root:current train perplexity169.5076141357422
INFO:root:current mean train loss 13019.127140057755
INFO:root:current train perplexity169.95883178710938
INFO:root:current mean train loss 13032.040102066532
INFO:root:current train perplexity170.2971954345703
INFO:root:current mean train loss 13045.328641432654
INFO:root:current train perplexity170.94822692871094
INFO:root:current mean train loss 13047.131222144486
INFO:root:current train perplexity171.05015563964844
INFO:root:current mean train loss 13041.717295574768
INFO:root:current train perplexity170.2538299560547
INFO:root:current mean train loss 13017.987787496108
INFO:root:current train perplexity169.36331176757812
INFO:root:current mean train loss 13008.188505762044
INFO:root:current train perplexity168.70375061035156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.37s/it]
INFO:root:final mean train loss: 12996.58627811555
INFO:root:final train perplexity: 168.6000213623047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 12602.308455230497
INFO:root:eval perplexity: 163.3676300048828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 12841.804639018173
INFO:root:eval perplexity: 190.79330444335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [14:38:56<18:09:01, 588.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13115.73153409091
INFO:root:current train perplexity167.25413513183594
INFO:root:current mean train loss 13049.417168144708
INFO:root:current train perplexity168.88768005371094
INFO:root:current mean train loss 13022.637218601896
INFO:root:current train perplexity170.01499938964844
INFO:root:current mean train loss 13062.100975306472
INFO:root:current train perplexity171.2090301513672
INFO:root:current mean train loss 13031.669558337135
INFO:root:current train perplexity171.01043701171875
INFO:root:current mean train loss 13036.972732693248
INFO:root:current train perplexity170.8255157470703
INFO:root:current mean train loss 13043.067467522504
INFO:root:current train perplexity170.702880859375
INFO:root:current mean train loss 13039.488549083597
INFO:root:current train perplexity170.6263885498047
INFO:root:current mean train loss 13036.684239172318
INFO:root:current train perplexity170.75979614257812
INFO:root:current mean train loss 13040.162192988475
INFO:root:current train perplexity170.82656860351562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.32s/it]
INFO:root:final mean train loss: 13031.400051978326
INFO:root:final train perplexity: 170.9316864013672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 12682.497104942377
INFO:root:eval perplexity: 168.7518768310547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 12914.855184785018
INFO:root:eval perplexity: 196.57846069335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [14:48:44<17:58:39, 588.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12847.228258634868
INFO:root:current train perplexity168.95025634765625
INFO:root:current mean train loss 12997.419125853467
INFO:root:current train perplexity171.27410888671875
INFO:root:current mean train loss 13040.561273722888
INFO:root:current train perplexity171.82183837890625
INFO:root:current mean train loss 13063.676999657131
INFO:root:current train perplexity171.9210968017578
INFO:root:current mean train loss 13066.277607118884
INFO:root:current train perplexity172.38070678710938
INFO:root:current mean train loss 13066.330443159923
INFO:root:current train perplexity172.32342529296875
INFO:root:current mean train loss 13060.22745386965
INFO:root:current train perplexity172.36944580078125
INFO:root:current mean train loss 13058.94624695758
INFO:root:current train perplexity172.23585510253906
INFO:root:current mean train loss 13068.395244295634
INFO:root:current train perplexity172.39073181152344
INFO:root:current mean train loss 13064.992773012445
INFO:root:current train perplexity172.37428283691406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.15s/it]
INFO:root:final mean train loss: 13051.388869254819
INFO:root:final train perplexity: 172.28512573242188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 12682.96913785461
INFO:root:eval perplexity: 168.7840576171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 12916.849443151596
INFO:root:eval perplexity: 196.7388153076172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [14:58:26<17:45:40, 586.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12968.772424768518
INFO:root:current train perplexity171.97019958496094
INFO:root:current mean train loss 13020.129605991633
INFO:root:current train perplexity171.38742065429688
INFO:root:current mean train loss 13029.838544534692
INFO:root:current train perplexity171.55462646484375
INFO:root:current mean train loss 13047.595067015482
INFO:root:current train perplexity172.1273956298828
INFO:root:current mean train loss 13040.788698861974
INFO:root:current train perplexity171.9707794189453
INFO:root:current mean train loss 13051.282252505336
INFO:root:current train perplexity171.9502716064453
INFO:root:current mean train loss 13051.853778845196
INFO:root:current train perplexity171.87863159179688
INFO:root:current mean train loss 13055.319313101789
INFO:root:current train perplexity171.70455932617188
INFO:root:current mean train loss 13054.207239079504
INFO:root:current train perplexity171.74148559570312
INFO:root:current mean train loss 13050.228431347761
INFO:root:current train perplexity171.74148559570312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.06s/it]
INFO:root:final mean train loss: 13042.838723213443
INFO:root:final train perplexity: 171.7048797607422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 12696.963541666666
INFO:root:eval perplexity: 169.74192810058594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 12935.08383892952
INFO:root:eval perplexity: 198.21133422851562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [15:08:14<17:36:23, 586.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12943.765178571428
INFO:root:current train perplexity170.39247131347656
INFO:root:current mean train loss 12979.276294849536
INFO:root:current train perplexity170.39027404785156
INFO:root:current mean train loss 13016.64137300532
INFO:root:current train perplexity171.11134338378906
INFO:root:current mean train loss 13007.711561333956
INFO:root:current train perplexity170.6886444091797
INFO:root:current mean train loss 13036.262264278017
INFO:root:current train perplexity171.2078094482422
INFO:root:current mean train loss 13057.207292275118
INFO:root:current train perplexity171.7039031982422
INFO:root:current mean train loss 13056.697008796751
INFO:root:current train perplexity171.5966796875
INFO:root:current mean train loss 13058.151380474064
INFO:root:current train perplexity171.67803955078125
INFO:root:current mean train loss 13052.716657700224
INFO:root:current train perplexity171.77072143554688
INFO:root:current mean train loss 13055.66126650234
INFO:root:current train perplexity171.75811767578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.42s/it]
INFO:root:final mean train loss: 13041.444624377835
INFO:root:final train perplexity: 171.61050415039062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 12689.585729720744
INFO:root:eval perplexity: 169.2362518310547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 12927.69470994016
INFO:root:eval perplexity: 197.61329650878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [15:18:02<17:27:26, 587.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13027.749046148256
INFO:root:current train perplexity171.1675567626953
INFO:root:current mean train loss 13082.863977819055
INFO:root:current train perplexity171.87486267089844
INFO:root:current mean train loss 13054.872432002316
INFO:root:current train perplexity171.4752960205078
INFO:root:current mean train loss 13062.743269405977
INFO:root:current train perplexity171.57418823242188
INFO:root:current mean train loss 13048.437813029062
INFO:root:current train perplexity171.28407287597656
INFO:root:current mean train loss 13052.156931615447
INFO:root:current train perplexity171.34884643554688
INFO:root:current mean train loss 13048.764657550058
INFO:root:current train perplexity171.2786865234375
INFO:root:current mean train loss 13049.944514689183
INFO:root:current train perplexity171.58392333984375
INFO:root:current mean train loss 13060.065908122035
INFO:root:current train perplexity172.03179931640625
INFO:root:current mean train loss 13062.162423159132
INFO:root:current train perplexity172.19215393066406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.69s/it]
INFO:root:final mean train loss: 13050.271522029754
INFO:root:final train perplexity: 172.2091522216797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 12705.831421764184
INFO:root:eval perplexity: 170.3516082763672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 12957.661070478724
INFO:root:eval perplexity: 200.0498046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [15:27:51<17:18:06, 587.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13003.250670189951
INFO:root:current train perplexity170.9988555908203
INFO:root:current mean train loss 13022.875116411424
INFO:root:current train perplexity172.59388732910156
INFO:root:current mean train loss 13029.465244490786
INFO:root:current train perplexity173.0205535888672
INFO:root:current mean train loss 13035.848418580841
INFO:root:current train perplexity173.1700439453125
INFO:root:current mean train loss 13063.459839679184
INFO:root:current train perplexity173.30154418945312
INFO:root:current mean train loss 13075.453729369896
INFO:root:current train perplexity173.59829711914062
INFO:root:current mean train loss 13080.992161998367
INFO:root:current train perplexity173.7423095703125
INFO:root:current mean train loss 13087.929557465046
INFO:root:current train perplexity173.6553497314453
INFO:root:current mean train loss 13082.776387843345
INFO:root:current train perplexity173.84788513183594
INFO:root:current mean train loss 13104.509102260778
INFO:root:current train perplexity175.18458557128906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.95s/it]
INFO:root:final mean train loss: 13109.715350489463
INFO:root:final train perplexity: 176.29559326171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 13314.376468306738
INFO:root:eval perplexity: 217.87969970703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 13599.001703789894
INFO:root:eval perplexity: 260.03564453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [15:37:39<17:08:32, 587.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13493.749602754237
INFO:root:current train perplexity210.76409912109375
INFO:root:current mean train loss 13493.880693543631
INFO:root:current train perplexity204.91741943359375
INFO:root:current mean train loss 13419.890421392374
INFO:root:current train perplexity196.941650390625
INFO:root:current mean train loss 13441.58844827211
INFO:root:current train perplexity199.8099365234375
INFO:root:current mean train loss 13591.571480545343
INFO:root:current train perplexity211.81663513183594
INFO:root:current mean train loss 13564.825179589669
INFO:root:current train perplexity209.43955993652344
INFO:root:current mean train loss 13511.313999668058
INFO:root:current train perplexity205.46083068847656
INFO:root:current mean train loss 13465.662231606142
INFO:root:current train perplexity201.59063720703125
INFO:root:current mean train loss 13416.867003328725
INFO:root:current train perplexity198.34814453125
INFO:root:current mean train loss 13385.339944563022
INFO:root:current train perplexity195.71163940429688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.28s/it]
INFO:root:final mean train loss: 13361.73368023288
INFO:root:final train perplexity: 194.7254638671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 12650.633456615691
INFO:root:eval perplexity: 166.59152221679688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 12894.82364389406
INFO:root:eval perplexity: 194.97483825683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [15:47:27<16:59:14, 588.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13014.068723763992
INFO:root:current train perplexity167.346923828125
INFO:root:current mean train loss 13016.575505239522
INFO:root:current train perplexity167.4364013671875
INFO:root:current mean train loss 13003.30879491456
INFO:root:current train perplexity167.0239715576172
INFO:root:current mean train loss 13018.839731990804
INFO:root:current train perplexity167.24671936035156
INFO:root:current mean train loss 13001.921686797377
INFO:root:current train perplexity167.15663146972656
INFO:root:current mean train loss 12996.756832492834
INFO:root:current train perplexity167.090576171875
INFO:root:current mean train loss 12978.223452726761
INFO:root:current train perplexity166.84725952148438
INFO:root:current mean train loss 12976.973695200457
INFO:root:current train perplexity166.7188262939453
INFO:root:current mean train loss 12985.784929849697
INFO:root:current train perplexity166.7881622314453
INFO:root:current mean train loss 12979.757635769454
INFO:root:current train perplexity166.85520935058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.08s/it]
INFO:root:final mean train loss: 12971.751659024147
INFO:root:final train perplexity: 166.95620727539062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 12651.756531194593
INFO:root:eval perplexity: 166.6671600341797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 12900.329724900266
INFO:root:eval perplexity: 195.4143524169922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [15:57:17<16:50:35, 588.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13086.149479166666
INFO:root:current train perplexity168.4067840576172
INFO:root:current mean train loss 12995.209140625
INFO:root:current train perplexity168.06118774414062
INFO:root:current mean train loss 13004.120088778409
INFO:root:current train perplexity168.553955078125
INFO:root:current mean train loss 13034.306247395833
INFO:root:current train perplexity171.3731231689453
INFO:root:current mean train loss 13164.683145559211
INFO:root:current train perplexity179.29869079589844
INFO:root:current mean train loss 13284.623345788043
INFO:root:current train perplexity188.110595703125
INFO:root:current mean train loss 13327.764431423611
INFO:root:current train perplexity190.65480041503906
INFO:root:current mean train loss 13303.979720262098
INFO:root:current train perplexity190.0637969970703
INFO:root:current mean train loss 13283.022510044642
INFO:root:current train perplexity188.28378295898438
INFO:root:current mean train loss 13267.38708233173
INFO:root:current train perplexity186.6331787109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.26s/it]
INFO:root:final mean train loss: 13250.850693979572
INFO:root:final train perplexity: 186.39047241210938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 12743.901948969415
INFO:root:eval perplexity: 172.99441528320312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 12981.623961103724
INFO:root:eval perplexity: 202.01953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [16:07:07<16:41:04, 588.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13118.979656908885
INFO:root:current train perplexity174.60955810546875
INFO:root:current mean train loss 13079.728094048838
INFO:root:current train perplexity171.56289672851562
INFO:root:current mean train loss 13045.334470930875
INFO:root:current train perplexity171.89404296875
INFO:root:current mean train loss 13077.416030923629
INFO:root:current train perplexity174.48770141601562
INFO:root:current mean train loss 13106.41684256923
INFO:root:current train perplexity176.2194366455078
INFO:root:current mean train loss 13118.61218073274
INFO:root:current train perplexity176.59156799316406
INFO:root:current mean train loss 13109.106112165995
INFO:root:current train perplexity176.35890197753906
INFO:root:current mean train loss 13095.510194663953
INFO:root:current train perplexity175.39361572265625
INFO:root:current mean train loss 13108.172217847537
INFO:root:current train perplexity175.83668518066406
INFO:root:current mean train loss 13141.315346237601
INFO:root:current train perplexity177.78126525878906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.53s/it]
INFO:root:final mean train loss: 13131.063419218986
INFO:root:final train perplexity: 177.78668212890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 12931.288958610372
INFO:root:eval perplexity: 186.6123504638672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 13197.200216090425
INFO:root:eval perplexity: 220.63644409179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [16:16:59<16:33:08, 589.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13120.411551339286
INFO:root:current train perplexity180.83863830566406
INFO:root:current mean train loss 13255.529414471532
INFO:root:current train perplexity184.69418334960938
INFO:root:current mean train loss 13269.565352502148
INFO:root:current train perplexity187.17129516601562
INFO:root:current mean train loss 13249.860945991848
INFO:root:current train perplexity186.79254150390625
INFO:root:current mean train loss 13401.515233181644
INFO:root:current train perplexity196.5626220703125
INFO:root:current mean train loss 13536.649490072441
INFO:root:current train perplexity207.0557861328125
INFO:root:current mean train loss 13480.719219202243
INFO:root:current train perplexity202.36546325683594
INFO:root:current mean train loss 13492.409726611884
INFO:root:current train perplexity203.83985900878906
INFO:root:current mean train loss 13456.619243651796
INFO:root:current train perplexity200.8212890625
INFO:root:current mean train loss 13445.128491383388
INFO:root:current train perplexity200.37037658691406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.95s/it]
INFO:root:final mean train loss: 13434.084253864903
INFO:root:final train perplexity: 200.3638916015625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 13455.196150542997
INFO:root:eval perplexity: 230.64645385742188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 13709.641504598847
INFO:root:eval perplexity: 272.0704345703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [16:26:57<16:27:01, 592.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13635.641019570707
INFO:root:current train perplexity214.57554626464844
INFO:root:current mean train loss 13415.60768687186
INFO:root:current train perplexity197.99728393554688
INFO:root:current mean train loss 13345.391297815635
INFO:root:current train perplexity192.32933044433594
INFO:root:current mean train loss 13296.819808309838
INFO:root:current train perplexity189.30221557617188
INFO:root:current mean train loss 13269.055744301102
INFO:root:current train perplexity187.75625610351562
INFO:root:current mean train loss 13262.067469219533
INFO:root:current train perplexity186.87966918945312
INFO:root:current mean train loss 13245.934243394582
INFO:root:current train perplexity186.17710876464844
INFO:root:current mean train loss 13258.619015957447
INFO:root:current train perplexity186.13502502441406
INFO:root:current mean train loss 13262.778387661638
INFO:root:current train perplexity186.30081176757812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.70s/it]
INFO:root:final mean train loss: 13255.643595541676
INFO:root:final train perplexity: 186.7432861328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 13091.84587627438
INFO:root:eval perplexity: 199.13006591796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 13340.599740968528
INFO:root:eval perplexity: 233.9611053466797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [16:36:52<16:18:41, 593.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13135.216099330357
INFO:root:current train perplexity187.21556091308594
INFO:root:current mean train loss 13522.03359557535
INFO:root:current train perplexity201.03091430664062
INFO:root:current mean train loss 13367.561108280495
INFO:root:current train perplexity194.6691131591797
INFO:root:current mean train loss 13327.832514759772
INFO:root:current train perplexity191.24298095703125
INFO:root:current mean train loss 13262.435117379453
INFO:root:current train perplexity187.43539428710938
INFO:root:current mean train loss 13204.62395987426
INFO:root:current train perplexity183.3747100830078
INFO:root:current mean train loss 13170.391649827532
INFO:root:current train perplexity180.51651000976562
INFO:root:current mean train loss 13149.906324588932
INFO:root:current train perplexity178.8115997314453
INFO:root:current mean train loss 13136.214416579538
INFO:root:current train perplexity178.04891967773438
INFO:root:current mean train loss 13144.717800354878
INFO:root:current train perplexity178.3944549560547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.64s/it]
INFO:root:final mean train loss: 13141.999375620197
INFO:root:final train perplexity: 178.55548095703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 12765.544838763299
INFO:root:eval perplexity: 174.51516723632812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 13019.21791888298
INFO:root:eval perplexity: 205.1491241455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [16:46:46<16:08:57, 593.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13183.088541666666
INFO:root:current train perplexity173.95204162597656
INFO:root:current mean train loss 13053.756963315218
INFO:root:current train perplexity173.70114135742188
INFO:root:current mean train loss 13089.002280159884
INFO:root:current train perplexity173.57289123535156
INFO:root:current mean train loss 13064.233792162699
INFO:root:current train perplexity173.63356018066406
INFO:root:current mean train loss 13084.967829913403
INFO:root:current train perplexity174.23046875
INFO:root:current mean train loss 13105.277171192354
INFO:root:current train perplexity174.6194610595703
INFO:root:current mean train loss 13102.689272103658
INFO:root:current train perplexity174.73941040039062
INFO:root:current mean train loss 13087.803168706294
INFO:root:current train perplexity173.64085388183594
INFO:root:current mean train loss 13073.880679639571
INFO:root:current train perplexity172.96932983398438
INFO:root:current mean train loss 13070.75718814037
INFO:root:current train perplexity172.7151641845703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.17s/it]
INFO:root:final mean train loss: 13060.058706468151
INFO:root:final train perplexity: 172.8754119873047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 12874.343389849291
INFO:root:eval perplexity: 182.3644256591797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 13137.487741023937
INFO:root:eval perplexity: 215.31442260742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [16:56:41<16:00:03, 593.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13327.8564453125
INFO:root:current train perplexity179.5903778076172
INFO:root:current mean train loss 13220.303758574695
INFO:root:current train perplexity182.00390625
INFO:root:current mean train loss 13222.250919632848
INFO:root:current train perplexity182.98757934570312
INFO:root:current mean train loss 13198.486349288893
INFO:root:current train perplexity182.2440185546875
INFO:root:current mean train loss 13208.159939236111
INFO:root:current train perplexity181.4346923828125
INFO:root:current mean train loss 13191.250356641372
INFO:root:current train perplexity180.5010223388672
INFO:root:current mean train loss 13174.285486995886
INFO:root:current train perplexity179.2514190673828
INFO:root:current mean train loss 13151.337877117912
INFO:root:current train perplexity178.09298706054688
INFO:root:current mean train loss 13138.090197353433
INFO:root:current train perplexity177.20033264160156
INFO:root:current mean train loss 13120.703774630958
INFO:root:current train perplexity176.1833953857422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.68s/it]
INFO:root:final mean train loss: 13099.749252319336
INFO:root:final train perplexity: 175.60366821289062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.62s/it]
INFO:root:eval mean loss: 12677.729790004432
INFO:root:eval perplexity: 168.42684936523438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 12928.425150986259
INFO:root:eval perplexity: 197.67230224609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [17:06:41<15:53:25, 595.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13277.368290070564
INFO:root:current train perplexity172.58746337890625
INFO:root:current mean train loss 13084.420980438932
INFO:root:current train perplexity169.84402465820312
INFO:root:current mean train loss 13047.841357210498
INFO:root:current train perplexity169.3058319091797
INFO:root:current mean train loss 13037.648823994525
INFO:root:current train perplexity169.43585205078125
INFO:root:current mean train loss 13029.79230713457
INFO:root:current train perplexity169.2047882080078
INFO:root:current mean train loss 13003.092666769657
INFO:root:current train perplexity168.9091033935547
INFO:root:current mean train loss 13008.023339998514
INFO:root:current train perplexity169.14517211914062
INFO:root:current mean train loss 13002.504985678865
INFO:root:current train perplexity169.27354431152344
INFO:root:current mean train loss 13008.014870543773
INFO:root:current train perplexity169.48101806640625
INFO:root:current mean train loss 13018.192269527055
INFO:root:current train perplexity169.74298095703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.48s/it]
INFO:root:final mean train loss: 13016.175569595829
INFO:root:final train perplexity: 169.90809631347656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.68s/it]
INFO:root:eval mean loss: 12743.547318262412
INFO:root:eval perplexity: 172.96966552734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 13003.546161624557
INFO:root:eval perplexity: 203.83868408203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [17:16:40<15:44:39, 596.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13051.427333733975
INFO:root:current train perplexity170.17941284179688
INFO:root:current mean train loss 13031.958612016637
INFO:root:current train perplexity170.6029510498047
INFO:root:current mean train loss 13037.324079824792
INFO:root:current train perplexity170.9072265625
INFO:root:current mean train loss 13049.331365804757
INFO:root:current train perplexity170.1549072265625
INFO:root:current mean train loss 13049.152779755126
INFO:root:current train perplexity171.2581787109375
INFO:root:current mean train loss 13046.624996376391
INFO:root:current train perplexity171.24014282226562
INFO:root:current mean train loss 13046.670724215082
INFO:root:current train perplexity171.2916717529297
INFO:root:current mean train loss 13045.197710958644
INFO:root:current train perplexity170.95907592773438
INFO:root:current mean train loss 13036.04165231116
INFO:root:current train perplexity170.643798828125
INFO:root:current mean train loss 13029.448360747803
INFO:root:current train perplexity170.3341522216797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.47s/it]
INFO:root:final mean train loss: 13022.566615196967
INFO:root:final train perplexity: 170.3369903564453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 12703.228072362588
INFO:root:eval perplexity: 170.17251586914062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 12963.461027537678
INFO:root:eval perplexity: 200.52464294433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [17:26:38<15:35:21, 597.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13018.497007978724
INFO:root:current train perplexity168.9210968017578
INFO:root:current mean train loss 13034.05316618835
INFO:root:current train perplexity169.67218017578125
INFO:root:current mean train loss 12990.470248450152
INFO:root:current train perplexity168.56199645996094
INFO:root:current mean train loss 12994.01337637338
INFO:root:current train perplexity167.90090942382812
INFO:root:current mean train loss 12988.055098224273
INFO:root:current train perplexity167.91860961914062
INFO:root:current mean train loss 12983.676138311243
INFO:root:current train perplexity168.38131713867188
INFO:root:current mean train loss 12989.88024355197
INFO:root:current train perplexity168.42251586914062
INFO:root:current mean train loss 12985.721169835593
INFO:root:current train perplexity168.33636474609375
INFO:root:current mean train loss 12996.747310129502
INFO:root:current train perplexity168.41680908203125
INFO:root:current mean train loss 12999.386709469047
INFO:root:current train perplexity168.3612518310547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.47s/it]
INFO:root:final mean train loss: 12992.35369823825
INFO:root:final train perplexity: 168.31878662109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 12636.708928967199
INFO:root:eval perplexity: 165.65615844726562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 12887.802194148937
INFO:root:eval perplexity: 194.415771484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [17:36:35<15:25:27, 597.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12981.222869318182
INFO:root:current train perplexity166.20240783691406
INFO:root:current mean train loss 12986.73738029234
INFO:root:current train perplexity166.52774047851562
INFO:root:current mean train loss 12974.024908088235
INFO:root:current train perplexity166.79730224609375
INFO:root:current mean train loss 12966.889805237675
INFO:root:current train perplexity166.7578582763672
INFO:root:current mean train loss 12978.910070398351
INFO:root:current train perplexity166.99801635742188
INFO:root:current mean train loss 12979.577482756195
INFO:root:current train perplexity167.0506591796875
INFO:root:current mean train loss 12979.51041567271
INFO:root:current train perplexity167.206298828125
INFO:root:current mean train loss 12984.471643470613
INFO:root:current train perplexity167.23133850097656
INFO:root:current mean train loss 12989.094994974415
INFO:root:current train perplexity167.2913055419922
INFO:root:current mean train loss 12991.404418561846
INFO:root:current train perplexity167.39712524414062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.16s/it]
INFO:root:final mean train loss: 12979.489602611911
INFO:root:final train perplexity: 167.46665954589844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it]
INFO:root:eval mean loss: 12685.96760028812
INFO:root:eval perplexity: 168.9888458251953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 12948.966658355497
INFO:root:eval perplexity: 199.33963012695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [17:46:29<15:14:05, 596.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12799.017144097223
INFO:root:current train perplexity166.9925994873047
INFO:root:current mean train loss 12947.681167321702
INFO:root:current train perplexity167.3531494140625
INFO:root:current mean train loss 12954.338555281607
INFO:root:current train perplexity166.71620178222656
INFO:root:current mean train loss 12969.998923898072
INFO:root:current train perplexity166.6400604248047
INFO:root:current mean train loss 12964.354498515118
INFO:root:current train perplexity166.69871520996094
INFO:root:current mean train loss 12972.581023465253
INFO:root:current train perplexity167.25198364257812
INFO:root:current mean train loss 12970.379423253677
INFO:root:current train perplexity166.9105224609375
INFO:root:current mean train loss 12970.172603262205
INFO:root:current train perplexity166.6470489501953
INFO:root:current mean train loss 12967.381558697856
INFO:root:current train perplexity166.49859619140625
INFO:root:current mean train loss 12972.777469496366
INFO:root:current train perplexity166.46176147460938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.69s/it]
INFO:root:final mean train loss: 12964.181115427325
INFO:root:final train perplexity: 166.45826721191406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it]
INFO:root:eval mean loss: 12636.692285848847
INFO:root:eval perplexity: 165.65505981445312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 12886.17734652039
INFO:root:eval perplexity: 194.28668212890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [17:56:25<15:04:11, 596.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12947.978515625
INFO:root:current train perplexity165.06690979003906
INFO:root:current mean train loss 12965.34787897478
INFO:root:current train perplexity165.4554901123047
INFO:root:current mean train loss 12961.597519315037
INFO:root:current train perplexity165.12957763671875
INFO:root:current mean train loss 12994.48614123568
INFO:root:current train perplexity165.61231994628906
INFO:root:current mean train loss 12976.273690452495
INFO:root:current train perplexity165.40089416503906
INFO:root:current mean train loss 12976.703853573774
INFO:root:current train perplexity165.3827667236328
INFO:root:current mean train loss 12966.175325714885
INFO:root:current train perplexity165.21156311035156
INFO:root:current mean train loss 12963.759452770348
INFO:root:current train perplexity165.08706665039062
INFO:root:current mean train loss 12951.373540201635
INFO:root:current train perplexity164.99420166015625
INFO:root:current mean train loss 12951.176208684668
INFO:root:current train perplexity164.98089599609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.69s/it]
INFO:root:final mean train loss: 12942.353132678616
INFO:root:final train perplexity: 165.03086853027344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 12599.945762688387
INFO:root:eval perplexity: 163.2117462158203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 12852.093784629877
INFO:root:eval perplexity: 191.59759521484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [18:06:22<14:54:43, 596.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12918.806900217563
INFO:root:current train perplexity163.41671752929688
INFO:root:current mean train loss 12947.561179731145
INFO:root:current train perplexity163.65806579589844
INFO:root:current mean train loss 12954.036762852822
INFO:root:current train perplexity163.76486206054688
INFO:root:current mean train loss 12961.734601748021
INFO:root:current train perplexity164.2382049560547
INFO:root:current mean train loss 12955.38856993737
INFO:root:current train perplexity164.46995544433594
INFO:root:current mean train loss 12940.581572484887
INFO:root:current train perplexity164.4923858642578
INFO:root:current mean train loss 12936.532676730487
INFO:root:current train perplexity164.57327270507812
INFO:root:current mean train loss 12947.974395007623
INFO:root:current train perplexity164.5830841064453
INFO:root:current mean train loss 12952.115487681314
INFO:root:current train perplexity164.7433319091797
INFO:root:current mean train loss 12945.139139707291
INFO:root:current train perplexity164.64163208007812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.21s/it]
INFO:root:final mean train loss: 12935.937186702606
INFO:root:final train perplexity: 164.6136932373047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 12610.387189716312
INFO:root:eval perplexity: 163.9022674560547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 12862.058496786347
INFO:root:eval perplexity: 192.3799591064453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [18:16:21<14:45:39, 597.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12891.193011404454
INFO:root:current train perplexity163.05430603027344
INFO:root:current mean train loss 12918.77083681484
INFO:root:current train perplexity163.49551391601562
INFO:root:current mean train loss 12952.940382050305
INFO:root:current train perplexity164.28317260742188
INFO:root:current mean train loss 12947.729113674903
INFO:root:current train perplexity164.5519256591797
INFO:root:current mean train loss 12951.871675275925
INFO:root:current train perplexity164.47300720214844
INFO:root:current mean train loss 12947.357343683454
INFO:root:current train perplexity164.27227783203125
INFO:root:current mean train loss 12935.051302936226
INFO:root:current train perplexity164.1931915283203
INFO:root:current mean train loss 12934.90352133299
INFO:root:current train perplexity164.06553649902344
INFO:root:current mean train loss 12932.674243191586
INFO:root:current train perplexity164.08399963378906
INFO:root:current mean train loss 12937.1455394741
INFO:root:current train perplexity164.0914306640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.02s/it]
INFO:root:final mean train loss: 12928.381357008411
INFO:root:final train perplexity: 164.12374877929688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it]
INFO:root:eval mean loss: 12590.57561087101
INFO:root:eval perplexity: 162.59451293945312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 12844.630381482713
INFO:root:eval perplexity: 191.0138702392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [18:26:20<14:36:32, 597.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12907.458079769736
INFO:root:current train perplexity162.89669799804688
INFO:root:current mean train loss 12857.05873397436
INFO:root:current train perplexity163.2019500732422
INFO:root:current mean train loss 12885.470428363347
INFO:root:current train perplexity163.26678466796875
INFO:root:current mean train loss 12874.327897547468
INFO:root:current train perplexity162.85421752929688
INFO:root:current mean train loss 12883.50649068813
INFO:root:current train perplexity163.1514434814453
INFO:root:current mean train loss 12906.861636685924
INFO:root:current train perplexity163.2978515625
INFO:root:current mean train loss 12922.43655435027
INFO:root:current train perplexity163.48194885253906
INFO:root:current mean train loss 12932.259088787343
INFO:root:current train perplexity163.72596740722656
INFO:root:current mean train loss 12944.616663756984
INFO:root:current train perplexity164.0802459716797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:42<00:00, 522.51s/it]
INFO:root:final mean train loss: 12928.12425478043
INFO:root:final train perplexity: 164.1070098876953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.64s/it]
INFO:root:eval mean loss: 12624.702792553191
INFO:root:eval perplexity: 164.85382080078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 12876.23394558954
INFO:root:eval perplexity: 193.49832153320312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [18:36:22<14:28:31, 598.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12512.8603515625
INFO:root:current train perplexity158.85430908203125
INFO:root:current mean train loss 12909.306109678399
INFO:root:current train perplexity163.8019561767578
INFO:root:current mean train loss 12910.905855526478
INFO:root:current train perplexity164.569580078125
INFO:root:current mean train loss 12943.742271297442
INFO:root:current train perplexity165.27578735351562
INFO:root:current mean train loss 12934.65585258995
INFO:root:current train perplexity165.49642944335938
INFO:root:current mean train loss 12957.472355321197
INFO:root:current train perplexity165.70790100097656
INFO:root:current mean train loss 12959.770025199523
INFO:root:current train perplexity165.63143920898438
INFO:root:current mean train loss 12967.508627922742
INFO:root:current train perplexity165.75729370117188
INFO:root:current mean train loss 12958.339322024829
INFO:root:current train perplexity165.596923828125
INFO:root:current mean train loss 12958.117427585134
INFO:root:current train perplexity165.70364379882812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.85s/it]
INFO:root:final mean train loss: 12952.93083633915
INFO:root:final train perplexity: 165.7210235595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 12622.316302360372
INFO:root:eval perplexity: 164.6948699951172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 12874.152925531915
INFO:root:eval perplexity: 193.3337860107422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [18:46:20<14:18:14, 598.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12909.962624289772
INFO:root:current train perplexity166.05245971679688
INFO:root:current mean train loss 12875.350841075451
INFO:root:current train perplexity163.07412719726562
INFO:root:current mean train loss 12961.883131849821
INFO:root:current train perplexity168.52381896972656
INFO:root:current mean train loss 12967.817222668811
INFO:root:current train perplexity168.29046630859375
INFO:root:current mean train loss 12975.680321909216
INFO:root:current train perplexity167.9657745361328
INFO:root:current mean train loss 12978.320323966487
INFO:root:current train perplexity167.62220764160156
INFO:root:current mean train loss 12970.431215476678
INFO:root:current train perplexity166.96209716796875
INFO:root:current mean train loss 12973.388531777426
INFO:root:current train perplexity166.6846466064453
INFO:root:current mean train loss 12966.43885466438
INFO:root:current train perplexity166.49391174316406
INFO:root:current mean train loss 12971.8476926969
INFO:root:current train perplexity166.90184020996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.92s/it]
INFO:root:final mean train loss: 12972.720814612603
INFO:root:final train perplexity: 167.01998901367188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it]
INFO:root:eval mean loss: 12625.610815602837
INFO:root:eval perplexity: 164.91436767578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 12882.169963430852
INFO:root:eval perplexity: 193.96852111816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [18:56:19<14:08:14, 598.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13077.064298930922
INFO:root:current train perplexity167.3207550048828
INFO:root:current mean train loss 13060.578855370273
INFO:root:current train perplexity167.2802276611328
INFO:root:current mean train loss 12950.924760095604
INFO:root:current train perplexity165.56455993652344
INFO:root:current mean train loss 12948.710570141066
INFO:root:current train perplexity165.06045532226562
INFO:root:current mean train loss 12947.893626939142
INFO:root:current train perplexity164.95211791992188
INFO:root:current mean train loss 12934.599150258911
INFO:root:current train perplexity164.6525421142578
INFO:root:current mean train loss 12939.985681290387
INFO:root:current train perplexity164.9474639892578
INFO:root:current mean train loss 12947.484214729659
INFO:root:current train perplexity165.21502685546875
INFO:root:current mean train loss 12953.445907499618
INFO:root:current train perplexity165.181396484375
INFO:root:current mean train loss 12950.242796390437
INFO:root:current train perplexity165.0442352294922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.48s/it]
INFO:root:final mean train loss: 12942.8962823191
INFO:root:final train perplexity: 165.0663604736328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.50s/it]
INFO:root:eval mean loss: 12600.296708776596
INFO:root:eval perplexity: 163.23486328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 39.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.00s/it]
INFO:root:eval mean loss: 12854.46467060062
INFO:root:eval perplexity: 191.78359985351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [19:06:20<13:59:03, 599.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13091.063404224536
INFO:root:current train perplexity162.91224670410156
INFO:root:current mean train loss 12964.126960814468
INFO:root:current train perplexity163.37628173828125
INFO:root:current mean train loss 12944.247577952918
INFO:root:current train perplexity163.29800415039062
INFO:root:current mean train loss 12927.474030007645
INFO:root:current train perplexity163.05523681640625
INFO:root:current mean train loss 12953.524199081528
INFO:root:current train perplexity163.81398010253906
INFO:root:current mean train loss 12936.460629892077
INFO:root:current train perplexity163.536376953125
INFO:root:current mean train loss 12922.732576069078
INFO:root:current train perplexity163.3859405517578
INFO:root:current mean train loss 12926.40781894773
INFO:root:current train perplexity163.62701416015625
INFO:root:current mean train loss 12922.661400865327
INFO:root:current train perplexity163.68475341796875
INFO:root:current mean train loss 12927.35266021103
INFO:root:current train perplexity163.61724853515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:51<00:00, 531.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:51<00:00, 531.65s/it]
INFO:root:final mean train loss: 12921.658702973396
INFO:root:final train perplexity: 163.68896484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.27s/it]
INFO:root:eval mean loss: 12592.610233820922
INFO:root:eval perplexity: 162.7283172607422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it]
INFO:root:eval mean loss: 12847.866543384309
INFO:root:eval perplexity: 191.26678466796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [19:16:32<13:54:37, 603.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12984.772767857143
INFO:root:current train perplexity163.19113159179688
INFO:root:current mean train loss 13016.284642650464
INFO:root:current train perplexity164.75425720214844
INFO:root:current mean train loss 12983.869680851063
INFO:root:current train perplexity164.2490997314453
INFO:root:current mean train loss 13005.604602961754
INFO:root:current train perplexity164.73477172851562
INFO:root:current mean train loss 12975.041904633621
INFO:root:current train perplexity164.4974822998047
INFO:root:current mean train loss 12973.940059141356
INFO:root:current train perplexity164.82843017578125
INFO:root:current mean train loss 12973.821375184547
INFO:root:current train perplexity165.45201110839844
INFO:root:current mean train loss 12983.052750318877
INFO:root:current train perplexity165.6089324951172
INFO:root:current mean train loss 12975.50791892777
INFO:root:current train perplexity165.6180877685547
INFO:root:current mean train loss 12972.686776194852
INFO:root:current train perplexity165.69091796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.33s/it]
INFO:root:final mean train loss: 12950.733506233462
INFO:root:final train perplexity: 165.57742309570312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 12630.08081227837
INFO:root:eval perplexity: 165.21273803710938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 12876.211553911791
INFO:root:eval perplexity: 193.49656677246094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [19:26:26<13:40:49, 600.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12928.074900072674
INFO:root:current train perplexity163.05438232421875
INFO:root:current mean train loss 12967.519893192744
INFO:root:current train perplexity164.45074462890625
INFO:root:current mean train loss 12990.977261766975
INFO:root:current train perplexity164.96328735351562
INFO:root:current mean train loss 12942.366714877915
INFO:root:current train perplexity164.3727264404297
INFO:root:current mean train loss 12942.483047933127
INFO:root:current train perplexity164.3845672607422
INFO:root:current mean train loss 12939.595730101864
INFO:root:current train perplexity164.56863403320312
INFO:root:current mean train loss 12946.54806874514
INFO:root:current train perplexity164.73406982421875
INFO:root:current mean train loss 12954.017982944986
INFO:root:current train perplexity165.10421752929688
INFO:root:current mean train loss 12951.242007942245
INFO:root:current train perplexity165.161865234375
INFO:root:current mean train loss 12959.223936240722
INFO:root:current train perplexity165.3560333251953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.26s/it]
INFO:root:final mean train loss: 12948.4768241144
INFO:root:final train perplexity: 165.4300079345703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 12662.442327404699
INFO:root:eval perplexity: 167.38890075683594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 12927.294831837322
INFO:root:eval perplexity: 197.5809783935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [19:36:14<13:25:32, 596.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12927.993489583334
INFO:root:current train perplexity165.82749938964844
INFO:root:current mean train loss 12982.691154025248
INFO:root:current train perplexity166.62806701660156
INFO:root:current mean train loss 12975.739366751743
INFO:root:current train perplexity166.24314880371094
INFO:root:current mean train loss 12965.159494079417
INFO:root:current train perplexity165.8947296142578
INFO:root:current mean train loss 12987.703356689994
INFO:root:current train perplexity166.63870239257812
INFO:root:current mean train loss 12995.517558629197
INFO:root:current train perplexity166.90797424316406
INFO:root:current mean train loss 12977.278696836598
INFO:root:current train perplexity167.0360870361328
INFO:root:current mean train loss 12973.19221246671
INFO:root:current train perplexity166.80422973632812
INFO:root:current mean train loss 12970.088611284518
INFO:root:current train perplexity166.643310546875
INFO:root:current mean train loss 12974.972774341155
INFO:root:current train perplexity166.70069885253906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:40<00:00, 520.27s/it]
INFO:root:final mean train loss: 12967.902755983414
INFO:root:final train perplexity: 166.70285034179688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 12633.798315602837
INFO:root:eval perplexity: 165.46116638183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 12893.007486979166
INFO:root:eval perplexity: 194.83004760742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [19:46:11<13:15:49, 596.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13017.509500794491
INFO:root:current train perplexity165.81129455566406
INFO:root:current mean train loss 12907.359289013364
INFO:root:current train perplexity164.54054260253906
INFO:root:current mean train loss 12918.085172086148
INFO:root:current train perplexity164.81655883789062
INFO:root:current mean train loss 12922.45409884227
INFO:root:current train perplexity164.3622283935547
INFO:root:current mean train loss 12943.746144812092
INFO:root:current train perplexity164.03636169433594
INFO:root:current mean train loss 12940.726787860576
INFO:root:current train perplexity163.97605895996094
INFO:root:current mean train loss 12947.970008120732
INFO:root:current train perplexity164.42047119140625
INFO:root:current mean train loss 12944.148438786644
INFO:root:current train perplexity164.26397705078125
INFO:root:current mean train loss 12945.854479682042
INFO:root:current train perplexity164.29624938964844
INFO:root:current mean train loss 12943.839185919578
INFO:root:current train perplexity164.31968688964844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.46s/it]
INFO:root:final mean train loss: 12931.185361308437
INFO:root:final train perplexity: 164.305419921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 12605.996031416224
INFO:root:eval perplexity: 163.6114044189453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 12868.829205452128
INFO:root:eval perplexity: 192.91339111328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [19:56:08<13:05:36, 596.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12891.07709013526
INFO:root:current train perplexity161.7683563232422
INFO:root:current mean train loss 12945.970153443113
INFO:root:current train perplexity164.1384735107422
INFO:root:current mean train loss 12974.41404786985
INFO:root:current train perplexity164.5139617919922
INFO:root:current mean train loss 12957.516367400374
INFO:root:current train perplexity164.1305694580078
INFO:root:current mean train loss 12941.638688604122
INFO:root:current train perplexity164.0904998779297
INFO:root:current mean train loss 12937.898940421075
INFO:root:current train perplexity164.4272918701172
INFO:root:current mean train loss 12934.396610288606
INFO:root:current train perplexity164.2447052001953
INFO:root:current mean train loss 12931.694305380133
INFO:root:current train perplexity164.1916961669922
INFO:root:current mean train loss 12928.980018202134
INFO:root:current train perplexity163.90679931640625
INFO:root:current mean train loss 12936.544026103607
INFO:root:current train perplexity163.87991333007812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:41<00:00, 521.49s/it]
INFO:root:final mean train loss: 12923.937300159085
INFO:root:final train perplexity: 163.83616638183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 12596.72773991578
INFO:root:eval perplexity: 162.99949645996094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 12855.259931848404
INFO:root:eval perplexity: 191.84597778320312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [20:06:06<12:56:23, 597.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12878.872408854166
INFO:root:current train perplexity163.2216339111328
INFO:root:current mean train loss 12949.198683035715
INFO:root:current train perplexity163.80804443359375
INFO:root:current mean train loss 12906.16489346591
INFO:root:current train perplexity163.9530029296875
INFO:root:current mean train loss 12925.189575520833
INFO:root:current train perplexity164.23382568359375
INFO:root:current mean train loss 12954.816019736842
INFO:root:current train perplexity164.27525329589844
INFO:root:current mean train loss 12946.667245244565
INFO:root:current train perplexity163.9831085205078
INFO:root:current mean train loss 12952.888635706018
INFO:root:current train perplexity164.07211303710938
INFO:root:current mean train loss 12946.836401209677
INFO:root:current train perplexity163.86952209472656
INFO:root:current mean train loss 12948.088533482143
INFO:root:current train perplexity163.90328979492188
INFO:root:current mean train loss 12935.532414863783
INFO:root:current train perplexity163.62762451171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.85s/it]
INFO:root:final mean train loss: 12919.379268523186
INFO:root:final train perplexity: 163.5418243408203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 12570.87554715204
INFO:root:eval perplexity: 161.30435180664062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 12827.924361425088
INFO:root:eval perplexity: 189.71337890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [20:16:01<12:45:27, 596.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12829.638354198041
INFO:root:current train perplexity161.38389587402344
INFO:root:current mean train loss 12909.657520064891
INFO:root:current train perplexity162.6322021484375
INFO:root:current mean train loss 12909.55229958039
INFO:root:current train perplexity162.59149169921875
INFO:root:current mean train loss 12893.53934297487
INFO:root:current train perplexity162.0010223388672
INFO:root:current mean train loss 12893.386516563147
INFO:root:current train perplexity162.01113891601562
INFO:root:current mean train loss 12889.412196478344
INFO:root:current train perplexity162.12388610839844
INFO:root:current mean train loss 12891.225597376006
INFO:root:current train perplexity162.13687133789062
INFO:root:current mean train loss 12907.02280766084
INFO:root:current train perplexity162.3302764892578
INFO:root:current mean train loss 12906.93875305245
INFO:root:current train perplexity162.3706817626953
INFO:root:current mean train loss 12912.01962463441
INFO:root:current train perplexity162.4628448486328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.51s/it]
INFO:root:final mean train loss: 12902.472872334141
INFO:root:final train perplexity: 162.4546356201172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12576.359610483156
INFO:root:eval perplexity: 161.66249084472656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 12831.582211325354
INFO:root:eval perplexity: 189.99737548828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [20:25:55<12:34:35, 595.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12983.788493732829
INFO:root:current train perplexity163.12811279296875
INFO:root:current mean train loss 12914.045550760799
INFO:root:current train perplexity163.03611755371094
INFO:root:current mean train loss 12901.75199339562
INFO:root:current train perplexity162.7783660888672
INFO:root:current mean train loss 12935.867919297474
INFO:root:current train perplexity162.93539428710938
INFO:root:current mean train loss 12913.29743388811
INFO:root:current train perplexity162.63623046875
INFO:root:current mean train loss 12905.167924135469
INFO:root:current train perplexity162.4628448486328
INFO:root:current mean train loss 12908.185415441842
INFO:root:current train perplexity162.15736389160156
INFO:root:current mean train loss 12905.103895879425
INFO:root:current train perplexity162.0990753173828
INFO:root:current mean train loss 12900.223304003577
INFO:root:current train perplexity161.83277893066406
INFO:root:current mean train loss 12902.790384948916
INFO:root:current train perplexity161.82737731933594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.34s/it]
INFO:root:final mean train loss: 12892.611133452385
INFO:root:final train perplexity: 161.82383728027344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 12549.19709247562
INFO:root:eval perplexity: 159.89659118652344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 12807.569827681738
INFO:root:eval perplexity: 188.1409149169922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [20:35:45<12:22:42, 594.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12926.96000039457
INFO:root:current train perplexity161.56146240234375
INFO:root:current mean train loss 12927.835515467965
INFO:root:current train perplexity161.54273986816406
INFO:root:current mean train loss 12900.71074806647
INFO:root:current train perplexity161.03091430664062
INFO:root:current mean train loss 12883.985373590225
INFO:root:current train perplexity160.8045654296875
INFO:root:current mean train loss 12863.937590023797
INFO:root:current train perplexity160.57989501953125
INFO:root:current mean train loss 12877.379046457638
INFO:root:current train perplexity160.9476318359375
INFO:root:current mean train loss 12878.88728037822
INFO:root:current train perplexity160.8882293701172
INFO:root:current mean train loss 12887.84126153786
INFO:root:current train perplexity160.9334259033203
INFO:root:current mean train loss 12887.788445494994
INFO:root:current train perplexity160.88677978515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.33s/it]
INFO:root:final mean train loss: 12879.926745014805
INFO:root:final train perplexity: 161.01602172851562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 12549.552027925532
INFO:root:eval perplexity: 159.91946411132812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 12807.162975121897
INFO:root:eval perplexity: 188.10960388183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [20:45:38<12:12:17, 593.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12903.835658482143
INFO:root:current train perplexity160.72238159179688
INFO:root:current mean train loss 12894.313221013435
INFO:root:current train perplexity160.4731903076172
INFO:root:current mean train loss 12922.332899305555
INFO:root:current train perplexity161.12454223632812
INFO:root:current mean train loss 12947.443594767916
INFO:root:current train perplexity161.3315887451172
INFO:root:current mean train loss 12929.914019310503
INFO:root:current train perplexity161.16835021972656
INFO:root:current mean train loss 12919.979155109713
INFO:root:current train perplexity161.2446746826172
INFO:root:current mean train loss 12917.49052074753
INFO:root:current train perplexity161.4099884033203
INFO:root:current mean train loss 12909.16266879199
INFO:root:current train perplexity161.43185424804688
INFO:root:current mean train loss 12902.818223842163
INFO:root:current train perplexity161.3225860595703
INFO:root:current mean train loss 12895.502480705623
INFO:root:current train perplexity161.12246704101562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.05s/it]
INFO:root:final mean train loss: 12879.654220334945
INFO:root:final train perplexity: 160.99874877929688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 12546.81817237367
INFO:root:eval perplexity: 159.7427215576172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 12803.15845938608
INFO:root:eval perplexity: 187.8018341064453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [20:55:30<12:01:38, 593.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12829.752018229166
INFO:root:current train perplexity158.2604217529297
INFO:root:current mean train loss 12818.27804857337
INFO:root:current train perplexity160.18038940429688
INFO:root:current mean train loss 12822.051435319767
INFO:root:current train perplexity160.5433807373047
INFO:root:current mean train loss 12876.22318328373
INFO:root:current train perplexity160.6485137939453
INFO:root:current mean train loss 12880.21852880271
INFO:root:current train perplexity160.51712036132812
INFO:root:current mean train loss 12888.922263728762
INFO:root:current train perplexity160.70628356933594
INFO:root:current mean train loss 12886.822927782012
INFO:root:current train perplexity160.7292022705078
INFO:root:current mean train loss 12889.202182583042
INFO:root:current train perplexity160.77841186523438
INFO:root:current mean train loss 12895.380891727378
INFO:root:current train perplexity160.96551513671875
INFO:root:current mean train loss 12901.870797045765
INFO:root:current train perplexity161.02691650390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.17s/it]
INFO:root:final mean train loss: 12876.08128652265
INFO:root:final train perplexity: 160.7718963623047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 12543.871647828015
INFO:root:eval perplexity: 159.55255126953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 12800.773070423316
INFO:root:eval perplexity: 187.61878967285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [21:05:19<11:50:24, 592.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12874.72707201087
INFO:root:current train perplexity159.548828125
INFO:root:current mean train loss 12875.68362550813
INFO:root:current train perplexity161.01210021972656
INFO:root:current mean train loss 12857.458879274103
INFO:root:current train perplexity160.2112579345703
INFO:root:current mean train loss 12868.84994799729
INFO:root:current train perplexity160.27696228027344
INFO:root:current mean train loss 12882.973164154846
INFO:root:current train perplexity160.4438934326172
INFO:root:current mean train loss 12882.60755818296
INFO:root:current train perplexity160.5247802734375
INFO:root:current mean train loss 12877.902194835975
INFO:root:current train perplexity160.36135864257812
INFO:root:current mean train loss 12879.730545740405
INFO:root:current train perplexity160.3611297607422
INFO:root:current mean train loss 12871.12265411414
INFO:root:current train perplexity160.38858032226562
INFO:root:current mean train loss 12885.791425082949
INFO:root:current train perplexity160.64047241210938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.22s/it]
INFO:root:final mean train loss: 12873.758144255607
INFO:root:final train perplexity: 160.62461853027344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 12543.46231576906
INFO:root:eval perplexity: 159.52615356445312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 12800.67634225399
INFO:root:eval perplexity: 187.61135864257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [21:15:08<11:39:18, 590.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13001.034935735886
INFO:root:current train perplexity161.35227966308594
INFO:root:current mean train loss 12818.03047471374
INFO:root:current train perplexity159.6055908203125
INFO:root:current mean train loss 12842.694610727815
INFO:root:current train perplexity160.02496337890625
INFO:root:current mean train loss 12844.122760692031
INFO:root:current train perplexity160.1178436279297
INFO:root:current mean train loss 12839.878369253915
INFO:root:current train perplexity159.95339965820312
INFO:root:current mean train loss 12853.814107374059
INFO:root:current train perplexity160.42376708984375
INFO:root:current mean train loss 12853.32165430616
INFO:root:current train perplexity160.2684783935547
INFO:root:current mean train loss 12871.182613179719
INFO:root:current train perplexity160.4532928466797
INFO:root:current mean train loss 12886.036680439605
INFO:root:current train perplexity160.67770385742188
INFO:root:current mean train loss 12881.208750461534
INFO:root:current train perplexity160.59483337402344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.49s/it]
INFO:root:final mean train loss: 12873.377615405667
INFO:root:final train perplexity: 160.60049438476562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 12543.85472074468
INFO:root:eval perplexity: 159.55149841308594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 12801.212821365249
INFO:root:eval perplexity: 187.65252685546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [21:24:57<11:28:56, 590.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12876.478740985576
INFO:root:current train perplexity159.1974334716797
INFO:root:current mean train loss 12820.26632756295
INFO:root:current train perplexity159.8090057373047
INFO:root:current mean train loss 12863.283950869509
INFO:root:current train perplexity160.61505126953125
INFO:root:current mean train loss 12866.702128272493
INFO:root:current train perplexity161.2825927734375
INFO:root:current mean train loss 12870.499826487756
INFO:root:current train perplexity161.6372833251953
INFO:root:current mean train loss 12882.823910743275
INFO:root:current train perplexity161.98989868164062
INFO:root:current mean train loss 12885.177989595559
INFO:root:current train perplexity162.08462524414062
INFO:root:current mean train loss 12897.868479892591
INFO:root:current train perplexity162.30218505859375
INFO:root:current mean train loss 12899.337314464765
INFO:root:current train perplexity162.4009552001953
INFO:root:current mean train loss 12908.093162398496
INFO:root:current train perplexity162.41659545898438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.37s/it]
INFO:root:final mean train loss: 12901.93454053325
INFO:root:final train perplexity: 162.4200897216797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 12554.49431377438
INFO:root:eval perplexity: 160.23936462402344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 12814.34165142952
INFO:root:eval perplexity: 188.66250610351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [21:34:44<11:17:43, 589.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12889.632937167553
INFO:root:current train perplexity161.2852783203125
INFO:root:current mean train loss 12888.753886320153
INFO:root:current train perplexity161.6246337890625
INFO:root:current mean train loss 12893.600748038967
INFO:root:current train perplexity161.1175537109375
INFO:root:current mean train loss 12888.20918137608
INFO:root:current train perplexity160.86399841308594
INFO:root:current mean train loss 12896.932245787892
INFO:root:current train perplexity160.88677978515625
INFO:root:current mean train loss 12898.129291876143
INFO:root:current train perplexity160.87940979003906
INFO:root:current mean train loss 12898.220666900115
INFO:root:current train perplexity160.9456329345703
INFO:root:current mean train loss 12890.852673715695
INFO:root:current train perplexity160.76905822753906
INFO:root:current mean train loss 12882.148521666544
INFO:root:current train perplexity160.65135192871094
INFO:root:current mean train loss 12884.059157825699
INFO:root:current train perplexity160.62477111816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.70s/it]
INFO:root:final mean train loss: 12875.014478621944
INFO:root:final train perplexity: 160.7042236328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 12547.820506427304
INFO:root:eval perplexity: 159.80747985839844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 12802.92203429743
INFO:root:eval perplexity: 187.78366088867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [21:44:28<11:06:20, 587.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12945.846200284092
INFO:root:current train perplexity161.35073852539062
INFO:root:current mean train loss 12947.658518145161
INFO:root:current train perplexity161.9095001220703
INFO:root:current mean train loss 12917.211580882353
INFO:root:current train perplexity161.42884826660156
INFO:root:current mean train loss 12919.651570752641
INFO:root:current train perplexity161.81326293945312
INFO:root:current mean train loss 12912.323501888737
INFO:root:current train perplexity161.8397216796875
INFO:root:current mean train loss 12904.118561725789
INFO:root:current train perplexity162.01708984375
INFO:root:current mean train loss 12904.895615159829
INFO:root:current train perplexity161.78309631347656
INFO:root:current mean train loss 12897.670375879554
INFO:root:current train perplexity161.63165283203125
INFO:root:current mean train loss 12895.48556743421
INFO:root:current train perplexity161.442626953125
INFO:root:current mean train loss 12896.479763170812
INFO:root:current train perplexity161.41445922851562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.10s/it]
INFO:root:final mean train loss: 12885.355322560956
INFO:root:final train perplexity: 161.3612060546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 12536.776200964096
INFO:root:eval perplexity: 159.09544372558594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 12796.14020944149
INFO:root:eval perplexity: 187.2635955810547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [21:54:16<10:56:16, 587.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12953.80017671131
INFO:root:current train perplexity161.00059509277344
INFO:root:current mean train loss 12922.746117714723
INFO:root:current train perplexity160.38108825683594
INFO:root:current mean train loss 12946.670074114782
INFO:root:current train perplexity160.8282470703125
INFO:root:current mean train loss 12925.235529119318
INFO:root:current train perplexity160.84527587890625
INFO:root:current mean train loss 12897.291011406587
INFO:root:current train perplexity160.49468994140625
INFO:root:current mean train loss 12897.286982751442
INFO:root:current train perplexity160.4668426513672
INFO:root:current mean train loss 12895.57772583192
INFO:root:current train perplexity160.41122436523438
INFO:root:current mean train loss 12899.968101091497
INFO:root:current train perplexity160.59153747558594
INFO:root:current mean train loss 12888.229983297726
INFO:root:current train perplexity160.56748962402344
INFO:root:current mean train loss 12883.051521531022
INFO:root:current train perplexity160.52561950683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.67s/it]
INFO:root:final mean train loss: 12871.581964308216
INFO:root:final train perplexity: 160.48681640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 12540.362263131648
INFO:root:eval perplexity: 159.32630920410156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 12798.002437943262
INFO:root:eval perplexity: 187.40634155273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [22:04:01<10:45:50, 587.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12845.204637984154
INFO:root:current train perplexity159.23068237304688
INFO:root:current mean train loss 12859.642452485381
INFO:root:current train perplexity160.1376190185547
INFO:root:current mean train loss 12872.1673201107
INFO:root:current train perplexity160.24058532714844
INFO:root:current mean train loss 12874.218236712433
INFO:root:current train perplexity160.51321411132812
INFO:root:current mean train loss 12881.672808021496
INFO:root:current train perplexity160.42315673828125
INFO:root:current mean train loss 12867.06838331874
INFO:root:current train perplexity160.551025390625
INFO:root:current mean train loss 12874.854097778501
INFO:root:current train perplexity160.83599853515625
INFO:root:current mean train loss 12873.821890706064
INFO:root:current train perplexity160.81092834472656
INFO:root:current mean train loss 12885.167391333596
INFO:root:current train perplexity160.97402954101562
INFO:root:current mean train loss 12890.489129079235
INFO:root:current train perplexity161.1127166748047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.11s/it]
INFO:root:final mean train loss: 12881.825570137271
INFO:root:final train perplexity: 161.13661193847656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 12559.22264239805
INFO:root:eval perplexity: 160.5459747314453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 12818.011254709663
INFO:root:eval perplexity: 188.94590759277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [22:13:51<10:36:49, 587.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12875.89000692247
INFO:root:current train perplexity161.74197387695312
INFO:root:current mean train loss 12901.703277758379
INFO:root:current train perplexity161.5731658935547
INFO:root:current mean train loss 12905.068016353047
INFO:root:current train perplexity161.3731231689453
INFO:root:current mean train loss 12902.966673194262
INFO:root:current train perplexity161.36404418945312
INFO:root:current mean train loss 12907.088251484212
INFO:root:current train perplexity161.33897399902344
INFO:root:current mean train loss 12897.43206228411
INFO:root:current train perplexity161.27220153808594
INFO:root:current mean train loss 12900.85972017673
INFO:root:current train perplexity161.3148956298828
INFO:root:current mean train loss 12895.669836629493
INFO:root:current train perplexity161.25636291503906
INFO:root:current mean train loss 12895.640062837741
INFO:root:current train perplexity161.2648162841797
INFO:root:current mean train loss 12893.364575020749
INFO:root:current train perplexity161.2924346923828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.01s/it]
INFO:root:final mean train loss: 12884.921407638058
INFO:root:final train perplexity: 161.33358764648438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 12565.99830313608
INFO:root:eval perplexity: 160.9866180419922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 12824.79121647828
INFO:root:eval perplexity: 189.47064208984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [22:23:37<10:26:34, 587.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12867.401479436063
INFO:root:current train perplexity161.245361328125
INFO:root:current mean train loss 12898.278435202206
INFO:root:current train perplexity161.05955505371094
INFO:root:current mean train loss 12897.58808117378
INFO:root:current train perplexity161.1332244873047
INFO:root:current mean train loss 12886.083171834625
INFO:root:current train perplexity161.255126953125
INFO:root:current mean train loss 12882.501255293892
INFO:root:current train perplexity161.10894775390625
INFO:root:current mean train loss 12888.628941186647
INFO:root:current train perplexity161.2120819091797
INFO:root:current mean train loss 12892.308252592795
INFO:root:current train perplexity161.11517333984375
INFO:root:current mean train loss 12879.538695203304
INFO:root:current train perplexity160.9097900390625
INFO:root:current mean train loss 12885.50351320286
INFO:root:current train perplexity160.88455200195312
INFO:root:current mean train loss 12886.75191948455
INFO:root:current train perplexity160.85862731933594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.46s/it]
INFO:root:final mean train loss: 12877.430256259056
INFO:root:final train perplexity: 160.8575439453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 12540.405640514184
INFO:root:eval perplexity: 159.32904052734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 12801.198221409575
INFO:root:eval perplexity: 187.65135192871094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [22:33:25<10:16:53, 587.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12957.051120476974
INFO:root:current train perplexity160.9799346923828
INFO:root:current mean train loss 12894.010231370192
INFO:root:current train perplexity160.802490234375
INFO:root:current mean train loss 12878.018942002118
INFO:root:current train perplexity160.48031616210938
INFO:root:current mean train loss 12861.299310225475
INFO:root:current train perplexity160.2460174560547
INFO:root:current mean train loss 12880.941532512627
INFO:root:current train perplexity160.61099243164062
INFO:root:current mean train loss 12869.863025210085
INFO:root:current train perplexity160.47511291503906
INFO:root:current mean train loss 12863.63014697617
INFO:root:current train perplexity160.37306213378906
INFO:root:current mean train loss 12860.543643130895
INFO:root:current train perplexity160.29232788085938
INFO:root:current mean train loss 12874.367318435754
INFO:root:current train perplexity160.32717895507812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.96s/it]
INFO:root:final mean train loss: 12871.020220110493
INFO:root:final train perplexity: 160.45123291015625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 12534.478841145834
INFO:root:eval perplexity: 158.94772338867188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 12794.912213264628
INFO:root:eval perplexity: 187.169677734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [22:43:13<10:07:06, 587.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12949.028645833334
INFO:root:current train perplexity158.03697204589844
INFO:root:current mean train loss 12856.464910118326
INFO:root:current train perplexity159.7025909423828
INFO:root:current mean train loss 12841.590805880542
INFO:root:current train perplexity159.517333984375
INFO:root:current mean train loss 12871.130788469472
INFO:root:current train perplexity160.1556396484375
INFO:root:current mean train loss 12876.497995987127
INFO:root:current train perplexity160.05258178710938
INFO:root:current mean train loss 12868.16587972167
INFO:root:current train perplexity160.0233612060547
INFO:root:current mean train loss 12878.328662676202
INFO:root:current train perplexity160.18023681640625
INFO:root:current mean train loss 12881.354250477863
INFO:root:current train perplexity160.22409057617188
INFO:root:current mean train loss 12887.380680602038
INFO:root:current train perplexity160.332763671875
INFO:root:current mean train loss 12885.382300967261
INFO:root:current train perplexity160.3258819580078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.53s/it]
INFO:root:final mean train loss: 12868.069154308689
INFO:root:final train perplexity: 160.26443481445312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 12530.82269503546
INFO:root:eval perplexity: 158.71287536621094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 12791.534525986259
INFO:root:eval perplexity: 186.91139221191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [22:52:58<9:56:38, 586.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12919.328924005682
INFO:root:current train perplexity163.34005737304688
INFO:root:current mean train loss 12899.309473536036
INFO:root:current train perplexity160.3574676513672
INFO:root:current mean train loss 12915.527987077903
INFO:root:current train perplexity160.05166625976562
INFO:root:current mean train loss 12910.381591011857
INFO:root:current train perplexity160.03518676757812
INFO:root:current mean train loss 12900.777735800639
INFO:root:current train perplexity160.40847778320312
INFO:root:current mean train loss 12926.974565420132
INFO:root:current train perplexity160.687744140625
INFO:root:current mean train loss 12923.97034510536
INFO:root:current train perplexity160.8182830810547
INFO:root:current mean train loss 12903.163184829906
INFO:root:current train perplexity160.48268127441406
INFO:root:current mean train loss 12897.33937533716
INFO:root:current train perplexity160.3674774169922
INFO:root:current mean train loss 12884.779628112994
INFO:root:current train perplexity160.3005828857422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.31s/it]
INFO:root:final mean train loss: 12866.17825218939
INFO:root:final train perplexity: 160.14495849609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 12528.974907191932
INFO:root:eval perplexity: 158.5943145751953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 12789.788203679078
INFO:root:eval perplexity: 186.77784729003906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [23:02:47<9:47:24, 587.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12803.081877055922
INFO:root:current train perplexity160.5958251953125
INFO:root:current mean train loss 12843.59118960084
INFO:root:current train perplexity160.1693878173828
INFO:root:current mean train loss 12846.647188926941
INFO:root:current train perplexity160.01708984375
INFO:root:current mean train loss 12884.344711255877
INFO:root:current train perplexity160.44534301757812
INFO:root:current mean train loss 12865.98072512679
INFO:root:current train perplexity160.13563537597656
INFO:root:current mean train loss 12865.450955488319
INFO:root:current train perplexity160.22195434570312
INFO:root:current mean train loss 12877.441676027363
INFO:root:current train perplexity160.27406311035156
INFO:root:current mean train loss 12884.372384062066
INFO:root:current train perplexity160.28567504882812
INFO:root:current mean train loss 12882.484141292734
INFO:root:current train perplexity160.2112579345703
INFO:root:current mean train loss 12876.260547725109
INFO:root:current train perplexity160.1148681640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.88s/it]
INFO:root:final mean train loss: 12865.037766979587
INFO:root:final train perplexity: 160.07289123535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 12530.35521248892
INFO:root:eval perplexity: 158.68283081054688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 12792.356195977394
INFO:root:eval perplexity: 186.97406005859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [23:12:34<9:37:38, 587.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12994.330186631945
INFO:root:current train perplexity159.19256591796875
INFO:root:current mean train loss 12826.690914124016
INFO:root:current train perplexity159.03567504882812
INFO:root:current mean train loss 12855.61202075303
INFO:root:current train perplexity159.76695251464844
INFO:root:current mean train loss 12882.064046970565
INFO:root:current train perplexity160.13319396972656
INFO:root:current mean train loss 12875.916255763319
INFO:root:current train perplexity159.8298797607422
INFO:root:current mean train loss 12871.90347967564
INFO:root:current train perplexity159.7427978515625
INFO:root:current mean train loss 12872.03694739334
INFO:root:current train perplexity159.86090087890625
INFO:root:current mean train loss 12884.298445291008
INFO:root:current train perplexity160.05433654785156
INFO:root:current mean train loss 12882.468666159688
INFO:root:current train perplexity160.07135009765625
INFO:root:current mean train loss 12880.630671858145
INFO:root:current train perplexity160.1483917236328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.88s/it]
INFO:root:final mean train loss: 12865.117785299977
INFO:root:final train perplexity: 160.0780029296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 12541.231798537234
INFO:root:eval perplexity: 159.38238525390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 12801.021366633422
INFO:root:eval perplexity: 187.63775634765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [23:22:23<9:28:14, 587.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13106.976785714285
INFO:root:current train perplexity163.14024353027344
INFO:root:current mean train loss 12984.638151041667
INFO:root:current train perplexity161.61793518066406
INFO:root:current mean train loss 12965.03263380984
INFO:root:current train perplexity160.92306518554688
INFO:root:current mean train loss 12912.318263176307
INFO:root:current train perplexity160.45054626464844
INFO:root:current mean train loss 12897.807114313937
INFO:root:current train perplexity160.4080810546875
INFO:root:current mean train loss 12885.303824109229
INFO:root:current train perplexity160.05593872070312
INFO:root:current mean train loss 12888.962032480315
INFO:root:current train perplexity160.08433532714844
INFO:root:current mean train loss 12891.662480070154
INFO:root:current train perplexity160.1755828857422
INFO:root:current mean train loss 12889.204996257486
INFO:root:current train perplexity160.14915466308594
INFO:root:current mean train loss 12879.8953407002
INFO:root:current train perplexity160.01922607421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.84s/it]
INFO:root:final mean train loss: 12864.277769027218
INFO:root:final train perplexity: 160.02503967285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 12527.556107324912
INFO:root:eval perplexity: 158.50344848632812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 12786.210466533688
INFO:root:eval perplexity: 186.5048065185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [23:32:10<9:18:22, 587.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12931.537767986918
INFO:root:current train perplexity159.87379455566406
INFO:root:current mean train loss 12972.188531195367
INFO:root:current train perplexity160.7115020751953
INFO:root:current mean train loss 12934.452116287293
INFO:root:current train perplexity160.39837646484375
INFO:root:current mean train loss 12915.648804778608
INFO:root:current train perplexity160.44625854492188
INFO:root:current mean train loss 12892.72076484904
INFO:root:current train perplexity160.40350341796875
INFO:root:current mean train loss 12897.206903559507
INFO:root:current train perplexity160.46133422851562
INFO:root:current mean train loss 12889.23698119168
INFO:root:current train perplexity160.24342346191406
INFO:root:current mean train loss 12883.124880394094
INFO:root:current train perplexity160.11959838867188
INFO:root:current mean train loss 12873.300651505042
INFO:root:current train perplexity160.08616638183594
INFO:root:current mean train loss 12874.270689040959
INFO:root:current train perplexity160.02694702148438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.60s/it]
INFO:root:final mean train loss: 12862.969372164818
INFO:root:final train perplexity: 159.9423370361328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 12527.91966561392
INFO:root:eval perplexity: 158.5267333984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 12787.936461103724
INFO:root:eval perplexity: 186.63645935058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [23:41:59<9:08:56, 588.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12859.487228094362
INFO:root:current train perplexity159.38534545898438
INFO:root:current mean train loss 12885.47700227649
INFO:root:current train perplexity159.7701416015625
INFO:root:current mean train loss 12883.911681399402
INFO:root:current train perplexity159.6352081298828
INFO:root:current mean train loss 12880.635669849536
INFO:root:current train perplexity159.82073974609375
INFO:root:current mean train loss 12885.789162105044
INFO:root:current train perplexity159.8335418701172
INFO:root:current mean train loss 12882.839586759868
INFO:root:current train perplexity159.7351837158203
INFO:root:current mean train loss 12881.513347854263
INFO:root:current train perplexity159.72291564941406
INFO:root:current mean train loss 12886.028560877165
INFO:root:current train perplexity159.72984313964844
INFO:root:current mean train loss 12878.235273529304
INFO:root:current train perplexity159.75643920898438
INFO:root:current mean train loss 12876.172729363827
INFO:root:current train perplexity159.7571258544922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.87s/it]
INFO:root:final mean train loss: 12858.621303681404
INFO:root:final train perplexity: 159.66824340820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 12523.011358599291
INFO:root:eval perplexity: 158.2123565673828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 12783.515417220744
INFO:root:eval perplexity: 186.29930114746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [23:51:48<8:59:17, 588.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12871.380776615466
INFO:root:current train perplexity159.5644989013672
INFO:root:current mean train loss 12857.375589622641
INFO:root:current train perplexity159.21929931640625
INFO:root:current mean train loss 12827.318578064673
INFO:root:current train perplexity159.2410888671875
INFO:root:current mean train loss 12842.70815198468
INFO:root:current train perplexity159.26856994628906
INFO:root:current mean train loss 12850.708963099129
INFO:root:current train perplexity159.585205078125
INFO:root:current mean train loss 12846.037271844252
INFO:root:current train perplexity159.49717712402344
INFO:root:current mean train loss 12852.80617679486
INFO:root:current train perplexity159.54122924804688
INFO:root:current mean train loss 12853.755617486002
INFO:root:current train perplexity159.49452209472656
INFO:root:current mean train loss 12853.64095127874
INFO:root:current train perplexity159.39385986328125
INFO:root:current mean train loss 12863.874286162343
INFO:root:current train perplexity159.51901245117188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.93s/it]
INFO:root:final mean train loss: 12857.41526622157
INFO:root:final train perplexity: 159.59228515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 12523.000470966312
INFO:root:eval perplexity: 158.211669921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 12783.26933039672
INFO:root:eval perplexity: 186.2806396484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [24:01:35<8:49:11, 587.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12950.97557136194
INFO:root:current train perplexity159.94554138183594
INFO:root:current mean train loss 12897.75601726235
INFO:root:current train perplexity159.77487182617188
INFO:root:current mean train loss 12872.95736042837
INFO:root:current train perplexity159.57492065429688
INFO:root:current mean train loss 12865.131354308583
INFO:root:current train perplexity160.04159545898438
INFO:root:current mean train loss 12879.912621704363
INFO:root:current train perplexity160.21133422851562
INFO:root:current mean train loss 12864.297562210648
INFO:root:current train perplexity159.90809631347656
INFO:root:current mean train loss 12860.102000269397
INFO:root:current train perplexity159.74661254882812
INFO:root:current mean train loss 12864.459790325538
INFO:root:current train perplexity159.7350311279297
INFO:root:current mean train loss 12870.509347741854
INFO:root:current train perplexity159.74569702148438
INFO:root:current mean train loss 12871.598317727185
INFO:root:current train perplexity159.7560577392578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.87s/it]
INFO:root:final mean train loss: 12859.139592570644
INFO:root:final train perplexity: 159.70091247558594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 12524.925185616135
INFO:root:eval perplexity: 158.3348388671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 12784.914228723404
INFO:root:eval perplexity: 186.40602111816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [24:11:17<8:37:45, 586.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12827.574166666667
INFO:root:current train perplexity158.53822326660156
INFO:root:current mean train loss 12815.049308035714
INFO:root:current train perplexity158.96304321289062
INFO:root:current mean train loss 12874.383046875
INFO:root:current train perplexity159.83811950683594
INFO:root:current mean train loss 12877.3005546875
INFO:root:current train perplexity160.00686645507812
INFO:root:current mean train loss 12864.371184210526
INFO:root:current train perplexity159.73944091796875
INFO:root:current mean train loss 12866.940681046195
INFO:root:current train perplexity159.70501708984375
INFO:root:current mean train loss 12862.843566261574
INFO:root:current train perplexity159.66062927246094
INFO:root:current mean train loss 12871.944623235888
INFO:root:current train perplexity159.76473999023438
INFO:root:current mean train loss 12871.452938616072
INFO:root:current train perplexity159.7554473876953
INFO:root:current mean train loss 12867.861801883013
INFO:root:current train perplexity159.67137145996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.13s/it]
INFO:root:final mean train loss: 12858.766934302545
INFO:root:final train perplexity: 159.67745971679688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 12525.945367907801
INFO:root:eval perplexity: 158.40016174316406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 12786.986660571809
INFO:root:eval perplexity: 186.5640411376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [24:21:06<8:28:48, 587.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12855.059640907379
INFO:root:current train perplexity160.21713256835938
INFO:root:current mean train loss 12823.450488814891
INFO:root:current train perplexity159.64830017089844
INFO:root:current mean train loss 12844.58695547151
INFO:root:current train perplexity160.031982421875
INFO:root:current mean train loss 12883.376152496736
INFO:root:current train perplexity160.2090301513672
INFO:root:current mean train loss 12896.690354878365
INFO:root:current train perplexity160.1868133544922
INFO:root:current mean train loss 12875.269417345626
INFO:root:current train perplexity159.94821166992188
INFO:root:current mean train loss 12873.98782942899
INFO:root:current train perplexity159.70159912109375
INFO:root:current mean train loss 12863.898659502715
INFO:root:current train perplexity159.71066284179688
INFO:root:current mean train loss 12865.81976726182
INFO:root:current train perplexity159.64662170410156
INFO:root:current mean train loss 12870.89780963886
INFO:root:current train perplexity159.79299926757812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.03s/it]
INFO:root:final mean train loss: 12860.817689711048
INFO:root:final train perplexity: 159.8067169189453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 12522.558143561613
INFO:root:eval perplexity: 158.18345642089844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 12784.515444924646
INFO:root:eval perplexity: 186.37562561035156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [24:30:54<8:19:12, 587.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12857.749001974587
INFO:root:current train perplexity160.0418243408203
INFO:root:current mean train loss 12832.818154859293
INFO:root:current train perplexity159.80108642578125
INFO:root:current mean train loss 12878.167109643471
INFO:root:current train perplexity160.30563354492188
INFO:root:current mean train loss 12863.003941216431
INFO:root:current train perplexity159.76808166503906
INFO:root:current mean train loss 12867.120912757764
INFO:root:current train perplexity159.7285614013672
INFO:root:current mean train loss 12873.148374709179
INFO:root:current train perplexity159.762451171875
INFO:root:current mean train loss 12875.62725132281
INFO:root:current train perplexity159.88880920410156
INFO:root:current mean train loss 12875.543576169406
INFO:root:current train perplexity159.9397430419922
INFO:root:current mean train loss 12874.509661502174
INFO:root:current train perplexity159.93936157226562
INFO:root:current mean train loss 12870.38647633388
INFO:root:current train perplexity159.7808837890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.26s/it]
INFO:root:final mean train loss: 12860.455014874859
INFO:root:final train perplexity: 159.7838592529297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 12522.734471963653
INFO:root:eval perplexity: 158.1947021484375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 12782.795919215425
INFO:root:eval perplexity: 186.2445831298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [24:40:40<8:08:59, 586.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12856.00620462437
INFO:root:current train perplexity159.375244140625
INFO:root:current mean train loss 12847.216762523556
INFO:root:current train perplexity159.25369262695312
INFO:root:current mean train loss 12869.559455999164
INFO:root:current train perplexity159.4777069091797
INFO:root:current mean train loss 12892.107101249218
INFO:root:current train perplexity159.8108367919922
INFO:root:current mean train loss 12877.035440020667
INFO:root:current train perplexity159.76329040527344
INFO:root:current mean train loss 12879.399956959516
INFO:root:current train perplexity159.86212158203125
INFO:root:current mean train loss 12875.542524476932
INFO:root:current train perplexity159.76214599609375
INFO:root:current mean train loss 12872.688765008996
INFO:root:current train perplexity159.71278381347656
INFO:root:current mean train loss 12873.862722903921
INFO:root:current train perplexity159.75772094726562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.09s/it]
INFO:root:final mean train loss: 12858.877023020099
INFO:root:final train perplexity: 159.68438720703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 12519.051896332003
INFO:root:eval perplexity: 157.9593048095703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 12782.067687555407
INFO:root:eval perplexity: 186.1890869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [24:50:29<7:59:44, 587.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12659.795619419643
INFO:root:current train perplexity160.8490447998047
INFO:root:current mean train loss 12904.36266063084
INFO:root:current train perplexity160.4694366455078
INFO:root:current mean train loss 12873.128953426933
INFO:root:current train perplexity159.5762176513672
INFO:root:current mean train loss 12838.833074613192
INFO:root:current train perplexity159.31703186035156
INFO:root:current mean train loss 12854.363797124539
INFO:root:current train perplexity159.2108612060547
INFO:root:current mean train loss 12851.734475160256
INFO:root:current train perplexity159.1608428955078
INFO:root:current mean train loss 12847.180934346685
INFO:root:current train perplexity159.26364135742188
INFO:root:current mean train loss 12853.5160780587
INFO:root:current train perplexity159.41848754882812
INFO:root:current mean train loss 12865.192145630033
INFO:root:current train perplexity159.6981658935547
INFO:root:current mean train loss 12861.55331363699
INFO:root:current train perplexity159.6776123046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.75s/it]
INFO:root:final mean train loss: 12859.450699836978
INFO:root:final train perplexity: 159.72047424316406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 12522.108862477837
INFO:root:eval perplexity: 158.15464782714844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 12783.681370511968
INFO:root:eval perplexity: 186.3120880126953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [25:00:18<7:50:24, 588.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12854.333658854166
INFO:root:current train perplexity158.7416229248047
INFO:root:current mean train loss 12866.39383491848
INFO:root:current train perplexity159.26075744628906
INFO:root:current mean train loss 12871.98773619186
INFO:root:current train perplexity159.3275146484375
INFO:root:current mean train loss 12888.861352926588
INFO:root:current train perplexity159.69078063964844
INFO:root:current mean train loss 12873.804506306476
INFO:root:current train perplexity159.66078186035156
INFO:root:current mean train loss 12876.233753033981
INFO:root:current train perplexity159.7762451171875
INFO:root:current mean train loss 12875.137609565549
INFO:root:current train perplexity159.73533630371094
INFO:root:current mean train loss 12873.757344023164
INFO:root:current train perplexity159.6964111328125
INFO:root:current mean train loss 12873.808761503067
INFO:root:current train perplexity159.75315856933594
INFO:root:current mean train loss 12865.91847250683
INFO:root:current train perplexity159.6185302734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.87s/it]
INFO:root:final mean train loss: 12858.700438714797
INFO:root:final train perplexity: 159.67318725585938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 12523.232740469859
INFO:root:eval perplexity: 158.22653198242188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 12781.485358488475
INFO:root:eval perplexity: 186.14488220214844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [25:10:06<7:40:33, 587.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12838.6064453125
INFO:root:current train perplexity160.5150604248047
INFO:root:current mean train loss 12852.61617917937
INFO:root:current train perplexity159.12525939941406
INFO:root:current mean train loss 12880.418362878363
INFO:root:current train perplexity159.4969482421875
INFO:root:current mean train loss 12878.788058726781
INFO:root:current train perplexity159.42730712890625
INFO:root:current mean train loss 12881.663312186023
INFO:root:current train perplexity159.5980682373047
INFO:root:current mean train loss 12879.883064576363
INFO:root:current train perplexity159.693603515625
INFO:root:current mean train loss 12877.889549683989
INFO:root:current train perplexity159.7827911376953
INFO:root:current mean train loss 12878.045707987552
INFO:root:current train perplexity159.82257080078125
INFO:root:current mean train loss 12879.255143862014
INFO:root:current train perplexity159.7708282470703
INFO:root:current mean train loss 12871.310255916509
INFO:root:current train perplexity159.71484375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.03s/it]
INFO:root:final mean train loss: 12858.692608248803
INFO:root:final train perplexity: 159.6727294921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 12521.652108266844
INFO:root:eval perplexity: 158.12547302246094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 12780.943110039894
INFO:root:eval perplexity: 186.10353088378906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [25:19:54<7:30:46, 587.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12810.965599798386
INFO:root:current train perplexity160.40020751953125
INFO:root:current mean train loss 12860.20384810353
INFO:root:current train perplexity160.45742797851562
INFO:root:current mean train loss 12876.709462087392
INFO:root:current train perplexity159.97125244140625
INFO:root:current mean train loss 12886.250755287008
INFO:root:current train perplexity159.91603088378906
INFO:root:current mean train loss 12887.512473263487
INFO:root:current train perplexity159.90496826171875
INFO:root:current mean train loss 12881.29169977048
INFO:root:current train perplexity159.61106872558594
INFO:root:current mean train loss 12883.176420426407
INFO:root:current train perplexity159.6404571533203
INFO:root:current mean train loss 12887.41244870041
INFO:root:current train perplexity159.6273651123047
INFO:root:current mean train loss 12872.591331509477
INFO:root:current train perplexity159.46554565429688
INFO:root:current mean train loss 12868.84272623523
INFO:root:current train perplexity159.47314453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.90s/it]
INFO:root:final mean train loss: 12853.19086333244
INFO:root:final train perplexity: 159.3265380859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 12517.883110316932
INFO:root:eval perplexity: 157.8845977783203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 12777.704018450799
INFO:root:eval perplexity: 185.85716247558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [25:29:46<7:21:50, 589.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12829.246168870191
INFO:root:current train perplexity159.5552215576172
INFO:root:current mean train loss 12865.29213972572
INFO:root:current train perplexity159.65599060058594
INFO:root:current mean train loss 12876.259524548901
INFO:root:current train perplexity159.90977478027344
INFO:root:current mean train loss 12873.767073999816
INFO:root:current train perplexity159.45809936523438
INFO:root:current mean train loss 12884.775619750142
INFO:root:current train perplexity159.4466094970703
INFO:root:current mean train loss 12869.976307035598
INFO:root:current train perplexity159.42312622070312
INFO:root:current mean train loss 12866.029478738752
INFO:root:current train perplexity159.35289001464844
INFO:root:current mean train loss 12862.26464050871
INFO:root:current train perplexity159.3058624267578
INFO:root:current mean train loss 12861.510010056614
INFO:root:current train perplexity159.31863403320312
INFO:root:current mean train loss 12865.756129775693
INFO:root:current train perplexity159.28392028808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.73s/it]
INFO:root:final mean train loss: 12852.208041775611
INFO:root:final train perplexity: 159.2646942138672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 12520.380339926862
INFO:root:eval perplexity: 158.04412841796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 12783.702453180407
INFO:root:eval perplexity: 186.31369018554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [25:39:33<7:11:40, 588.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12744.83338181516
INFO:root:current train perplexity158.1770477294922
INFO:root:current mean train loss 12854.865380527212
INFO:root:current train perplexity159.55833435058594
INFO:root:current mean train loss 12885.463701132338
INFO:root:current train perplexity159.51087951660156
INFO:root:current mean train loss 12862.04912081232
INFO:root:current train perplexity159.17709350585938
INFO:root:current mean train loss 12869.435391761046
INFO:root:current train perplexity159.5715789794922
INFO:root:current mean train loss 12884.582407949612
INFO:root:current train perplexity159.66580200195312
INFO:root:current mean train loss 12874.880782397122
INFO:root:current train perplexity159.5524139404297
INFO:root:current mean train loss 12878.570937395414
INFO:root:current train perplexity159.60963439941406
INFO:root:current mean train loss 12873.70254390496
INFO:root:current train perplexity159.42205810546875
INFO:root:current mean train loss 12863.007099929053
INFO:root:current train perplexity159.30198669433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.32s/it]
INFO:root:final mean train loss: 12851.672532112369
INFO:root:final train perplexity: 159.23114013671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 12518.459898603724
INFO:root:eval perplexity: 157.92149353027344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 12778.381150265957
INFO:root:eval perplexity: 185.90866088867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [25:49:23<7:02:08, 589.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12861.357563920454
INFO:root:current train perplexity158.7910614013672
INFO:root:current mean train loss 12827.270463709678
INFO:root:current train perplexity158.37289428710938
INFO:root:current mean train loss 12823.155292585785
INFO:root:current train perplexity158.67434692382812
INFO:root:current mean train loss 12806.857837257923
INFO:root:current train perplexity158.44647216796875
INFO:root:current mean train loss 12822.333269660028
INFO:root:current train perplexity158.8649139404297
INFO:root:current mean train loss 12841.761929898648
INFO:root:current train perplexity159.3076171875
INFO:root:current mean train loss 12854.033645932728
INFO:root:current train perplexity159.34339904785156
INFO:root:current mean train loss 12854.40825227649
INFO:root:current train perplexity159.25216674804688
INFO:root:current mean train loss 12850.644366776316
INFO:root:current train perplexity159.1793670654297
INFO:root:current mean train loss 12857.626989937828
INFO:root:current train perplexity159.176025390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.91s/it]
INFO:root:final mean train loss: 12850.608805994834
INFO:root:final train perplexity: 159.16433715820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 12515.467891179078
INFO:root:eval perplexity: 157.73048400878906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 12777.733848625887
INFO:root:eval perplexity: 185.85946655273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [25:59:10<6:51:51, 588.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12826.327411954366
INFO:root:current train perplexity159.247314453125
INFO:root:current mean train loss 12819.257518932132
INFO:root:current train perplexity158.92764282226562
INFO:root:current mean train loss 12814.094537191064
INFO:root:current train perplexity159.18817138671875
INFO:root:current mean train loss 12833.758689523072
INFO:root:current train perplexity159.1827850341797
INFO:root:current mean train loss 12852.283414045627
INFO:root:current train perplexity159.3544921875
INFO:root:current mean train loss 12848.955695631661
INFO:root:current train perplexity159.2331085205078
INFO:root:current mean train loss 12850.743246547418
INFO:root:current train perplexity159.18148803710938
INFO:root:current mean train loss 12857.829992371806
INFO:root:current train perplexity159.14004516601562
INFO:root:current mean train loss 12860.133294557503
INFO:root:current train perplexity159.123046875
INFO:root:current mean train loss 12865.006159543744
INFO:root:current train perplexity159.2037353515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.81s/it]
INFO:root:final mean train loss: 12849.664285721317
INFO:root:final train perplexity: 159.10507202148438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 12515.769205729166
INFO:root:eval perplexity: 157.74974060058594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 12777.10279532358
INFO:root:eval perplexity: 185.8115234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [26:09:01<6:42:35, 589.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12811.41953675176
INFO:root:current train perplexity158.6555938720703
INFO:root:current mean train loss 12842.581854212354
INFO:root:current train perplexity158.7970428466797
INFO:root:current mean train loss 12866.95069620618
INFO:root:current train perplexity159.19796752929688
INFO:root:current mean train loss 12869.809896710747
INFO:root:current train perplexity159.23971557617188
INFO:root:current mean train loss 12851.7409476181
INFO:root:current train perplexity159.093994140625
INFO:root:current mean train loss 12859.01210527036
INFO:root:current train perplexity159.26751708984375
INFO:root:current mean train loss 12868.711909696349
INFO:root:current train perplexity159.218994140625
INFO:root:current mean train loss 12866.229070403697
INFO:root:current train perplexity159.2239227294922
INFO:root:current mean train loss 12859.037326887199
INFO:root:current train perplexity159.15341186523438
INFO:root:current mean train loss 12857.15729294059
INFO:root:current train perplexity159.07594299316406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:39<00:00, 519.21s/it]
INFO:root:final mean train loss: 12849.226196535172
INFO:root:final train perplexity: 159.07752990722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 12515.577619403812
INFO:root:eval perplexity: 157.73748779296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 12778.331712655141
INFO:root:eval perplexity: 185.90493774414062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [26:18:58<6:34:20, 591.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12939.221333564083
INFO:root:current train perplexity160.1513671875
INFO:root:current mean train loss 12867.534419736383
INFO:root:current train perplexity158.9871368408203
INFO:root:current mean train loss 12838.984427503361
INFO:root:current train perplexity158.4388427734375
INFO:root:current mean train loss 12855.144466832948
INFO:root:current train perplexity158.78402709960938
INFO:root:current mean train loss 12841.85561757894
INFO:root:current train perplexity158.6587677001953
INFO:root:current mean train loss 12851.853446472905
INFO:root:current train perplexity158.98471069335938
INFO:root:current mean train loss 12867.01727178065
INFO:root:current train perplexity159.1073455810547
INFO:root:current mean train loss 12854.914428554237
INFO:root:current train perplexity159.02102661132812
INFO:root:current mean train loss 12856.016118280717
INFO:root:current train perplexity159.03005981445312
INFO:root:current mean train loss 12858.783674947332
INFO:root:current train perplexity159.01026916503906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.19s/it]
INFO:root:final mean train loss: 12848.3438536121
INFO:root:final train perplexity: 159.0220947265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 12515.949516566932
INFO:root:eval perplexity: 157.76126098632812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 12777.681425919769
INFO:root:eval perplexity: 185.85548400878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [26:28:51<6:24:40, 591.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12911.186893857759
INFO:root:current train perplexity159.18490600585938
INFO:root:current mean train loss 12848.6150672627
INFO:root:current train perplexity158.84877014160156
INFO:root:current mean train loss 12866.05832834277
INFO:root:current train perplexity159.28111267089844
INFO:root:current mean train loss 12873.36896146237
INFO:root:current train perplexity159.52622985839844
INFO:root:current mean train loss 12864.964839739476
INFO:root:current train perplexity159.30966186523438
INFO:root:current mean train loss 12871.386101535882
INFO:root:current train perplexity159.3121795654297
INFO:root:current mean train loss 12860.495837882096
INFO:root:current train perplexity159.20828247070312
INFO:root:current mean train loss 12866.29173780972
INFO:root:current train perplexity159.21664428710938
INFO:root:current mean train loss 12854.198303841953
INFO:root:current train perplexity159.13299560546875
INFO:root:current mean train loss 12858.884845768427
INFO:root:current train perplexity159.09210205078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.34s/it]
INFO:root:final mean train loss: 12849.625782382103
INFO:root:final train perplexity: 159.10256958007812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 12516.8672152039
INFO:root:eval perplexity: 157.81971740722656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 12778.276921265515
INFO:root:eval perplexity: 185.90077209472656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [26:38:44<6:15:12, 592.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12938.439288651316
INFO:root:current train perplexity160.22515869140625
INFO:root:current mean train loss 12924.982802483974
INFO:root:current train perplexity159.9311981201172
INFO:root:current mean train loss 12890.01227820445
INFO:root:current train perplexity159.48843383789062
INFO:root:current mean train loss 12878.195443532437
INFO:root:current train perplexity159.35775756835938
INFO:root:current mean train loss 12878.94837042298
INFO:root:current train perplexity159.3935546875
INFO:root:current mean train loss 12882.357630317752
INFO:root:current train perplexity159.26181030273438
INFO:root:current mean train loss 12873.228675809352
INFO:root:current train perplexity159.16122436523438
INFO:root:current mean train loss 12864.625809502752
INFO:root:current train perplexity159.0600128173828
INFO:root:current mean train loss 12861.062665851956
INFO:root:current train perplexity158.98873901367188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.60s/it]
INFO:root:final mean train loss: 12848.376315209174
INFO:root:final train perplexity: 159.0242156982422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 12516.124944592199
INFO:root:eval perplexity: 157.77230834960938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 12777.411714594415
INFO:root:eval perplexity: 185.8350067138672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [26:48:36<6:05:07, 592.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12705.117838541666
INFO:root:current train perplexity153.0961151123047
INFO:root:current mean train loss 12820.265880992112
INFO:root:current train perplexity159.07579040527344
INFO:root:current mean train loss 12855.500702355295
INFO:root:current train perplexity159.22315979003906
INFO:root:current mean train loss 12889.295089469884
INFO:root:current train perplexity159.4901123046875
INFO:root:current mean train loss 12880.102337934242
INFO:root:current train perplexity159.53269958496094
INFO:root:current mean train loss 12876.059463531312
INFO:root:current train perplexity159.2371368408203
INFO:root:current mean train loss 12859.981370815194
INFO:root:current train perplexity158.87232971191406
INFO:root:current mean train loss 12862.091605174253
INFO:root:current train perplexity158.96084594726562
INFO:root:current mean train loss 12856.453545785336
INFO:root:current train perplexity158.9688720703125
INFO:root:current mean train loss 12859.783560008305
INFO:root:current train perplexity158.98501586914062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:32<00:00, 512.97s/it]
INFO:root:final mean train loss: 12847.609834978657
INFO:root:final train perplexity: 158.9759979248047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 12516.845405308068
INFO:root:eval perplexity: 157.818359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 12777.721728169327
INFO:root:eval perplexity: 185.85858154296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [26:58:26<5:54:50, 591.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13034.050248579546
INFO:root:current train perplexity162.47470092773438
INFO:root:current mean train loss 12856.740454321509
INFO:root:current train perplexity159.2687225341797
INFO:root:current mean train loss 12884.804511626186
INFO:root:current train perplexity159.08792114257812
INFO:root:current mean train loss 12842.28145096463
INFO:root:current train perplexity158.518798828125
INFO:root:current mean train loss 12849.18311616104
INFO:root:current train perplexity158.651123046875
INFO:root:current mean train loss 12840.005693110934
INFO:root:current train perplexity158.53126525878906
INFO:root:current mean train loss 12845.799998082037
INFO:root:current train perplexity158.69032287597656
INFO:root:current mean train loss 12838.41804429281
INFO:root:current train perplexity158.8221893310547
INFO:root:current mean train loss 12847.418273398967
INFO:root:current train perplexity158.98532104492188
INFO:root:current mean train loss 12854.641230661704
INFO:root:current train perplexity159.029296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.35s/it]
INFO:root:final mean train loss: 12848.21239717545
INFO:root:final train perplexity: 159.01390075683594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 12514.109645113032
INFO:root:eval perplexity: 157.6438751220703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 12776.594075520834
INFO:root:eval perplexity: 185.7729034423828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [27:08:17<5:44:57, 591.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12583.251798930922
INFO:root:current train perplexity156.28787231445312
INFO:root:current mean train loss 12807.832589285714
INFO:root:current train perplexity159.58253479003906
INFO:root:current mean train loss 12874.008503674371
INFO:root:current train perplexity159.6444091796875
INFO:root:current mean train loss 12848.13962700823
INFO:root:current train perplexity159.07540893554688
INFO:root:current mean train loss 12861.132980310262
INFO:root:current train perplexity159.25611877441406
INFO:root:current mean train loss 12864.148678347785
INFO:root:current train perplexity159.27890014648438
INFO:root:current mean train loss 12872.22313269891
INFO:root:current train perplexity159.45611572265625
INFO:root:current mean train loss 12854.914612580407
INFO:root:current train perplexity159.2644805908203
INFO:root:current mean train loss 12857.243698250535
INFO:root:current train perplexity159.47528076171875
INFO:root:current mean train loss 12858.833145955183
INFO:root:current train perplexity159.45619201660156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.42s/it]
INFO:root:final mean train loss: 12854.993821174869
INFO:root:final train perplexity: 159.43992614746094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 12520.998760250443
INFO:root:eval perplexity: 158.08370971679688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 12781.21722628546
INFO:root:eval perplexity: 186.1244659423828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [27:18:08<5:35:06, 591.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12854.350947627316
INFO:root:current train perplexity160.64706420898438
INFO:root:current mean train loss 12947.117456631398
INFO:root:current train perplexity160.85723876953125
INFO:root:current mean train loss 12909.332680857655
INFO:root:current train perplexity160.27825927734375
INFO:root:current mean train loss 12876.262423547401
INFO:root:current train perplexity159.50509643554688
INFO:root:current mean train loss 12882.930288989315
INFO:root:current train perplexity159.7178955078125
INFO:root:current mean train loss 12869.267192688567
INFO:root:current train perplexity159.47573852539062
INFO:root:current mean train loss 12873.814383036783
INFO:root:current train perplexity159.341796875
INFO:root:current mean train loss 12871.597204908872
INFO:root:current train perplexity159.41749572753906
INFO:root:current mean train loss 12878.638015322702
INFO:root:current train perplexity159.5535430908203
INFO:root:current mean train loss 12864.993824585355
INFO:root:current train perplexity159.45384216308594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.82s/it]
INFO:root:final mean train loss: 12854.72220734627
INFO:root:final train perplexity: 159.42282104492188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12521.3681363586
INFO:root:eval perplexity: 158.1072235107422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 12780.332855441045
INFO:root:eval perplexity: 186.05711364746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [27:28:00<5:25:17, 591.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12998.0919921875
INFO:root:current train perplexity161.82568359375
INFO:root:current mean train loss 12954.63880931713
INFO:root:current train perplexity160.69334411621094
INFO:root:current mean train loss 12906.985397273937
INFO:root:current train perplexity159.7677001953125
INFO:root:current mean train loss 12903.347495918842
INFO:root:current train perplexity159.57073974609375
INFO:root:current mean train loss 12900.857361260776
INFO:root:current train perplexity159.56671142578125
INFO:root:current mean train loss 12876.569323160047
INFO:root:current train perplexity159.24571228027344
INFO:root:current mean train loss 12859.187756828249
INFO:root:current train perplexity159.10765075683594
INFO:root:current mean train loss 12859.703284438776
INFO:root:current train perplexity159.14772033691406
INFO:root:current mean train loss 12856.149001216318
INFO:root:current train perplexity159.1956787109375
INFO:root:current mean train loss 12861.933927974598
INFO:root:current train perplexity159.13414001464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 516.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 516.00s/it]
INFO:root:final mean train loss: 12850.334706460277
INFO:root:final train perplexity: 159.14710998535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 12518.786804632093
INFO:root:eval perplexity: 157.94235229492188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 12779.52599318484
INFO:root:eval perplexity: 185.99581909179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [27:37:52<5:15:35, 591.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12840.80941133721
INFO:root:current train perplexity158.21710205078125
INFO:root:current mean train loss 12916.902623743445
INFO:root:current train perplexity159.05455017089844
INFO:root:current mean train loss 12877.854986496914
INFO:root:current train perplexity158.82528686523438
INFO:root:current mean train loss 12865.985943763666
INFO:root:current train perplexity159.05181884765625
INFO:root:current mean train loss 12863.932954465294
INFO:root:current train perplexity158.86695861816406
INFO:root:current mean train loss 12867.741059867058
INFO:root:current train perplexity158.92430114746094
INFO:root:current mean train loss 12884.128139276341
INFO:root:current train perplexity159.28672790527344
INFO:root:current mean train loss 12874.65262370668
INFO:root:current train perplexity159.30860900878906
INFO:root:current mean train loss 12857.8488668168
INFO:root:current train perplexity159.0526580810547
INFO:root:current mean train loss 12854.726649489661
INFO:root:current train perplexity159.01361083984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.92s/it]
INFO:root:final mean train loss: 12848.774128821588
INFO:root:final train perplexity: 159.04916381835938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 12517.57829814938
INFO:root:eval perplexity: 157.86509704589844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 12779.343438331118
INFO:root:eval perplexity: 185.9818115234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [27:47:45<5:05:51, 591.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12889.017884497549
INFO:root:current train perplexity157.6585235595703
INFO:root:current mean train loss 12938.38286423841
INFO:root:current train perplexity159.75033569335938
INFO:root:current mean train loss 12911.071296843875
INFO:root:current train perplexity159.76695251464844
INFO:root:current mean train loss 12885.129048143697
INFO:root:current train perplexity159.40023803710938
INFO:root:current mean train loss 12873.865396774529
INFO:root:current train perplexity159.25042724609375
INFO:root:current mean train loss 12861.663911850612
INFO:root:current train perplexity159.1912841796875
INFO:root:current mean train loss 12873.46142953149
INFO:root:current train perplexity159.3854217529297
INFO:root:current mean train loss 12866.373137899467
INFO:root:current train perplexity159.31947326660156
INFO:root:current mean train loss 12860.671483686472
INFO:root:current train perplexity159.1981201171875
INFO:root:current mean train loss 12856.265584951696
INFO:root:current train perplexity159.12069702148438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.97s/it]
INFO:root:final mean train loss: 12849.939510960732
INFO:root:final train perplexity: 159.12229919433594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.59s/it]
INFO:root:eval mean loss: 12524.864174700799
INFO:root:eval perplexity: 158.33091735839844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 12786.334912455673
INFO:root:eval perplexity: 186.51431274414062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [27:57:42<4:56:45, 593.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12810.021087129237
INFO:root:current train perplexity158.59786987304688
INFO:root:current mean train loss 12879.806063286163
INFO:root:current train perplexity159.28611755371094
INFO:root:current mean train loss 12871.926286498552
INFO:root:current train perplexity158.99154663085938
INFO:root:current mean train loss 12853.492848515843
INFO:root:current train perplexity158.81651306152344
INFO:root:current mean train loss 12869.65545215482
INFO:root:current train perplexity159.26553344726562
INFO:root:current mean train loss 12867.708573834414
INFO:root:current train perplexity159.17625427246094
INFO:root:current mean train loss 12864.19693516455
INFO:root:current train perplexity159.24139404296875
INFO:root:current mean train loss 12859.095743010952
INFO:root:current train perplexity159.1197967529297
INFO:root:current mean train loss 12849.888944721333
INFO:root:current train perplexity158.89588928222656
INFO:root:current mean train loss 12852.705698277829
INFO:root:current train perplexity158.95326232910156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.76s/it]
INFO:root:final mean train loss: 12849.833696180774
INFO:root:final train perplexity: 159.11569213867188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 12524.75508366578
INFO:root:eval perplexity: 158.3240509033203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 12786.147149268618
INFO:root:eval perplexity: 186.5
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [28:07:33<4:46:27, 592.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13005.751603311568
INFO:root:current train perplexity161.34474182128906
INFO:root:current mean train loss 12931.144215475299
INFO:root:current train perplexity160.7734375
INFO:root:current mean train loss 12919.312152533941
INFO:root:current train perplexity160.25900268554688
INFO:root:current mean train loss 12897.154661422854
INFO:root:current train perplexity160.0011444091797
INFO:root:current mean train loss 12870.925281467478
INFO:root:current train perplexity159.60110473632812
INFO:root:current mean train loss 12867.391586061507
INFO:root:current train perplexity159.40951538085938
INFO:root:current mean train loss 12873.264254591455
INFO:root:current train perplexity159.352294921875
INFO:root:current mean train loss 12866.98114101206
INFO:root:current train perplexity159.13626098632812
INFO:root:current mean train loss 12864.589826854455
INFO:root:current train perplexity159.0772247314453
INFO:root:current mean train loss 12859.912216423216
INFO:root:current train perplexity159.08860778808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.42s/it]
INFO:root:final mean train loss: 12849.31705179522
INFO:root:final train perplexity: 159.08322143554688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12517.173190935284
INFO:root:eval perplexity: 157.83935546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 12778.619653147163
INFO:root:eval perplexity: 185.9269256591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [28:17:24<4:36:28, 592.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12814.435533854166
INFO:root:current train perplexity159.10902404785156
INFO:root:current mean train loss 12819.496127232143
INFO:root:current train perplexity158.68206787109375
INFO:root:current mean train loss 12792.495678267045
INFO:root:current train perplexity158.1819610595703
INFO:root:current mean train loss 12815.8115390625
INFO:root:current train perplexity158.18519592285156
INFO:root:current mean train loss 12841.1765625
INFO:root:current train perplexity158.3946533203125
INFO:root:current mean train loss 12844.622002377717
INFO:root:current train perplexity158.6510467529297
INFO:root:current mean train loss 12853.600888310186
INFO:root:current train perplexity158.7034149169922
INFO:root:current mean train loss 12863.458800403227
INFO:root:current train perplexity158.89263916015625
INFO:root:current mean train loss 12859.70226450893
INFO:root:current train perplexity159.04734802246094
INFO:root:current mean train loss 12858.717095352564
INFO:root:current train perplexity159.05728149414062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.56s/it]
INFO:root:final mean train loss: 12848.297453849545
INFO:root:final train perplexity: 159.01913452148438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 12516.602407468972
INFO:root:eval perplexity: 157.8028564453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 12778.777281416224
INFO:root:eval perplexity: 185.9388885498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [28:27:15<4:26:21, 591.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12851.783108998494
INFO:root:current train perplexity158.44435119628906
INFO:root:current mean train loss 12877.282882940573
INFO:root:current train perplexity158.90794372558594
INFO:root:current mean train loss 12865.308973332598
INFO:root:current train perplexity158.77244567871094
INFO:root:current mean train loss 12870.305439682605
INFO:root:current train perplexity158.79629516601562
INFO:root:current mean train loss 12863.288290146222
INFO:root:current train perplexity158.98654174804688
INFO:root:current mean train loss 12854.193796566788
INFO:root:current train perplexity159.13746643066406
INFO:root:current mean train loss 12841.612241775714
INFO:root:current train perplexity158.87347412109375
INFO:root:current mean train loss 12847.68491329422
INFO:root:current train perplexity159.0845947265625
INFO:root:current mean train loss 12853.765730066181
INFO:root:current train perplexity159.17222595214844
INFO:root:current mean train loss 12856.635069621057
INFO:root:current train perplexity159.0634307861328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.89s/it]
INFO:root:final mean train loss: 12849.800744579685
INFO:root:final train perplexity: 159.1135711669922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 12522.862339317377
INFO:root:eval perplexity: 158.20285034179688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 12783.408500941932
INFO:root:eval perplexity: 186.2912139892578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [28:37:08<4:16:37, 592.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12800.227313701924
INFO:root:current train perplexity158.06507873535156
INFO:root:current mean train loss 12877.690956315446
INFO:root:current train perplexity158.67124938964844
INFO:root:current mean train loss 12830.932147363617
INFO:root:current train perplexity158.2912139892578
INFO:root:current mean train loss 12847.949171295557
INFO:root:current train perplexity158.7368621826172
INFO:root:current mean train loss 12853.194536818992
INFO:root:current train perplexity158.90953063964844
INFO:root:current mean train loss 12849.78795705108
INFO:root:current train perplexity158.6876678466797
INFO:root:current mean train loss 12853.269381444465
INFO:root:current train perplexity158.67132568359375
INFO:root:current mean train loss 12860.461558499921
INFO:root:current train perplexity158.8686981201172
INFO:root:current mean train loss 12855.276836288229
INFO:root:current train perplexity158.7709197998047
INFO:root:current mean train loss 12856.451943467773
INFO:root:current train perplexity158.90074157714844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.83s/it]
INFO:root:final mean train loss: 12846.445585927655
INFO:root:final train perplexity: 158.90309143066406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 12514.73907081117
INFO:root:eval perplexity: 157.68394470214844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 12775.492499168882
INFO:root:eval perplexity: 185.689208984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [28:46:59<4:06:33, 591.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12890.048364504419
INFO:root:current train perplexity159.9889373779297
INFO:root:current mean train loss 12799.300162923995
INFO:root:current train perplexity158.2748260498047
INFO:root:current mean train loss 12827.504843619356
INFO:root:current train perplexity158.66754150390625
INFO:root:current mean train loss 12842.454505404135
INFO:root:current train perplexity158.6130828857422
INFO:root:current mean train loss 12842.216325228583
INFO:root:current train perplexity158.67723083496094
INFO:root:current mean train loss 12856.122983292467
INFO:root:current train perplexity158.87559509277344
INFO:root:current mean train loss 12851.252217174087
INFO:root:current train perplexity158.83953857421875
INFO:root:current mean train loss 12854.786477481617
INFO:root:current train perplexity158.86021423339844
INFO:root:current mean train loss 12852.038327090864
INFO:root:current train perplexity158.860595703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.94s/it]
INFO:root:final mean train loss: 12848.102240039456
INFO:root:final train perplexity: 159.0070037841797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 12517.504238696809
INFO:root:eval perplexity: 157.8604278564453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 12778.91463735594
INFO:root:eval perplexity: 185.9492645263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [28:56:50<3:56:41, 591.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12870.854073660714
INFO:root:current train perplexity156.9888458251953
INFO:root:current mean train loss 12845.949346524532
INFO:root:current train perplexity159.7198028564453
INFO:root:current mean train loss 12862.56945387983
INFO:root:current train perplexity159.43771362304688
INFO:root:current mean train loss 12864.199603649226
INFO:root:current train perplexity159.187255859375
INFO:root:current mean train loss 12853.312891104883
INFO:root:current train perplexity159.19256591796875
INFO:root:current mean train loss 12860.386348927515
INFO:root:current train perplexity159.21922302246094
INFO:root:current mean train loss 12861.46382374897
INFO:root:current train perplexity159.2136688232422
INFO:root:current mean train loss 12854.436418460484
INFO:root:current train perplexity158.99745178222656
INFO:root:current mean train loss 12858.559066904818
INFO:root:current train perplexity159.10157775878906
INFO:root:current mean train loss 12855.332375792448
INFO:root:current train perplexity159.09323120117188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.39s/it]
INFO:root:final mean train loss: 12850.486854307113
INFO:root:final train perplexity: 159.15667724609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 12526.447265625
INFO:root:eval perplexity: 158.4324188232422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 12786.95384530142
INFO:root:eval perplexity: 186.56155395507812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [29:06:42<3:46:50, 591.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12830.740690104167
INFO:root:current train perplexity156.9798583984375
INFO:root:current mean train loss 12843.690242866847
INFO:root:current train perplexity158.85983276367188
INFO:root:current mean train loss 12844.12328306686
INFO:root:current train perplexity159.2364501953125
INFO:root:current mean train loss 12844.42673611111
INFO:root:current train perplexity159.36109924316406
INFO:root:current mean train loss 12847.84296875
INFO:root:current train perplexity158.85702514648438
INFO:root:current mean train loss 12848.649931735437
INFO:root:current train perplexity158.6677703857422
INFO:root:current mean train loss 12841.477985264228
INFO:root:current train perplexity158.56263732910156
INFO:root:current mean train loss 12849.424718640734
INFO:root:current train perplexity158.8489227294922
INFO:root:current mean train loss 12845.133972392638
INFO:root:current train perplexity158.8238525390625
INFO:root:current mean train loss 12854.592409494535
INFO:root:current train perplexity158.99517822265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:38<00:00, 518.41s/it]
INFO:root:final mean train loss: 12849.923558388988
INFO:root:final train perplexity: 159.12130737304688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 12527.233723958334
INFO:root:eval perplexity: 158.4827423095703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 12788.8154019836
INFO:root:eval perplexity: 186.70358276367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [29:16:38<3:37:23, 592.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12707.607039741848
INFO:root:current train perplexity158.44752502441406
INFO:root:current mean train loss 12874.099363249492
INFO:root:current train perplexity159.69808959960938
INFO:root:current mean train loss 12845.055580857623
INFO:root:current train perplexity159.505859375
INFO:root:current mean train loss 12852.23289655089
INFO:root:current train perplexity159.47747802734375
INFO:root:current mean train loss 12834.058159722223
INFO:root:current train perplexity159.1506805419922
INFO:root:current mean train loss 12850.031574898423
INFO:root:current train perplexity159.2075958251953
INFO:root:current mean train loss 12844.700306606139
INFO:root:current train perplexity159.1287384033203
INFO:root:current mean train loss 12858.728757401885
INFO:root:current train perplexity159.34658813476562
INFO:root:current mean train loss 12860.066273352066
INFO:root:current train perplexity159.14581298828125
INFO:root:current mean train loss 12851.667902094056
INFO:root:current train perplexity159.04627990722656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.32s/it]
INFO:root:final mean train loss: 12848.448072125835
INFO:root:final train perplexity: 159.0287628173828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 12519.840501717641
INFO:root:eval perplexity: 158.00955200195312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 12782.463257701684
INFO:root:eval perplexity: 186.2192840576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [29:26:30<3:27:25, 592.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12851.017830141129
INFO:root:current train perplexity158.42955017089844
INFO:root:current mean train loss 12891.056416984733
INFO:root:current train perplexity159.1439971923828
INFO:root:current mean train loss 12851.179201332521
INFO:root:current train perplexity158.9982147216797
INFO:root:current mean train loss 12852.634328974698
INFO:root:current train perplexity158.9898681640625
INFO:root:current mean train loss 12837.228506561774
INFO:root:current train perplexity159.03399658203125
INFO:root:current mean train loss 12844.886681967984
INFO:root:current train perplexity158.92794799804688
INFO:root:current mean train loss 12845.289775963252
INFO:root:current train perplexity158.92408752441406
INFO:root:current mean train loss 12856.994880728455
INFO:root:current train perplexity158.998291015625
INFO:root:current mean train loss 12856.63335660161
INFO:root:current train perplexity159.0604705810547
INFO:root:current mean train loss 12856.977887310351
INFO:root:current train perplexity159.00033569335938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.58s/it]
INFO:root:final mean train loss: 12849.423387342884
INFO:root:final train perplexity: 159.08990478515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 12520.312846298759
INFO:root:eval perplexity: 158.0398406982422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 12781.83984375
INFO:root:eval perplexity: 186.17169189453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [29:36:22<3:17:29, 592.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13014.26880508814
INFO:root:current train perplexity160.63265991210938
INFO:root:current mean train loss 12933.341543952338
INFO:root:current train perplexity160.33811950683594
INFO:root:current mean train loss 12890.874746665795
INFO:root:current train perplexity159.513916015625
INFO:root:current mean train loss 12893.7802359882
INFO:root:current train perplexity159.55361938476562
INFO:root:current mean train loss 12881.345465101795
INFO:root:current train perplexity159.4459228515625
INFO:root:current mean train loss 12851.982142857143
INFO:root:current train perplexity158.9961700439453
INFO:root:current mean train loss 12849.113878802327
INFO:root:current train perplexity158.9789581298828
INFO:root:current mean train loss 12852.049137347767
INFO:root:current train perplexity158.92401123046875
INFO:root:current mean train loss 12858.386292740613
INFO:root:current train perplexity159.09976196289062
INFO:root:current mean train loss 12857.855762030751
INFO:root:current train perplexity159.08155822753906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.63s/it]
INFO:root:final mean train loss: 12849.542784413983
INFO:root:final train perplexity: 159.0973358154297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 12518.712599734043
INFO:root:eval perplexity: 157.93760681152344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 12780.955431349734
INFO:root:eval perplexity: 186.10450744628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [29:46:10<3:07:14, 591.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12791.870969082447
INFO:root:current train perplexity158.18783569335938
INFO:root:current mean train loss 12853.749707695579
INFO:root:current train perplexity159.60536193847656
INFO:root:current mean train loss 12856.873817845395
INFO:root:current train perplexity159.65020751953125
INFO:root:current mean train loss 12855.96445256214
INFO:root:current train perplexity159.24359130859375
INFO:root:current mean train loss 12843.069185192953
INFO:root:current train perplexity159.02967834472656
INFO:root:current mean train loss 12841.29284199326
INFO:root:current train perplexity159.13079833984375
INFO:root:current mean train loss 12854.388443960104
INFO:root:current train perplexity159.26409912109375
INFO:root:current mean train loss 12855.67731995691
INFO:root:current train perplexity159.1115264892578
INFO:root:current mean train loss 12858.782382212958
INFO:root:current train perplexity159.0973358154297
INFO:root:current mean train loss 12864.1325577894
INFO:root:current train perplexity159.12600708007812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.44s/it]
INFO:root:final mean train loss: 12848.76324733611
INFO:root:final train perplexity: 159.0484161376953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 12515.039692763741
INFO:root:eval perplexity: 157.70318603515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 12777.430712544327
INFO:root:eval perplexity: 185.83642578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [29:56:01<2:57:21, 591.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12928.600035511363
INFO:root:current train perplexity160.70407104492188
INFO:root:current mean train loss 12928.242477318548
INFO:root:current train perplexity160.76806640625
INFO:root:current mean train loss 12876.840287990197
INFO:root:current train perplexity159.6710662841797
INFO:root:current mean train loss 12857.12968474912
INFO:root:current train perplexity159.0127716064453
INFO:root:current mean train loss 12855.066011332417
INFO:root:current train perplexity158.9589385986328
INFO:root:current mean train loss 12845.364475999437
INFO:root:current train perplexity158.94235229492188
INFO:root:current mean train loss 12846.191075262404
INFO:root:current train perplexity158.87339782714844
INFO:root:current mean train loss 12856.419735616722
INFO:root:current train perplexity158.85536193847656
INFO:root:current mean train loss 12857.276184438962
INFO:root:current train perplexity158.95114135742188
INFO:root:current mean train loss 12860.410542784686
INFO:root:current train perplexity159.06661987304688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:37<00:00, 517.22s/it]
INFO:root:final mean train loss: 12848.715270257766
INFO:root:final train perplexity: 159.0454559326172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 12515.851500166224
INFO:root:eval perplexity: 157.7550048828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 12776.815263464096
INFO:root:eval perplexity: 185.78955078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [30:05:55<2:47:44, 592.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12917.451156374007
INFO:root:current train perplexity158.47616577148438
INFO:root:current mean train loss 12840.460458205522
INFO:root:current train perplexity158.24856567382812
INFO:root:current mean train loss 12817.631223265209
INFO:root:current train perplexity158.22645568847656
INFO:root:current mean train loss 12836.777763429753
INFO:root:current train perplexity158.50889587402344
INFO:root:current mean train loss 12847.020613272813
INFO:root:current train perplexity158.93453979492188
INFO:root:current mean train loss 12844.809110651642
INFO:root:current train perplexity159.01747131347656
INFO:root:current mean train loss 12863.621288178732
INFO:root:current train perplexity159.11288452148438
INFO:root:current mean train loss 12867.85881312459
INFO:root:current train perplexity159.14938354492188
INFO:root:current mean train loss 12865.049900872682
INFO:root:current train perplexity159.11492919921875
INFO:root:current mean train loss 12856.72672880971
INFO:root:current train perplexity159.0565185546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.83s/it]
INFO:root:final mean train loss: 12849.081090619487
INFO:root:final train perplexity: 159.068359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 12514.891005928635
INFO:root:eval perplexity: 157.69371032714844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it]
INFO:root:eval mean loss: 12777.789505762412
INFO:root:eval perplexity: 185.8637237548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [30:15:50<2:38:05, 592.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12793.274579115317
INFO:root:current train perplexity156.89686584472656
INFO:root:current mean train loss 12854.951457419591
INFO:root:current train perplexity157.63687133789062
INFO:root:current mean train loss 12836.999268479012
INFO:root:current train perplexity158.1185302734375
INFO:root:current mean train loss 12859.781586927224
INFO:root:current train perplexity158.39102172851562
INFO:root:current mean train loss 12856.024219164676
INFO:root:current train perplexity158.5778350830078
INFO:root:current mean train loss 12847.267020577934
INFO:root:current train perplexity158.5537109375
INFO:root:current mean train loss 12848.379229345193
INFO:root:current train perplexity158.62472534179688
INFO:root:current mean train loss 12854.903026457117
INFO:root:current train perplexity158.74874877929688
INFO:root:current mean train loss 12853.472666340773
INFO:root:current train perplexity158.79849243164062
INFO:root:current mean train loss 12861.104557559862
INFO:root:current train perplexity159.06448364257812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.03s/it]
INFO:root:final mean train loss: 12848.77709640995
INFO:root:final train perplexity: 159.0492401123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 12519.609894448138
INFO:root:eval perplexity: 157.99493408203125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 12781.62916251108
INFO:root:eval perplexity: 186.1557159423828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [30:25:42<2:28:06, 592.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12871.192815466773
INFO:root:current train perplexity159.0177001953125
INFO:root:current mean train loss 12867.528238477653
INFO:root:current train perplexity159.22825622558594
INFO:root:current mean train loss 12825.393957213262
INFO:root:current train perplexity158.5723114013672
INFO:root:current mean train loss 12843.016586102407
INFO:root:current train perplexity158.7354278564453
INFO:root:current mean train loss 12855.779790253131
INFO:root:current train perplexity158.9318084716797
INFO:root:current mean train loss 12873.90387521589
INFO:root:current train perplexity159.0778350830078
INFO:root:current mean train loss 12868.968378935015
INFO:root:current train perplexity158.93173217773438
INFO:root:current mean train loss 12863.68526481266
INFO:root:current train perplexity158.91354370117188
INFO:root:current mean train loss 12856.737546883887
INFO:root:current train perplexity158.8916473388672
INFO:root:current mean train loss 12854.250340150984
INFO:root:current train perplexity158.95484924316406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.56s/it]
INFO:root:final mean train loss: 12847.900091601956
INFO:root:final train perplexity: 158.9942626953125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 12517.084233710106
INFO:root:eval perplexity: 157.83363342285156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 12778.561932070035
INFO:root:eval perplexity: 185.9224090576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [30:35:33<2:18:08, 592.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12957.052161907328
INFO:root:current train perplexity159.68711853027344
INFO:root:current mean train loss 12921.272586271725
INFO:root:current train perplexity160.07937622070312
INFO:root:current mean train loss 12897.747893755444
INFO:root:current train perplexity159.67852783203125
INFO:root:current mean train loss 12861.048934108527
INFO:root:current train perplexity159.2404022216797
INFO:root:current mean train loss 12849.991808505518
INFO:root:current train perplexity158.91954040527344
INFO:root:current mean train loss 12848.202291511392
INFO:root:current train perplexity158.80340576171875
INFO:root:current mean train loss 12855.623028395652
INFO:root:current train perplexity158.86021423339844
INFO:root:current mean train loss 12865.16610496744
INFO:root:current train perplexity158.95545959472656
INFO:root:current mean train loss 12856.22497930172
INFO:root:current train perplexity158.97872924804688
INFO:root:current mean train loss 12858.429041405458
INFO:root:current train perplexity159.0342254638672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.74s/it]
INFO:root:final mean train loss: 12848.381018853957
INFO:root:final train perplexity: 159.02452087402344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 12515.31678025266
INFO:root:eval perplexity: 157.72085571289062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 12777.408424756206
INFO:root:eval perplexity: 185.8348388671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [30:45:25<2:08:17, 592.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12819.675884046053
INFO:root:current train perplexity159.43284606933594
INFO:root:current mean train loss 12860.058764022437
INFO:root:current train perplexity159.600341796875
INFO:root:current mean train loss 12859.150897113348
INFO:root:current train perplexity159.69093322753906
INFO:root:current mean train loss 12857.0441159019
INFO:root:current train perplexity159.29843139648438
INFO:root:current mean train loss 12851.436156486743
INFO:root:current train perplexity159.14923095703125
INFO:root:current mean train loss 12853.245727744223
INFO:root:current train perplexity159.20501708984375
INFO:root:current mean train loss 12872.21759217626
INFO:root:current train perplexity159.2881622314453
INFO:root:current mean train loss 12873.583852938285
INFO:root:current train perplexity159.2602996826172
INFO:root:current mean train loss 12868.8757987081
INFO:root:current train perplexity159.10780334472656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:36<00:00, 516.05s/it]
INFO:root:final mean train loss: 12847.120767408802
INFO:root:final train perplexity: 158.94544982910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 12514.413376828457
INFO:root:eval perplexity: 157.66326904296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 12776.79902897828
INFO:root:eval perplexity: 185.7884979248047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [30:55:18<1:58:27, 592.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13161.105143229166
INFO:root:current train perplexity161.22744750976562
INFO:root:current mean train loss 12919.38422519721
INFO:root:current train perplexity160.68406677246094
INFO:root:current mean train loss 12920.907168834667
INFO:root:current train perplexity159.93653869628906
INFO:root:current mean train loss 12892.589147586634
INFO:root:current train perplexity159.4194793701172
INFO:root:current mean train loss 12878.93427952466
INFO:root:current train perplexity159.32835388183594
INFO:root:current mean train loss 12887.452773592819
INFO:root:current train perplexity159.55712890625
INFO:root:current mean train loss 12872.40703869973
INFO:root:current train perplexity159.3687744140625
INFO:root:current mean train loss 12859.901067134157
INFO:root:current train perplexity159.23007202148438
INFO:root:current mean train loss 12854.528973381071
INFO:root:current train perplexity159.07974243164062
INFO:root:current mean train loss 12857.022069447328
INFO:root:current train perplexity159.01951599121094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.35s/it]
INFO:root:final mean train loss: 12847.760933906802
INFO:root:final train perplexity: 158.9855499267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it]
INFO:root:eval mean loss: 12512.757646276596
INFO:root:eval perplexity: 157.55767822265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 12775.026076296543
INFO:root:eval perplexity: 185.65379333496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [31:05:03<1:48:13, 590.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12794.113547585228
INFO:root:current train perplexity159.18687438964844
INFO:root:current mean train loss 12856.704946157095
INFO:root:current train perplexity159.20631408691406
INFO:root:current mean train loss 12843.85587603673
INFO:root:current train perplexity159.08580017089844
INFO:root:current mean train loss 12868.91036977492
INFO:root:current train perplexity159.30593872070312
INFO:root:current mean train loss 12857.862694362075
INFO:root:current train perplexity159.28269958496094
INFO:root:current mean train loss 12853.58590501162
INFO:root:current train perplexity159.17086791992188
INFO:root:current mean train loss 12860.210785661313
INFO:root:current train perplexity159.14065551757812
INFO:root:current mean train loss 12859.841941093091
INFO:root:current train perplexity159.23190307617188
INFO:root:current mean train loss 12855.508969684417
INFO:root:current train perplexity159.03794860839844
INFO:root:current mean train loss 12855.822066239023
INFO:root:current train perplexity158.9816131591797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.47s/it]
INFO:root:final mean train loss: 12846.580584372243
INFO:root:final train perplexity: 158.9115753173828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12512.51732186392
INFO:root:eval perplexity: 157.54241943359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 12774.465570977394
INFO:root:eval perplexity: 185.61131286621094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [31:14:56<1:38:29, 590.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12872.076634457237
INFO:root:current train perplexity157.67115783691406
INFO:root:current mean train loss 12845.560932576156
INFO:root:current train perplexity158.14129638671875
INFO:root:current mean train loss 12861.774967001998
INFO:root:current train perplexity158.81582641601562
INFO:root:current mean train loss 12844.656081627156
INFO:root:current train perplexity158.49105834960938
INFO:root:current mean train loss 12848.029287552208
INFO:root:current train perplexity158.46408081054688
INFO:root:current mean train loss 12843.354499713992
INFO:root:current train perplexity158.65989685058594
INFO:root:current mean train loss 12848.417336114197
INFO:root:current train perplexity158.78842163085938
INFO:root:current mean train loss 12850.469839295029
INFO:root:current train perplexity158.77516174316406
INFO:root:current mean train loss 12850.137140853938
INFO:root:current train perplexity158.88247680664062
INFO:root:current mean train loss 12848.715636476469
INFO:root:current train perplexity158.77137756347656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.15s/it]
INFO:root:final mean train loss: 12846.632637762254
INFO:root:final train perplexity: 158.91476440429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 12511.686204842641
INFO:root:eval perplexity: 157.48947143554688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 12773.73687527704
INFO:root:eval perplexity: 185.555908203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [31:24:47<1:28:40, 591.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12881.096245659723
INFO:root:current train perplexity158.41867065429688
INFO:root:current mean train loss 12805.87113988681
INFO:root:current train perplexity157.47940063476562
INFO:root:current mean train loss 12820.010174318557
INFO:root:current train perplexity158.26766967773438
INFO:root:current mean train loss 12837.947871870221
INFO:root:current train perplexity158.67124938964844
INFO:root:current mean train loss 12853.964372621487
INFO:root:current train perplexity158.65634155273438
INFO:root:current mean train loss 12865.056959351281
INFO:root:current train perplexity158.79318237304688
INFO:root:current mean train loss 12859.041140226276
INFO:root:current train perplexity158.69735717773438
INFO:root:current mean train loss 12856.410481323075
INFO:root:current train perplexity158.82937622070312
INFO:root:current mean train loss 12849.813134116157
INFO:root:current train perplexity158.74087524414062
INFO:root:current mean train loss 12856.703372564389
INFO:root:current train perplexity158.8358917236328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.08s/it]
INFO:root:final mean train loss: 12846.240685493716
INFO:root:final train perplexity: 158.8902130126953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 12511.854083554965
INFO:root:eval perplexity: 157.50021362304688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 12773.976908798759
INFO:root:eval perplexity: 185.5741424560547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [31:34:39<1:18:49, 591.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13119.5890625
INFO:root:current train perplexity162.1088104248047
INFO:root:current mean train loss 12856.258781828703
INFO:root:current train perplexity158.9633331298828
INFO:root:current mean train loss 12891.376288231382
INFO:root:current train perplexity159.01004028320312
INFO:root:current mean train loss 12862.841225513059
INFO:root:current train perplexity158.5235595703125
INFO:root:current mean train loss 12865.728398886495
INFO:root:current train perplexity158.77615356445312
INFO:root:current mean train loss 12856.019047532127
INFO:root:current train perplexity158.66127014160156
INFO:root:current mean train loss 12860.77296382874
INFO:root:current train perplexity158.915283203125
INFO:root:current mean train loss 12851.81011107568
INFO:root:current train perplexity158.915283203125
INFO:root:current mean train loss 12853.801526244386
INFO:root:current train perplexity158.85855102539062
INFO:root:current mean train loss 12861.962639956551
INFO:root:current train perplexity158.99298095703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:35<00:00, 515.78s/it]
INFO:root:final mean train loss: 12846.96179543772
INFO:root:final train perplexity: 158.93545532226562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 12515.089137300532
INFO:root:eval perplexity: 157.70626831054688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 12777.132528535018
INFO:root:eval perplexity: 185.81382751464844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [31:44:31<1:09:00, 591.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12876.886082848838
INFO:root:current train perplexity159.9397430419922
INFO:root:current mean train loss 12834.997316160403
INFO:root:current train perplexity159.42373657226562
INFO:root:current mean train loss 12862.0083751286
INFO:root:current train perplexity159.43923950195312
INFO:root:current mean train loss 12862.267842907253
INFO:root:current train perplexity159.45497131347656
INFO:root:current mean train loss 12870.099219190886
INFO:root:current train perplexity159.67784118652344
INFO:root:current mean train loss 12867.300484504489
INFO:root:current train perplexity159.47186279296875
INFO:root:current mean train loss 12870.212137320179
INFO:root:current train perplexity159.4860076904297
INFO:root:current mean train loss 12864.755040534572
INFO:root:current train perplexity159.35183715820312
INFO:root:current mean train loss 12856.9577332629
INFO:root:current train perplexity159.2156524658203
INFO:root:current mean train loss 12858.748106939289
INFO:root:current train perplexity159.24974060058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:34<00:00, 514.78s/it]
INFO:root:final mean train loss: 12852.61792755127
INFO:root:final train perplexity: 159.2906036376953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 12513.271477449025
INFO:root:eval perplexity: 157.59036254882812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 12774.882881759751
INFO:root:eval perplexity: 185.64291381835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_200e_128/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [31:54:23<59:10, 591.74s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][Aslurmstepd: error: *** JOB 30005433 ON gr033 CANCELLED AT 2023-02-10T14:34:54 ***
