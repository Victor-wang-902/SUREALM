INFO:root:Output: distilroberta_baseline
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14776.558287957701
INFO:root:current train perplexity108261.53125
INFO:root:current mean train loss 10765.268728898398
INFO:root:current train perplexity4814.60009765625
INFO:root:current mean train loss 8836.26341385347
INFO:root:current train perplexity1062.3309326171875
INFO:root:current mean train loss 7718.007884090108
INFO:root:current train perplexity441.7440490722656
INFO:root:current mean train loss 6981.122587949336
INFO:root:current train perplexity246.47117614746094
INFO:root:current mean train loss 6448.679030480488
INFO:root:current train perplexity162.4113311767578
INFO:root:current mean train loss 6049.399772414834
INFO:root:current train perplexity117.69454193115234
INFO:root:current mean train loss 5730.931691958698
INFO:root:current train perplexity91.6070327758789
INFO:root:current mean train loss 5475.112713670572
INFO:root:current train perplexity74.6752700805664
INFO:root:current mean train loss 5256.32055884009
INFO:root:current train perplexity63.16495132446289
INFO:root:current mean train loss 5075.6502091301045
INFO:root:current train perplexity54.77351379394531
INFO:root:current mean train loss 4918.32634169425
INFO:root:current train perplexity48.46780014038086
INFO:root:current mean train loss 4784.021032367145
INFO:root:current train perplexity43.52484130859375
INFO:root:current mean train loss 4665.391418500659
INFO:root:current train perplexity39.67194366455078
INFO:root:current mean train loss 4557.881713948622
INFO:root:current train perplexity36.49372482299805
INFO:root:current mean train loss 4464.16074026369
INFO:root:current train perplexity33.872615814208984
INFO:root:current mean train loss 4378.748796827867
INFO:root:current train perplexity31.648550033569336
INFO:root:current mean train loss 4301.217760409429
INFO:root:current train perplexity29.800539016723633
INFO:root:current mean train loss 4230.984157343298
INFO:root:current train perplexity28.19040298461914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.87s/it]
INFO:root:final mean train loss: 4176.398987524328
INFO:root:final train perplexity: 27.004539489746094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2690.7507869639294
INFO:root:eval perplexity: 8.82329273223877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2959.058785945811
INFO:root:eval perplexity: 11.389901161193848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/1
  0%|          | 1/200 [06:11<20:32:27, 371.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2925.6439514160156
INFO:root:current train perplexity10.175501823425293
INFO:root:current mean train loss 2896.8622268150593
INFO:root:current train perplexity9.983553886413574
INFO:root:current mean train loss 2895.8228759765625
INFO:root:current train perplexity9.913166046142578
INFO:root:current mean train loss 2887.0567449255836
INFO:root:current train perplexity9.777957916259766
INFO:root:current mean train loss 2878.7773196880635
INFO:root:current train perplexity9.70300579071045
INFO:root:current mean train loss 2866.4737354840418
INFO:root:current train perplexity9.618596076965332
INFO:root:current mean train loss 2858.454363141741
INFO:root:current train perplexity9.556902885437012
INFO:root:current mean train loss 2846.7578148868497
INFO:root:current train perplexity9.475959777832031
INFO:root:current mean train loss 2841.443556841682
INFO:root:current train perplexity9.426297187805176
INFO:root:current mean train loss 2830.627722061357
INFO:root:current train perplexity9.357535362243652
INFO:root:current mean train loss 2821.8878772164894
INFO:root:current train perplexity9.307168006896973
INFO:root:current mean train loss 2814.131045105637
INFO:root:current train perplexity9.252462387084961
INFO:root:current mean train loss 2809.4130142613462
INFO:root:current train perplexity9.197175025939941
INFO:root:current mean train loss 2806.268913663267
INFO:root:current train perplexity9.157809257507324
INFO:root:current mean train loss 2799.0206672970185
INFO:root:current train perplexity9.111612319946289
INFO:root:current mean train loss 2791.6428385309305
INFO:root:current train perplexity9.065726280212402
INFO:root:current mean train loss 2787.4362536137646
INFO:root:current train perplexity9.025280952453613
INFO:root:current mean train loss 2781.9013472692673
INFO:root:current train perplexity8.982619285583496
INFO:root:current mean train loss 2776.7995481785174
INFO:root:current train perplexity8.945284843444824
INFO:root:current mean train loss 2771.2220738038636
INFO:root:current train perplexity8.90550708770752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.12s/it]
INFO:root:final mean train loss: 2767.05747652655
INFO:root:final train perplexity: 8.879591941833496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2471.865789318761
INFO:root:eval perplexity: 7.391054153442383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2778.275150380236
INFO:root:eval perplexity: 9.816844940185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/2
  1%|          | 2/200 [12:22<20:24:45, 371.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2626.999393347538
INFO:root:current train perplexity7.938042640686035
INFO:root:current mean train loss 2645.8986853119127
INFO:root:current train perplexity7.976602554321289
INFO:root:current mean train loss 2629.6878049138277
INFO:root:current train perplexity7.956966400146484
INFO:root:current mean train loss 2628.49915173963
INFO:root:current train perplexity7.9633941650390625
INFO:root:current mean train loss 2624.6897649258444
INFO:root:current train perplexity7.951631546020508
INFO:root:current mean train loss 2622.2714321573053
INFO:root:current train perplexity7.948441505432129
INFO:root:current mean train loss 2620.7403504671456
INFO:root:current train perplexity7.9330949783325195
INFO:root:current mean train loss 2613.4635840776346
INFO:root:current train perplexity7.901260852813721
INFO:root:current mean train loss 2611.588134765625
INFO:root:current train perplexity7.880017280578613
INFO:root:current mean train loss 2610.2657550513295
INFO:root:current train perplexity7.861288070678711
INFO:root:current mean train loss 2606.230055861644
INFO:root:current train perplexity7.834836006164551
INFO:root:current mean train loss 2605.6277025699196
INFO:root:current train perplexity7.823210716247559
INFO:root:current mean train loss 2603.7325424602723
INFO:root:current train perplexity7.812875270843506
INFO:root:current mean train loss 2601.5639956131613
INFO:root:current train perplexity7.801254749298096
INFO:root:current mean train loss 2599.0904318682396
INFO:root:current train perplexity7.776732444763184
INFO:root:current mean train loss 2596.439046701729
INFO:root:current train perplexity7.757490158081055
INFO:root:current mean train loss 2592.8742787909523
INFO:root:current train perplexity7.739017009735107
INFO:root:current mean train loss 2590.113737411191
INFO:root:current train perplexity7.723546028137207
INFO:root:current mean train loss 2588.420079574127
INFO:root:current train perplexity7.7014641761779785
INFO:root:current mean train loss 2584.730465339862
INFO:root:current train perplexity7.6863908767700195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.71s/it]
INFO:root:final mean train loss: 2583.1823793258322
INFO:root:final train perplexity: 7.680171966552734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2377.3124870137967
INFO:root:eval perplexity: 6.846627712249756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2700.9765386919603
INFO:root:eval perplexity: 9.21239948272705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/3
  2%|â–         | 3/200 [18:32<20:17:32, 370.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2538.260224609375
INFO:root:current train perplexity7.281314373016357
INFO:root:current mean train loss 2512.188416341146
INFO:root:current train perplexity7.237870693206787
INFO:root:current mean train loss 2497.612724609375
INFO:root:current train perplexity7.188859939575195
INFO:root:current mean train loss 2499.966605747768
INFO:root:current train perplexity7.201260089874268
INFO:root:current mean train loss 2501.6594452582467
INFO:root:current train perplexity7.218008518218994
INFO:root:current mean train loss 2499.293789284446
INFO:root:current train perplexity7.203592300415039
INFO:root:current mean train loss 2498.0756103515623
INFO:root:current train perplexity7.204257011413574
INFO:root:current mean train loss 2497.6573932291667
INFO:root:current train perplexity7.189022064208984
INFO:root:current mean train loss 2498.773373736213
INFO:root:current train perplexity7.191346645355225
INFO:root:current mean train loss 2499.5768834806745
INFO:root:current train perplexity7.190156936645508
INFO:root:current mean train loss 2495.837908063616
INFO:root:current train perplexity7.173086643218994
INFO:root:current mean train loss 2496.374743970788
INFO:root:current train perplexity7.1701579093933105
INFO:root:current mean train loss 2494.706342578125
INFO:root:current train perplexity7.156243324279785
INFO:root:current mean train loss 2491.940718677662
INFO:root:current train perplexity7.146545886993408
INFO:root:current mean train loss 2490.032153993804
INFO:root:current train perplexity7.137808799743652
INFO:root:current mean train loss 2489.3457470703124
INFO:root:current train perplexity7.127951145172119
INFO:root:current mean train loss 2488.096082208807
INFO:root:current train perplexity7.123977184295654
INFO:root:current mean train loss 2486.830716029576
INFO:root:current train perplexity7.113711357116699
INFO:root:current mean train loss 2485.5916511164487
INFO:root:current train perplexity7.10737943649292
INFO:root:current mean train loss 2482.8287161333133
INFO:root:current train perplexity7.092001438140869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.88s/it]
INFO:root:final mean train loss: 2481.839332692141
INFO:root:final train perplexity: 7.089834690093994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2318.7940760402817
INFO:root:eval perplexity: 6.529969215393066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2655.593582045102
INFO:root:eval perplexity: 8.875012397766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/4
  2%|â–         | 4/200 [24:43<20:11:01, 370.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2433.0893336054105
INFO:root:current train perplexity6.773889541625977
INFO:root:current mean train loss 2427.664604872287
INFO:root:current train perplexity6.817377090454102
INFO:root:current mean train loss 2434.4416915379215
INFO:root:current train perplexity6.821328163146973
INFO:root:current mean train loss 2433.255520771245
INFO:root:current train perplexity6.7960100173950195
INFO:root:current mean train loss 2434.5530592859172
INFO:root:current train perplexity6.797889232635498
INFO:root:current mean train loss 2433.663282068108
INFO:root:current train perplexity6.79583740234375
INFO:root:current mean train loss 2432.0050337990183
INFO:root:current train perplexity6.793470859527588
INFO:root:current mean train loss 2430.5906979238816
INFO:root:current train perplexity6.7934417724609375
INFO:root:current mean train loss 2429.5814411730917
INFO:root:current train perplexity6.783069133758545
INFO:root:current mean train loss 2427.0244890467457
INFO:root:current train perplexity6.774314880371094
INFO:root:current mean train loss 2425.529077674701
INFO:root:current train perplexity6.76663875579834
INFO:root:current mean train loss 2423.000672798843
INFO:root:current train perplexity6.7553253173828125
INFO:root:current mean train loss 2420.2411170965493
INFO:root:current train perplexity6.751193046569824
INFO:root:current mean train loss 2419.1177746340927
INFO:root:current train perplexity6.74653959274292
INFO:root:current mean train loss 2418.9314097981105
INFO:root:current train perplexity6.745650291442871
INFO:root:current mean train loss 2417.133551153927
INFO:root:current train perplexity6.737306594848633
INFO:root:current mean train loss 2417.1389236312893
INFO:root:current train perplexity6.7384490966796875
INFO:root:current mean train loss 2416.0897788116336
INFO:root:current train perplexity6.731327533721924
INFO:root:current mean train loss 2414.9270749207035
INFO:root:current train perplexity6.721925258636475
INFO:root:current mean train loss 2414.4867331228947
INFO:root:current train perplexity6.718825340270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.08s/it]
INFO:root:final mean train loss: 2413.906384381993
INFO:root:final train perplexity: 6.719740867614746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2277.5850068220857
INFO:root:eval perplexity: 6.315804958343506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2623.1363499418217
INFO:root:eval perplexity: 8.64132308959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/5
  2%|â–Ž         | 5/200 [30:54<20:04:53, 370.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2391.344294956752
INFO:root:current train perplexity6.522214412689209
INFO:root:current mean train loss 2358.0827802575154
INFO:root:current train perplexity6.475055694580078
INFO:root:current mean train loss 2364.4169663979974
INFO:root:current train perplexity6.497191905975342
INFO:root:current mean train loss 2376.3064931233725
INFO:root:current train perplexity6.515937805175781
INFO:root:current mean train loss 2375.3372724548844
INFO:root:current train perplexity6.525403022766113
INFO:root:current mean train loss 2368.156758765652
INFO:root:current train perplexity6.49657678604126
INFO:root:current mean train loss 2366.8611796418127
INFO:root:current train perplexity6.4760518074035645
INFO:root:current mean train loss 2365.523193515077
INFO:root:current train perplexity6.473453044891357
INFO:root:current mean train loss 2365.3171771985913
INFO:root:current train perplexity6.4773335456848145
INFO:root:current mean train loss 2364.7100804026536
INFO:root:current train perplexity6.47252082824707
INFO:root:current mean train loss 2364.843122193734
INFO:root:current train perplexity6.467682361602783
INFO:root:current mean train loss 2367.145922583503
INFO:root:current train perplexity6.471530914306641
INFO:root:current mean train loss 2366.7841609586435
INFO:root:current train perplexity6.467241287231445
INFO:root:current mean train loss 2366.3124626027366
INFO:root:current train perplexity6.473121643066406
INFO:root:current mean train loss 2367.191848302466
INFO:root:current train perplexity6.47195291519165
INFO:root:current mean train loss 2367.094723942304
INFO:root:current train perplexity6.470432281494141
INFO:root:current mean train loss 2364.169208372574
INFO:root:current train perplexity6.459385395050049
INFO:root:current mean train loss 2363.2557559847296
INFO:root:current train perplexity6.452975273132324
INFO:root:current mean train loss 2361.760670979818
INFO:root:current train perplexity6.449500560760498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.14s/it]
INFO:root:final mean train loss: 2361.7771127213146
INFO:root:final train perplexity: 6.448898792266846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2248.21036134544
INFO:root:eval perplexity: 6.167447566986084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2600.3466705971578
INFO:root:eval perplexity: 8.480924606323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/6
  3%|â–Ž         | 6/200 [37:05<19:58:51, 370.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2281.644287109375
INFO:root:current train perplexity6.133145332336426
INFO:root:current mean train loss 2330.000651444539
INFO:root:current train perplexity6.2687458992004395
INFO:root:current mean train loss 2319.4089659126244
INFO:root:current train perplexity6.261046886444092
INFO:root:current mean train loss 2328.4371970547395
INFO:root:current train perplexity6.279036998748779
INFO:root:current mean train loss 2331.233433140781
INFO:root:current train perplexity6.2637619972229
INFO:root:current mean train loss 2331.674565907248
INFO:root:current train perplexity6.274546146392822
INFO:root:current mean train loss 2332.9681217745815
INFO:root:current train perplexity6.276042938232422
INFO:root:current mean train loss 2330.974432973821
INFO:root:current train perplexity6.2703857421875
INFO:root:current mean train loss 2331.521420977684
INFO:root:current train perplexity6.276390552520752
INFO:root:current mean train loss 2330.092129079668
INFO:root:current train perplexity6.270084857940674
INFO:root:current mean train loss 2329.3229945103726
INFO:root:current train perplexity6.260326385498047
INFO:root:current mean train loss 2326.9069677867424
INFO:root:current train perplexity6.2568793296813965
INFO:root:current mean train loss 2327.848863536571
INFO:root:current train perplexity6.258948802947998
INFO:root:current mean train loss 2327.77415706743
INFO:root:current train perplexity6.262319564819336
INFO:root:current mean train loss 2326.0349695286013
INFO:root:current train perplexity6.258687973022461
INFO:root:current mean train loss 2325.590230292435
INFO:root:current train perplexity6.260476589202881
INFO:root:current mean train loss 2325.4445306705284
INFO:root:current train perplexity6.258866310119629
INFO:root:current mean train loss 2323.6866164434523
INFO:root:current train perplexity6.255258083343506
INFO:root:current mean train loss 2322.314528969908
INFO:root:current train perplexity6.248697280883789
INFO:root:current mean train loss 2322.4901937919185
INFO:root:current train perplexity6.247796058654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.03s/it]
INFO:root:final mean train loss: 2321.146594779995
INFO:root:final train perplexity: 6.245390892028809
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2221.975131420379
INFO:root:eval perplexity: 6.037892818450928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 2582.7701532891456
INFO:root:eval perplexity: 8.35925579071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/7
  4%|â–Ž         | 7/200 [43:15<19:52:42, 370.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2377.0182834201387
INFO:root:current train perplexity6.171844959259033
INFO:root:current mean train loss 2298.6382942846267
INFO:root:current train perplexity6.0686798095703125
INFO:root:current mean train loss 2289.7001958724554
INFO:root:current train perplexity6.080764293670654
INFO:root:current mean train loss 2294.937906133304
INFO:root:current train perplexity6.094936847686768
INFO:root:current mean train loss 2294.4395217530464
INFO:root:current train perplexity6.095149040222168
INFO:root:current mean train loss 2294.044368316768
INFO:root:current train perplexity6.098522186279297
INFO:root:current mean train loss 2295.5745602703405
INFO:root:current train perplexity6.0991926193237305
INFO:root:current mean train loss 2291.894986208435
INFO:root:current train perplexity6.095082759857178
INFO:root:current mean train loss 2288.286193698426
INFO:root:current train perplexity6.0889410972595215
INFO:root:current mean train loss 2284.923287717865
INFO:root:current train perplexity6.089231491088867
INFO:root:current mean train loss 2285.2300555335983
INFO:root:current train perplexity6.08551549911499
INFO:root:current mean train loss 2285.4161358391448
INFO:root:current train perplexity6.085040092468262
INFO:root:current mean train loss 2286.484414487441
INFO:root:current train perplexity6.087691307067871
INFO:root:current mean train loss 2286.1856430123175
INFO:root:current train perplexity6.085846900939941
INFO:root:current mean train loss 2285.9101899097263
INFO:root:current train perplexity6.082372665405273
INFO:root:current mean train loss 2285.999107230165
INFO:root:current train perplexity6.0846099853515625
INFO:root:current mean train loss 2285.7142176303933
INFO:root:current train perplexity6.081723213195801
INFO:root:current mean train loss 2286.5005802958335
INFO:root:current train perplexity6.080448150634766
INFO:root:current mean train loss 2286.6644904175478
INFO:root:current train perplexity6.081766128540039
INFO:root:current mean train loss 2286.471324296142
INFO:root:current train perplexity6.077792167663574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.03s/it]
INFO:root:final mean train loss: 2286.3258846127137
INFO:root:final train perplexity: 6.076101779937744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2208.7260495449636
INFO:root:eval perplexity: 5.973503589630127
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 2572.316749518645
INFO:root:eval perplexity: 8.28772258758545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/8
  4%|â–         | 8/200 [49:25<19:45:49, 370.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2257.7825125558034
INFO:root:current train perplexity5.936664581298828
INFO:root:current mean train loss 2256.0000515407987
INFO:root:current train perplexity5.945639610290527
INFO:root:current mean train loss 2259.9380308759974
INFO:root:current train perplexity5.962328910827637
INFO:root:current mean train loss 2260.5020427646923
INFO:root:current train perplexity5.970531940460205
INFO:root:current mean train loss 2256.5996191967492
INFO:root:current train perplexity5.9579291343688965
INFO:root:current mean train loss 2256.409014265114
INFO:root:current train perplexity5.9663777351379395
INFO:root:current mean train loss 2257.1697984590305
INFO:root:current train perplexity5.9639129638671875
INFO:root:current mean train loss 2255.8913924651893
INFO:root:current train perplexity5.959412574768066
INFO:root:current mean train loss 2253.773519952283
INFO:root:current train perplexity5.9471282958984375
INFO:root:current mean train loss 2255.3286619788187
INFO:root:current train perplexity5.9528656005859375
INFO:root:current mean train loss 2251.408918445237
INFO:root:current train perplexity5.942380905151367
INFO:root:current mean train loss 2252.122189909141
INFO:root:current train perplexity5.94270658493042
INFO:root:current mean train loss 2255.647542581288
INFO:root:current train perplexity5.949618339538574
INFO:root:current mean train loss 2254.8968078841876
INFO:root:current train perplexity5.944985389709473
INFO:root:current mean train loss 2254.3611004872605
INFO:root:current train perplexity5.940770149230957
INFO:root:current mean train loss 2255.341190976817
INFO:root:current train perplexity5.94025182723999
INFO:root:current mean train loss 2256.592916711463
INFO:root:current train perplexity5.943072319030762
INFO:root:current mean train loss 2256.495626083506
INFO:root:current train perplexity5.93810510635376
INFO:root:current mean train loss 2256.2776375835533
INFO:root:current train perplexity5.938009738922119
INFO:root:current mean train loss 2256.9721892916264
INFO:root:current train perplexity5.935714244842529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.52s/it]
INFO:root:final mean train loss: 2256.259266201679
INFO:root:final train perplexity: 5.933622360229492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2189.6828344899714
INFO:root:eval perplexity: 5.8821563720703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2557.759978598737
INFO:root:eval perplexity: 8.189130783081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/9
  4%|â–         | 9/200 [55:38<19:41:39, 371.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2243.3511023888223
INFO:root:current train perplexity5.862095355987549
INFO:root:current mean train loss 2239.411322342722
INFO:root:current train perplexity5.867507457733154
INFO:root:current mean train loss 2238.1681479802205
INFO:root:current train perplexity5.856329441070557
INFO:root:current mean train loss 2234.071154507724
INFO:root:current train perplexity5.838415622711182
INFO:root:current mean train loss 2230.8925748841953
INFO:root:current train perplexity5.833781719207764
INFO:root:current mean train loss 2230.0633173403535
INFO:root:current train perplexity5.820213317871094
INFO:root:current mean train loss 2229.5688542091043
INFO:root:current train perplexity5.811581611633301
INFO:root:current mean train loss 2227.2587241314827
INFO:root:current train perplexity5.797246932983398
INFO:root:current mean train loss 2226.258535608999
INFO:root:current train perplexity5.791451454162598
INFO:root:current mean train loss 2228.2156646472067
INFO:root:current train perplexity5.802999496459961
INFO:root:current mean train loss 2230.389037389719
INFO:root:current train perplexity5.809709548950195
INFO:root:current mean train loss 2231.8710262510513
INFO:root:current train perplexity5.811988830566406
INFO:root:current mean train loss 2231.736125421981
INFO:root:current train perplexity5.811940670013428
INFO:root:current mean train loss 2230.641356248122
INFO:root:current train perplexity5.809675216674805
INFO:root:current mean train loss 2231.250876182367
INFO:root:current train perplexity5.808228969573975
INFO:root:current mean train loss 2231.0998336162766
INFO:root:current train perplexity5.804791450500488
INFO:root:current mean train loss 2231.4049167586872
INFO:root:current train perplexity5.808370113372803
INFO:root:current mean train loss 2231.7422959837195
INFO:root:current train perplexity5.80869197845459
INFO:root:current mean train loss 2232.405092045761
INFO:root:current train perplexity5.812602996826172
INFO:root:current mean train loss 2230.8641207335427
INFO:root:current train perplexity5.811570644378662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it]
INFO:root:final mean train loss: 2229.8572768434033
INFO:root:final train perplexity: 5.8112664222717285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2175.2689546625666
INFO:root:eval perplexity: 5.8139472007751465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2547.704176016733
INFO:root:eval perplexity: 8.121708869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/10
  5%|â–Œ         | 10/200 [1:01:50<19:35:57, 371.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2211.654443713202
INFO:root:current train perplexity5.73795223236084
INFO:root:current mean train loss 2204.434857069388
INFO:root:current train perplexity5.74070405960083
INFO:root:current mean train loss 2209.6194020097582
INFO:root:current train perplexity5.740675926208496
INFO:root:current mean train loss 2210.3814971841125
INFO:root:current train perplexity5.716772556304932
INFO:root:current mean train loss 2204.5609112639927
INFO:root:current train perplexity5.6934733390808105
INFO:root:current mean train loss 2207.7272322777076
INFO:root:current train perplexity5.7104926109313965
INFO:root:current mean train loss 2210.634234646511
INFO:root:current train perplexity5.715996742248535
INFO:root:current mean train loss 2210.392843695394
INFO:root:current train perplexity5.7169189453125
INFO:root:current mean train loss 2209.4335305375253
INFO:root:current train perplexity5.715010166168213
INFO:root:current mean train loss 2208.8100790017897
INFO:root:current train perplexity5.711401462554932
INFO:root:current mean train loss 2209.1446293401764
INFO:root:current train perplexity5.710768699645996
INFO:root:current mean train loss 2208.157842866165
INFO:root:current train perplexity5.705634117126465
INFO:root:current mean train loss 2207.234927731297
INFO:root:current train perplexity5.7037882804870605
INFO:root:current mean train loss 2207.59173472525
INFO:root:current train perplexity5.703488349914551
INFO:root:current mean train loss 2207.7274421707475
INFO:root:current train perplexity5.704379558563232
INFO:root:current mean train loss 2208.3170909796495
INFO:root:current train perplexity5.707483291625977
INFO:root:current mean train loss 2208.02158611245
INFO:root:current train perplexity5.709810256958008
INFO:root:current mean train loss 2208.2582635874123
INFO:root:current train perplexity5.7094407081604
INFO:root:current mean train loss 2208.9011630838477
INFO:root:current train perplexity5.710446834564209
INFO:root:current mean train loss 2208.3148807740686
INFO:root:current train perplexity5.710707664489746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.04s/it]
INFO:root:final mean train loss: 2207.2672636539
INFO:root:final train perplexity: 5.708581447601318
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 2168.345273714539
INFO:root:eval perplexity: 5.781463623046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2550.655527967088
INFO:root:eval perplexity: 8.141439437866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/11
  6%|â–Œ         | 11/200 [1:08:02<19:30:17, 371.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2206.6064367959666
INFO:root:current train perplexity5.596949100494385
INFO:root:current mean train loss 2195.693208427839
INFO:root:current train perplexity5.6134209632873535
INFO:root:current mean train loss 2199.732911863527
INFO:root:current train perplexity5.630163192749023
INFO:root:current mean train loss 2200.602581122996
INFO:root:current train perplexity5.639094829559326
INFO:root:current mean train loss 2197.980354717239
INFO:root:current train perplexity5.629194736480713
INFO:root:current mean train loss 2193.821493415702
INFO:root:current train perplexity5.62278413772583
INFO:root:current mean train loss 2193.334998661853
INFO:root:current train perplexity5.626087665557861
INFO:root:current mean train loss 2194.52639125989
INFO:root:current train perplexity5.631496429443359
INFO:root:current mean train loss 2191.952650083107
INFO:root:current train perplexity5.624231815338135
INFO:root:current mean train loss 2193.1318047390023
INFO:root:current train perplexity5.624841690063477
INFO:root:current mean train loss 2191.4079777557768
INFO:root:current train perplexity5.62060546875
INFO:root:current mean train loss 2191.781923239388
INFO:root:current train perplexity5.617307186126709
INFO:root:current mean train loss 2191.614956062281
INFO:root:current train perplexity5.622232913970947
INFO:root:current mean train loss 2189.918675013951
INFO:root:current train perplexity5.6177215576171875
INFO:root:current mean train loss 2188.746598871367
INFO:root:current train perplexity5.618428707122803
INFO:root:current mean train loss 2187.474461828475
INFO:root:current train perplexity5.61649751663208
INFO:root:current mean train loss 2187.6244791377057
INFO:root:current train perplexity5.614296913146973
INFO:root:current mean train loss 2187.661607219017
INFO:root:current train perplexity5.612552642822266
INFO:root:current mean train loss 2187.585023202421
INFO:root:current train perplexity5.613892078399658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it]
INFO:root:final mean train loss: 2186.0974056149635
INFO:root:final train perplexity: 5.613998889923096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2156.0513045939992
INFO:root:eval perplexity: 5.724232196807861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2538.40214289672
INFO:root:eval perplexity: 8.059837341308594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/12
  6%|â–Œ         | 12/200 [1:14:13<19:24:21, 371.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2279.255615234375
INFO:root:current train perplexity5.925579071044922
INFO:root:current mean train loss 2175.6869038702216
INFO:root:current train perplexity5.563764572143555
INFO:root:current mean train loss 2172.5185468701893
INFO:root:current train perplexity5.546513557434082
INFO:root:current mean train loss 2171.741612198329
INFO:root:current train perplexity5.54768705368042
INFO:root:current mean train loss 2172.0887717727396
INFO:root:current train perplexity5.542788505554199
INFO:root:current mean train loss 2175.350109305107
INFO:root:current train perplexity5.538637161254883
INFO:root:current mean train loss 2173.825755661795
INFO:root:current train perplexity5.537196636199951
INFO:root:current mean train loss 2171.5736716041183
INFO:root:current train perplexity5.53156852722168
INFO:root:current mean train loss 2169.986145551594
INFO:root:current train perplexity5.536368370056152
INFO:root:current mean train loss 2170.395049947441
INFO:root:current train perplexity5.528449535369873
INFO:root:current mean train loss 2170.5216002383477
INFO:root:current train perplexity5.527883052825928
INFO:root:current mean train loss 2169.7992886277834
INFO:root:current train perplexity5.528508186340332
INFO:root:current mean train loss 2169.924064046427
INFO:root:current train perplexity5.525357723236084
INFO:root:current mean train loss 2168.333435386488
INFO:root:current train perplexity5.526271820068359
INFO:root:current mean train loss 2168.5083990987505
INFO:root:current train perplexity5.528453350067139
INFO:root:current mean train loss 2167.6700274581044
INFO:root:current train perplexity5.525078296661377
INFO:root:current mean train loss 2169.5098075842902
INFO:root:current train perplexity5.529401779174805
INFO:root:current mean train loss 2170.0837352884846
INFO:root:current train perplexity5.534718036651611
INFO:root:current mean train loss 2169.5220536302345
INFO:root:current train perplexity5.532045364379883
INFO:root:current mean train loss 2168.0709191952265
INFO:root:current train perplexity5.531353950500488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.62s/it]
INFO:root:final mean train loss: 2166.8304420274976
INFO:root:final train perplexity: 5.529282093048096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2147.0463520888743
INFO:root:eval perplexity: 5.682670593261719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2531.5604005637742
INFO:root:eval perplexity: 8.014629364013672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/13
  6%|â–‹         | 13/200 [1:20:25<19:18:07, 371.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2131.531146240234
INFO:root:current train perplexity5.455033302307129
INFO:root:current mean train loss 2158.9014424641928
INFO:root:current train perplexity5.481165885925293
INFO:root:current mean train loss 2151.2674932306463
INFO:root:current train perplexity5.439697265625
INFO:root:current mean train loss 2151.9533336639406
INFO:root:current train perplexity5.454166412353516
INFO:root:current mean train loss 2151.7171003069197
INFO:root:current train perplexity5.449501991271973
INFO:root:current mean train loss 2150.8966010460485
INFO:root:current train perplexity5.447682857513428
INFO:root:current mean train loss 2149.2192075667845
INFO:root:current train perplexity5.45005464553833
INFO:root:current mean train loss 2148.2725848727755
INFO:root:current train perplexity5.443203926086426
INFO:root:current mean train loss 2149.9242564131573
INFO:root:current train perplexity5.449660301208496
INFO:root:current mean train loss 2150.564133353855
INFO:root:current train perplexity5.451948165893555
INFO:root:current mean train loss 2150.1793684417125
INFO:root:current train perplexity5.452062129974365
INFO:root:current mean train loss 2149.4818858555386
INFO:root:current train perplexity5.450545787811279
INFO:root:current mean train loss 2150.330242619749
INFO:root:current train perplexity5.453708171844482
INFO:root:current mean train loss 2150.7351872299655
INFO:root:current train perplexity5.454052448272705
INFO:root:current mean train loss 2150.7717720998844
INFO:root:current train perplexity5.456063270568848
INFO:root:current mean train loss 2150.09951171875
INFO:root:current train perplexity5.45588493347168
INFO:root:current mean train loss 2150.372579767675
INFO:root:current train perplexity5.457749366760254
INFO:root:current mean train loss 2150.6910799248276
INFO:root:current train perplexity5.458506107330322
INFO:root:current mean train loss 2150.8091798216433
INFO:root:current train perplexity5.457308292388916
INFO:root:current mean train loss 2150.1917682647704
INFO:root:current train perplexity5.455750465393066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.11s/it]
INFO:root:final mean train loss: 2149.341802723048
INFO:root:final train perplexity: 5.453490734100342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2140.355551861702
INFO:root:eval perplexity: 5.6519880294799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2531.838308347878
INFO:root:eval perplexity: 8.016458511352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/14
  7%|â–‹         | 14/200 [1:26:36<19:11:21, 371.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2148.5983028927367
INFO:root:current train perplexity5.341543197631836
INFO:root:current mean train loss 2148.235032575844
INFO:root:current train perplexity5.363367557525635
INFO:root:current mean train loss 2143.1522577342103
INFO:root:current train perplexity5.348014831542969
INFO:root:current mean train loss 2135.7604132858864
INFO:root:current train perplexity5.354186058044434
INFO:root:current mean train loss 2137.314514020488
INFO:root:current train perplexity5.369096755981445
INFO:root:current mean train loss 2139.224143825652
INFO:root:current train perplexity5.380069732666016
INFO:root:current mean train loss 2135.9153763368327
INFO:root:current train perplexity5.378232002258301
INFO:root:current mean train loss 2134.9252550391684
INFO:root:current train perplexity5.380387306213379
INFO:root:current mean train loss 2135.2595200259484
INFO:root:current train perplexity5.389557838439941
INFO:root:current mean train loss 2134.404634555096
INFO:root:current train perplexity5.384068965911865
INFO:root:current mean train loss 2136.4487549534415
INFO:root:current train perplexity5.383484840393066
INFO:root:current mean train loss 2134.5910402967306
INFO:root:current train perplexity5.378899574279785
INFO:root:current mean train loss 2133.1417574809266
INFO:root:current train perplexity5.3743672370910645
INFO:root:current mean train loss 2132.098062268459
INFO:root:current train perplexity5.374389171600342
INFO:root:current mean train loss 2133.407186891772
INFO:root:current train perplexity5.375063896179199
INFO:root:current mean train loss 2132.3710676204405
INFO:root:current train perplexity5.375123500823975
INFO:root:current mean train loss 2131.999746090767
INFO:root:current train perplexity5.374448299407959
INFO:root:current mean train loss 2131.3151529385705
INFO:root:current train perplexity5.371952533721924
INFO:root:current mean train loss 2132.0125403489897
INFO:root:current train perplexity5.377055644989014
INFO:root:current mean train loss 2133.2602216398586
INFO:root:current train perplexity5.380393028259277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it]
INFO:root:final mean train loss: 2132.8262108106896
INFO:root:final train perplexity: 5.382870674133301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2131.940417999917
INFO:root:eval perplexity: 5.613630771636963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2521.711729658411
INFO:root:eval perplexity: 7.949995517730713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/15
  8%|â–Š         | 15/200 [1:32:48<19:05:31, 371.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2093.4706805193864
INFO:root:current train perplexity5.294158458709717
INFO:root:current mean train loss 2124.0902820933948
INFO:root:current train perplexity5.3188886642456055
INFO:root:current mean train loss 2127.6637381005476
INFO:root:current train perplexity5.330239295959473
INFO:root:current mean train loss 2123.963023040254
INFO:root:current train perplexity5.324816703796387
INFO:root:current mean train loss 2122.9170604823444
INFO:root:current train perplexity5.31387996673584
INFO:root:current mean train loss 2118.168994008419
INFO:root:current train perplexity5.314694404602051
INFO:root:current mean train loss 2115.1351596470636
INFO:root:current train perplexity5.305882453918457
INFO:root:current mean train loss 2111.3428883843458
INFO:root:current train perplexity5.3043904304504395
INFO:root:current mean train loss 2113.651548005937
INFO:root:current train perplexity5.3037309646606445
INFO:root:current mean train loss 2113.0333524500047
INFO:root:current train perplexity5.300225734710693
INFO:root:current mean train loss 2113.02697545437
INFO:root:current train perplexity5.30033016204834
INFO:root:current mean train loss 2115.4252241058616
INFO:root:current train perplexity5.306934833526611
INFO:root:current mean train loss 2116.6319288043883
INFO:root:current train perplexity5.3057026863098145
INFO:root:current mean train loss 2117.115285763536
INFO:root:current train perplexity5.310521125793457
INFO:root:current mean train loss 2117.5536159006406
INFO:root:current train perplexity5.309337615966797
INFO:root:current mean train loss 2117.220189000035
INFO:root:current train perplexity5.30967378616333
INFO:root:current mean train loss 2117.499513490024
INFO:root:current train perplexity5.314393997192383
INFO:root:current mean train loss 2117.297454033637
INFO:root:current train perplexity5.314352989196777
INFO:root:current mean train loss 2117.1905876414803
INFO:root:current train perplexity5.313277721405029
INFO:root:current mean train loss 2117.2817605212863
INFO:root:current train perplexity5.3148956298828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it]
INFO:root:final mean train loss: 2116.454726226391
INFO:root:final train perplexity: 5.313769817352295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2125.595282804881
INFO:root:eval perplexity: 5.584880352020264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2521.560169409353
INFO:root:eval perplexity: 7.949006080627441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/16
  8%|â–Š         | 16/200 [1:39:00<18:59:36, 371.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.7191162109375
INFO:root:current train perplexity5.166745662689209
INFO:root:current mean train loss 2075.3141468784265
INFO:root:current train perplexity5.193000793457031
INFO:root:current mean train loss 2089.3281722966153
INFO:root:current train perplexity5.217728137969971
INFO:root:current mean train loss 2094.7859673101625
INFO:root:current train perplexity5.2332539558410645
INFO:root:current mean train loss 2094.8227215096704
INFO:root:current train perplexity5.234955310821533
INFO:root:current mean train loss 2098.4349837695654
INFO:root:current train perplexity5.244552135467529
INFO:root:current mean train loss 2099.571331814398
INFO:root:current train perplexity5.249068737030029
INFO:root:current mean train loss 2098.8165981426314
INFO:root:current train perplexity5.250190734863281
INFO:root:current mean train loss 2095.7967059795674
INFO:root:current train perplexity5.249320030212402
INFO:root:current mean train loss 2095.9708952191686
INFO:root:current train perplexity5.250112533569336
INFO:root:current mean train loss 2097.0673091827875
INFO:root:current train perplexity5.251318454742432
INFO:root:current mean train loss 2097.972712437787
INFO:root:current train perplexity5.255989074707031
INFO:root:current mean train loss 2099.020606640471
INFO:root:current train perplexity5.250389575958252
INFO:root:current mean train loss 2099.630259618891
INFO:root:current train perplexity5.250894069671631
INFO:root:current mean train loss 2100.467754600001
INFO:root:current train perplexity5.254560947418213
INFO:root:current mean train loss 2101.1903058300345
INFO:root:current train perplexity5.25479793548584
INFO:root:current mean train loss 2101.2535290812248
INFO:root:current train perplexity5.251071929931641
INFO:root:current mean train loss 2101.720306517107
INFO:root:current train perplexity5.251757621765137
INFO:root:current mean train loss 2102.281883512953
INFO:root:current train perplexity5.251664161682129
INFO:root:current mean train loss 2102.601814258407
INFO:root:current train perplexity5.254088878631592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.32s/it]
INFO:root:final mean train loss: 2102.2158931668696
INFO:root:final train perplexity: 5.254391193389893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2120.5444686564992
INFO:root:eval perplexity: 5.562100887298584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2519.584617235982
INFO:root:eval perplexity: 7.9361066818237305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/17
  8%|â–Š         | 17/200 [1:45:12<18:53:57, 371.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2095.3709217418323
INFO:root:current train perplexity5.202457904815674
INFO:root:current mean train loss 2076.9806284803026
INFO:root:current train perplexity5.183064937591553
INFO:root:current mean train loss 2080.149765862359
INFO:root:current train perplexity5.172491073608398
INFO:root:current mean train loss 2080.2202324621458
INFO:root:current train perplexity5.169397354125977
INFO:root:current mean train loss 2083.6822299644596
INFO:root:current train perplexity5.177743434906006
INFO:root:current mean train loss 2084.6575234341785
INFO:root:current train perplexity5.179582595825195
INFO:root:current mean train loss 2084.642693098201
INFO:root:current train perplexity5.178146839141846
INFO:root:current mean train loss 2084.062669628163
INFO:root:current train perplexity5.180881977081299
INFO:root:current mean train loss 2087.6297155156867
INFO:root:current train perplexity5.183024883270264
INFO:root:current mean train loss 2088.200949109035
INFO:root:current train perplexity5.181492805480957
INFO:root:current mean train loss 2087.5670702317184
INFO:root:current train perplexity5.182170867919922
INFO:root:current mean train loss 2088.2759999490345
INFO:root:current train perplexity5.182427883148193
INFO:root:current mean train loss 2087.493997514618
INFO:root:current train perplexity5.183771133422852
INFO:root:current mean train loss 2088.115001139792
INFO:root:current train perplexity5.1892313957214355
INFO:root:current mean train loss 2088.112106323242
INFO:root:current train perplexity5.193102836608887
INFO:root:current mean train loss 2088.6019810597304
INFO:root:current train perplexity5.192777633666992
INFO:root:current mean train loss 2088.670904656722
INFO:root:current train perplexity5.193347454071045
INFO:root:current mean train loss 2088.2214701607722
INFO:root:current train perplexity5.1946797370910645
INFO:root:current mean train loss 2087.46076195927
INFO:root:current train perplexity5.1926727294921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.24s/it]
INFO:root:final mean train loss: 2087.6040962746333
INFO:root:final train perplexity: 5.194148540496826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2118.434754716589
INFO:root:eval perplexity: 5.552613258361816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2519.9328773444427
INFO:root:eval perplexity: 7.938379287719727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/18
  9%|â–‰         | 18/200 [1:51:24<18:48:10, 371.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2134.2685791015624
INFO:root:current train perplexity5.277742862701416
INFO:root:current mean train loss 2084.8449974423365
INFO:root:current train perplexity5.156495571136475
INFO:root:current mean train loss 2073.3719565786964
INFO:root:current train perplexity5.1449971199035645
INFO:root:current mean train loss 2068.586304911629
INFO:root:current train perplexity5.133592128753662
INFO:root:current mean train loss 2066.8503592785496
INFO:root:current train perplexity5.131753921508789
INFO:root:current mean train loss 2066.729574373453
INFO:root:current train perplexity5.122513771057129
INFO:root:current mean train loss 2064.945431140238
INFO:root:current train perplexity5.1144585609436035
INFO:root:current mean train loss 2066.732070554909
INFO:root:current train perplexity5.120747089385986
INFO:root:current mean train loss 2066.2275713618496
INFO:root:current train perplexity5.119651794433594
INFO:root:current mean train loss 2067.352110535005
INFO:root:current train perplexity5.121805667877197
INFO:root:current mean train loss 2068.8338199141012
INFO:root:current train perplexity5.124197483062744
INFO:root:current mean train loss 2069.3488866745615
INFO:root:current train perplexity5.128551006317139
INFO:root:current mean train loss 2070.38958248914
INFO:root:current train perplexity5.129213333129883
INFO:root:current mean train loss 2071.081658117068
INFO:root:current train perplexity5.130458831787109
INFO:root:current mean train loss 2073.433174540564
INFO:root:current train perplexity5.13245153427124
INFO:root:current mean train loss 2073.8658231513446
INFO:root:current train perplexity5.133359909057617
INFO:root:current mean train loss 2073.3089952510463
INFO:root:current train perplexity5.134984970092773
INFO:root:current mean train loss 2073.2113372892227
INFO:root:current train perplexity5.135550498962402
INFO:root:current mean train loss 2073.9649813073493
INFO:root:current train perplexity5.137823104858398
INFO:root:current mean train loss 2074.1654981878487
INFO:root:current train perplexity5.138607501983643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.45s/it]
INFO:root:final mean train loss: 2074.1569644468213
INFO:root:final train perplexity: 5.139317035675049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2111.8960069155864
INFO:root:eval perplexity: 5.52331018447876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2513.9521207335993
INFO:root:eval perplexity: 7.899441242218018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/19
 10%|â–‰         | 19/200 [1:57:35<18:41:29, 371.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2026.9821166992188
INFO:root:current train perplexity5.026459693908691
INFO:root:current mean train loss 2067.6202772797133
INFO:root:current train perplexity5.022370338439941
INFO:root:current mean train loss 2066.8151195629225
INFO:root:current train perplexity5.047611713409424
INFO:root:current mean train loss 2061.2467029642617
INFO:root:current train perplexity5.0400519371032715
INFO:root:current mean train loss 2059.1693361110597
INFO:root:current train perplexity5.053164482116699
INFO:root:current mean train loss 2056.3505113389756
INFO:root:current train perplexity5.058790683746338
INFO:root:current mean train loss 2053.1797738519895
INFO:root:current train perplexity5.058273792266846
INFO:root:current mean train loss 2054.540363174396
INFO:root:current train perplexity5.063470840454102
INFO:root:current mean train loss 2055.409878844472
INFO:root:current train perplexity5.06431245803833
INFO:root:current mean train loss 2056.707084606113
INFO:root:current train perplexity5.067729949951172
INFO:root:current mean train loss 2058.6799272212497
INFO:root:current train perplexity5.077770709991455
INFO:root:current mean train loss 2059.2100486279382
INFO:root:current train perplexity5.081005573272705
INFO:root:current mean train loss 2059.7442242361717
INFO:root:current train perplexity5.0818352699279785
INFO:root:current mean train loss 2061.1050391954664
INFO:root:current train perplexity5.081705093383789
INFO:root:current mean train loss 2060.1391013530406
INFO:root:current train perplexity5.077013969421387
INFO:root:current mean train loss 2059.1911647561033
INFO:root:current train perplexity5.07792329788208
INFO:root:current mean train loss 2060.075184475185
INFO:root:current train perplexity5.078522682189941
INFO:root:current mean train loss 2060.3171649715764
INFO:root:current train perplexity5.081014633178711
INFO:root:current mean train loss 2061.1566417371664
INFO:root:current train perplexity5.083828926086426
INFO:root:current mean train loss 2060.938113082584
INFO:root:current train perplexity5.085525989532471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.25s/it]
INFO:root:final mean train loss: 2061.3876070069714
INFO:root:final train perplexity: 5.087784767150879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2107.485651976673
INFO:root:eval perplexity: 5.503632068634033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2511.4954033168497
INFO:root:eval perplexity: 7.883502960205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/20
 10%|â–ˆ         | 20/200 [2:03:48<18:35:40, 371.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2050.8445325020034
INFO:root:current train perplexity4.9752326011657715
INFO:root:current mean train loss 2030.235870580879
INFO:root:current train perplexity4.949877738952637
INFO:root:current mean train loss 2037.4652400954499
INFO:root:current train perplexity4.97113561630249
INFO:root:current mean train loss 2042.2270385382099
INFO:root:current train perplexity4.9989237785339355
INFO:root:current mean train loss 2041.7198591992633
INFO:root:current train perplexity5.006799221038818
INFO:root:current mean train loss 2037.0080147426513
INFO:root:current train perplexity5.006686210632324
INFO:root:current mean train loss 2036.5888994721367
INFO:root:current train perplexity5.003974437713623
INFO:root:current mean train loss 2037.7334281704584
INFO:root:current train perplexity5.012091159820557
INFO:root:current mean train loss 2039.7205915303282
INFO:root:current train perplexity5.01795768737793
INFO:root:current mean train loss 2041.9020130291533
INFO:root:current train perplexity5.020172595977783
INFO:root:current mean train loss 2043.0506049001067
INFO:root:current train perplexity5.02631139755249
INFO:root:current mean train loss 2043.8589664556355
INFO:root:current train perplexity5.031030654907227
INFO:root:current mean train loss 2043.9714729857117
INFO:root:current train perplexity5.030881404876709
INFO:root:current mean train loss 2045.1349740288344
INFO:root:current train perplexity5.033329010009766
INFO:root:current mean train loss 2045.0537433425447
INFO:root:current train perplexity5.034560203552246
INFO:root:current mean train loss 2046.7292633552377
INFO:root:current train perplexity5.036148548126221
INFO:root:current mean train loss 2048.9905046575896
INFO:root:current train perplexity5.038891315460205
INFO:root:current mean train loss 2048.8745077175954
INFO:root:current train perplexity5.0398054122924805
INFO:root:current mean train loss 2049.8808834040665
INFO:root:current train perplexity5.0416035652160645
INFO:root:current mean train loss 2050.61767257053
INFO:root:current train perplexity5.042476177215576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.04s/it]
INFO:root:final mean train loss: 2049.9833668272604
INFO:root:final train perplexity: 5.042200088500977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2106.673479661874
INFO:root:eval perplexity: 5.500017166137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2513.6084711602393
INFO:root:eval perplexity: 7.897209644317627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/21
 10%|â–ˆ         | 21/200 [2:10:00<18:29:38, 371.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2034.1695186070033
INFO:root:current train perplexity4.93617057800293
INFO:root:current mean train loss 2025.4183529584836
INFO:root:current train perplexity4.939281940460205
INFO:root:current mean train loss 2028.8212041854858
INFO:root:current train perplexity4.953530311584473
INFO:root:current mean train loss 2029.315107367012
INFO:root:current train perplexity4.954850673675537
INFO:root:current mean train loss 2031.5819386264734
INFO:root:current train perplexity4.963829040527344
INFO:root:current mean train loss 2032.9987700757363
INFO:root:current train perplexity4.967641830444336
INFO:root:current mean train loss 2033.6048723546471
INFO:root:current train perplexity4.974752426147461
INFO:root:current mean train loss 2033.5870545402406
INFO:root:current train perplexity4.981512069702148
INFO:root:current mean train loss 2033.179050195997
INFO:root:current train perplexity4.978118419647217
INFO:root:current mean train loss 2032.7404672790271
INFO:root:current train perplexity4.976123332977295
INFO:root:current mean train loss 2033.081734975179
INFO:root:current train perplexity4.979495525360107
INFO:root:current mean train loss 2035.8119655727928
INFO:root:current train perplexity4.988449573516846
INFO:root:current mean train loss 2036.251340732453
INFO:root:current train perplexity4.986649513244629
INFO:root:current mean train loss 2036.6920472991853
INFO:root:current train perplexity4.991035461425781
INFO:root:current mean train loss 2036.8804297814002
INFO:root:current train perplexity4.992191314697266
INFO:root:current mean train loss 2038.7760812323013
INFO:root:current train perplexity4.993053436279297
INFO:root:current mean train loss 2037.4122896056244
INFO:root:current train perplexity4.9908905029296875
INFO:root:current mean train loss 2037.4618675562135
INFO:root:current train perplexity4.992387771606445
INFO:root:current mean train loss 2038.9946444938923
INFO:root:current train perplexity4.995100498199463
INFO:root:current mean train loss 2039.3003631779022
INFO:root:current train perplexity4.996013641357422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.28s/it]
INFO:root:final mean train loss: 2038.4665468863268
INFO:root:final train perplexity: 4.996578216552734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2102.759195097795
INFO:root:eval perplexity: 5.482623100280762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2513.855536711131
INFO:root:eval perplexity: 7.8988142013549805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/22
 11%|â–ˆ         | 22/200 [2:16:13<18:24:35, 372.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.3392367428296
INFO:root:current train perplexity4.973172187805176
INFO:root:current mean train loss 2045.486349998871
INFO:root:current train perplexity4.987963676452637
INFO:root:current mean train loss 2036.6622614039607
INFO:root:current train perplexity4.958889484405518
INFO:root:current mean train loss 2028.3534907527649
INFO:root:current train perplexity4.936583995819092
INFO:root:current mean train loss 2026.6206663748678
INFO:root:current train perplexity4.929216384887695
INFO:root:current mean train loss 2026.5444274156714
INFO:root:current train perplexity4.936488151550293
INFO:root:current mean train loss 2025.7386489119963
INFO:root:current train perplexity4.931894779205322
INFO:root:current mean train loss 2025.5005329719336
INFO:root:current train perplexity4.935962677001953
INFO:root:current mean train loss 2023.8778157272427
INFO:root:current train perplexity4.931738376617432
INFO:root:current mean train loss 2022.3846768009698
INFO:root:current train perplexity4.931670188903809
INFO:root:current mean train loss 2024.1411100958178
INFO:root:current train perplexity4.937439441680908
INFO:root:current mean train loss 2024.8957956611653
INFO:root:current train perplexity4.9417901039123535
INFO:root:current mean train loss 2024.8562813374533
INFO:root:current train perplexity4.9420366287231445
INFO:root:current mean train loss 2025.2744644731827
INFO:root:current train perplexity4.945655822753906
INFO:root:current mean train loss 2026.1547657642247
INFO:root:current train perplexity4.94630765914917
INFO:root:current mean train loss 2026.4317022421826
INFO:root:current train perplexity4.946334362030029
INFO:root:current mean train loss 2027.1047306368612
INFO:root:current train perplexity4.946686744689941
INFO:root:current mean train loss 2027.371095264691
INFO:root:current train perplexity4.948966979980469
INFO:root:current mean train loss 2026.9912900583538
INFO:root:current train perplexity4.9491071701049805
INFO:root:current mean train loss 2027.4799551018832
INFO:root:current train perplexity4.950463771820068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.81s/it]
INFO:root:final mean train loss: 2026.6421175450312
INFO:root:final train perplexity: 4.950168132781982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2100.8179879695813
INFO:root:eval perplexity: 5.474018096923828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 2511.0009527544603
INFO:root:eval perplexity: 7.880299091339111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/23
 12%|â–ˆâ–        | 23/200 [2:22:26<18:18:48, 372.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1994.8519748263889
INFO:root:current train perplexity4.868962287902832
INFO:root:current mean train loss 2003.518787263569
INFO:root:current train perplexity4.866110801696777
INFO:root:current mean train loss 2009.7655243972251
INFO:root:current train perplexity4.860827922821045
INFO:root:current mean train loss 2010.2474803435496
INFO:root:current train perplexity4.870960235595703
INFO:root:current mean train loss 2012.3516247807718
INFO:root:current train perplexity4.869950771331787
INFO:root:current mean train loss 2011.7380900754767
INFO:root:current train perplexity4.8737311363220215
INFO:root:current mean train loss 2011.2339252858922
INFO:root:current train perplexity4.878213405609131
INFO:root:current mean train loss 2014.5677000407932
INFO:root:current train perplexity4.88179874420166
INFO:root:current mean train loss 2016.797310475553
INFO:root:current train perplexity4.8896989822387695
INFO:root:current mean train loss 2014.9406647036774
INFO:root:current train perplexity4.890574932098389
INFO:root:current mean train loss 2015.8262892416858
INFO:root:current train perplexity4.895171642303467
INFO:root:current mean train loss 2016.3414828773307
INFO:root:current train perplexity4.902451515197754
INFO:root:current mean train loss 2018.4206501332364
INFO:root:current train perplexity4.910112380981445
INFO:root:current mean train loss 2017.9284090988929
INFO:root:current train perplexity4.906397819519043
INFO:root:current mean train loss 2019.6853591816537
INFO:root:current train perplexity4.911251544952393
INFO:root:current mean train loss 2019.0280750970421
INFO:root:current train perplexity4.912339210510254
INFO:root:current mean train loss 2017.4236651719675
INFO:root:current train perplexity4.909882545471191
INFO:root:current mean train loss 2016.847331092877
INFO:root:current train perplexity4.910867691040039
INFO:root:current mean train loss 2016.40489250062
INFO:root:current train perplexity4.907654285430908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.22s/it]
INFO:root:final mean train loss: 2015.8617325944847
INFO:root:final train perplexity: 4.908230781555176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2098.75295479416
INFO:root:eval perplexity: 5.464877605438232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2511.6755392737423
INFO:root:eval perplexity: 7.884672164916992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/24
 12%|â–ˆâ–        | 24/200 [2:28:38<18:12:22, 372.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.997349330357
INFO:root:current train perplexity4.666659832000732
INFO:root:current mean train loss 1969.5076117114486
INFO:root:current train perplexity4.77664852142334
INFO:root:current mean train loss 1975.5973767266757
INFO:root:current train perplexity4.804442882537842
INFO:root:current mean train loss 1990.5760275377902
INFO:root:current train perplexity4.832160949707031
INFO:root:current mean train loss 1993.9393244562923
INFO:root:current train perplexity4.837296962738037
INFO:root:current mean train loss 1995.8828180377066
INFO:root:current train perplexity4.833611011505127
INFO:root:current mean train loss 1996.2981888144177
INFO:root:current train perplexity4.840405464172363
INFO:root:current mean train loss 1997.6854441425587
INFO:root:current train perplexity4.84283971786499
INFO:root:current mean train loss 1999.9140204485168
INFO:root:current train perplexity4.847452640533447
INFO:root:current mean train loss 2001.2225893603138
INFO:root:current train perplexity4.849948406219482
INFO:root:current mean train loss 2003.1566106347366
INFO:root:current train perplexity4.853727340698242
INFO:root:current mean train loss 2003.7629185015808
INFO:root:current train perplexity4.854373455047607
INFO:root:current mean train loss 2002.560761787522
INFO:root:current train perplexity4.85165548324585
INFO:root:current mean train loss 2003.8678879799875
INFO:root:current train perplexity4.855857849121094
INFO:root:current mean train loss 2004.3913177728823
INFO:root:current train perplexity4.858548164367676
INFO:root:current mean train loss 2004.6326956138282
INFO:root:current train perplexity4.859572410583496
INFO:root:current mean train loss 2004.724655331776
INFO:root:current train perplexity4.8595871925354
INFO:root:current mean train loss 2004.0725046167893
INFO:root:current train perplexity4.858523845672607
INFO:root:current mean train loss 2006.5234333116439
INFO:root:current train perplexity4.866079807281494
INFO:root:current mean train loss 2006.7304138919728
INFO:root:current train perplexity4.869801998138428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.91s/it]
INFO:root:final mean train loss: 2005.888439830601
INFO:root:final train perplexity: 4.869750499725342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2098.7321907205783
INFO:root:eval perplexity: 5.464785575866699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2512.120427990636
INFO:root:eval perplexity: 7.887556552886963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/25
 12%|â–ˆâ–Ž        | 25/200 [2:34:50<18:05:44, 372.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1946.122049967448
INFO:root:current train perplexity4.668187618255615
INFO:root:current mean train loss 1979.121799592049
INFO:root:current train perplexity4.76150369644165
INFO:root:current mean train loss 1989.0959025791713
INFO:root:current train perplexity4.783182144165039
INFO:root:current mean train loss 1989.2459528416764
INFO:root:current train perplexity4.78840970993042
INFO:root:current mean train loss 1989.1980867205925
INFO:root:current train perplexity4.792105674743652
INFO:root:current mean train loss 1989.102330331584
INFO:root:current train perplexity4.7915143966674805
INFO:root:current mean train loss 1989.269058227539
INFO:root:current train perplexity4.799734115600586
INFO:root:current mean train loss 1987.1942157218468
INFO:root:current train perplexity4.794566631317139
INFO:root:current mean train loss 1989.0806726251992
INFO:root:current train perplexity4.79695987701416
INFO:root:current mean train loss 1989.299528576079
INFO:root:current train perplexity4.800369739532471
INFO:root:current mean train loss 1990.8662230968475
INFO:root:current train perplexity4.803710460662842
INFO:root:current mean train loss 1992.623211735084
INFO:root:current train perplexity4.810613632202148
INFO:root:current mean train loss 1993.104542252285
INFO:root:current train perplexity4.813930511474609
INFO:root:current mean train loss 1993.846615794202
INFO:root:current train perplexity4.819527626037598
INFO:root:current mean train loss 1993.5823568279823
INFO:root:current train perplexity4.823563098907471
INFO:root:current mean train loss 1993.0799383528902
INFO:root:current train perplexity4.825583457946777
INFO:root:current mean train loss 1995.3804026636585
INFO:root:current train perplexity4.82895565032959
INFO:root:current mean train loss 1995.2475896777796
INFO:root:current train perplexity4.830373287200928
INFO:root:current mean train loss 1996.3468455264442
INFO:root:current train perplexity4.831310272216797
INFO:root:current mean train loss 1995.9365944336953
INFO:root:current train perplexity4.830625534057617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.43s/it]
INFO:root:final mean train loss: 1995.5822270057206
INFO:root:final train perplexity: 4.830302715301514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2095.587482425338
INFO:root:eval perplexity: 5.450897693634033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2511.929343798482
INFO:root:eval perplexity: 7.88631534576416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/26
 13%|â–ˆâ–Ž        | 26/200 [2:41:01<17:58:48, 372.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.1980605706935
INFO:root:current train perplexity4.782780170440674
INFO:root:current mean train loss 1989.2064866952016
INFO:root:current train perplexity4.775097846984863
INFO:root:current mean train loss 1977.4476835005512
INFO:root:current train perplexity4.766473770141602
INFO:root:current mean train loss 1981.1522632050724
INFO:root:current train perplexity4.772607326507568
INFO:root:current mean train loss 1979.6509744034333
INFO:root:current train perplexity4.768848419189453
INFO:root:current mean train loss 1978.9935936777958
INFO:root:current train perplexity4.7675557136535645
INFO:root:current mean train loss 1979.7735251011602
INFO:root:current train perplexity4.768662929534912
INFO:root:current mean train loss 1985.4756859330191
INFO:root:current train perplexity4.780939102172852
INFO:root:current mean train loss 1986.6362094221445
INFO:root:current train perplexity4.790830135345459
INFO:root:current mean train loss 1985.030101682884
INFO:root:current train perplexity4.791705131530762
INFO:root:current mean train loss 1985.950342946048
INFO:root:current train perplexity4.788711071014404
INFO:root:current mean train loss 1986.9244930391035
INFO:root:current train perplexity4.7939019203186035
INFO:root:current mean train loss 1985.8315913640713
INFO:root:current train perplexity4.792419910430908
INFO:root:current mean train loss 1986.1252002644949
INFO:root:current train perplexity4.790920257568359
INFO:root:current mean train loss 1986.9124393291063
INFO:root:current train perplexity4.792985916137695
INFO:root:current mean train loss 1985.92700789425
INFO:root:current train perplexity4.7935309410095215
INFO:root:current mean train loss 1985.874534258241
INFO:root:current train perplexity4.795260906219482
INFO:root:current mean train loss 1986.8834676550832
INFO:root:current train perplexity4.795921325683594
INFO:root:current mean train loss 1987.3086445407982
INFO:root:current train perplexity4.797181129455566
INFO:root:current mean train loss 1987.4093130780889
INFO:root:current train perplexity4.796709060668945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.55s/it]
INFO:root:final mean train loss: 1986.5906312974246
INFO:root:final train perplexity: 4.796148300170898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2095.392322296792
INFO:root:eval perplexity: 5.450036525726318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2517.083171871537
INFO:root:eval perplexity: 7.919804096221924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/27
 14%|â–ˆâ–Ž        | 27/200 [2:47:13<17:52:10, 371.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1971.1746257913524
INFO:root:current train perplexity4.774199962615967
INFO:root:current mean train loss 1971.9273333972014
INFO:root:current train perplexity4.7347564697265625
INFO:root:current mean train loss 1970.3660126915274
INFO:root:current train perplexity4.7272868156433105
INFO:root:current mean train loss 1969.7506621802986
INFO:root:current train perplexity4.733820915222168
INFO:root:current mean train loss 1970.7254270861763
INFO:root:current train perplexity4.738961219787598
INFO:root:current mean train loss 1971.21728187479
INFO:root:current train perplexity4.742505073547363
INFO:root:current mean train loss 1967.3777209806588
INFO:root:current train perplexity4.739505290985107
INFO:root:current mean train loss 1968.4715898257132
INFO:root:current train perplexity4.747506618499756
INFO:root:current mean train loss 1970.884534004407
INFO:root:current train perplexity4.747051239013672
INFO:root:current mean train loss 1973.069707245319
INFO:root:current train perplexity4.74971342086792
INFO:root:current mean train loss 1973.7464892670428
INFO:root:current train perplexity4.752591133117676
INFO:root:current mean train loss 1975.0812098580527
INFO:root:current train perplexity4.754451274871826
INFO:root:current mean train loss 1976.2903888744845
INFO:root:current train perplexity4.7573628425598145
INFO:root:current mean train loss 1977.0880086502727
INFO:root:current train perplexity4.75787878036499
INFO:root:current mean train loss 1977.521793234659
INFO:root:current train perplexity4.756325721740723
INFO:root:current mean train loss 1977.4790555393283
INFO:root:current train perplexity4.755001068115234
INFO:root:current mean train loss 1977.2347223629279
INFO:root:current train perplexity4.755438327789307
INFO:root:current mean train loss 1977.731757154237
INFO:root:current train perplexity4.756007671356201
INFO:root:current mean train loss 1977.7925186403602
INFO:root:current train perplexity4.759756088256836
INFO:root:current mean train loss 1976.8974969725566
INFO:root:current train perplexity4.7573137283325195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.08s/it]
INFO:root:final mean train loss: 1976.8519188000346
INFO:root:final train perplexity: 4.759426116943359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2092.6254471582724
INFO:root:eval perplexity: 5.43784761428833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2515.819506922512
INFO:root:eval perplexity: 7.911579132080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/28
 14%|â–ˆâ–        | 28/200 [2:53:25<17:46:08, 371.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1940.4690559895832
INFO:root:current train perplexity4.660214424133301
INFO:root:current mean train loss 1949.2541043526785
INFO:root:current train perplexity4.68100643157959
INFO:root:current mean train loss 1951.8228284801137
INFO:root:current train perplexity4.686801433563232
INFO:root:current mean train loss 1958.3658997395833
INFO:root:current train perplexity4.694695949554443
INFO:root:current mean train loss 1962.4739280941612
INFO:root:current train perplexity4.705071926116943
INFO:root:current mean train loss 1963.239874108356
INFO:root:current train perplexity4.709792613983154
INFO:root:current mean train loss 1965.9401448567708
INFO:root:current train perplexity4.71731424331665
INFO:root:current mean train loss 1964.6472330204133
INFO:root:current train perplexity4.714345932006836
INFO:root:current mean train loss 1967.0611090959821
INFO:root:current train perplexity4.71523380279541
INFO:root:current mean train loss 1967.5418568459536
INFO:root:current train perplexity4.721320152282715
INFO:root:current mean train loss 1968.8879427461845
INFO:root:current train perplexity4.721071243286133
INFO:root:current mean train loss 1967.759892266456
INFO:root:current train perplexity4.720940589904785
INFO:root:current mean train loss 1967.4743499157476
INFO:root:current train perplexity4.71978235244751
INFO:root:current mean train loss 1967.4490622336648
INFO:root:current train perplexity4.722074031829834
INFO:root:current mean train loss 1968.1659196239407
INFO:root:current train perplexity4.720250606536865
INFO:root:current mean train loss 1968.5647574869793
INFO:root:current train perplexity4.721706390380859
INFO:root:current mean train loss 1969.6111618178638
INFO:root:current train perplexity4.7234787940979
INFO:root:current mean train loss 1968.816572471941
INFO:root:current train perplexity4.726158142089844
INFO:root:current mean train loss 1968.2321486979167
INFO:root:current train perplexity4.724695682525635
INFO:root:current mean train loss 1967.9979125049447
INFO:root:current train perplexity4.724893569946289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.52s/it]
INFO:root:final mean train loss: 1967.5745719413353
INFO:root:final train perplexity: 4.72470760345459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2092.723468753463
INFO:root:eval perplexity: 5.438278675079346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2515.7494550123283
INFO:root:eval perplexity: 7.911122798919678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/29
 14%|â–ˆâ–        | 29/200 [2:59:37<17:40:22, 372.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.8154641856318
INFO:root:current train perplexity4.628818988800049
INFO:root:current mean train loss 1937.1460787455242
INFO:root:current train perplexity4.636011123657227
INFO:root:current mean train loss 1938.1572683674015
INFO:root:current train perplexity4.635706901550293
INFO:root:current mean train loss 1945.291404879823
INFO:root:current train perplexity4.652384281158447
INFO:root:current mean train loss 1950.601605671208
INFO:root:current train perplexity4.667222499847412
INFO:root:current mean train loss 1951.1994787680137
INFO:root:current train perplexity4.673482894897461
INFO:root:current mean train loss 1952.0867501848695
INFO:root:current train perplexity4.6731367111206055
INFO:root:current mean train loss 1952.2026092837555
INFO:root:current train perplexity4.67371129989624
INFO:root:current mean train loss 1952.9741562642323
INFO:root:current train perplexity4.674011707305908
INFO:root:current mean train loss 1952.9226293256206
INFO:root:current train perplexity4.674099922180176
INFO:root:current mean train loss 1953.7755137013864
INFO:root:current train perplexity4.675833225250244
INFO:root:current mean train loss 1954.9550756672086
INFO:root:current train perplexity4.681016445159912
INFO:root:current mean train loss 1955.0533636228956
INFO:root:current train perplexity4.682093620300293
INFO:root:current mean train loss 1955.9101875568258
INFO:root:current train perplexity4.680075168609619
INFO:root:current mean train loss 1957.080210995099
INFO:root:current train perplexity4.68330192565918
INFO:root:current mean train loss 1958.3428172202566
INFO:root:current train perplexity4.6866254806518555
INFO:root:current mean train loss 1958.2128401952432
INFO:root:current train perplexity4.686783790588379
INFO:root:current mean train loss 1958.2829337801252
INFO:root:current train perplexity4.6890387535095215
INFO:root:current mean train loss 1958.329292797387
INFO:root:current train perplexity4.689169406890869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.80s/it]
INFO:root:final mean train loss: 1958.1562218062516
INFO:root:final train perplexity: 4.689719200134277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2092.6913443490967
INFO:root:eval perplexity: 5.438137531280518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2520.7715852345136
INFO:root:eval perplexity: 7.94385290145874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/30
 15%|â–ˆâ–Œ        | 30/200 [3:05:49<17:33:52, 371.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1898.6617702907986
INFO:root:current train perplexity4.5337066650390625
INFO:root:current mean train loss 1935.4221986543148
INFO:root:current train perplexity4.63386869430542
INFO:root:current mean train loss 1946.467129794034
INFO:root:current train perplexity4.630731582641602
INFO:root:current mean train loss 1944.3699943270883
INFO:root:current train perplexity4.620923042297363
INFO:root:current mean train loss 1949.2143715856128
INFO:root:current train perplexity4.630452632904053
INFO:root:current mean train loss 1949.050520561533
INFO:root:current train perplexity4.63357400894165
INFO:root:current mean train loss 1947.9062979060832
INFO:root:current train perplexity4.63486909866333
INFO:root:current mean train loss 1952.358288591436
INFO:root:current train perplexity4.64060115814209
INFO:root:current mean train loss 1951.1431130313756
INFO:root:current train perplexity4.643782138824463
INFO:root:current mean train loss 1952.0300262081873
INFO:root:current train perplexity4.64736795425415
INFO:root:current mean train loss 1952.3047951735164
INFO:root:current train perplexity4.6529035568237305
INFO:root:current mean train loss 1950.753762715566
INFO:root:current train perplexity4.651800632476807
INFO:root:current mean train loss 1950.3519514287375
INFO:root:current train perplexity4.654266357421875
INFO:root:current mean train loss 1951.3706612350195
INFO:root:current train perplexity4.65566349029541
INFO:root:current mean train loss 1951.080447974655
INFO:root:current train perplexity4.655327320098877
INFO:root:current mean train loss 1950.363642769037
INFO:root:current train perplexity4.656217575073242
INFO:root:current mean train loss 1949.9876468485375
INFO:root:current train perplexity4.656357288360596
INFO:root:current mean train loss 1949.9865560514875
INFO:root:current train perplexity4.6573686599731445
INFO:root:current mean train loss 1949.9926173440524
INFO:root:current train perplexity4.658831596374512
INFO:root:current mean train loss 1950.748505358049
INFO:root:current train perplexity4.659161567687988

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.99s/it]
INFO:root:final mean train loss: 1949.2988737397764
INFO:root:final train perplexity: 4.657051086425781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2093.259413266013
INFO:root:eval perplexity: 5.440638542175293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2524.9287884218475
INFO:root:eval perplexity: 7.971053123474121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/31
 16%|â–ˆâ–Œ        | 31/200 [3:12:01<17:27:33, 371.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.3258760892427
INFO:root:current train perplexity4.641287326812744
INFO:root:current mean train loss 1928.2545786055307
INFO:root:current train perplexity4.605422019958496
INFO:root:current mean train loss 1927.0049076586697
INFO:root:current train perplexity4.596219062805176
INFO:root:current mean train loss 1929.5532177884154
INFO:root:current train perplexity4.606448173522949
INFO:root:current mean train loss 1929.9852357962882
INFO:root:current train perplexity4.603222370147705
INFO:root:current mean train loss 1933.025393641947
INFO:root:current train perplexity4.610848426818848
INFO:root:current mean train loss 1934.199106624713
INFO:root:current train perplexity4.616644382476807
INFO:root:current mean train loss 1933.748822340952
INFO:root:current train perplexity4.612753391265869
INFO:root:current mean train loss 1933.7560563722477
INFO:root:current train perplexity4.611551284790039
INFO:root:current mean train loss 1934.4632070059395
INFO:root:current train perplexity4.6120710372924805
INFO:root:current mean train loss 1934.4600357739782
INFO:root:current train perplexity4.6163153648376465
INFO:root:current mean train loss 1934.6029220770772
INFO:root:current train perplexity4.616235733032227
INFO:root:current mean train loss 1937.167324445765
INFO:root:current train perplexity4.621858596801758
INFO:root:current mean train loss 1936.0468140569028
INFO:root:current train perplexity4.618042945861816
INFO:root:current mean train loss 1936.1542408904388
INFO:root:current train perplexity4.618640422821045
INFO:root:current mean train loss 1937.627314376331
INFO:root:current train perplexity4.621743202209473
INFO:root:current mean train loss 1939.0414332616226
INFO:root:current train perplexity4.622408390045166
INFO:root:current mean train loss 1940.4524561593596
INFO:root:current train perplexity4.6261887550354
INFO:root:current mean train loss 1941.5837587521605
INFO:root:current train perplexity4.628418922424316
INFO:root:current mean train loss 1941.9532942885799
INFO:root:current train perplexity4.628288269042969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it]
INFO:root:final mean train loss: 1941.395408457238
INFO:root:final train perplexity: 4.628093719482422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2093.1735614749555
INFO:root:eval perplexity: 5.4402594566345215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2525.607840896498
INFO:root:eval perplexity: 7.975501537322998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/32
 16%|â–ˆâ–Œ        | 32/200 [3:18:12<17:21:03, 371.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1935.3259589616644
INFO:root:current train perplexity4.581686019897461
INFO:root:current mean train loss 1931.9578729376092
INFO:root:current train perplexity4.5430216789245605
INFO:root:current mean train loss 1928.461758334941
INFO:root:current train perplexity4.550483226776123
INFO:root:current mean train loss 1933.3758722866937
INFO:root:current train perplexity4.569765567779541
INFO:root:current mean train loss 1937.6908479780968
INFO:root:current train perplexity4.580462455749512
INFO:root:current mean train loss 1936.1336712635243
INFO:root:current train perplexity4.583159923553467
INFO:root:current mean train loss 1937.6467406657027
INFO:root:current train perplexity4.589473724365234
INFO:root:current mean train loss 1935.4276640572425
INFO:root:current train perplexity4.585896968841553
INFO:root:current mean train loss 1935.655268514142
INFO:root:current train perplexity4.586986541748047
INFO:root:current mean train loss 1934.2072027697923
INFO:root:current train perplexity4.580698013305664
INFO:root:current mean train loss 1936.452809466383
INFO:root:current train perplexity4.585009574890137
INFO:root:current mean train loss 1936.1798635033902
INFO:root:current train perplexity4.583874225616455
INFO:root:current mean train loss 1937.2275298311167
INFO:root:current train perplexity4.58754301071167
INFO:root:current mean train loss 1936.170895074431
INFO:root:current train perplexity4.590779781341553
INFO:root:current mean train loss 1934.6183313064416
INFO:root:current train perplexity4.590490341186523
INFO:root:current mean train loss 1933.528135427004
INFO:root:current train perplexity4.590668201446533
INFO:root:current mean train loss 1933.6415595845776
INFO:root:current train perplexity4.592112064361572
INFO:root:current mean train loss 1934.358935042626
INFO:root:current train perplexity4.593506336212158
INFO:root:current mean train loss 1934.1606131360638
INFO:root:current train perplexity4.594587802886963
INFO:root:current mean train loss 1933.0580749354654
INFO:root:current train perplexity4.594720363616943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.77s/it]
INFO:root:final mean train loss: 1932.615133172986
INFO:root:final train perplexity: 4.596135139465332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2093.3332342053136
INFO:root:eval perplexity: 5.440962791442871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2525.5838670662956
INFO:root:eval perplexity: 7.975343704223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/33
 16%|â–ˆâ–‹        | 33/200 [3:24:24<17:14:48, 371.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1906.6112263997395
INFO:root:current train perplexity4.494375228881836
INFO:root:current mean train loss 1909.8521278381347
INFO:root:current train perplexity4.521888256072998
INFO:root:current mean train loss 1914.733647273137
INFO:root:current train perplexity4.533693313598633
INFO:root:current mean train loss 1912.1742377387152
INFO:root:current train perplexity4.544149398803711
INFO:root:current mean train loss 1916.2487623131794
INFO:root:current train perplexity4.551476001739502
INFO:root:current mean train loss 1921.443564278739
INFO:root:current train perplexity4.559857368469238
INFO:root:current mean train loss 1919.8898171164772
INFO:root:current train perplexity4.554277420043945
INFO:root:current mean train loss 1920.3644495913857
INFO:root:current train perplexity4.559572696685791
INFO:root:current mean train loss 1922.0863816372184
INFO:root:current train perplexity4.5635480880737305
INFO:root:current mean train loss 1924.479504776001
INFO:root:current train perplexity4.563506603240967
INFO:root:current mean train loss 1923.0984278265034
INFO:root:current train perplexity4.563961982727051
INFO:root:current mean train loss 1922.9995976941339
INFO:root:current train perplexity4.559947490692139
INFO:root:current mean train loss 1923.7973669627356
INFO:root:current train perplexity4.562751770019531
INFO:root:current mean train loss 1923.4652036779066
INFO:root:current train perplexity4.560741901397705
INFO:root:current mean train loss 1925.164259902745
INFO:root:current train perplexity4.563034534454346
INFO:root:current mean train loss 1924.5200206267527
INFO:root:current train perplexity4.562355995178223
INFO:root:current mean train loss 1924.3461858174887
INFO:root:current train perplexity4.563918113708496
INFO:root:current mean train loss 1924.5761589743875
INFO:root:current train perplexity4.5647501945495605
INFO:root:current mean train loss 1924.335438389932
INFO:root:current train perplexity4.566898822784424
INFO:root:current mean train loss 1925.3560253532564
INFO:root:current train perplexity4.5677289962768555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.50s/it]
INFO:root:final mean train loss: 1924.9146238510739
INFO:root:final train perplexity: 4.5682878494262695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2092.0198165136026
INFO:root:eval perplexity: 5.435184001922607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 2526.0681853598735
INFO:root:eval perplexity: 7.978521823883057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/34
 17%|â–ˆâ–‹        | 34/200 [3:30:37<17:09:11, 372.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1927.1011978743913
INFO:root:current train perplexity4.545770645141602
INFO:root:current mean train loss 1917.26019942289
INFO:root:current train perplexity4.526744842529297
INFO:root:current mean train loss 1913.0615987949852
INFO:root:current train perplexity4.522161483764648
INFO:root:current mean train loss 1915.8863285783116
INFO:root:current train perplexity4.533518314361572
INFO:root:current mean train loss 1913.6299196639152
INFO:root:current train perplexity4.532815456390381
INFO:root:current mean train loss 1915.3942299880848
INFO:root:current train perplexity4.530684947967529
INFO:root:current mean train loss 1915.610664942416
INFO:root:current train perplexity4.530389785766602
INFO:root:current mean train loss 1915.2693483801881
INFO:root:current train perplexity4.530015468597412
INFO:root:current mean train loss 1915.626265940128
INFO:root:current train perplexity4.534861087799072
INFO:root:current mean train loss 1914.2858406933694
INFO:root:current train perplexity4.536623001098633
INFO:root:current mean train loss 1914.8535949650359
INFO:root:current train perplexity4.535894870758057
INFO:root:current mean train loss 1916.1586789606786
INFO:root:current train perplexity4.535075664520264
INFO:root:current mean train loss 1916.7964789645225
INFO:root:current train perplexity4.53598690032959
INFO:root:current mean train loss 1917.4850391617874
INFO:root:current train perplexity4.538914680480957
INFO:root:current mean train loss 1917.8813316226408
INFO:root:current train perplexity4.539078712463379
INFO:root:current mean train loss 1917.7674473077343
INFO:root:current train perplexity4.53628396987915
INFO:root:current mean train loss 1917.4135376777263
INFO:root:current train perplexity4.535460948944092
INFO:root:current mean train loss 1916.5358567288838
INFO:root:current train perplexity4.535506248474121
INFO:root:current mean train loss 1917.6286239989845
INFO:root:current train perplexity4.537557125091553
INFO:root:current mean train loss 1917.0974214329042
INFO:root:current train perplexity4.537747859954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.76s/it]
INFO:root:final mean train loss: 1916.384900314785
INFO:root:final train perplexity: 4.537639141082764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2092.656166022551
INFO:root:eval perplexity: 5.43798303604126
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2528.3667161008143
INFO:root:eval perplexity: 7.993612766265869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/35
 18%|â–ˆâ–Š        | 35/200 [3:36:48<17:02:45, 371.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.6973941884141
INFO:root:current train perplexity4.47174596786499
INFO:root:current mean train loss 1904.2058583682344
INFO:root:current train perplexity4.48284387588501
INFO:root:current mean train loss 1900.035779888127
INFO:root:current train perplexity4.475831985473633
INFO:root:current mean train loss 1900.7407939155694
INFO:root:current train perplexity4.480440616607666
INFO:root:current mean train loss 1905.149300393788
INFO:root:current train perplexity4.4898834228515625
INFO:root:current mean train loss 1905.2860130027489
INFO:root:current train perplexity4.494170188903809
INFO:root:current mean train loss 1903.8545884014206
INFO:root:current train perplexity4.489973068237305
INFO:root:current mean train loss 1904.1903133056026
INFO:root:current train perplexity4.492312431335449
INFO:root:current mean train loss 1904.7219875941607
INFO:root:current train perplexity4.492045879364014
INFO:root:current mean train loss 1907.105107696963
INFO:root:current train perplexity4.498926162719727
INFO:root:current mean train loss 1906.8543138800417
INFO:root:current train perplexity4.499483585357666
INFO:root:current mean train loss 1906.7270870751872
INFO:root:current train perplexity4.498732089996338
INFO:root:current mean train loss 1907.6883543978518
INFO:root:current train perplexity4.501067638397217
INFO:root:current mean train loss 1907.574769642637
INFO:root:current train perplexity4.50187349319458
INFO:root:current mean train loss 1908.8639543525665
INFO:root:current train perplexity4.503735542297363
INFO:root:current mean train loss 1909.609849190323
INFO:root:current train perplexity4.503275394439697
INFO:root:current mean train loss 1909.3768771012813
INFO:root:current train perplexity4.504169940948486
INFO:root:current mean train loss 1909.2437413448474
INFO:root:current train perplexity4.506914138793945
INFO:root:current mean train loss 1909.4423763673938
INFO:root:current train perplexity4.509960651397705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.76s/it]
INFO:root:final mean train loss: 1908.6771241465542
INFO:root:final train perplexity: 4.510120391845703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2092.8167802526596
INFO:root:eval perplexity: 5.438689231872559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2530.8399692833
INFO:root:eval perplexity: 8.009883880615234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/36
 18%|â–ˆâ–Š        | 36/200 [3:43:00<16:56:18, 371.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.4821333451705
INFO:root:current train perplexity4.365267276763916
INFO:root:current mean train loss 1879.038344374648
INFO:root:current train perplexity4.437807083129883
INFO:root:current mean train loss 1882.58880644161
INFO:root:current train perplexity4.459265232086182
INFO:root:current mean train loss 1892.247260286877
INFO:root:current train perplexity4.4670586585998535
INFO:root:current mean train loss 1894.0928022472817
INFO:root:current train perplexity4.47770881652832
INFO:root:current mean train loss 1895.766410932149
INFO:root:current train perplexity4.468870639801025
INFO:root:current mean train loss 1896.2297295353417
INFO:root:current train perplexity4.472386837005615
INFO:root:current mean train loss 1893.8826471642603
INFO:root:current train perplexity4.4629130363464355
INFO:root:current mean train loss 1894.2960465474723
INFO:root:current train perplexity4.467190265655518
INFO:root:current mean train loss 1893.950765063289
INFO:root:current train perplexity4.4704108238220215
INFO:root:current mean train loss 1895.2963879261715
INFO:root:current train perplexity4.472222805023193
INFO:root:current mean train loss 1897.2468419937697
INFO:root:current train perplexity4.474033355712891
INFO:root:current mean train loss 1899.3575875922534
INFO:root:current train perplexity4.47635555267334
INFO:root:current mean train loss 1900.4842006005374
INFO:root:current train perplexity4.4759345054626465
INFO:root:current mean train loss 1899.3964686295735
INFO:root:current train perplexity4.4747114181518555
INFO:root:current mean train loss 1899.9217139091973
INFO:root:current train perplexity4.475724697113037
INFO:root:current mean train loss 1900.501554483216
INFO:root:current train perplexity4.476816654205322
INFO:root:current mean train loss 1901.2120653126826
INFO:root:current train perplexity4.479920864105225
INFO:root:current mean train loss 1900.9278846879745
INFO:root:current train perplexity4.481333255767822
INFO:root:current mean train loss 1901.296792214482
INFO:root:current train perplexity4.481337070465088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.03s/it]
INFO:root:final mean train loss: 1900.621074943908
INFO:root:final train perplexity: 4.481536865234375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2096.136128310616
INFO:root:eval perplexity: 5.453318119049072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2533.4878877680353
INFO:root:eval perplexity: 8.027338981628418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/37
 18%|â–ˆâ–Š        | 37/200 [3:49:12<16:50:11, 371.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.0094168526787
INFO:root:current train perplexity4.453173637390137
INFO:root:current mean train loss 1874.5057134628296
INFO:root:current train perplexity4.40806245803833
INFO:root:current mean train loss 1885.929772092585
INFO:root:current train perplexity4.430925369262695
INFO:root:current mean train loss 1880.583623002215
INFO:root:current train perplexity4.41032600402832
INFO:root:current mean train loss 1886.4087692688558
INFO:root:current train perplexity4.4275031089782715
INFO:root:current mean train loss 1892.505202553489
INFO:root:current train perplexity4.435013771057129
INFO:root:current mean train loss 1891.6802900763835
INFO:root:current train perplexity4.437832355499268
INFO:root:current mean train loss 1891.1488218202696
INFO:root:current train perplexity4.439419269561768
INFO:root:current mean train loss 1893.6081156707617
INFO:root:current train perplexity4.445829391479492
INFO:root:current mean train loss 1893.6358521560144
INFO:root:current train perplexity4.442698001861572
INFO:root:current mean train loss 1894.2396544222702
INFO:root:current train perplexity4.4452128410339355
INFO:root:current mean train loss 1892.8073726140015
INFO:root:current train perplexity4.447385787963867
INFO:root:current mean train loss 1893.1884045927065
INFO:root:current train perplexity4.453577995300293
INFO:root:current mean train loss 1893.2809314957585
INFO:root:current train perplexity4.45305871963501
INFO:root:current mean train loss 1893.2163949319963
INFO:root:current train perplexity4.450471878051758
INFO:root:current mean train loss 1893.4010505875992
INFO:root:current train perplexity4.451567649841309
INFO:root:current mean train loss 1892.252774400266
INFO:root:current train perplexity4.451952934265137
INFO:root:current mean train loss 1893.1009774384675
INFO:root:current train perplexity4.452427387237549
INFO:root:current mean train loss 1893.4608651793499
INFO:root:current train perplexity4.453181743621826
INFO:root:current mean train loss 1893.8574100351927
INFO:root:current train perplexity4.455013275146484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.15s/it]
INFO:root:final mean train loss: 1893.5040327217382
INFO:root:final train perplexity: 4.456435203552246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2094.5934608405364
INFO:root:eval perplexity: 5.44651460647583
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2536.856325406555
INFO:root:eval perplexity: 8.049599647521973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/38
 19%|â–ˆâ–‰        | 38/200 [3:55:23<16:43:14, 371.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1854.1744411892362
INFO:root:current train perplexity4.340295314788818
INFO:root:current mean train loss 1858.5741387728988
INFO:root:current train perplexity4.3572998046875
INFO:root:current mean train loss 1867.103013392857
INFO:root:current train perplexity4.37553071975708
INFO:root:current mean train loss 1867.6971322322238
INFO:root:current train perplexity4.390413761138916
INFO:root:current mean train loss 1869.665151806092
INFO:root:current train perplexity4.3917646408081055
INFO:root:current mean train loss 1876.0198419133458
INFO:root:current train perplexity4.3935065269470215
INFO:root:current mean train loss 1878.6009966236677
INFO:root:current train perplexity4.400677680969238
INFO:root:current mean train loss 1880.4922697540899
INFO:root:current train perplexity4.408603191375732
INFO:root:current mean train loss 1879.4370303543362
INFO:root:current train perplexity4.408581733703613
INFO:root:current mean train loss 1880.5078208963707
INFO:root:current train perplexity4.410651683807373
INFO:root:current mean train loss 1881.5625497626345
INFO:root:current train perplexity4.4118266105651855
INFO:root:current mean train loss 1883.479087276542
INFO:root:current train perplexity4.413804531097412
INFO:root:current mean train loss 1883.810659140468
INFO:root:current train perplexity4.418120384216309
INFO:root:current mean train loss 1884.3162437013534
INFO:root:current train perplexity4.419366359710693
INFO:root:current mean train loss 1885.1077856360835
INFO:root:current train perplexity4.420809745788574
INFO:root:current mean train loss 1885.955714628843
INFO:root:current train perplexity4.423867225646973
INFO:root:current mean train loss 1885.526745197331
INFO:root:current train perplexity4.424106121063232
INFO:root:current mean train loss 1885.795800361524
INFO:root:current train perplexity4.425518035888672
INFO:root:current mean train loss 1886.479410410315
INFO:root:current train perplexity4.428082466125488
INFO:root:current mean train loss 1886.4447048471643
INFO:root:current train perplexity4.428648471832275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it]
INFO:root:final mean train loss: 1885.3483838703196
INFO:root:final train perplexity: 4.427844524383545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2095.1998278029423
INFO:root:eval perplexity: 5.449188232421875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2538.056631101784
INFO:root:eval perplexity: 8.057546615600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/39
 20%|â–ˆâ–‰        | 39/200 [4:01:34<16:36:28, 371.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.7826380575857
INFO:root:current train perplexity4.377053260803223
INFO:root:current mean train loss 1867.4123587902682
INFO:root:current train perplexity4.359842777252197
INFO:root:current mean train loss 1866.7624111029938
INFO:root:current train perplexity4.366348743438721
INFO:root:current mean train loss 1870.3445883060688
INFO:root:current train perplexity4.378000259399414
INFO:root:current mean train loss 1870.8060186476935
INFO:root:current train perplexity4.375612735748291
INFO:root:current mean train loss 1871.5136849074177
INFO:root:current train perplexity4.373999118804932
INFO:root:current mean train loss 1871.679870789865
INFO:root:current train perplexity4.377033710479736
INFO:root:current mean train loss 1871.5831673689715
INFO:root:current train perplexity4.378525257110596
INFO:root:current mean train loss 1872.5604038459796
INFO:root:current train perplexity4.38334846496582
INFO:root:current mean train loss 1872.8968401807758
INFO:root:current train perplexity4.383495807647705
INFO:root:current mean train loss 1872.7576988205847
INFO:root:current train perplexity4.38576602935791
INFO:root:current mean train loss 1874.8552102172641
INFO:root:current train perplexity4.390018939971924
INFO:root:current mean train loss 1873.8394887594716
INFO:root:current train perplexity4.389827251434326
INFO:root:current mean train loss 1874.120861081475
INFO:root:current train perplexity4.389912128448486
INFO:root:current mean train loss 1875.2199750448872
INFO:root:current train perplexity4.390638828277588
INFO:root:current mean train loss 1875.2557122185349
INFO:root:current train perplexity4.391002178192139
INFO:root:current mean train loss 1877.202809100834
INFO:root:current train perplexity4.394049644470215
INFO:root:current mean train loss 1877.1059318828259
INFO:root:current train perplexity4.398334503173828
INFO:root:current mean train loss 1877.932653244789
INFO:root:current train perplexity4.400684356689453
INFO:root:current mean train loss 1878.2301562947964
INFO:root:current train perplexity4.402139663696289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.26s/it]
INFO:root:final mean train loss: 1878.1242080819288
INFO:root:final train perplexity: 4.402670860290527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2096.126448394559
INFO:root:eval perplexity: 5.453275680541992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2540.0659803025264
INFO:root:eval perplexity: 8.070866584777832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/40
 20%|â–ˆâ–ˆ        | 40/200 [4:07:46<16:30:59, 371.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.0463604504548
INFO:root:current train perplexity4.315642356872559
INFO:root:current mean train loss 1859.9679691591743
INFO:root:current train perplexity4.347539901733398
INFO:root:current mean train loss 1860.7189302615368
INFO:root:current train perplexity4.352294921875
INFO:root:current mean train loss 1860.8043026081175
INFO:root:current train perplexity4.358311176300049
INFO:root:current mean train loss 1860.0127264034772
INFO:root:current train perplexity4.356759071350098
INFO:root:current mean train loss 1863.809068748988
INFO:root:current train perplexity4.364894866943359
INFO:root:current mean train loss 1865.367601532297
INFO:root:current train perplexity4.363821983337402
INFO:root:current mean train loss 1865.577240891267
INFO:root:current train perplexity4.365407943725586
INFO:root:current mean train loss 1868.2055432142793
INFO:root:current train perplexity4.371428966522217
INFO:root:current mean train loss 1865.7703624253863
INFO:root:current train perplexity4.365248203277588
INFO:root:current mean train loss 1867.2290313975252
INFO:root:current train perplexity4.3702168464660645
INFO:root:current mean train loss 1869.2558878477191
INFO:root:current train perplexity4.3745527267456055
INFO:root:current mean train loss 1868.9516455536248
INFO:root:current train perplexity4.373877048492432
INFO:root:current mean train loss 1869.8808790266385
INFO:root:current train perplexity4.371464729309082
INFO:root:current mean train loss 1868.9322683915968
INFO:root:current train perplexity4.3688435554504395
INFO:root:current mean train loss 1870.1764041255592
INFO:root:current train perplexity4.371305465698242
INFO:root:current mean train loss 1869.5324340602199
INFO:root:current train perplexity4.3708577156066895
INFO:root:current mean train loss 1869.932091372545
INFO:root:current train perplexity4.373826026916504
INFO:root:current mean train loss 1870.5584060644583
INFO:root:current train perplexity4.375180244445801
INFO:root:current mean train loss 1871.4102910886575
INFO:root:current train perplexity4.377779960632324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.92s/it]
INFO:root:final mean train loss: 1870.8718661232783
INFO:root:final train perplexity: 4.37754487991333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2095.8252065672095
INFO:root:eval perplexity: 5.451945781707764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2542.5666971409573
INFO:root:eval perplexity: 8.087478637695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/41
 20%|â–ˆâ–ˆ        | 41/200 [4:13:58<16:24:53, 371.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1860.37642288208
INFO:root:current train perplexity4.316997051239014
INFO:root:current mean train loss 1843.225884885204
INFO:root:current train perplexity4.3118577003479
INFO:root:current mean train loss 1844.8205471554318
INFO:root:current train perplexity4.317399024963379
INFO:root:current mean train loss 1847.6998102978023
INFO:root:current train perplexity4.320644378662109
INFO:root:current mean train loss 1850.3496364470452
INFO:root:current train perplexity4.3205790519714355
INFO:root:current mean train loss 1851.953181529205
INFO:root:current train perplexity4.327396869659424
INFO:root:current mean train loss 1855.7304375308684
INFO:root:current train perplexity4.33345890045166
INFO:root:current mean train loss 1857.6900151698433
INFO:root:current train perplexity4.338442325592041
INFO:root:current mean train loss 1859.0601791654315
INFO:root:current train perplexity4.340041160583496
INFO:root:current mean train loss 1860.392457280293
INFO:root:current train perplexity4.3405561447143555
INFO:root:current mean train loss 1862.8190884555343
INFO:root:current train perplexity4.343486785888672
INFO:root:current mean train loss 1863.390930379912
INFO:root:current train perplexity4.343168258666992
INFO:root:current mean train loss 1863.0173426498602
INFO:root:current train perplexity4.3445515632629395
INFO:root:current mean train loss 1863.0625735394933
INFO:root:current train perplexity4.345808506011963
INFO:root:current mean train loss 1863.2189526073435
INFO:root:current train perplexity4.346102237701416
INFO:root:current mean train loss 1863.1661329532326
INFO:root:current train perplexity4.347756385803223
INFO:root:current mean train loss 1862.684207268481
INFO:root:current train perplexity4.3479743003845215
INFO:root:current mean train loss 1863.4368556644974
INFO:root:current train perplexity4.350991249084473
INFO:root:current mean train loss 1863.8850939143056
INFO:root:current train perplexity4.352292060852051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.85s/it]
INFO:root:final mean train loss: 1863.5286781514947
INFO:root:final train perplexity: 4.352249622344971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2096.023019777122
INFO:root:eval perplexity: 5.452818870544434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2539.4722467517176
INFO:root:eval perplexity: 8.066930770874023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/42
 21%|â–ˆâ–ˆ        | 42/200 [4:20:09<16:18:44, 371.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1862.2059889573318
INFO:root:current train perplexity4.233242034912109
INFO:root:current mean train loss 1831.3820401081996
INFO:root:current train perplexity4.245551586151123
INFO:root:current mean train loss 1835.309405259683
INFO:root:current train perplexity4.263610363006592
INFO:root:current mean train loss 1839.487050406849
INFO:root:current train perplexity4.273599147796631
INFO:root:current mean train loss 1846.8772605175545
INFO:root:current train perplexity4.287290096282959
INFO:root:current mean train loss 1844.6816941646107
INFO:root:current train perplexity4.287715435028076
INFO:root:current mean train loss 1846.435676711613
INFO:root:current train perplexity4.292064666748047
INFO:root:current mean train loss 1848.521202911334
INFO:root:current train perplexity4.294219493865967
INFO:root:current mean train loss 1849.1115794727284
INFO:root:current train perplexity4.297307968139648
INFO:root:current mean train loss 1852.9288408962555
INFO:root:current train perplexity4.305883884429932
INFO:root:current mean train loss 1854.0476959921411
INFO:root:current train perplexity4.307770729064941
INFO:root:current mean train loss 1854.4675171227468
INFO:root:current train perplexity4.313583850860596
INFO:root:current mean train loss 1854.3640867329193
INFO:root:current train perplexity4.313623428344727
INFO:root:current mean train loss 1853.0785171497168
INFO:root:current train perplexity4.313078880310059
INFO:root:current mean train loss 1853.8793423511588
INFO:root:current train perplexity4.316539287567139
INFO:root:current mean train loss 1855.3244164990654
INFO:root:current train perplexity4.320991039276123
INFO:root:current mean train loss 1856.2979500966271
INFO:root:current train perplexity4.323218822479248
INFO:root:current mean train loss 1857.1061942595456
INFO:root:current train perplexity4.325471878051758
INFO:root:current mean train loss 1857.2809014970007
INFO:root:current train perplexity4.328047752380371
INFO:root:current mean train loss 1857.210321979752
INFO:root:current train perplexity4.328634262084961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.10s/it]
INFO:root:final mean train loss: 1856.5204788800506
INFO:root:final train perplexity: 4.328244209289551
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2101.4284100904533
INFO:root:eval perplexity: 5.4767231941223145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2550.055286596853
INFO:root:eval perplexity: 8.137422561645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/43
 22%|â–ˆâ–ˆâ–       | 43/200 [4:26:21<16:12:46, 371.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1829.0065307617188
INFO:root:current train perplexity4.208029747009277
INFO:root:current mean train loss 1840.0604388897236
INFO:root:current train perplexity4.239031791687012
INFO:root:current mean train loss 1845.0490505052649
INFO:root:current train perplexity4.245960712432861
INFO:root:current mean train loss 1845.0135080048533
INFO:root:current train perplexity4.267663955688477
INFO:root:current mean train loss 1845.2204271893168
INFO:root:current train perplexity4.275417327880859
INFO:root:current mean train loss 1845.686217110112
INFO:root:current train perplexity4.285019397735596
INFO:root:current mean train loss 1847.473531281002
INFO:root:current train perplexity4.288008689880371
INFO:root:current mean train loss 1847.1921742896511
INFO:root:current train perplexity4.290074825286865
INFO:root:current mean train loss 1848.4685135071536
INFO:root:current train perplexity4.293390274047852
INFO:root:current mean train loss 1850.392702951739
INFO:root:current train perplexity4.297222137451172
INFO:root:current mean train loss 1851.847113925971
INFO:root:current train perplexity4.298272132873535
INFO:root:current mean train loss 1851.7575684674018
INFO:root:current train perplexity4.2977519035339355
INFO:root:current mean train loss 1851.2265671644755
INFO:root:current train perplexity4.296596050262451
INFO:root:current mean train loss 1851.0837731841812
INFO:root:current train perplexity4.298055171966553
INFO:root:current mean train loss 1851.4752228850252
INFO:root:current train perplexity4.297524452209473
INFO:root:current mean train loss 1850.9028564453124
INFO:root:current train perplexity4.299201011657715
INFO:root:current mean train loss 1850.419672716761
INFO:root:current train perplexity4.30047082901001
INFO:root:current mean train loss 1849.5553280516167
INFO:root:current train perplexity4.300198554992676
INFO:root:current mean train loss 1849.5406276014985
INFO:root:current train perplexity4.30187463760376
INFO:root:current mean train loss 1850.569619861662
INFO:root:current train perplexity4.304469585418701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.29s/it]
INFO:root:final mean train loss: 1849.5468654584477
INFO:root:final train perplexity: 4.304488658905029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2098.8042342814992
INFO:root:eval perplexity: 5.465103626251221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2547.2338196233654
INFO:root:eval perplexity: 8.118568420410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/44
 22%|â–ˆâ–ˆâ–       | 44/200 [4:32:34<16:06:58, 371.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1835.0123914353392
INFO:root:current train perplexity4.282519817352295
INFO:root:current mean train loss 1837.8047215468218
INFO:root:current train perplexity4.246450424194336
INFO:root:current mean train loss 1833.474644958249
INFO:root:current train perplexity4.246859073638916
INFO:root:current mean train loss 1833.3669577826684
INFO:root:current train perplexity4.247664451599121
INFO:root:current mean train loss 1837.018756499493
INFO:root:current train perplexity4.243136882781982
INFO:root:current mean train loss 1838.0837946862146
INFO:root:current train perplexity4.248909950256348
INFO:root:current mean train loss 1837.3427287224088
INFO:root:current train perplexity4.2483744621276855
INFO:root:current mean train loss 1838.224311797973
INFO:root:current train perplexity4.2556071281433105
INFO:root:current mean train loss 1837.9317655777284
INFO:root:current train perplexity4.257776737213135
INFO:root:current mean train loss 1838.9687471641532
INFO:root:current train perplexity4.26412296295166
INFO:root:current mean train loss 1839.4211228743209
INFO:root:current train perplexity4.265694618225098
INFO:root:current mean train loss 1838.7510665986676
INFO:root:current train perplexity4.266312122344971
INFO:root:current mean train loss 1838.8809808579654
INFO:root:current train perplexity4.268465042114258
INFO:root:current mean train loss 1839.6053953446897
INFO:root:current train perplexity4.273758888244629
INFO:root:current mean train loss 1840.8731749349408
INFO:root:current train perplexity4.276582717895508
INFO:root:current mean train loss 1840.703992748692
INFO:root:current train perplexity4.275925159454346
INFO:root:current mean train loss 1841.0442527488426
INFO:root:current train perplexity4.276505470275879
INFO:root:current mean train loss 1841.756256400481
INFO:root:current train perplexity4.277989864349365
INFO:root:current mean train loss 1843.3725281918314
INFO:root:current train perplexity4.2812418937683105
INFO:root:current mean train loss 1844.0728391736486
INFO:root:current train perplexity4.283858776092529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it]
INFO:root:final mean train loss: 1843.22289903634
INFO:root:final train perplexity: 4.283059120178223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2100.3214721679688
INFO:root:eval perplexity: 5.471817970275879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2550.609342534491
INFO:root:eval perplexity: 8.141130447387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:38:45<16:00:19, 371.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.4474620819092
INFO:root:current train perplexity4.267086982727051
INFO:root:current mean train loss 1821.6767868414158
INFO:root:current train perplexity4.233006000518799
INFO:root:current mean train loss 1822.2675642533736
INFO:root:current train perplexity4.226990222930908
INFO:root:current mean train loss 1821.9864984868648
INFO:root:current train perplexity4.228017807006836
INFO:root:current mean train loss 1821.2911258565969
INFO:root:current train perplexity4.234747409820557
INFO:root:current mean train loss 1827.2025564207254
INFO:root:current train perplexity4.240520000457764
INFO:root:current mean train loss 1827.9908711996422
INFO:root:current train perplexity4.2389817237854
INFO:root:current mean train loss 1831.1248935879214
INFO:root:current train perplexity4.243536949157715
INFO:root:current mean train loss 1831.8146126358597
INFO:root:current train perplexity4.247529029846191
INFO:root:current mean train loss 1833.932111558083
INFO:root:current train perplexity4.252341270446777
INFO:root:current mean train loss 1832.8443152635618
INFO:root:current train perplexity4.254136085510254
INFO:root:current mean train loss 1832.6806165557546
INFO:root:current train perplexity4.2548112869262695
INFO:root:current mean train loss 1834.3343110869203
INFO:root:current train perplexity4.256140232086182
INFO:root:current mean train loss 1834.726617807517
INFO:root:current train perplexity4.255156993865967
INFO:root:current mean train loss 1835.1814268351905
INFO:root:current train perplexity4.256821155548096
INFO:root:current mean train loss 1835.4165821904721
INFO:root:current train perplexity4.257523059844971
INFO:root:current mean train loss 1835.768381192134
INFO:root:current train perplexity4.258833885192871
INFO:root:current mean train loss 1835.6539720461753
INFO:root:current train perplexity4.258017539978027
INFO:root:current mean train loss 1835.495507170714
INFO:root:current train perplexity4.259134769439697
INFO:root:current mean train loss 1837.0195809731415
INFO:root:current train perplexity4.260600566864014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.54s/it]
INFO:root:final mean train loss: 1836.6272442654654
INFO:root:final train perplexity: 4.260822296142578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 2101.8584044977283
INFO:root:eval perplexity: 5.478628635406494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2553.0734049479165
INFO:root:eval perplexity: 8.15764045715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:44:56<15:53:50, 371.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1828.1350233289932
INFO:root:current train perplexity4.2098894119262695
INFO:root:current mean train loss 1809.1099293745683
INFO:root:current train perplexity4.193907260894775
INFO:root:current mean train loss 1811.408253951429
INFO:root:current train perplexity4.204728603363037
INFO:root:current mean train loss 1814.5133867238762
INFO:root:current train perplexity4.218229293823242
INFO:root:current mean train loss 1816.6574336505978
INFO:root:current train perplexity4.221226692199707
INFO:root:current mean train loss 1818.1656796690108
INFO:root:current train perplexity4.2152886390686035
INFO:root:current mean train loss 1817.7629518214826
INFO:root:current train perplexity4.215643882751465
INFO:root:current mean train loss 1819.553281425056
INFO:root:current train perplexity4.2174835205078125
INFO:root:current mean train loss 1822.0119023404245
INFO:root:current train perplexity4.222152233123779
INFO:root:current mean train loss 1823.0103130126704
INFO:root:current train perplexity4.225998401641846
INFO:root:current mean train loss 1822.034907479511
INFO:root:current train perplexity4.224884510040283
INFO:root:current mean train loss 1823.5734535624272
INFO:root:current train perplexity4.227273941040039
INFO:root:current mean train loss 1825.1833323613448
INFO:root:current train perplexity4.228407859802246
INFO:root:current mean train loss 1827.4473421730743
INFO:root:current train perplexity4.229455947875977
INFO:root:current mean train loss 1827.9406289069093
INFO:root:current train perplexity4.2293620109558105
INFO:root:current mean train loss 1828.729544845282
INFO:root:current train perplexity4.2327961921691895
INFO:root:current mean train loss 1829.8006186590246
INFO:root:current train perplexity4.234949111938477
INFO:root:current mean train loss 1829.6627047847724
INFO:root:current train perplexity4.234744548797607
INFO:root:current mean train loss 1829.5613271255938
INFO:root:current train perplexity4.235668182373047
INFO:root:current mean train loss 1830.0531654107576
INFO:root:current train perplexity4.236706256866455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.56s/it]
INFO:root:final mean train loss: 1829.4640777172372
INFO:root:final train perplexity: 4.2368035316467285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2105.2511055587875
INFO:root:eval perplexity: 5.493690013885498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2558.98710513284
INFO:root:eval perplexity: 8.197397232055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:51:07<15:47:22, 371.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1823.3886619100765
INFO:root:current train perplexity4.194575786590576
INFO:root:current mean train loss 1808.4560922950204
INFO:root:current train perplexity4.166822910308838
INFO:root:current mean train loss 1809.1807550007866
INFO:root:current train perplexity4.184654712677002
INFO:root:current mean train loss 1807.7760273535646
INFO:root:current train perplexity4.183851718902588
INFO:root:current mean train loss 1809.0697555848394
INFO:root:current train perplexity4.190478324890137
INFO:root:current mean train loss 1810.6064159176422
INFO:root:current train perplexity4.193151473999023
INFO:root:current mean train loss 1811.8596590145953
INFO:root:current train perplexity4.199567794799805
INFO:root:current mean train loss 1814.299008018092
INFO:root:current train perplexity4.2066850662231445
INFO:root:current mean train loss 1816.411143687361
INFO:root:current train perplexity4.2026801109313965
INFO:root:current mean train loss 1818.0746708260272
INFO:root:current train perplexity4.201481342315674
INFO:root:current mean train loss 1818.9478813129697
INFO:root:current train perplexity4.203356742858887
INFO:root:current mean train loss 1817.9232682115048
INFO:root:current train perplexity4.204603672027588
INFO:root:current mean train loss 1818.488973796827
INFO:root:current train perplexity4.205138206481934
INFO:root:current mean train loss 1818.7785832264562
INFO:root:current train perplexity4.204922199249268
INFO:root:current mean train loss 1820.0513566428415
INFO:root:current train perplexity4.207927227020264
INFO:root:current mean train loss 1821.5562246081527
INFO:root:current train perplexity4.208843231201172
INFO:root:current mean train loss 1821.6685865781894
INFO:root:current train perplexity4.212323188781738
INFO:root:current mean train loss 1822.2426252015043
INFO:root:current train perplexity4.212113380432129
INFO:root:current mean train loss 1822.3543169284897
INFO:root:current train perplexity4.212270259857178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.46s/it]
INFO:root:final mean train loss: 1822.3947505518095
INFO:root:final train perplexity: 4.213231563568115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2105.5619987325467
INFO:root:eval perplexity: 5.495072841644287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2558.9678115303636
INFO:root:eval perplexity: 8.197266578674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/48
 24%|â–ˆâ–ˆâ–       | 48/200 [4:57:17<15:39:22, 370.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.682568359375
INFO:root:current train perplexity4.255886077880859
INFO:root:current mean train loss 1806.9408585258152
INFO:root:current train perplexity4.187042713165283
INFO:root:current mean train loss 1808.112971815952
INFO:root:current train perplexity4.175737380981445
INFO:root:current mean train loss 1816.9026595827133
INFO:root:current train perplexity4.164851665496826
INFO:root:current mean train loss 1815.6048478092055
INFO:root:current train perplexity4.167308807373047
INFO:root:current mean train loss 1815.3824240082677
INFO:root:current train perplexity4.166989803314209
INFO:root:current mean train loss 1815.8195209286077
INFO:root:current train perplexity4.168965816497803
INFO:root:current mean train loss 1817.092680561626
INFO:root:current train perplexity4.175487995147705
INFO:root:current mean train loss 1817.0649482961082
INFO:root:current train perplexity4.176968574523926
INFO:root:current mean train loss 1815.1225718013575
INFO:root:current train perplexity4.180215358734131
INFO:root:current mean train loss 1813.841438842172
INFO:root:current train perplexity4.17839241027832
INFO:root:current mean train loss 1813.7368892105171
INFO:root:current train perplexity4.179809093475342
INFO:root:current mean train loss 1815.237976023984
INFO:root:current train perplexity4.184814453125
INFO:root:current mean train loss 1816.323750427014
INFO:root:current train perplexity4.187560081481934
INFO:root:current mean train loss 1817.3958358926402
INFO:root:current train perplexity4.190515518188477
INFO:root:current mean train loss 1817.3057060417955
INFO:root:current train perplexity4.192437648773193
INFO:root:current mean train loss 1817.4007318927777
INFO:root:current train perplexity4.19293212890625
INFO:root:current mean train loss 1817.925522589058
INFO:root:current train perplexity4.19525671005249
INFO:root:current mean train loss 1817.2313311784392
INFO:root:current train perplexity4.194258213043213
INFO:root:current mean train loss 1817.1197931752815
INFO:root:current train perplexity4.193810939788818

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.53s/it]
INFO:root:final mean train loss: 1816.5330921659793
INFO:root:final train perplexity: 4.19378662109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2107.3157785834997
INFO:root:eval perplexity: 5.5028767585754395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2563.4024792393893
INFO:root:eval perplexity: 8.227208137512207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:03:27<15:32:48, 370.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.3766479492188
INFO:root:current train perplexity4.094374179840088
INFO:root:current mean train loss 1802.9231086499763
INFO:root:current train perplexity4.106640338897705
INFO:root:current mean train loss 1798.4025926261113
INFO:root:current train perplexity4.104925632476807
INFO:root:current mean train loss 1797.9087064811981
INFO:root:current train perplexity4.118358135223389
INFO:root:current mean train loss 1799.8550499810112
INFO:root:current train perplexity4.126046657562256
INFO:root:current mean train loss 1802.0187912560943
INFO:root:current train perplexity4.131686687469482
INFO:root:current mean train loss 1802.0138105561462
INFO:root:current train perplexity4.133973598480225
INFO:root:current mean train loss 1801.936376519542
INFO:root:current train perplexity4.137363910675049
INFO:root:current mean train loss 1803.8026488377498
INFO:root:current train perplexity4.141132831573486
INFO:root:current mean train loss 1805.2110750255667
INFO:root:current train perplexity4.145413875579834
INFO:root:current mean train loss 1805.197258054748
INFO:root:current train perplexity4.150625228881836
INFO:root:current mean train loss 1807.4718363731572
INFO:root:current train perplexity4.1541619300842285
INFO:root:current mean train loss 1807.9218390328545
INFO:root:current train perplexity4.157037258148193
INFO:root:current mean train loss 1806.4076748868008
INFO:root:current train perplexity4.155956268310547
INFO:root:current mean train loss 1808.1338417436823
INFO:root:current train perplexity4.15979528427124
INFO:root:current mean train loss 1809.367836815259
INFO:root:current train perplexity4.1637864112854
INFO:root:current mean train loss 1809.0681555504893
INFO:root:current train perplexity4.1635637283325195
INFO:root:current mean train loss 1809.8748358534885
INFO:root:current train perplexity4.166300296783447
INFO:root:current mean train loss 1810.6145607894164
INFO:root:current train perplexity4.1698150634765625
INFO:root:current mean train loss 1810.3700950101295
INFO:root:current train perplexity4.173647403717041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.42s/it]
INFO:root:final mean train loss: 1810.5256097729134
INFO:root:final train perplexity: 4.173949718475342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2106.239848251884
INFO:root:eval perplexity: 5.498087406158447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2564.61592350953
INFO:root:eval perplexity: 8.235421180725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:09:37<15:26:10, 370.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.5241101323343
INFO:root:current train perplexity4.087037563323975
INFO:root:current mean train loss 1794.3671743917785
INFO:root:current train perplexity4.1292500495910645
INFO:root:current mean train loss 1797.827370517225
INFO:root:current train perplexity4.126936435699463
INFO:root:current mean train loss 1800.249220009178
INFO:root:current train perplexity4.130370140075684
INFO:root:current mean train loss 1799.0715628371206
INFO:root:current train perplexity4.134801864624023
INFO:root:current mean train loss 1802.2131634488132
INFO:root:current train perplexity4.138589382171631
INFO:root:current mean train loss 1800.8044362119608
INFO:root:current train perplexity4.137782096862793
INFO:root:current mean train loss 1800.2704990117031
INFO:root:current train perplexity4.143239498138428
INFO:root:current mean train loss 1800.736862991387
INFO:root:current train perplexity4.144857883453369
INFO:root:current mean train loss 1800.1147369609869
INFO:root:current train perplexity4.1440558433532715
INFO:root:current mean train loss 1800.4769984155296
INFO:root:current train perplexity4.143774509429932
INFO:root:current mean train loss 1800.184653817518
INFO:root:current train perplexity4.145190238952637
INFO:root:current mean train loss 1800.6331689374938
INFO:root:current train perplexity4.146345138549805
INFO:root:current mean train loss 1802.627268661827
INFO:root:current train perplexity4.149846076965332
INFO:root:current mean train loss 1803.1061716020477
INFO:root:current train perplexity4.149191379547119
INFO:root:current mean train loss 1803.760640685523
INFO:root:current train perplexity4.1496500968933105
INFO:root:current mean train loss 1802.7844900821758
INFO:root:current train perplexity4.147221565246582
INFO:root:current mean train loss 1803.0548737113172
INFO:root:current train perplexity4.147573947906494
INFO:root:current mean train loss 1803.013376173037
INFO:root:current train perplexity4.148271560668945
INFO:root:current mean train loss 1803.5730185276304
INFO:root:current train perplexity4.149704456329346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.80s/it]
INFO:root:final mean train loss: 1803.3549283903412
INFO:root:final train perplexity: 4.15039587020874
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2110.500784799562
INFO:root:eval perplexity: 5.5170769691467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2571.025608793218
INFO:root:eval perplexity: 8.278929710388184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:15:46<15:19:11, 370.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.5079919063683
INFO:root:current train perplexity4.1035895347595215
INFO:root:current mean train loss 1784.8540186135165
INFO:root:current train perplexity4.088981628417969
INFO:root:current mean train loss 1789.949651961936
INFO:root:current train perplexity4.091965198516846
INFO:root:current mean train loss 1787.5971392855618
INFO:root:current train perplexity4.0992889404296875
INFO:root:current mean train loss 1788.263069120088
INFO:root:current train perplexity4.098621845245361
INFO:root:current mean train loss 1787.8699638447576
INFO:root:current train perplexity4.098895072937012
INFO:root:current mean train loss 1789.4551153326179
INFO:root:current train perplexity4.102822780609131
INFO:root:current mean train loss 1791.4222463104807
INFO:root:current train perplexity4.113536357879639
INFO:root:current mean train loss 1792.1168289008372
INFO:root:current train perplexity4.117218971252441
INFO:root:current mean train loss 1792.4632923450035
INFO:root:current train perplexity4.118022918701172
INFO:root:current mean train loss 1792.9443567787728
INFO:root:current train perplexity4.115128517150879
INFO:root:current mean train loss 1793.063869260392
INFO:root:current train perplexity4.11715030670166
INFO:root:current mean train loss 1793.8675655708494
INFO:root:current train perplexity4.118130207061768
INFO:root:current mean train loss 1795.3369674124096
INFO:root:current train perplexity4.123721599578857
INFO:root:current mean train loss 1794.059599789233
INFO:root:current train perplexity4.12339448928833
INFO:root:current mean train loss 1794.902406500065
INFO:root:current train perplexity4.124584674835205
INFO:root:current mean train loss 1795.9464377303657
INFO:root:current train perplexity4.12653923034668
INFO:root:current mean train loss 1796.1144109879317
INFO:root:current train perplexity4.128592491149902
INFO:root:current mean train loss 1796.8622808752848
INFO:root:current train perplexity4.130405426025391
INFO:root:current mean train loss 1798.0078626071934
INFO:root:current train perplexity4.130679607391357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.24s/it]
INFO:root:final mean train loss: 1797.481855322241
INFO:root:final train perplexity: 4.1312031745910645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2110.5041218209776
INFO:root:eval perplexity: 5.517092227935791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2569.5244409006536
INFO:root:eval perplexity: 8.268719673156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:21:56<15:12:53, 370.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.7180190488516
INFO:root:current train perplexity4.063951015472412
INFO:root:current mean train loss 1789.4267498078893
INFO:root:current train perplexity4.081045150756836
INFO:root:current mean train loss 1786.5719615275784
INFO:root:current train perplexity4.096059322357178
INFO:root:current mean train loss 1787.6579860756976
INFO:root:current train perplexity4.0915327072143555
INFO:root:current mean train loss 1785.5048557700084
INFO:root:current train perplexity4.091404438018799
INFO:root:current mean train loss 1786.1913624889446
INFO:root:current train perplexity4.0933518409729
INFO:root:current mean train loss 1784.7115819883556
INFO:root:current train perplexity4.091460227966309
INFO:root:current mean train loss 1787.2272384857918
INFO:root:current train perplexity4.095982551574707
INFO:root:current mean train loss 1787.2858626818197
INFO:root:current train perplexity4.097586631774902
INFO:root:current mean train loss 1786.2455899460754
INFO:root:current train perplexity4.099375247955322
INFO:root:current mean train loss 1787.1556208250374
INFO:root:current train perplexity4.1005964279174805
INFO:root:current mean train loss 1788.2638676208858
INFO:root:current train perplexity4.10145378112793
INFO:root:current mean train loss 1790.41432605009
INFO:root:current train perplexity4.1050944328308105
INFO:root:current mean train loss 1791.2708692571346
INFO:root:current train perplexity4.109976291656494
INFO:root:current mean train loss 1791.8639590982964
INFO:root:current train perplexity4.1104207038879395
INFO:root:current mean train loss 1792.5120229618653
INFO:root:current train perplexity4.109796047210693
INFO:root:current mean train loss 1792.9293915719697
INFO:root:current train perplexity4.11251974105835
INFO:root:current mean train loss 1793.6724195581971
INFO:root:current train perplexity4.1121697425842285
INFO:root:current mean train loss 1793.2510610328225
INFO:root:current train perplexity4.112571716308594
INFO:root:current mean train loss 1791.9077587964496
INFO:root:current train perplexity4.113070011138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it]
INFO:root:final mean train loss: 1791.9077587964496
INFO:root:final train perplexity: 4.113070011138916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2113.355524590675
INFO:root:eval perplexity: 5.529838562011719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2573.4587311440328
INFO:root:eval perplexity: 8.295507431030273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:28:06<15:06:14, 369.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1759.2343542480469
INFO:root:current train perplexity4.056447505950928
INFO:root:current mean train loss 1769.2951525878907
INFO:root:current train perplexity4.062097549438477
INFO:root:current mean train loss 1773.801505126953
INFO:root:current train perplexity4.0703887939453125
INFO:root:current mean train loss 1772.3604055786134
INFO:root:current train perplexity4.070276260375977
INFO:root:current mean train loss 1773.0060009765625
INFO:root:current train perplexity4.060781002044678
INFO:root:current mean train loss 1773.221483968099
INFO:root:current train perplexity4.0626726150512695
INFO:root:current mean train loss 1773.1819682965959
INFO:root:current train perplexity4.071408271789551
INFO:root:current mean train loss 1773.1857691955565
INFO:root:current train perplexity4.06948709487915
INFO:root:current mean train loss 1775.223753390842
INFO:root:current train perplexity4.0711870193481445
INFO:root:current mean train loss 1776.7875122070313
INFO:root:current train perplexity4.076937198638916
INFO:root:current mean train loss 1775.8178862970526
INFO:root:current train perplexity4.075502395629883
INFO:root:current mean train loss 1776.9925225830077
INFO:root:current train perplexity4.077610969543457
INFO:root:current mean train loss 1778.7263731971154
INFO:root:current train perplexity4.0822858810424805
INFO:root:current mean train loss 1780.6812683105468
INFO:root:current train perplexity4.085146903991699
INFO:root:current mean train loss 1781.9116563313803
INFO:root:current train perplexity4.087502956390381
INFO:root:current mean train loss 1782.408706893921
INFO:root:current train perplexity4.086994647979736
INFO:root:current mean train loss 1783.5064359777114
INFO:root:current train perplexity4.089468955993652
INFO:root:current mean train loss 1784.6421392822265
INFO:root:current train perplexity4.090881824493408
INFO:root:current mean train loss 1785.5750876978825
INFO:root:current train perplexity4.0930609703063965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.30s/it]
INFO:root:final mean train loss: 1785.6293999483894
INFO:root:final train perplexity: 4.092741012573242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2114.649808410212
INFO:root:eval perplexity: 5.5356316566467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2580.510911873892
INFO:root:eval perplexity: 8.343743324279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:34:16<15:00:09, 369.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.2399256089154
INFO:root:current train perplexity4.016662120819092
INFO:root:current mean train loss 1760.5479225093484
INFO:root:current train perplexity4.026111125946045
INFO:root:current mean train loss 1771.0441354496688
INFO:root:current train perplexity4.042957305908203
INFO:root:current mean train loss 1774.1695514281841
INFO:root:current train perplexity4.037552833557129
INFO:root:current mean train loss 1773.4354590546313
INFO:root:current train perplexity4.033666610717773
INFO:root:current mean train loss 1774.4117830671241
INFO:root:current train perplexity4.043457508087158
INFO:root:current mean train loss 1775.6971087339825
INFO:root:current train perplexity4.04637336730957
INFO:root:current mean train loss 1775.481977348381
INFO:root:current train perplexity4.052239418029785
INFO:root:current mean train loss 1775.4879933314048
INFO:root:current train perplexity4.050920486450195
INFO:root:current mean train loss 1775.7752075860908
INFO:root:current train perplexity4.05433464050293
INFO:root:current mean train loss 1773.9114162028716
INFO:root:current train perplexity4.0550408363342285
INFO:root:current mean train loss 1775.0916013657886
INFO:root:current train perplexity4.056056022644043
INFO:root:current mean train loss 1776.9786354886182
INFO:root:current train perplexity4.058787822723389
INFO:root:current mean train loss 1778.1929510836358
INFO:root:current train perplexity4.0607733726501465
INFO:root:current mean train loss 1778.7621191613002
INFO:root:current train perplexity4.062155723571777
INFO:root:current mean train loss 1779.3071890964898
INFO:root:current train perplexity4.065639972686768
INFO:root:current mean train loss 1778.9353359507866
INFO:root:current train perplexity4.067121982574463
INFO:root:current mean train loss 1778.7709308284343
INFO:root:current train perplexity4.068452835083008
INFO:root:current mean train loss 1779.7354961388965
INFO:root:current train perplexity4.070762634277344
INFO:root:current mean train loss 1780.0003574234033
INFO:root:current train perplexity4.0718793869018555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.84s/it]
INFO:root:final mean train loss: 1779.1105433169243
INFO:root:final train perplexity: 4.0717387199401855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2119.0884105060118
INFO:root:eval perplexity: 5.555550575256348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2585.8716309459496
INFO:root:eval perplexity: 8.380596160888672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:40:25<14:53:38, 369.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1746.8843276079963
INFO:root:current train perplexity4.044041633605957
INFO:root:current mean train loss 1775.462500728778
INFO:root:current train perplexity4.04963493347168
INFO:root:current mean train loss 1778.394784258981
INFO:root:current train perplexity4.0571112632751465
INFO:root:current mean train loss 1775.6752681161115
INFO:root:current train perplexity4.042176246643066
INFO:root:current mean train loss 1771.3522819835468
INFO:root:current train perplexity4.039396286010742
INFO:root:current mean train loss 1770.788908654831
INFO:root:current train perplexity4.044412612915039
INFO:root:current mean train loss 1769.050783945559
INFO:root:current train perplexity4.040343761444092
INFO:root:current mean train loss 1770.0338181331956
INFO:root:current train perplexity4.0416579246521
INFO:root:current mean train loss 1770.3801392479766
INFO:root:current train perplexity4.039623260498047
INFO:root:current mean train loss 1769.7795628419015
INFO:root:current train perplexity4.040554523468018
INFO:root:current mean train loss 1769.127057132684
INFO:root:current train perplexity4.039393424987793
INFO:root:current mean train loss 1769.2263757345747
INFO:root:current train perplexity4.042965412139893
INFO:root:current mean train loss 1770.0104449255155
INFO:root:current train perplexity4.044061183929443
INFO:root:current mean train loss 1769.871778222217
INFO:root:current train perplexity4.045566082000732
INFO:root:current mean train loss 1770.4825025742025
INFO:root:current train perplexity4.044915676116943
INFO:root:current mean train loss 1771.3440709319232
INFO:root:current train perplexity4.045737266540527
INFO:root:current mean train loss 1771.8903599415735
INFO:root:current train perplexity4.0473151206970215
INFO:root:current mean train loss 1771.3093287766048
INFO:root:current train perplexity4.048583507537842
INFO:root:current mean train loss 1772.8199651254301
INFO:root:current train perplexity4.052372455596924
INFO:root:current mean train loss 1773.1894717448254
INFO:root:current train perplexity4.051640510559082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.61s/it]
INFO:root:final mean train loss: 1772.4404661916328
INFO:root:final train perplexity: 4.050361633300781
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2120.9385592413287
INFO:root:eval perplexity: 5.5638747215271
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2589.837079853031
INFO:root:eval perplexity: 8.407962799072266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:46:34<14:47:05, 369.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.8241541245404
INFO:root:current train perplexity3.9833221435546875
INFO:root:current mean train loss 1754.7154638025145
INFO:root:current train perplexity3.9955873489379883
INFO:root:current mean train loss 1764.4538720119522
INFO:root:current train perplexity3.996616840362549
INFO:root:current mean train loss 1763.4648917434563
INFO:root:current train perplexity4.002012252807617
INFO:root:current mean train loss 1764.5403914694775
INFO:root:current train perplexity4.0059123039245605
INFO:root:current mean train loss 1765.543036099138
INFO:root:current train perplexity4.010408878326416
INFO:root:current mean train loss 1764.8193545011882
INFO:root:current train perplexity4.010251045227051
INFO:root:current mean train loss 1765.5534338005057
INFO:root:current train perplexity4.01442813873291
INFO:root:current mean train loss 1764.1846175053706
INFO:root:current train perplexity4.016323566436768
INFO:root:current mean train loss 1765.037679549898
INFO:root:current train perplexity4.018257141113281
INFO:root:current mean train loss 1764.923279679695
INFO:root:current train perplexity4.0207109451293945
INFO:root:current mean train loss 1765.4430946595353
INFO:root:current train perplexity4.022876739501953
INFO:root:current mean train loss 1764.9657363952588
INFO:root:current train perplexity4.023247241973877
INFO:root:current mean train loss 1765.9704916930746
INFO:root:current train perplexity4.024583339691162
INFO:root:current mean train loss 1766.7424746302388
INFO:root:current train perplexity4.028284549713135
INFO:root:current mean train loss 1767.3425471627427
INFO:root:current train perplexity4.02906608581543
INFO:root:current mean train loss 1767.9164010596087
INFO:root:current train perplexity4.030061721801758
INFO:root:current mean train loss 1767.5483769319317
INFO:root:current train perplexity4.029621601104736
INFO:root:current mean train loss 1767.7768822437617
INFO:root:current train perplexity4.032264709472656
INFO:root:current mean train loss 1768.3186940516282
INFO:root:current train perplexity4.0343098640441895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.91s/it]
INFO:root:final mean train loss: 1767.2557707924586
INFO:root:final train perplexity: 4.033822059631348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 2121.0710908064607
INFO:root:eval perplexity: 5.564470291137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2589.7479170129654
INFO:root:eval perplexity: 8.40734577178955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:52:44<14:40:50, 369.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.1756627699908
INFO:root:current train perplexity4.016820907592773
INFO:root:current mean train loss 1763.8799794514973
INFO:root:current train perplexity4.017688751220703
INFO:root:current mean train loss 1760.3911656621676
INFO:root:current train perplexity4.010851860046387
INFO:root:current mean train loss 1761.535859812861
INFO:root:current train perplexity4.008049011230469
INFO:root:current mean train loss 1758.8358477731035
INFO:root:current train perplexity4.006864547729492
INFO:root:current mean train loss 1758.8984003201338
INFO:root:current train perplexity4.005058288574219
INFO:root:current mean train loss 1757.7068985807682
INFO:root:current train perplexity4.006651401519775
INFO:root:current mean train loss 1757.866623242696
INFO:root:current train perplexity4.00646448135376
INFO:root:current mean train loss 1757.532701202252
INFO:root:current train perplexity4.005493640899658
INFO:root:current mean train loss 1757.9845504130215
INFO:root:current train perplexity4.007996559143066
INFO:root:current mean train loss 1758.298611987396
INFO:root:current train perplexity4.00921106338501
INFO:root:current mean train loss 1759.4760970024213
INFO:root:current train perplexity4.009634971618652
INFO:root:current mean train loss 1760.26868311163
INFO:root:current train perplexity4.011487007141113
INFO:root:current mean train loss 1760.7880954853972
INFO:root:current train perplexity4.011614799499512
INFO:root:current mean train loss 1761.2249443199719
INFO:root:current train perplexity4.013660430908203
INFO:root:current mean train loss 1761.2883221373265
INFO:root:current train perplexity4.013307094573975
INFO:root:current mean train loss 1760.8401042837604
INFO:root:current train perplexity4.013556480407715
INFO:root:current mean train loss 1761.7390836137452
INFO:root:current train perplexity4.015035629272461
INFO:root:current mean train loss 1762.113364242129
INFO:root:current train perplexity4.014738082885742
INFO:root:current mean train loss 1762.129702994494
INFO:root:current train perplexity4.016238212585449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.74s/it]
INFO:root:final mean train loss: 1761.8203891402113
INFO:root:final train perplexity: 4.016556262969971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 2120.3963631704346
INFO:root:eval perplexity: 5.5614333152771
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2589.967621066046
INFO:root:eval perplexity: 8.408866882324219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:58:55<14:35:56, 370.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.0158404181984
INFO:root:current train perplexity3.97771954536438
INFO:root:current mean train loss 1748.1701798722552
INFO:root:current train perplexity3.9778339862823486
INFO:root:current mean train loss 1747.9343540124726
INFO:root:current train perplexity3.9692957401275635
INFO:root:current mean train loss 1746.044021725345
INFO:root:current train perplexity3.9675755500793457
INFO:root:current mean train loss 1746.1133874637565
INFO:root:current train perplexity3.96914005279541
INFO:root:current mean train loss 1745.6906400240384
INFO:root:current train perplexity3.9731245040893555
INFO:root:current mean train loss 1747.302174455406
INFO:root:current train perplexity3.976776123046875
INFO:root:current mean train loss 1748.6504249912919
INFO:root:current train perplexity3.975797176361084
INFO:root:current mean train loss 1748.9655582406426
INFO:root:current train perplexity3.977786064147949
INFO:root:current mean train loss 1750.9094357253332
INFO:root:current train perplexity3.9820070266723633
INFO:root:current mean train loss 1753.0981331680227
INFO:root:current train perplexity3.9847357273101807
INFO:root:current mean train loss 1754.7360565829379
INFO:root:current train perplexity3.9883954524993896
INFO:root:current mean train loss 1754.8424425652056
INFO:root:current train perplexity3.9878029823303223
INFO:root:current mean train loss 1754.430357961276
INFO:root:current train perplexity3.9906976222991943
INFO:root:current mean train loss 1755.1937671802661
INFO:root:current train perplexity3.9938812255859375
INFO:root:current mean train loss 1755.0245599307473
INFO:root:current train perplexity3.9959824085235596
INFO:root:current mean train loss 1755.7317025657223
INFO:root:current train perplexity3.997920036315918
INFO:root:current mean train loss 1756.2028316209296
INFO:root:current train perplexity3.997349262237549
INFO:root:current mean train loss 1756.0715451187418
INFO:root:current train perplexity3.996411085128784

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.25s/it]
INFO:root:final mean train loss: 1756.0035280967325
INFO:root:final train perplexity: 3.998159885406494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2123.681219872008
INFO:root:eval perplexity: 5.576237201690674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2591.4586861251937
INFO:root:eval perplexity: 8.419179916381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:05:08<14:31:43, 370.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.7212524414062
INFO:root:current train perplexity3.9377877712249756
INFO:root:current mean train loss 1757.3895347445618
INFO:root:current train perplexity3.9434125423431396
INFO:root:current mean train loss 1751.8054924388923
INFO:root:current train perplexity3.94557785987854
INFO:root:current mean train loss 1749.2772851400819
INFO:root:current train perplexity3.950636386871338
INFO:root:current mean train loss 1750.9717656225707
INFO:root:current train perplexity3.95947527885437
INFO:root:current mean train loss 1749.9740984791304
INFO:root:current train perplexity3.962829351425171
INFO:root:current mean train loss 1748.2133888422056
INFO:root:current train perplexity3.9668190479278564
INFO:root:current mean train loss 1746.344634922821
INFO:root:current train perplexity3.962475061416626
INFO:root:current mean train loss 1748.0155058216276
INFO:root:current train perplexity3.9633800983428955
INFO:root:current mean train loss 1746.9808812448032
INFO:root:current train perplexity3.9632763862609863
INFO:root:current mean train loss 1745.9559543023329
INFO:root:current train perplexity3.9678854942321777
INFO:root:current mean train loss 1745.9983545985283
INFO:root:current train perplexity3.968878984451294
INFO:root:current mean train loss 1747.6923788518159
INFO:root:current train perplexity3.970674753189087
INFO:root:current mean train loss 1748.324200842604
INFO:root:current train perplexity3.97066068649292
INFO:root:current mean train loss 1749.4517421749622
INFO:root:current train perplexity3.973102331161499
INFO:root:current mean train loss 1749.3196047847662
INFO:root:current train perplexity3.975520133972168
INFO:root:current mean train loss 1750.1068448222682
INFO:root:current train perplexity3.9761059284210205
INFO:root:current mean train loss 1750.3582141844843
INFO:root:current train perplexity3.9772236347198486
INFO:root:current mean train loss 1750.0635268267463
INFO:root:current train perplexity3.978137493133545
INFO:root:current mean train loss 1750.5679402155831
INFO:root:current train perplexity3.97934627532959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.68s/it]
INFO:root:final mean train loss: 1750.0281028574425
INFO:root:final train perplexity: 3.979349136352539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2125.2885053918717
INFO:root:eval perplexity: 5.583494186401367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2598.302008446227
INFO:root:eval perplexity: 8.466681480407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [6:11:20<14:25:48, 371.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.5877749794408
INFO:root:current train perplexity3.9731900691986084
INFO:root:current mean train loss 1743.1203326056984
INFO:root:current train perplexity3.9647719860076904
INFO:root:current mean train loss 1742.8156944518764
INFO:root:current train perplexity3.9586470127105713
INFO:root:current mean train loss 1742.4715426932307
INFO:root:current train perplexity3.9388725757598877
INFO:root:current mean train loss 1736.7306123792698
INFO:root:current train perplexity3.935094118118286
INFO:root:current mean train loss 1736.6036181734705
INFO:root:current train perplexity3.944425582885742
INFO:root:current mean train loss 1737.9511436745886
INFO:root:current train perplexity3.945091485977173
INFO:root:current mean train loss 1740.3360998076755
INFO:root:current train perplexity3.947455406188965
INFO:root:current mean train loss 1739.3462590740423
INFO:root:current train perplexity3.947822093963623
INFO:root:current mean train loss 1741.057496046994
INFO:root:current train perplexity3.9466423988342285
INFO:root:current mean train loss 1740.847909015809
INFO:root:current train perplexity3.9517862796783447
INFO:root:current mean train loss 1742.0701198492654
INFO:root:current train perplexity3.9555156230926514
INFO:root:current mean train loss 1744.3523451920119
INFO:root:current train perplexity3.9586946964263916
INFO:root:current mean train loss 1743.7869931351877
INFO:root:current train perplexity3.9588465690612793
INFO:root:current mean train loss 1743.910805743206
INFO:root:current train perplexity3.9583888053894043
INFO:root:current mean train loss 1743.962924618247
INFO:root:current train perplexity3.9609227180480957
INFO:root:current mean train loss 1744.9848659955992
INFO:root:current train perplexity3.9638757705688477
INFO:root:current mean train loss 1744.139490647951
INFO:root:current train perplexity3.962343692779541
INFO:root:current mean train loss 1744.616205971473
INFO:root:current train perplexity3.9613916873931885
INFO:root:current mean train loss 1745.3228657351242
INFO:root:current train perplexity3.9616878032684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.10s/it]
INFO:root:final mean train loss: 1744.7835069772757
INFO:root:final train perplexity: 3.9629125595092773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2126.558810619598
INFO:root:eval perplexity: 5.589237213134766
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2598.252834022468
INFO:root:eval perplexity: 8.466339111328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [6:17:29<14:18:41, 370.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.0638800726997
INFO:root:current train perplexity3.914196014404297
INFO:root:current mean train loss 1715.4625459558824
INFO:root:current train perplexity3.917346477508545
INFO:root:current mean train loss 1732.431540279065
INFO:root:current train perplexity3.937039375305176
INFO:root:current mean train loss 1732.9872977847144
INFO:root:current train perplexity3.9341540336608887
INFO:root:current mean train loss 1730.9262191352495
INFO:root:current train perplexity3.9336204528808594
INFO:root:current mean train loss 1730.6591084039032
INFO:root:current train perplexity3.9299261569976807
INFO:root:current mean train loss 1730.7275962589672
INFO:root:current train perplexity3.925776243209839
INFO:root:current mean train loss 1732.0071072785752
INFO:root:current train perplexity3.928647756576538
INFO:root:current mean train loss 1733.1076200202322
INFO:root:current train perplexity3.9317409992218018
INFO:root:current mean train loss 1734.1409443912344
INFO:root:current train perplexity3.9352662563323975
INFO:root:current mean train loss 1734.1009444895858
INFO:root:current train perplexity3.9359991550445557
INFO:root:current mean train loss 1735.3344463294661
INFO:root:current train perplexity3.937357187271118
INFO:root:current mean train loss 1736.307547362491
INFO:root:current train perplexity3.938730001449585
INFO:root:current mean train loss 1736.6384198765554
INFO:root:current train perplexity3.9402365684509277
INFO:root:current mean train loss 1738.1394418700493
INFO:root:current train perplexity3.940795421600342
INFO:root:current mean train loss 1737.2816019058228
INFO:root:current train perplexity3.939181089401245
INFO:root:current mean train loss 1738.4254435420328
INFO:root:current train perplexity3.9404773712158203
INFO:root:current mean train loss 1739.0484019336614
INFO:root:current train perplexity3.942925453186035
INFO:root:current mean train loss 1740.130076821853
INFO:root:current train perplexity3.9451258182525635
INFO:root:current mean train loss 1740.52271913891
INFO:root:current train perplexity3.9460487365722656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.40s/it]
INFO:root:final mean train loss: 1739.431786641531
INFO:root:final train perplexity: 3.9462101459503174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2131.163059965093
INFO:root:eval perplexity: 5.610098838806152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2606.540583617298
INFO:root:eval perplexity: 8.524221420288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:23:39<14:12:07, 370.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.3965396521226
INFO:root:current train perplexity3.8985371589660645
INFO:root:current mean train loss 1722.6159604141135
INFO:root:current train perplexity3.8826162815093994
INFO:root:current mean train loss 1722.9683008005497
INFO:root:current train perplexity3.891963481903076
INFO:root:current mean train loss 1722.0141425200293
INFO:root:current train perplexity3.893326759338379
INFO:root:current mean train loss 1722.1351857301152
INFO:root:current train perplexity3.9000964164733887
INFO:root:current mean train loss 1724.0911935871807
INFO:root:current train perplexity3.9106271266937256
INFO:root:current mean train loss 1725.207288102388
INFO:root:current train perplexity3.9128754138946533
INFO:root:current mean train loss 1726.4694642653344
INFO:root:current train perplexity3.9140467643737793
INFO:root:current mean train loss 1727.5885968582852
INFO:root:current train perplexity3.91645884513855
INFO:root:current mean train loss 1727.358114460708
INFO:root:current train perplexity3.9168715476989746
INFO:root:current mean train loss 1728.7237891969744
INFO:root:current train perplexity3.919711112976074
INFO:root:current mean train loss 1730.3501640379377
INFO:root:current train perplexity3.9207561016082764
INFO:root:current mean train loss 1730.843835536899
INFO:root:current train perplexity3.920372247695923
INFO:root:current mean train loss 1731.4683946156977
INFO:root:current train perplexity3.9196293354034424
INFO:root:current mean train loss 1732.6474956347051
INFO:root:current train perplexity3.923140048980713
INFO:root:current mean train loss 1733.0298389992404
INFO:root:current train perplexity3.9249260425567627
INFO:root:current mean train loss 1733.3266203523187
INFO:root:current train perplexity3.9271349906921387
INFO:root:current mean train loss 1734.128754375869
INFO:root:current train perplexity3.9296393394470215
INFO:root:current mean train loss 1734.9810703399048
INFO:root:current train perplexity3.930450439453125
INFO:root:current mean train loss 1734.9867900920658
INFO:root:current train perplexity3.9297990798950195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.91s/it]
INFO:root:final mean train loss: 1734.1641811538211
INFO:root:final train perplexity: 3.9298388957977295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2129.4625638055463
INFO:root:eval perplexity: 5.602385997772217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2605.3327835840537
INFO:root:eval perplexity: 8.515763282775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [6:29:49<14:05:16, 370.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.5835501534598
INFO:root:current train perplexity3.846123695373535
INFO:root:current mean train loss 1702.7115930893842
INFO:root:current train perplexity3.8679661750793457
INFO:root:current mean train loss 1716.4509702329283
INFO:root:current train perplexity3.8801043033599854
INFO:root:current mean train loss 1719.5883531725085
INFO:root:current train perplexity3.8869688510894775
INFO:root:current mean train loss 1716.9411363966922
INFO:root:current train perplexity3.885793924331665
INFO:root:current mean train loss 1720.390433114035
INFO:root:current train perplexity3.8908817768096924
INFO:root:current mean train loss 1720.7225800927006
INFO:root:current train perplexity3.897393226623535
INFO:root:current mean train loss 1721.241004210633
INFO:root:current train perplexity3.8989644050598145
INFO:root:current mean train loss 1721.7425358914782
INFO:root:current train perplexity3.899906635284424
INFO:root:current mean train loss 1722.9863311452964
INFO:root:current train perplexity3.9003710746765137
INFO:root:current mean train loss 1724.4468919985761
INFO:root:current train perplexity3.8996336460113525
INFO:root:current mean train loss 1725.2810741978833
INFO:root:current train perplexity3.904731273651123
INFO:root:current mean train loss 1726.2409880390317
INFO:root:current train perplexity3.9056901931762695
INFO:root:current mean train loss 1726.6049353829264
INFO:root:current train perplexity3.907872438430786
INFO:root:current mean train loss 1727.1736642850499
INFO:root:current train perplexity3.910219192504883
INFO:root:current mean train loss 1728.1508702758013
INFO:root:current train perplexity3.912116050720215
INFO:root:current mean train loss 1728.4538065470622
INFO:root:current train perplexity3.911238431930542
INFO:root:current mean train loss 1728.6102967343088
INFO:root:current train perplexity3.9109482765197754
INFO:root:current mean train loss 1728.8149147727272
INFO:root:current train perplexity3.9105679988861084
INFO:root:current mean train loss 1729.03420286227
INFO:root:current train perplexity3.912555694580078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it]
INFO:root:final mean train loss: 1728.6304706952455
INFO:root:final train perplexity: 3.9127144813537598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2133.697781177277
INFO:root:eval perplexity: 5.62161922454834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2609.799509467808
INFO:root:eval perplexity: 8.547091484069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:35:59<13:59:22, 370.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.9205420483117
INFO:root:current train perplexity3.843311309814453
INFO:root:current mean train loss 1708.8444275881518
INFO:root:current train perplexity3.848269462585449
INFO:root:current mean train loss 1713.8690781011815
INFO:root:current train perplexity3.858567476272583
INFO:root:current mean train loss 1711.8853125757025
INFO:root:current train perplexity3.8643219470977783
INFO:root:current mean train loss 1714.8960066213745
INFO:root:current train perplexity3.8648500442504883
INFO:root:current mean train loss 1715.4125833072694
INFO:root:current train perplexity3.870288133621216
INFO:root:current mean train loss 1715.4771897317366
INFO:root:current train perplexity3.8725080490112305
INFO:root:current mean train loss 1716.222458797004
INFO:root:current train perplexity3.8748819828033447
INFO:root:current mean train loss 1718.1870966312447
INFO:root:current train perplexity3.8776187896728516
INFO:root:current mean train loss 1717.897512140245
INFO:root:current train perplexity3.8801028728485107
INFO:root:current mean train loss 1718.3995602773546
INFO:root:current train perplexity3.884037971496582
INFO:root:current mean train loss 1719.6533841757384
INFO:root:current train perplexity3.884843111038208
INFO:root:current mean train loss 1719.2167761031287
INFO:root:current train perplexity3.8825161457061768
INFO:root:current mean train loss 1719.4653083564742
INFO:root:current train perplexity3.886378765106201
INFO:root:current mean train loss 1720.695054157516
INFO:root:current train perplexity3.889831781387329
INFO:root:current mean train loss 1720.8128315205083
INFO:root:current train perplexity3.88889741897583
INFO:root:current mean train loss 1721.3747922561547
INFO:root:current train perplexity3.8884284496307373
INFO:root:current mean train loss 1722.3491251923615
INFO:root:current train perplexity3.8909761905670166
INFO:root:current mean train loss 1722.509079844723
INFO:root:current train perplexity3.8920376300811768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it]
INFO:root:final mean train loss: 1722.3228200815329
INFO:root:final train perplexity: 3.8932855129241943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2136.7682850073415
INFO:root:eval perplexity: 5.635603904724121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2614.522312029034
INFO:root:eval perplexity: 8.580343246459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:42:10<13:53:24, 370.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.6463012695312
INFO:root:current train perplexity3.86769962310791
INFO:root:current mean train loss 1719.0227543757512
INFO:root:current train perplexity3.8585832118988037
INFO:root:current mean train loss 1708.3114019655713
INFO:root:current train perplexity3.845064640045166
INFO:root:current mean train loss 1708.188959222091
INFO:root:current train perplexity3.829477548599243
INFO:root:current mean train loss 1706.90852461711
INFO:root:current train perplexity3.8373823165893555
INFO:root:current mean train loss 1705.9774889264788
INFO:root:current train perplexity3.8374509811401367
INFO:root:current mean train loss 1708.7550327730494
INFO:root:current train perplexity3.8475301265716553
INFO:root:current mean train loss 1711.3697367581453
INFO:root:current train perplexity3.858731269836426
INFO:root:current mean train loss 1712.0220629943544
INFO:root:current train perplexity3.8604788780212402
INFO:root:current mean train loss 1711.8603191544523
INFO:root:current train perplexity3.8631346225738525
INFO:root:current mean train loss 1711.9721665097422
INFO:root:current train perplexity3.864217519760132
INFO:root:current mean train loss 1712.1355960127237
INFO:root:current train perplexity3.864442825317383
INFO:root:current mean train loss 1713.1347468683489
INFO:root:current train perplexity3.867311954498291
INFO:root:current mean train loss 1716.165208406975
INFO:root:current train perplexity3.873182535171509
INFO:root:current mean train loss 1717.706411856192
INFO:root:current train perplexity3.875305652618408
INFO:root:current mean train loss 1718.8971157479793
INFO:root:current train perplexity3.876657485961914
INFO:root:current mean train loss 1719.6671724771325
INFO:root:current train perplexity3.879754066467285
INFO:root:current mean train loss 1719.247382938582
INFO:root:current train perplexity3.880086660385132
INFO:root:current mean train loss 1719.432557032008
INFO:root:current train perplexity3.8794660568237305
INFO:root:current mean train loss 1718.6531391945207
INFO:root:current train perplexity3.88034987449646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.06s/it]
INFO:root:final mean train loss: 1717.947139337937
INFO:root:final train perplexity: 3.87986421585083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2138.8670927007147
INFO:root:eval perplexity: 5.645184516906738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2617.832959330674
INFO:root:eval perplexity: 8.603726387023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:48:19<13:46:04, 369.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1731.426281156994
INFO:root:current train perplexity3.8098855018615723
INFO:root:current mean train loss 1708.0876495109117
INFO:root:current train perplexity3.8380987644195557
INFO:root:current mean train loss 1709.6895254834205
INFO:root:current train perplexity3.8440041542053223
INFO:root:current mean train loss 1710.6691191010757
INFO:root:current train perplexity3.8438773155212402
INFO:root:current mean train loss 1708.7905879439763
INFO:root:current train perplexity3.8425116539001465
INFO:root:current mean train loss 1709.4489279836703
INFO:root:current train perplexity3.8438351154327393
INFO:root:current mean train loss 1707.799830634813
INFO:root:current train perplexity3.8454198837280273
INFO:root:current mean train loss 1704.5689511027977
INFO:root:current train perplexity3.8415141105651855
INFO:root:current mean train loss 1704.933521191763
INFO:root:current train perplexity3.8443140983581543
INFO:root:current mean train loss 1706.573102091604
INFO:root:current train perplexity3.8474788665771484
INFO:root:current mean train loss 1706.252830094385
INFO:root:current train perplexity3.848310947418213
INFO:root:current mean train loss 1706.8087966197522
INFO:root:current train perplexity3.852123737335205
INFO:root:current mean train loss 1706.2848801171556
INFO:root:current train perplexity3.852341651916504
INFO:root:current mean train loss 1708.1335091601711
INFO:root:current train perplexity3.852315664291382
INFO:root:current mean train loss 1710.2363350832654
INFO:root:current train perplexity3.8524868488311768
INFO:root:current mean train loss 1710.3091093184994
INFO:root:current train perplexity3.852322578430176
INFO:root:current mean train loss 1711.1328938300046
INFO:root:current train perplexity3.854088068008423
INFO:root:current mean train loss 1711.2569347428139
INFO:root:current train perplexity3.856043577194214
INFO:root:current mean train loss 1711.634037292246
INFO:root:current train perplexity3.8588271141052246
INFO:root:current mean train loss 1712.5697632153663
INFO:root:current train perplexity3.861361026763916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.85s/it]
INFO:root:final mean train loss: 1712.2009952639428
INFO:root:final train perplexity: 3.862309455871582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 2139.700123022634
INFO:root:eval perplexity: 5.648991584777832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2618.787353515625
INFO:root:eval perplexity: 8.610480308532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:54:28<13:39:38, 369.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1681.7687474300988
INFO:root:current train perplexity3.7756669521331787
INFO:root:current mean train loss 1695.6337819859602
INFO:root:current train perplexity3.79488205909729
INFO:root:current mean train loss 1689.522748674665
INFO:root:current train perplexity3.808209180831909
INFO:root:current mean train loss 1691.494965863651
INFO:root:current train perplexity3.8148229122161865
INFO:root:current mean train loss 1691.2035218678652
INFO:root:current train perplexity3.8118977546691895
INFO:root:current mean train loss 1691.1523886755053
INFO:root:current train perplexity3.8103184700012207
INFO:root:current mean train loss 1693.490478515625
INFO:root:current train perplexity3.8147692680358887
INFO:root:current mean train loss 1692.9758193266748
INFO:root:current train perplexity3.815218210220337
INFO:root:current mean train loss 1695.8470592999515
INFO:root:current train perplexity3.817365884780884
INFO:root:current mean train loss 1696.060831488831
INFO:root:current train perplexity3.820486068725586
INFO:root:current mean train loss 1696.825987946321
INFO:root:current train perplexity3.821307420730591
INFO:root:current mean train loss 1699.694939853018
INFO:root:current train perplexity3.824101448059082
INFO:root:current mean train loss 1699.219978591352
INFO:root:current train perplexity3.8263189792633057
INFO:root:current mean train loss 1700.5911956467792
INFO:root:current train perplexity3.830110788345337
INFO:root:current mean train loss 1701.4251180975095
INFO:root:current train perplexity3.831549644470215
INFO:root:current mean train loss 1702.500901955157
INFO:root:current train perplexity3.8347442150115967
INFO:root:current mean train loss 1704.404033954327
INFO:root:current train perplexity3.839344024658203
INFO:root:current mean train loss 1705.2734840665232
INFO:root:current train perplexity3.842085123062134
INFO:root:current mean train loss 1705.9483963361372
INFO:root:current train perplexity3.8447649478912354
INFO:root:current mean train loss 1707.493454058227
INFO:root:current train perplexity3.8468472957611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.03s/it]
INFO:root:final mean train loss: 1707.4202005191096
INFO:root:final train perplexity: 3.847764492034912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 2141.5912752624945
INFO:root:eval perplexity: 5.657641887664795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2622.8024434840427
INFO:root:eval perplexity: 8.638951301574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [7:00:37<13:32:41, 369.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.825985440341
INFO:root:current train perplexity3.8017101287841797
INFO:root:current mean train loss 1696.8639868951614
INFO:root:current train perplexity3.794576644897461
INFO:root:current mean train loss 1693.9886508118873
INFO:root:current train perplexity3.795313596725464
INFO:root:current mean train loss 1689.4246423855634
INFO:root:current train perplexity3.7953927516937256
INFO:root:current mean train loss 1688.9394930996737
INFO:root:current train perplexity3.791901111602783
INFO:root:current mean train loss 1690.0026415575733
INFO:root:current train perplexity3.789149284362793
INFO:root:current mean train loss 1691.8295926392534
INFO:root:current train perplexity3.7949178218841553
INFO:root:current mean train loss 1693.611916487738
INFO:root:current train perplexity3.801264762878418
INFO:root:current mean train loss 1695.2624126233552
INFO:root:current train perplexity3.8016974925994873
INFO:root:current mean train loss 1698.3392649705497
INFO:root:current train perplexity3.808911085128784
INFO:root:current mean train loss 1698.4590564601228
INFO:root:current train perplexity3.8085386753082275
INFO:root:current mean train loss 1698.9497253153747
INFO:root:current train perplexity3.8114869594573975
INFO:root:current mean train loss 1698.9080106332483
INFO:root:current train perplexity3.812664270401001
INFO:root:current mean train loss 1699.504719031077
INFO:root:current train perplexity3.817129611968994
INFO:root:current mean train loss 1700.399677499463
INFO:root:current train perplexity3.820880651473999
INFO:root:current mean train loss 1701.0130121457998
INFO:root:current train perplexity3.822404146194458
INFO:root:current mean train loss 1701.7612953024689
INFO:root:current train perplexity3.8250889778137207
INFO:root:current mean train loss 1701.6745400974894
INFO:root:current train perplexity3.8275742530822754
INFO:root:current mean train loss 1702.6940371778132
INFO:root:current train perplexity3.8297970294952393
INFO:root:current mean train loss 1702.1807632797515
INFO:root:current train perplexity3.830958366394043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.47s/it]
INFO:root:final mean train loss: 1701.7936827351334
INFO:root:final train perplexity: 3.830716133117676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 2145.13531797152
INFO:root:eval perplexity: 5.673891067504883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2628.5709778264904
INFO:root:eval perplexity: 8.68001651763916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [7:06:49<13:28:38, 370.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.7554829915364
INFO:root:current train perplexity3.795971632003784
INFO:root:current mean train loss 1697.0310306992642
INFO:root:current train perplexity3.7992470264434814
INFO:root:current mean train loss 1696.7041702270508
INFO:root:current train perplexity3.788818597793579
INFO:root:current mean train loss 1696.3822500577537
INFO:root:current train perplexity3.793889284133911
INFO:root:current mean train loss 1694.0852653374106
INFO:root:current train perplexity3.790720224380493
INFO:root:current mean train loss 1692.7634435266882
INFO:root:current train perplexity3.789421558380127
INFO:root:current mean train loss 1694.8571621122815
INFO:root:current train perplexity3.7936739921569824
INFO:root:current mean train loss 1694.861177118331
INFO:root:current train perplexity3.7970409393310547
INFO:root:current mean train loss 1695.7941323376576
INFO:root:current train perplexity3.7983651161193848
INFO:root:current mean train loss 1696.8408456810218
INFO:root:current train perplexity3.803295850753784
INFO:root:current mean train loss 1696.6241428887665
INFO:root:current train perplexity3.806431770324707
INFO:root:current mean train loss 1696.6734294175287
INFO:root:current train perplexity3.808229684829712
INFO:root:current mean train loss 1696.2928417853589
INFO:root:current train perplexity3.8080053329467773
INFO:root:current mean train loss 1696.5724751553105
INFO:root:current train perplexity3.810053586959839
INFO:root:current mean train loss 1696.6269468224566
INFO:root:current train perplexity3.8109843730926514
INFO:root:current mean train loss 1697.4226861618856
INFO:root:current train perplexity3.8129234313964844
INFO:root:current mean train loss 1697.524827509976
INFO:root:current train perplexity3.814885139465332
INFO:root:current mean train loss 1697.9253059886648
INFO:root:current train perplexity3.8135316371917725
INFO:root:current mean train loss 1697.714930151263
INFO:root:current train perplexity3.8148229122161865
INFO:root:current mean train loss 1697.7857229608067
INFO:root:current train perplexity3.8173043727874756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it]
INFO:root:final mean train loss: 1697.3778706222126
INFO:root:final train perplexity: 3.817389965057373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2143.9626663965537
INFO:root:eval perplexity: 5.668509483337402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2627.7340780488144
INFO:root:eval perplexity: 8.674047470092773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [7:13:01<13:23:33, 370.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.3779982663273
INFO:root:current train perplexity3.7855639457702637
INFO:root:current mean train loss 1675.3517885561344
INFO:root:current train perplexity3.7612829208374023
INFO:root:current mean train loss 1679.643648035386
INFO:root:current train perplexity3.7486186027526855
INFO:root:current mean train loss 1680.6900336650465
INFO:root:current train perplexity3.7575976848602295
INFO:root:current mean train loss 1681.8487870854103
INFO:root:current train perplexity3.764969825744629
INFO:root:current mean train loss 1684.6704594817752
INFO:root:current train perplexity3.769509792327881
INFO:root:current mean train loss 1685.4962960784426
INFO:root:current train perplexity3.7756569385528564
INFO:root:current mean train loss 1686.0056206494078
INFO:root:current train perplexity3.778217077255249
INFO:root:current mean train loss 1689.067428811999
INFO:root:current train perplexity3.7860682010650635
INFO:root:current mean train loss 1689.3342027191686
INFO:root:current train perplexity3.786449909210205
INFO:root:current mean train loss 1689.9015300600106
INFO:root:current train perplexity3.7878053188323975
INFO:root:current mean train loss 1690.6860414188984
INFO:root:current train perplexity3.792226552963257
INFO:root:current mean train loss 1690.4212081116054
INFO:root:current train perplexity3.79284405708313
INFO:root:current mean train loss 1691.559158489977
INFO:root:current train perplexity3.795422315597534
INFO:root:current mean train loss 1692.0639636960104
INFO:root:current train perplexity3.797031879425049
INFO:root:current mean train loss 1691.992773806246
INFO:root:current train perplexity3.797536611557007
INFO:root:current mean train loss 1692.6377802341206
INFO:root:current train perplexity3.7995431423187256
INFO:root:current mean train loss 1692.7035451156592
INFO:root:current train perplexity3.8006751537323
INFO:root:current mean train loss 1693.0513424244805
INFO:root:current train perplexity3.8021719455718994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.27s/it]
INFO:root:final mean train loss: 1692.2449532882529
INFO:root:final train perplexity: 3.801957607269287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2149.260793266567
INFO:root:eval perplexity: 5.692863941192627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2634.7369709420714
INFO:root:eval perplexity: 8.724128723144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [7:19:11<13:16:47, 370.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1671.426493326823
INFO:root:current train perplexity3.7652993202209473
INFO:root:current mean train loss 1662.0101779002064
INFO:root:current train perplexity3.763828754425049
INFO:root:current mean train loss 1669.5649526651623
INFO:root:current train perplexity3.76149582862854
INFO:root:current mean train loss 1668.2644449869792
INFO:root:current train perplexity3.7596216201782227
INFO:root:current mean train loss 1674.698280372056
INFO:root:current train perplexity3.7611541748046875
INFO:root:current mean train loss 1677.0853138799253
INFO:root:current train perplexity3.7645983695983887
INFO:root:current mean train loss 1678.8818339231384
INFO:root:current train perplexity3.7650949954986572
INFO:root:current mean train loss 1677.8638359264341
INFO:root:current train perplexity3.7659339904785156
INFO:root:current mean train loss 1680.7352450917435
INFO:root:current train perplexity3.7712788581848145
INFO:root:current mean train loss 1681.1577469107858
INFO:root:current train perplexity3.7710022926330566
INFO:root:current mean train loss 1682.1350995588966
INFO:root:current train perplexity3.7716219425201416
INFO:root:current mean train loss 1684.5869513678938
INFO:root:current train perplexity3.7773542404174805
INFO:root:current mean train loss 1684.476471503971
INFO:root:current train perplexity3.779959201812744
INFO:root:current mean train loss 1684.9823174702994
INFO:root:current train perplexity3.780905246734619
INFO:root:current mean train loss 1686.5692109152737
INFO:root:current train perplexity3.7823550701141357
INFO:root:current mean train loss 1686.93664818266
INFO:root:current train perplexity3.7816898822784424
INFO:root:current mean train loss 1687.6744704003056
INFO:root:current train perplexity3.7828524112701416
INFO:root:current mean train loss 1688.3250064827494
INFO:root:current train perplexity3.7836198806762695
INFO:root:current mean train loss 1687.7275990161918
INFO:root:current train perplexity3.7842843532562256
INFO:root:current mean train loss 1688.5081263218947
INFO:root:current train perplexity3.7865288257598877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it]
INFO:root:final mean train loss: 1687.5737325001774
INFO:root:final train perplexity: 3.7879669666290283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2150.631555435505
INFO:root:eval perplexity: 5.699182987213135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2635.4196119376106
INFO:root:eval perplexity: 8.729026794433594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [7:25:21<13:10:11, 370.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1630.2730341372283
INFO:root:current train perplexity3.75762677192688
INFO:root:current mean train loss 1668.3919836525026
INFO:root:current train perplexity3.7646706104278564
INFO:root:current mean train loss 1671.8792231948921
INFO:root:current train perplexity3.7593436241149902
INFO:root:current mean train loss 1677.7548590031201
INFO:root:current train perplexity3.756216526031494
INFO:root:current mean train loss 1675.868241113974
INFO:root:current train perplexity3.7568652629852295
INFO:root:current mean train loss 1677.587532816608
INFO:root:current train perplexity3.7602763175964355
INFO:root:current mean train loss 1679.5593951425813
INFO:root:current train perplexity3.766140937805176
INFO:root:current mean train loss 1678.6118439269428
INFO:root:current train perplexity3.7647342681884766
INFO:root:current mean train loss 1679.0678129509038
INFO:root:current train perplexity3.7633657455444336
INFO:root:current mean train loss 1680.1298416815496
INFO:root:current train perplexity3.7594566345214844
INFO:root:current mean train loss 1679.7596408101936
INFO:root:current train perplexity3.7610416412353516
INFO:root:current mean train loss 1681.9999961954934
INFO:root:current train perplexity3.764317274093628
INFO:root:current mean train loss 1682.2363128537345
INFO:root:current train perplexity3.7646331787109375
INFO:root:current mean train loss 1682.7298318253083
INFO:root:current train perplexity3.767442226409912
INFO:root:current mean train loss 1682.5945742962986
INFO:root:current train perplexity3.7699155807495117
INFO:root:current mean train loss 1682.3517849196435
INFO:root:current train perplexity3.7686030864715576
INFO:root:current mean train loss 1682.5047027531482
INFO:root:current train perplexity3.770024299621582
INFO:root:current mean train loss 1682.641814530207
INFO:root:current train perplexity3.770840883255005
INFO:root:current mean train loss 1682.5985482404733
INFO:root:current train perplexity3.771244764328003
INFO:root:current mean train loss 1683.8572841253495
INFO:root:current train perplexity3.773658275604248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it]
INFO:root:final mean train loss: 1682.97732748627
INFO:root:final train perplexity: 3.7742512226104736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 2153.0074307056184
INFO:root:eval perplexity: 5.710150718688965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2640.5664750768783
INFO:root:eval perplexity: 8.766043663024902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [7:31:31<13:03:25, 370.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1643.0603424072265
INFO:root:current train perplexity3.6690800189971924
INFO:root:current mean train loss 1668.139226422991
INFO:root:current train perplexity3.7182998657226562
INFO:root:current mean train loss 1668.5851216634114
INFO:root:current train perplexity3.727208375930786
INFO:root:current mean train loss 1671.3742862477022
INFO:root:current train perplexity3.735471248626709
INFO:root:current mean train loss 1670.3086489590733
INFO:root:current train perplexity3.73284912109375
INFO:root:current mean train loss 1670.975188530816
INFO:root:current train perplexity3.739168167114258
INFO:root:current mean train loss 1672.1977005004883
INFO:root:current train perplexity3.7376034259796143
INFO:root:current mean train loss 1673.9495692897488
INFO:root:current train perplexity3.743917942047119
INFO:root:current mean train loss 1676.0136856805711
INFO:root:current train perplexity3.7471232414245605
INFO:root:current mean train loss 1676.41854767495
INFO:root:current train perplexity3.745924472808838
INFO:root:current mean train loss 1678.1528255756084
INFO:root:current train perplexity3.7512378692626953
INFO:root:current mean train loss 1678.5589096337035
INFO:root:current train perplexity3.7535057067871094
INFO:root:current mean train loss 1678.6544580275013
INFO:root:current train perplexity3.753324031829834
INFO:root:current mean train loss 1678.6834217583955
INFO:root:current train perplexity3.756269693374634
INFO:root:current mean train loss 1678.7313872443306
INFO:root:current train perplexity3.7583417892456055
INFO:root:current mean train loss 1678.1672937962917
INFO:root:current train perplexity3.7572038173675537
INFO:root:current mean train loss 1677.3129550840797
INFO:root:current train perplexity3.7578225135803223
INFO:root:current mean train loss 1677.2289829999552
INFO:root:current train perplexity3.756826400756836
INFO:root:current mean train loss 1677.5673931619394
INFO:root:current train perplexity3.757553815841675
INFO:root:current mean train loss 1677.5579811332152
INFO:root:current train perplexity3.7578282356262207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.88s/it]
INFO:root:final mean train loss: 1677.388695236414
INFO:root:final train perplexity: 3.7576420307159424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2154.2553979319036
INFO:root:eval perplexity: 5.715919494628906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 2641.503039637356
INFO:root:eval perplexity: 8.772794723510742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [7:37:43<12:58:25, 370.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1658.7934655975878
INFO:root:current train perplexity3.6950173377990723
INFO:root:current mean train loss 1671.806359163515
INFO:root:current train perplexity3.730644941329956
INFO:root:current mean train loss 1669.6498125721973
INFO:root:current train perplexity3.732619524002075
INFO:root:current mean train loss 1667.920187557445
INFO:root:current train perplexity3.725484848022461
INFO:root:current mean train loss 1670.9125706779096
INFO:root:current train perplexity3.7285749912261963
INFO:root:current mean train loss 1668.8590006802626
INFO:root:current train perplexity3.7252538204193115
INFO:root:current mean train loss 1667.9771193412885
INFO:root:current train perplexity3.7266175746917725
INFO:root:current mean train loss 1669.0850883292396
INFO:root:current train perplexity3.732328176498413
INFO:root:current mean train loss 1671.4721711024104
INFO:root:current train perplexity3.734549045562744
INFO:root:current mean train loss 1669.7704283456194
INFO:root:current train perplexity3.7323224544525146
INFO:root:current mean train loss 1670.4665223611562
INFO:root:current train perplexity3.7329261302948
INFO:root:current mean train loss 1671.388395871597
INFO:root:current train perplexity3.7317845821380615
INFO:root:current mean train loss 1671.0202868817435
INFO:root:current train perplexity3.7320008277893066
INFO:root:current mean train loss 1670.493021032436
INFO:root:current train perplexity3.7343099117279053
INFO:root:current mean train loss 1671.2230132449222
INFO:root:current train perplexity3.735677719116211
INFO:root:current mean train loss 1672.2422465359314
INFO:root:current train perplexity3.737730026245117
INFO:root:current mean train loss 1673.2541971707387
INFO:root:current train perplexity3.7397239208221436
INFO:root:current mean train loss 1674.2434219594834
INFO:root:current train perplexity3.74336314201355
INFO:root:current mean train loss 1673.5262609593767
INFO:root:current train perplexity3.7427773475646973
INFO:root:current mean train loss 1674.0406447982202
INFO:root:current train perplexity3.7455034255981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.09s/it]
INFO:root:final mean train loss: 1673.426881791123
INFO:root:final train perplexity: 3.7459115982055664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2156.509608924812
INFO:root:eval perplexity: 5.726356029510498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2643.0760835688166
INFO:root:eval perplexity: 8.784147262573242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:43:54<12:52:17, 370.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1660.8380687816723
INFO:root:current train perplexity3.658639907836914
INFO:root:current mean train loss 1661.6161463945762
INFO:root:current train perplexity3.6951332092285156
INFO:root:current mean train loss 1662.596135717239
INFO:root:current train perplexity3.693650007247925
INFO:root:current mean train loss 1663.3921042049633
INFO:root:current train perplexity3.6924476623535156
INFO:root:current mean train loss 1666.5295420457542
INFO:root:current train perplexity3.697894334793091
INFO:root:current mean train loss 1667.8164285799353
INFO:root:current train perplexity3.703735589981079
INFO:root:current mean train loss 1670.6533717486554
INFO:root:current train perplexity3.711676836013794
INFO:root:current mean train loss 1670.5563212549964
INFO:root:current train perplexity3.7183690071105957
INFO:root:current mean train loss 1668.7784976915582
INFO:root:current train perplexity3.7178773880004883
INFO:root:current mean train loss 1669.7213272627375
INFO:root:current train perplexity3.720841407775879
INFO:root:current mean train loss 1669.7760903129365
INFO:root:current train perplexity3.7233736515045166
INFO:root:current mean train loss 1669.8043646479384
INFO:root:current train perplexity3.7261340618133545
INFO:root:current mean train loss 1668.4688679501999
INFO:root:current train perplexity3.7282376289367676
INFO:root:current mean train loss 1668.5737336670988
INFO:root:current train perplexity3.729198455810547
INFO:root:current mean train loss 1668.4749017971665
INFO:root:current train perplexity3.7313668727874756
INFO:root:current mean train loss 1668.5460908494729
INFO:root:current train perplexity3.730546712875366
INFO:root:current mean train loss 1667.4591016325044
INFO:root:current train perplexity3.729640483856201
INFO:root:current mean train loss 1668.6236356887903
INFO:root:current train perplexity3.7298943996429443
INFO:root:current mean train loss 1668.9859617186457
INFO:root:current train perplexity3.73075532913208
INFO:root:current mean train loss 1669.149010624446
INFO:root:current train perplexity3.732042074203491

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.25s/it]
INFO:root:final mean train loss: 1668.6052423689741
INFO:root:final train perplexity: 3.7316839694976807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2160.1848720252938
INFO:root:eval perplexity: 5.743411064147949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2650.78759765625
INFO:root:eval perplexity: 8.840011596679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:50:03<12:45:39, 370.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1641.7881194733002
INFO:root:current train perplexity3.67516827583313
INFO:root:current mean train loss 1651.652663305792
INFO:root:current train perplexity3.6717734336853027
INFO:root:current mean train loss 1651.1526797579736
INFO:root:current train perplexity3.6779329776763916
INFO:root:current mean train loss 1651.1501558503837
INFO:root:current train perplexity3.69132661819458
INFO:root:current mean train loss 1654.563956390816
INFO:root:current train perplexity3.69952392578125
INFO:root:current mean train loss 1655.3590903758195
INFO:root:current train perplexity3.702972173690796
INFO:root:current mean train loss 1655.8134896351528
INFO:root:current train perplexity3.7056620121002197
INFO:root:current mean train loss 1658.225838874595
INFO:root:current train perplexity3.7026071548461914
INFO:root:current mean train loss 1658.274883437237
INFO:root:current train perplexity3.704246759414673
INFO:root:current mean train loss 1658.2277966296276
INFO:root:current train perplexity3.708037853240967
INFO:root:current mean train loss 1659.449872066732
INFO:root:current train perplexity3.7081785202026367
INFO:root:current mean train loss 1660.4103675925562
INFO:root:current train perplexity3.709226369857788
INFO:root:current mean train loss 1661.2628529354365
INFO:root:current train perplexity3.7103443145751953
INFO:root:current mean train loss 1661.6567785618204
INFO:root:current train perplexity3.709944009780884
INFO:root:current mean train loss 1662.288607949782
INFO:root:current train perplexity3.7121174335479736
INFO:root:current mean train loss 1662.6534678556873
INFO:root:current train perplexity3.7137091159820557
INFO:root:current mean train loss 1663.033153026362
INFO:root:current train perplexity3.71527361869812
INFO:root:current mean train loss 1663.4645112089308
INFO:root:current train perplexity3.7168848514556885
INFO:root:current mean train loss 1663.867136761097
INFO:root:current train perplexity3.7179620265960693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.44s/it]
INFO:root:final mean train loss: 1663.7238587318377
INFO:root:final train perplexity: 3.7173359394073486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2162.5499908230827
INFO:root:eval perplexity: 5.7544145584106445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2653.918660914644
INFO:root:eval perplexity: 8.862800598144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:56:14<12:39:16, 370.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.4195556640625
INFO:root:current train perplexity3.655754327774048
INFO:root:current mean train loss 1652.8930483217594
INFO:root:current train perplexity3.6786108016967773
INFO:root:current mean train loss 1651.5768197866587
INFO:root:current train perplexity3.6812102794647217
INFO:root:current mean train loss 1650.694123899782
INFO:root:current train perplexity3.6803596019744873
INFO:root:current mean train loss 1649.4976274078967
INFO:root:current train perplexity3.679500102996826
INFO:root:current mean train loss 1649.8604013037493
INFO:root:current train perplexity3.683689832687378
INFO:root:current mean train loss 1651.1748761628803
INFO:root:current train perplexity3.69124698638916
INFO:root:current mean train loss 1651.7979389772577
INFO:root:current train perplexity3.6904516220092773
INFO:root:current mean train loss 1652.7552049089186
INFO:root:current train perplexity3.690279006958008
INFO:root:current mean train loss 1654.7267528651569
INFO:root:current train perplexity3.6939215660095215
INFO:root:current mean train loss 1654.7822040376209
INFO:root:current train perplexity3.692197561264038
INFO:root:current mean train loss 1654.6445489876537
INFO:root:current train perplexity3.6933422088623047
INFO:root:current mean train loss 1655.9285537012365
INFO:root:current train perplexity3.695206880569458
INFO:root:current mean train loss 1656.003789872569
INFO:root:current train perplexity3.6951208114624023
INFO:root:current mean train loss 1656.9288743625987
INFO:root:current train perplexity3.6971375942230225
INFO:root:current mean train loss 1657.621752104013
INFO:root:current train perplexity3.6982924938201904
INFO:root:current mean train loss 1658.2007517648574
INFO:root:current train perplexity3.699298620223999
INFO:root:current mean train loss 1658.1740563993433
INFO:root:current train perplexity3.6988065242767334
INFO:root:current mean train loss 1658.5580548986925
INFO:root:current train perplexity3.70035982131958
INFO:root:current mean train loss 1659.2775308221142
INFO:root:current train perplexity3.701453924179077

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.48s/it]
INFO:root:final mean train loss: 1658.472452460908
INFO:root:final train perplexity: 3.7019619941711426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2164.165851565963
INFO:root:eval perplexity: 5.76194429397583
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2655.8077487810283
INFO:root:eval perplexity: 8.87657642364502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [8:02:24<12:32:57, 370.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.443388671875
INFO:root:current train perplexity3.64322566986084
INFO:root:current mean train loss 1649.74702734375
INFO:root:current train perplexity3.6711480617523193
INFO:root:current mean train loss 1648.289007703993
INFO:root:current train perplexity3.6885149478912354
INFO:root:current mean train loss 1646.0551303335337
INFO:root:current train perplexity3.683715581893921
INFO:root:current mean train loss 1645.4450551470588
INFO:root:current train perplexity3.6795029640197754
INFO:root:current mean train loss 1647.0833561197917
INFO:root:current train perplexity3.680196762084961
INFO:root:current mean train loss 1646.6882880859375
INFO:root:current train perplexity3.6807479858398438
INFO:root:current mean train loss 1647.5865141769934
INFO:root:current train perplexity3.6809427738189697
INFO:root:current mean train loss 1648.2916511304452
INFO:root:current train perplexity3.682178258895874
INFO:root:current mean train loss 1650.0743856894003
INFO:root:current train perplexity3.6847825050354004
INFO:root:current mean train loss 1651.9109722751525
INFO:root:current train perplexity3.6906442642211914
INFO:root:current mean train loss 1652.5430652126736
INFO:root:current train perplexity3.6907498836517334
INFO:root:current mean train loss 1652.0489654416454
INFO:root:current train perplexity3.6891262531280518
INFO:root:current mean train loss 1651.82186366819
INFO:root:current train perplexity3.6875667572021484
INFO:root:current mean train loss 1652.355642047012
INFO:root:current train perplexity3.6871540546417236
INFO:root:current mean train loss 1653.9011138415729
INFO:root:current train perplexity3.6892929077148438
INFO:root:current mean train loss 1653.7973969350962
INFO:root:current train perplexity3.6895766258239746
INFO:root:current mean train loss 1653.6836514945653
INFO:root:current train perplexity3.689725637435913
INFO:root:current mean train loss 1653.651847442209
INFO:root:current train perplexity3.690034866333008
INFO:root:current mean train loss 1654.6897344257304
INFO:root:current train perplexity3.6900508403778076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it]
INFO:root:final mean train loss: 1654.2274934169445
INFO:root:final train perplexity: 3.689580202102661
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2167.692983207973
INFO:root:eval perplexity: 5.778412818908691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2659.8032066399323
INFO:root:eval perplexity: 8.905780792236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [8:08:34<12:27:00, 370.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1627.6652076357886
INFO:root:current train perplexity3.613878011703491
INFO:root:current mean train loss 1635.4149685711927
INFO:root:current train perplexity3.646056652069092
INFO:root:current mean train loss 1638.0453344928333
INFO:root:current train perplexity3.655571699142456
INFO:root:current mean train loss 1643.33454511319
INFO:root:current train perplexity3.65983247756958
INFO:root:current mean train loss 1642.9620281236744
INFO:root:current train perplexity3.6538307666778564
INFO:root:current mean train loss 1642.3571439510781
INFO:root:current train perplexity3.655883312225342
INFO:root:current mean train loss 1643.145116883275
INFO:root:current train perplexity3.6606454849243164
INFO:root:current mean train loss 1643.5305086943017
INFO:root:current train perplexity3.659770965576172
INFO:root:current mean train loss 1646.5262010442955
INFO:root:current train perplexity3.664480209350586
INFO:root:current mean train loss 1646.5352727481009
INFO:root:current train perplexity3.663546323776245
INFO:root:current mean train loss 1647.5628248569833
INFO:root:current train perplexity3.6667091846466064
INFO:root:current mean train loss 1647.811126869322
INFO:root:current train perplexity3.6689329147338867
INFO:root:current mean train loss 1648.4615098151608
INFO:root:current train perplexity3.670180559158325
INFO:root:current mean train loss 1649.027295722336
INFO:root:current train perplexity3.6710903644561768
INFO:root:current mean train loss 1649.0062497968318
INFO:root:current train perplexity3.6708054542541504
INFO:root:current mean train loss 1650.4494483245176
INFO:root:current train perplexity3.6731197834014893
INFO:root:current mean train loss 1649.9196058452203
INFO:root:current train perplexity3.6728246212005615
INFO:root:current mean train loss 1649.835595675095
INFO:root:current train perplexity3.673872947692871
INFO:root:current mean train loss 1650.416768391927
INFO:root:current train perplexity3.6759424209594727
INFO:root:current mean train loss 1650.3852469918656
INFO:root:current train perplexity3.676896572113037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.43s/it]
INFO:root:final mean train loss: 1649.7870909998169
INFO:root:final train perplexity: 3.676673412322998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2167.977833416445
INFO:root:eval perplexity: 5.779745101928711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2661.2672370207224
INFO:root:eval perplexity: 8.916505813598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [8:14:45<12:20:52, 370.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1633.9163839049259
INFO:root:current train perplexity3.6464922428131104
INFO:root:current mean train loss 1641.859433348074
INFO:root:current train perplexity3.658412218093872
INFO:root:current mean train loss 1638.3933044197936
INFO:root:current train perplexity3.643493175506592
INFO:root:current mean train loss 1634.1792532833174
INFO:root:current train perplexity3.638188123703003
INFO:root:current mean train loss 1634.154005395561
INFO:root:current train perplexity3.63547945022583
INFO:root:current mean train loss 1636.2521734630059
INFO:root:current train perplexity3.6414220333099365
INFO:root:current mean train loss 1638.6220227069305
INFO:root:current train perplexity3.6441712379455566
INFO:root:current mean train loss 1640.7111790673378
INFO:root:current train perplexity3.648845911026001
INFO:root:current mean train loss 1641.242177126155
INFO:root:current train perplexity3.6500649452209473
INFO:root:current mean train loss 1640.4332050088797
INFO:root:current train perplexity3.6501762866973877
INFO:root:current mean train loss 1641.851301760579
INFO:root:current train perplexity3.650113344192505
INFO:root:current mean train loss 1643.0140753705714
INFO:root:current train perplexity3.6525399684906006
INFO:root:current mean train loss 1644.1359912729906
INFO:root:current train perplexity3.6566548347473145
INFO:root:current mean train loss 1644.3476942453954
INFO:root:current train perplexity3.6598339080810547
INFO:root:current mean train loss 1645.2604424082474
INFO:root:current train perplexity3.6594297885894775
INFO:root:current mean train loss 1646.0340061738293
INFO:root:current train perplexity3.661261796951294
INFO:root:current mean train loss 1646.25813316451
INFO:root:current train perplexity3.662105083465576
INFO:root:current mean train loss 1645.7665074594051
INFO:root:current train perplexity3.663597822189331
INFO:root:current mean train loss 1645.5782383369335
INFO:root:current train perplexity3.6636154651641846
INFO:root:current mean train loss 1645.6221311295624
INFO:root:current train perplexity3.664113759994507

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.65s/it]
INFO:root:final mean train loss: 1645.5350226682663
INFO:root:final train perplexity: 3.664356231689453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2170.0594205382868
INFO:root:eval perplexity: 5.789488792419434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2665.169878587655
INFO:root:eval perplexity: 8.945158958435059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [8:20:55<12:14:37, 370.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1649.6028233578331
INFO:root:current train perplexity3.609633207321167
INFO:root:current mean train loss 1640.35456570712
INFO:root:current train perplexity3.633275032043457
INFO:root:current mean train loss 1633.4997293223505
INFO:root:current train perplexity3.6235644817352295
INFO:root:current mean train loss 1633.0248383866979
INFO:root:current train perplexity3.6250243186950684
INFO:root:current mean train loss 1636.521305372735
INFO:root:current train perplexity3.6340415477752686
INFO:root:current mean train loss 1635.4553574456108
INFO:root:current train perplexity3.6331000328063965
INFO:root:current mean train loss 1637.0448552419448
INFO:root:current train perplexity3.637718915939331
INFO:root:current mean train loss 1635.1161782176225
INFO:root:current train perplexity3.6370320320129395
INFO:root:current mean train loss 1633.9879519667256
INFO:root:current train perplexity3.63580060005188
INFO:root:current mean train loss 1635.3228236964492
INFO:root:current train perplexity3.638568878173828
INFO:root:current mean train loss 1635.2906515695793
INFO:root:current train perplexity3.639653444290161
INFO:root:current mean train loss 1636.0803073182399
INFO:root:current train perplexity3.641021728515625
INFO:root:current mean train loss 1636.543014191535
INFO:root:current train perplexity3.6421968936920166
INFO:root:current mean train loss 1638.1737205150516
INFO:root:current train perplexity3.6458241939544678
INFO:root:current mean train loss 1637.7359988825108
INFO:root:current train perplexity3.6476356983184814
INFO:root:current mean train loss 1638.7534629705594
INFO:root:current train perplexity3.6475672721862793
INFO:root:current mean train loss 1639.582999290885
INFO:root:current train perplexity3.6486384868621826
INFO:root:current mean train loss 1639.2975208866703
INFO:root:current train perplexity3.648622512817383
INFO:root:current mean train loss 1640.3335387142483
INFO:root:current train perplexity3.6510093212127686
INFO:root:current mean train loss 1641.0467206205917
INFO:root:current train perplexity3.6504156589508057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.70s/it]
INFO:root:final mean train loss: 1640.7980973652018
INFO:root:final train perplexity: 3.6506829261779785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2173.4265015514184
INFO:root:eval perplexity: 5.805285453796387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2669.6981711962544
INFO:root:eval perplexity: 8.978525161743164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [8:27:05<12:07:49, 370.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1623.8902981665826
INFO:root:current train perplexity3.608306884765625
INFO:root:current mean train loss 1623.0768258682804
INFO:root:current train perplexity3.6145970821380615
INFO:root:current mean train loss 1621.356669455258
INFO:root:current train perplexity3.622119665145874
INFO:root:current mean train loss 1624.430153106612
INFO:root:current train perplexity3.6270179748535156
INFO:root:current mean train loss 1626.997288454377
INFO:root:current train perplexity3.62850022315979
INFO:root:current mean train loss 1628.6381955331735
INFO:root:current train perplexity3.6270368099212646
INFO:root:current mean train loss 1629.1432661576705
INFO:root:current train perplexity3.6248886585235596
INFO:root:current mean train loss 1628.8277592508668
INFO:root:current train perplexity3.6237876415252686
INFO:root:current mean train loss 1631.2575613878341
INFO:root:current train perplexity3.627976179122925
INFO:root:current mean train loss 1631.6657187470496
INFO:root:current train perplexity3.6272499561309814
INFO:root:current mean train loss 1631.4047392542386
INFO:root:current train perplexity3.6283109188079834
INFO:root:current mean train loss 1632.4925714126678
INFO:root:current train perplexity3.6294422149658203
INFO:root:current mean train loss 1632.5022050071298
INFO:root:current train perplexity3.6297736167907715
INFO:root:current mean train loss 1633.1123411420945
INFO:root:current train perplexity3.6299705505371094
INFO:root:current mean train loss 1634.5376704242192
INFO:root:current train perplexity3.6316215991973877
INFO:root:current mean train loss 1633.7945584993429
INFO:root:current train perplexity3.631802558898926
INFO:root:current mean train loss 1634.7536341334262
INFO:root:current train perplexity3.6327967643737793
INFO:root:current mean train loss 1636.1177154047425
INFO:root:current train perplexity3.633829355239868
INFO:root:current mean train loss 1636.4427274209258
INFO:root:current train perplexity3.6343436241149902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.83s/it]
INFO:root:final mean train loss: 1635.9248077961993
INFO:root:final train perplexity: 3.636669635772705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 2175.556049319869
INFO:root:eval perplexity: 5.815297603607178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2671.5389451912956
INFO:root:eval perplexity: 8.992122650146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [8:33:14<12:01:12, 369.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1605.6559814453126
INFO:root:current train perplexity3.570890426635742
INFO:root:current mean train loss 1626.4708529385653
INFO:root:current train perplexity3.5924577713012695
INFO:root:current mean train loss 1621.6255911690848
INFO:root:current train perplexity3.6074259281158447
INFO:root:current mean train loss 1622.9875630040322
INFO:root:current train perplexity3.615805149078369
INFO:root:current mean train loss 1623.0307066382431
INFO:root:current train perplexity3.6120166778564453
INFO:root:current mean train loss 1624.4940240598191
INFO:root:current train perplexity3.6105589866638184
INFO:root:current mean train loss 1624.272520171619
INFO:root:current train perplexity3.608365297317505
INFO:root:current mean train loss 1626.1225922920335
INFO:root:current train perplexity3.610755681991577
INFO:root:current mean train loss 1627.1818740656347
INFO:root:current train perplexity3.611217975616455
INFO:root:current mean train loss 1628.7164534684066
INFO:root:current train perplexity3.6129777431488037
INFO:root:current mean train loss 1628.8160534547108
INFO:root:current train perplexity3.6131768226623535
INFO:root:current mean train loss 1628.5493498381193
INFO:root:current train perplexity3.6146795749664307
INFO:root:current mean train loss 1630.1346783598592
INFO:root:current train perplexity3.615405559539795
INFO:root:current mean train loss 1631.1896833812918
INFO:root:current train perplexity3.617264986038208
INFO:root:current mean train loss 1631.8762510042664
INFO:root:current train perplexity3.618041753768921
INFO:root:current mean train loss 1632.1377017798013
INFO:root:current train perplexity3.6226353645324707
INFO:root:current mean train loss 1632.3444984199098
INFO:root:current train perplexity3.622624158859253
INFO:root:current mean train loss 1631.8203326308937
INFO:root:current train perplexity3.6230807304382324
INFO:root:current mean train loss 1633.4248719947773
INFO:root:current train perplexity3.6264290809631348
INFO:root:current mean train loss 1633.8957091326488
INFO:root:current train perplexity3.627987861633301

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.40s/it]
INFO:root:final mean train loss: 1632.668424159063
INFO:root:final train perplexity: 3.627335786819458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it]
INFO:root:eval mean loss: 2179.5915782739085
INFO:root:eval perplexity: 5.834319114685059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2677.953156166888
INFO:root:eval perplexity: 9.039664268493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [8:39:23<11:54:30, 369.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1599.52734375
INFO:root:current train perplexity3.561344861984253
INFO:root:current mean train loss 1618.5088121309054
INFO:root:current train perplexity3.594503402709961
INFO:root:current mean train loss 1622.6685920076748
INFO:root:current train perplexity3.5794544219970703
INFO:root:current mean train loss 1618.1084368877819
INFO:root:current train perplexity3.5821163654327393
INFO:root:current mean train loss 1621.3547105990194
INFO:root:current train perplexity3.5901498794555664
INFO:root:current mean train loss 1624.0717511692808
INFO:root:current train perplexity3.5954337120056152
INFO:root:current mean train loss 1623.4514679977199
INFO:root:current train perplexity3.602414846420288
INFO:root:current mean train loss 1626.4168639045306
INFO:root:current train perplexity3.6069483757019043
INFO:root:current mean train loss 1626.36049267401
INFO:root:current train perplexity3.604055643081665
INFO:root:current mean train loss 1626.4090776330315
INFO:root:current train perplexity3.6016740798950195
INFO:root:current mean train loss 1626.5891910838989
INFO:root:current train perplexity3.6001524925231934
INFO:root:current mean train loss 1626.242004881946
INFO:root:current train perplexity3.6028692722320557
INFO:root:current mean train loss 1626.6316933729051
INFO:root:current train perplexity3.606342077255249
INFO:root:current mean train loss 1625.8968699037714
INFO:root:current train perplexity3.6046066284179688
INFO:root:current mean train loss 1626.2622436437894
INFO:root:current train perplexity3.606581211090088
INFO:root:current mean train loss 1626.1685109916043
INFO:root:current train perplexity3.60939359664917
INFO:root:current mean train loss 1627.093138297936
INFO:root:current train perplexity3.611617088317871
INFO:root:current mean train loss 1627.631605721514
INFO:root:current train perplexity3.6129627227783203
INFO:root:current mean train loss 1627.7534384808387
INFO:root:current train perplexity3.613689422607422
INFO:root:current mean train loss 1628.6972677788094
INFO:root:current train perplexity3.61456561088562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.32s/it]
INFO:root:final mean train loss: 1628.0921437873783
INFO:root:final train perplexity: 3.6142590045928955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 2178.116234312666
INFO:root:eval perplexity: 5.827357292175293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2678.5729357130986
INFO:root:eval perplexity: 9.044270515441895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [8:45:32<11:47:54, 369.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.6828363591974
INFO:root:current train perplexity3.542306423187256
INFO:root:current mean train loss 1614.319552951389
INFO:root:current train perplexity3.566124200820923
INFO:root:current mean train loss 1614.066394243084
INFO:root:current train perplexity3.576059341430664
INFO:root:current mean train loss 1616.1030213112056
INFO:root:current train perplexity3.577246904373169
INFO:root:current mean train loss 1617.797282450908
INFO:root:current train perplexity3.5792291164398193
INFO:root:current mean train loss 1616.6535206963035
INFO:root:current train perplexity3.582066774368286
INFO:root:current mean train loss 1617.5183461823078
INFO:root:current train perplexity3.5829708576202393
INFO:root:current mean train loss 1617.909401842343
INFO:root:current train perplexity3.5832650661468506
INFO:root:current mean train loss 1617.6105019808945
INFO:root:current train perplexity3.5853512287139893
INFO:root:current mean train loss 1620.8383659750727
INFO:root:current train perplexity3.5897903442382812
INFO:root:current mean train loss 1620.7586005784542
INFO:root:current train perplexity3.5907533168792725
INFO:root:current mean train loss 1620.9420695271526
INFO:root:current train perplexity3.5908048152923584
INFO:root:current mean train loss 1621.2199630491987
INFO:root:current train perplexity3.5909831523895264
INFO:root:current mean train loss 1621.3730098179408
INFO:root:current train perplexity3.5926260948181152
INFO:root:current mean train loss 1623.0839984080137
INFO:root:current train perplexity3.5954902172088623
INFO:root:current mean train loss 1623.2467195975348
INFO:root:current train perplexity3.5974984169006348
INFO:root:current mean train loss 1623.490094855464
INFO:root:current train perplexity3.599632740020752
INFO:root:current mean train loss 1623.353232497469
INFO:root:current train perplexity3.599639654159546
INFO:root:current mean train loss 1624.0716520297035
INFO:root:current train perplexity3.6024487018585205
INFO:root:current mean train loss 1624.0878103750724
INFO:root:current train perplexity3.6026854515075684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.40s/it]
INFO:root:final mean train loss: 1624.022266043597
INFO:root:final train perplexity: 3.602668285369873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it]
INFO:root:eval mean loss: 2180.379146494764
INFO:root:eval perplexity: 5.838039398193359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2680.2809738267397
INFO:root:eval perplexity: 9.05698013305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:51:41<11:41:32, 369.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1589.1199991194928
INFO:root:current train perplexity3.547398328781128
INFO:root:current mean train loss 1601.0303773109956
INFO:root:current train perplexity3.554279088973999
INFO:root:current mean train loss 1605.4273068950552
INFO:root:current train perplexity3.5632436275482178
INFO:root:current mean train loss 1604.717803870542
INFO:root:current train perplexity3.563732624053955
INFO:root:current mean train loss 1608.41122654979
INFO:root:current train perplexity3.5743303298950195
INFO:root:current mean train loss 1615.1377442711814
INFO:root:current train perplexity3.579636573791504
INFO:root:current mean train loss 1616.3820813708514
INFO:root:current train perplexity3.579127073287964
INFO:root:current mean train loss 1616.6979499245442
INFO:root:current train perplexity3.5803847312927246
INFO:root:current mean train loss 1617.3752527890445
INFO:root:current train perplexity3.5849900245666504
INFO:root:current mean train loss 1618.143803782071
INFO:root:current train perplexity3.584881544113159
INFO:root:current mean train loss 1617.1507105849803
INFO:root:current train perplexity3.5843417644500732
INFO:root:current mean train loss 1619.1293207212937
INFO:root:current train perplexity3.5888054370880127
INFO:root:current mean train loss 1619.0853753570145
INFO:root:current train perplexity3.5901811122894287
INFO:root:current mean train loss 1619.2241655808
INFO:root:current train perplexity3.590137481689453
INFO:root:current mean train loss 1619.9007941839386
INFO:root:current train perplexity3.591524362564087
INFO:root:current mean train loss 1619.8443070973135
INFO:root:current train perplexity3.590785503387451
INFO:root:current mean train loss 1620.3766795875508
INFO:root:current train perplexity3.5913381576538086
INFO:root:current mean train loss 1620.5091697610555
INFO:root:current train perplexity3.5908350944519043
INFO:root:current mean train loss 1620.594567825178
INFO:root:current train perplexity3.590451240539551
INFO:root:current mean train loss 1620.3033848149262
INFO:root:current train perplexity3.5916366577148438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.32s/it]
INFO:root:final mean train loss: 1619.9817817599499
INFO:root:final train perplexity: 3.5911989212036133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2181.9701382251496
INFO:root:eval perplexity: 5.845559597015381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2680.8831111826794
INFO:root:eval perplexity: 9.061464309692383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:57:51<11:35:49, 369.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.0526467347756
INFO:root:current train perplexity3.527834177017212
INFO:root:current mean train loss 1599.691509118241
INFO:root:current train perplexity3.534080743789673
INFO:root:current mean train loss 1606.5298808804519
INFO:root:current train perplexity3.5428972244262695
INFO:root:current mean train loss 1609.1705225384424
INFO:root:current train perplexity3.555320978164673
INFO:root:current mean train loss 1608.1904799968129
INFO:root:current train perplexity3.558504581451416
INFO:root:current mean train loss 1610.4858132332668
INFO:root:current train perplexity3.5599353313446045
INFO:root:current mean train loss 1613.2806911412242
INFO:root:current train perplexity3.561189651489258
INFO:root:current mean train loss 1613.3011435383696
INFO:root:current train perplexity3.563035488128662
INFO:root:current mean train loss 1614.407845673094
INFO:root:current train perplexity3.565209150314331
INFO:root:current mean train loss 1615.1720415049049
INFO:root:current train perplexity3.568880558013916
INFO:root:current mean train loss 1615.2373069522553
INFO:root:current train perplexity3.571690320968628
INFO:root:current mean train loss 1615.299519822229
INFO:root:current train perplexity3.5738766193389893
INFO:root:current mean train loss 1615.2164905530187
INFO:root:current train perplexity3.5742475986480713
INFO:root:current mean train loss 1615.8859933263504
INFO:root:current train perplexity3.577216625213623
INFO:root:current mean train loss 1616.261983703696
INFO:root:current train perplexity3.5788962841033936
INFO:root:current mean train loss 1616.1265780179372
INFO:root:current train perplexity3.5789783000946045
INFO:root:current mean train loss 1615.6573236804184
INFO:root:current train perplexity3.578555107116699
INFO:root:current mean train loss 1616.0627007500527
INFO:root:current train perplexity3.5786638259887695
INFO:root:current mean train loss 1616.683797720522
INFO:root:current train perplexity3.578763246536255
INFO:root:current mean train loss 1616.2806108279947
INFO:root:current train perplexity3.5795888900756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it]
INFO:root:final mean train loss: 1615.875319518889
INFO:root:final train perplexity: 3.5795793533325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2187.166234658965
INFO:root:eval perplexity: 5.870190620422363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2687.724448778951
INFO:root:eval perplexity: 9.112574577331543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [9:04:01<11:29:57, 369.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1602.1083470394738
INFO:root:current train perplexity3.5563595294952393
INFO:root:current mean train loss 1603.4493952824519
INFO:root:current train perplexity3.543546676635742
INFO:root:current mean train loss 1604.554291909428
INFO:root:current train perplexity3.539881944656372
INFO:root:current mean train loss 1603.736231704905
INFO:root:current train perplexity3.5430517196655273
INFO:root:current mean train loss 1606.829400943024
INFO:root:current train perplexity3.546177864074707
INFO:root:current mean train loss 1609.5551901424633
INFO:root:current train perplexity3.552356243133545
INFO:root:current mean train loss 1609.8080446970548
INFO:root:current train perplexity3.550389528274536
INFO:root:current mean train loss 1610.9311290045205
INFO:root:current train perplexity3.5522711277008057
INFO:root:current mean train loss 1611.9540551894204
INFO:root:current train perplexity3.5562751293182373
INFO:root:current mean train loss 1612.3457340413001
INFO:root:current train perplexity3.556908130645752
INFO:root:current mean train loss 1612.4103212400114
INFO:root:current train perplexity3.5559775829315186
INFO:root:current mean train loss 1611.725147403733
INFO:root:current train perplexity3.5574913024902344
INFO:root:current mean train loss 1611.1514266673203
INFO:root:current train perplexity3.559427261352539
INFO:root:current mean train loss 1611.505218046455
INFO:root:current train perplexity3.5606627464294434
INFO:root:current mean train loss 1611.7115082501568
INFO:root:current train perplexity3.561398506164551
INFO:root:current mean train loss 1612.1845775831455
INFO:root:current train perplexity3.5629501342773438
INFO:root:current mean train loss 1612.100804223705
INFO:root:current train perplexity3.564178228378296
INFO:root:current mean train loss 1612.1092539497736
INFO:root:current train perplexity3.5645639896392822
INFO:root:current mean train loss 1611.8519554440138
INFO:root:current train perplexity3.566084384918213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.26s/it]
INFO:root:final mean train loss: 1611.467046525102
INFO:root:final train perplexity: 3.5671472549438477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2186.953725395473
INFO:root:eval perplexity: 5.869182109832764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2690.599882518146
INFO:root:eval perplexity: 9.13414192199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [9:10:11<11:23:59, 369.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.6259867350261
INFO:root:current train perplexity3.4867382049560547
INFO:root:current mean train loss 1601.8741673060827
INFO:root:current train perplexity3.554262399673462
INFO:root:current mean train loss 1598.87256032116
INFO:root:current train perplexity3.5408923625946045
INFO:root:current mean train loss 1603.3907122489734
INFO:root:current train perplexity3.5423645973205566
INFO:root:current mean train loss 1603.7801315159475
INFO:root:current train perplexity3.54171085357666
INFO:root:current mean train loss 1606.161058664322
INFO:root:current train perplexity3.5489277839660645
INFO:root:current mean train loss 1605.3976877249922
INFO:root:current train perplexity3.545377254486084
INFO:root:current mean train loss 1604.854620601354
INFO:root:current train perplexity3.5483415126800537
INFO:root:current mean train loss 1605.7392575118342
INFO:root:current train perplexity3.5479304790496826
INFO:root:current mean train loss 1606.2276893749572
INFO:root:current train perplexity3.5496132373809814
INFO:root:current mean train loss 1606.2143641535943
INFO:root:current train perplexity3.5489773750305176
INFO:root:current mean train loss 1607.5872028817375
INFO:root:current train perplexity3.5510506629943848
INFO:root:current mean train loss 1607.0237911211775
INFO:root:current train perplexity3.55269718170166
INFO:root:current mean train loss 1607.1647492385491
INFO:root:current train perplexity3.5530412197113037
INFO:root:current mean train loss 1607.0287744451853
INFO:root:current train perplexity3.5544772148132324
INFO:root:current mean train loss 1606.6456584627665
INFO:root:current train perplexity3.555406332015991
INFO:root:current mean train loss 1606.5283240988
INFO:root:current train perplexity3.5553665161132812
INFO:root:current mean train loss 1607.037859123444
INFO:root:current train perplexity3.5557596683502197
INFO:root:current mean train loss 1606.7573866012608
INFO:root:current train perplexity3.555595636367798
INFO:root:current mean train loss 1607.2806466713112
INFO:root:current train perplexity3.5555660724639893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it]
INFO:root:final mean train loss: 1607.8542798110109
INFO:root:final train perplexity: 3.5569918155670166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2192.125049347573
INFO:root:eval perplexity: 5.893793106079102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2695.8743870511967
INFO:root:eval perplexity: 9.173836708068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [9:16:20<11:17:55, 369.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1592.7453150255926
INFO:root:current train perplexity3.502641439437866
INFO:root:current mean train loss 1590.5996803461119
INFO:root:current train perplexity3.5054681301116943
INFO:root:current mean train loss 1598.2093937636462
INFO:root:current train perplexity3.5198237895965576
INFO:root:current mean train loss 1599.820665724734
INFO:root:current train perplexity3.5229880809783936
INFO:root:current mean train loss 1598.1552023009542
INFO:root:current train perplexity3.522296905517578
INFO:root:current mean train loss 1598.753191365637
INFO:root:current train perplexity3.5248756408691406
INFO:root:current mean train loss 1600.2057697920807
INFO:root:current train perplexity3.529698133468628
INFO:root:current mean train loss 1600.482939124925
INFO:root:current train perplexity3.5319786071777344
INFO:root:current mean train loss 1600.009332120778
INFO:root:current train perplexity3.532998561859131
INFO:root:current mean train loss 1600.6035348093549
INFO:root:current train perplexity3.536675453186035
INFO:root:current mean train loss 1599.3035981203307
INFO:root:current train perplexity3.535954236984253
INFO:root:current mean train loss 1600.1466101214778
INFO:root:current train perplexity3.538130283355713
INFO:root:current mean train loss 1600.513460312945
INFO:root:current train perplexity3.5377368927001953
INFO:root:current mean train loss 1600.6009472803212
INFO:root:current train perplexity3.5374720096588135
INFO:root:current mean train loss 1600.4255668367848
INFO:root:current train perplexity3.5385525226593018
INFO:root:current mean train loss 1601.6482814990904
INFO:root:current train perplexity3.5404727458953857
INFO:root:current mean train loss 1602.106418710314
INFO:root:current train perplexity3.5403382778167725
INFO:root:current mean train loss 1603.6906208062599
INFO:root:current train perplexity3.542623519897461
INFO:root:current mean train loss 1603.4157949106625
INFO:root:current train perplexity3.5438246726989746
INFO:root:current mean train loss 1604.1122352042428
INFO:root:current train perplexity3.5448248386383057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.36s/it]
INFO:root:final mean train loss: 1603.5197796997131
INFO:root:final train perplexity: 3.544844627380371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2192.0910419437055
INFO:root:eval perplexity: 5.893631458282471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2696.4588103598735
INFO:root:eval perplexity: 9.178244590759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [9:22:31<11:11:55, 369.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1591.146341075068
INFO:root:current train perplexity3.521944284439087
INFO:root:current mean train loss 1581.731036460563
INFO:root:current train perplexity3.4962167739868164
INFO:root:current mean train loss 1584.6072799558563
INFO:root:current train perplexity3.5050671100616455
INFO:root:current mean train loss 1585.2476721967575
INFO:root:current train perplexity3.5054869651794434
INFO:root:current mean train loss 1593.8164883600757
INFO:root:current train perplexity3.5130722522735596
INFO:root:current mean train loss 1595.5845804179544
INFO:root:current train perplexity3.514587879180908
INFO:root:current mean train loss 1593.9498846567822
INFO:root:current train perplexity3.5110585689544678
INFO:root:current mean train loss 1594.263453752042
INFO:root:current train perplexity3.513073444366455
INFO:root:current mean train loss 1595.0834354914673
INFO:root:current train perplexity3.5156948566436768
INFO:root:current mean train loss 1595.988261507127
INFO:root:current train perplexity3.5187792778015137
INFO:root:current mean train loss 1597.5729350277845
INFO:root:current train perplexity3.522982358932495
INFO:root:current mean train loss 1597.4486086114746
INFO:root:current train perplexity3.5241668224334717
INFO:root:current mean train loss 1597.7909427355037
INFO:root:current train perplexity3.528071403503418
INFO:root:current mean train loss 1597.8853515806381
INFO:root:current train perplexity3.527531385421753
INFO:root:current mean train loss 1598.5765693210797
INFO:root:current train perplexity3.528691053390503
INFO:root:current mean train loss 1599.426648454555
INFO:root:current train perplexity3.53001070022583
INFO:root:current mean train loss 1598.494998899439
INFO:root:current train perplexity3.5307254791259766
INFO:root:current mean train loss 1598.630510782458
INFO:root:current train perplexity3.5318498611450195
INFO:root:current mean train loss 1598.702093750529
INFO:root:current train perplexity3.532663345336914
INFO:root:current mean train loss 1599.5867762472499
INFO:root:current train perplexity3.532585859298706

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.43s/it]
INFO:root:final mean train loss: 1599.372260928094
INFO:root:final train perplexity: 3.5332605838775635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2195.9911014205177
INFO:root:eval perplexity: 5.912261009216309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2702.0105062714706
INFO:root:eval perplexity: 9.220232963562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [9:28:40<11:05:23, 369.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1585.9824645027281
INFO:root:current train perplexity3.502267837524414
INFO:root:current mean train loss 1580.8085076267735
INFO:root:current train perplexity3.502321243286133
INFO:root:current mean train loss 1583.7634903940411
INFO:root:current train perplexity3.4937493801116943
INFO:root:current mean train loss 1587.6306216237301
INFO:root:current train perplexity3.5026347637176514
INFO:root:current mean train loss 1588.9050830816348
INFO:root:current train perplexity3.50183367729187
INFO:root:current mean train loss 1591.0016842667628
INFO:root:current train perplexity3.5031847953796387
INFO:root:current mean train loss 1593.1142414259875
INFO:root:current train perplexity3.509892225265503
INFO:root:current mean train loss 1595.096286278721
INFO:root:current train perplexity3.5109455585479736
INFO:root:current mean train loss 1594.5480536928321
INFO:root:current train perplexity3.5105390548706055
INFO:root:current mean train loss 1595.599709896036
INFO:root:current train perplexity3.5126781463623047
INFO:root:current mean train loss 1594.0655145510568
INFO:root:current train perplexity3.5125794410705566
INFO:root:current mean train loss 1593.6422169522182
INFO:root:current train perplexity3.5141441822052
INFO:root:current mean train loss 1593.8166813189703
INFO:root:current train perplexity3.5145702362060547
INFO:root:current mean train loss 1593.7037355306825
INFO:root:current train perplexity3.5169034004211426
INFO:root:current mean train loss 1594.181585055056
INFO:root:current train perplexity3.517198085784912
INFO:root:current mean train loss 1594.5157307474108
INFO:root:current train perplexity3.517820358276367
INFO:root:current mean train loss 1594.8140210709655
INFO:root:current train perplexity3.519101858139038
INFO:root:current mean train loss 1594.973421699407
INFO:root:current train perplexity3.5211567878723145
INFO:root:current mean train loss 1595.085309194994
INFO:root:current train perplexity3.5217061042785645
INFO:root:current mean train loss 1595.402914178414
INFO:root:current train perplexity3.5221168994903564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.06s/it]
INFO:root:final mean train loss: 1595.1384428469628
INFO:root:final train perplexity: 3.521474838256836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2199.3879892335717
INFO:root:eval perplexity: 5.928534984588623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2706.3040096201794
INFO:root:eval perplexity: 9.252838134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [9:34:49<10:59:17, 369.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1592.9994049072266
INFO:root:current train perplexity3.4841933250427246
INFO:root:current mean train loss 1591.8564751519098
INFO:root:current train perplexity3.4950969219207764
INFO:root:current mean train loss 1586.7909489222936
INFO:root:current train perplexity3.494795799255371
INFO:root:current mean train loss 1587.9784083316201
INFO:root:current train perplexity3.4947283267974854
INFO:root:current mean train loss 1588.603458404541
INFO:root:current train perplexity3.4942874908447266
INFO:root:current mean train loss 1588.3708921235184
INFO:root:current train perplexity3.4928202629089355
INFO:root:current mean train loss 1586.647511919807
INFO:root:current train perplexity3.4930052757263184
INFO:root:current mean train loss 1588.4788106282551
INFO:root:current train perplexity3.4979209899902344
INFO:root:current mean train loss 1586.7153108076616
INFO:root:current train perplexity3.498018980026245
INFO:root:current mean train loss 1587.622758265904
INFO:root:current train perplexity3.501042127609253
INFO:root:current mean train loss 1588.5562833432798
INFO:root:current train perplexity3.503710985183716
INFO:root:current mean train loss 1588.5961377160024
INFO:root:current train perplexity3.5041980743408203
INFO:root:current mean train loss 1588.9634026527406
INFO:root:current train perplexity3.5054471492767334
INFO:root:current mean train loss 1589.0247782389322
INFO:root:current train perplexity3.507030487060547
INFO:root:current mean train loss 1589.4792721310178
INFO:root:current train perplexity3.5097904205322266
INFO:root:current mean train loss 1589.9984991532338
INFO:root:current train perplexity3.5106654167175293
INFO:root:current mean train loss 1590.2778390793574
INFO:root:current train perplexity3.5109939575195312
INFO:root:current mean train loss 1591.4913833446717
INFO:root:current train perplexity3.5114214420318604
INFO:root:current mean train loss 1591.7140069839802
INFO:root:current train perplexity3.5115017890930176
INFO:root:current mean train loss 1592.3806057400175
INFO:root:current train perplexity3.512637138366699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.34s/it]
INFO:root:final mean train loss: 1591.9808589687145
INFO:root:final train perplexity: 3.5127100944519043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2202.558477739916
INFO:root:eval perplexity: 5.943765163421631
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2711.1804069356717
INFO:root:eval perplexity: 9.29000473022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [9:41:00<10:53:20, 369.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1567.2874340568621
INFO:root:current train perplexity3.4671027660369873
INFO:root:current mean train loss 1571.0414438005632
INFO:root:current train perplexity3.4677529335021973
INFO:root:current mean train loss 1579.015673499316
INFO:root:current train perplexity3.473231792449951
INFO:root:current mean train loss 1579.4935653263735
INFO:root:current train perplexity3.479921579360962
INFO:root:current mean train loss 1580.005553585183
INFO:root:current train perplexity3.4811530113220215
INFO:root:current mean train loss 1580.7336844950664
INFO:root:current train perplexity3.4859139919281006
INFO:root:current mean train loss 1582.8213626199336
INFO:root:current train perplexity3.4898200035095215
INFO:root:current mean train loss 1584.590628400202
INFO:root:current train perplexity3.4931225776672363
INFO:root:current mean train loss 1586.2633153262611
INFO:root:current train perplexity3.493084669113159
INFO:root:current mean train loss 1585.3459797115956
INFO:root:current train perplexity3.4925460815429688
INFO:root:current mean train loss 1585.7750253042745
INFO:root:current train perplexity3.494802951812744
INFO:root:current mean train loss 1585.8212838615093
INFO:root:current train perplexity3.49662184715271
INFO:root:current mean train loss 1586.0537131963185
INFO:root:current train perplexity3.4967188835144043
INFO:root:current mean train loss 1585.5721248552982
INFO:root:current train perplexity3.4979114532470703
INFO:root:current mean train loss 1585.77507211689
INFO:root:current train perplexity3.497204542160034
INFO:root:current mean train loss 1586.0620786013571
INFO:root:current train perplexity3.495347023010254
INFO:root:current mean train loss 1586.2250491014704
INFO:root:current train perplexity3.495678186416626
INFO:root:current mean train loss 1586.9999212690639
INFO:root:current train perplexity3.4970452785491943
INFO:root:current mean train loss 1587.122151649809
INFO:root:current train perplexity3.4980239868164062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.93s/it]
INFO:root:final mean train loss: 1587.2371932975705
INFO:root:final train perplexity: 3.4995839595794678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2202.4832512605276
INFO:root:eval perplexity: 5.943403720855713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2710.0350246564717
INFO:root:eval perplexity: 9.281262397766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [9:47:10<10:47:37, 370.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1558.076904296875
INFO:root:current train perplexity3.425795555114746
INFO:root:current mean train loss 1581.9368425335801
INFO:root:current train perplexity3.4698054790496826
INFO:root:current mean train loss 1580.8951039537092
INFO:root:current train perplexity3.4693782329559326
INFO:root:current mean train loss 1580.2894528139927
INFO:root:current train perplexity3.4704744815826416
INFO:root:current mean train loss 1581.532708062066
INFO:root:current train perplexity3.4749608039855957
INFO:root:current mean train loss 1582.1932527415947
INFO:root:current train perplexity3.475569725036621
INFO:root:current mean train loss 1581.4641578500357
INFO:root:current train perplexity3.4788737297058105
INFO:root:current mean train loss 1581.5563178396358
INFO:root:current train perplexity3.4791321754455566
INFO:root:current mean train loss 1582.6634539479999
INFO:root:current train perplexity3.4799585342407227
INFO:root:current mean train loss 1582.9777758575374
INFO:root:current train perplexity3.479285717010498
INFO:root:current mean train loss 1583.1454092172476
INFO:root:current train perplexity3.4797468185424805
INFO:root:current mean train loss 1583.6482826657527
INFO:root:current train perplexity3.4786908626556396
INFO:root:current mean train loss 1583.6524649153432
INFO:root:current train perplexity3.480710983276367
INFO:root:current mean train loss 1582.8366255157796
INFO:root:current train perplexity3.480724811553955
INFO:root:current mean train loss 1583.114530528283
INFO:root:current train perplexity3.482027530670166
INFO:root:current mean train loss 1583.1829116397994
INFO:root:current train perplexity3.4830031394958496
INFO:root:current mean train loss 1582.999220534919
INFO:root:current train perplexity3.4828262329101562
INFO:root:current mean train loss 1583.275130887293
INFO:root:current train perplexity3.485161542892456
INFO:root:current mean train loss 1583.7184626569822
INFO:root:current train perplexity3.486642599105835
INFO:root:current mean train loss 1584.3943922786254
INFO:root:current train perplexity3.4890575408935547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.54s/it]
INFO:root:final mean train loss: 1583.982045199134
INFO:root:final train perplexity: 3.490605115890503
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2205.3271016871677
INFO:root:eval perplexity: 5.957096576690674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2714.279407690603
INFO:root:eval perplexity: 9.313703536987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [9:53:21<10:41:34, 370.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1558.3891995337701
INFO:root:current train perplexity3.4407103061676025
INFO:root:current mean train loss 1578.1035473073712
INFO:root:current train perplexity3.4347047805786133
INFO:root:current mean train loss 1574.7636449244114
INFO:root:current train perplexity3.4450838565826416
INFO:root:current mean train loss 1575.0259522959545
INFO:root:current train perplexity3.448481559753418
INFO:root:current mean train loss 1576.0871689657047
INFO:root:current train perplexity3.455014705657959
INFO:root:current mean train loss 1573.5745840413872
INFO:root:current train perplexity3.4570016860961914
INFO:root:current mean train loss 1574.842011030049
INFO:root:current train perplexity3.458345413208008
INFO:root:current mean train loss 1575.242211212701
INFO:root:current train perplexity3.4598591327667236
INFO:root:current mean train loss 1575.9414303408919
INFO:root:current train perplexity3.4601857662200928
INFO:root:current mean train loss 1576.5427408679343
INFO:root:current train perplexity3.46608567237854
INFO:root:current mean train loss 1576.953537860504
INFO:root:current train perplexity3.470681667327881
INFO:root:current mean train loss 1576.7086125516344
INFO:root:current train perplexity3.4703660011291504
INFO:root:current mean train loss 1577.3841999961921
INFO:root:current train perplexity3.4732110500335693
INFO:root:current mean train loss 1577.3200643239927
INFO:root:current train perplexity3.472231149673462
INFO:root:current mean train loss 1577.331359735325
INFO:root:current train perplexity3.475651264190674
INFO:root:current mean train loss 1578.385820883384
INFO:root:current train perplexity3.476222276687622
INFO:root:current mean train loss 1578.8407434478704
INFO:root:current train perplexity3.477665662765503
INFO:root:current mean train loss 1579.3977612121334
INFO:root:current train perplexity3.4787120819091797
INFO:root:current mean train loss 1579.810549808421
INFO:root:current train perplexity3.4794697761535645
INFO:root:current mean train loss 1580.8351872511814
INFO:root:current train perplexity3.479848861694336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.22s/it]
INFO:root:final mean train loss: 1580.6557399578546
INFO:root:final train perplexity: 3.4814534187316895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2206.392408438608
INFO:root:eval perplexity: 5.9622344970703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2716.1939030640515
INFO:root:eval perplexity: 9.328374862670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:59:30<10:35:17, 370.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1583.5722885131836
INFO:root:current train perplexity3.455094575881958
INFO:root:current mean train loss 1567.568733009132
INFO:root:current train perplexity3.4435060024261475
INFO:root:current mean train loss 1566.5527885190902
INFO:root:current train perplexity3.4467480182647705
INFO:root:current mean train loss 1568.5258098032282
INFO:root:current train perplexity3.449904203414917
INFO:root:current mean train loss 1569.8473145621163
INFO:root:current train perplexity3.45176362991333
INFO:root:current mean train loss 1570.9733871125827
INFO:root:current train perplexity3.453922986984253
INFO:root:current mean train loss 1572.1005126576365
INFO:root:current train perplexity3.458857774734497
INFO:root:current mean train loss 1572.3874702657608
INFO:root:current train perplexity3.4596614837646484
INFO:root:current mean train loss 1572.6211503226803
INFO:root:current train perplexity3.457435131072998
INFO:root:current mean train loss 1573.435306211061
INFO:root:current train perplexity3.4577975273132324
INFO:root:current mean train loss 1573.608545434384
INFO:root:current train perplexity3.458009719848633
INFO:root:current mean train loss 1574.6357518638054
INFO:root:current train perplexity3.4623289108276367
INFO:root:current mean train loss 1574.6059919504019
INFO:root:current train perplexity3.463156223297119
INFO:root:current mean train loss 1574.4810595413344
INFO:root:current train perplexity3.462773561477661
INFO:root:current mean train loss 1574.6030466490688
INFO:root:current train perplexity3.464669942855835
INFO:root:current mean train loss 1575.6426024128916
INFO:root:current train perplexity3.466477870941162
INFO:root:current mean train loss 1575.9993196505945
INFO:root:current train perplexity3.4682137966156006
INFO:root:current mean train loss 1576.7978616186356
INFO:root:current train perplexity3.4699759483337402
INFO:root:current mean train loss 1577.0563715815028
INFO:root:current train perplexity3.4696693420410156
INFO:root:current mean train loss 1577.6663555168764
INFO:root:current train perplexity3.471683979034424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it]
INFO:root:final mean train loss: 1577.0039455858193
INFO:root:final train perplexity: 3.4714348316192627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 2208.534867956283
INFO:root:eval perplexity: 5.972579479217529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2718.715140268312
INFO:root:eval perplexity: 9.347733497619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [10:05:41<10:29:27, 370.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1561.391015625
INFO:root:current train perplexity3.4387643337249756
INFO:root:current mean train loss 1573.340255829782
INFO:root:current train perplexity3.4431824684143066
INFO:root:current mean train loss 1570.676680885171
INFO:root:current train perplexity3.443906307220459
INFO:root:current mean train loss 1570.3582004494863
INFO:root:current train perplexity3.4463436603546143
INFO:root:current mean train loss 1570.358230689264
INFO:root:current train perplexity3.4446234703063965
INFO:root:current mean train loss 1569.9333297324392
INFO:root:current train perplexity3.446078300476074
INFO:root:current mean train loss 1570.2587613442786
INFO:root:current train perplexity3.447141170501709
INFO:root:current mean train loss 1570.2425104677288
INFO:root:current train perplexity3.4459550380706787
INFO:root:current mean train loss 1571.0328892702312
INFO:root:current train perplexity3.4457123279571533
INFO:root:current mean train loss 1570.4445660368767
INFO:root:current train perplexity3.4452362060546875
INFO:root:current mean train loss 1570.4279635004034
INFO:root:current train perplexity3.4461896419525146
INFO:root:current mean train loss 1570.3780350975724
INFO:root:current train perplexity3.4478280544281006
INFO:root:current mean train loss 1571.7217420253828
INFO:root:current train perplexity3.450129985809326
INFO:root:current mean train loss 1572.2150839557578
INFO:root:current train perplexity3.4521331787109375
INFO:root:current mean train loss 1572.2927762705312
INFO:root:current train perplexity3.4525351524353027
INFO:root:current mean train loss 1572.881237519968
INFO:root:current train perplexity3.455977201461792
INFO:root:current mean train loss 1572.2932847398179
INFO:root:current train perplexity3.4559426307678223
INFO:root:current mean train loss 1572.9073901298025
INFO:root:current train perplexity3.4582996368408203
INFO:root:current mean train loss 1573.5558449752848
INFO:root:current train perplexity3.4601452350616455
INFO:root:current mean train loss 1573.6531246893885
INFO:root:current train perplexity3.4612951278686523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.51s/it]
INFO:root:final mean train loss: 1573.405732663184
INFO:root:final train perplexity: 3.4615910053253174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2211.6182986861427
INFO:root:eval perplexity: 5.987499713897705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2724.6014490871567
INFO:root:eval perplexity: 9.393078804016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [10:11:52<10:23:47, 370.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1555.777960056212
INFO:root:current train perplexity3.4411606788635254
INFO:root:current mean train loss 1562.150155203683
INFO:root:current train perplexity3.450061798095703
INFO:root:current mean train loss 1561.8110139454511
INFO:root:current train perplexity3.4438557624816895
INFO:root:current mean train loss 1560.6538012439669
INFO:root:current train perplexity3.4365017414093018
INFO:root:current mean train loss 1561.8391176595728
INFO:root:current train perplexity3.4333853721618652
INFO:root:current mean train loss 1561.1581209058204
INFO:root:current train perplexity3.4326064586639404
INFO:root:current mean train loss 1561.8210112719942
INFO:root:current train perplexity3.4305312633514404
INFO:root:current mean train loss 1562.5005731997283
INFO:root:current train perplexity3.435269355773926
INFO:root:current mean train loss 1563.8162574681564
INFO:root:current train perplexity3.4391496181488037
INFO:root:current mean train loss 1565.2212505767884
INFO:root:current train perplexity3.4388554096221924
INFO:root:current mean train loss 1566.4581047241436
INFO:root:current train perplexity3.443866491317749
INFO:root:current mean train loss 1567.839896213383
INFO:root:current train perplexity3.444502830505371
INFO:root:current mean train loss 1567.756170644775
INFO:root:current train perplexity3.44266939163208
INFO:root:current mean train loss 1568.0587099906159
INFO:root:current train perplexity3.443246841430664
INFO:root:current mean train loss 1568.1915562432787
INFO:root:current train perplexity3.4438252449035645
INFO:root:current mean train loss 1568.7676518918893
INFO:root:current train perplexity3.4443275928497314
INFO:root:current mean train loss 1568.7366515895558
INFO:root:current train perplexity3.4459521770477295
INFO:root:current mean train loss 1568.5804747507627
INFO:root:current train perplexity3.4476537704467773
INFO:root:current mean train loss 1569.4762135423584
INFO:root:current train perplexity3.4483985900878906
INFO:root:current mean train loss 1570.1699277259988
INFO:root:current train perplexity3.4515249729156494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.89s/it]
INFO:root:final mean train loss: 1569.6940092778361
INFO:root:final train perplexity: 3.4514665603637695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2212.203553544714
INFO:root:eval perplexity: 5.99033784866333
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2725.5929786195147
INFO:root:eval perplexity: 9.400735855102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [10:18:03<10:17:38, 370.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1558.2337227253
INFO:root:current train perplexity3.4077045917510986
INFO:root:current mean train loss 1550.1605512916144
INFO:root:current train perplexity3.4062376022338867
INFO:root:current mean train loss 1551.7021092443563
INFO:root:current train perplexity3.4014158248901367
INFO:root:current mean train loss 1553.2808828712407
INFO:root:current train perplexity3.412466049194336
INFO:root:current mean train loss 1555.8411488504353
INFO:root:current train perplexity3.417055130004883
INFO:root:current mean train loss 1559.6017025038475
INFO:root:current train perplexity3.4217803478240967
INFO:root:current mean train loss 1560.3379578597214
INFO:root:current train perplexity3.4244253635406494
INFO:root:current mean train loss 1560.693433625528
INFO:root:current train perplexity3.4241106510162354
INFO:root:current mean train loss 1560.6631312895404
INFO:root:current train perplexity3.4266557693481445
INFO:root:current mean train loss 1561.1476728193036
INFO:root:current train perplexity3.4324705600738525
INFO:root:current mean train loss 1563.591181636182
INFO:root:current train perplexity3.436110496520996
INFO:root:current mean train loss 1563.1658606700246
INFO:root:current train perplexity3.438612937927246
INFO:root:current mean train loss 1563.9035707492842
INFO:root:current train perplexity3.4397811889648438
INFO:root:current mean train loss 1564.017631263542
INFO:root:current train perplexity3.43882417678833
INFO:root:current mean train loss 1563.6191904629127
INFO:root:current train perplexity3.4401907920837402
INFO:root:current mean train loss 1563.639043124487
INFO:root:current train perplexity3.4400975704193115
INFO:root:current mean train loss 1564.8912770235938
INFO:root:current train perplexity3.4408230781555176
INFO:root:current mean train loss 1565.6451753252675
INFO:root:current train perplexity3.4399454593658447
INFO:root:current mean train loss 1565.9177570714644
INFO:root:current train perplexity3.4403769969940186

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.72s/it]
INFO:root:final mean train loss: 1565.7107225688371
INFO:root:final train perplexity: 3.4406328201293945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2215.5156920953846
INFO:root:eval perplexity: 6.006414413452148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2729.5140865677636
INFO:root:eval perplexity: 9.431092262268066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [10:24:13<10:11:23, 370.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1544.7219696044922
INFO:root:current train perplexity3.3684871196746826
INFO:root:current mean train loss 1555.5079261516703
INFO:root:current train perplexity3.4108664989471436
INFO:root:current mean train loss 1552.2762739393447
INFO:root:current train perplexity3.412350654602051
INFO:root:current mean train loss 1553.123643319818
INFO:root:current train perplexity3.4121692180633545
INFO:root:current mean train loss 1553.6422582773062
INFO:root:current train perplexity3.4156951904296875
INFO:root:current mean train loss 1552.5690636450006
INFO:root:current train perplexity3.4166932106018066
INFO:root:current mean train loss 1554.1452351359578
INFO:root:current train perplexity3.4198737144470215
INFO:root:current mean train loss 1555.9646834900925
INFO:root:current train perplexity3.420006275177002
INFO:root:current mean train loss 1556.7831108242858
INFO:root:current train perplexity3.4226186275482178
INFO:root:current mean train loss 1557.4762297384605
INFO:root:current train perplexity3.423370122909546
INFO:root:current mean train loss 1558.1210932694082
INFO:root:current train perplexity3.4250094890594482
INFO:root:current mean train loss 1557.911147797834
INFO:root:current train perplexity3.424706220626831
INFO:root:current mean train loss 1557.3449289422285
INFO:root:current train perplexity3.4254183769226074
INFO:root:current mean train loss 1558.2074084992105
INFO:root:current train perplexity3.4244425296783447
INFO:root:current mean train loss 1559.010571237338
INFO:root:current train perplexity3.425325870513916
INFO:root:current mean train loss 1560.5392204022974
INFO:root:current train perplexity3.4284286499023438
INFO:root:current mean train loss 1560.6865312935101
INFO:root:current train perplexity3.427400827407837
INFO:root:current mean train loss 1561.428116947343
INFO:root:current train perplexity3.429295539855957
INFO:root:current mean train loss 1562.4388628047993
INFO:root:current train perplexity3.431044578552246
INFO:root:current mean train loss 1562.1834697683569
INFO:root:current train perplexity3.4309165477752686

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.74s/it]
INFO:root:final mean train loss: 1562.5410173794144
INFO:root:final train perplexity: 3.4320363998413086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2219.5889490005816
INFO:root:eval perplexity: 6.026244163513184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2733.4677015805073
INFO:root:eval perplexity: 9.461795806884766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [10:30:23<10:04:39, 370.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1530.0353633996212
INFO:root:current train perplexity3.4184370040893555
INFO:root:current mean train loss 1549.8111379523027
INFO:root:current train perplexity3.416372060775757
INFO:root:current mean train loss 1553.3458990661884
INFO:root:current train perplexity3.4154465198516846
INFO:root:current mean train loss 1555.9691283079956
INFO:root:current train perplexity3.4152612686157227
INFO:root:current mean train loss 1556.297141975949
INFO:root:current train perplexity3.4094181060791016
INFO:root:current mean train loss 1557.1076053240063
INFO:root:current train perplexity3.4121720790863037
INFO:root:current mean train loss 1558.4057887169233
INFO:root:current train perplexity3.4110682010650635
INFO:root:current mean train loss 1558.5943904944363
INFO:root:current train perplexity3.4119205474853516
INFO:root:current mean train loss 1560.0655407670881
INFO:root:current train perplexity3.4111685752868652
INFO:root:current mean train loss 1560.271156760785
INFO:root:current train perplexity3.412006139755249
INFO:root:current mean train loss 1559.2332044012433
INFO:root:current train perplexity3.412755250930786
INFO:root:current mean train loss 1558.6219182902485
INFO:root:current train perplexity3.414829969406128
INFO:root:current mean train loss 1559.402611552267
INFO:root:current train perplexity3.4169132709503174
INFO:root:current mean train loss 1559.7123100355168
INFO:root:current train perplexity3.4179537296295166
INFO:root:current mean train loss 1558.8041552632153
INFO:root:current train perplexity3.419678211212158
INFO:root:current mean train loss 1558.529262634795
INFO:root:current train perplexity3.419962167739868
INFO:root:current mean train loss 1558.9478764250755
INFO:root:current train perplexity3.4208903312683105
INFO:root:current mean train loss 1559.1468129716577
INFO:root:current train perplexity3.422830820083618
INFO:root:current mean train loss 1559.047613748487
INFO:root:current train perplexity3.422192335128784
INFO:root:current mean train loss 1559.5194908335488
INFO:root:current train perplexity3.423227071762085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.59s/it]
INFO:root:final mean train loss: 1559.6220355627818
INFO:root:final train perplexity: 3.4241394996643066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2221.888455005402
INFO:root:eval perplexity: 6.037468910217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2739.1864195478724
INFO:root:eval perplexity: 9.506386756896973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [10:36:33<9:58:29, 370.20s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1539.0629272460938
INFO:root:current train perplexity3.368673324584961
INFO:root:current mean train loss 1539.340770670573
INFO:root:current train perplexity3.345902681350708
INFO:root:current mean train loss 1545.818255859375
INFO:root:current train perplexity3.3691565990448
INFO:root:current mean train loss 1546.017444893973
INFO:root:current train perplexity3.373182535171509
INFO:root:current mean train loss 1547.101356065538
INFO:root:current train perplexity3.375575542449951
INFO:root:current mean train loss 1548.9298876953126
INFO:root:current train perplexity3.380906820297241
INFO:root:current mean train loss 1550.6608280123196
INFO:root:current train perplexity3.3869965076446533
INFO:root:current mean train loss 1550.566977701823
INFO:root:current train perplexity3.3883039951324463
INFO:root:current mean train loss 1550.5323008099724
INFO:root:current train perplexity3.391800880432129
INFO:root:current mean train loss 1551.4519181743422
INFO:root:current train perplexity3.394562005996704
INFO:root:current mean train loss 1551.9054089936756
INFO:root:current train perplexity3.396719217300415
INFO:root:current mean train loss 1552.577798382303
INFO:root:current train perplexity3.399149179458618
INFO:root:current mean train loss 1553.8516330078126
INFO:root:current train perplexity3.4017531871795654
INFO:root:current mean train loss 1553.2024436668114
INFO:root:current train perplexity3.403270959854126
INFO:root:current mean train loss 1553.584989813443
INFO:root:current train perplexity3.4049928188323975
INFO:root:current mean train loss 1554.4662132213962
INFO:root:current train perplexity3.40681791305542
INFO:root:current mean train loss 1554.982559037642
INFO:root:current train perplexity3.40750789642334
INFO:root:current mean train loss 1554.7976391601562
INFO:root:current train perplexity3.4091482162475586
INFO:root:current mean train loss 1555.1994479782518
INFO:root:current train perplexity3.409627914428711
INFO:root:current mean train loss 1555.092672338241
INFO:root:current train perplexity3.4113924503326416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.76s/it]
INFO:root:final mean train loss: 1555.0921701343746
INFO:root:final train perplexity: 3.4119210243225098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2221.9537756087934
INFO:root:eval perplexity: 6.037787437438965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2736.8493427249555
INFO:root:eval perplexity: 9.488136291503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [10:42:43<9:52:23, 370.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1545.6951740321829
INFO:root:current train perplexity3.3721141815185547
INFO:root:current mean train loss 1551.0096494023671
INFO:root:current train perplexity3.3981010913848877
INFO:root:current mean train loss 1549.9521726686855
INFO:root:current train perplexity3.379739761352539
INFO:root:current mean train loss 1550.3023738185457
INFO:root:current train perplexity3.3814094066619873
INFO:root:current mean train loss 1551.352954676626
INFO:root:current train perplexity3.387059450149536
INFO:root:current mean train loss 1553.1135210847938
INFO:root:current train perplexity3.394893169403076
INFO:root:current mean train loss 1552.964058620104
INFO:root:current train perplexity3.397113561630249
INFO:root:current mean train loss 1551.0109662748532
INFO:root:current train perplexity3.393376588821411
INFO:root:current mean train loss 1550.219901712983
INFO:root:current train perplexity3.392547130584717
INFO:root:current mean train loss 1549.7773607918741
INFO:root:current train perplexity3.394965887069702
INFO:root:current mean train loss 1550.0389970602448
INFO:root:current train perplexity3.394833564758301
INFO:root:current mean train loss 1550.3347645999022
INFO:root:current train perplexity3.3952553272247314
INFO:root:current mean train loss 1551.4197335186773
INFO:root:current train perplexity3.397794485092163
INFO:root:current mean train loss 1552.5834598387778
INFO:root:current train perplexity3.399484395980835
INFO:root:current mean train loss 1552.4966649092535
INFO:root:current train perplexity3.4003031253814697
INFO:root:current mean train loss 1552.1834097486737
INFO:root:current train perplexity3.401456832885742
INFO:root:current mean train loss 1552.3658909331416
INFO:root:current train perplexity3.402021646499634
INFO:root:current mean train loss 1552.1807731451393
INFO:root:current train perplexity3.4028382301330566
INFO:root:current mean train loss 1552.5013151817548
INFO:root:current train perplexity3.4035205841064453
INFO:root:current mean train loss 1552.8478962947222
INFO:root:current train perplexity3.404122829437256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.12s/it]
INFO:root:final mean train loss: 1552.3933569311314
INFO:root:final train perplexity: 3.404661178588867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2226.0292310782356
INFO:root:eval perplexity: 6.057733535766602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2743.4171731286015
INFO:root:eval perplexity: 9.539507865905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [10:48:53<9:46:00, 370.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1534.4889439174108
INFO:root:current train perplexity3.3782756328582764
INFO:root:current mean train loss 1534.9473087476647
INFO:root:current train perplexity3.3712620735168457
INFO:root:current mean train loss 1536.0839800767496
INFO:root:current train perplexity3.370062828063965
INFO:root:current mean train loss 1535.1728502909343
INFO:root:current train perplexity3.372122287750244
INFO:root:current mean train loss 1537.379702229145
INFO:root:current train perplexity3.374199628829956
INFO:root:current mean train loss 1538.5547748722443
INFO:root:current train perplexity3.3741445541381836
INFO:root:current mean train loss 1538.8474224603665
INFO:root:current train perplexity3.3771860599517822
INFO:root:current mean train loss 1541.0165880164323
INFO:root:current train perplexity3.3799288272857666
INFO:root:current mean train loss 1541.6315661123974
INFO:root:current train perplexity3.381694793701172
INFO:root:current mean train loss 1542.6815758681878
INFO:root:current train perplexity3.3830931186676025
INFO:root:current mean train loss 1543.1921199784508
INFO:root:current train perplexity3.383009195327759
INFO:root:current mean train loss 1544.0347605524837
INFO:root:current train perplexity3.385586738586426
INFO:root:current mean train loss 1544.670842250931
INFO:root:current train perplexity3.385841131210327
INFO:root:current mean train loss 1545.0009000921525
INFO:root:current train perplexity3.3868021965026855
INFO:root:current mean train loss 1545.0665136784555
INFO:root:current train perplexity3.3864643573760986
INFO:root:current mean train loss 1546.2448440705887
INFO:root:current train perplexity3.387629270553589
INFO:root:current mean train loss 1546.4480561100106
INFO:root:current train perplexity3.3889026641845703
INFO:root:current mean train loss 1546.8022543047575
INFO:root:current train perplexity3.391249179840088
INFO:root:current mean train loss 1547.3444671306893
INFO:root:current train perplexity3.3919029235839844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.23s/it]
INFO:root:final mean train loss: 1548.4669814270912
INFO:root:final train perplexity: 3.394127607345581
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2228.08056640625
INFO:root:eval perplexity: 6.067797660827637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2743.5100759952625
INFO:root:eval perplexity: 9.54023551940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [10:55:03<9:39:47, 370.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1586.5115966796875
INFO:root:current train perplexity3.4537553787231445
INFO:root:current mean train loss 1548.8529524094988
INFO:root:current train perplexity3.374351978302002
INFO:root:current mean train loss 1543.7086485298119
INFO:root:current train perplexity3.374453067779541
INFO:root:current mean train loss 1541.5753696986608
INFO:root:current train perplexity3.373382091522217
INFO:root:current mean train loss 1542.9817804731335
INFO:root:current train perplexity3.3711187839508057
INFO:root:current mean train loss 1542.4711321984937
INFO:root:current train perplexity3.3690474033355713
INFO:root:current mean train loss 1541.941455606216
INFO:root:current train perplexity3.3702008724212646
INFO:root:current mean train loss 1542.610977238153
INFO:root:current train perplexity3.3702142238616943
INFO:root:current mean train loss 1541.7401232773
INFO:root:current train perplexity3.3728725910186768
INFO:root:current mean train loss 1542.9120062723275
INFO:root:current train perplexity3.372610330581665
INFO:root:current mean train loss 1543.154054441652
INFO:root:current train perplexity3.3732762336730957
INFO:root:current mean train loss 1542.367060107821
INFO:root:current train perplexity3.374764919281006
INFO:root:current mean train loss 1542.1394790026866
INFO:root:current train perplexity3.3756511211395264
INFO:root:current mean train loss 1542.9613037109375
INFO:root:current train perplexity3.375460147857666
INFO:root:current mean train loss 1542.8535570992817
INFO:root:current train perplexity3.377723455429077
INFO:root:current mean train loss 1543.6960378465137
INFO:root:current train perplexity3.378105640411377
INFO:root:current mean train loss 1544.5948923219376
INFO:root:current train perplexity3.3794198036193848
INFO:root:current mean train loss 1545.2606653284145
INFO:root:current train perplexity3.3811042308807373
INFO:root:current mean train loss 1545.4151033849466
INFO:root:current train perplexity3.381962537765503
INFO:root:current mean train loss 1544.9012682983462
INFO:root:current train perplexity3.3832390308380127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.46s/it]
INFO:root:final mean train loss: 1544.7629974411402
INFO:root:final train perplexity: 3.384220838546753
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2228.305612983433
INFO:root:eval perplexity: 6.0689005851745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2748.65598638007
INFO:root:eval perplexity: 9.580683708190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [11:01:13<9:33:35, 370.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1536.3955959743923
INFO:root:current train perplexity3.3917770385742188
INFO:root:current mean train loss 1531.1375360003972
INFO:root:current train perplexity3.348806858062744
INFO:root:current mean train loss 1532.8569100756165
INFO:root:current train perplexity3.3465189933776855
INFO:root:current mean train loss 1535.3263511417797
INFO:root:current train perplexity3.358482837677002
INFO:root:current mean train loss 1536.4386704732356
INFO:root:current train perplexity3.359797716140747
INFO:root:current mean train loss 1533.317355240634
INFO:root:current train perplexity3.361682415008545
INFO:root:current mean train loss 1534.6088035608186
INFO:root:current train perplexity3.367602586746216
INFO:root:current mean train loss 1537.2744093020979
INFO:root:current train perplexity3.3671743869781494
INFO:root:current mean train loss 1537.1936203786388
INFO:root:current train perplexity3.3665454387664795
INFO:root:current mean train loss 1538.0162172670719
INFO:root:current train perplexity3.3675827980041504
INFO:root:current mean train loss 1538.7096820224244
INFO:root:current train perplexity3.367734670639038
INFO:root:current mean train loss 1538.7590896524555
INFO:root:current train perplexity3.368293046951294
INFO:root:current mean train loss 1539.498606714709
INFO:root:current train perplexity3.3689863681793213
INFO:root:current mean train loss 1540.0495839791884
INFO:root:current train perplexity3.3700249195098877
INFO:root:current mean train loss 1540.665293877821
INFO:root:current train perplexity3.372479200363159
INFO:root:current mean train loss 1541.0471591069922
INFO:root:current train perplexity3.3745431900024414
INFO:root:current mean train loss 1541.121394021844
INFO:root:current train perplexity3.3751935958862305
INFO:root:current mean train loss 1541.757788839107
INFO:root:current train perplexity3.377096652984619
INFO:root:current mean train loss 1541.7919749982811
INFO:root:current train perplexity3.3768224716186523
INFO:root:current mean train loss 1542.1229873673137
INFO:root:current train perplexity3.3774001598358154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.49s/it]
INFO:root:final mean train loss: 1542.1647845492841
INFO:root:final train perplexity: 3.377288579940796
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2232.431650148216
INFO:root:eval perplexity: 6.089199542999268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2751.1550994223735
INFO:root:eval perplexity: 9.600386619567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [11:07:23<9:27:27, 370.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1506.8325823102678
INFO:root:current train perplexity3.339879274368286
INFO:root:current mean train loss 1523.9834852430556
INFO:root:current train perplexity3.346754312515259
INFO:root:current mean train loss 1525.381678544714
INFO:root:current train perplexity3.3469250202178955
INFO:root:current mean train loss 1532.0552206010962
INFO:root:current train perplexity3.3547582626342773
INFO:root:current mean train loss 1533.7899335488505
INFO:root:current train perplexity3.3524386882781982
INFO:root:current mean train loss 1534.9704443815713
INFO:root:current train perplexity3.352004051208496
INFO:root:current mean train loss 1535.5864965243602
INFO:root:current train perplexity3.3564822673797607
INFO:root:current mean train loss 1537.9924015797726
INFO:root:current train perplexity3.358847141265869
INFO:root:current mean train loss 1537.73590446061
INFO:root:current train perplexity3.360743522644043
INFO:root:current mean train loss 1538.8415922929896
INFO:root:current train perplexity3.3612749576568604
INFO:root:current mean train loss 1537.9979671459844
INFO:root:current train perplexity3.36236572265625
INFO:root:current mean train loss 1538.9659564719852
INFO:root:current train perplexity3.3642189502716064
INFO:root:current mean train loss 1539.2072723265119
INFO:root:current train perplexity3.3640360832214355
INFO:root:current mean train loss 1538.9785592411342
INFO:root:current train perplexity3.363149404525757
INFO:root:current mean train loss 1539.152284203506
INFO:root:current train perplexity3.3642678260803223
INFO:root:current mean train loss 1539.4582629275244
INFO:root:current train perplexity3.3658454418182373
INFO:root:current mean train loss 1539.4559465040854
INFO:root:current train perplexity3.3671152591705322
INFO:root:current mean train loss 1539.5437037751035
INFO:root:current train perplexity3.3679120540618896
INFO:root:current mean train loss 1540.0784885500043
INFO:root:current train perplexity3.369662284851074
INFO:root:current mean train loss 1539.9252452761627
INFO:root:current train perplexity3.368422746658325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.01s/it]
INFO:root:final mean train loss: 1539.2681260871213
INFO:root:final train perplexity: 3.3695766925811768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2233.6766387723014
INFO:root:eval perplexity: 6.095336437225342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2751.8646742367573
INFO:root:eval perplexity: 9.60599136352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [11:13:33<9:21:05, 369.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1522.497063269982
INFO:root:current train perplexity3.331514835357666
INFO:root:current mean train loss 1523.1346074154503
INFO:root:current train perplexity3.3288700580596924
INFO:root:current mean train loss 1523.2425198025173
INFO:root:current train perplexity3.333199977874756
INFO:root:current mean train loss 1527.9212844155052
INFO:root:current train perplexity3.3405168056488037
INFO:root:current mean train loss 1528.9990987862107
INFO:root:current train perplexity3.3480639457702637
INFO:root:current mean train loss 1530.071232671323
INFO:root:current train perplexity3.348628044128418
INFO:root:current mean train loss 1532.1237060921324
INFO:root:current train perplexity3.353200674057007
INFO:root:current mean train loss 1531.2306960085605
INFO:root:current train perplexity3.3510096073150635
INFO:root:current mean train loss 1532.7285478618783
INFO:root:current train perplexity3.3520591259002686
INFO:root:current mean train loss 1533.7433276777508
INFO:root:current train perplexity3.352280855178833
INFO:root:current mean train loss 1534.125689720473
INFO:root:current train perplexity3.3543970584869385
INFO:root:current mean train loss 1535.1162951787312
INFO:root:current train perplexity3.3553497791290283
INFO:root:current mean train loss 1535.4587181018182
INFO:root:current train perplexity3.355178117752075
INFO:root:current mean train loss 1535.644340018549
INFO:root:current train perplexity3.3558385372161865
INFO:root:current mean train loss 1535.6076058211734
INFO:root:current train perplexity3.3564698696136475
INFO:root:current mean train loss 1535.6372478524434
INFO:root:current train perplexity3.357361078262329
INFO:root:current mean train loss 1535.665586162133
INFO:root:current train perplexity3.3577377796173096
INFO:root:current mean train loss 1536.647037662872
INFO:root:current train perplexity3.3592591285705566
INFO:root:current mean train loss 1536.488681142325
INFO:root:current train perplexity3.3609907627105713
INFO:root:current mean train loss 1537.3531375947546
INFO:root:current train perplexity3.36350417137146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.02s/it]
INFO:root:final mean train loss: 1536.7684257842047
INFO:root:final train perplexity: 3.362935781478882
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2236.2704069529864
INFO:root:eval perplexity: 6.108143329620361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2755.6952938864415
INFO:root:eval perplexity: 9.63629150390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [11:19:44<9:15:15, 370.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1523.4209108214447
INFO:root:current train perplexity3.3314805030822754
INFO:root:current mean train loss 1531.1742275621764
INFO:root:current train perplexity3.3396944999694824
INFO:root:current mean train loss 1526.8448549859143
INFO:root:current train perplexity3.3380753993988037
INFO:root:current mean train loss 1524.3640527079099
INFO:root:current train perplexity3.3354332447052
INFO:root:current mean train loss 1523.3611883557935
INFO:root:current train perplexity3.3396434783935547
INFO:root:current mean train loss 1524.7299557972458
INFO:root:current train perplexity3.3425538539886475
INFO:root:current mean train loss 1524.3338553709477
INFO:root:current train perplexity3.3422486782073975
INFO:root:current mean train loss 1524.842024348027
INFO:root:current train perplexity3.3420379161834717
INFO:root:current mean train loss 1526.6648737267603
INFO:root:current train perplexity3.343428134918213
INFO:root:current mean train loss 1527.5215158688886
INFO:root:current train perplexity3.3455703258514404
INFO:root:current mean train loss 1527.2553017797372
INFO:root:current train perplexity3.3447751998901367
INFO:root:current mean train loss 1528.1886513663521
INFO:root:current train perplexity3.3458399772644043
INFO:root:current mean train loss 1529.0556923435654
INFO:root:current train perplexity3.346970558166504
INFO:root:current mean train loss 1529.7328624516356
INFO:root:current train perplexity3.3493871688842773
INFO:root:current mean train loss 1529.9565473729206
INFO:root:current train perplexity3.3513023853302
INFO:root:current mean train loss 1530.6235365566743
INFO:root:current train perplexity3.35152530670166
INFO:root:current mean train loss 1531.3597779271129
INFO:root:current train perplexity3.351179838180542
INFO:root:current mean train loss 1532.0257740182483
INFO:root:current train perplexity3.350926160812378
INFO:root:current mean train loss 1533.2537586422386
INFO:root:current train perplexity3.3522448539733887
INFO:root:current mean train loss 1533.1813489953656
INFO:root:current train perplexity3.3522837162017822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.97s/it]
INFO:root:final mean train loss: 1532.9399436531316
INFO:root:final train perplexity: 3.352790117263794
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2236.23404861342
INFO:root:eval perplexity: 6.107964515686035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2757.386484998338
INFO:root:eval perplexity: 9.649699211120605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [11:25:53<9:08:52, 370.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1531.6624287450036
INFO:root:current train perplexity3.319904088973999
INFO:root:current mean train loss 1522.948271064348
INFO:root:current train perplexity3.321315288543701
INFO:root:current mean train loss 1522.1966872848832
INFO:root:current train perplexity3.31697154045105
INFO:root:current mean train loss 1523.3805004376823
INFO:root:current train perplexity3.3212859630584717
INFO:root:current mean train loss 1521.4133443950136
INFO:root:current train perplexity3.3177685737609863
INFO:root:current mean train loss 1523.3716072368948
INFO:root:current train perplexity3.3225836753845215
INFO:root:current mean train loss 1525.05988598704
INFO:root:current train perplexity3.3284800052642822
INFO:root:current mean train loss 1523.9561320297591
INFO:root:current train perplexity3.3292996883392334
INFO:root:current mean train loss 1525.808573634576
INFO:root:current train perplexity3.3309338092803955
INFO:root:current mean train loss 1526.6591764686075
INFO:root:current train perplexity3.3343310356140137
INFO:root:current mean train loss 1527.3096893479153
INFO:root:current train perplexity3.3359673023223877
INFO:root:current mean train loss 1527.778382479843
INFO:root:current train perplexity3.3367350101470947
INFO:root:current mean train loss 1528.1584636872144
INFO:root:current train perplexity3.3363232612609863
INFO:root:current mean train loss 1529.2076972642158
INFO:root:current train perplexity3.336798667907715
INFO:root:current mean train loss 1528.9177213234984
INFO:root:current train perplexity3.339296817779541
INFO:root:current mean train loss 1529.2907448536512
INFO:root:current train perplexity3.3395721912384033
INFO:root:current mean train loss 1529.531176584047
INFO:root:current train perplexity3.340784788131714
INFO:root:current mean train loss 1530.2571478797768
INFO:root:current train perplexity3.3413686752319336
INFO:root:current mean train loss 1530.9563758502204
INFO:root:current train perplexity3.3446691036224365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.34s/it]
INFO:root:final mean train loss: 1530.255129723253
INFO:root:final train perplexity: 3.345693588256836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2240.4416884834886
INFO:root:eval perplexity: 6.128796577453613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2760.901042965287
INFO:root:eval perplexity: 9.677618980407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [11:32:03<9:02:41, 370.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.71337890625
INFO:root:current train perplexity3.3204243183135986
INFO:root:current mean train loss 1520.5796301388045
INFO:root:current train perplexity3.3123698234558105
INFO:root:current mean train loss 1515.7313172288716
INFO:root:current train perplexity3.323995351791382
INFO:root:current mean train loss 1520.3204929867986
INFO:root:current train perplexity3.3256287574768066
INFO:root:current mean train loss 1521.9240174400009
INFO:root:current train perplexity3.332461357116699
INFO:root:current mean train loss 1521.8872339692314
INFO:root:current train perplexity3.3351616859436035
INFO:root:current mean train loss 1522.6255210762592
INFO:root:current train perplexity3.3340208530426025
INFO:root:current mean train loss 1522.3141685257935
INFO:root:current train perplexity3.3334624767303467
INFO:root:current mean train loss 1523.0574311176838
INFO:root:current train perplexity3.331300735473633
INFO:root:current mean train loss 1523.5816801795663
INFO:root:current train perplexity3.332894802093506
INFO:root:current mean train loss 1523.0880520060912
INFO:root:current train perplexity3.3322205543518066
INFO:root:current mean train loss 1524.2694987126729
INFO:root:current train perplexity3.331376552581787
INFO:root:current mean train loss 1524.5319721732453
INFO:root:current train perplexity3.330949544906616
INFO:root:current mean train loss 1524.4671206470646
INFO:root:current train perplexity3.3305270671844482
INFO:root:current mean train loss 1525.1686619318814
INFO:root:current train perplexity3.3318989276885986
INFO:root:current mean train loss 1524.6945247688218
INFO:root:current train perplexity3.3314552307128906
INFO:root:current mean train loss 1525.750151997719
INFO:root:current train perplexity3.3325915336608887
INFO:root:current mean train loss 1525.6264512963107
INFO:root:current train perplexity3.33369779586792
INFO:root:current mean train loss 1525.7148135540158
INFO:root:current train perplexity3.33463454246521
INFO:root:current mean train loss 1526.7678050102838
INFO:root:current train perplexity3.3357772827148438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.86s/it]
INFO:root:final mean train loss: 1526.9972243008442
INFO:root:final train perplexity: 3.3371024131774902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2240.253283777981
INFO:root:eval perplexity: 6.127861976623535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2762.2249197452625
INFO:root:eval perplexity: 9.688155174255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [11:38:13<8:56:19, 369.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1530.595654296875
INFO:root:current train perplexity3.3381967544555664
INFO:root:current mean train loss 1510.9001383463542
INFO:root:current train perplexity3.2988619804382324
INFO:root:current mean train loss 1514.3934836647727
INFO:root:current train perplexity3.3075923919677734
INFO:root:current mean train loss 1515.3565437316895
INFO:root:current train perplexity3.309123992919922
INFO:root:current mean train loss 1517.8119341169086
INFO:root:current train perplexity3.3051793575286865
INFO:root:current mean train loss 1518.088124201848
INFO:root:current train perplexity3.3071885108947754
INFO:root:current mean train loss 1519.1664391302293
INFO:root:current train perplexity3.3065555095672607
INFO:root:current mean train loss 1520.527054341634
INFO:root:current train perplexity3.310781240463257
INFO:root:current mean train loss 1521.187162520246
INFO:root:current train perplexity3.317019462585449
INFO:root:current mean train loss 1521.8408402152684
INFO:root:current train perplexity3.317960023880005
INFO:root:current mean train loss 1521.6127837536383
INFO:root:current train perplexity3.320005416870117
INFO:root:current mean train loss 1520.8544453212194
INFO:root:current train perplexity3.319101572036743
INFO:root:current mean train loss 1521.6547618428215
INFO:root:current train perplexity3.3214352130889893
INFO:root:current mean train loss 1522.3362356474906
INFO:root:current train perplexity3.3204903602600098
INFO:root:current mean train loss 1521.890274176799
INFO:root:current train perplexity3.321920394897461
INFO:root:current mean train loss 1521.9621004606547
INFO:root:current train perplexity3.3230338096618652
INFO:root:current mean train loss 1522.4581262659144
INFO:root:current train perplexity3.324842691421509
INFO:root:current mean train loss 1523.0934160099473
INFO:root:current train perplexity3.3254435062408447
INFO:root:current mean train loss 1522.8822386353881
INFO:root:current train perplexity3.326780080795288
INFO:root:current mean train loss 1523.3223311742147
INFO:root:current train perplexity3.3277063369750977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.22s/it]
INFO:root:final mean train loss: 1523.7798982390357
INFO:root:final train perplexity: 3.3286402225494385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2244.848495591617
INFO:root:eval perplexity: 6.150690078735352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2769.003378577266
INFO:root:eval perplexity: 9.74229907989502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [11:44:23<8:50:09, 369.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1524.3988433013092
INFO:root:current train perplexity3.284383535385132
INFO:root:current mean train loss 1512.8339139840898
INFO:root:current train perplexity3.294618606567383
INFO:root:current mean train loss 1515.838819801556
INFO:root:current train perplexity3.302570343017578
INFO:root:current mean train loss 1515.7135219856964
INFO:root:current train perplexity3.3016464710235596
INFO:root:current mean train loss 1515.2028224779212
INFO:root:current train perplexity3.300832986831665
INFO:root:current mean train loss 1516.0310308644669
INFO:root:current train perplexity3.3066818714141846
INFO:root:current mean train loss 1518.477321558882
INFO:root:current train perplexity3.312009334564209
INFO:root:current mean train loss 1517.1310155653728
INFO:root:current train perplexity3.3151469230651855
INFO:root:current mean train loss 1518.1703261508737
INFO:root:current train perplexity3.312819719314575
INFO:root:current mean train loss 1520.1938102665172
INFO:root:current train perplexity3.3139495849609375
INFO:root:current mean train loss 1520.203019527483
INFO:root:current train perplexity3.313206195831299
INFO:root:current mean train loss 1520.286336155659
INFO:root:current train perplexity3.3146233558654785
INFO:root:current mean train loss 1520.0828916631403
INFO:root:current train perplexity3.3149514198303223
INFO:root:current mean train loss 1520.3183786396492
INFO:root:current train perplexity3.316493272781372
INFO:root:current mean train loss 1520.9123786602406
INFO:root:current train perplexity3.3192789554595947
INFO:root:current mean train loss 1521.8221410132105
INFO:root:current train perplexity3.3199377059936523
INFO:root:current mean train loss 1522.06813484616
INFO:root:current train perplexity3.320540189743042
INFO:root:current mean train loss 1521.917588905418
INFO:root:current train perplexity3.3207151889801025
INFO:root:current mean train loss 1522.152991446971
INFO:root:current train perplexity3.320497751235962
INFO:root:current mean train loss 1521.3649995613787
INFO:root:current train perplexity3.321148633956909

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.93s/it]
INFO:root:final mean train loss: 1520.6766220454429
INFO:root:final train perplexity: 3.320497751235962
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2247.6545128788507
INFO:root:eval perplexity: 6.164673805236816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2771.9508039325688
INFO:root:eval perplexity: 9.7659330368042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [11:50:33<8:43:53, 369.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1521.7484515154804
INFO:root:current train perplexity3.3191676139831543
INFO:root:current mean train loss 1514.2403952858665
INFO:root:current train perplexity3.3205790519714355
INFO:root:current mean train loss 1514.2583704670583
INFO:root:current train perplexity3.3183159828186035
INFO:root:current mean train loss 1515.9831591245145
INFO:root:current train perplexity3.309931755065918
INFO:root:current mean train loss 1516.5379912926762
INFO:root:current train perplexity3.30972957611084
INFO:root:current mean train loss 1515.92776500275
INFO:root:current train perplexity3.3088018894195557
INFO:root:current mean train loss 1515.1661873447056
INFO:root:current train perplexity3.307270050048828
INFO:root:current mean train loss 1515.7141665349905
INFO:root:current train perplexity3.308046817779541
INFO:root:current mean train loss 1514.5562421097409
INFO:root:current train perplexity3.305386543273926
INFO:root:current mean train loss 1515.0510247508435
INFO:root:current train perplexity3.308516263961792
INFO:root:current mean train loss 1514.8275222923091
INFO:root:current train perplexity3.306840419769287
INFO:root:current mean train loss 1515.3875657317956
INFO:root:current train perplexity3.306432008743286
INFO:root:current mean train loss 1516.053217983702
INFO:root:current train perplexity3.3080906867980957
INFO:root:current mean train loss 1515.8520141781873
INFO:root:current train perplexity3.30831241607666
INFO:root:current mean train loss 1517.168136575691
INFO:root:current train perplexity3.308281660079956
INFO:root:current mean train loss 1517.5262931126579
INFO:root:current train perplexity3.307685613632202
INFO:root:current mean train loss 1517.2951378966472
INFO:root:current train perplexity3.3083794116973877
INFO:root:current mean train loss 1517.1629393696105
INFO:root:current train perplexity3.3097782135009766
INFO:root:current mean train loss 1517.745995185136
INFO:root:current train perplexity3.3113749027252197
INFO:root:current mean train loss 1517.8509563965345
INFO:root:current train perplexity3.312384843826294

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.49s/it]
INFO:root:final mean train loss: 1517.5392158112018
INFO:root:final train perplexity: 3.312286615371704
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2247.017736123809
INFO:root:eval perplexity: 6.161497116088867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2771.3307953963044
INFO:root:eval perplexity: 9.760958671569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [11:56:43<8:37:52, 369.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1525.9225799130722
INFO:root:current train perplexity3.311662435531616
INFO:root:current mean train loss 1508.7068684895833
INFO:root:current train perplexity3.2826037406921387
INFO:root:current mean train loss 1509.8585241113642
INFO:root:current train perplexity3.2936487197875977
INFO:root:current mean train loss 1510.0994833563216
INFO:root:current train perplexity3.295666217803955
INFO:root:current mean train loss 1511.645790051503
INFO:root:current train perplexity3.301178216934204
INFO:root:current mean train loss 1511.2247632990368
INFO:root:current train perplexity3.2974166870117188
INFO:root:current mean train loss 1511.054013657321
INFO:root:current train perplexity3.2980668544769287
INFO:root:current mean train loss 1511.0780786101147
INFO:root:current train perplexity3.2975871562957764
INFO:root:current mean train loss 1512.7342016349294
INFO:root:current train perplexity3.299126148223877
INFO:root:current mean train loss 1512.253636714727
INFO:root:current train perplexity3.2996835708618164
INFO:root:current mean train loss 1513.2900138733878
INFO:root:current train perplexity3.3001527786254883
INFO:root:current mean train loss 1514.1462891250467
INFO:root:current train perplexity3.3027431964874268
INFO:root:current mean train loss 1514.4876828077363
INFO:root:current train perplexity3.3006391525268555
INFO:root:current mean train loss 1515.247945995595
INFO:root:current train perplexity3.3026161193847656
INFO:root:current mean train loss 1513.67770300683
INFO:root:current train perplexity3.3028931617736816
INFO:root:current mean train loss 1514.1494118091334
INFO:root:current train perplexity3.30379581451416
INFO:root:current mean train loss 1514.2760799460466
INFO:root:current train perplexity3.303812026977539
INFO:root:current mean train loss 1514.6959830251271
INFO:root:current train perplexity3.305208444595337
INFO:root:current mean train loss 1514.9291247108415
INFO:root:current train perplexity3.3047900199890137
INFO:root:current mean train loss 1515.351121411839
INFO:root:current train perplexity3.3055641651153564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.71s/it]
INFO:root:final mean train loss: 1514.8498573938043
INFO:root:final train perplexity: 3.3052632808685303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2248.177498891844
INFO:root:eval perplexity: 6.1672821044921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2775.653983474623
INFO:root:eval perplexity: 9.7957124710083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [12:02:53<8:31:55, 370.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1501.0690487948332
INFO:root:current train perplexity3.305844783782959
INFO:root:current mean train loss 1511.8909464085357
INFO:root:current train perplexity3.2984395027160645
INFO:root:current mean train loss 1509.441414727105
INFO:root:current train perplexity3.2966506481170654
INFO:root:current mean train loss 1510.4198318953368
INFO:root:current train perplexity3.295057773590088
INFO:root:current mean train loss 1509.8520140100698
INFO:root:current train perplexity3.288555145263672
INFO:root:current mean train loss 1513.831828422287
INFO:root:current train perplexity3.2915656566619873
INFO:root:current mean train loss 1514.8494720458984
INFO:root:current train perplexity3.2926504611968994
INFO:root:current mean train loss 1514.5031563231182
INFO:root:current train perplexity3.2913403511047363
INFO:root:current mean train loss 1513.516876908036
INFO:root:current train perplexity3.2902066707611084
INFO:root:current mean train loss 1514.7840125203616
INFO:root:current train perplexity3.2918195724487305
INFO:root:current mean train loss 1514.268191057093
INFO:root:current train perplexity3.292985677719116
INFO:root:current mean train loss 1514.9492713594277
INFO:root:current train perplexity3.2942955493927
INFO:root:current mean train loss 1514.3059015688689
INFO:root:current train perplexity3.295884370803833
INFO:root:current mean train loss 1514.4683953101078
INFO:root:current train perplexity3.2957940101623535
INFO:root:current mean train loss 1513.1539725847142
INFO:root:current train perplexity3.2945659160614014
INFO:root:current mean train loss 1512.3027984849753
INFO:root:current train perplexity3.295869827270508
INFO:root:current mean train loss 1513.0391259939186
INFO:root:current train perplexity3.2972817420959473
INFO:root:current mean train loss 1512.5812272108108
INFO:root:current train perplexity3.297316312789917
INFO:root:current mean train loss 1513.2288451113943
INFO:root:current train perplexity3.29848051071167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.37s/it]
INFO:root:final mean train loss: 1512.7021778624164
INFO:root:final train perplexity: 3.299665689468384
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2254.4783714781415
INFO:root:eval perplexity: 6.198808193206787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2780.3566812285294
INFO:root:eval perplexity: 9.833657264709473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [12:09:03<8:25:44, 370.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1535.501123046875
INFO:root:current train perplexity3.2492856979370117
INFO:root:current mean train loss 1501.9900553385417
INFO:root:current train perplexity3.26692795753479
INFO:root:current mean train loss 1496.6023401772104
INFO:root:current train perplexity3.2613203525543213
INFO:root:current mean train loss 1497.2549168320952
INFO:root:current train perplexity3.260136365890503
INFO:root:current mean train loss 1497.4531961323303
INFO:root:current train perplexity3.2600841522216797
INFO:root:current mean train loss 1498.2051549930384
INFO:root:current train perplexity3.2651007175445557
INFO:root:current mean train loss 1501.1707448912061
INFO:root:current train perplexity3.269350051879883
INFO:root:current mean train loss 1501.1112252742687
INFO:root:current train perplexity3.2690045833587646
INFO:root:current mean train loss 1501.7932445834142
INFO:root:current train perplexity3.26859712600708
INFO:root:current mean train loss 1502.8754140948722
INFO:root:current train perplexity3.2728278636932373
INFO:root:current mean train loss 1503.3013895366914
INFO:root:current train perplexity3.2749037742614746
INFO:root:current mean train loss 1504.299821810485
INFO:root:current train perplexity3.2776856422424316
INFO:root:current mean train loss 1505.7964981522302
INFO:root:current train perplexity3.2808661460876465
INFO:root:current mean train loss 1506.9610163546156
INFO:root:current train perplexity3.284540891647339
INFO:root:current mean train loss 1507.4898322814724
INFO:root:current train perplexity3.2855710983276367
INFO:root:current mean train loss 1507.9564285227627
INFO:root:current train perplexity3.285681962966919
INFO:root:current mean train loss 1508.358765332944
INFO:root:current train perplexity3.2873733043670654
INFO:root:current mean train loss 1508.9192421474065
INFO:root:current train perplexity3.286323308944702
INFO:root:current mean train loss 1509.5011390073148
INFO:root:current train perplexity3.287586212158203
INFO:root:current mean train loss 1509.2126179692627
INFO:root:current train perplexity3.2881267070770264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.56s/it]
INFO:root:final mean train loss: 1508.8020998617644
INFO:root:final train perplexity: 3.2895255088806152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2254.454897616772
INFO:root:eval perplexity: 6.198691368103027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2780.071888159353
INFO:root:eval perplexity: 9.831355094909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [12:15:13<8:19:36, 370.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1486.3658946644175
INFO:root:current train perplexity3.24003529548645
INFO:root:current mean train loss 1502.2325639568392
INFO:root:current train perplexity3.258673906326294
INFO:root:current mean train loss 1500.4250559763866
INFO:root:current train perplexity3.263939380645752
INFO:root:current mean train loss 1502.3326723086907
INFO:root:current train perplexity3.2663161754608154
INFO:root:current mean train loss 1504.0869733620593
INFO:root:current train perplexity3.269744396209717
INFO:root:current mean train loss 1505.1735991847013
INFO:root:current train perplexity3.269585371017456
INFO:root:current mean train loss 1504.5893988409994
INFO:root:current train perplexity3.2678229808807373
INFO:root:current mean train loss 1505.2277160813603
INFO:root:current train perplexity3.2704851627349854
INFO:root:current mean train loss 1505.0127515955273
INFO:root:current train perplexity3.2704920768737793
INFO:root:current mean train loss 1504.5616026110865
INFO:root:current train perplexity3.27490496635437
INFO:root:current mean train loss 1503.987937135939
INFO:root:current train perplexity3.276125907897949
INFO:root:current mean train loss 1503.5547487527504
INFO:root:current train perplexity3.2783992290496826
INFO:root:current mean train loss 1503.556055846269
INFO:root:current train perplexity3.279116153717041
INFO:root:current mean train loss 1502.7818535185797
INFO:root:current train perplexity3.2790942192077637
INFO:root:current mean train loss 1503.7609054629813
INFO:root:current train perplexity3.2814974784851074
INFO:root:current mean train loss 1504.2431114487517
INFO:root:current train perplexity3.28263521194458
INFO:root:current mean train loss 1505.2593806745385
INFO:root:current train perplexity3.2844021320343018
INFO:root:current mean train loss 1505.3313543339639
INFO:root:current train perplexity3.2832822799682617
INFO:root:current mean train loss 1505.8337185940288
INFO:root:current train perplexity3.283064603805542
INFO:root:current mean train loss 1506.7711088912915
INFO:root:current train perplexity3.2832303047180176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.02s/it]
INFO:root:final mean train loss: 1505.9239678010156
INFO:root:final train perplexity: 3.28206205368042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2258.0135208021666
INFO:root:eval perplexity: 6.216567516326904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2785.347492190963
INFO:root:eval perplexity: 9.874090194702148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [12:21:24<8:13:40, 370.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1475.435014773638
INFO:root:current train perplexity3.2396888732910156
INFO:root:current mean train loss 1488.8448503892198
INFO:root:current train perplexity3.2515063285827637
INFO:root:current mean train loss 1495.6855816063023
INFO:root:current train perplexity3.253319025039673
INFO:root:current mean train loss 1495.0194030581674
INFO:root:current train perplexity3.2592601776123047
INFO:root:current mean train loss 1496.8498268214337
INFO:root:current train perplexity3.2619478702545166
INFO:root:current mean train loss 1496.2450607950923
INFO:root:current train perplexity3.2657511234283447
INFO:root:current mean train loss 1496.7216831261003
INFO:root:current train perplexity3.26619029045105
INFO:root:current mean train loss 1496.4966989808863
INFO:root:current train perplexity3.2638587951660156
INFO:root:current mean train loss 1497.9805541555702
INFO:root:current train perplexity3.2618842124938965
INFO:root:current mean train loss 1498.744821176742
INFO:root:current train perplexity3.2632594108581543
INFO:root:current mean train loss 1499.1954178869782
INFO:root:current train perplexity3.263878345489502
INFO:root:current mean train loss 1498.9967347531071
INFO:root:current train perplexity3.266414165496826
INFO:root:current mean train loss 1499.8268046898645
INFO:root:current train perplexity3.265634298324585
INFO:root:current mean train loss 1500.736317458662
INFO:root:current train perplexity3.2659778594970703
INFO:root:current mean train loss 1501.1456950322217
INFO:root:current train perplexity3.2688562870025635
INFO:root:current mean train loss 1502.222669972004
INFO:root:current train perplexity3.2704520225524902
INFO:root:current mean train loss 1501.9989894752898
INFO:root:current train perplexity3.269775629043579
INFO:root:current mean train loss 1502.0190029572043
INFO:root:current train perplexity3.2702012062072754
INFO:root:current mean train loss 1502.1107698142885
INFO:root:current train perplexity3.271691083908081
INFO:root:current mean train loss 1503.0806955905107
INFO:root:current train perplexity3.2730913162231445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.73s/it]
INFO:root:final mean train loss: 1502.8262956689478
INFO:root:final train perplexity: 3.274048089981079
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2258.4945600793717
INFO:root:eval perplexity: 6.218986511230469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2785.265592534491
INFO:root:eval perplexity: 9.87342357635498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [12:27:34<8:07:34, 370.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1490.5656433105469
INFO:root:current train perplexity3.2789254188537598
INFO:root:current mean train loss 1489.03369531876
INFO:root:current train perplexity3.252411127090454
INFO:root:current mean train loss 1491.0904893875122
INFO:root:current train perplexity3.244359016418457
INFO:root:current mean train loss 1493.6319724093662
INFO:root:current train perplexity3.2467129230499268
INFO:root:current mean train loss 1493.7830652605023
INFO:root:current train perplexity3.256068706512451
INFO:root:current mean train loss 1496.886274818036
INFO:root:current train perplexity3.256284475326538
INFO:root:current mean train loss 1496.0987277147246
INFO:root:current train perplexity3.255998134613037
INFO:root:current mean train loss 1496.071114353402
INFO:root:current train perplexity3.258836507797241
INFO:root:current mean train loss 1496.3021153245018
INFO:root:current train perplexity3.2582015991210938
INFO:root:current mean train loss 1496.1678085007927
INFO:root:current train perplexity3.2604098320007324
INFO:root:current mean train loss 1496.217551838268
INFO:root:current train perplexity3.262326955795288
INFO:root:current mean train loss 1496.6927964365607
INFO:root:current train perplexity3.2628941535949707
INFO:root:current mean train loss 1496.6571439512215
INFO:root:current train perplexity3.262739419937134
INFO:root:current mean train loss 1497.286404139876
INFO:root:current train perplexity3.26544451713562
INFO:root:current mean train loss 1498.0053892030821
INFO:root:current train perplexity3.2647199630737305
INFO:root:current mean train loss 1498.5609589015303
INFO:root:current train perplexity3.2661194801330566
INFO:root:current mean train loss 1499.0444860043733
INFO:root:current train perplexity3.266249418258667
INFO:root:current mean train loss 1500.1719677345084
INFO:root:current train perplexity3.268296718597412
INFO:root:current mean train loss 1501.134122059263
INFO:root:current train perplexity3.2691917419433594
INFO:root:current mean train loss 1501.6905202417042
INFO:root:current train perplexity3.270120620727539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.78s/it]
INFO:root:final mean train loss: 1501.2724086128578
INFO:root:final train perplexity: 3.270035982131958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2260.454609323055
INFO:root:eval perplexity: 6.228858470916748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2787.5139389579176
INFO:root:eval perplexity: 9.891691207885742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [12:33:45<8:01:34, 370.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1486.2415219659674
INFO:root:current train perplexity3.2354965209960938
INFO:root:current mean train loss 1488.0420366408507
INFO:root:current train perplexity3.253390312194824
INFO:root:current mean train loss 1496.8409951458048
INFO:root:current train perplexity3.248919725418091
INFO:root:current mean train loss 1494.53810426441
INFO:root:current train perplexity3.2450222969055176
INFO:root:current mean train loss 1494.2699483020613
INFO:root:current train perplexity3.250190258026123
INFO:root:current mean train loss 1494.64904955586
INFO:root:current train perplexity3.2488701343536377
INFO:root:current mean train loss 1496.1989833157272
INFO:root:current train perplexity3.2517025470733643
INFO:root:current mean train loss 1497.2749724591688
INFO:root:current train perplexity3.2510743141174316
INFO:root:current mean train loss 1496.5048712067314
INFO:root:current train perplexity3.2515885829925537
INFO:root:current mean train loss 1496.766342994243
INFO:root:current train perplexity3.2540040016174316
INFO:root:current mean train loss 1496.716546249745
INFO:root:current train perplexity3.2531540393829346
INFO:root:current mean train loss 1496.4738727904546
INFO:root:current train perplexity3.254153251647949
INFO:root:current mean train loss 1496.8539944129577
INFO:root:current train perplexity3.25492000579834
INFO:root:current mean train loss 1496.4381778325292
INFO:root:current train perplexity3.256479024887085
INFO:root:current mean train loss 1496.197784651726
INFO:root:current train perplexity3.2571933269500732
INFO:root:current mean train loss 1496.247419062649
INFO:root:current train perplexity3.2574522495269775
INFO:root:current mean train loss 1497.242300814522
INFO:root:current train perplexity3.258326530456543
INFO:root:current mean train loss 1497.96829648779
INFO:root:current train perplexity3.2587716579437256
INFO:root:current mean train loss 1498.3132988338602
INFO:root:current train perplexity3.2604382038116455
INFO:root:current mean train loss 1498.3721614476092
INFO:root:current train perplexity3.261165142059326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.19s/it]
INFO:root:final mean train loss: 1497.852441677107
INFO:root:final train perplexity: 3.2612216472625732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2263.6915620844416
INFO:root:eval perplexity: 6.245196342468262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2792.2766433607603
INFO:root:eval perplexity: 9.930500984191895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [12:39:57<7:56:03, 370.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1497.1675740559897
INFO:root:current train perplexity3.2380990982055664
INFO:root:current mean train loss 1488.1975418893915
INFO:root:current train perplexity3.2350432872772217
INFO:root:current mean train loss 1489.2435668945313
INFO:root:current train perplexity3.231443405151367
INFO:root:current mean train loss 1490.0659351837942
INFO:root:current train perplexity3.236905574798584
INFO:root:current mean train loss 1492.2895301040337
INFO:root:current train perplexity3.237553119659424
INFO:root:current mean train loss 1491.6164192846265
INFO:root:current train perplexity3.2377560138702393
INFO:root:current mean train loss 1490.7954296167345
INFO:root:current train perplexity3.2418854236602783
INFO:root:current mean train loss 1492.0527048617978
INFO:root:current train perplexity3.242898464202881
INFO:root:current mean train loss 1492.5531470823823
INFO:root:current train perplexity3.2441372871398926
INFO:root:current mean train loss 1493.480254941998
INFO:root:current train perplexity3.2460901737213135
INFO:root:current mean train loss 1493.6553539591098
INFO:root:current train perplexity3.2458889484405518
INFO:root:current mean train loss 1494.594893665474
INFO:root:current train perplexity3.2471649646759033
INFO:root:current mean train loss 1494.2548019054325
INFO:root:current train perplexity3.248878240585327
INFO:root:current mean train loss 1493.489228041395
INFO:root:current train perplexity3.248948335647583
INFO:root:current mean train loss 1493.2953122542208
INFO:root:current train perplexity3.249560832977295
INFO:root:current mean train loss 1493.9763848454697
INFO:root:current train perplexity3.2511773109436035
INFO:root:current mean train loss 1495.0727833764793
INFO:root:current train perplexity3.2538228034973145
INFO:root:current mean train loss 1496.5529299602829
INFO:root:current train perplexity3.255727767944336
INFO:root:current mean train loss 1496.0342236069775
INFO:root:current train perplexity3.2557733058929443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.77s/it]
INFO:root:final mean train loss: 1495.9670193778466
INFO:root:final train perplexity: 3.2563729286193848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2263.997063819398
INFO:root:eval perplexity: 6.246739387512207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2794.4597618157136
INFO:root:eval perplexity: 9.94833755493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [12:46:09<7:50:07, 371.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1506.8566022600446
INFO:root:current train perplexity3.3124337196350098
INFO:root:current mean train loss 1488.5170407874562
INFO:root:current train perplexity3.2273030281066895
INFO:root:current mean train loss 1489.3409317680027
INFO:root:current train perplexity3.223464012145996
INFO:root:current mean train loss 1492.167854632151
INFO:root:current train perplexity3.244469165802002
INFO:root:current mean train loss 1490.3952918650184
INFO:root:current train perplexity3.245532512664795
INFO:root:current mean train loss 1490.1367558285565
INFO:root:current train perplexity3.241598606109619
INFO:root:current mean train loss 1491.330426839863
INFO:root:current train perplexity3.2432947158813477
INFO:root:current mean train loss 1491.7763254038853
INFO:root:current train perplexity3.2431976795196533
INFO:root:current mean train loss 1491.0023199409948
INFO:root:current train perplexity3.2426395416259766
INFO:root:current mean train loss 1491.622287939507
INFO:root:current train perplexity3.242770195007324
INFO:root:current mean train loss 1491.5435458868003
INFO:root:current train perplexity3.243140459060669
INFO:root:current mean train loss 1491.3370115423158
INFO:root:current train perplexity3.242931365966797
INFO:root:current mean train loss 1491.6241504634424
INFO:root:current train perplexity3.2434887886047363
INFO:root:current mean train loss 1490.8097082603588
INFO:root:current train perplexity3.2424156665802
INFO:root:current mean train loss 1492.694249525253
INFO:root:current train perplexity3.244878053665161
INFO:root:current mean train loss 1493.4217338131687
INFO:root:current train perplexity3.2463467121124268
INFO:root:current mean train loss 1493.8767790209824
INFO:root:current train perplexity3.2479183673858643
INFO:root:current mean train loss 1493.4723069158017
INFO:root:current train perplexity3.2480313777923584
INFO:root:current mean train loss 1493.314615592682
INFO:root:current train perplexity3.247307062149048
INFO:root:current mean train loss 1493.4924677432239
INFO:root:current train perplexity3.2482144832611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.26s/it]
INFO:root:final mean train loss: 1493.1174467224337
INFO:root:final train perplexity: 3.2490575313568115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 2268.0462083748894
INFO:root:eval perplexity: 6.267242431640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2797.039746872922
INFO:root:eval perplexity: 9.969460487365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [12:52:21<7:44:17, 371.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1471.6498311360676
INFO:root:current train perplexity3.2540993690490723
INFO:root:current mean train loss 1481.689682499055
INFO:root:current train perplexity3.244035243988037
INFO:root:current mean train loss 1484.0330080304827
INFO:root:current train perplexity3.2396435737609863
INFO:root:current mean train loss 1486.6838382673852
INFO:root:current train perplexity3.2409040927886963
INFO:root:current mean train loss 1488.0405961522515
INFO:root:current train perplexity3.2392914295196533
INFO:root:current mean train loss 1489.620006299201
INFO:root:current train perplexity3.2366437911987305
INFO:root:current mean train loss 1490.0652160644531
INFO:root:current train perplexity3.238406181335449
INFO:root:current mean train loss 1489.3289235151933
INFO:root:current train perplexity3.237157106399536
INFO:root:current mean train loss 1490.4743529384575
INFO:root:current train perplexity3.236821413040161
INFO:root:current mean train loss 1491.2806979092684
INFO:root:current train perplexity3.237590789794922
INFO:root:current mean train loss 1489.2573597431183
INFO:root:current train perplexity3.236379623413086
INFO:root:current mean train loss 1488.064947922459
INFO:root:current train perplexity3.238053560256958
INFO:root:current mean train loss 1488.014646143695
INFO:root:current train perplexity3.2368452548980713
INFO:root:current mean train loss 1489.0867651625342
INFO:root:current train perplexity3.2383391857147217
INFO:root:current mean train loss 1489.4877315049762
INFO:root:current train perplexity3.2399027347564697
INFO:root:current mean train loss 1488.7133071378773
INFO:root:current train perplexity3.2376461029052734
INFO:root:current mean train loss 1488.4357984571034
INFO:root:current train perplexity3.2391090393066406
INFO:root:current mean train loss 1489.602508898954
INFO:root:current train perplexity3.240030527114868
INFO:root:current mean train loss 1489.9300790753282
INFO:root:current train perplexity3.2411253452301025
INFO:root:current mean train loss 1490.552632417104
INFO:root:current train perplexity3.241468906402588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it]
INFO:root:final mean train loss: 1490.510588999415
INFO:root:final train perplexity: 3.242379665374756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2266.865106244459
INFO:root:eval perplexity: 6.261255741119385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2798.354439809813
INFO:root:eval perplexity: 9.980240821838379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [12:58:32<7:38:03, 371.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1464.0056301209984
INFO:root:current train perplexity3.1760027408599854
INFO:root:current mean train loss 1481.6736290032136
INFO:root:current train perplexity3.2113301753997803
INFO:root:current mean train loss 1485.4998951512255
INFO:root:current train perplexity3.2164809703826904
INFO:root:current mean train loss 1483.8528841527675
INFO:root:current train perplexity3.2173068523406982
INFO:root:current mean train loss 1480.4573274296697
INFO:root:current train perplexity3.221544027328491
INFO:root:current mean train loss 1479.9359597930627
INFO:root:current train perplexity3.2186548709869385
INFO:root:current mean train loss 1482.3973914278836
INFO:root:current train perplexity3.221895217895508
INFO:root:current mean train loss 1483.097767447653
INFO:root:current train perplexity3.223576068878174
INFO:root:current mean train loss 1482.4030843002192
INFO:root:current train perplexity3.224536657333374
INFO:root:current mean train loss 1484.0445839439012
INFO:root:current train perplexity3.224653720855713
INFO:root:current mean train loss 1484.97776455838
INFO:root:current train perplexity3.2268545627593994
INFO:root:current mean train loss 1485.0408338568484
INFO:root:current train perplexity3.227526903152466
INFO:root:current mean train loss 1485.8353220334848
INFO:root:current train perplexity3.2299225330352783
INFO:root:current mean train loss 1485.6962565650342
INFO:root:current train perplexity3.2322990894317627
INFO:root:current mean train loss 1486.6933708958622
INFO:root:current train perplexity3.232931613922119
INFO:root:current mean train loss 1487.3926936996827
INFO:root:current train perplexity3.2344696521759033
INFO:root:current mean train loss 1488.332504430535
INFO:root:current train perplexity3.2365455627441406
INFO:root:current mean train loss 1488.0625653472323
INFO:root:current train perplexity3.2356064319610596
INFO:root:current mean train loss 1487.7995283882103
INFO:root:current train perplexity3.235214948654175
INFO:root:current mean train loss 1488.8241878079116
INFO:root:current train perplexity3.236327886581421

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it]
INFO:root:final mean train loss: 1488.0944574291634
INFO:root:final train perplexity: 3.236203670501709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2271.8253745221077
INFO:root:eval perplexity: 6.286437511444092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2802.9981360469305
INFO:root:eval perplexity: 10.018418312072754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [13:04:43<7:31:44, 371.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1488.7642885405442
INFO:root:current train perplexity3.1913864612579346
INFO:root:current mean train loss 1484.7064216710344
INFO:root:current train perplexity3.1984407901763916
INFO:root:current mean train loss 1485.8487302794938
INFO:root:current train perplexity3.2107670307159424
INFO:root:current mean train loss 1487.3161436965345
INFO:root:current train perplexity3.209667682647705
INFO:root:current mean train loss 1483.9511452220934
INFO:root:current train perplexity3.2150628566741943
INFO:root:current mean train loss 1481.7635060518874
INFO:root:current train perplexity3.215074300765991
INFO:root:current mean train loss 1483.059535620785
INFO:root:current train perplexity3.218862533569336
INFO:root:current mean train loss 1484.2239162475264
INFO:root:current train perplexity3.2204103469848633
INFO:root:current mean train loss 1484.8019076260653
INFO:root:current train perplexity3.221158027648926
INFO:root:current mean train loss 1483.7691928170668
INFO:root:current train perplexity3.222064733505249
INFO:root:current mean train loss 1484.359872973033
INFO:root:current train perplexity3.2236123085021973
INFO:root:current mean train loss 1484.0150893875148
INFO:root:current train perplexity3.226660966873169
INFO:root:current mean train loss 1484.8421346546168
INFO:root:current train perplexity3.228001356124878
INFO:root:current mean train loss 1484.6010683759148
INFO:root:current train perplexity3.2288870811462402
INFO:root:current mean train loss 1484.4535637163494
INFO:root:current train perplexity3.22981595993042
INFO:root:current mean train loss 1484.8588198856457
INFO:root:current train perplexity3.22841477394104
INFO:root:current mean train loss 1484.347577839335
INFO:root:current train perplexity3.2284116744995117
INFO:root:current mean train loss 1484.9389366523126
INFO:root:current train perplexity3.228299617767334
INFO:root:current mean train loss 1485.7637183904903
INFO:root:current train perplexity3.2291502952575684
INFO:root:current mean train loss 1485.7396469661724
INFO:root:current train perplexity3.2291414737701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.57s/it]
INFO:root:final mean train loss: 1485.5620234456258
INFO:root:final train perplexity: 3.2297420501708984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2269.73417414672
INFO:root:eval perplexity: 6.275808811187744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2800.3851331345577
INFO:root:eval perplexity: 9.996917724609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [13:10:55<7:25:37, 371.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1481.722068684896
INFO:root:current train perplexity3.211961507797241
INFO:root:current mean train loss 1476.3476869419642
INFO:root:current train perplexity3.2184512615203857
INFO:root:current mean train loss 1478.9859556995739
INFO:root:current train perplexity3.21751070022583
INFO:root:current mean train loss 1480.177793294271
INFO:root:current train perplexity3.2143964767456055
INFO:root:current mean train loss 1479.054304327714
INFO:root:current train perplexity3.2150495052337646
INFO:root:current mean train loss 1479.5157954738452
INFO:root:current train perplexity3.216305732727051
INFO:root:current mean train loss 1480.6469243706597
INFO:root:current train perplexity3.2155685424804688
INFO:root:current mean train loss 1482.2695747227822
INFO:root:current train perplexity3.217364549636841
INFO:root:current mean train loss 1481.6271976841517
INFO:root:current train perplexity3.2188072204589844
INFO:root:current mean train loss 1482.5185326522435
INFO:root:current train perplexity3.2178196907043457
INFO:root:current mean train loss 1482.7178231740552
INFO:root:current train perplexity3.218567132949829
INFO:root:current mean train loss 1483.1721579953457
INFO:root:current train perplexity3.2192561626434326
INFO:root:current mean train loss 1483.0899053117341
INFO:root:current train perplexity3.219982862472534
INFO:root:current mean train loss 1483.1270006214488
INFO:root:current train perplexity3.2211172580718994
INFO:root:current mean train loss 1483.2023873642743
INFO:root:current train perplexity3.2210538387298584
INFO:root:current mean train loss 1482.9219488622273
INFO:root:current train perplexity3.2223141193389893
INFO:root:current mean train loss 1483.354219114389
INFO:root:current train perplexity3.2225029468536377
INFO:root:current mean train loss 1483.0692041015625
INFO:root:current train perplexity3.2226574420928955
INFO:root:current mean train loss 1483.45436328125
INFO:root:current train perplexity3.2237110137939453
INFO:root:current mean train loss 1483.5786178550238
INFO:root:current train perplexity3.223559856414795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.10s/it]
INFO:root:final mean train loss: 1483.2217386296707
INFO:root:final train perplexity: 3.2237820625305176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2275.6779633650544
INFO:root:eval perplexity: 6.306066513061523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2807.7743924188276
INFO:root:eval perplexity: 10.057835578918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [13:17:07<7:19:38, 371.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1470.1332278044326
INFO:root:current train perplexity3.2078664302825928
INFO:root:current mean train loss 1477.5971183776855
INFO:root:current train perplexity3.2190494537353516
INFO:root:current mean train loss 1474.9423075636773
INFO:root:current train perplexity3.2039456367492676
INFO:root:current mean train loss 1474.7750624053333
INFO:root:current train perplexity3.2026262283325195
INFO:root:current mean train loss 1476.3028924213193
INFO:root:current train perplexity3.2010726928710938
INFO:root:current mean train loss 1477.0197048702755
INFO:root:current train perplexity3.2010228633880615
INFO:root:current mean train loss 1477.5239928140807
INFO:root:current train perplexity3.2010629177093506
INFO:root:current mean train loss 1478.3682130755801
INFO:root:current train perplexity3.2026259899139404
INFO:root:current mean train loss 1479.0447844774733
INFO:root:current train perplexity3.2057290077209473
INFO:root:current mean train loss 1479.4428008294874
INFO:root:current train perplexity3.2061145305633545
INFO:root:current mean train loss 1479.5325331914992
INFO:root:current train perplexity3.2083561420440674
INFO:root:current mean train loss 1480.4817301090932
INFO:root:current train perplexity3.208359718322754
INFO:root:current mean train loss 1480.5022087923883
INFO:root:current train perplexity3.2094039916992188
INFO:root:current mean train loss 1480.308323301118
INFO:root:current train perplexity3.2107093334198
INFO:root:current mean train loss 1480.2960265622382
INFO:root:current train perplexity3.211634874343872
INFO:root:current mean train loss 1479.634129969918
INFO:root:current train perplexity3.21313214302063
INFO:root:current mean train loss 1479.993845405308
INFO:root:current train perplexity3.214724540710449
INFO:root:current mean train loss 1480.382581778935
INFO:root:current train perplexity3.215214252471924
INFO:root:current mean train loss 1480.8253779663344
INFO:root:current train perplexity3.2154834270477295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.21s/it]
INFO:root:final mean train loss: 1480.1245834958474
INFO:root:final train perplexity: 3.2159128189086914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2276.7189482560393
INFO:root:eval perplexity: 6.3113813400268555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2811.088625644116
INFO:root:eval perplexity: 10.08527660369873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [13:23:19<7:13:39, 371.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.951388888889
INFO:root:current train perplexity3.2148375511169434
INFO:root:current mean train loss 1474.6733264048164
INFO:root:current train perplexity3.1643521785736084
INFO:root:current mean train loss 1478.005229165109
INFO:root:current train perplexity3.176391363143921
INFO:root:current mean train loss 1473.3676564238217
INFO:root:current train perplexity3.182814598083496
INFO:root:current mean train loss 1476.692272382144
INFO:root:current train perplexity3.1911373138427734
INFO:root:current mean train loss 1477.0372343231982
INFO:root:current train perplexity3.1957929134368896
INFO:root:current mean train loss 1477.220058497537
INFO:root:current train perplexity3.198296070098877
INFO:root:current mean train loss 1477.6048971372531
INFO:root:current train perplexity3.1994457244873047
INFO:root:current mean train loss 1477.5516707487543
INFO:root:current train perplexity3.196309804916382
INFO:root:current mean train loss 1477.26533479764
INFO:root:current train perplexity3.1966516971588135
INFO:root:current mean train loss 1477.2544282850827
INFO:root:current train perplexity3.1967453956604004
INFO:root:current mean train loss 1476.941681431047
INFO:root:current train perplexity3.1979010105133057
INFO:root:current mean train loss 1475.968999390961
INFO:root:current train perplexity3.1971089839935303
INFO:root:current mean train loss 1475.9786287428678
INFO:root:current train perplexity3.1996161937713623
INFO:root:current mean train loss 1476.7000255056778
INFO:root:current train perplexity3.200554609298706
INFO:root:current mean train loss 1476.2481634444634
INFO:root:current train perplexity3.2026095390319824
INFO:root:current mean train loss 1476.2102165340712
INFO:root:current train perplexity3.204486131668091
INFO:root:current mean train loss 1475.8842224156808
INFO:root:current train perplexity3.2043306827545166
INFO:root:current mean train loss 1477.0814365536683
INFO:root:current train perplexity3.205479860305786
INFO:root:current mean train loss 1477.8694285677016
INFO:root:current train perplexity3.2071990966796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.98s/it]
INFO:root:final mean train loss: 1477.5353518210452
INFO:root:final train perplexity: 3.209347724914551
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2276.9594743877437
INFO:root:eval perplexity: 6.3126091957092285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2810.385293297734
INFO:root:eval perplexity: 10.079447746276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [13:29:31<7:07:31, 371.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1495.2715735802283
INFO:root:current train perplexity3.1972107887268066
INFO:root:current mean train loss 1465.6383095393105
INFO:root:current train perplexity3.1956100463867188
INFO:root:current mean train loss 1469.4660104397124
INFO:root:current train perplexity3.188183307647705
INFO:root:current mean train loss 1468.9561569120256
INFO:root:current train perplexity3.1858737468719482
INFO:root:current mean train loss 1472.1272482715303
INFO:root:current train perplexity3.194390296936035
INFO:root:current mean train loss 1471.6396695561282
INFO:root:current train perplexity3.1953272819519043
INFO:root:current mean train loss 1472.7644559720072
INFO:root:current train perplexity3.199160099029541
INFO:root:current mean train loss 1473.7397980492963
INFO:root:current train perplexity3.1978225708007812
INFO:root:current mean train loss 1474.5141003033727
INFO:root:current train perplexity3.1974737644195557
INFO:root:current mean train loss 1474.3385941771144
INFO:root:current train perplexity3.1981136798858643
INFO:root:current mean train loss 1474.8895003112436
INFO:root:current train perplexity3.1995787620544434
INFO:root:current mean train loss 1475.411203713019
INFO:root:current train perplexity3.201352834701538
INFO:root:current mean train loss 1474.326653485197
INFO:root:current train perplexity3.2017898559570312
INFO:root:current mean train loss 1474.2493464727388
INFO:root:current train perplexity3.2007720470428467
INFO:root:current mean train loss 1474.571296338781
INFO:root:current train perplexity3.201758623123169
INFO:root:current mean train loss 1474.7230007026642
INFO:root:current train perplexity3.2020246982574463
INFO:root:current mean train loss 1474.7131491047576
INFO:root:current train perplexity3.2016994953155518
INFO:root:current mean train loss 1474.9562776108053
INFO:root:current train perplexity3.2018845081329346
INFO:root:current mean train loss 1475.449670129381
INFO:root:current train perplexity3.2031359672546387
INFO:root:current mean train loss 1476.0504217573664
INFO:root:current train perplexity3.2047805786132812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.89s/it]
INFO:root:final mean train loss: 1476.1632323541608
INFO:root:final train perplexity: 3.205873966217041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2278.8778093486812
INFO:root:eval perplexity: 6.32241678237915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2812.0740733045213
INFO:root:eval perplexity: 10.093450546264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [13:35:43<7:01:21, 371.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1481.79052734375
INFO:root:current train perplexity3.181171178817749
INFO:root:current mean train loss 1462.5921647932146
INFO:root:current train perplexity3.1766552925109863
INFO:root:current mean train loss 1466.7875710318608
INFO:root:current train perplexity3.193837881088257
INFO:root:current mean train loss 1469.4509569173651
INFO:root:current train perplexity3.198235273361206
INFO:root:current mean train loss 1470.6301748994779
INFO:root:current train perplexity3.190866470336914
INFO:root:current mean train loss 1469.8322499874107
INFO:root:current train perplexity3.192256212234497
INFO:root:current mean train loss 1470.1540206505758
INFO:root:current train perplexity3.1928775310516357
INFO:root:current mean train loss 1472.2131050284424
INFO:root:current train perplexity3.1926276683807373
INFO:root:current mean train loss 1471.0230747643739
INFO:root:current train perplexity3.191190481185913
INFO:root:current mean train loss 1470.6014280025931
INFO:root:current train perplexity3.190622568130493
INFO:root:current mean train loss 1471.7026034800456
INFO:root:current train perplexity3.194392681121826
INFO:root:current mean train loss 1471.484593936256
INFO:root:current train perplexity3.1940228939056396
INFO:root:current mean train loss 1471.719862774506
INFO:root:current train perplexity3.1967906951904297
INFO:root:current mean train loss 1472.135054212671
INFO:root:current train perplexity3.197299003601074
INFO:root:current mean train loss 1472.309670641946
INFO:root:current train perplexity3.1975088119506836
INFO:root:current mean train loss 1472.607233033888
INFO:root:current train perplexity3.1981122493743896
INFO:root:current mean train loss 1472.9579480032478
INFO:root:current train perplexity3.19893741607666
INFO:root:current mean train loss 1473.3627440145626
INFO:root:current train perplexity3.1999752521514893
INFO:root:current mean train loss 1472.9607805903038
INFO:root:current train perplexity3.199613571166992
INFO:root:current mean train loss 1473.7472641925742
INFO:root:current train perplexity3.199782133102417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.08s/it]
INFO:root:final mean train loss: 1473.7796942960476
INFO:root:final train perplexity: 3.1998493671417236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2280.84749305671
INFO:root:eval perplexity: 6.3325018882751465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2816.334681301252
INFO:root:eval perplexity: 10.128866195678711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [13:41:55<6:55:12, 371.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1456.99794921875
INFO:root:current train perplexity3.1579678058624268
INFO:root:current mean train loss 1462.2429656982422
INFO:root:current train perplexity3.1728436946868896
INFO:root:current mean train loss 1467.0191096379206
INFO:root:current train perplexity3.1809608936309814
INFO:root:current mean train loss 1465.6331098768446
INFO:root:current train perplexity3.1826069355010986
INFO:root:current mean train loss 1467.3768751061482
INFO:root:current train perplexity3.1861166954040527
INFO:root:current mean train loss 1465.5401561192105
INFO:root:current train perplexity3.1852939128875732
INFO:root:current mean train loss 1467.742403527462
INFO:root:current train perplexity3.188028573989868
INFO:root:current mean train loss 1466.9450792814555
INFO:root:current train perplexity3.191072940826416
INFO:root:current mean train loss 1468.7809834325037
INFO:root:current train perplexity3.190748691558838
INFO:root:current mean train loss 1468.9873381296793
INFO:root:current train perplexity3.1890251636505127
INFO:root:current mean train loss 1469.230172211269
INFO:root:current train perplexity3.188934326171875
INFO:root:current mean train loss 1468.996323052768
INFO:root:current train perplexity3.189385175704956
INFO:root:current mean train loss 1469.265018717448
INFO:root:current train perplexity3.1904149055480957
INFO:root:current mean train loss 1468.708846507353
INFO:root:current train perplexity3.1892406940460205
INFO:root:current mean train loss 1469.0408951432737
INFO:root:current train perplexity3.1888833045959473
INFO:root:current mean train loss 1470.2594163943559
INFO:root:current train perplexity3.1923320293426514
INFO:root:current mean train loss 1470.0651664274285
INFO:root:current train perplexity3.192174196243286
INFO:root:current mean train loss 1470.6905589017001
INFO:root:current train perplexity3.1914522647857666
INFO:root:current mean train loss 1471.0500117476267
INFO:root:current train perplexity3.191987991333008
INFO:root:current mean train loss 1471.443180442343
INFO:root:current train perplexity3.1929843425750732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.16s/it]
INFO:root:final mean train loss: 1471.085674707179
INFO:root:final train perplexity: 3.1930532455444336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2282.127219342171
INFO:root:eval perplexity: 6.339061260223389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2816.5626770452404
INFO:root:eval perplexity: 10.130766868591309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [13:48:06<6:48:45, 371.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.0251512403613
INFO:root:current train perplexity3.188446283340454
INFO:root:current mean train loss 1465.7513234628796
INFO:root:current train perplexity3.180990695953369
INFO:root:current mean train loss 1464.4821627510153
INFO:root:current train perplexity3.1746511459350586
INFO:root:current mean train loss 1464.3713974687087
INFO:root:current train perplexity3.1740615367889404
INFO:root:current mean train loss 1463.707101114141
INFO:root:current train perplexity3.1803176403045654
INFO:root:current mean train loss 1462.5012903064749
INFO:root:current train perplexity3.1793265342712402
INFO:root:current mean train loss 1462.7692445560608
INFO:root:current train perplexity3.1822361946105957
INFO:root:current mean train loss 1464.1400198328909
INFO:root:current train perplexity3.1835076808929443
INFO:root:current mean train loss 1463.8294926885867
INFO:root:current train perplexity3.1828153133392334
INFO:root:current mean train loss 1464.8025572043725
INFO:root:current train perplexity3.183166265487671
INFO:root:current mean train loss 1465.9155301773228
INFO:root:current train perplexity3.183628559112549
INFO:root:current mean train loss 1466.7527805480697
INFO:root:current train perplexity3.184739112854004
INFO:root:current mean train loss 1467.4085704830352
INFO:root:current train perplexity3.1851038932800293
INFO:root:current mean train loss 1467.1876480446056
INFO:root:current train perplexity3.184826135635376
INFO:root:current mean train loss 1467.6827500019835
INFO:root:current train perplexity3.184701919555664
INFO:root:current mean train loss 1468.2141706216312
INFO:root:current train perplexity3.186288833618164
INFO:root:current mean train loss 1468.6149246497885
INFO:root:current train perplexity3.1865437030792236
INFO:root:current mean train loss 1468.7434286741172
INFO:root:current train perplexity3.1865828037261963
INFO:root:current mean train loss 1469.4011867809752
INFO:root:current train perplexity3.1871089935302734
INFO:root:current mean train loss 1469.617438741326
INFO:root:current train perplexity3.188594102859497

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.05s/it]
INFO:root:final mean train loss: 1469.2894959634925
INFO:root:final train perplexity: 3.188530206680298
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2288.2791873580177
INFO:root:eval perplexity: 6.37069845199585
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2824.6774625304743
INFO:root:eval perplexity: 10.198579788208008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [13:54:18<6:42:40, 371.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1450.43040174119
INFO:root:current train perplexity3.1615347862243652
INFO:root:current mean train loss 1456.424916690158
INFO:root:current train perplexity3.166404962539673
INFO:root:current mean train loss 1457.4115417895673
INFO:root:current train perplexity3.1698262691497803
INFO:root:current mean train loss 1457.7259719771178
INFO:root:current train perplexity3.176647186279297
INFO:root:current mean train loss 1457.799280823001
INFO:root:current train perplexity3.1755058765411377
INFO:root:current mean train loss 1460.4004185737583
INFO:root:current train perplexity3.1768336296081543
INFO:root:current mean train loss 1461.0037908636527
INFO:root:current train perplexity3.1762356758117676
INFO:root:current mean train loss 1461.1626608437796
INFO:root:current train perplexity3.174258232116699
INFO:root:current mean train loss 1462.3738299546892
INFO:root:current train perplexity3.176180362701416
INFO:root:current mean train loss 1463.7898980798855
INFO:root:current train perplexity3.176028251647949
INFO:root:current mean train loss 1464.0751753393868
INFO:root:current train perplexity3.175633430480957
INFO:root:current mean train loss 1463.7684828152808
INFO:root:current train perplexity3.1741480827331543
INFO:root:current mean train loss 1464.4813843716795
INFO:root:current train perplexity3.173532724380493
INFO:root:current mean train loss 1464.2246770653526
INFO:root:current train perplexity3.175180673599243
INFO:root:current mean train loss 1464.7733206589378
INFO:root:current train perplexity3.176050901412964
INFO:root:current mean train loss 1465.3593162622774
INFO:root:current train perplexity3.177532434463501
INFO:root:current mean train loss 1466.1595103006014
INFO:root:current train perplexity3.178581476211548
INFO:root:current mean train loss 1467.0233807515938
INFO:root:current train perplexity3.1804304122924805
INFO:root:current mean train loss 1466.5710833991593
INFO:root:current train perplexity3.1806604862213135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.34s/it]
INFO:root:final mean train loss: 1466.5590301682957
INFO:root:final train perplexity: 3.181666612625122
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2288.572702827183
INFO:root:eval perplexity: 6.372212886810303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2823.2320855323305
INFO:root:eval perplexity: 10.1864652633667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [14:00:30<6:36:40, 371.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1474.1424560546875
INFO:root:current train perplexity3.1652965545654297
INFO:root:current mean train loss 1462.8210845122467
INFO:root:current train perplexity3.1614911556243896
INFO:root:current mean train loss 1462.7190433158694
INFO:root:current train perplexity3.1635258197784424
INFO:root:current mean train loss 1463.41069791248
INFO:root:current train perplexity3.1628379821777344
INFO:root:current mean train loss 1463.2617015235326
INFO:root:current train perplexity3.164935350418091
INFO:root:current mean train loss 1463.459678814136
INFO:root:current train perplexity3.1681668758392334
INFO:root:current mean train loss 1464.4945384024013
INFO:root:current train perplexity3.170069456100464
INFO:root:current mean train loss 1461.9244230246243
INFO:root:current train perplexity3.16938853263855
INFO:root:current mean train loss 1462.8692797038764
INFO:root:current train perplexity3.1710753440856934
INFO:root:current mean train loss 1462.7954010445253
INFO:root:current train perplexity3.1707963943481445
INFO:root:current mean train loss 1463.4605152647055
INFO:root:current train perplexity3.171922206878662
INFO:root:current mean train loss 1462.7548195249212
INFO:root:current train perplexity3.170929431915283
INFO:root:current mean train loss 1463.2045900453525
INFO:root:current train perplexity3.171600103378296
INFO:root:current mean train loss 1464.010174388289
INFO:root:current train perplexity3.1719062328338623
INFO:root:current mean train loss 1463.8317266365555
INFO:root:current train perplexity3.17313551902771
INFO:root:current mean train loss 1464.3657048829418
INFO:root:current train perplexity3.174025535583496
INFO:root:current mean train loss 1463.9921973504909
INFO:root:current train perplexity3.173962354660034
INFO:root:current mean train loss 1464.2618327583923
INFO:root:current train perplexity3.174084186553955
INFO:root:current mean train loss 1464.3533590433678
INFO:root:current train perplexity3.1736457347869873
INFO:root:current mean train loss 1464.3568233408148
INFO:root:current train perplexity3.1750919818878174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.67s/it]
INFO:root:final mean train loss: 1464.2532700439083
INFO:root:final train perplexity: 3.17588210105896
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2286.488274756898
INFO:root:eval perplexity: 6.36147403717041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2824.198863360899
INFO:root:eval perplexity: 10.194568634033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [14:06:41<6:30:23, 371.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1492.2935224260602
INFO:root:current train perplexity3.128307819366455
INFO:root:current mean train loss 1463.056866645813
INFO:root:current train perplexity3.143777370452881
INFO:root:current mean train loss 1459.2291227641858
INFO:root:current train perplexity3.1503615379333496
INFO:root:current mean train loss 1460.2307326154012
INFO:root:current train perplexity3.153365135192871
INFO:root:current mean train loss 1459.398136031962
INFO:root:current train perplexity3.1497974395751953
INFO:root:current mean train loss 1459.9626776955345
INFO:root:current train perplexity3.157712459564209
INFO:root:current mean train loss 1459.016941143449
INFO:root:current train perplexity3.1597213745117188
INFO:root:current mean train loss 1460.021925370772
INFO:root:current train perplexity3.160613775253296
INFO:root:current mean train loss 1460.7881969507189
INFO:root:current train perplexity3.163222551345825
INFO:root:current mean train loss 1461.5588885340198
INFO:root:current train perplexity3.1638436317443848
INFO:root:current mean train loss 1460.6477601760093
INFO:root:current train perplexity3.1647677421569824
INFO:root:current mean train loss 1460.5753909712987
INFO:root:current train perplexity3.1653692722320557
INFO:root:current mean train loss 1460.180139498136
INFO:root:current train perplexity3.1653435230255127
INFO:root:current mean train loss 1461.1529943627047
INFO:root:current train perplexity3.1651406288146973
INFO:root:current mean train loss 1461.1490772578563
INFO:root:current train perplexity3.1663248538970947
INFO:root:current mean train loss 1461.5755364383078
INFO:root:current train perplexity3.167576789855957
INFO:root:current mean train loss 1461.72201583075
INFO:root:current train perplexity3.169394016265869
INFO:root:current mean train loss 1461.3010611357513
INFO:root:current train perplexity3.1696856021881104
INFO:root:current mean train loss 1462.3861252932893
INFO:root:current train perplexity3.1710352897644043
INFO:root:current mean train loss 1462.6553880367042
INFO:root:current train perplexity3.1714744567871094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.69s/it]
INFO:root:final mean train loss: 1462.5261052872759
INFO:root:final train perplexity: 3.171555757522583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2291.2410706865026
INFO:root:eval perplexity: 6.385987281799316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2828.160684788481
INFO:root:eval perplexity: 10.227827072143555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [14:12:53<6:24:06, 371.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.0908338758682
INFO:root:current train perplexity3.1505215167999268
INFO:root:current mean train loss 1448.153677262931
INFO:root:current train perplexity3.143749713897705
INFO:root:current mean train loss 1455.1574428013394
INFO:root:current train perplexity3.156282663345337
INFO:root:current mean train loss 1452.9577573029892
INFO:root:current train perplexity3.147893190383911
INFO:root:current mean train loss 1453.563541300913
INFO:root:current train perplexity3.152029037475586
INFO:root:current mean train loss 1455.2723359554186
INFO:root:current train perplexity3.1545941829681396
INFO:root:current mean train loss 1455.0248132040335
INFO:root:current train perplexity3.1573567390441895
INFO:root:current mean train loss 1455.477833505925
INFO:root:current train perplexity3.156851291656494
INFO:root:current mean train loss 1455.1740755882488
INFO:root:current train perplexity3.160836935043335
INFO:root:current mean train loss 1455.7696126302083
INFO:root:current train perplexity3.162518262863159
INFO:root:current mean train loss 1456.036704148288
INFO:root:current train perplexity3.161858081817627
INFO:root:current mean train loss 1457.3400919418668
INFO:root:current train perplexity3.162219285964966
INFO:root:current mean train loss 1457.6996441821975
INFO:root:current train perplexity3.161512613296509
INFO:root:current mean train loss 1457.2881853181634
INFO:root:current train perplexity3.1632726192474365
INFO:root:current mean train loss 1458.0572052741134
INFO:root:current train perplexity3.164252519607544
INFO:root:current mean train loss 1458.4055933486297
INFO:root:current train perplexity3.164945602416992
INFO:root:current mean train loss 1458.6743137348024
INFO:root:current train perplexity3.165529727935791
INFO:root:current mean train loss 1459.1014090201916
INFO:root:current train perplexity3.1670374870300293
INFO:root:current mean train loss 1460.2198627916455
INFO:root:current train perplexity3.1663832664489746
INFO:root:current mean train loss 1460.9859720813583
INFO:root:current train perplexity3.167008876800537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.33s/it]
INFO:root:final mean train loss: 1460.6293495320576
INFO:root:final train perplexity: 3.1668126583099365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2292.0788803641676
INFO:root:eval perplexity: 6.390317916870117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2829.2061274102393
INFO:root:eval perplexity: 10.236618995666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [14:19:04<6:17:44, 371.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1450.7753709362398
INFO:root:current train perplexity3.159295082092285
INFO:root:current mean train loss 1461.6242193528165
INFO:root:current train perplexity3.1746139526367188
INFO:root:current mean train loss 1458.811886387017
INFO:root:current train perplexity3.15541410446167
INFO:root:current mean train loss 1459.2656239883677
INFO:root:current train perplexity3.159668207168579
INFO:root:current mean train loss 1458.1330946885146
INFO:root:current train perplexity3.1571836471557617
INFO:root:current mean train loss 1457.7193434094195
INFO:root:current train perplexity3.1542744636535645
INFO:root:current mean train loss 1456.8793646590586
INFO:root:current train perplexity3.1526877880096436
INFO:root:current mean train loss 1456.3036886700809
INFO:root:current train perplexity3.152282238006592
INFO:root:current mean train loss 1456.323004702681
INFO:root:current train perplexity3.150747537612915
INFO:root:current mean train loss 1455.6583825505945
INFO:root:current train perplexity3.1526107788085938
INFO:root:current mean train loss 1455.7330269391477
INFO:root:current train perplexity3.154141426086426
INFO:root:current mean train loss 1456.5698860943214
INFO:root:current train perplexity3.1557254791259766
INFO:root:current mean train loss 1456.5962437359165
INFO:root:current train perplexity3.1568920612335205
INFO:root:current mean train loss 1456.9766844806868
INFO:root:current train perplexity3.1562559604644775
INFO:root:current mean train loss 1456.86746695919
INFO:root:current train perplexity3.1566545963287354
INFO:root:current mean train loss 1457.455889165783
INFO:root:current train perplexity3.1581311225891113
INFO:root:current mean train loss 1458.2765656435677
INFO:root:current train perplexity3.158452272415161
INFO:root:current mean train loss 1458.39411522717
INFO:root:current train perplexity3.1598474979400635
INFO:root:current mean train loss 1458.7625190906954
INFO:root:current train perplexity3.160370349884033
INFO:root:current mean train loss 1458.756836808542
INFO:root:current train perplexity3.16147780418396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.95s/it]
INFO:root:final mean train loss: 1458.4691579783137
INFO:root:final train perplexity: 3.1614184379577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2294.309466855746
INFO:root:eval perplexity: 6.401862621307373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 2832.7400313573526
INFO:root:eval perplexity: 10.266403198242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [14:25:16<6:11:40, 371.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1444.1639311585245
INFO:root:current train perplexity3.1554062366485596
INFO:root:current mean train loss 1447.3084089396386
INFO:root:current train perplexity3.1406047344207764
INFO:root:current mean train loss 1453.0190591572862
INFO:root:current train perplexity3.146660804748535
INFO:root:current mean train loss 1451.419450986354
INFO:root:current train perplexity3.1405646800994873
INFO:root:current mean train loss 1453.8312037712847
INFO:root:current train perplexity3.143261432647705
INFO:root:current mean train loss 1453.0544218547604
INFO:root:current train perplexity3.145289897918701
INFO:root:current mean train loss 1453.9156069860894
INFO:root:current train perplexity3.147632122039795
INFO:root:current mean train loss 1453.5831016765785
INFO:root:current train perplexity3.1481359004974365
INFO:root:current mean train loss 1455.7924794966314
INFO:root:current train perplexity3.1498148441314697
INFO:root:current mean train loss 1455.3816930441617
INFO:root:current train perplexity3.1498677730560303
INFO:root:current mean train loss 1456.4126116847196
INFO:root:current train perplexity3.152360439300537
INFO:root:current mean train loss 1457.6039061671702
INFO:root:current train perplexity3.15409517288208
INFO:root:current mean train loss 1457.5702311834198
INFO:root:current train perplexity3.1536688804626465
INFO:root:current mean train loss 1457.880911956411
INFO:root:current train perplexity3.1541929244995117
INFO:root:current mean train loss 1458.2694421114352
INFO:root:current train perplexity3.1527724266052246
INFO:root:current mean train loss 1458.3036244291532
INFO:root:current train perplexity3.153494358062744
INFO:root:current mean train loss 1458.0069102411685
INFO:root:current train perplexity3.154521942138672
INFO:root:current mean train loss 1457.8184730739927
INFO:root:current train perplexity3.154651641845703
INFO:root:current mean train loss 1457.2555186305674
INFO:root:current train perplexity3.155580997467041
INFO:root:current mean train loss 1457.1678650611696
INFO:root:current train perplexity3.157050132751465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.44s/it]
INFO:root:final mean train loss: 1456.7890048813351
INFO:root:final train perplexity: 3.157228708267212
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2296.784445904671
INFO:root:eval perplexity: 6.414696216583252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2835.1050384737923
INFO:root:eval perplexity: 10.286383628845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [14:31:28<6:05:41, 371.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1456.3009249369304
INFO:root:current train perplexity3.1289174556732178
INFO:root:current mean train loss 1456.7332034986846
INFO:root:current train perplexity3.138741970062256
INFO:root:current mean train loss 1458.5871202623523
INFO:root:current train perplexity3.141697883605957
INFO:root:current mean train loss 1454.7064810088186
INFO:root:current train perplexity3.1409084796905518
INFO:root:current mean train loss 1453.0216544366651
INFO:root:current train perplexity3.1430201530456543
INFO:root:current mean train loss 1452.508799098482
INFO:root:current train perplexity3.141094207763672
INFO:root:current mean train loss 1451.828377910044
INFO:root:current train perplexity3.142399787902832
INFO:root:current mean train loss 1452.711482369121
INFO:root:current train perplexity3.1421566009521484
INFO:root:current mean train loss 1453.286363192967
INFO:root:current train perplexity3.1429107189178467
INFO:root:current mean train loss 1454.0177312031328
INFO:root:current train perplexity3.1435225009918213
INFO:root:current mean train loss 1454.099584203567
INFO:root:current train perplexity3.145277261734009
INFO:root:current mean train loss 1454.2539911684783
INFO:root:current train perplexity3.1463770866394043
INFO:root:current mean train loss 1454.708955835413
INFO:root:current train perplexity3.146503448486328
INFO:root:current mean train loss 1454.807660559187
INFO:root:current train perplexity3.1477766036987305
INFO:root:current mean train loss 1454.337684508951
INFO:root:current train perplexity3.146714448928833
INFO:root:current mean train loss 1453.9967745443932
INFO:root:current train perplexity3.1479127407073975
INFO:root:current mean train loss 1454.281397477636
INFO:root:current train perplexity3.1502912044525146
INFO:root:current mean train loss 1454.8282043185159
INFO:root:current train perplexity3.1516642570495605
INFO:root:current mean train loss 1454.9147832041551
INFO:root:current train perplexity3.1516382694244385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.83s/it]
INFO:root:final mean train loss: 1455.0114330882325
INFO:root:final train perplexity: 3.1528027057647705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2295.1910374418217
INFO:root:eval perplexity: 6.406431674957275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 2833.1287677304963
INFO:root:eval perplexity: 10.269688606262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [14:37:40<5:59:25, 371.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1429.4851825420674
INFO:root:current train perplexity3.116135835647583
INFO:root:current mean train loss 1448.1971089861033
INFO:root:current train perplexity3.1332271099090576
INFO:root:current mean train loss 1445.8434623037706
INFO:root:current train perplexity3.1349315643310547
INFO:root:current mean train loss 1444.1154106554513
INFO:root:current train perplexity3.133859872817993
INFO:root:current mean train loss 1444.7496098479116
INFO:root:current train perplexity3.1335577964782715
INFO:root:current mean train loss 1445.720441375792
INFO:root:current train perplexity3.130913257598877
INFO:root:current mean train loss 1446.3230187570095
INFO:root:current train perplexity3.133451223373413
INFO:root:current mean train loss 1447.222941993831
INFO:root:current train perplexity3.135977268218994
INFO:root:current mean train loss 1448.5232381034748
INFO:root:current train perplexity3.137267827987671
INFO:root:current mean train loss 1448.6856423385302
INFO:root:current train perplexity3.1376571655273438
INFO:root:current mean train loss 1449.4905652783348
INFO:root:current train perplexity3.1390841007232666
INFO:root:current mean train loss 1449.6380129366016
INFO:root:current train perplexity3.1391143798828125
INFO:root:current mean train loss 1448.9282475131067
INFO:root:current train perplexity3.1409354209899902
INFO:root:current mean train loss 1449.202825077054
INFO:root:current train perplexity3.140204668045044
INFO:root:current mean train loss 1450.1190807561206
INFO:root:current train perplexity3.141395092010498
INFO:root:current mean train loss 1450.5175591649713
INFO:root:current train perplexity3.1411750316619873
INFO:root:current mean train loss 1450.3615267825141
INFO:root:current train perplexity3.141875982284546
INFO:root:current mean train loss 1451.0261200539076
INFO:root:current train perplexity3.144345998764038
INFO:root:current mean train loss 1451.8340276685526
INFO:root:current train perplexity3.1443898677825928
INFO:root:current mean train loss 1452.1945695493212
INFO:root:current train perplexity3.1444287300109863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.63s/it]
INFO:root:final mean train loss: 1451.8325687164138
INFO:root:final train perplexity: 3.1449031829833984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2298.4231753518397
INFO:root:eval perplexity: 6.423208713531494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2837.242893949468
INFO:root:eval perplexity: 10.304478645324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [14:43:52<5:53:09, 371.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.9280924479167
INFO:root:current train perplexity3.097943067550659
INFO:root:current mean train loss 1444.4513671875
INFO:root:current train perplexity3.1207711696624756
INFO:root:current mean train loss 1439.7122691278873
INFO:root:current train perplexity3.114832878112793
INFO:root:current mean train loss 1441.95927845348
INFO:root:current train perplexity3.1192550659179688
INFO:root:current mean train loss 1446.2757710301598
INFO:root:current train perplexity3.1301121711730957
INFO:root:current mean train loss 1448.5103950932341
INFO:root:current train perplexity3.1314265727996826
INFO:root:current mean train loss 1448.2322968982514
INFO:root:current train perplexity3.133185625076294
INFO:root:current mean train loss 1447.377193921233
INFO:root:current train perplexity3.1288864612579346
INFO:root:current mean train loss 1447.814594755977
INFO:root:current train perplexity3.129096269607544
INFO:root:current mean train loss 1447.2554511613744
INFO:root:current train perplexity3.132636547088623
INFO:root:current mean train loss 1447.2116412412772
INFO:root:current train perplexity3.133500814437866
INFO:root:current mean train loss 1448.48243786297
INFO:root:current train perplexity3.1331026554107666
INFO:root:current mean train loss 1448.659509376588
INFO:root:current train perplexity3.134340286254883
INFO:root:current mean train loss 1448.8599025640272
INFO:root:current train perplexity3.135329484939575
INFO:root:current mean train loss 1449.2679447627568
INFO:root:current train perplexity3.1353225708007812
INFO:root:current mean train loss 1449.594153550092
INFO:root:current train perplexity3.136366844177246
INFO:root:current mean train loss 1449.6047398479438
INFO:root:current train perplexity3.137528896331787
INFO:root:current mean train loss 1450.086869185784
INFO:root:current train perplexity3.1380972862243652
INFO:root:current mean train loss 1449.3185294062714
INFO:root:current train perplexity3.137948751449585
INFO:root:current mean train loss 1449.7950288920822
INFO:root:current train perplexity3.138960599899292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.80s/it]
INFO:root:final mean train loss: 1449.8060688397768
INFO:root:final train perplexity: 3.1398777961730957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2297.9078234949857
INFO:root:eval perplexity: 6.420530796051025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2836.7946985123003
INFO:root:eval perplexity: 10.300683975219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [14:50:03<5:46:58, 371.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1453.705195000831
INFO:root:current train perplexity3.128283977508545
INFO:root:current mean train loss 1450.8703148251489
INFO:root:current train perplexity3.1145436763763428
INFO:root:current mean train loss 1447.4964826946798
INFO:root:current train perplexity3.1186740398406982
INFO:root:current mean train loss 1447.035777155192
INFO:root:current train perplexity3.1266419887542725
INFO:root:current mean train loss 1447.4343338183376
INFO:root:current train perplexity3.1311957836151123
INFO:root:current mean train loss 1446.6382695116117
INFO:root:current train perplexity3.12961483001709
INFO:root:current mean train loss 1449.9400414020238
INFO:root:current train perplexity3.1344199180603027
INFO:root:current mean train loss 1449.7068581944968
INFO:root:current train perplexity3.1315343379974365
INFO:root:current mean train loss 1449.3495933775919
INFO:root:current train perplexity3.131749153137207
INFO:root:current mean train loss 1448.8990152393249
INFO:root:current train perplexity3.1297245025634766
INFO:root:current mean train loss 1448.8838909626463
INFO:root:current train perplexity3.1303699016571045
INFO:root:current mean train loss 1448.8253000354184
INFO:root:current train perplexity3.130713701248169
INFO:root:current mean train loss 1448.0772625786262
INFO:root:current train perplexity3.1307618618011475
INFO:root:current mean train loss 1448.4609094972334
INFO:root:current train perplexity3.1316561698913574
INFO:root:current mean train loss 1448.5021938068255
INFO:root:current train perplexity3.134267568588257
INFO:root:current mean train loss 1449.209395089917
INFO:root:current train perplexity3.1363160610198975
INFO:root:current mean train loss 1449.1178159360531
INFO:root:current train perplexity3.135741949081421
INFO:root:current mean train loss 1449.5973462878328
INFO:root:current train perplexity3.136037826538086
INFO:root:current mean train loss 1449.431167809074
INFO:root:current train perplexity3.136533260345459
INFO:root:current mean train loss 1448.957475204742
INFO:root:current train perplexity3.136889934539795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.65s/it]
INFO:root:final mean train loss: 1448.4812415541871
INFO:root:final train perplexity: 3.136596202850342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2300.264496066046
INFO:root:eval perplexity: 6.432785987854004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2840.4299935415283
INFO:root:eval perplexity: 10.331514358520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [14:56:16<5:41:00, 372.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.0411014556885
INFO:root:current train perplexity3.0967941284179688
INFO:root:current mean train loss 1446.4253807998284
INFO:root:current train perplexity3.113675832748413
INFO:root:current mean train loss 1445.8754531397965
INFO:root:current train perplexity3.1138157844543457
INFO:root:current mean train loss 1444.370329804473
INFO:root:current train perplexity3.1206777095794678
INFO:root:current mean train loss 1443.3089970555798
INFO:root:current train perplexity3.119112730026245
INFO:root:current mean train loss 1444.484328033231
INFO:root:current train perplexity3.1239962577819824
INFO:root:current mean train loss 1444.7079975174133
INFO:root:current train perplexity3.127441883087158
INFO:root:current mean train loss 1445.8239126155513
INFO:root:current train perplexity3.1269991397857666
INFO:root:current mean train loss 1446.8495148552788
INFO:root:current train perplexity3.1265006065368652
INFO:root:current mean train loss 1445.9674517999547
INFO:root:current train perplexity3.1257553100585938
INFO:root:current mean train loss 1445.5294664425958
INFO:root:current train perplexity3.1269898414611816
INFO:root:current mean train loss 1445.8718101265504
INFO:root:current train perplexity3.1268603801727295
INFO:root:current mean train loss 1446.240636028821
INFO:root:current train perplexity3.1284055709838867
INFO:root:current mean train loss 1446.3819659728108
INFO:root:current train perplexity3.1293282508850098
INFO:root:current mean train loss 1446.9657935470832
INFO:root:current train perplexity3.129916191101074
INFO:root:current mean train loss 1446.5223581455552
INFO:root:current train perplexity3.1291797161102295
INFO:root:current mean train loss 1446.544137587914
INFO:root:current train perplexity3.1296937465667725
INFO:root:current mean train loss 1446.3248091717155
INFO:root:current train perplexity3.130099296569824
INFO:root:current mean train loss 1446.2503614957752
INFO:root:current train perplexity3.130680799484253
INFO:root:current mean train loss 1446.7655475562071
INFO:root:current train perplexity3.1309690475463867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.95s/it]
INFO:root:final mean train loss: 1446.3897145820038
INFO:root:final train perplexity: 3.131423234939575
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 2301.8814234091037
INFO:root:eval perplexity: 6.441209316253662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2841.882470097102
INFO:root:eval perplexity: 10.343859672546387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [15:02:28<5:34:47, 371.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.3330876856674
INFO:root:current train perplexity3.141176462173462
INFO:root:current mean train loss 1439.3279186269856
INFO:root:current train perplexity3.127936601638794
INFO:root:current mean train loss 1439.138852591192
INFO:root:current train perplexity3.127342462539673
INFO:root:current mean train loss 1437.5346644444103
INFO:root:current train perplexity3.1287083625793457
INFO:root:current mean train loss 1438.4496395245908
INFO:root:current train perplexity3.126568078994751
INFO:root:current mean train loss 1436.8259548377662
INFO:root:current train perplexity3.126277208328247
INFO:root:current mean train loss 1438.536034941148
INFO:root:current train perplexity3.1241910457611084
INFO:root:current mean train loss 1439.5154046169773
INFO:root:current train perplexity3.1235177516937256
INFO:root:current mean train loss 1440.6024523246842
INFO:root:current train perplexity3.126504898071289
INFO:root:current mean train loss 1441.0071125555476
INFO:root:current train perplexity3.1259536743164062
INFO:root:current mean train loss 1440.8662574619855
INFO:root:current train perplexity3.1243526935577393
INFO:root:current mean train loss 1441.106064837631
INFO:root:current train perplexity3.1250250339508057
INFO:root:current mean train loss 1441.8920761215602
INFO:root:current train perplexity3.123467206954956
INFO:root:current mean train loss 1442.7285317124706
INFO:root:current train perplexity3.1240763664245605
INFO:root:current mean train loss 1443.444137459909
INFO:root:current train perplexity3.124626874923706
INFO:root:current mean train loss 1443.2618022149006
INFO:root:current train perplexity3.124289035797119
INFO:root:current mean train loss 1444.1973681611578
INFO:root:current train perplexity3.1253931522369385
INFO:root:current mean train loss 1444.2539052904356
INFO:root:current train perplexity3.126060962677002
INFO:root:current mean train loss 1444.304473341557
INFO:root:current train perplexity3.1265196800231934
INFO:root:current mean train loss 1444.9182212093995
INFO:root:current train perplexity3.1265876293182373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it]
INFO:root:final mean train loss: 1444.4516814862366
INFO:root:final train perplexity: 3.1266374588012695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2303.5401888367132
INFO:root:eval perplexity: 6.449862003326416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2844.6808843950853
INFO:root:eval perplexity: 10.36768627166748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [15:08:40<5:28:29, 371.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1441.8476550043845
INFO:root:current train perplexity3.08325457572937
INFO:root:current mean train loss 1443.406813496291
INFO:root:current train perplexity3.1044116020202637
INFO:root:current mean train loss 1445.7545415891097
INFO:root:current train perplexity3.1080448627471924
INFO:root:current mean train loss 1445.1184312063247
INFO:root:current train perplexity3.1076555252075195
INFO:root:current mean train loss 1444.416051167561
INFO:root:current train perplexity3.1083157062530518
INFO:root:current mean train loss 1441.378188117292
INFO:root:current train perplexity3.1080260276794434
INFO:root:current mean train loss 1442.9117094110964
INFO:root:current train perplexity3.110015392303467
INFO:root:current mean train loss 1442.6470376686345
INFO:root:current train perplexity3.1119072437286377
INFO:root:current mean train loss 1441.7947215056897
INFO:root:current train perplexity3.1116650104522705
INFO:root:current mean train loss 1441.742907323436
INFO:root:current train perplexity3.1136314868927
INFO:root:current mean train loss 1441.5236371705657
INFO:root:current train perplexity3.1137678623199463
INFO:root:current mean train loss 1442.2007603207494
INFO:root:current train perplexity3.1151087284088135
INFO:root:current mean train loss 1441.5902860432818
INFO:root:current train perplexity3.11398983001709
INFO:root:current mean train loss 1441.1489309330013
INFO:root:current train perplexity3.115842580795288
INFO:root:current mean train loss 1441.9180679219428
INFO:root:current train perplexity3.1174566745758057
INFO:root:current mean train loss 1442.085147098546
INFO:root:current train perplexity3.117938756942749
INFO:root:current mean train loss 1442.1933576496247
INFO:root:current train perplexity3.119011163711548
INFO:root:current mean train loss 1441.6642548388184
INFO:root:current train perplexity3.1193320751190186
INFO:root:current mean train loss 1441.7688775499703
INFO:root:current train perplexity3.1203131675720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it]
INFO:root:final mean train loss: 1442.0331146963545
INFO:root:final train perplexity: 3.120675563812256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 2304.989427498892
INFO:root:eval perplexity: 6.457428932189941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2846.0769618690438
INFO:root:eval perplexity: 10.379591941833496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [15:14:50<5:21:50, 371.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1450.3770345052083
INFO:root:current train perplexity3.130305767059326
INFO:root:current mean train loss 1439.2937468155571
INFO:root:current train perplexity3.1077046394348145
INFO:root:current mean train loss 1437.4896206168241
INFO:root:current train perplexity3.1173737049102783
INFO:root:current mean train loss 1438.1347586495535
INFO:root:current train perplexity3.113218069076538
INFO:root:current mean train loss 1438.5024787627071
INFO:root:current train perplexity3.1182267665863037
INFO:root:current mean train loss 1438.0349187462075
INFO:root:current train perplexity3.117079019546509
INFO:root:current mean train loss 1437.6382506827997
INFO:root:current train perplexity3.1187446117401123
INFO:root:current mean train loss 1439.016787997159
INFO:root:current train perplexity3.1197726726531982
INFO:root:current mean train loss 1440.0338621549079
INFO:root:current train perplexity3.120814561843872
INFO:root:current mean train loss 1440.2360363569417
INFO:root:current train perplexity3.121985912322998
INFO:root:current mean train loss 1439.6771175290564
INFO:root:current train perplexity3.122701406478882
INFO:root:current mean train loss 1439.5265344730942
INFO:root:current train perplexity3.122558355331421
INFO:root:current mean train loss 1440.9320900245948
INFO:root:current train perplexity3.122323513031006
INFO:root:current mean train loss 1441.0989905759861
INFO:root:current train perplexity3.122191905975342
INFO:root:current mean train loss 1441.1686501870306
INFO:root:current train perplexity3.121884822845459
INFO:root:current mean train loss 1441.5397116078796
INFO:root:current train perplexity3.1213340759277344
INFO:root:current mean train loss 1441.660455114406
INFO:root:current train perplexity3.121574878692627
INFO:root:current mean train loss 1442.2652328802615
INFO:root:current train perplexity3.1209638118743896
INFO:root:current mean train loss 1442.3139172262397
INFO:root:current train perplexity3.120857000350952
INFO:root:current mean train loss 1441.953854999592
INFO:root:current train perplexity3.1201908588409424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.32s/it]
INFO:root:final mean train loss: 1441.709356156973
INFO:root:final train perplexity: 3.119878053665161
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2308.772849657857
INFO:root:eval perplexity: 6.477230072021484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2851.159094844304
INFO:root:eval perplexity: 10.423049926757812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [15:21:00<5:15:19, 370.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.1860809326172
INFO:root:current train perplexity3.101264238357544
INFO:root:current mean train loss 1440.6011463512075
INFO:root:current train perplexity3.1155507564544678
INFO:root:current mean train loss 1441.5686777049098
INFO:root:current train perplexity3.1136720180511475
INFO:root:current mean train loss 1435.137528017343
INFO:root:current train perplexity3.1098079681396484
INFO:root:current mean train loss 1434.9528548629196
INFO:root:current train perplexity3.10686993598938
INFO:root:current mean train loss 1437.5144742807947
INFO:root:current train perplexity3.1042890548706055
INFO:root:current mean train loss 1438.2666131514536
INFO:root:current train perplexity3.1063923835754395
INFO:root:current mean train loss 1437.4302223080495
INFO:root:current train perplexity3.1071605682373047
INFO:root:current mean train loss 1438.544174194336
INFO:root:current train perplexity3.1108386516571045
INFO:root:current mean train loss 1438.0202158653685
INFO:root:current train perplexity3.1096484661102295
INFO:root:current mean train loss 1438.729799019274
INFO:root:current train perplexity3.1098456382751465
INFO:root:current mean train loss 1439.4282111178018
INFO:root:current train perplexity3.1126983165740967
INFO:root:current mean train loss 1439.4789820088968
INFO:root:current train perplexity3.114828109741211
INFO:root:current mean train loss 1439.2129522100224
INFO:root:current train perplexity3.1142044067382812
INFO:root:current mean train loss 1438.9967527762471
INFO:root:current train perplexity3.113487958908081
INFO:root:current mean train loss 1439.696592405633
INFO:root:current train perplexity3.1139581203460693
INFO:root:current mean train loss 1439.5433152890673
INFO:root:current train perplexity3.114161729812622
INFO:root:current mean train loss 1439.3390189296379
INFO:root:current train perplexity3.114712715148926
INFO:root:current mean train loss 1439.4152964629461
INFO:root:current train perplexity3.113875389099121
INFO:root:current mean train loss 1438.8902268182665
INFO:root:current train perplexity3.1136600971221924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.23s/it]
INFO:root:final mean train loss: 1439.1386571009834
INFO:root:final train perplexity: 3.1135547161102295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2307.703694228585
INFO:root:eval perplexity: 6.471628665924072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2849.290213943373
INFO:root:eval perplexity: 10.407048225402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [15:27:11<5:09:07, 370.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1438.1149204799108
INFO:root:current train perplexity3.0872035026550293
INFO:root:current mean train loss 1433.8922127333262
INFO:root:current train perplexity3.114345073699951
INFO:root:current mean train loss 1431.1564348213165
INFO:root:current train perplexity3.1129605770111084
INFO:root:current mean train loss 1433.6732761853061
INFO:root:current train perplexity3.1068623065948486
INFO:root:current mean train loss 1434.1859837725326
INFO:root:current train perplexity3.1139678955078125
INFO:root:current mean train loss 1433.1636329192281
INFO:root:current train perplexity3.1147189140319824
INFO:root:current mean train loss 1433.4980310754527
INFO:root:current train perplexity3.1079084873199463
INFO:root:current mean train loss 1433.999346296364
INFO:root:current train perplexity3.1076722145080566
INFO:root:current mean train loss 1434.2957983657243
INFO:root:current train perplexity3.1078062057495117
INFO:root:current mean train loss 1434.9227092972044
INFO:root:current train perplexity3.107806921005249
INFO:root:current mean train loss 1435.1823253358855
INFO:root:current train perplexity3.107179880142212
INFO:root:current mean train loss 1436.0413439080858
INFO:root:current train perplexity3.1081430912017822
INFO:root:current mean train loss 1436.2333335418334
INFO:root:current train perplexity3.1079907417297363
INFO:root:current mean train loss 1436.5677234149139
INFO:root:current train perplexity3.1083157062530518
INFO:root:current mean train loss 1436.9000406732553
INFO:root:current train perplexity3.109229564666748
INFO:root:current mean train loss 1437.2333006393994
INFO:root:current train perplexity3.111237049102783
INFO:root:current mean train loss 1437.2665367149598
INFO:root:current train perplexity3.112483024597168
INFO:root:current mean train loss 1438.20976488518
INFO:root:current train perplexity3.1125717163085938
INFO:root:current mean train loss 1438.444472532133
INFO:root:current train perplexity3.111215829849243
INFO:root:current mean train loss 1438.9452253784993
INFO:root:current train perplexity3.1109821796417236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it]
INFO:root:final mean train loss: 1438.2457010381702
INFO:root:final train perplexity: 3.111361265182495
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2308.4718878996287
INFO:root:eval perplexity: 6.475652694702148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2850.5893797096633
INFO:root:eval perplexity: 10.418169975280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [15:33:21<5:02:45, 370.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1427.7229947176847
INFO:root:current train perplexity3.103703260421753
INFO:root:current mean train loss 1429.3176151873117
INFO:root:current train perplexity3.104732036590576
INFO:root:current mean train loss 1428.490181600241
INFO:root:current train perplexity3.1032772064208984
INFO:root:current mean train loss 1426.5923998890028
INFO:root:current train perplexity3.100355863571167
INFO:root:current mean train loss 1429.6846174641228
INFO:root:current train perplexity3.096919536590576
INFO:root:current mean train loss 1429.9459737501381
INFO:root:current train perplexity3.095824718475342
INFO:root:current mean train loss 1430.8568095072612
INFO:root:current train perplexity3.0948779582977295
INFO:root:current mean train loss 1430.7897670337488
INFO:root:current train perplexity3.0952823162078857
INFO:root:current mean train loss 1431.3011143356218
INFO:root:current train perplexity3.093393325805664
INFO:root:current mean train loss 1432.354579633314
INFO:root:current train perplexity3.0939977169036865
INFO:root:current mean train loss 1433.0781884399184
INFO:root:current train perplexity3.0967042446136475
INFO:root:current mean train loss 1432.9694385561281
INFO:root:current train perplexity3.097381353378296
INFO:root:current mean train loss 1433.1551800045356
INFO:root:current train perplexity3.099351167678833
INFO:root:current mean train loss 1433.988172494824
INFO:root:current train perplexity3.1003599166870117
INFO:root:current mean train loss 1433.8873565798729
INFO:root:current train perplexity3.0999953746795654
INFO:root:current mean train loss 1434.3423923380378
INFO:root:current train perplexity3.101728677749634
INFO:root:current mean train loss 1435.2083125486522
INFO:root:current train perplexity3.1025145053863525
INFO:root:current mean train loss 1435.5690104397074
INFO:root:current train perplexity3.103210926055908
INFO:root:current mean train loss 1435.8902012864876
INFO:root:current train perplexity3.1038293838500977
INFO:root:current mean train loss 1435.77624089502
INFO:root:current train perplexity3.1041066646575928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.86s/it]
INFO:root:final mean train loss: 1435.3550150953515
INFO:root:final train perplexity: 3.104271411895752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2311.916832024324
INFO:root:eval perplexity: 6.493730545043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2855.6083984375
INFO:root:eval perplexity: 10.461244583129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [15:39:32<4:56:31, 370.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1435.7430772896273
INFO:root:current train perplexity3.102318048477173
INFO:root:current mean train loss 1431.4365014248208
INFO:root:current train perplexity3.089257001876831
INFO:root:current mean train loss 1433.4282334398465
INFO:root:current train perplexity3.084066390991211
INFO:root:current mean train loss 1432.1829049929627
INFO:root:current train perplexity3.0873517990112305
INFO:root:current mean train loss 1432.247398866136
INFO:root:current train perplexity3.088989496231079
INFO:root:current mean train loss 1432.3106695734616
INFO:root:current train perplexity3.09171986579895
INFO:root:current mean train loss 1432.6468010786512
INFO:root:current train perplexity3.093970537185669
INFO:root:current mean train loss 1432.8933329965876
INFO:root:current train perplexity3.094550609588623
INFO:root:current mean train loss 1432.7653446391917
INFO:root:current train perplexity3.095186710357666
INFO:root:current mean train loss 1433.9690919955651
INFO:root:current train perplexity3.095951795578003
INFO:root:current mean train loss 1434.3028155297784
INFO:root:current train perplexity3.096613883972168
INFO:root:current mean train loss 1434.7507491381816
INFO:root:current train perplexity3.098250389099121
INFO:root:current mean train loss 1434.1637433855587
INFO:root:current train perplexity3.0983834266662598
INFO:root:current mean train loss 1434.2641736607748
INFO:root:current train perplexity3.098705530166626
INFO:root:current mean train loss 1433.5911862764983
INFO:root:current train perplexity3.0979342460632324
INFO:root:current mean train loss 1434.1664953466766
INFO:root:current train perplexity3.09932804107666
INFO:root:current mean train loss 1433.9198258434528
INFO:root:current train perplexity3.099769115447998
INFO:root:current mean train loss 1434.5311531242332
INFO:root:current train perplexity3.100799798965454
INFO:root:current mean train loss 1434.7076143739835
INFO:root:current train perplexity3.1015892028808594
INFO:root:current mean train loss 1434.3885999132274
INFO:root:current train perplexity3.10190486907959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.51s/it]
INFO:root:final mean train loss: 1434.3885999132274
INFO:root:final train perplexity: 3.10190486907959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2312.0878256939827
INFO:root:eval perplexity: 6.49462890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2854.665835549645
INFO:root:eval perplexity: 10.453145027160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [15:45:42<4:50:16, 370.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1428.0055041503906
INFO:root:current train perplexity3.072675943374634
INFO:root:current mean train loss 1421.3116143798827
INFO:root:current train perplexity3.0695252418518066
INFO:root:current mean train loss 1424.0192834472657
INFO:root:current train perplexity3.0806684494018555
INFO:root:current mean train loss 1427.3715060424804
INFO:root:current train perplexity3.0782039165496826
INFO:root:current mean train loss 1430.3657314453126
INFO:root:current train perplexity3.0828914642333984
INFO:root:current mean train loss 1430.9967435709636
INFO:root:current train perplexity3.0821542739868164
INFO:root:current mean train loss 1431.008879220145
INFO:root:current train perplexity3.0847740173339844
INFO:root:current mean train loss 1431.5257501220703
INFO:root:current train perplexity3.088244915008545
INFO:root:current mean train loss 1430.734908718533
INFO:root:current train perplexity3.0883114337921143
INFO:root:current mean train loss 1430.9950533447266
INFO:root:current train perplexity3.090080738067627
INFO:root:current mean train loss 1431.3418600186435
INFO:root:current train perplexity3.0897915363311768
INFO:root:current mean train loss 1431.000087890625
INFO:root:current train perplexity3.09039568901062
INFO:root:current mean train loss 1431.0728358811598
INFO:root:current train perplexity3.089043140411377
INFO:root:current mean train loss 1430.9641268484934
INFO:root:current train perplexity3.0897626876831055
INFO:root:current mean train loss 1431.5703266601563
INFO:root:current train perplexity3.091594934463501
INFO:root:current mean train loss 1431.5642083740233
INFO:root:current train perplexity3.090411424636841
INFO:root:current mean train loss 1432.4057460650276
INFO:root:current train perplexity3.092554807662964
INFO:root:current mean train loss 1431.7445759412979
INFO:root:current train perplexity3.0933334827423096
INFO:root:current mean train loss 1432.2300911672492
INFO:root:current train perplexity3.0950868129730225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.60s/it]
INFO:root:final mean train loss: 1432.2610234478418
INFO:root:final train perplexity: 3.096700668334961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2314.952222891733
INFO:root:eval perplexity: 6.50969934463501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2857.0695082211323
INFO:root:eval perplexity: 10.473820686340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [15:51:52<4:44:02, 370.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1441.749605066636
INFO:root:current train perplexity3.076634168624878
INFO:root:current mean train loss 1426.1782904730903
INFO:root:current train perplexity3.0841379165649414
INFO:root:current mean train loss 1424.3392125846053
INFO:root:current train perplexity3.082517147064209
INFO:root:current mean train loss 1426.8501484867902
INFO:root:current train perplexity3.085007667541504
INFO:root:current mean train loss 1425.4536536786195
INFO:root:current train perplexity3.084120273590088
INFO:root:current mean train loss 1425.6820899476397
INFO:root:current train perplexity3.0867369174957275
INFO:root:current mean train loss 1427.282170770234
INFO:root:current train perplexity3.08793306350708
INFO:root:current mean train loss 1428.9268499185516
INFO:root:current train perplexity3.086737632751465
INFO:root:current mean train loss 1428.6075570936448
INFO:root:current train perplexity3.0864083766937256
INFO:root:current mean train loss 1428.802481182269
INFO:root:current train perplexity3.087395429611206
INFO:root:current mean train loss 1428.7702503485666
INFO:root:current train perplexity3.0874390602111816
INFO:root:current mean train loss 1429.1894839431093
INFO:root:current train perplexity3.0864474773406982
INFO:root:current mean train loss 1430.0209556711238
INFO:root:current train perplexity3.087921619415283
INFO:root:current mean train loss 1430.1169887765755
INFO:root:current train perplexity3.0880398750305176
INFO:root:current mean train loss 1430.4286518406514
INFO:root:current train perplexity3.089367628097534
INFO:root:current mean train loss 1430.6194629002812
INFO:root:current train perplexity3.090165853500366
INFO:root:current mean train loss 1430.8461024013654
INFO:root:current train perplexity3.09006667137146
INFO:root:current mean train loss 1431.0830435733428
INFO:root:current train perplexity3.09122896194458
INFO:root:current mean train loss 1431.2690889886533
INFO:root:current train perplexity3.091909885406494
INFO:root:current mean train loss 1431.027963143808
INFO:root:current train perplexity3.092801094055176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.29s/it]
INFO:root:final mean train loss: 1430.6466294681552
INFO:root:final train perplexity: 3.0927577018737793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2314.601676345717
INFO:root:eval perplexity: 6.507852554321289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2858.958715127715
INFO:root:eval perplexity: 10.490099906921387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [15:58:02<4:37:45, 370.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1431.7413545496324
INFO:root:current train perplexity3.1007795333862305
INFO:root:current mean train loss 1416.7607485643073
INFO:root:current train perplexity3.068796157836914
INFO:root:current mean train loss 1416.7983575804622
INFO:root:current train perplexity3.071269989013672
INFO:root:current mean train loss 1425.4404399209393
INFO:root:current train perplexity3.0812771320343018
INFO:root:current mean train loss 1425.6071414508028
INFO:root:current train perplexity3.0766220092773438
INFO:root:current mean train loss 1428.4508148079062
INFO:root:current train perplexity3.0801448822021484
INFO:root:current mean train loss 1429.4907808033074
INFO:root:current train perplexity3.0819926261901855
INFO:root:current mean train loss 1429.960124418586
INFO:root:current train perplexity3.0817391872406006
INFO:root:current mean train loss 1430.0460992534097
INFO:root:current train perplexity3.082277536392212
INFO:root:current mean train loss 1428.8248142021882
INFO:root:current train perplexity3.0802433490753174
INFO:root:current mean train loss 1428.2582860242005
INFO:root:current train perplexity3.081312656402588
INFO:root:current mean train loss 1429.5793542071415
INFO:root:current train perplexity3.081400156021118
INFO:root:current mean train loss 1429.447708698687
INFO:root:current train perplexity3.082855224609375
INFO:root:current mean train loss 1429.998343723646
INFO:root:current train perplexity3.0826659202575684
INFO:root:current mean train loss 1429.1316134188132
INFO:root:current train perplexity3.0821690559387207
INFO:root:current mean train loss 1429.3777165817003
INFO:root:current train perplexity3.084158182144165
INFO:root:current mean train loss 1429.5442515341713
INFO:root:current train perplexity3.0848727226257324
INFO:root:current mean train loss 1429.9199781230852
INFO:root:current train perplexity3.0866141319274902
INFO:root:current mean train loss 1430.0335896366166
INFO:root:current train perplexity3.087860584259033
INFO:root:current mean train loss 1429.7395341433314
INFO:root:current train perplexity3.0884242057800293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.60s/it]
INFO:root:final mean train loss: 1429.1474533965957
INFO:root:final train perplexity: 3.0891010761260986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2316.812423814273
INFO:root:eval perplexity: 6.519506931304932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2860.271340661015
INFO:root:eval perplexity: 10.501422882080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [16:04:12<4:31:34, 370.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.7976098154106
INFO:root:current train perplexity3.096700668334961
INFO:root:current mean train loss 1416.2705652097993
INFO:root:current train perplexity3.086742877960205
INFO:root:current mean train loss 1422.000815098979
INFO:root:current train perplexity3.085221290588379
INFO:root:current mean train loss 1423.6341824001736
INFO:root:current train perplexity3.082183837890625
INFO:root:current mean train loss 1422.1621900334326
INFO:root:current train perplexity3.08249831199646
INFO:root:current mean train loss 1424.40899580663
INFO:root:current train perplexity3.084970235824585
INFO:root:current mean train loss 1424.0159795851935
INFO:root:current train perplexity3.082441806793213
INFO:root:current mean train loss 1424.340347310357
INFO:root:current train perplexity3.083832025527954
INFO:root:current mean train loss 1425.1412743681606
INFO:root:current train perplexity3.0843136310577393
INFO:root:current mean train loss 1425.1892105246943
INFO:root:current train perplexity3.0837714672088623
INFO:root:current mean train loss 1423.8857482271349
INFO:root:current train perplexity3.081352710723877
INFO:root:current mean train loss 1424.1799286710605
INFO:root:current train perplexity3.080124616622925
INFO:root:current mean train loss 1423.5149136550135
INFO:root:current train perplexity3.0806427001953125
INFO:root:current mean train loss 1423.87284502076
INFO:root:current train perplexity3.080401659011841
INFO:root:current mean train loss 1425.0805161815936
INFO:root:current train perplexity3.08286714553833
INFO:root:current mean train loss 1425.2089244810556
INFO:root:current train perplexity3.0842931270599365
INFO:root:current mean train loss 1426.003368874451
INFO:root:current train perplexity3.084063768386841
INFO:root:current mean train loss 1426.2229418011136
INFO:root:current train perplexity3.08355450630188
INFO:root:current mean train loss 1427.0800039991052
INFO:root:current train perplexity3.0843234062194824
INFO:root:current mean train loss 1427.3941428899643
INFO:root:current train perplexity3.084075927734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.85s/it]
INFO:root:final mean train loss: 1427.0154480811507
INFO:root:final train perplexity: 3.0839078426361084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2319.0097634606327
INFO:root:eval perplexity: 6.53110933303833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2864.399243077488
INFO:root:eval perplexity: 10.537126541137695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [16:10:23<4:25:26, 370.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1427.4023347742418
INFO:root:current train perplexity3.0780317783355713
INFO:root:current mean train loss 1419.4869348435175
INFO:root:current train perplexity3.0716469287872314
INFO:root:current mean train loss 1420.4163986889284
INFO:root:current train perplexity3.078955888748169
INFO:root:current mean train loss 1420.077266195546
INFO:root:current train perplexity3.0725529193878174
INFO:root:current mean train loss 1421.1006242800981
INFO:root:current train perplexity3.0779905319213867
INFO:root:current mean train loss 1420.4253653942699
INFO:root:current train perplexity3.07869553565979
INFO:root:current mean train loss 1421.542462742971
INFO:root:current train perplexity3.0802712440490723
INFO:root:current mean train loss 1423.1483832995098
INFO:root:current train perplexity3.081990957260132
INFO:root:current mean train loss 1424.1106601134973
INFO:root:current train perplexity3.0811710357666016
INFO:root:current mean train loss 1424.5687297474253
INFO:root:current train perplexity3.081918239593506
INFO:root:current mean train loss 1424.0326734678576
INFO:root:current train perplexity3.081275224685669
INFO:root:current mean train loss 1423.1989920629214
INFO:root:current train perplexity3.080326557159424
INFO:root:current mean train loss 1422.9060027787361
INFO:root:current train perplexity3.0805654525756836
INFO:root:current mean train loss 1423.2573668719733
INFO:root:current train perplexity3.081489086151123
INFO:root:current mean train loss 1423.6739522741666
INFO:root:current train perplexity3.080303192138672
INFO:root:current mean train loss 1423.6404464877382
INFO:root:current train perplexity3.0798299312591553
INFO:root:current mean train loss 1424.3978499817333
INFO:root:current train perplexity3.081273078918457
INFO:root:current mean train loss 1425.308690619145
INFO:root:current train perplexity3.081296920776367
INFO:root:current mean train loss 1426.0310396443597
INFO:root:current train perplexity3.0819108486175537
INFO:root:current mean train loss 1426.4065350168119
INFO:root:current train perplexity3.081618309020996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.20s/it]
INFO:root:final mean train loss: 1426.0298411436172
INFO:root:final train perplexity: 3.081509590148926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2318.774659501745
INFO:root:eval perplexity: 6.529866695404053
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2864.2801119757037
INFO:root:eval perplexity: 10.536093711853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [16:16:34<4:19:21, 370.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.227836339614
INFO:root:current train perplexity3.052713394165039
INFO:root:current mean train loss 1414.8497017525337
INFO:root:current train perplexity3.059314250946045
INFO:root:current mean train loss 1417.055938613624
INFO:root:current train perplexity3.0617754459381104
INFO:root:current mean train loss 1418.3176434405439
INFO:root:current train perplexity3.067390203475952
INFO:root:current mean train loss 1418.7308178459245
INFO:root:current train perplexity3.066565752029419
INFO:root:current mean train loss 1420.4167983356704
INFO:root:current train perplexity3.066800117492676
INFO:root:current mean train loss 1420.7823518404996
INFO:root:current train perplexity3.067629337310791
INFO:root:current mean train loss 1421.3021734735769
INFO:root:current train perplexity3.067336320877075
INFO:root:current mean train loss 1420.6007302149542
INFO:root:current train perplexity3.069159746170044
INFO:root:current mean train loss 1421.2756118387135
INFO:root:current train perplexity3.0732264518737793
INFO:root:current mean train loss 1421.8296189831149
INFO:root:current train perplexity3.0738885402679443
INFO:root:current mean train loss 1423.3282508817906
INFO:root:current train perplexity3.0749363899230957
INFO:root:current mean train loss 1423.2541139120258
INFO:root:current train perplexity3.075119972229004
INFO:root:current mean train loss 1423.6512474087601
INFO:root:current train perplexity3.076815605163574
INFO:root:current mean train loss 1423.9685195049453
INFO:root:current train perplexity3.076472282409668
INFO:root:current mean train loss 1424.7392924696865
INFO:root:current train perplexity3.077369213104248
INFO:root:current mean train loss 1424.6018685813474
INFO:root:current train perplexity3.0766241550445557
INFO:root:current mean train loss 1425.0755281507134
INFO:root:current train perplexity3.0770456790924072
INFO:root:current mean train loss 1425.2036533669389
INFO:root:current train perplexity3.077580451965332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.21s/it]
INFO:root:final mean train loss: 1425.1359224612822
INFO:root:final train perplexity: 3.079336404800415
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2317.879659882674
INFO:root:eval perplexity: 6.52514123916626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2862.1760163002828
INFO:root:eval perplexity: 10.51788330078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [16:22:44<4:13:03, 370.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1355.855712890625
INFO:root:current train perplexity3.249472141265869
INFO:root:current mean train loss 1424.1255900065105
INFO:root:current train perplexity3.0876681804656982
INFO:root:current mean train loss 1422.2749355807164
INFO:root:current train perplexity3.0794622898101807
INFO:root:current mean train loss 1421.9955686859737
INFO:root:current train perplexity3.0778119564056396
INFO:root:current mean train loss 1424.2254183185635
INFO:root:current train perplexity3.078768730163574
INFO:root:current mean train loss 1422.6686598333229
INFO:root:current train perplexity3.0795364379882812
INFO:root:current mean train loss 1422.07939964117
INFO:root:current train perplexity3.076345682144165
INFO:root:current mean train loss 1421.7175618141805
INFO:root:current train perplexity3.0756707191467285
INFO:root:current mean train loss 1422.68244747628
INFO:root:current train perplexity3.076521158218384
INFO:root:current mean train loss 1422.2232648422344
INFO:root:current train perplexity3.0733730792999268
INFO:root:current mean train loss 1422.5191770999018
INFO:root:current train perplexity3.075505018234253
INFO:root:current mean train loss 1422.449275354292
INFO:root:current train perplexity3.0760369300842285
INFO:root:current mean train loss 1423.4652184916415
INFO:root:current train perplexity3.0763468742370605
INFO:root:current mean train loss 1422.8142531434512
INFO:root:current train perplexity3.0758635997772217
INFO:root:current mean train loss 1423.220944392358
INFO:root:current train perplexity3.076486587524414
INFO:root:current mean train loss 1423.3649287928595
INFO:root:current train perplexity3.0767087936401367
INFO:root:current mean train loss 1423.7904250850986
INFO:root:current train perplexity3.077251672744751
INFO:root:current mean train loss 1423.932715733099
INFO:root:current train perplexity3.077083110809326
INFO:root:current mean train loss 1424.193611102681
INFO:root:current train perplexity3.0762860774993896
INFO:root:current mean train loss 1424.1533868029542
INFO:root:current train perplexity3.076578378677368

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.16s/it]
INFO:root:final mean train loss: 1423.8690876539945
INFO:root:final train perplexity: 3.0762596130371094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2322.0466235005265
INFO:root:eval perplexity: 6.547179222106934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2867.8138479679187
INFO:root:eval perplexity: 10.566749572753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [16:28:53<4:06:47, 370.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1425.5744885896381
INFO:root:current train perplexity3.082575559616089
INFO:root:current mean train loss 1418.1862587808562
INFO:root:current train perplexity3.080599784851074
INFO:root:current mean train loss 1417.1287713595177
INFO:root:current train perplexity3.0799872875213623
INFO:root:current mean train loss 1417.7757484172953
INFO:root:current train perplexity3.071948528289795
INFO:root:current mean train loss 1419.2597994201224
INFO:root:current train perplexity3.0745503902435303
INFO:root:current mean train loss 1419.623606893139
INFO:root:current train perplexity3.0691230297088623
INFO:root:current mean train loss 1419.828278228809
INFO:root:current train perplexity3.071381092071533
INFO:root:current mean train loss 1421.5077301577169
INFO:root:current train perplexity3.0697407722473145
INFO:root:current mean train loss 1422.0970289069655
INFO:root:current train perplexity3.0718393325805664
INFO:root:current mean train loss 1421.6163777713548
INFO:root:current train perplexity3.072807788848877
INFO:root:current mean train loss 1421.8708750057501
INFO:root:current train perplexity3.0726473331451416
INFO:root:current mean train loss 1421.9963136729223
INFO:root:current train perplexity3.072514772415161
INFO:root:current mean train loss 1421.484919159211
INFO:root:current train perplexity3.0719034671783447
INFO:root:current mean train loss 1421.751141760004
INFO:root:current train perplexity3.0729074478149414
INFO:root:current mean train loss 1421.6466516087473
INFO:root:current train perplexity3.0735552310943604
INFO:root:current mean train loss 1421.5598934492523
INFO:root:current train perplexity3.074007272720337
INFO:root:current mean train loss 1421.5031862688918
INFO:root:current train perplexity3.0732312202453613
INFO:root:current mean train loss 1422.2808286834415
INFO:root:current train perplexity3.0737926959991455
INFO:root:current mean train loss 1422.7488753962084
INFO:root:current train perplexity3.0743751525878906
INFO:root:current mean train loss 1423.3599496655565
INFO:root:current train perplexity3.074347734451294

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.95s/it]
INFO:root:final mean train loss: 1422.914691288304
INFO:root:final train perplexity: 3.073943614959717
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2321.451211266484
INFO:root:eval perplexity: 6.544024467468262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2866.9990567687555
INFO:root:eval perplexity: 10.559670448303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [16:35:03<4:00:30, 370.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1396.2359551323784
INFO:root:current train perplexity3.061647415161133
INFO:root:current mean train loss 1403.6970089183135
INFO:root:current train perplexity3.0441458225250244
INFO:root:current mean train loss 1406.8061249296543
INFO:root:current train perplexity3.049710273742676
INFO:root:current mean train loss 1409.1491237822033
INFO:root:current train perplexity3.0514955520629883
INFO:root:current mean train loss 1412.2235678576549
INFO:root:current train perplexity3.053285837173462
INFO:root:current mean train loss 1412.8853324776264
INFO:root:current train perplexity3.0520124435424805
INFO:root:current mean train loss 1415.5853108340089
INFO:root:current train perplexity3.0511908531188965
INFO:root:current mean train loss 1416.5916711558466
INFO:root:current train perplexity3.052468776702881
INFO:root:current mean train loss 1417.494899621991
INFO:root:current train perplexity3.05580997467041
INFO:root:current mean train loss 1417.6646569406885
INFO:root:current train perplexity3.0560460090637207
INFO:root:current mean train loss 1418.5714163172659
INFO:root:current train perplexity3.0582776069641113
INFO:root:current mean train loss 1418.4573250354176
INFO:root:current train perplexity3.061343193054199
INFO:root:current mean train loss 1419.0952433860803
INFO:root:current train perplexity3.061720371246338
INFO:root:current mean train loss 1419.6693817869632
INFO:root:current train perplexity3.06234073638916
INFO:root:current mean train loss 1418.8495955188293
INFO:root:current train perplexity3.062661647796631
INFO:root:current mean train loss 1419.4196701844533
INFO:root:current train perplexity3.0641958713531494
INFO:root:current mean train loss 1420.0638774694614
INFO:root:current train perplexity3.0670483112335205
INFO:root:current mean train loss 1420.3707433603877
INFO:root:current train perplexity3.06744647026062
INFO:root:current mean train loss 1420.4899943565752
INFO:root:current train perplexity3.0676450729370117
INFO:root:current mean train loss 1420.8599708494075
INFO:root:current train perplexity3.0686285495758057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.31s/it]
INFO:root:final mean train loss: 1420.4945040658095
INFO:root:final train perplexity: 3.068077564239502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2325.1807874314327
INFO:root:eval perplexity: 6.5638041496276855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2870.7960257022937
INFO:root:eval perplexity: 10.592684745788574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [16:41:13<3:54:20, 370.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.9582865013267
INFO:root:current train perplexity3.031165838241577
INFO:root:current mean train loss 1412.9466010199653
INFO:root:current train perplexity3.0404372215270996
INFO:root:current mean train loss 1409.1896683161438
INFO:root:current train perplexity3.041931629180908
INFO:root:current mean train loss 1410.659760299553
INFO:root:current train perplexity3.046713352203369
INFO:root:current mean train loss 1412.994268893143
INFO:root:current train perplexity3.0495176315307617
INFO:root:current mean train loss 1413.1735599234996
INFO:root:current train perplexity3.0500071048736572
INFO:root:current mean train loss 1415.55484864029
INFO:root:current train perplexity3.055349826812744
INFO:root:current mean train loss 1416.2022653202296
INFO:root:current train perplexity3.061230421066284
INFO:root:current mean train loss 1416.352862198216
INFO:root:current train perplexity3.060900926589966
INFO:root:current mean train loss 1415.4996395531382
INFO:root:current train perplexity3.060722589492798
INFO:root:current mean train loss 1416.026287430259
INFO:root:current train perplexity3.0620079040527344
INFO:root:current mean train loss 1416.9346113908011
INFO:root:current train perplexity3.060180187225342
INFO:root:current mean train loss 1417.0582658260798
INFO:root:current train perplexity3.0611448287963867
INFO:root:current mean train loss 1417.4098715997147
INFO:root:current train perplexity3.062328338623047
INFO:root:current mean train loss 1417.8585765442187
INFO:root:current train perplexity3.062917709350586
INFO:root:current mean train loss 1418.864783587336
INFO:root:current train perplexity3.063396692276001
INFO:root:current mean train loss 1419.0009124626627
INFO:root:current train perplexity3.0646510124206543
INFO:root:current mean train loss 1419.5122925431403
INFO:root:current train perplexity3.0647525787353516
INFO:root:current mean train loss 1419.4243784625016
INFO:root:current train perplexity3.0647881031036377
INFO:root:current mean train loss 1419.5120158940172
INFO:root:current train perplexity3.064803123474121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.40s/it]
INFO:root:final mean train loss: 1419.2006827934908
INFO:root:final train perplexity: 3.064946174621582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2326.6704906707114
INFO:root:eval perplexity: 6.571722030639648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2872.8596282309672
INFO:root:eval perplexity: 10.610669136047363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [16:47:24<3:48:22, 370.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1408.764217703683
INFO:root:current train perplexity3.053828477859497
INFO:root:current mean train loss 1408.2797564338234
INFO:root:current train perplexity3.0497629642486572
INFO:root:current mean train loss 1414.0282940899883
INFO:root:current train perplexity3.0574960708618164
INFO:root:current mean train loss 1414.3466407569679
INFO:root:current train perplexity3.0533177852630615
INFO:root:current mean train loss 1413.986313061004
INFO:root:current train perplexity3.05566143989563
INFO:root:current mean train loss 1414.7813868472451
INFO:root:current train perplexity3.056286096572876
INFO:root:current mean train loss 1414.9699672414295
INFO:root:current train perplexity3.0572292804718018
INFO:root:current mean train loss 1416.5391756924716
INFO:root:current train perplexity3.0570244789123535
INFO:root:current mean train loss 1415.0838848947108
INFO:root:current train perplexity3.054702043533325
INFO:root:current mean train loss 1414.8895300167123
INFO:root:current train perplexity3.05513072013855
INFO:root:current mean train loss 1414.7938347647123
INFO:root:current train perplexity3.052830219268799
INFO:root:current mean train loss 1415.9607976929753
INFO:root:current train perplexity3.0549190044403076
INFO:root:current mean train loss 1415.8637961560346
INFO:root:current train perplexity3.055962562561035
INFO:root:current mean train loss 1416.258222549327
INFO:root:current train perplexity3.0566978454589844
INFO:root:current mean train loss 1416.4941072425063
INFO:root:current train perplexity3.057501792907715
INFO:root:current mean train loss 1416.7609399880573
INFO:root:current train perplexity3.0580897331237793
INFO:root:current mean train loss 1417.3850547927582
INFO:root:current train perplexity3.0596749782562256
INFO:root:current mean train loss 1417.3666850116967
INFO:root:current train perplexity3.0595290660858154
INFO:root:current mean train loss 1418.2096845494234
INFO:root:current train perplexity3.060081720352173
INFO:root:current mean train loss 1418.0286779103546
INFO:root:current train perplexity3.0613903999328613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 337.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 337.00s/it]
INFO:root:final mean train loss: 1417.7311744555282
INFO:root:final train perplexity: 3.061393976211548
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2325.3172096631206
INFO:root:eval perplexity: 6.564528942108154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2870.9367030799813
INFO:root:eval perplexity: 10.593913078308105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [16:53:34<3:42:04, 370.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1424.4373667048312
INFO:root:current train perplexity3.0531671047210693
INFO:root:current mean train loss 1419.1863302139038
INFO:root:current train perplexity3.0514276027679443
INFO:root:current mean train loss 1416.174299392966
INFO:root:current train perplexity3.0471088886260986
INFO:root:current mean train loss 1415.312809434048
INFO:root:current train perplexity3.052293062210083
INFO:root:current mean train loss 1415.9706229145277
INFO:root:current train perplexity3.05234432220459
INFO:root:current mean train loss 1415.782027756335
INFO:root:current train perplexity3.054075002670288
INFO:root:current mean train loss 1416.4199519039414
INFO:root:current train perplexity3.0524826049804688
INFO:root:current mean train loss 1415.6527053076854
INFO:root:current train perplexity3.0505847930908203
INFO:root:current mean train loss 1415.39890444991
INFO:root:current train perplexity3.0506255626678467
INFO:root:current mean train loss 1415.3699074293947
INFO:root:current train perplexity3.051774263381958
INFO:root:current mean train loss 1415.567119243941
INFO:root:current train perplexity3.0537707805633545
INFO:root:current mean train loss 1415.7697953414595
INFO:root:current train perplexity3.055811882019043
INFO:root:current mean train loss 1416.2712509522812
INFO:root:current train perplexity3.0566935539245605
INFO:root:current mean train loss 1416.4152049619513
INFO:root:current train perplexity3.056950330734253
INFO:root:current mean train loss 1416.9738079961226
INFO:root:current train perplexity3.056537628173828
INFO:root:current mean train loss 1417.5335000319983
INFO:root:current train perplexity3.057255744934082
INFO:root:current mean train loss 1417.595229749787
INFO:root:current train perplexity3.057568073272705
INFO:root:current mean train loss 1416.961912627986
INFO:root:current train perplexity3.058088779449463
INFO:root:current mean train loss 1416.7238688668563
INFO:root:current train perplexity3.0588059425354004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.79s/it]
INFO:root:final mean train loss: 1416.8891220515986
INFO:root:final train perplexity: 3.0593605041503906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2326.5446647481717
INFO:root:eval perplexity: 6.571053981781006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2874.4563594304077
INFO:root:eval perplexity: 10.62460708618164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [16:59:44<3:35:57, 370.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1409.35791015625
INFO:root:current train perplexity3.1959292888641357
INFO:root:current mean train loss 1404.7021038348857
INFO:root:current train perplexity3.070702314376831
INFO:root:current mean train loss 1412.3965825099572
INFO:root:current train perplexity3.065133810043335
INFO:root:current mean train loss 1415.1391123721473
INFO:root:current train perplexity3.0593557357788086
INFO:root:current mean train loss 1416.4402831426942
INFO:root:current train perplexity3.0583314895629883
INFO:root:current mean train loss 1413.3979821583582
INFO:root:current train perplexity3.0559535026550293
INFO:root:current mean train loss 1413.2883707008614
INFO:root:current train perplexity3.0534567832946777
INFO:root:current mean train loss 1412.979094245217
INFO:root:current train perplexity3.050975799560547
INFO:root:current mean train loss 1412.8490406245141
INFO:root:current train perplexity3.0533626079559326
INFO:root:current mean train loss 1412.6461817648558
INFO:root:current train perplexity3.0540878772735596
INFO:root:current mean train loss 1413.3033196802633
INFO:root:current train perplexity3.0526390075683594
INFO:root:current mean train loss 1413.611961364746
INFO:root:current train perplexity3.0529747009277344
INFO:root:current mean train loss 1414.3718042722176
INFO:root:current train perplexity3.0551791191101074
INFO:root:current mean train loss 1415.1788910473783
INFO:root:current train perplexity3.0548226833343506
INFO:root:current mean train loss 1415.844815854673
INFO:root:current train perplexity3.055509090423584
INFO:root:current mean train loss 1415.846463954195
INFO:root:current train perplexity3.0542848110198975
INFO:root:current mean train loss 1416.1176467096418
INFO:root:current train perplexity3.054884195327759
INFO:root:current mean train loss 1416.1868328398941
INFO:root:current train perplexity3.0558390617370605
INFO:root:current mean train loss 1416.269224247224
INFO:root:current train perplexity3.0570261478424072
INFO:root:current mean train loss 1416.1863839285713
INFO:root:current train perplexity3.0567965507507324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.19s/it]
INFO:root:final mean train loss: 1416.0813883032633
INFO:root:final train perplexity: 3.057410717010498
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2327.15793950507
INFO:root:eval perplexity: 6.574315071105957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2873.1154876059672
INFO:root:eval perplexity: 10.612905502319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [17:05:54<3:29:44, 370.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.9949660528273
INFO:root:current train perplexity3.0804250240325928
INFO:root:current mean train loss 1405.9408816503098
INFO:root:current train perplexity3.051172971725464
INFO:root:current mean train loss 1408.8716234578267
INFO:root:current train perplexity3.0443472862243652
INFO:root:current mean train loss 1412.3933873637072
INFO:root:current train perplexity3.043233633041382
INFO:root:current mean train loss 1413.5075616904505
INFO:root:current train perplexity3.038778781890869
INFO:root:current mean train loss 1412.408242721704
INFO:root:current train perplexity3.045133113861084
INFO:root:current mean train loss 1410.44832061915
INFO:root:current train perplexity3.0446066856384277
INFO:root:current mean train loss 1408.4332360044102
INFO:root:current train perplexity3.04553484916687
INFO:root:current mean train loss 1409.5307342120414
INFO:root:current train perplexity3.046910047531128
INFO:root:current mean train loss 1410.574915253249
INFO:root:current train perplexity3.047645330429077
INFO:root:current mean train loss 1412.0075744569126
INFO:root:current train perplexity3.0489695072174072
INFO:root:current mean train loss 1413.556585851256
INFO:root:current train perplexity3.0495519638061523
INFO:root:current mean train loss 1413.070165135839
INFO:root:current train perplexity3.0495569705963135
INFO:root:current mean train loss 1413.0821706929232
INFO:root:current train perplexity3.048922300338745
INFO:root:current mean train loss 1412.7238175931068
INFO:root:current train perplexity3.050023317337036
INFO:root:current mean train loss 1412.608518100114
INFO:root:current train perplexity3.050910711288452
INFO:root:current mean train loss 1413.0778922305146
INFO:root:current train perplexity3.0512547492980957
INFO:root:current mean train loss 1413.2697292862072
INFO:root:current train perplexity3.0511183738708496
INFO:root:current mean train loss 1413.6287104414428
INFO:root:current train perplexity3.0523781776428223
INFO:root:current mean train loss 1413.930770691331
INFO:root:current train perplexity3.052464008331299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.50s/it]
INFO:root:final mean train loss: 1414.1519391266193
INFO:root:final train perplexity: 3.0527584552764893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2328.728831189744
INFO:root:eval perplexity: 6.582678318023682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2876.279721523853
INFO:root:eval perplexity: 10.640547752380371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [17:12:04<3:23:34, 370.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.6287488435444
INFO:root:current train perplexity3.0505459308624268
INFO:root:current mean train loss 1412.314260289289
INFO:root:current train perplexity3.059390068054199
INFO:root:current mean train loss 1409.0389768456212
INFO:root:current train perplexity3.0542187690734863
INFO:root:current mean train loss 1406.9712091028337
INFO:root:current train perplexity3.044532299041748
INFO:root:current mean train loss 1409.9374339482556
INFO:root:current train perplexity3.0437934398651123
INFO:root:current mean train loss 1410.252411909706
INFO:root:current train perplexity3.042116165161133
INFO:root:current mean train loss 1410.379194397164
INFO:root:current train perplexity3.0393283367156982
INFO:root:current mean train loss 1410.4187648535421
INFO:root:current train perplexity3.040109157562256
INFO:root:current mean train loss 1412.4388187381135
INFO:root:current train perplexity3.042292356491089
INFO:root:current mean train loss 1412.203407791886
INFO:root:current train perplexity3.044200897216797
INFO:root:current mean train loss 1412.3094884618858
INFO:root:current train perplexity3.04374623298645
INFO:root:current mean train loss 1412.1429415469847
INFO:root:current train perplexity3.04433012008667
INFO:root:current mean train loss 1412.464504457637
INFO:root:current train perplexity3.0469021797180176
INFO:root:current mean train loss 1411.7150409966484
INFO:root:current train perplexity3.048003911972046
INFO:root:current mean train loss 1412.6227333801014
INFO:root:current train perplexity3.0494093894958496
INFO:root:current mean train loss 1413.4739064785842
INFO:root:current train perplexity3.0494837760925293
INFO:root:current mean train loss 1413.20259349483
INFO:root:current train perplexity3.050224781036377
INFO:root:current mean train loss 1412.6617277823602
INFO:root:current train perplexity3.0493671894073486
INFO:root:current mean train loss 1413.0650954220578
INFO:root:current train perplexity3.048706293106079
INFO:root:current mean train loss 1413.2047080088203
INFO:root:current train perplexity3.0493767261505127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.33s/it]
INFO:root:final mean train loss: 1412.801349341719
INFO:root:final train perplexity: 3.049506425857544
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2331.7584942756816
INFO:root:eval perplexity: 6.5988359451293945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2880.5934820513353
INFO:root:eval perplexity: 10.678351402282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [17:18:15<3:17:24, 370.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.138973721591
INFO:root:current train perplexity3.0685572624206543
INFO:root:current mean train loss 1407.3311791204637
INFO:root:current train perplexity3.0435707569122314
INFO:root:current mean train loss 1407.933313706342
INFO:root:current train perplexity3.047423839569092
INFO:root:current mean train loss 1412.849989684199
INFO:root:current train perplexity3.0478625297546387
INFO:root:current mean train loss 1412.198247553228
INFO:root:current train perplexity3.043133497238159
INFO:root:current mean train loss 1412.375646862683
INFO:root:current train perplexity3.046337604522705
INFO:root:current mean train loss 1411.8672270097804
INFO:root:current train perplexity3.0439326763153076
INFO:root:current mean train loss 1410.67279157828
INFO:root:current train perplexity3.044039011001587
INFO:root:current mean train loss 1410.2012986567981
INFO:root:current train perplexity3.0453381538391113
INFO:root:current mean train loss 1411.03806497464
INFO:root:current train perplexity3.044787883758545
INFO:root:current mean train loss 1411.3715507905065
INFO:root:current train perplexity3.0463552474975586
INFO:root:current mean train loss 1410.844651417918
INFO:root:current train perplexity3.0461647510528564
INFO:root:current mean train loss 1411.246685134462
INFO:root:current train perplexity3.0466768741607666
INFO:root:current mean train loss 1411.0951260162017
INFO:root:current train perplexity3.04750919342041
INFO:root:current mean train loss 1411.1209330870113
INFO:root:current train perplexity3.047315835952759
INFO:root:current mean train loss 1411.2362150038937
INFO:root:current train perplexity3.0468945503234863
INFO:root:current mean train loss 1412.0173817061225
INFO:root:current train perplexity3.047579526901245
INFO:root:current mean train loss 1412.1379456435852
INFO:root:current train perplexity3.047740936279297
INFO:root:current mean train loss 1411.9499386029102
INFO:root:current train perplexity3.047807455062866
INFO:root:current mean train loss 1412.260565419697
INFO:root:current train perplexity3.048027992248535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.65s/it]
INFO:root:final mean train loss: 1411.9408819570845
INFO:root:final train perplexity: 3.047436475753784
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2331.648474294243
INFO:root:eval perplexity: 6.598247528076172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2879.7175297297485
INFO:root:eval perplexity: 10.67066478729248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [17:24:25<3:11:16, 370.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1411.162794325087
INFO:root:current train perplexity3.0425164699554443
INFO:root:current mean train loss 1418.376768600109
INFO:root:current train perplexity3.043013095855713
INFO:root:current mean train loss 1416.3248555800494
INFO:root:current train perplexity3.0502476692199707
INFO:root:current mean train loss 1413.4442571824598
INFO:root:current train perplexity3.04402756690979
INFO:root:current mean train loss 1411.753715385825
INFO:root:current train perplexity3.0410516262054443
INFO:root:current mean train loss 1411.4223331904911
INFO:root:current train perplexity3.0417020320892334
INFO:root:current mean train loss 1413.3731967381068
INFO:root:current train perplexity3.0423028469085693
INFO:root:current mean train loss 1412.2607470892872
INFO:root:current train perplexity3.042388439178467
INFO:root:current mean train loss 1411.1995162263922
INFO:root:current train perplexity3.042736768722534
INFO:root:current mean train loss 1410.2374435864358
INFO:root:current train perplexity3.0404129028320312
INFO:root:current mean train loss 1409.6574601130699
INFO:root:current train perplexity3.041003704071045
INFO:root:current mean train loss 1409.6899555714058
INFO:root:current train perplexity3.041430711746216
INFO:root:current mean train loss 1410.5028210525993
INFO:root:current train perplexity3.042679786682129
INFO:root:current mean train loss 1409.6190510296613
INFO:root:current train perplexity3.041461944580078
INFO:root:current mean train loss 1410.5126620582912
INFO:root:current train perplexity3.042487382888794
INFO:root:current mean train loss 1410.577654734216
INFO:root:current train perplexity3.0428738594055176
INFO:root:current mean train loss 1410.5415743595106
INFO:root:current train perplexity3.0423388481140137
INFO:root:current mean train loss 1410.6615281632469
INFO:root:current train perplexity3.0426745414733887
INFO:root:current mean train loss 1410.6753706972822
INFO:root:current train perplexity3.0435354709625244
INFO:root:current mean train loss 1410.9953326676002
INFO:root:current train perplexity3.044457197189331

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.76s/it]
INFO:root:final mean train loss: 1410.6988248377813
INFO:root:final train perplexity: 3.044450521469116
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 2332.8405532295824
INFO:root:eval perplexity: 6.604616641998291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2880.8367543321974
INFO:root:eval perplexity: 10.680489540100098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [17:30:34<3:04:59, 369.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1409.2357548060043
INFO:root:current train perplexity3.039790630340576
INFO:root:current mean train loss 1410.5792333209326
INFO:root:current train perplexity3.039118528366089
INFO:root:current mean train loss 1410.7447150735295
INFO:root:current train perplexity3.035449981689453
INFO:root:current mean train loss 1410.8880659167135
INFO:root:current train perplexity3.037792682647705
INFO:root:current mean train loss 1411.630072033966
INFO:root:current train perplexity3.04144024848938
INFO:root:current mean train loss 1410.4361928735807
INFO:root:current train perplexity3.040327310562134
INFO:root:current mean train loss 1409.4839391611483
INFO:root:current train perplexity3.0387635231018066
INFO:root:current mean train loss 1409.9612639491247
INFO:root:current train perplexity3.0400688648223877
INFO:root:current mean train loss 1409.9945745307227
INFO:root:current train perplexity3.0416574478149414
INFO:root:current mean train loss 1408.9973645649013
INFO:root:current train perplexity3.0390796661376953
INFO:root:current mean train loss 1408.7531043298754
INFO:root:current train perplexity3.0384531021118164
INFO:root:current mean train loss 1408.472338292256
INFO:root:current train perplexity3.037959098815918
INFO:root:current mean train loss 1408.0358388588538
INFO:root:current train perplexity3.037655830383301
INFO:root:current mean train loss 1408.8345591337068
INFO:root:current train perplexity3.038562059402466
INFO:root:current mean train loss 1409.213914900678
INFO:root:current train perplexity3.040666103363037
INFO:root:current mean train loss 1408.626401695986
INFO:root:current train perplexity3.039485216140747
INFO:root:current mean train loss 1409.4419720086776
INFO:root:current train perplexity3.040419101715088
INFO:root:current mean train loss 1409.973265646289
INFO:root:current train perplexity3.041140079498291
INFO:root:current mean train loss 1409.8939426113147
INFO:root:current train perplexity3.0413565635681152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.89s/it]
INFO:root:final mean train loss: 1409.7472282098029
INFO:root:final train perplexity: 3.0421650409698486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2332.0876005997893
INFO:root:eval perplexity: 6.600594520568848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2880.5836718403702
INFO:root:eval perplexity: 10.678267478942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [17:36:44<2:58:45, 369.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1393.780985514323
INFO:root:current train perplexity3.1183876991271973
INFO:root:current mean train loss 1405.122869527565
INFO:root:current train perplexity3.046954393386841
INFO:root:current mean train loss 1406.5288542219737
INFO:root:current train perplexity3.033010482788086
INFO:root:current mean train loss 1407.789980819802
INFO:root:current train perplexity3.032151699066162
INFO:root:current mean train loss 1405.923524151882
INFO:root:current train perplexity3.039668083190918
INFO:root:current mean train loss 1406.3928567637568
INFO:root:current train perplexity3.040149688720703
INFO:root:current mean train loss 1406.4459510526249
INFO:root:current train perplexity3.039769172668457
INFO:root:current mean train loss 1406.676196219901
INFO:root:current train perplexity3.0406625270843506
INFO:root:current mean train loss 1406.177253817802
INFO:root:current train perplexity3.0415871143341064
INFO:root:current mean train loss 1406.5971581330625
INFO:root:current train perplexity3.0421142578125
INFO:root:current mean train loss 1406.7694032339168
INFO:root:current train perplexity3.0424962043762207
INFO:root:current mean train loss 1406.9338712226634
INFO:root:current train perplexity3.0424418449401855
INFO:root:current mean train loss 1407.7100263250804
INFO:root:current train perplexity3.040741205215454
INFO:root:current mean train loss 1407.3976896557654
INFO:root:current train perplexity3.04032039642334
INFO:root:current mean train loss 1407.7105185019004
INFO:root:current train perplexity3.0403194427490234
INFO:root:current mean train loss 1407.970739600193
INFO:root:current train perplexity3.03950834274292
INFO:root:current mean train loss 1408.8461191217748
INFO:root:current train perplexity3.0404107570648193
INFO:root:current mean train loss 1409.5870150245228
INFO:root:current train perplexity3.038961172103882
INFO:root:current mean train loss 1409.215552041697
INFO:root:current train perplexity3.0383241176605225
INFO:root:current mean train loss 1409.2137540835274
INFO:root:current train perplexity3.038817882537842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.84s/it]
INFO:root:final mean train loss: 1408.3897053790224
INFO:root:final train perplexity: 3.038907527923584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 2333.1567404456173
INFO:root:eval perplexity: 6.606306076049805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2881.6059457765405
INFO:root:eval perplexity: 10.68724250793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [17:42:52<2:52:23, 369.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1398.4836319633152
INFO:root:current train perplexity3.0880279541015625
INFO:root:current mean train loss 1406.819541372904
INFO:root:current train perplexity3.040681838989258
INFO:root:current mean train loss 1410.9411380237527
INFO:root:current train perplexity3.040140390396118
INFO:root:current mean train loss 1410.372255874492
INFO:root:current train perplexity3.037659168243408
INFO:root:current mean train loss 1409.881173063959
INFO:root:current train perplexity3.0326671600341797
INFO:root:current mean train loss 1408.8029435050191
INFO:root:current train perplexity3.033964157104492
INFO:root:current mean train loss 1408.2675361939457
INFO:root:current train perplexity3.032761812210083
INFO:root:current mean train loss 1410.2194795516186
INFO:root:current train perplexity3.0383198261260986
INFO:root:current mean train loss 1409.6057412204302
INFO:root:current train perplexity3.037731647491455
INFO:root:current mean train loss 1409.5533953797908
INFO:root:current train perplexity3.0381555557250977
INFO:root:current mean train loss 1408.3618436125366
INFO:root:current train perplexity3.0364248752593994
INFO:root:current mean train loss 1408.213443800263
INFO:root:current train perplexity3.0353331565856934
INFO:root:current mean train loss 1407.8212096119942
INFO:root:current train perplexity3.035381317138672
INFO:root:current mean train loss 1408.4691764618174
INFO:root:current train perplexity3.037148952484131
INFO:root:current mean train loss 1408.1195129265855
INFO:root:current train perplexity3.038508176803589
INFO:root:current mean train loss 1408.0257527482252
INFO:root:current train perplexity3.038942337036133
INFO:root:current mean train loss 1408.2021707004776
INFO:root:current train perplexity3.0382256507873535
INFO:root:current mean train loss 1407.5495601926373
INFO:root:current train perplexity3.0372726917266846
INFO:root:current mean train loss 1408.4915625508904
INFO:root:current train perplexity3.0386295318603516
INFO:root:current mean train loss 1408.078319182572
INFO:root:current train perplexity3.0382041931152344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.47s/it]
INFO:root:final mean train loss: 1407.7507014887776
INFO:root:final train perplexity: 3.0373752117156982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2334.0511708361037
INFO:root:eval perplexity: 6.611089706420898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2883.0141579918827
INFO:root:eval perplexity: 10.699625968933105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [17:49:02<2:46:20, 369.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.9231750488282
INFO:root:current train perplexity3.007672071456909
INFO:root:current mean train loss 1404.4149335588727
INFO:root:current train perplexity3.0306649208068848
INFO:root:current mean train loss 1399.3896657307944
INFO:root:current train perplexity3.0265800952911377
INFO:root:current mean train loss 1398.6415150361902
INFO:root:current train perplexity3.025508403778076
INFO:root:current mean train loss 1401.9469019109551
INFO:root:current train perplexity3.0287647247314453
INFO:root:current mean train loss 1403.348479546441
INFO:root:current train perplexity3.026655673980713
INFO:root:current mean train loss 1402.6246217727662
INFO:root:current train perplexity3.0255091190338135
INFO:root:current mean train loss 1402.5365310256545
INFO:root:current train perplexity3.0248773097991943
INFO:root:current mean train loss 1403.01838843936
INFO:root:current train perplexity3.0284698009490967
INFO:root:current mean train loss 1402.9968842202045
INFO:root:current train perplexity3.0271127223968506
INFO:root:current mean train loss 1403.5344957791842
INFO:root:current train perplexity3.028150796890259
INFO:root:current mean train loss 1404.7173232764528
INFO:root:current train perplexity3.029951810836792
INFO:root:current mean train loss 1404.7283083023563
INFO:root:current train perplexity3.0304524898529053
INFO:root:current mean train loss 1405.028933761369
INFO:root:current train perplexity3.031083345413208
INFO:root:current mean train loss 1405.3258666144477
INFO:root:current train perplexity3.0299768447875977
INFO:root:current mean train loss 1405.949250694374
INFO:root:current train perplexity3.0313518047332764
INFO:root:current mean train loss 1405.802614463248
INFO:root:current train perplexity3.032651662826538
INFO:root:current mean train loss 1405.5338741609419
INFO:root:current train perplexity3.0330495834350586
INFO:root:current mean train loss 1406.12616928764
INFO:root:current train perplexity3.0334668159484863
INFO:root:current mean train loss 1406.5128872271666
INFO:root:current train perplexity3.033034086227417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.31s/it]
INFO:root:final mean train loss: 1406.0386880402366
INFO:root:final train perplexity: 3.0332741737365723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2335.1294443116967
INFO:root:eval perplexity: 6.616861343383789
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2884.2029678669383
INFO:root:eval perplexity: 10.710084915161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [17:55:13<2:40:20, 370.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1398.848264459978
INFO:root:current train perplexity3.0416388511657715
INFO:root:current mean train loss 1397.7272358305136
INFO:root:current train perplexity3.0317811965942383
INFO:root:current mean train loss 1393.7301984853782
INFO:root:current train perplexity3.0301854610443115
INFO:root:current mean train loss 1398.409829361432
INFO:root:current train perplexity3.025749444961548
INFO:root:current mean train loss 1400.120579825971
INFO:root:current train perplexity3.0245168209075928
INFO:root:current mean train loss 1402.155741118015
INFO:root:current train perplexity3.025041341781616
INFO:root:current mean train loss 1401.8338253305747
INFO:root:current train perplexity3.023385524749756
INFO:root:current mean train loss 1401.8932882936344
INFO:root:current train perplexity3.0250067710876465
INFO:root:current mean train loss 1402.6036402592165
INFO:root:current train perplexity3.0275962352752686
INFO:root:current mean train loss 1403.099097623596
INFO:root:current train perplexity3.027726650238037
INFO:root:current mean train loss 1402.780788396368
INFO:root:current train perplexity3.0258095264434814
INFO:root:current mean train loss 1404.0156368166595
INFO:root:current train perplexity3.0264289379119873
INFO:root:current mean train loss 1404.4104972117082
INFO:root:current train perplexity3.0264687538146973
INFO:root:current mean train loss 1404.1785724052368
INFO:root:current train perplexity3.0256659984588623
INFO:root:current mean train loss 1403.5098141347535
INFO:root:current train perplexity3.026949644088745
INFO:root:current mean train loss 1403.9434894422116
INFO:root:current train perplexity3.0279898643493652
INFO:root:current mean train loss 1404.6849653282004
INFO:root:current train perplexity3.0272281169891357
INFO:root:current mean train loss 1405.1325525187199
INFO:root:current train perplexity3.028424024581909
INFO:root:current mean train loss 1405.1550744569745
INFO:root:current train perplexity3.0300307273864746
INFO:root:current mean train loss 1405.745532800424
INFO:root:current train perplexity3.0314269065856934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.20s/it]
INFO:root:final mean train loss: 1405.4405605914433
INFO:root:final train perplexity: 3.0318429470062256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2335.350699783217
INFO:root:eval perplexity: 6.618046760559082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2883.9054634689437
INFO:root:eval perplexity: 10.707468032836914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [18:01:23<2:34:09, 369.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.3123234929265
INFO:root:current train perplexity3.0312559604644775
INFO:root:current mean train loss 1407.1950073242188
INFO:root:current train perplexity3.0297164916992188
INFO:root:current mean train loss 1405.6659038014654
INFO:root:current train perplexity3.0291025638580322
INFO:root:current mean train loss 1406.5140795376212
INFO:root:current train perplexity3.0339996814727783
INFO:root:current mean train loss 1407.1958986435259
INFO:root:current train perplexity3.0320053100585938
INFO:root:current mean train loss 1406.8674267493059
INFO:root:current train perplexity3.0282886028289795
INFO:root:current mean train loss 1405.234055516274
INFO:root:current train perplexity3.028855085372925
INFO:root:current mean train loss 1405.1260620432615
INFO:root:current train perplexity3.029927968978882
INFO:root:current mean train loss 1404.50331684872
INFO:root:current train perplexity3.0296788215637207
INFO:root:current mean train loss 1405.9791164515689
INFO:root:current train perplexity3.029580593109131
INFO:root:current mean train loss 1404.7578101131503
INFO:root:current train perplexity3.028829574584961
INFO:root:current mean train loss 1405.4560502164409
INFO:root:current train perplexity3.0281193256378174
INFO:root:current mean train loss 1405.2748360386822
INFO:root:current train perplexity3.0287742614746094
INFO:root:current mean train loss 1404.4876940864663
INFO:root:current train perplexity3.0276143550872803
INFO:root:current mean train loss 1404.4413114260462
INFO:root:current train perplexity3.027676820755005
INFO:root:current mean train loss 1404.8625216066005
INFO:root:current train perplexity3.0289485454559326
INFO:root:current mean train loss 1405.1350382778664
INFO:root:current train perplexity3.0298941135406494
INFO:root:current mean train loss 1405.1346335771252
INFO:root:current train perplexity3.030000925064087
INFO:root:current mean train loss 1404.8105621826433
INFO:root:current train perplexity3.02954363822937
INFO:root:current mean train loss 1404.7272141600572
INFO:root:current train perplexity3.0295443534851074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.80s/it]
INFO:root:final mean train loss: 1404.3735468215673
INFO:root:final train perplexity: 3.0292909145355225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2337.578107685062
INFO:root:eval perplexity: 6.6299848556518555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2888.0962931315103
INFO:root:eval perplexity: 10.744422912597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [18:07:34<2:28:03, 370.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1406.4605444604224
INFO:root:current train perplexity3.0198633670806885
INFO:root:current mean train loss 1410.3105705221285
INFO:root:current train perplexity3.024426221847534
INFO:root:current mean train loss 1407.400915401498
INFO:root:current train perplexity3.019753932952881
INFO:root:current mean train loss 1405.8998811141305
INFO:root:current train perplexity3.0260210037231445
INFO:root:current mean train loss 1404.8209688454685
INFO:root:current train perplexity3.026768445968628
INFO:root:current mean train loss 1404.2573748231944
INFO:root:current train perplexity3.0224111080169678
INFO:root:current mean train loss 1404.4065672768181
INFO:root:current train perplexity3.019998550415039
INFO:root:current mean train loss 1405.0905295660161
INFO:root:current train perplexity3.0243213176727295
INFO:root:current mean train loss 1405.0665105098292
INFO:root:current train perplexity3.025527238845825
INFO:root:current mean train loss 1404.2796795919132
INFO:root:current train perplexity3.0256457328796387
INFO:root:current mean train loss 1403.9860539982672
INFO:root:current train perplexity3.0250723361968994
INFO:root:current mean train loss 1404.0040305751797
INFO:root:current train perplexity3.0224969387054443
INFO:root:current mean train loss 1403.7189869544563
INFO:root:current train perplexity3.023566722869873
INFO:root:current mean train loss 1404.3597484070308
INFO:root:current train perplexity3.0255730152130127
INFO:root:current mean train loss 1403.9691755677293
INFO:root:current train perplexity3.025787591934204
INFO:root:current mean train loss 1404.1534116158764
INFO:root:current train perplexity3.0284667015075684
INFO:root:current mean train loss 1403.5207679789141
INFO:root:current train perplexity3.0271289348602295
INFO:root:current mean train loss 1403.754603979642
INFO:root:current train perplexity3.0286142826080322
INFO:root:current mean train loss 1404.0623841268055
INFO:root:current train perplexity3.0290257930755615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.76s/it]
INFO:root:final mean train loss: 1403.9941681108269
INFO:root:final train perplexity: 3.02838397026062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2337.760004571144
INFO:root:eval perplexity: 6.630962371826172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2887.6423023846132
INFO:root:eval perplexity: 10.740411758422852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [18:13:44<2:21:55, 370.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1381.1380004882812
INFO:root:current train perplexity3.0408565998077393
INFO:root:current mean train loss 1393.783127396195
INFO:root:current train perplexity3.022657871246338
INFO:root:current mean train loss 1394.738737839919
INFO:root:current train perplexity3.020878553390503
INFO:root:current mean train loss 1396.440634987571
INFO:root:current train perplexity3.0203232765197754
INFO:root:current mean train loss 1396.660260368796
INFO:root:current train perplexity3.0202014446258545
INFO:root:current mean train loss 1398.4257281446082
INFO:root:current train perplexity3.02164626121521
INFO:root:current mean train loss 1399.6872590717517
INFO:root:current train perplexity3.022242546081543
INFO:root:current mean train loss 1401.644590216168
INFO:root:current train perplexity3.0225887298583984
INFO:root:current mean train loss 1401.1118300031908
INFO:root:current train perplexity3.0225296020507812
INFO:root:current mean train loss 1400.487739596598
INFO:root:current train perplexity3.0253090858459473
INFO:root:current mean train loss 1399.8218071347192
INFO:root:current train perplexity3.024196147918701
INFO:root:current mean train loss 1399.8235204813714
INFO:root:current train perplexity3.0246810913085938
INFO:root:current mean train loss 1400.194330581766
INFO:root:current train perplexity3.022796630859375
INFO:root:current mean train loss 1401.8610066171816
INFO:root:current train perplexity3.0231246948242188
INFO:root:current mean train loss 1403.0305166244507
INFO:root:current train perplexity3.023583173751831
INFO:root:current mean train loss 1403.2797775470926
INFO:root:current train perplexity3.024094581604004
INFO:root:current mean train loss 1402.8731423752818
INFO:root:current train perplexity3.0247936248779297
INFO:root:current mean train loss 1402.8743065291321
INFO:root:current train perplexity3.0258586406707764
INFO:root:current mean train loss 1403.4137360564375
INFO:root:current train perplexity3.02639102935791
INFO:root:current mean train loss 1403.3593527995815
INFO:root:current train perplexity3.027113437652588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.57s/it]
INFO:root:final mean train loss: 1403.1049989362707
INFO:root:final train perplexity: 3.026259422302246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2337.628896726784
INFO:root:eval perplexity: 6.630257606506348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 2887.8250308205897
INFO:root:eval perplexity: 10.742025375366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [18:19:54<2:15:45, 370.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1391.9210009765625
INFO:root:current train perplexity2.9828178882598877
INFO:root:current mean train loss 1397.49004296875
INFO:root:current train perplexity3.009981155395508
INFO:root:current mean train loss 1401.297650282118
INFO:root:current train perplexity3.0114779472351074
INFO:root:current mean train loss 1398.0634622896634
INFO:root:current train perplexity3.0143680572509766
INFO:root:current mean train loss 1396.870962488511
INFO:root:current train perplexity3.0168306827545166
INFO:root:current mean train loss 1398.9935774739583
INFO:root:current train perplexity3.016072988510132
INFO:root:current mean train loss 1400.5620951171875
INFO:root:current train perplexity3.0177347660064697
INFO:root:current mean train loss 1400.8117701037177
INFO:root:current train perplexity3.0201563835144043
INFO:root:current mean train loss 1401.8023660925662
INFO:root:current train perplexity3.023237466812134
INFO:root:current mean train loss 1401.8187873469171
INFO:root:current train perplexity3.0236434936523438
INFO:root:current mean train loss 1401.408965320122
INFO:root:current train perplexity3.022773265838623
INFO:root:current mean train loss 1401.6542297092014
INFO:root:current train perplexity3.0220184326171875
INFO:root:current mean train loss 1401.1692121731505
INFO:root:current train perplexity3.021278142929077
INFO:root:current mean train loss 1400.6868478220813
INFO:root:current train perplexity3.0212080478668213
INFO:root:current mean train loss 1401.178111122533
INFO:root:current train perplexity3.02215313911438
INFO:root:current mean train loss 1401.6993090420083
INFO:root:current train perplexity3.022862672805786
INFO:root:current mean train loss 1402.2813145282453
INFO:root:current train perplexity3.025442361831665
INFO:root:current mean train loss 1402.5011120782383
INFO:root:current train perplexity3.0248372554779053
INFO:root:current mean train loss 1402.4283646591396
INFO:root:current train perplexity3.023956537246704
INFO:root:current mean train loss 1402.3071275111606
INFO:root:current train perplexity3.0234899520874023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.99s/it]
INFO:root:final mean train loss: 1401.9181973471284
INFO:root:final train perplexity: 3.0234262943267822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 2339.6139591298206
INFO:root:eval perplexity: 6.640918254852295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2889.790871045268
INFO:root:eval perplexity: 10.759403228759766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [18:26:05<2:09:37, 370.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1389.6385934012276
INFO:root:current train perplexity2.996095895767212
INFO:root:current mean train loss 1391.2790449975241
INFO:root:current train perplexity3.015011787414551
INFO:root:current mean train loss 1390.071699662642
INFO:root:current train perplexity3.00722599029541
INFO:root:current mean train loss 1391.8267811557703
INFO:root:current train perplexity3.0093300342559814
INFO:root:current mean train loss 1393.548070847179
INFO:root:current train perplexity3.0118656158447266
INFO:root:current mean train loss 1394.1438591876154
INFO:root:current train perplexity3.0119330883026123
INFO:root:current mean train loss 1394.5769736982209
INFO:root:current train perplexity3.0122838020324707
INFO:root:current mean train loss 1395.5064404428488
INFO:root:current train perplexity3.017552375793457
INFO:root:current mean train loss 1396.3614819451918
INFO:root:current train perplexity3.01802396774292
INFO:root:current mean train loss 1397.9298997623905
INFO:root:current train perplexity3.0184082984924316
INFO:root:current mean train loss 1398.3415397307238
INFO:root:current train perplexity3.018852710723877
INFO:root:current mean train loss 1398.6133500882497
INFO:root:current train perplexity3.018937587738037
INFO:root:current mean train loss 1399.3168504011612
INFO:root:current train perplexity3.0216236114501953
INFO:root:current mean train loss 1399.8706367595007
INFO:root:current train perplexity3.020240306854248
INFO:root:current mean train loss 1401.1922324679265
INFO:root:current train perplexity3.020500659942627
INFO:root:current mean train loss 1401.1197286524198
INFO:root:current train perplexity3.0197412967681885
INFO:root:current mean train loss 1400.0423691780936
INFO:root:current train perplexity3.019604206085205
INFO:root:current mean train loss 1400.4033912282039
INFO:root:current train perplexity3.01981520652771
INFO:root:current mean train loss 1400.6967731687068
INFO:root:current train perplexity3.0202155113220215
INFO:root:current mean train loss 1400.7697807964164
INFO:root:current train perplexity3.019778251647949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.61s/it]
INFO:root:final mean train loss: 1400.7134289532314
INFO:root:final train perplexity: 3.0205533504486084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2340.167312513852
INFO:root:eval perplexity: 6.643891334533691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2889.867825988337
INFO:root:eval perplexity: 10.760083198547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [18:32:15<2:03:27, 370.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1409.9539774231991
INFO:root:current train perplexity3.030970573425293
INFO:root:current mean train loss 1403.4729810030956
INFO:root:current train perplexity3.0248842239379883
INFO:root:current mean train loss 1400.38709957167
INFO:root:current train perplexity3.0178380012512207
INFO:root:current mean train loss 1399.5461395178665
INFO:root:current train perplexity3.0161337852478027
INFO:root:current mean train loss 1398.5909713711874
INFO:root:current train perplexity3.015848159790039
INFO:root:current mean train loss 1397.745405221028
INFO:root:current train perplexity3.0148303508758545
INFO:root:current mean train loss 1398.813316704109
INFO:root:current train perplexity3.0146329402923584
INFO:root:current mean train loss 1399.285817423985
INFO:root:current train perplexity3.016857624053955
INFO:root:current mean train loss 1400.3770281577415
INFO:root:current train perplexity3.0163533687591553
INFO:root:current mean train loss 1401.729124067225
INFO:root:current train perplexity3.0179402828216553
INFO:root:current mean train loss 1401.6872453698581
INFO:root:current train perplexity3.0202343463897705
INFO:root:current mean train loss 1401.8437767522514
INFO:root:current train perplexity3.020794153213501
INFO:root:current mean train loss 1401.7170040745693
INFO:root:current train perplexity3.0197055339813232
INFO:root:current mean train loss 1401.368760671047
INFO:root:current train perplexity3.0191805362701416
INFO:root:current mean train loss 1400.7843127182039
INFO:root:current train perplexity3.018451452255249
INFO:root:current mean train loss 1401.3105389666603
INFO:root:current train perplexity3.018031358718872
INFO:root:current mean train loss 1400.8245958508749
INFO:root:current train perplexity3.0188891887664795
INFO:root:current mean train loss 1401.0487161867316
INFO:root:current train perplexity3.019831418991089
INFO:root:current mean train loss 1401.2550203796354
INFO:root:current train perplexity3.0202486515045166
INFO:root:current mean train loss 1401.0088743683998
INFO:root:current train perplexity3.0209457874298096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.11s/it]
INFO:root:final mean train loss: 1400.7728091426047
INFO:root:final train perplexity: 3.0206947326660156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 2339.0624580112753
INFO:root:eval perplexity: 6.637954235076904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 2888.696727996177
INFO:root:eval perplexity: 10.74972915649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [18:38:27<1:57:22, 370.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1392.2943404348273
INFO:root:current train perplexity3.0096726417541504
INFO:root:current mean train loss 1397.7696838378906
INFO:root:current train perplexity3.012087821960449
INFO:root:current mean train loss 1395.6993324169214
INFO:root:current train perplexity3.007423162460327
INFO:root:current mean train loss 1397.2524988702003
INFO:root:current train perplexity3.014108657836914
INFO:root:current mean train loss 1396.0842464671416
INFO:root:current train perplexity3.014465093612671
INFO:root:current mean train loss 1396.626652399699
INFO:root:current train perplexity3.016155242919922
INFO:root:current mean train loss 1395.6816135383922
INFO:root:current train perplexity3.016035556793213
INFO:root:current mean train loss 1396.4264438275209
INFO:root:current train perplexity3.0156302452087402
INFO:root:current mean train loss 1396.545242936644
INFO:root:current train perplexity3.0145323276519775
INFO:root:current mean train loss 1398.077872354476
INFO:root:current train perplexity3.0186126232147217
INFO:root:current mean train loss 1398.2382441524237
INFO:root:current train perplexity3.017638683319092
INFO:root:current mean train loss 1398.5474589860357
INFO:root:current train perplexity3.0164012908935547
INFO:root:current mean train loss 1398.1501947959016
INFO:root:current train perplexity3.0178956985473633
INFO:root:current mean train loss 1397.8019200702047
INFO:root:current train perplexity3.016967535018921
INFO:root:current mean train loss 1397.499663314199
INFO:root:current train perplexity3.0174965858459473
INFO:root:current mean train loss 1398.0470371924075
INFO:root:current train perplexity3.017993450164795
INFO:root:current mean train loss 1398.9114061596854
INFO:root:current train perplexity3.0180108547210693
INFO:root:current mean train loss 1399.4803140313775
INFO:root:current train perplexity3.0180628299713135
INFO:root:current mean train loss 1399.7408821415038
INFO:root:current train perplexity3.018261432647705
INFO:root:current mean train loss 1399.9736976160211
INFO:root:current train perplexity3.0180952548980713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.09s/it]
INFO:root:final mean train loss: 1399.7031845885338
INFO:root:final train perplexity: 3.018145799636841
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 2339.984897045379
INFO:root:eval perplexity: 6.642910957336426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2890.662977719138
INFO:root:eval perplexity: 10.767117500305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [18:44:39<1:51:19, 371.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1388.2962672736055
INFO:root:current train perplexity3.0189685821533203
INFO:root:current mean train loss 1396.3511886991985
INFO:root:current train perplexity3.029348373413086
INFO:root:current mean train loss 1395.1041359754959
INFO:root:current train perplexity3.0192384719848633
INFO:root:current mean train loss 1395.347368934379
INFO:root:current train perplexity3.014106035232544
INFO:root:current mean train loss 1395.8979138109312
INFO:root:current train perplexity3.015359401702881
INFO:root:current mean train loss 1395.698963699212
INFO:root:current train perplexity3.0142786502838135
INFO:root:current mean train loss 1395.520349984217
INFO:root:current train perplexity3.0137860774993896
INFO:root:current mean train loss 1396.9998820859275
INFO:root:current train perplexity3.0156397819519043
INFO:root:current mean train loss 1398.014661970491
INFO:root:current train perplexity3.015678882598877
INFO:root:current mean train loss 1398.2452068040739
INFO:root:current train perplexity3.0174381732940674
INFO:root:current mean train loss 1399.0808764402734
INFO:root:current train perplexity3.0161125659942627
INFO:root:current mean train loss 1399.19640622135
INFO:root:current train perplexity3.0166187286376953
INFO:root:current mean train loss 1399.239468910117
INFO:root:current train perplexity3.01613187789917
INFO:root:current mean train loss 1399.4905140062758
INFO:root:current train perplexity3.0152242183685303
INFO:root:current mean train loss 1399.8462371928374
INFO:root:current train perplexity3.0142526626586914
INFO:root:current mean train loss 1399.7066647325457
INFO:root:current train perplexity3.014960289001465
INFO:root:current mean train loss 1399.2819708854013
INFO:root:current train perplexity3.016815423965454
INFO:root:current mean train loss 1399.4990536657313
INFO:root:current train perplexity3.017125129699707
INFO:root:current mean train loss 1399.6515191789033
INFO:root:current train perplexity3.017024517059326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.23s/it]
INFO:root:final mean train loss: 1398.97730975745
INFO:root:final train perplexity: 3.0164172649383545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 2342.1057354000445
INFO:root:eval perplexity: 6.654321193695068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 2892.5470888394834
INFO:root:eval perplexity: 10.783808708190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [18:50:50<1:45:09, 371.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1413.6952392578125
INFO:root:current train perplexity2.951937675476074
INFO:root:current mean train loss 1389.9842928799717
INFO:root:current train perplexity3.0024895668029785
INFO:root:current mean train loss 1390.419330124628
INFO:root:current train perplexity3.012749433517456
INFO:root:current mean train loss 1390.750136639995
INFO:root:current train perplexity3.009352684020996
INFO:root:current mean train loss 1393.8924524818979
INFO:root:current train perplexity3.006845235824585
INFO:root:current mean train loss 1392.6452000038296
INFO:root:current train perplexity3.0062203407287598
INFO:root:current mean train loss 1394.4351778624489
INFO:root:current train perplexity3.00638484954834
INFO:root:current mean train loss 1397.8110356720401
INFO:root:current train perplexity3.010187864303589
INFO:root:current mean train loss 1397.5003157250676
INFO:root:current train perplexity3.0134756565093994
INFO:root:current mean train loss 1397.7497911390367
INFO:root:current train perplexity3.0154833793640137
INFO:root:current mean train loss 1398.192885838877
INFO:root:current train perplexity3.014598846435547
INFO:root:current mean train loss 1397.6074778513866
INFO:root:current train perplexity3.0149118900299072
INFO:root:current mean train loss 1398.1938523978242
INFO:root:current train perplexity3.013521671295166
INFO:root:current mean train loss 1398.9784539375596
INFO:root:current train perplexity3.013331651687622
INFO:root:current mean train loss 1398.5259379501883
INFO:root:current train perplexity3.013376474380493
INFO:root:current mean train loss 1398.5117383944278
INFO:root:current train perplexity3.0124666690826416
INFO:root:current mean train loss 1398.361787139703
INFO:root:current train perplexity3.01375150680542
INFO:root:current mean train loss 1398.4058870014392
INFO:root:current train perplexity3.0137393474578857
INFO:root:current mean train loss 1398.5245357281594
INFO:root:current train perplexity3.0137059688568115
INFO:root:current mean train loss 1398.4812389433696
INFO:root:current train perplexity3.014988422393799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.38s/it]
INFO:root:final mean train loss: 1398.6100481411331
INFO:root:final train perplexity: 3.0155434608459473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 2340.174612491689
INFO:root:eval perplexity: 6.643930912017822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 2890.5409338119184
INFO:root:eval perplexity: 10.76603889465332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [18:57:03<1:39:04, 371.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1421.670541268808
INFO:root:current train perplexity3.0289344787597656
INFO:root:current mean train loss 1396.5867410494586
INFO:root:current train perplexity3.0049099922180176
INFO:root:current mean train loss 1396.0768010479762
INFO:root:current train perplexity2.9976303577423096
INFO:root:current mean train loss 1397.0520975188742
INFO:root:current train perplexity2.999002456665039
INFO:root:current mean train loss 1395.4230256627818
INFO:root:current train perplexity2.9974637031555176
INFO:root:current mean train loss 1396.4513810391218
INFO:root:current train perplexity3.004833698272705
INFO:root:current mean train loss 1396.3721439051285
INFO:root:current train perplexity3.006610870361328
INFO:root:current mean train loss 1397.4639853958906
INFO:root:current train perplexity3.0066864490509033
INFO:root:current mean train loss 1397.6968287107013
INFO:root:current train perplexity3.007863759994507
INFO:root:current mean train loss 1397.3154157290824
INFO:root:current train perplexity3.0076422691345215
INFO:root:current mean train loss 1397.6294538429208
INFO:root:current train perplexity3.010449171066284
INFO:root:current mean train loss 1397.2985617799259
INFO:root:current train perplexity3.0093491077423096
INFO:root:current mean train loss 1397.5405099335587
INFO:root:current train perplexity3.009932518005371
INFO:root:current mean train loss 1397.1976115982068
INFO:root:current train perplexity3.0086915493011475
INFO:root:current mean train loss 1398.0476351379095
INFO:root:current train perplexity3.011204719543457
INFO:root:current mean train loss 1398.0486536132173
INFO:root:current train perplexity3.0115535259246826
INFO:root:current mean train loss 1398.1376650762763
INFO:root:current train perplexity3.0123884677886963
INFO:root:current mean train loss 1397.674090926055
INFO:root:current train perplexity3.0125133991241455
INFO:root:current mean train loss 1397.7546662663135
INFO:root:current train perplexity3.013188123703003
INFO:root:current mean train loss 1397.6141940217346
INFO:root:current train perplexity3.0132596492767334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.34s/it]
INFO:root:final mean train loss: 1397.4092164070871
INFO:root:final train perplexity: 3.0126864910125732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2342.8987383470467
INFO:root:eval perplexity: 6.6585917472839355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 2893.7063273977724
INFO:root:eval perplexity: 10.794092178344727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [19:03:15<1:32:56, 371.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.7602622292259
INFO:root:current train perplexity3.013705253601074
INFO:root:current mean train loss 1392.443009270562
INFO:root:current train perplexity2.997685670852661
INFO:root:current mean train loss 1395.1202052382173
INFO:root:current train perplexity3.0096259117126465
INFO:root:current mean train loss 1399.5389858511992
INFO:root:current train perplexity3.0055789947509766
INFO:root:current mean train loss 1396.7917953353744
INFO:root:current train perplexity3.0009002685546875
INFO:root:current mean train loss 1396.6440315246582
INFO:root:current train perplexity3.001685380935669
INFO:root:current mean train loss 1396.0293768651736
INFO:root:current train perplexity3.004229784011841
INFO:root:current mean train loss 1396.6007357361495
INFO:root:current train perplexity3.0073368549346924
INFO:root:current mean train loss 1396.4307997283213
INFO:root:current train perplexity3.0067238807678223
INFO:root:current mean train loss 1395.9833217556193
INFO:root:current train perplexity3.005688428878784
INFO:root:current mean train loss 1395.8552544253996
INFO:root:current train perplexity3.005305528640747
INFO:root:current mean train loss 1396.4036817217207
INFO:root:current train perplexity3.005397319793701
INFO:root:current mean train loss 1395.8834557241948
INFO:root:current train perplexity3.0062432289123535
INFO:root:current mean train loss 1395.8569772811163
INFO:root:current train perplexity3.007075071334839
INFO:root:current mean train loss 1395.5425512255724
INFO:root:current train perplexity3.006596565246582
INFO:root:current mean train loss 1395.9991608456626
INFO:root:current train perplexity3.0064284801483154
INFO:root:current mean train loss 1395.7141615967391
INFO:root:current train perplexity3.0068278312683105
INFO:root:current mean train loss 1396.20039591658
INFO:root:current train perplexity3.0083110332489014
INFO:root:current mean train loss 1396.328331407394
INFO:root:current train perplexity3.008819580078125
INFO:root:current mean train loss 1396.5064268386905
INFO:root:current train perplexity3.008854389190674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.48s/it]
INFO:root:final mean train loss: 1395.8898594597044
INFO:root:final train perplexity: 3.0090763568878174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2343.0695506427305
INFO:root:eval perplexity: 6.659513473510742
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 2893.7941929161125
INFO:root:eval perplexity: 10.794875144958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [19:09:27<1:26:47, 371.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1389.6895411757173
INFO:root:current train perplexity3.0039772987365723
INFO:root:current mean train loss 1391.4378662109375
INFO:root:current train perplexity3.0100057125091553
INFO:root:current mean train loss 1396.3517860617217
INFO:root:current train perplexity3.0124588012695312
INFO:root:current mean train loss 1395.6434184151012
INFO:root:current train perplexity3.0094516277313232
INFO:root:current mean train loss 1395.9539042905199
INFO:root:current train perplexity3.0101449489593506
INFO:root:current mean train loss 1397.8100962375363
INFO:root:current train perplexity3.0118846893310547
INFO:root:current mean train loss 1396.6711176469719
INFO:root:current train perplexity3.0120081901550293
INFO:root:current mean train loss 1397.3604981752012
INFO:root:current train perplexity3.0104620456695557
INFO:root:current mean train loss 1397.4616042789544
INFO:root:current train perplexity3.009376287460327
INFO:root:current mean train loss 1398.1696960258682
INFO:root:current train perplexity3.010169506072998
INFO:root:current mean train loss 1397.632950562559
INFO:root:current train perplexity3.0116159915924072
INFO:root:current mean train loss 1398.0774574509785
INFO:root:current train perplexity3.011681318283081
INFO:root:current mean train loss 1397.5210064518178
INFO:root:current train perplexity3.0106465816497803
INFO:root:current mean train loss 1397.479001753651
INFO:root:current train perplexity3.0106799602508545
INFO:root:current mean train loss 1397.2033430722215
INFO:root:current train perplexity3.009169340133667
INFO:root:current mean train loss 1397.4153147959541
INFO:root:current train perplexity3.0090506076812744
INFO:root:current mean train loss 1397.0684191975372
INFO:root:current train perplexity3.0095736980438232
INFO:root:current mean train loss 1396.6195864831773
INFO:root:current train perplexity3.00998592376709
INFO:root:current mean train loss 1396.679422238128
INFO:root:current train perplexity3.0093753337860107
INFO:root:current mean train loss 1396.3436340923397
INFO:root:current train perplexity3.0092368125915527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.05s/it]
INFO:root:final mean train loss: 1396.0209906766106
INFO:root:final train perplexity: 3.0093882083892822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 2343.2479274019283
INFO:root:eval perplexity: 6.660473823547363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2893.7815283376276
INFO:root:eval perplexity: 10.794758796691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [19:15:40<1:20:38, 372.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.7718662359775
INFO:root:current train perplexity3.0019819736480713
INFO:root:current mean train loss 1400.6326568260622
INFO:root:current train perplexity3.0000455379486084
INFO:root:current mean train loss 1398.9828798582228
INFO:root:current train perplexity3.006375551223755
INFO:root:current mean train loss 1399.2302908115287
INFO:root:current train perplexity3.0008609294891357
INFO:root:current mean train loss 1398.3127952160696
INFO:root:current train perplexity3.0041518211364746
INFO:root:current mean train loss 1397.0180161420037
INFO:root:current train perplexity3.006615161895752
INFO:root:current mean train loss 1396.1015410746797
INFO:root:current train perplexity3.0083069801330566
INFO:root:current mean train loss 1396.451138140916
INFO:root:current train perplexity3.007079839706421
INFO:root:current mean train loss 1396.3618720191487
INFO:root:current train perplexity3.007033109664917
INFO:root:current mean train loss 1396.1205872455746
INFO:root:current train perplexity3.006495952606201
INFO:root:current mean train loss 1395.3804265802557
INFO:root:current train perplexity3.006201982498169
INFO:root:current mean train loss 1395.6128704802898
INFO:root:current train perplexity3.005943536758423
INFO:root:current mean train loss 1396.2459796075716
INFO:root:current train perplexity3.0078001022338867
INFO:root:current mean train loss 1396.611889311814
INFO:root:current train perplexity3.0061259269714355
INFO:root:current mean train loss 1396.1229783240126
INFO:root:current train perplexity3.006855010986328
INFO:root:current mean train loss 1396.1153310720156
INFO:root:current train perplexity3.007097005844116
INFO:root:current mean train loss 1395.4181812454606
INFO:root:current train perplexity3.006434917449951
INFO:root:current mean train loss 1395.0405784237907
INFO:root:current train perplexity3.0064175128936768
INFO:root:current mean train loss 1395.1722963310785
INFO:root:current train perplexity3.0064122676849365
INFO:root:current mean train loss 1395.6562898672507
INFO:root:current train perplexity3.0076472759246826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.84s/it]
INFO:root:final mean train loss: 1395.3086513071064
INFO:root:final train perplexity: 3.0076963901519775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2341.76011711824
INFO:root:eval perplexity: 6.652461051940918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2893.1172593569927
INFO:root:eval perplexity: 10.788864135742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [19:21:52<1:14:24, 372.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.7987767269738
INFO:root:current train perplexity3.0211665630340576
INFO:root:current mean train loss 1399.0177302433895
INFO:root:current train perplexity3.0114753246307373
INFO:root:current mean train loss 1394.8059284792107
INFO:root:current train perplexity3.007347583770752
INFO:root:current mean train loss 1395.3909195139438
INFO:root:current train perplexity3.0093634128570557
INFO:root:current mean train loss 1395.723369436553
INFO:root:current train perplexity3.0096969604492188
INFO:root:current mean train loss 1395.0214031315652
INFO:root:current train perplexity3.0055103302001953
INFO:root:current mean train loss 1394.7956312879385
INFO:root:current train perplexity3.0031023025512695
INFO:root:current mean train loss 1395.4806066357114
INFO:root:current train perplexity3.000368356704712
INFO:root:current mean train loss 1395.4755399735946
INFO:root:current train perplexity3.001513957977295
INFO:root:current mean train loss 1394.6555895934753
INFO:root:current train perplexity3.0027639865875244
INFO:root:current mean train loss 1394.9460715655323
INFO:root:current train perplexity3.001296043395996
INFO:root:current mean train loss 1395.11810430423
INFO:root:current train perplexity3.0019519329071045
INFO:root:current mean train loss 1394.812211461601
INFO:root:current train perplexity3.003030300140381
INFO:root:current mean train loss 1395.0258690181172
INFO:root:current train perplexity3.003527879714966
INFO:root:current mean train loss 1395.3817264416546
INFO:root:current train perplexity3.003728151321411
INFO:root:current mean train loss 1395.3532997250932
INFO:root:current train perplexity3.0042693614959717
INFO:root:current mean train loss 1395.9154740505162
INFO:root:current train perplexity3.0055344104766846
INFO:root:current mean train loss 1395.8852438413996
INFO:root:current train perplexity3.0059680938720703
INFO:root:current mean train loss 1395.6156103773294
INFO:root:current train perplexity3.0060207843780518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.05s/it]
INFO:root:final mean train loss: 1394.984022178015
INFO:root:final train perplexity: 3.0069260597229004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 2342.9441220980166
INFO:root:eval perplexity: 6.658836841583252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 2894.5377630139074
INFO:root:eval perplexity: 10.801470756530762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [19:28:04<1:08:12, 372.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.5348409016926
INFO:root:current train perplexity3.002092123031616
INFO:root:current mean train loss 1391.1400865827288
INFO:root:current train perplexity3.0048983097076416
INFO:root:current mean train loss 1391.9997253417969
INFO:root:current train perplexity3.011387825012207
INFO:root:current mean train loss 1391.8347833095452
INFO:root:current train perplexity3.011026620864868
INFO:root:current mean train loss 1392.2767769526508
INFO:root:current train perplexity3.00734543800354
INFO:root:current mean train loss 1392.6741466522217
INFO:root:current train perplexity3.0091919898986816
INFO:root:current mean train loss 1392.9866737914242
INFO:root:current train perplexity3.010791778564453
INFO:root:current mean train loss 1393.4489082593595
INFO:root:current train perplexity3.0094237327575684
INFO:root:current mean train loss 1393.4884675124597
INFO:root:current train perplexity3.0068933963775635
INFO:root:current mean train loss 1392.6477772227504
INFO:root:current train perplexity3.004901170730591
INFO:root:current mean train loss 1392.8322864879262
INFO:root:current train perplexity3.0038607120513916
INFO:root:current mean train loss 1392.6950922904255
INFO:root:current train perplexity3.004767417907715
INFO:root:current mean train loss 1393.16506424202
INFO:root:current train perplexity3.0041027069091797
INFO:root:current mean train loss 1393.6430370051687
INFO:root:current train perplexity3.004653215408325
INFO:root:current mean train loss 1393.5154243447626
INFO:root:current train perplexity3.0053439140319824
INFO:root:current mean train loss 1392.1583850194538
INFO:root:current train perplexity3.003856658935547
INFO:root:current mean train loss 1392.793481187844
INFO:root:current train perplexity3.003995180130005
INFO:root:current mean train loss 1393.1321188668223
INFO:root:current train perplexity3.004565477371216
INFO:root:current mean train loss 1393.3709513346355
INFO:root:current train perplexity3.0043461322784424
INFO:root:current mean train loss 1394.2807983653815
INFO:root:current train perplexity3.00435733795166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.37s/it]
INFO:root:final mean train loss: 1394.0110510875645
INFO:root:final train perplexity: 3.0046181678771973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2343.717947019753
INFO:root:eval perplexity: 6.663008689880371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2894.7402802595857
INFO:root:eval perplexity: 10.803271293640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [19:34:15<1:01:57, 371.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1405.8733288995152
INFO:root:current train perplexity2.9834117889404297
INFO:root:current mean train loss 1395.1226626847142
INFO:root:current train perplexity2.9808297157287598
INFO:root:current mean train loss 1393.5956562158842
INFO:root:current train perplexity2.995151996612549
INFO:root:current mean train loss 1392.6745186199896
INFO:root:current train perplexity3.002535343170166
INFO:root:current mean train loss 1393.9976248930107
INFO:root:current train perplexity3.001816987991333
INFO:root:current mean train loss 1393.3816167186023
INFO:root:current train perplexity3.001997709274292
INFO:root:current mean train loss 1392.5960966998707
INFO:root:current train perplexity3.0018811225891113
INFO:root:current mean train loss 1392.0897982038753
INFO:root:current train perplexity3.0007004737854004
INFO:root:current mean train loss 1391.356378902716
INFO:root:current train perplexity3.0003151893615723
INFO:root:current mean train loss 1391.9544245429393
INFO:root:current train perplexity2.999819755554199
INFO:root:current mean train loss 1393.0333504635114
INFO:root:current train perplexity3.0015077590942383
INFO:root:current mean train loss 1393.31451259238
INFO:root:current train perplexity3.001436710357666
INFO:root:current mean train loss 1393.5583606344399
INFO:root:current train perplexity3.001681089401245
INFO:root:current mean train loss 1394.2646419160612
INFO:root:current train perplexity3.0028038024902344
INFO:root:current mean train loss 1394.1283798698282
INFO:root:current train perplexity3.004002332687378
INFO:root:current mean train loss 1393.8236958196228
INFO:root:current train perplexity3.003427743911743
INFO:root:current mean train loss 1394.1025123104425
INFO:root:current train perplexity3.005152463912964
INFO:root:current mean train loss 1393.7231114896617
INFO:root:current train perplexity3.0045361518859863
INFO:root:current mean train loss 1393.734250727216
INFO:root:current train perplexity3.0045368671417236
INFO:root:current mean train loss 1393.9559172397453
INFO:root:current train perplexity3.0042426586151123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.62s/it]
INFO:root:final mean train loss: 1394.0891761183439
INFO:root:final train perplexity: 3.00480318069458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2344.2903148028868
INFO:root:eval perplexity: 6.66609525680542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 2895.5005584067485
INFO:root:eval perplexity: 10.810026168823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [19:40:26<55:45, 371.67s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1393.780398161515
INFO:root:current train perplexity3.0163888931274414
INFO:root:current mean train loss 1394.0869901474207
INFO:root:current train perplexity3.0039405822753906
INFO:root:current mean train loss 1396.2922139981897
INFO:root:current train perplexity2.996192216873169
INFO:root:current mean train loss 1395.5575625028225
INFO:root:current train perplexity2.999675750732422
INFO:root:current mean train loss 1395.7006740142413
INFO:root:current train perplexity2.999936103820801
INFO:root:current mean train loss 1394.3167357951293
INFO:root:current train perplexity2.9991836547851562
INFO:root:current mean train loss 1393.3845910228813
INFO:root:current train perplexity2.9996235370635986
INFO:root:current mean train loss 1394.0836631631723
INFO:root:current train perplexity2.997063636779785
INFO:root:current mean train loss 1394.16423824662
INFO:root:current train perplexity2.9988906383514404
INFO:root:current mean train loss 1393.2945105006277
INFO:root:current train perplexity2.9982645511627197
INFO:root:current mean train loss 1392.5718345277396
INFO:root:current train perplexity2.9980275630950928
INFO:root:current mean train loss 1392.2852663902297
INFO:root:current train perplexity2.998483419418335
INFO:root:current mean train loss 1392.6469951892932
INFO:root:current train perplexity2.999851703643799
INFO:root:current mean train loss 1392.5170734286485
INFO:root:current train perplexity3.0015342235565186
INFO:root:current mean train loss 1392.86250822244
INFO:root:current train perplexity3.0039620399475098
INFO:root:current mean train loss 1393.0553410420289
INFO:root:current train perplexity3.0030558109283447
INFO:root:current mean train loss 1393.3109526883354
INFO:root:current train perplexity3.002445697784424
INFO:root:current mean train loss 1393.4312939201434
INFO:root:current train perplexity3.002296209335327
INFO:root:current mean train loss 1393.9276082709448
INFO:root:current train perplexity3.0024831295013428
INFO:root:current mean train loss 1394.2016028848238
INFO:root:current train perplexity3.003908157348633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.30s/it]
INFO:root:final mean train loss: 1393.991118753792
INFO:root:final train perplexity: 3.0045711994171143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2344.5701151097073
INFO:root:eval perplexity: 6.667605400085449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 2895.925624982685
INFO:root:eval perplexity: 10.81380558013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [19:46:38<49:32, 371.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1394.9420282273065
INFO:root:current train perplexity2.9891388416290283
INFO:root:current mean train loss 1394.9820024923313
INFO:root:current train perplexity2.9935083389282227
INFO:root:current mean train loss 1396.8670765691836
INFO:root:current train perplexity2.9999120235443115
INFO:root:current mean train loss 1394.7065957650009
INFO:root:current train perplexity3.0091545581817627
INFO:root:current mean train loss 1394.5416565600533
INFO:root:current train perplexity3.0103559494018555
INFO:root:current mean train loss 1393.813563724606
INFO:root:current train perplexity3.009148597717285
INFO:root:current mean train loss 1392.5851607056584
INFO:root:current train perplexity3.0057027339935303
INFO:root:current mean train loss 1393.0128764181275
INFO:root:current train perplexity3.0021684169769287
INFO:root:current mean train loss 1393.4841387805077
INFO:root:current train perplexity3.0036206245422363
INFO:root:current mean train loss 1393.5931368597076
INFO:root:current train perplexity3.0034446716308594
INFO:root:current mean train loss 1393.5318860747516
INFO:root:current train perplexity3.002673864364624
INFO:root:current mean train loss 1393.2300599246628
INFO:root:current train perplexity3.0022449493408203
INFO:root:current mean train loss 1392.7955426648791
INFO:root:current train perplexity3.0017852783203125
INFO:root:current mean train loss 1393.145064042582
INFO:root:current train perplexity3.002420425415039
INFO:root:current mean train loss 1393.3633500866424
INFO:root:current train perplexity3.001251220703125
INFO:root:current mean train loss 1392.8331808040177
INFO:root:current train perplexity3.0013301372528076
INFO:root:current mean train loss 1392.9366131367915
INFO:root:current train perplexity3.001246213912964
INFO:root:current mean train loss 1393.25478774583
INFO:root:current train perplexity3.0027916431427
INFO:root:current mean train loss 1393.506355125931
INFO:root:current train perplexity3.0023653507232666
INFO:root:current mean train loss 1393.4369266488634
INFO:root:current train perplexity3.0019469261169434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.30s/it]
INFO:root:final mean train loss: 1392.8332466591023
INFO:root:final train perplexity: 3.001826763153076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 2345.2174660973515
INFO:root:eval perplexity: 6.671098232269287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 2896.7256127756536
INFO:root:eval perplexity: 10.820920944213867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [19:52:49<43:19, 371.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1406.2292556762695
INFO:root:current train perplexity3.019927978515625
INFO:root:current mean train loss 1399.4097635904948
INFO:root:current train perplexity3.0030171871185303
INFO:root:current mean train loss 1400.2717912946428
INFO:root:current train perplexity3.0062432289123535
INFO:root:current mean train loss 1401.250837787829
INFO:root:current train perplexity3.0032544136047363
INFO:root:current mean train loss 1399.5188362121582
INFO:root:current train perplexity3.0033392906188965
INFO:root:current mean train loss 1396.6784202838767
INFO:root:current train perplexity3.004814624786377
INFO:root:current mean train loss 1396.8623129451976
INFO:root:current train perplexity3.004138946533203
INFO:root:current mean train loss 1398.1221521622094
INFO:root:current train perplexity3.0072524547576904
INFO:root:current mean train loss 1397.2311474886808
INFO:root:current train perplexity3.0067169666290283
INFO:root:current mean train loss 1396.143177141462
INFO:root:current train perplexity3.0066442489624023
INFO:root:current mean train loss 1395.4941444679544
INFO:root:current train perplexity3.005345344543457
INFO:root:current mean train loss 1395.2198940471067
INFO:root:current train perplexity3.004348039627075
INFO:root:current mean train loss 1395.5098103523255
INFO:root:current train perplexity3.0048844814300537
INFO:root:current mean train loss 1395.583386495839
INFO:root:current train perplexity3.0049383640289307
INFO:root:current mean train loss 1395.0254219673775
INFO:root:current train perplexity3.002920389175415
INFO:root:current mean train loss 1394.3442877274526
INFO:root:current train perplexity3.0014331340789795
INFO:root:current mean train loss 1394.2051041376023
INFO:root:current train perplexity3.0019469261169434
INFO:root:current mean train loss 1394.021865124649
INFO:root:current train perplexity3.0015876293182373
INFO:root:current mean train loss 1394.2927573995387
INFO:root:current train perplexity3.0026626586914062
INFO:root:current mean train loss 1393.8311861905186
INFO:root:current train perplexity3.003182888031006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.36s/it]
INFO:root:final mean train loss: 1393.413165594073
INFO:root:final train perplexity: 3.0032007694244385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2345.078432773022
INFO:root:eval perplexity: 6.670348167419434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2896.73479921598
INFO:root:eval perplexity: 10.820998191833496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [19:59:00<37:07, 371.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.2088786646264
INFO:root:current train perplexity3.012878656387329
INFO:root:current mean train loss 1389.6999455950586
INFO:root:current train perplexity3.0038952827453613
INFO:root:current mean train loss 1391.182963258891
INFO:root:current train perplexity3.006988763809204
INFO:root:current mean train loss 1390.2958775287311
INFO:root:current train perplexity3.0004281997680664
INFO:root:current mean train loss 1389.6361327142542
INFO:root:current train perplexity3.001836061477661
INFO:root:current mean train loss 1391.1797337108721
INFO:root:current train perplexity3.001163959503174
INFO:root:current mean train loss 1391.188475861953
INFO:root:current train perplexity3.0013716220855713
INFO:root:current mean train loss 1392.8830249360394
INFO:root:current train perplexity3.00169038772583
INFO:root:current mean train loss 1393.6634609941123
INFO:root:current train perplexity2.9994001388549805
INFO:root:current mean train loss 1394.6491554742352
INFO:root:current train perplexity3.0017199516296387
INFO:root:current mean train loss 1394.1297063279826
INFO:root:current train perplexity3.0007405281066895
INFO:root:current mean train loss 1393.3927963626513
INFO:root:current train perplexity3.0007340908050537
INFO:root:current mean train loss 1393.1020418400938
INFO:root:current train perplexity2.999969720840454
INFO:root:current mean train loss 1393.4401549637616
INFO:root:current train perplexity2.9979844093322754
INFO:root:current mean train loss 1393.789280383684
INFO:root:current train perplexity2.9986581802368164
INFO:root:current mean train loss 1392.7806125896457
INFO:root:current train perplexity2.998429298400879
INFO:root:current mean train loss 1392.3268473978667
INFO:root:current train perplexity2.9986367225646973
INFO:root:current mean train loss 1392.563999352219
INFO:root:current train perplexity3.0004119873046875
INFO:root:current mean train loss 1392.835386671389
INFO:root:current train perplexity3.0009989738464355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.76s/it]
INFO:root:final mean train loss: 1392.2673785218794
INFO:root:final train perplexity: 3.000486135482788
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 2345.445936703513
INFO:root:eval perplexity: 6.672331809997559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2897.3233508387357
INFO:root:eval perplexity: 10.826236724853516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [20:05:09<30:53, 370.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1391.0446515764509
INFO:root:current train perplexity3.022275686264038
INFO:root:current mean train loss 1383.7482042814556
INFO:root:current train perplexity2.987921714782715
INFO:root:current mean train loss 1384.8382836457724
INFO:root:current train perplexity2.9922492504119873
INFO:root:current mean train loss 1386.4264588568622
INFO:root:current train perplexity2.996119737625122
INFO:root:current mean train loss 1388.4739807423762
INFO:root:current train perplexity2.9944727420806885
INFO:root:current mean train loss 1389.3137104910172
INFO:root:current train perplexity2.9974143505096436
INFO:root:current mean train loss 1389.094680239401
INFO:root:current train perplexity2.999650716781616
INFO:root:current mean train loss 1389.6621781036633
INFO:root:current train perplexity3.001206636428833
INFO:root:current mean train loss 1389.4889569856612
INFO:root:current train perplexity2.9960334300994873
INFO:root:current mean train loss 1388.6997571148027
INFO:root:current train perplexity2.997082233428955
INFO:root:current mean train loss 1389.009165385771
INFO:root:current train perplexity2.995790481567383
INFO:root:current mean train loss 1389.2623468532597
INFO:root:current train perplexity2.9963936805725098
INFO:root:current mean train loss 1389.335974603744
INFO:root:current train perplexity2.9965267181396484
INFO:root:current mean train loss 1389.429743518568
INFO:root:current train perplexity2.9955694675445557
INFO:root:current mean train loss 1389.5619064827451
INFO:root:current train perplexity2.9951419830322266
INFO:root:current mean train loss 1390.5856250677273
INFO:root:current train perplexity2.995945930480957
INFO:root:current mean train loss 1390.8474240592568
INFO:root:current train perplexity2.9971814155578613
INFO:root:current mean train loss 1391.026309784541
INFO:root:current train perplexity2.997913360595703
INFO:root:current mean train loss 1391.0628202495134
INFO:root:current train perplexity2.997459888458252
INFO:root:current mean train loss 1391.2706450618796
INFO:root:current train perplexity2.997737169265747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.79s/it]
INFO:root:final mean train loss: 1390.9928819095614
INFO:root:final train perplexity: 2.997469902038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2345.9986178350787
INFO:root:eval perplexity: 6.67531681060791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2897.677957304826
INFO:root:eval perplexity: 10.829394340515137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [20:11:20<24:42, 370.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1379.2837110950102
INFO:root:current train perplexity3.0410714149475098
INFO:root:current mean train loss 1396.5332897856035
INFO:root:current train perplexity3.0108916759490967
INFO:root:current mean train loss 1398.4110863095239
INFO:root:current train perplexity3.014061689376831
INFO:root:current mean train loss 1394.990981179782
INFO:root:current train perplexity3.004744529724121
INFO:root:current mean train loss 1395.2388893357563
INFO:root:current train perplexity3.0026919841766357
INFO:root:current mean train loss 1393.9144838839602
INFO:root:current train perplexity3.002598285675049
INFO:root:current mean train loss 1393.7193268837907
INFO:root:current train perplexity3.004232406616211
INFO:root:current mean train loss 1394.791116821456
INFO:root:current train perplexity3.0030086040496826
INFO:root:current mean train loss 1394.2244900957055
INFO:root:current train perplexity3.000674247741699
INFO:root:current mean train loss 1392.9797573069113
INFO:root:current train perplexity2.9995579719543457
INFO:root:current mean train loss 1392.1725606539085
INFO:root:current train perplexity2.9994564056396484
INFO:root:current mean train loss 1391.7895870461705
INFO:root:current train perplexity2.998183250427246
INFO:root:current mean train loss 1392.0623715832212
INFO:root:current train perplexity2.9993178844451904
INFO:root:current mean train loss 1392.1257501225289
INFO:root:current train perplexity3.001286745071411
INFO:root:current mean train loss 1392.0229664501987
INFO:root:current train perplexity3.0004889965057373
INFO:root:current mean train loss 1392.405553377975
INFO:root:current train perplexity3.0015933513641357
INFO:root:current mean train loss 1392.1654640258564
INFO:root:current train perplexity3.0006768703460693
INFO:root:current mean train loss 1392.1532369577285
INFO:root:current train perplexity3.0003890991210938
INFO:root:current mean train loss 1392.4452708987576
INFO:root:current train perplexity3.000277519226074
INFO:root:current mean train loss 1392.3033385945996
INFO:root:current train perplexity3.0001235008239746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.45s/it]
INFO:root:final mean train loss: 1392.1554352745407
INFO:root:final train perplexity: 3.0002214908599854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2346.101550812417
INFO:root:eval perplexity: 6.6758713722229
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 2898.0978475800644
INFO:root:eval perplexity: 10.833130836486816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [20:17:30<18:31, 370.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.1678110758464
INFO:root:current train perplexity2.987830877304077
INFO:root:current mean train loss 1392.7166599582981
INFO:root:current train perplexity2.9930903911590576
INFO:root:current mean train loss 1390.171644641507
INFO:root:current train perplexity2.9961986541748047
INFO:root:current mean train loss 1394.627172360475
INFO:root:current train perplexity2.995760440826416
INFO:root:current mean train loss 1393.1867931910924
INFO:root:current train perplexity2.9979641437530518
INFO:root:current mean train loss 1392.9420644941122
INFO:root:current train perplexity2.998809814453125
INFO:root:current mean train loss 1392.417574847186
INFO:root:current train perplexity2.999753952026367
INFO:root:current mean train loss 1391.8710488712086
INFO:root:current train perplexity3.0022342205047607
INFO:root:current mean train loss 1392.17077334422
INFO:root:current train perplexity2.999582290649414
INFO:root:current mean train loss 1392.495027695024
INFO:root:current train perplexity2.9975380897521973
INFO:root:current mean train loss 1393.0852019331837
INFO:root:current train perplexity2.99786114692688
INFO:root:current mean train loss 1392.296408091688
INFO:root:current train perplexity2.9998154640197754
INFO:root:current mean train loss 1392.2596805279072
INFO:root:current train perplexity2.999596357345581
INFO:root:current mean train loss 1392.9118621554503
INFO:root:current train perplexity3.000720500946045
INFO:root:current mean train loss 1393.1403788361101
INFO:root:current train perplexity2.9985594749450684
INFO:root:current mean train loss 1392.9891109022983
INFO:root:current train perplexity2.997431516647339
INFO:root:current mean train loss 1392.944608521693
INFO:root:current train perplexity2.997694969177246
INFO:root:current mean train loss 1392.5110062308934
INFO:root:current train perplexity2.9971442222595215
INFO:root:current mean train loss 1392.7087681097385
INFO:root:current train perplexity2.9984540939331055
INFO:root:current mean train loss 1392.1973509739557
INFO:root:current train perplexity2.99857234954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.19s/it]
INFO:root:final mean train loss: 1391.4790186494874
INFO:root:final train perplexity: 2.998619556427002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2346.023085141013
INFO:root:eval perplexity: 6.675448894500732
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2898.0399849533187
INFO:root:eval perplexity: 10.832616806030273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [20:23:39<12:20, 370.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1391.9785663311297
INFO:root:current train perplexity2.9841582775115967
INFO:root:current mean train loss 1391.1604654947917
INFO:root:current train perplexity2.986966371536255
INFO:root:current mean train loss 1391.0084108748526
INFO:root:current train perplexity2.9877517223358154
INFO:root:current mean train loss 1393.6270009498073
INFO:root:current train perplexity2.9927070140838623
INFO:root:current mean train loss 1393.908765435988
INFO:root:current train perplexity2.9944260120391846
INFO:root:current mean train loss 1393.5254273541207
INFO:root:current train perplexity2.9952805042266846
INFO:root:current mean train loss 1393.5584111034423
INFO:root:current train perplexity2.9973483085632324
INFO:root:current mean train loss 1393.6320293351716
INFO:root:current train perplexity2.996927499771118
INFO:root:current mean train loss 1394.1065534117595
INFO:root:current train perplexity2.996586561203003
INFO:root:current mean train loss 1394.7094611449563
INFO:root:current train perplexity2.9991984367370605
INFO:root:current mean train loss 1393.9085210809126
INFO:root:current train perplexity3.0001745223999023
INFO:root:current mean train loss 1393.7888430877817
INFO:root:current train perplexity3.0009186267852783
INFO:root:current mean train loss 1392.6516920006793
INFO:root:current train perplexity3.000753402709961
INFO:root:current mean train loss 1392.464891773266
INFO:root:current train perplexity2.999826669692993
INFO:root:current mean train loss 1392.3576829304875
INFO:root:current train perplexity2.9971911907196045
INFO:root:current mean train loss 1392.134827713159
INFO:root:current train perplexity2.9972083568573
INFO:root:current mean train loss 1391.9572833820148
INFO:root:current train perplexity2.997692346572876
INFO:root:current mean train loss 1391.8309944477028
INFO:root:current train perplexity2.9986846446990967
INFO:root:current mean train loss 1391.5349730463513
INFO:root:current train perplexity2.9983010292053223
INFO:root:current mean train loss 1391.9088316783952
INFO:root:current train perplexity2.998278856277466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.16s/it]
INFO:root:final mean train loss: 1391.4931795444384
INFO:root:final train perplexity: 2.9986536502838135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2345.940443972324
INFO:root:eval perplexity: 6.6750006675720215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 2897.9607266906305
INFO:root:eval perplexity: 10.831914901733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [20:29:49<06:10, 370.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1378.3487325528772
INFO:root:current train perplexity2.9899380207061768
INFO:root:current mean train loss 1383.8699501792153
INFO:root:current train perplexity2.985802412033081
INFO:root:current mean train loss 1386.934085927111
INFO:root:current train perplexity2.9881389141082764
INFO:root:current mean train loss 1387.896605486645
INFO:root:current train perplexity2.9875173568725586
INFO:root:current mean train loss 1387.6216418001168
INFO:root:current train perplexity2.988325595855713
INFO:root:current mean train loss 1388.7258112012726
INFO:root:current train perplexity2.991367816925049
INFO:root:current mean train loss 1389.5506106737423
INFO:root:current train perplexity2.9912660121917725
INFO:root:current mean train loss 1389.481546153193
INFO:root:current train perplexity2.991935968399048
INFO:root:current mean train loss 1391.0774754807521
INFO:root:current train perplexity2.9937856197357178
INFO:root:current mean train loss 1390.9901275945535
INFO:root:current train perplexity2.9947097301483154
INFO:root:current mean train loss 1390.3424886819837
INFO:root:current train perplexity2.994624376296997
INFO:root:current mean train loss 1391.0638522746801
INFO:root:current train perplexity2.993548631668091
INFO:root:current mean train loss 1391.1419568232925
INFO:root:current train perplexity2.995354175567627
INFO:root:current mean train loss 1390.8649370604762
INFO:root:current train perplexity2.9948856830596924
INFO:root:current mean train loss 1391.0250595030998
INFO:root:current train perplexity2.994699001312256
INFO:root:current mean train loss 1390.9210239029412
INFO:root:current train perplexity2.9951770305633545
INFO:root:current mean train loss 1391.2232340881856
INFO:root:current train perplexity2.995004653930664
INFO:root:current mean train loss 1391.2098654459087
INFO:root:current train perplexity2.996680498123169
INFO:root:current mean train loss 1391.342066246949
INFO:root:current train perplexity2.997572660446167
INFO:root:current mean train loss 1391.6838890714673
INFO:root:current train perplexity2.9982264041900635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.36s/it]
INFO:root:final mean train loss: 1391.3053730143722
INFO:root:final train perplexity: 2.998209238052368
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 2346.1718975094195
INFO:root:eval perplexity: 6.676253318786621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2898.2274247839096
INFO:root:eval perplexity: 10.834288597106934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_baseline/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [20:35:59<00:00, 370.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [20:35:59<00:00, 370.80s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 2346.1718975094195
INFO:root:eval perplexity: 6.676253318786621
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 2898.2274247839096
INFO:root:eval perplexity: 10.834288597106934
INFO:root:evalaution complete
INFO:root:save model final: distilroberta_baseline/final
