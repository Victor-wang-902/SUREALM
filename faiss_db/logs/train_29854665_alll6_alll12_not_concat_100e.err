INFO:root:Output: alll6_alll12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11646.515052872475
INFO:root:current train perplexity10211.578125
INFO:root:current mean train loss 9678.924083307162
INFO:root:current train perplexity2133.94189453125
INFO:root:current mean train loss 8520.389748053407
INFO:root:current train perplexity852.4219970703125
INFO:root:current mean train loss 7708.0116587856355
INFO:root:current train perplexity441.2388000488281
INFO:root:current mean train loss 7090.569161271762
INFO:root:current train perplexity270.895263671875
INFO:root:current mean train loss 6613.928208798518
INFO:root:current train perplexity185.970458984375
INFO:root:current mean train loss 6238.580906596477
INFO:root:current train perplexity137.93408203125
INFO:root:current mean train loss 5941.367113555029
INFO:root:current train perplexity108.4979019165039
INFO:root:current mean train loss 5690.235598961955
INFO:root:current train perplexity89.06122589111328
INFO:root:current mean train loss 5476.1302401033845
INFO:root:current train perplexity75.30754852294922
INFO:root:current mean train loss 5294.455915622867
INFO:root:current train perplexity65.12823486328125
INFO:root:current mean train loss 5136.727317523718
INFO:root:current train perplexity57.51072311401367
INFO:root:current mean train loss 4997.557114810371
INFO:root:current train perplexity51.510433197021484
INFO:root:current mean train loss 4873.9371289900155
INFO:root:current train perplexity46.73332977294922
INFO:root:current mean train loss 4762.991543841727
INFO:root:current train perplexity42.846458435058594
INFO:root:current mean train loss 4664.042197241196
INFO:root:current train perplexity39.59152603149414
INFO:root:current mean train loss 4573.38531583951
INFO:root:current train perplexity36.85297775268555
INFO:root:current mean train loss 4491.968680109827
INFO:root:current train perplexity34.54975891113281
INFO:root:current mean train loss 4417.208360202944
INFO:root:current train perplexity32.561378479003906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.13s/it]
INFO:root:final mean train loss: 4356.8663435343
INFO:root:final train perplexity: 31.06515884399414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2812.427710999834
INFO:root:eval perplexity: 9.723312377929688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 3114.446544890708
INFO:root:eval perplexity: 12.76976203918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/1
  1%|          | 1/100 [09:38<15:55:14, 578.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2964.178970336914
INFO:root:current train perplexity10.358381271362305
INFO:root:current mean train loss 3006.114798710264
INFO:root:current train perplexity10.56583309173584
INFO:root:current mean train loss 2984.3332542136864
INFO:root:current train perplexity10.420694351196289
INFO:root:current mean train loss 2968.02916167054
INFO:root:current train perplexity10.29181957244873
INFO:root:current mean train loss 2947.4741392869214
INFO:root:current train perplexity10.134849548339844
INFO:root:current mean train loss 2932.1442880556565
INFO:root:current train perplexity10.043510437011719
INFO:root:current mean train loss 2920.883136699726
INFO:root:current train perplexity9.967988967895508
INFO:root:current mean train loss 2906.7879417035833
INFO:root:current train perplexity9.870444297790527
INFO:root:current mean train loss 2893.4081519631777
INFO:root:current train perplexity9.77921199798584
INFO:root:current mean train loss 2886.6129670122305
INFO:root:current train perplexity9.713605880737305
INFO:root:current mean train loss 2873.8606411190485
INFO:root:current train perplexity9.62048625946045
INFO:root:current mean train loss 2862.899828401518
INFO:root:current train perplexity9.543539047241211
INFO:root:current mean train loss 2853.1378288269043
INFO:root:current train perplexity9.478888511657715
INFO:root:current mean train loss 2844.5732842999028
INFO:root:current train perplexity9.410761833190918
INFO:root:current mean train loss 2838.058298057082
INFO:root:current train perplexity9.352118492126465
INFO:root:current mean train loss 2828.0964999639264
INFO:root:current train perplexity9.289579391479492
INFO:root:current mean train loss 2819.220428617874
INFO:root:current train perplexity9.230636596679688
INFO:root:current mean train loss 2811.4205249706347
INFO:root:current train perplexity9.166765213012695
INFO:root:current mean train loss 2801.5836584956637
INFO:root:current train perplexity9.098888397216797
INFO:root:current mean train loss 2794.416784871844
INFO:root:current train perplexity9.051838874816895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.62s/it]
INFO:root:final mean train loss: 2788.4232532926358
INFO:root:final train perplexity: 9.017060279846191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2489.091175268728
INFO:root:eval perplexity: 7.485969543457031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it]
INFO:root:eval mean loss: 2834.1673363218915
INFO:root:eval perplexity: 10.15392017364502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/2
  2%|â–         | 2/100 [19:30<15:57:36, 586.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2603.203702059659
INFO:root:current train perplexity7.8420233726501465
INFO:root:current mean train loss 2614.0613141741073
INFO:root:current train perplexity7.859777450561523
INFO:root:current mean train loss 2604.025898814713
INFO:root:current train perplexity7.8310747146606445
INFO:root:current mean train loss 2606.2766773120775
INFO:root:current train perplexity7.799132823944092
INFO:root:current mean train loss 2603.305241749964
INFO:root:current train perplexity7.78897762298584
INFO:root:current mean train loss 2598.4001414458257
INFO:root:current train perplexity7.750075340270996
INFO:root:current mean train loss 2591.90745681835
INFO:root:current train perplexity7.720641136169434
INFO:root:current mean train loss 2589.472889399301
INFO:root:current train perplexity7.695319175720215
INFO:root:current mean train loss 2585.255720745329
INFO:root:current train perplexity7.66937255859375
INFO:root:current mean train loss 2578.7635664209038
INFO:root:current train perplexity7.635269641876221
INFO:root:current mean train loss 2571.839209882472
INFO:root:current train perplexity7.601083278656006
INFO:root:current mean train loss 2565.236203361168
INFO:root:current train perplexity7.563555717468262
INFO:root:current mean train loss 2561.1696933767994
INFO:root:current train perplexity7.541839122772217
INFO:root:current mean train loss 2556.359018221352
INFO:root:current train perplexity7.509834289550781
INFO:root:current mean train loss 2552.4729460498625
INFO:root:current train perplexity7.483974456787109
INFO:root:current mean train loss 2547.0175195185093
INFO:root:current train perplexity7.452991485595703
INFO:root:current mean train loss 2543.299671628617
INFO:root:current train perplexity7.426384925842285
INFO:root:current mean train loss 2540.0071503759737
INFO:root:current train perplexity7.406454086303711
INFO:root:current mean train loss 2537.2768875679812
INFO:root:current train perplexity7.39135217666626
INFO:root:current mean train loss 2533.875471735765
INFO:root:current train perplexity7.370418071746826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.25s/it]
INFO:root:final mean train loss: 2531.4817896702048
INFO:root:final train perplexity: 7.363084316253662
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2337.245063944066
INFO:root:eval perplexity: 6.620870590209961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it]
INFO:root:eval mean loss: 2700.6543107269504
INFO:root:eval perplexity: 9.103592872619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/3
  3%|â–Ž         | 3/100 [29:08<15:41:48, 582.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2411.9931201171876
INFO:root:current train perplexity6.7818498611450195
INFO:root:current mean train loss 2423.4133447265626
INFO:root:current train perplexity6.832055568695068
INFO:root:current mean train loss 2434.372984375
INFO:root:current train perplexity6.824085235595703
INFO:root:current mean train loss 2437.407936314174
INFO:root:current train perplexity6.801154136657715
INFO:root:current mean train loss 2437.1385956488716
INFO:root:current train perplexity6.802287578582764
INFO:root:current mean train loss 2431.1029427823155
INFO:root:current train perplexity6.785728931427002
INFO:root:current mean train loss 2427.2662563852164
INFO:root:current train perplexity6.779331684112549
INFO:root:current mean train loss 2422.112020182292
INFO:root:current train perplexity6.767673969268799
INFO:root:current mean train loss 2421.2400241268383
INFO:root:current train perplexity6.750279426574707
INFO:root:current mean train loss 2417.926851485403
INFO:root:current train perplexity6.732248783111572
INFO:root:current mean train loss 2413.6896769205728
INFO:root:current train perplexity6.726294994354248
INFO:root:current mean train loss 2414.796874681556
INFO:root:current train perplexity6.729366779327393
INFO:root:current mean train loss 2416.0960512695315
INFO:root:current train perplexity6.7305755615234375
INFO:root:current mean train loss 2415.9102342845777
INFO:root:current train perplexity6.72703742980957
INFO:root:current mean train loss 2416.3537980704473
INFO:root:current train perplexity6.721200466156006
INFO:root:current mean train loss 2416.297770208543
INFO:root:current train perplexity6.725172519683838
INFO:root:current mean train loss 2416.4763455847537
INFO:root:current train perplexity6.722081661224365
INFO:root:current mean train loss 2415.707482421875
INFO:root:current train perplexity6.715937614440918
INFO:root:current mean train loss 2413.948776657517
INFO:root:current train perplexity6.7113142013549805
INFO:root:current mean train loss 2412.8315322015224
INFO:root:current train perplexity6.702495098114014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.31s/it]
INFO:root:final mean train loss: 2411.7009615914963
INFO:root:final train perplexity: 6.6993632316589355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2265.5533871481603
INFO:root:eval perplexity: 6.2479071617126465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.50s/it]
INFO:root:eval mean loss: 2641.210772575216
INFO:root:eval perplexity: 8.671611785888672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/4
  4%|â–         | 4/100 [38:44<15:28:15, 580.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2387.146426072761
INFO:root:current train perplexity6.503053188323975
INFO:root:current mean train loss 2364.3125577458363
INFO:root:current train perplexity6.4106316566467285
INFO:root:current mean train loss 2361.3108417639573
INFO:root:current train perplexity6.424666404724121
INFO:root:current mean train loss 2356.229885673003
INFO:root:current train perplexity6.40671968460083
INFO:root:current mean train loss 2359.9063056766095
INFO:root:current train perplexity6.435335636138916
INFO:root:current mean train loss 2361.1842129285164
INFO:root:current train perplexity6.427660942077637
INFO:root:current mean train loss 2357.965921885249
INFO:root:current train perplexity6.42155647277832
INFO:root:current mean train loss 2360.269175065698
INFO:root:current train perplexity6.421417236328125
INFO:root:current mean train loss 2357.532434940888
INFO:root:current train perplexity6.415651798248291
INFO:root:current mean train loss 2356.1485887308527
INFO:root:current train perplexity6.405229568481445
INFO:root:current mean train loss 2355.4176416656296
INFO:root:current train perplexity6.400209903717041
INFO:root:current mean train loss 2352.4706862841085
INFO:root:current train perplexity6.384034156799316
INFO:root:current mean train loss 2352.82709592896
INFO:root:current train perplexity6.380093574523926
INFO:root:current mean train loss 2350.1834094390088
INFO:root:current train perplexity6.374094009399414
INFO:root:current mean train loss 2347.659850616559
INFO:root:current train perplexity6.359951496124268
INFO:root:current mean train loss 2347.2072369856064
INFO:root:current train perplexity6.35501766204834
INFO:root:current mean train loss 2344.0275587460633
INFO:root:current train perplexity6.3470892906188965
INFO:root:current mean train loss 2344.6396164519
INFO:root:current train perplexity6.3438944816589355
INFO:root:current mean train loss 2342.987611595934
INFO:root:current train perplexity6.3401079177856445
INFO:root:current mean train loss 2341.7085546775706
INFO:root:current train perplexity6.335367202758789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.50s/it]
INFO:root:final mean train loss: 2340.528554419105
INFO:root:final train perplexity: 6.333681106567383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2199.9388678800974
INFO:root:eval perplexity: 5.925004005432129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2584.525633467005
INFO:root:eval perplexity: 8.278783798217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/5
  5%|â–Œ         | 5/100 [48:21<15:16:21, 578.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2290.6693681989395
INFO:root:current train perplexity6.143963813781738
INFO:root:current mean train loss 2307.9046445100203
INFO:root:current train perplexity6.140380382537842
INFO:root:current mean train loss 2295.8002701880228
INFO:root:current train perplexity6.103211402893066
INFO:root:current mean train loss 2294.5237668355308
INFO:root:current train perplexity6.108198642730713
INFO:root:current mean train loss 2289.7444753095137
INFO:root:current train perplexity6.100461483001709
INFO:root:current mean train loss 2292.3794731244648
INFO:root:current train perplexity6.093489646911621
INFO:root:current mean train loss 2287.051577027081
INFO:root:current train perplexity6.080531597137451
INFO:root:current mean train loss 2284.029693292112
INFO:root:current train perplexity6.0667500495910645
INFO:root:current mean train loss 2283.9272835157576
INFO:root:current train perplexity6.0609612464904785
INFO:root:current mean train loss 2280.378701931093
INFO:root:current train perplexity6.050023078918457
INFO:root:current mean train loss 2279.5183897124007
INFO:root:current train perplexity6.042546272277832
INFO:root:current mean train loss 2279.124756271775
INFO:root:current train perplexity6.036101341247559
INFO:root:current mean train loss 2278.764451451762
INFO:root:current train perplexity6.028913497924805
INFO:root:current mean train loss 2277.498842713461
INFO:root:current train perplexity6.023233413696289
INFO:root:current mean train loss 2274.796572374205
INFO:root:current train perplexity6.019155025482178
INFO:root:current mean train loss 2272.7900968609433
INFO:root:current train perplexity6.011246681213379
INFO:root:current mean train loss 2272.6057101360693
INFO:root:current train perplexity6.007026672363281
INFO:root:current mean train loss 2272.133983321254
INFO:root:current train perplexity6.001089572906494
INFO:root:current mean train loss 2271.391951639941
INFO:root:current train perplexity5.998640537261963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.64s/it]
INFO:root:final mean train loss: 2271.3331357308607
INFO:root:final train perplexity: 5.997304439544678
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2148.785296933871
INFO:root:eval perplexity: 5.68488883972168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2540.065640929743
INFO:root:eval perplexity: 7.983170032501221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/6
  6%|â–Œ         | 6/100 [58:04<15:08:53, 580.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2274.854248046875
INFO:root:current train perplexity5.979921340942383
INFO:root:current mean train loss 2208.2575937403312
INFO:root:current train perplexity5.738218307495117
INFO:root:current mean train loss 2212.12084414354
INFO:root:current train perplexity5.756182670593262
INFO:root:current mean train loss 2213.3674279906822
INFO:root:current train perplexity5.739993572235107
INFO:root:current mean train loss 2215.4563411417744
INFO:root:current train perplexity5.749034404754639
INFO:root:current mean train loss 2221.980500181278
INFO:root:current train perplexity5.756539821624756
INFO:root:current mean train loss 2224.9034403516926
INFO:root:current train perplexity5.766177654266357
INFO:root:current mean train loss 2226.4754137156183
INFO:root:current train perplexity5.772132873535156
INFO:root:current mean train loss 2224.9862458304074
INFO:root:current train perplexity5.765422821044922
INFO:root:current mean train loss 2224.950418859687
INFO:root:current train perplexity5.765381813049316
INFO:root:current mean train loss 2222.957118930874
INFO:root:current train perplexity5.7662248611450195
INFO:root:current mean train loss 2223.452565982275
INFO:root:current train perplexity5.765033721923828
INFO:root:current mean train loss 2222.0312359736026
INFO:root:current train perplexity5.762037754058838
INFO:root:current mean train loss 2220.34183712724
INFO:root:current train perplexity5.755387306213379
INFO:root:current mean train loss 2220.4784363359317
INFO:root:current train perplexity5.754810333251953
INFO:root:current mean train loss 2219.912133528819
INFO:root:current train perplexity5.755524635314941
INFO:root:current mean train loss 2219.0334673183997
INFO:root:current train perplexity5.75258731842041
INFO:root:current mean train loss 2216.446487058968
INFO:root:current train perplexity5.745643138885498
INFO:root:current mean train loss 2215.719151252776
INFO:root:current train perplexity5.741375923156738
INFO:root:current mean train loss 2216.3425245450585
INFO:root:current train perplexity5.738643169403076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.36s/it]
INFO:root:final mean train loss: 2215.108653781754
INFO:root:final train perplexity: 5.737180709838867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2122.711637023493
INFO:root:eval perplexity: 5.5662665367126465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 2521.5115763346353
INFO:root:eval perplexity: 7.8629469871521
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/7
  7%|â–‹         | 7/100 [1:07:40<14:57:16, 578.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2280.961140950521
INFO:root:current train perplexity5.672732353210449
INFO:root:current mean train loss 2193.6739667472193
INFO:root:current train perplexity5.6141357421875
INFO:root:current mean train loss 2185.8847908230005
INFO:root:current train perplexity5.561960220336914
INFO:root:current mean train loss 2173.4089347791373
INFO:root:current train perplexity5.5375800132751465
INFO:root:current mean train loss 2183.899805972451
INFO:root:current train perplexity5.572925567626953
INFO:root:current mean train loss 2181.610155024584
INFO:root:current train perplexity5.55997896194458
INFO:root:current mean train loss 2181.4750733607025
INFO:root:current train perplexity5.557563304901123
INFO:root:current mean train loss 2182.899239797778
INFO:root:current train perplexity5.563914775848389
INFO:root:current mean train loss 2176.391959565776
INFO:root:current train perplexity5.553318500518799
INFO:root:current mean train loss 2177.7828706895084
INFO:root:current train perplexity5.553881645202637
INFO:root:current mean train loss 2176.5926079590804
INFO:root:current train perplexity5.552422523498535
INFO:root:current mean train loss 2175.1064253314025
INFO:root:current train perplexity5.551990509033203
INFO:root:current mean train loss 2172.6281882600833
INFO:root:current train perplexity5.546384334564209
INFO:root:current mean train loss 2173.722616980036
INFO:root:current train perplexity5.546924591064453
INFO:root:current mean train loss 2173.9273928708185
INFO:root:current train perplexity5.548610687255859
INFO:root:current mean train loss 2173.390854183393
INFO:root:current train perplexity5.547858715057373
INFO:root:current mean train loss 2171.746498060757
INFO:root:current train perplexity5.540804386138916
INFO:root:current mean train loss 2172.085156619479
INFO:root:current train perplexity5.540398597717285
INFO:root:current mean train loss 2170.6241931138916
INFO:root:current train perplexity5.536644458770752
INFO:root:current mean train loss 2169.573197381713
INFO:root:current train perplexity5.534007549285889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.26s/it]
INFO:root:final mean train loss: 2168.4556999879837
INFO:root:final train perplexity: 5.529928207397461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2082.4653073574636
INFO:root:eval perplexity: 5.388009071350098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it]
INFO:root:eval mean loss: 2486.261637802665
INFO:root:eval perplexity: 7.639506816864014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/8
  8%|â–Š         | 8/100 [1:17:15<14:45:49, 577.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2090.237388392857
INFO:root:current train perplexity5.229246616363525
INFO:root:current mean train loss 2122.8205204716437
INFO:root:current train perplexity5.35294771194458
INFO:root:current mean train loss 2117.671911880818
INFO:root:current train perplexity5.355714321136475
INFO:root:current mean train loss 2129.5743783523785
INFO:root:current train perplexity5.36738920211792
INFO:root:current mean train loss 2135.689285874641
INFO:root:current train perplexity5.388713836669922
INFO:root:current mean train loss 2133.7882463401725
INFO:root:current train perplexity5.376977443695068
INFO:root:current mean train loss 2134.6557401882383
INFO:root:current train perplexity5.374814033508301
INFO:root:current mean train loss 2133.8643255739794
INFO:root:current train perplexity5.377340793609619
INFO:root:current mean train loss 2133.1444275998783
INFO:root:current train perplexity5.380390644073486
INFO:root:current mean train loss 2135.7207706227023
INFO:root:current train perplexity5.37952995300293
INFO:root:current mean train loss 2136.050609525966
INFO:root:current train perplexity5.379444599151611
INFO:root:current mean train loss 2136.792794732585
INFO:root:current train perplexity5.384977340698242
INFO:root:current mean train loss 2134.327208830181
INFO:root:current train perplexity5.382983684539795
INFO:root:current mean train loss 2132.2740186827014
INFO:root:current train perplexity5.378076076507568
INFO:root:current mean train loss 2132.35741855741
INFO:root:current train perplexity5.375427722930908
INFO:root:current mean train loss 2132.9807249783694
INFO:root:current train perplexity5.377081871032715
INFO:root:current mean train loss 2133.738255566705
INFO:root:current train perplexity5.378131866455078
INFO:root:current mean train loss 2133.3377474474287
INFO:root:current train perplexity5.377433776855469
INFO:root:current mean train loss 2132.702176842962
INFO:root:current train perplexity5.375755310058594
INFO:root:current mean train loss 2132.909841706032
INFO:root:current train perplexity5.374083518981934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.57s/it]
INFO:root:final mean train loss: 2131.81260945084
INFO:root:final train perplexity: 5.372405529022217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2055.6175013332504
INFO:root:eval perplexity: 5.272278785705566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2467.4586285530254
INFO:root:eval perplexity: 7.522927284240723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/9
  9%|â–‰         | 9/100 [1:26:51<14:35:33, 577.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2061.5792025052583
INFO:root:current train perplexity5.204334259033203
INFO:root:current mean train loss 2095.946164582905
INFO:root:current train perplexity5.259764194488525
INFO:root:current mean train loss 2107.7981877402653
INFO:root:current train perplexity5.259748458862305
INFO:root:current mean train loss 2103.3979565013537
INFO:root:current train perplexity5.257720947265625
INFO:root:current mean train loss 2101.056546641662
INFO:root:current train perplexity5.252832412719727
INFO:root:current mean train loss 2097.313689964405
INFO:root:current train perplexity5.238534450531006
INFO:root:current mean train loss 2098.2210032457224
INFO:root:current train perplexity5.241732120513916
INFO:root:current mean train loss 2098.236761701868
INFO:root:current train perplexity5.239950656890869
INFO:root:current mean train loss 2101.930261746259
INFO:root:current train perplexity5.24498987197876
INFO:root:current mean train loss 2100.3984594264953
INFO:root:current train perplexity5.2423810958862305
INFO:root:current mean train loss 2100.941262132768
INFO:root:current train perplexity5.242042541503906
INFO:root:current mean train loss 2102.250615225898
INFO:root:current train perplexity5.244833946228027
INFO:root:current mean train loss 2099.6891479492188
INFO:root:current train perplexity5.240963459014893
INFO:root:current mean train loss 2100.2391641831255
INFO:root:current train perplexity5.236484527587891
INFO:root:current mean train loss 2100.7593532593783
INFO:root:current train perplexity5.237077713012695
INFO:root:current mean train loss 2100.561298724302
INFO:root:current train perplexity5.237831115722656
INFO:root:current mean train loss 2102.077574205745
INFO:root:current train perplexity5.241673946380615
INFO:root:current mean train loss 2102.0906650769657
INFO:root:current train perplexity5.2412428855896
INFO:root:current mean train loss 2100.841461313466
INFO:root:current train perplexity5.238101482391357
INFO:root:current mean train loss 2101.064153952677
INFO:root:current train perplexity5.238117694854736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.46s/it]
INFO:root:final mean train loss: 2099.2211316022617
INFO:root:final train perplexity: 5.236074447631836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 2036.2859700520833
INFO:root:eval perplexity: 5.190492153167725
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.38s/it]
INFO:root:eval mean loss: 2445.0739616231717
INFO:root:eval perplexity: 7.386460781097412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:36:34<14:28:14, 578.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2087.8207229393115
INFO:root:current train perplexity5.1733574867248535
INFO:root:current mean train loss 2095.258380957609
INFO:root:current train perplexity5.174823760986328
INFO:root:current mean train loss 2090.818311272944
INFO:root:current train perplexity5.158480644226074
INFO:root:current mean train loss 2083.6305980320544
INFO:root:current train perplexity5.1387786865234375
INFO:root:current mean train loss 2081.1034409252566
INFO:root:current train perplexity5.135659694671631
INFO:root:current mean train loss 2077.579228996183
INFO:root:current train perplexity5.1369171142578125
INFO:root:current mean train loss 2074.435363313364
INFO:root:current train perplexity5.125378608703613
INFO:root:current mean train loss 2076.1472461635954
INFO:root:current train perplexity5.133615016937256
INFO:root:current mean train loss 2075.190332621233
INFO:root:current train perplexity5.134219169616699
INFO:root:current mean train loss 2074.4828123992197
INFO:root:current train perplexity5.1322712898254395
INFO:root:current mean train loss 2073.259823976665
INFO:root:current train perplexity5.128729343414307
INFO:root:current mean train loss 2074.690048648518
INFO:root:current train perplexity5.1279802322387695
INFO:root:current mean train loss 2074.190859290349
INFO:root:current train perplexity5.129648208618164
INFO:root:current mean train loss 2073.924027414371
INFO:root:current train perplexity5.125462055206299
INFO:root:current mean train loss 2074.117422084406
INFO:root:current train perplexity5.127772808074951
INFO:root:current mean train loss 2072.8050072635338
INFO:root:current train perplexity5.123588562011719
INFO:root:current mean train loss 2071.9739062090416
INFO:root:current train perplexity5.121587753295898
INFO:root:current mean train loss 2071.959601834105
INFO:root:current train perplexity5.119720458984375
INFO:root:current mean train loss 2071.1538195663625
INFO:root:current train perplexity5.116384029388428
INFO:root:current mean train loss 2071.570010083045
INFO:root:current train perplexity5.121304035186768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.54s/it]
INFO:root:final mean train loss: 2070.9272148528607
INFO:root:final train perplexity: 5.1205291748046875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2018.0622523963875
INFO:root:eval perplexity: 5.1145548820495605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.18s/it]
INFO:root:eval mean loss: 2431.515391248338
INFO:root:eval perplexity: 7.30500602722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:46:09<14:17:03, 577.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2067.774490711301
INFO:root:current train perplexity5.046518325805664
INFO:root:current mean train loss 2046.32028624832
INFO:root:current train perplexity5.01984977722168
INFO:root:current mean train loss 2044.438437721946
INFO:root:current train perplexity5.014318943023682
INFO:root:current mean train loss 2046.8835819224619
INFO:root:current train perplexity5.024357795715332
INFO:root:current mean train loss 2041.0456681114165
INFO:root:current train perplexity5.0257792472839355
INFO:root:current mean train loss 2043.9388683957045
INFO:root:current train perplexity5.023553848266602
INFO:root:current mean train loss 2043.9124303878918
INFO:root:current train perplexity5.009603977203369
INFO:root:current mean train loss 2043.4016015438633
INFO:root:current train perplexity5.004143714904785
INFO:root:current mean train loss 2042.7520707864524
INFO:root:current train perplexity5.001708507537842
INFO:root:current mean train loss 2045.092435329971
INFO:root:current train perplexity5.007474422454834
INFO:root:current mean train loss 2046.9049665756647
INFO:root:current train perplexity5.015913009643555
INFO:root:current mean train loss 2047.2828320765375
INFO:root:current train perplexity5.0163679122924805
INFO:root:current mean train loss 2047.34046815009
INFO:root:current train perplexity5.01661491394043
INFO:root:current mean train loss 2046.8228895399307
INFO:root:current train perplexity5.017562389373779
INFO:root:current mean train loss 2045.3180178902833
INFO:root:current train perplexity5.01818323135376
INFO:root:current mean train loss 2046.6087686507428
INFO:root:current train perplexity5.019333362579346
INFO:root:current mean train loss 2045.231153096734
INFO:root:current train perplexity5.017852783203125
INFO:root:current mean train loss 2045.203983934836
INFO:root:current train perplexity5.017261505126953
INFO:root:current mean train loss 2044.4999062142722
INFO:root:current train perplexity5.016427993774414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.42s/it]
INFO:root:final mean train loss: 2045.1004015085257
INFO:root:final train perplexity: 5.01728630065918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2014.3767518388463
INFO:root:eval perplexity: 5.099331855773926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2429.3813268783247
INFO:root:eval perplexity: 7.292268753051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:55:43<14:05:40, 576.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2082.1398111979165
INFO:root:current train perplexity4.805910587310791
INFO:root:current mean train loss 2026.3798318511074
INFO:root:current train perplexity4.94612979888916
INFO:root:current mean train loss 2016.9971081963902
INFO:root:current train perplexity4.908689022064209
INFO:root:current mean train loss 2021.5245284782384
INFO:root:current train perplexity4.9138503074646
INFO:root:current mean train loss 2018.7045347152218
INFO:root:current train perplexity4.906402587890625
INFO:root:current mean train loss 2019.8951350490804
INFO:root:current train perplexity4.913621425628662
INFO:root:current mean train loss 2023.3083321996787
INFO:root:current train perplexity4.929024696350098
INFO:root:current mean train loss 2020.8272041765758
INFO:root:current train perplexity4.91831111907959
INFO:root:current mean train loss 2021.189186485737
INFO:root:current train perplexity4.919888019561768
INFO:root:current mean train loss 2021.4655408890937
INFO:root:current train perplexity4.922868251800537
INFO:root:current mean train loss 2020.0008538836614
INFO:root:current train perplexity4.916600227355957
INFO:root:current mean train loss 2019.789731285946
INFO:root:current train perplexity4.92104434967041
INFO:root:current mean train loss 2018.806335398483
INFO:root:current train perplexity4.920847415924072
INFO:root:current mean train loss 2018.7930686171935
INFO:root:current train perplexity4.920119285583496
INFO:root:current mean train loss 2019.67231307842
INFO:root:current train perplexity4.917901992797852
INFO:root:current mean train loss 2019.3577505633264
INFO:root:current train perplexity4.915994644165039
INFO:root:current mean train loss 2020.3185396248002
INFO:root:current train perplexity4.920271396636963
INFO:root:current mean train loss 2020.6195900559214
INFO:root:current train perplexity4.9206695556640625
INFO:root:current mean train loss 2020.6126125375893
INFO:root:current train perplexity4.919539928436279
INFO:root:current mean train loss 2021.6340888820694
INFO:root:current train perplexity4.921728134155273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.72s/it]
INFO:root:final mean train loss: 2020.4364813315526
INFO:root:final train perplexity: 4.920636177062988
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 1995.2058815381206
INFO:root:eval perplexity: 5.020880699157715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it]
INFO:root:eval mean loss: 2417.1360919492463
INFO:root:eval perplexity: 7.219605445861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [2:05:12<13:52:31, 574.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1977.6659118652344
INFO:root:current train perplexity4.824151992797852
INFO:root:current mean train loss 1993.7480509440104
INFO:root:current train perplexity4.806865692138672
INFO:root:current mean train loss 1994.8191350763495
INFO:root:current train perplexity4.841099739074707
INFO:root:current mean train loss 1994.7576286315918
INFO:root:current train perplexity4.824726581573486
INFO:root:current mean train loss 1995.707906377883
INFO:root:current train perplexity4.825953960418701
INFO:root:current mean train loss 2000.6012805645282
INFO:root:current train perplexity4.833323001861572
INFO:root:current mean train loss 1996.8096585181452
INFO:root:current train perplexity4.823115348815918
INFO:root:current mean train loss 1994.3019007364908
INFO:root:current train perplexity4.819594860076904
INFO:root:current mean train loss 1993.0519906392913
INFO:root:current train perplexity4.822914123535156
INFO:root:current mean train loss 1992.0321448284647
INFO:root:current train perplexity4.823129177093506
INFO:root:current mean train loss 1993.1645070992265
INFO:root:current train perplexity4.823941230773926
INFO:root:current mean train loss 1993.8259720938547
INFO:root:current train perplexity4.826874732971191
INFO:root:current mean train loss 1993.8448333239946
INFO:root:current train perplexity4.822773456573486
INFO:root:current mean train loss 1995.8643876509234
INFO:root:current train perplexity4.824045181274414
INFO:root:current mean train loss 1996.502820941764
INFO:root:current train perplexity4.830076217651367
INFO:root:current mean train loss 1995.51548606471
INFO:root:current train perplexity4.8310418128967285
INFO:root:current mean train loss 1996.1880206826293
INFO:root:current train perplexity4.8325653076171875
INFO:root:current mean train loss 1997.9836439265762
INFO:root:current train perplexity4.8336381912231445
INFO:root:current mean train loss 1997.0582355876545
INFO:root:current train perplexity4.83240270614624
INFO:root:current mean train loss 1997.7201898574829
INFO:root:current train perplexity4.8355712890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.25s/it]
INFO:root:final mean train loss: 1998.337556301315
INFO:root:final train perplexity: 4.83561897277832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 1993.695595166362
INFO:root:eval perplexity: 5.014752388000488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it]
INFO:root:eval mean loss: 2416.4206993157136
INFO:root:eval perplexity: 7.2153825759887695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [2:14:45<13:42:40, 573.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2009.493969066723
INFO:root:current train perplexity4.697748184204102
INFO:root:current mean train loss 1992.986247932824
INFO:root:current train perplexity4.753656387329102
INFO:root:current mean train loss 1983.1775571927742
INFO:root:current train perplexity4.750397205352783
INFO:root:current mean train loss 1979.0417458735162
INFO:root:current train perplexity4.735231876373291
INFO:root:current mean train loss 1979.291719833828
INFO:root:current train perplexity4.738230228424072
INFO:root:current mean train loss 1982.8251403012978
INFO:root:current train perplexity4.752603054046631
INFO:root:current mean train loss 1979.3286295700673
INFO:root:current train perplexity4.748502254486084
INFO:root:current mean train loss 1977.8357854504113
INFO:root:current train perplexity4.7477569580078125
INFO:root:current mean train loss 1977.4057577809979
INFO:root:current train perplexity4.743728160858154
INFO:root:current mean train loss 1974.4160975697455
INFO:root:current train perplexity4.738483905792236
INFO:root:current mean train loss 1973.9339678478334
INFO:root:current train perplexity4.741249084472656
INFO:root:current mean train loss 1974.5350341796875
INFO:root:current train perplexity4.744412899017334
INFO:root:current mean train loss 1974.544752930477
INFO:root:current train perplexity4.744366645812988
INFO:root:current mean train loss 1975.8458841761815
INFO:root:current train perplexity4.748227119445801
INFO:root:current mean train loss 1974.5662344850925
INFO:root:current train perplexity4.744091987609863
INFO:root:current mean train loss 1976.217714824689
INFO:root:current train perplexity4.747756481170654
INFO:root:current mean train loss 1976.9223355413867
INFO:root:current train perplexity4.750617504119873
INFO:root:current mean train loss 1977.2250353209781
INFO:root:current train perplexity4.752401351928711
INFO:root:current mean train loss 1977.245003822256
INFO:root:current train perplexity4.753569602966309
INFO:root:current mean train loss 1977.5976774878395
INFO:root:current train perplexity4.756099224090576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.61s/it]
INFO:root:final mean train loss: 1978.071258160182
INFO:root:final train perplexity: 4.758944511413574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 1969.4920511448638
INFO:root:eval perplexity: 4.917545795440674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.08s/it]
INFO:root:eval mean loss: 2390.7821412864305
INFO:root:eval perplexity: 7.065666198730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [2:24:20<13:33:26, 574.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1935.8974586769386
INFO:root:current train perplexity4.657630443572998
INFO:root:current mean train loss 1950.0500567547688
INFO:root:current train perplexity4.689310550689697
INFO:root:current mean train loss 1960.8000694935715
INFO:root:current train perplexity4.707955360412598
INFO:root:current mean train loss 1956.2638222214866
INFO:root:current train perplexity4.693284034729004
INFO:root:current mean train loss 1958.0999296079124
INFO:root:current train perplexity4.687453746795654
INFO:root:current mean train loss 1961.0481884677488
INFO:root:current train perplexity4.695534706115723
INFO:root:current mean train loss 1964.2196685137735
INFO:root:current train perplexity4.700291633605957
INFO:root:current mean train loss 1961.0503277765977
INFO:root:current train perplexity4.688822269439697
INFO:root:current mean train loss 1960.6540457303406
INFO:root:current train perplexity4.690098762512207
INFO:root:current mean train loss 1959.7093549364517
INFO:root:current train perplexity4.689049243927002
INFO:root:current mean train loss 1963.1583636463029
INFO:root:current train perplexity4.693776607513428
INFO:root:current mean train loss 1960.2314005674893
INFO:root:current train perplexity4.688658714294434
INFO:root:current mean train loss 1961.3441962283193
INFO:root:current train perplexity4.69212007522583
INFO:root:current mean train loss 1962.4937644969766
INFO:root:current train perplexity4.69041633605957
INFO:root:current mean train loss 1962.5759959896461
INFO:root:current train perplexity4.690835475921631
INFO:root:current mean train loss 1961.7388703924348
INFO:root:current train perplexity4.6910223960876465
INFO:root:current mean train loss 1960.8674929709937
INFO:root:current train perplexity4.690291404724121
INFO:root:current mean train loss 1960.9226086049966
INFO:root:current train perplexity4.691737174987793
INFO:root:current mean train loss 1961.0221809132072
INFO:root:current train perplexity4.691414833068848
INFO:root:current mean train loss 1959.5895783064186
INFO:root:current train perplexity4.688351631164551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.38s/it]
INFO:root:final mean train loss: 1959.1285739577424
INFO:root:final train perplexity: 4.688377857208252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 1970.8589382306905
INFO:root:eval perplexity: 4.922985076904297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2396.645748923011
INFO:root:eval perplexity: 7.099631309509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [2:34:01<13:26:39, 576.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1976.8966563050176
INFO:root:current train perplexity4.674517631530762
INFO:root:current mean train loss 1950.1800901178729
INFO:root:current train perplexity4.632370948791504
INFO:root:current mean train loss 1947.481051624481
INFO:root:current train perplexity4.6369452476501465
INFO:root:current mean train loss 1947.7822002400605
INFO:root:current train perplexity4.635354042053223
INFO:root:current mean train loss 1946.6222076739982
INFO:root:current train perplexity4.642307758331299
INFO:root:current mean train loss 1944.9604614044028
INFO:root:current train perplexity4.635788440704346
INFO:root:current mean train loss 1944.1152505661444
INFO:root:current train perplexity4.627124309539795
INFO:root:current mean train loss 1943.8770072729208
INFO:root:current train perplexity4.62742805480957
INFO:root:current mean train loss 1943.0260910927634
INFO:root:current train perplexity4.625914096832275
INFO:root:current mean train loss 1942.4519220228422
INFO:root:current train perplexity4.626716613769531
INFO:root:current mean train loss 1941.1950463616436
INFO:root:current train perplexity4.625305652618408
INFO:root:current mean train loss 1939.7814637012302
INFO:root:current train perplexity4.619567394256592
INFO:root:current mean train loss 1938.868503189387
INFO:root:current train perplexity4.614034175872803
INFO:root:current mean train loss 1940.3295023199591
INFO:root:current train perplexity4.617881774902344
INFO:root:current mean train loss 1941.3633069752188
INFO:root:current train perplexity4.621330261230469
INFO:root:current mean train loss 1941.1146364558053
INFO:root:current train perplexity4.623250961303711
INFO:root:current mean train loss 1941.0897146666714
INFO:root:current train perplexity4.623735427856445
INFO:root:current mean train loss 1940.2518137539262
INFO:root:current train perplexity4.6202521324157715
INFO:root:current mean train loss 1939.8741192799848
INFO:root:current train perplexity4.619018077850342
INFO:root:current mean train loss 1940.9653888859161
INFO:root:current train perplexity4.619542121887207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.25s/it]
INFO:root:final mean train loss: 1940.716913959082
INFO:root:final train perplexity: 4.620791912078857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 1957.3408852435173
INFO:root:eval perplexity: 4.869456768035889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 2384.637585362644
INFO:root:eval perplexity: 7.030249118804932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [2:43:31<13:14:48, 574.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.4141110506926
INFO:root:current train perplexity4.599827766418457
INFO:root:current mean train loss 1914.8101150837351
INFO:root:current train perplexity4.545028209686279
INFO:root:current mean train loss 1920.5950177510579
INFO:root:current train perplexity4.56412935256958
INFO:root:current mean train loss 1928.5945041302552
INFO:root:current train perplexity4.571139812469482
INFO:root:current mean train loss 1922.9867226022188
INFO:root:current train perplexity4.555433750152588
INFO:root:current mean train loss 1926.834166857661
INFO:root:current train perplexity4.564340114593506
INFO:root:current mean train loss 1922.2083246985146
INFO:root:current train perplexity4.555412769317627
INFO:root:current mean train loss 1922.2155496819976
INFO:root:current train perplexity4.558513164520264
INFO:root:current mean train loss 1923.7268339964721
INFO:root:current train perplexity4.563848495483398
INFO:root:current mean train loss 1923.3631780832886
INFO:root:current train perplexity4.56284236907959
INFO:root:current mean train loss 1923.0675352881935
INFO:root:current train perplexity4.561447620391846
INFO:root:current mean train loss 1924.023282754301
INFO:root:current train perplexity4.563648700714111
INFO:root:current mean train loss 1925.0660867631805
INFO:root:current train perplexity4.56641960144043
INFO:root:current mean train loss 1924.2680838197384
INFO:root:current train perplexity4.565720081329346
INFO:root:current mean train loss 1923.88143814251
INFO:root:current train perplexity4.565004348754883
INFO:root:current mean train loss 1923.0632741625423
INFO:root:current train perplexity4.562428951263428
INFO:root:current mean train loss 1922.9292115848775
INFO:root:current train perplexity4.562344551086426
INFO:root:current mean train loss 1923.7988447833648
INFO:root:current train perplexity4.5615458488464355
INFO:root:current mean train loss 1925.8582912380411
INFO:root:current train perplexity4.5643839836120605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.25s/it]
INFO:root:final mean train loss: 1924.6694067235073
INFO:root:final train perplexity: 4.562679767608643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 1939.3086508892952
INFO:root:eval perplexity: 4.798959255218506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.55s/it]
INFO:root:eval mean loss: 2373.5956087585882
INFO:root:eval perplexity: 6.9670491218566895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:53:00<13:02:35, 572.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1812.7455322265625
INFO:root:current train perplexity4.233541965484619
INFO:root:current mean train loss 1876.0864408947173
INFO:root:current train perplexity4.460361957550049
INFO:root:current mean train loss 1884.6097406154727
INFO:root:current train perplexity4.449038505554199
INFO:root:current mean train loss 1897.2553614882172
INFO:root:current train perplexity4.471872806549072
INFO:root:current mean train loss 1892.671516324267
INFO:root:current train perplexity4.468883037567139
INFO:root:current mean train loss 1895.9431804996907
INFO:root:current train perplexity4.470734119415283
INFO:root:current mean train loss 1895.1286631182206
INFO:root:current train perplexity4.469237327575684
INFO:root:current mean train loss 1897.1346523853058
INFO:root:current train perplexity4.472949981689453
INFO:root:current mean train loss 1899.2944190362966
INFO:root:current train perplexity4.480165958404541
INFO:root:current mean train loss 1903.6955636546097
INFO:root:current train perplexity4.488591194152832
INFO:root:current mean train loss 1903.6543217749145
INFO:root:current train perplexity4.488460063934326
INFO:root:current mean train loss 1904.5798307807197
INFO:root:current train perplexity4.491014003753662
INFO:root:current mean train loss 1904.0260200215573
INFO:root:current train perplexity4.490448951721191
INFO:root:current mean train loss 1903.839366787147
INFO:root:current train perplexity4.490122318267822
INFO:root:current mean train loss 1905.1543968770852
INFO:root:current train perplexity4.491416931152344
INFO:root:current mean train loss 1906.195811487749
INFO:root:current train perplexity4.492728233337402
INFO:root:current mean train loss 1906.93010748272
INFO:root:current train perplexity4.494366645812988
INFO:root:current mean train loss 1907.9872913707386
INFO:root:current train perplexity4.498486042022705
INFO:root:current mean train loss 1908.020883356237
INFO:root:current train perplexity4.500324249267578
INFO:root:current mean train loss 1908.5856738793882
INFO:root:current train perplexity4.502501964569092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.35s/it]
INFO:root:final mean train loss: 1908.010609498363
INFO:root:final train perplexity: 4.503126621246338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 1945.0717708506484
INFO:root:eval perplexity: 4.821377754211426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2377.3991352919993
INFO:root:eval perplexity: 6.9887542724609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [3:02:33<12:53:24, 572.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1869.9607100053267
INFO:root:current train perplexity4.472907066345215
INFO:root:current mean train loss 1886.8467767434042
INFO:root:current train perplexity4.466354846954346
INFO:root:current mean train loss 1901.474147487331
INFO:root:current train perplexity4.486811637878418
INFO:root:current mean train loss 1892.1402398340451
INFO:root:current train perplexity4.4632487297058105
INFO:root:current mean train loss 1887.3217776330162
INFO:root:current train perplexity4.446581840515137
INFO:root:current mean train loss 1892.1755799041398
INFO:root:current train perplexity4.455026149749756
INFO:root:current mean train loss 1891.5812016821367
INFO:root:current train perplexity4.452064514160156
INFO:root:current mean train loss 1895.3020077015885
INFO:root:current train perplexity4.464953899383545
INFO:root:current mean train loss 1893.2544552693982
INFO:root:current train perplexity4.463262557983398
INFO:root:current mean train loss 1893.776233069033
INFO:root:current train perplexity4.459897518157959
INFO:root:current mean train loss 1894.0903331062332
INFO:root:current train perplexity4.45663595199585
INFO:root:current mean train loss 1895.4823429971243
INFO:root:current train perplexity4.457194805145264
INFO:root:current mean train loss 1895.9933758375103
INFO:root:current train perplexity4.456745624542236
INFO:root:current mean train loss 1894.7136253553151
INFO:root:current train perplexity4.452810764312744
INFO:root:current mean train loss 1893.0262458897844
INFO:root:current train perplexity4.44696569442749
INFO:root:current mean train loss 1892.9470607040746
INFO:root:current train perplexity4.4471540451049805
INFO:root:current mean train loss 1893.8039853322962
INFO:root:current train perplexity4.448728084564209
INFO:root:current mean train loss 1893.3215223571565
INFO:root:current train perplexity4.448208808898926
INFO:root:current mean train loss 1893.6439438117454
INFO:root:current train perplexity4.448763370513916
INFO:root:current mean train loss 1893.527316249248
INFO:root:current train perplexity4.44998836517334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.31s/it]
INFO:root:final mean train loss: 1893.2100080912364
INFO:root:final train perplexity: 4.450869083404541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it]
INFO:root:eval mean loss: 1934.9661094719636
INFO:root:eval perplexity: 4.782134056091309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.65s/it]
INFO:root:eval mean loss: 2375.0939898118904
INFO:root:eval perplexity: 6.975591659545898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [3:12:12<12:46:15, 574.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.3855481270032
INFO:root:current train perplexity4.33125114440918
INFO:root:current mean train loss 1865.9651950314749
INFO:root:current train perplexity4.363480091094971
INFO:root:current mean train loss 1877.7451074831656
INFO:root:current train perplexity4.376901149749756
INFO:root:current mean train loss 1877.6046891564113
INFO:root:current train perplexity4.373021125793457
INFO:root:current mean train loss 1879.4363262897743
INFO:root:current train perplexity4.3926825523376465
INFO:root:current mean train loss 1873.8718746376392
INFO:root:current train perplexity4.38442850112915
INFO:root:current mean train loss 1877.9746636284722
INFO:root:current train perplexity4.392578601837158
INFO:root:current mean train loss 1878.298943092439
INFO:root:current train perplexity4.39018440246582
INFO:root:current mean train loss 1879.4869918732309
INFO:root:current train perplexity4.393867015838623
INFO:root:current mean train loss 1880.4743926644453
INFO:root:current train perplexity4.396326541900635
INFO:root:current mean train loss 1881.3994246364443
INFO:root:current train perplexity4.398517608642578
INFO:root:current mean train loss 1881.229210321897
INFO:root:current train perplexity4.400974273681641
INFO:root:current mean train loss 1879.7416123212395
INFO:root:current train perplexity4.399930477142334
INFO:root:current mean train loss 1880.5639838061286
INFO:root:current train perplexity4.39799690246582
INFO:root:current mean train loss 1882.1634652970813
INFO:root:current train perplexity4.400836944580078
INFO:root:current mean train loss 1881.630859375
INFO:root:current train perplexity4.402619361877441
INFO:root:current mean train loss 1882.4520273354085
INFO:root:current train perplexity4.403558731079102
INFO:root:current mean train loss 1883.2221124439557
INFO:root:current train perplexity4.405686855316162
INFO:root:current mean train loss 1881.4615131355356
INFO:root:current train perplexity4.4020562171936035
INFO:root:current mean train loss 1879.6089605653083
INFO:root:current train perplexity4.401732921600342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.34s/it]
INFO:root:final mean train loss: 1879.4029780785604
INFO:root:final train perplexity: 4.4026665687561035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 1926.480684753851
INFO:root:eval perplexity: 4.749429702758789
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.45s/it]
INFO:root:eval mean loss: 2368.3244970876276
INFO:root:eval perplexity: 6.937079429626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [3:21:44<12:35:40, 573.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.3868299211774
INFO:root:current train perplexity4.385035037994385
INFO:root:current mean train loss 1877.1295166015625
INFO:root:current train perplexity4.358390808105469
INFO:root:current mean train loss 1872.2293858528137
INFO:root:current train perplexity4.360093116760254
INFO:root:current mean train loss 1870.849597030811
INFO:root:current train perplexity4.358026504516602
INFO:root:current mean train loss 1865.1045797247637
INFO:root:current train perplexity4.360375881195068
INFO:root:current mean train loss 1865.2155375309128
INFO:root:current train perplexity4.358683109283447
INFO:root:current mean train loss 1865.4942993536229
INFO:root:current train perplexity4.358039379119873
INFO:root:current mean train loss 1868.7036647897548
INFO:root:current train perplexity4.3599934577941895
INFO:root:current mean train loss 1863.021538850303
INFO:root:current train perplexity4.345958709716797
INFO:root:current mean train loss 1865.0575822008204
INFO:root:current train perplexity4.349755764007568
INFO:root:current mean train loss 1864.562382437966
INFO:root:current train perplexity4.349921226501465
INFO:root:current mean train loss 1864.0104454594912
INFO:root:current train perplexity4.3498616218566895
INFO:root:current mean train loss 1865.1394687336722
INFO:root:current train perplexity4.352208614349365
INFO:root:current mean train loss 1864.4893842038855
INFO:root:current train perplexity4.348418235778809
INFO:root:current mean train loss 1864.4435107052982
INFO:root:current train perplexity4.347002983093262
INFO:root:current mean train loss 1865.7661681972004
INFO:root:current train perplexity4.3503193855285645
INFO:root:current mean train loss 1867.5456021811076
INFO:root:current train perplexity4.353599548339844
INFO:root:current mean train loss 1866.8552320476
INFO:root:current train perplexity4.354093551635742
INFO:root:current mean train loss 1867.6278137996278
INFO:root:current train perplexity4.357365131378174
INFO:root:current mean train loss 1867.5345205607346
INFO:root:current train perplexity4.359251022338867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.81s/it]
INFO:root:final mean train loss: 1866.7867746511854
INFO:root:final train perplexity: 4.359076499938965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 1914.7561095758533
INFO:root:eval perplexity: 4.7046074867248535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it]
INFO:root:eval mean loss: 2352.313356656555
INFO:root:eval perplexity: 6.846836566925049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:31:12<12:23:51, 572.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.1054001899615
INFO:root:current train perplexity4.344626426696777
INFO:root:current mean train loss 1868.3217053716583
INFO:root:current train perplexity4.33441686630249
INFO:root:current mean train loss 1872.1390108101534
INFO:root:current train perplexity4.330809593200684
INFO:root:current mean train loss 1866.2079685405497
INFO:root:current train perplexity4.3207316398620605
INFO:root:current mean train loss 1861.0863986831891
INFO:root:current train perplexity4.310751914978027
INFO:root:current mean train loss 1856.2063906471558
INFO:root:current train perplexity4.303651809692383
INFO:root:current mean train loss 1853.2881849722557
INFO:root:current train perplexity4.29550838470459
INFO:root:current mean train loss 1854.9282940350097
INFO:root:current train perplexity4.302011966705322
INFO:root:current mean train loss 1852.5317146502273
INFO:root:current train perplexity4.303279876708984
INFO:root:current mean train loss 1854.3645491252087
INFO:root:current train perplexity4.311001300811768
INFO:root:current mean train loss 1855.643379261198
INFO:root:current train perplexity4.312062740325928
INFO:root:current mean train loss 1855.5159316847494
INFO:root:current train perplexity4.312792778015137
INFO:root:current mean train loss 1856.7135821969512
INFO:root:current train perplexity4.316684722900391
INFO:root:current mean train loss 1856.2082514196786
INFO:root:current train perplexity4.313210964202881
INFO:root:current mean train loss 1855.5888541766112
INFO:root:current train perplexity4.311796188354492
INFO:root:current mean train loss 1855.8273698402982
INFO:root:current train perplexity4.311071395874023
INFO:root:current mean train loss 1856.0206174787759
INFO:root:current train perplexity4.3131818771362305
INFO:root:current mean train loss 1856.2140326330505
INFO:root:current train perplexity4.317409515380859
INFO:root:current mean train loss 1856.8027835159587
INFO:root:current train perplexity4.322188854217529
INFO:root:current mean train loss 1856.1837703900112
INFO:root:current train perplexity4.320824146270752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.89s/it]
INFO:root:final mean train loss: 1855.4253615755897
INFO:root:final train perplexity: 4.320193290710449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 1913.4794692452072
INFO:root:eval perplexity: 4.6997528076171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it]
INFO:root:eval mean loss: 2351.3367984852894
INFO:root:eval perplexity: 6.84136962890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:40:50<12:16:28, 573.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.4628512912327
INFO:root:current train perplexity4.210783958435059
INFO:root:current mean train loss 1832.9162552682976
INFO:root:current train perplexity4.246673107147217
INFO:root:current mean train loss 1834.7655997440734
INFO:root:current train perplexity4.259632587432861
INFO:root:current mean train loss 1840.1754497821514
INFO:root:current train perplexity4.2673749923706055
INFO:root:current mean train loss 1838.3043987663425
INFO:root:current train perplexity4.2624993324279785
INFO:root:current mean train loss 1842.2770590572034
INFO:root:current train perplexity4.267649173736572
INFO:root:current mean train loss 1840.6305522531702
INFO:root:current train perplexity4.265199184417725
INFO:root:current mean train loss 1840.127319954015
INFO:root:current train perplexity4.268976211547852
INFO:root:current mean train loss 1840.571150533269
INFO:root:current train perplexity4.269400596618652
INFO:root:current mean train loss 1837.7737061779908
INFO:root:current train perplexity4.263680458068848
INFO:root:current mean train loss 1838.1922281527739
INFO:root:current train perplexity4.260725498199463
INFO:root:current mean train loss 1839.2964412913602
INFO:root:current train perplexity4.266191005706787
INFO:root:current mean train loss 1839.6453951103742
INFO:root:current train perplexity4.269622802734375
INFO:root:current mean train loss 1839.6567560209644
INFO:root:current train perplexity4.270431041717529
INFO:root:current mean train loss 1840.505367898621
INFO:root:current train perplexity4.2730512619018555
INFO:root:current mean train loss 1840.3145522399518
INFO:root:current train perplexity4.273787975311279
INFO:root:current mean train loss 1839.9801476834089
INFO:root:current train perplexity4.273499965667725
INFO:root:current mean train loss 1841.6216091731408
INFO:root:current train perplexity4.274393081665039
INFO:root:current mean train loss 1842.0363425925925
INFO:root:current train perplexity4.275017738342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.64s/it]
INFO:root:final mean train loss: 1842.8350747589866
INFO:root:final train perplexity: 4.277507781982422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it]
INFO:root:eval mean loss: 1916.4608050407248
INFO:root:eval perplexity: 4.711098670959473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.71s/it]
INFO:root:eval mean loss: 2358.6567755083665
INFO:root:eval perplexity: 6.882447242736816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:50:20<12:05:35, 572.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1826.257533482143
INFO:root:current train perplexity4.206132888793945
INFO:root:current mean train loss 1818.6678364120912
INFO:root:current train perplexity4.189761161804199
INFO:root:current mean train loss 1826.5050390860886
INFO:root:current train perplexity4.2069783210754395
INFO:root:current mean train loss 1820.362522584996
INFO:root:current train perplexity4.198523044586182
INFO:root:current mean train loss 1813.480998421184
INFO:root:current train perplexity4.1837615966796875
INFO:root:current mean train loss 1814.6781460914385
INFO:root:current train perplexity4.190374851226807
INFO:root:current mean train loss 1820.6074950769666
INFO:root:current train perplexity4.2047438621521
INFO:root:current mean train loss 1822.0296560068953
INFO:root:current train perplexity4.212115287780762
INFO:root:current mean train loss 1824.4264620907393
INFO:root:current train perplexity4.218420505523682
INFO:root:current mean train loss 1826.672295045695
INFO:root:current train perplexity4.225975036621094
INFO:root:current mean train loss 1828.3460773365737
INFO:root:current train perplexity4.231210708618164
INFO:root:current mean train loss 1828.4625021392628
INFO:root:current train perplexity4.230301380157471
INFO:root:current mean train loss 1828.8134877885188
INFO:root:current train perplexity4.229863166809082
INFO:root:current mean train loss 1827.3236489328795
INFO:root:current train perplexity4.226943492889404
INFO:root:current mean train loss 1827.956189684946
INFO:root:current train perplexity4.229581356048584
INFO:root:current mean train loss 1829.9040345898827
INFO:root:current train perplexity4.233975410461426
INFO:root:current mean train loss 1830.9386555280607
INFO:root:current train perplexity4.237752914428711
INFO:root:current mean train loss 1830.8249543898974
INFO:root:current train perplexity4.237949848175049
INFO:root:current mean train loss 1831.5469397844104
INFO:root:current train perplexity4.240625381469727
INFO:root:current mean train loss 1831.6741125289846
INFO:root:current train perplexity4.239824295043945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.62s/it]
INFO:root:final mean train loss: 1831.8537348960303
INFO:root:final train perplexity: 4.240622043609619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 1897.5457625152371
INFO:root:eval perplexity: 4.639578342437744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.38s/it]
INFO:root:eval mean loss: 2343.399997575909
INFO:root:eval perplexity: 6.797104835510254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [3:59:48<11:54:00, 571.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1799.4548085530598
INFO:root:current train perplexity4.159933090209961
INFO:root:current mean train loss 1829.51462382655
INFO:root:current train perplexity4.208375930786133
INFO:root:current mean train loss 1822.149897984096
INFO:root:current train perplexity4.183115482330322
INFO:root:current mean train loss 1820.7427492494937
INFO:root:current train perplexity4.184370994567871
INFO:root:current mean train loss 1827.1252147746536
INFO:root:current train perplexity4.209107398986816
INFO:root:current mean train loss 1821.9023614548544
INFO:root:current train perplexity4.199318885803223
INFO:root:current mean train loss 1821.5818534264197
INFO:root:current train perplexity4.197824001312256
INFO:root:current mean train loss 1816.598673277797
INFO:root:current train perplexity4.195939064025879
INFO:root:current mean train loss 1818.2245129335274
INFO:root:current train perplexity4.197197437286377
INFO:root:current mean train loss 1817.421936167267
INFO:root:current train perplexity4.196508407592773
INFO:root:current mean train loss 1820.3574777841568
INFO:root:current train perplexity4.2007904052734375
INFO:root:current mean train loss 1820.1134223259216
INFO:root:current train perplexity4.197591781616211
INFO:root:current mean train loss 1821.903737585529
INFO:root:current train perplexity4.201356410980225
INFO:root:current mean train loss 1822.238997813798
INFO:root:current train perplexity4.20035982131958
INFO:root:current mean train loss 1821.6628594559231
INFO:root:current train perplexity4.202521324157715
INFO:root:current mean train loss 1820.7438645250215
INFO:root:current train perplexity4.198371410369873
INFO:root:current mean train loss 1821.829782720857
INFO:root:current train perplexity4.201303482055664
INFO:root:current mean train loss 1822.4593696328714
INFO:root:current train perplexity4.2027974128723145
INFO:root:current mean train loss 1821.21351918003
INFO:root:current train perplexity4.2021942138671875
INFO:root:current mean train loss 1821.041997390081
INFO:root:current train perplexity4.201643943786621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.30s/it]
INFO:root:final mean train loss: 1820.4737984969408
INFO:root:final train perplexity: 4.202733516693115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 1903.0521015140182
INFO:root:eval perplexity: 4.660285949707031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.17s/it]
INFO:root:eval mean loss: 2347.4737094311004
INFO:root:eval perplexity: 6.819787502288818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [4:09:20<11:44:48, 571.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.2067364948552
INFO:root:current train perplexity4.193922996520996
INFO:root:current mean train loss 1795.697737457059
INFO:root:current train perplexity4.135809421539307
INFO:root:current mean train loss 1799.9953744975362
INFO:root:current train perplexity4.146553039550781
INFO:root:current mean train loss 1798.4352182516955
INFO:root:current train perplexity4.1511993408203125
INFO:root:current mean train loss 1800.8292994769522
INFO:root:current train perplexity4.154451370239258
INFO:root:current mean train loss 1801.6299044737755
INFO:root:current train perplexity4.149141311645508
INFO:root:current mean train loss 1805.4173553514406
INFO:root:current train perplexity4.161415100097656
INFO:root:current mean train loss 1806.2572192811128
INFO:root:current train perplexity4.158904075622559
INFO:root:current mean train loss 1808.5534155592766
INFO:root:current train perplexity4.162281036376953
INFO:root:current mean train loss 1808.7622062529058
INFO:root:current train perplexity4.161565780639648
INFO:root:current mean train loss 1808.321811349889
INFO:root:current train perplexity4.161771297454834
INFO:root:current mean train loss 1808.088648723365
INFO:root:current train perplexity4.162786960601807
INFO:root:current mean train loss 1806.0824074941138
INFO:root:current train perplexity4.157578945159912
INFO:root:current mean train loss 1808.5403631268643
INFO:root:current train perplexity4.163058757781982
INFO:root:current mean train loss 1807.49813912661
INFO:root:current train perplexity4.160592079162598
INFO:root:current mean train loss 1808.9051631702223
INFO:root:current train perplexity4.1637139320373535
INFO:root:current mean train loss 1809.0329569759056
INFO:root:current train perplexity4.162654399871826
INFO:root:current mean train loss 1810.0799228201508
INFO:root:current train perplexity4.165475368499756
INFO:root:current mean train loss 1810.0500612937517
INFO:root:current train perplexity4.166093349456787
INFO:root:current mean train loss 1810.7235539479086
INFO:root:current train perplexity4.16827392578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:29<00:00, 509.28s/it]
INFO:root:final mean train loss: 1810.3442195982748
INFO:root:final train perplexity: 4.169292449951172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 1894.9646186558068
INFO:root:eval perplexity: 4.629904747009277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.75s/it]
INFO:root:eval mean loss: 2344.1682124577515
INFO:root:eval perplexity: 6.8013763427734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [4:19:02<11:39:19, 574.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.1732598666488
INFO:root:current train perplexity4.079902172088623
INFO:root:current mean train loss 1791.4726346172863
INFO:root:current train perplexity4.104220390319824
INFO:root:current mean train loss 1793.4674375075701
INFO:root:current train perplexity4.122424602508545
INFO:root:current mean train loss 1788.2154353477436
INFO:root:current train perplexity4.111123561859131
INFO:root:current mean train loss 1792.0598208498227
INFO:root:current train perplexity4.121271133422852
INFO:root:current mean train loss 1793.4737327876485
INFO:root:current train perplexity4.122664451599121
INFO:root:current mean train loss 1792.7066322025194
INFO:root:current train perplexity4.12006950378418
INFO:root:current mean train loss 1795.09878290423
INFO:root:current train perplexity4.121174335479736
INFO:root:current mean train loss 1795.7347533041502
INFO:root:current train perplexity4.125123977661133
INFO:root:current mean train loss 1797.6921705273846
INFO:root:current train perplexity4.124996185302734
INFO:root:current mean train loss 1796.6618245058114
INFO:root:current train perplexity4.122941017150879
INFO:root:current mean train loss 1795.1581491526338
INFO:root:current train perplexity4.119187355041504
INFO:root:current mean train loss 1795.3143504617324
INFO:root:current train perplexity4.121577262878418
INFO:root:current mean train loss 1795.8664602917318
INFO:root:current train perplexity4.1250996589660645
INFO:root:current mean train loss 1797.0452142409335
INFO:root:current train perplexity4.130088806152344
INFO:root:current mean train loss 1798.4714142354983
INFO:root:current train perplexity4.132071018218994
INFO:root:current mean train loss 1798.6973435939149
INFO:root:current train perplexity4.133951187133789
INFO:root:current mean train loss 1799.4939672407165
INFO:root:current train perplexity4.135776996612549
INFO:root:current mean train loss 1799.627418871203
INFO:root:current train perplexity4.136293888092041
INFO:root:current mean train loss 1801.260532398633
INFO:root:current train perplexity4.1372480392456055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.48s/it]
INFO:root:final mean train loss: 1800.4041435945774
INFO:root:final train perplexity: 4.136735439300537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 1892.8874580978502
INFO:root:eval perplexity: 4.622133255004883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.07s/it]
INFO:root:eval mean loss: 2342.807099903729
INFO:root:eval perplexity: 6.793810844421387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:28:36<11:29:23, 574.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.379777018229
INFO:root:current train perplexity4.118415832519531
INFO:root:current mean train loss 1787.9782979910715
INFO:root:current train perplexity4.087601184844971
INFO:root:current mean train loss 1783.7269722123579
INFO:root:current train perplexity4.074118137359619
INFO:root:current mean train loss 1789.155818033854
INFO:root:current train perplexity4.089055061340332
INFO:root:current mean train loss 1790.7729517886514
INFO:root:current train perplexity4.097694396972656
INFO:root:current mean train loss 1792.2576970108696
INFO:root:current train perplexity4.099761962890625
INFO:root:current mean train loss 1789.8240907118056
INFO:root:current train perplexity4.099070072174072
INFO:root:current mean train loss 1792.863166110131
INFO:root:current train perplexity4.106878757476807
INFO:root:current mean train loss 1794.7745636160714
INFO:root:current train perplexity4.108511447906494
INFO:root:current mean train loss 1795.8762442407854
INFO:root:current train perplexity4.114901542663574
INFO:root:current mean train loss 1795.4954432003997
INFO:root:current train perplexity4.108876705169678
INFO:root:current mean train loss 1791.8082806266623
INFO:root:current train perplexity4.103135585784912
INFO:root:current mean train loss 1791.2984692861519
INFO:root:current train perplexity4.103538990020752
INFO:root:current mean train loss 1790.7041962890626
INFO:root:current train perplexity4.103347301483154
INFO:root:current mean train loss 1791.6608443955245
INFO:root:current train perplexity4.105661392211914
INFO:root:current mean train loss 1792.1558132595487
INFO:root:current train perplexity4.105961322784424
INFO:root:current mean train loss 1792.5415489447296
INFO:root:current train perplexity4.106106758117676
INFO:root:current mean train loss 1792.4547762846612
INFO:root:current train perplexity4.106685638427734
INFO:root:current mean train loss 1792.0499751953125
INFO:root:current train perplexity4.10651159286499
INFO:root:current mean train loss 1792.2285053031053
INFO:root:current train perplexity4.108275890350342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.10s/it]
INFO:root:final mean train loss: 1791.6655024741553
INFO:root:final train perplexity: 4.108325004577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it]
INFO:root:eval mean loss: 1908.6321112450132
INFO:root:eval perplexity: 4.6813645362854
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.43s/it]
INFO:root:eval mean loss: 2355.447708454538
INFO:root:eval perplexity: 6.864409446716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:38:08<11:18:42, 573.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.8058338994565
INFO:root:current train perplexity4.064647674560547
INFO:root:current mean train loss 1785.5182132720947
INFO:root:current train perplexity4.073571681976318
INFO:root:current mean train loss 1780.353954994515
INFO:root:current train perplexity4.069911003112793
INFO:root:current mean train loss 1778.4115304752272
INFO:root:current train perplexity4.071551322937012
INFO:root:current mean train loss 1779.390966151788
INFO:root:current train perplexity4.073951244354248
INFO:root:current mean train loss 1781.77396763982
INFO:root:current train perplexity4.070010662078857
INFO:root:current mean train loss 1778.6149426057848
INFO:root:current train perplexity4.066603660583496
INFO:root:current mean train loss 1779.6010264387035
INFO:root:current train perplexity4.069060802459717
INFO:root:current mean train loss 1780.7221009121881
INFO:root:current train perplexity4.070614337921143
INFO:root:current mean train loss 1783.0080064342867
INFO:root:current train perplexity4.079883098602295
INFO:root:current mean train loss 1783.3788724906278
INFO:root:current train perplexity4.078744411468506
INFO:root:current mean train loss 1784.4357870217138
INFO:root:current train perplexity4.080279350280762
INFO:root:current mean train loss 1784.2172878017366
INFO:root:current train perplexity4.080654621124268
INFO:root:current mean train loss 1784.0118362602145
INFO:root:current train perplexity4.079509258270264
INFO:root:current mean train loss 1782.6255858884101
INFO:root:current train perplexity4.077496528625488
INFO:root:current mean train loss 1782.962354267063
INFO:root:current train perplexity4.081303596496582
INFO:root:current mean train loss 1783.4854695926604
INFO:root:current train perplexity4.081792831420898
INFO:root:current mean train loss 1784.5396258490425
INFO:root:current train perplexity4.082734107971191
INFO:root:current mean train loss 1783.9718544699929
INFO:root:current train perplexity4.0810651779174805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.36s/it]
INFO:root:final mean train loss: 1783.2435745954874
INFO:root:final train perplexity: 4.081126689910889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 1902.6923170157359
INFO:root:eval perplexity: 4.658929347991943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.56s/it]
INFO:root:eval mean loss: 2353.8223279587764
INFO:root:eval perplexity: 6.855288028717041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:47:40<11:08:47, 573.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1806.7652587890625
INFO:root:current train perplexity4.0517425537109375
INFO:root:current mean train loss 1762.380606275086
INFO:root:current train perplexity4.015660762786865
INFO:root:current mean train loss 1758.7300324508449
INFO:root:current train perplexity4.009227752685547
INFO:root:current mean train loss 1769.761589173746
INFO:root:current train perplexity4.03438138961792
INFO:root:current mean train loss 1767.953029492665
INFO:root:current train perplexity4.026473045349121
INFO:root:current mean train loss 1768.2706392359405
INFO:root:current train perplexity4.023862838745117
INFO:root:current mean train loss 1768.2123257741944
INFO:root:current train perplexity4.0319600105285645
INFO:root:current mean train loss 1769.1430743261856
INFO:root:current train perplexity4.030304431915283
INFO:root:current mean train loss 1768.02345364527
INFO:root:current train perplexity4.031935214996338
INFO:root:current mean train loss 1771.0395227144784
INFO:root:current train perplexity4.038139343261719
INFO:root:current mean train loss 1770.6771253542338
INFO:root:current train perplexity4.037407875061035
INFO:root:current mean train loss 1770.5851085446136
INFO:root:current train perplexity4.04400634765625
INFO:root:current mean train loss 1771.0629591014979
INFO:root:current train perplexity4.04541540145874
INFO:root:current mean train loss 1771.2399397836193
INFO:root:current train perplexity4.047717094421387
INFO:root:current mean train loss 1772.1545393695385
INFO:root:current train perplexity4.04892110824585
INFO:root:current mean train loss 1771.8345434392345
INFO:root:current train perplexity4.0481085777282715
INFO:root:current mean train loss 1772.8259026982016
INFO:root:current train perplexity4.049912452697754
INFO:root:current mean train loss 1773.1398371500604
INFO:root:current train perplexity4.04770040512085
INFO:root:current mean train loss 1773.2825481020461
INFO:root:current train perplexity4.047715187072754
INFO:root:current mean train loss 1773.7845040786447
INFO:root:current train perplexity4.048544406890869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.86s/it]
INFO:root:final mean train loss: 1773.4434994819244
INFO:root:final train perplexity: 4.0497050285339355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it]
INFO:root:eval mean loss: 1884.6589900889296
INFO:root:eval perplexity: 4.591475963592529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.31s/it]
INFO:root:eval mean loss: 2336.7432069169713
INFO:root:eval perplexity: 6.7602033615112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [4:57:12<10:58:50, 572.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.2444974459136
INFO:root:current train perplexity4.075794696807861
INFO:root:current mean train loss 1788.0134800502233
INFO:root:current train perplexity4.055524826049805
INFO:root:current mean train loss 1777.6331830320105
INFO:root:current train perplexity4.038835048675537
INFO:root:current mean train loss 1770.3180249922116
INFO:root:current train perplexity4.031518936157227
INFO:root:current mean train loss 1771.7570064347674
INFO:root:current train perplexity4.024548530578613
INFO:root:current mean train loss 1769.3001553495574
INFO:root:current train perplexity4.018276691436768
INFO:root:current mean train loss 1765.2908428545577
INFO:root:current train perplexity4.013943672180176
INFO:root:current mean train loss 1763.8976243704803
INFO:root:current train perplexity4.013363838195801
INFO:root:current mean train loss 1765.5931395006526
INFO:root:current train perplexity4.013798713684082
INFO:root:current mean train loss 1764.9827662029224
INFO:root:current train perplexity4.018207550048828
INFO:root:current mean train loss 1765.187260023567
INFO:root:current train perplexity4.019498348236084
INFO:root:current mean train loss 1764.9333917810904
INFO:root:current train perplexity4.023240089416504
INFO:root:current mean train loss 1764.5545519880136
INFO:root:current train perplexity4.022817134857178
INFO:root:current mean train loss 1764.3870928780166
INFO:root:current train perplexity4.021182060241699
INFO:root:current mean train loss 1763.4280092472113
INFO:root:current train perplexity4.019736289978027
INFO:root:current mean train loss 1764.1690709825268
INFO:root:current train perplexity4.0224151611328125
INFO:root:current mean train loss 1765.2634355420703
INFO:root:current train perplexity4.023934364318848
INFO:root:current mean train loss 1764.6790779971302
INFO:root:current train perplexity4.01989221572876
INFO:root:current mean train loss 1765.8931220933093
INFO:root:current train perplexity4.025150299072266
INFO:root:current mean train loss 1765.5594545168296
INFO:root:current train perplexity4.024771690368652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.65s/it]
INFO:root:final mean train loss: 1766.1367694741239
INFO:root:final train perplexity: 4.026436805725098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 1905.5701423807348
INFO:root:eval perplexity: 4.66978645324707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 2359.251473501219
INFO:root:eval perplexity: 6.885796070098877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [5:06:49<10:50:28, 573.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1766.6636366733285
INFO:root:current train perplexity4.024598121643066
INFO:root:current mean train loss 1769.522353379043
INFO:root:current train perplexity4.024855613708496
INFO:root:current mean train loss 1772.8191817169818
INFO:root:current train perplexity4.01000452041626
INFO:root:current mean train loss 1761.9807666300337
INFO:root:current train perplexity3.99202036857605
INFO:root:current mean train loss 1757.2226953786328
INFO:root:current train perplexity3.995854616165161
INFO:root:current mean train loss 1755.58167650423
INFO:root:current train perplexity3.9931256771087646
INFO:root:current mean train loss 1756.7706293132776
INFO:root:current train perplexity3.998412847518921
INFO:root:current mean train loss 1757.2519527964123
INFO:root:current train perplexity4.002191066741943
INFO:root:current mean train loss 1758.7495385076086
INFO:root:current train perplexity4.006860733032227
INFO:root:current mean train loss 1758.884060257945
INFO:root:current train perplexity4.003349781036377
INFO:root:current mean train loss 1757.776691850057
INFO:root:current train perplexity4.002166748046875
INFO:root:current mean train loss 1756.4481101849574
INFO:root:current train perplexity3.999260425567627
INFO:root:current mean train loss 1756.983101461937
INFO:root:current train perplexity3.9989287853240967
INFO:root:current mean train loss 1757.4224230893406
INFO:root:current train perplexity3.998335599899292
INFO:root:current mean train loss 1758.303029187917
INFO:root:current train perplexity4.001277446746826
INFO:root:current mean train loss 1757.6068895281867
INFO:root:current train perplexity4.000446319580078
INFO:root:current mean train loss 1758.2407731040541
INFO:root:current train perplexity4.001243591308594
INFO:root:current mean train loss 1757.501911664515
INFO:root:current train perplexity3.9977266788482666
INFO:root:current mean train loss 1759.0789731336688
INFO:root:current train perplexity4.001405715942383
INFO:root:current mean train loss 1758.132360720475
INFO:root:current train perplexity3.998387098312378

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.70s/it]
INFO:root:final mean train loss: 1757.722660374413
INFO:root:final train perplexity: 3.9998059272766113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 1870.5561852421322
INFO:root:eval perplexity: 4.53940486907959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2324.482633117243
INFO:root:eval perplexity: 6.6927571296691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [5:16:31<10:43:41, 576.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.7693115234374
INFO:root:current train perplexity3.947580575942993
INFO:root:current mean train loss 1744.6210258483886
INFO:root:current train perplexity3.9798691272735596
INFO:root:current mean train loss 1749.8368849534254
INFO:root:current train perplexity3.985809803009033
INFO:root:current mean train loss 1743.3821041531032
INFO:root:current train perplexity3.9705686569213867
INFO:root:current mean train loss 1744.9727103855298
INFO:root:current train perplexity3.97599196434021
INFO:root:current mean train loss 1741.5712411063057
INFO:root:current train perplexity3.9641456604003906
INFO:root:current mean train loss 1740.3045733827532
INFO:root:current train perplexity3.9641854763031006
INFO:root:current mean train loss 1743.8376994885896
INFO:root:current train perplexity3.964297294616699
INFO:root:current mean train loss 1741.2093118357104
INFO:root:current train perplexity3.9566173553466797
INFO:root:current mean train loss 1742.894157663981
INFO:root:current train perplexity3.9599556922912598
INFO:root:current mean train loss 1744.2528634701134
INFO:root:current train perplexity3.9611034393310547
INFO:root:current mean train loss 1745.2461078512258
INFO:root:current train perplexity3.961909770965576
INFO:root:current mean train loss 1746.084452795604
INFO:root:current train perplexity3.9649879932403564
INFO:root:current mean train loss 1749.2464104147518
INFO:root:current train perplexity3.9720752239227295
INFO:root:current mean train loss 1750.8451967004228
INFO:root:current train perplexity3.9737603664398193
INFO:root:current mean train loss 1751.8545462583884
INFO:root:current train perplexity3.975395441055298
INFO:root:current mean train loss 1752.0633425057651
INFO:root:current train perplexity3.976501226425171
INFO:root:current mean train loss 1751.6596088756214
INFO:root:current train perplexity3.9759252071380615
INFO:root:current mean train loss 1751.3520843834006
INFO:root:current train perplexity3.977240800857544
INFO:root:current mean train loss 1750.7680867720624
INFO:root:current train perplexity3.976694107055664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.10s/it]
INFO:root:final mean train loss: 1750.3753919115707
INFO:root:final train perplexity: 3.976696014404297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.46s/it]
INFO:root:eval mean loss: 1910.4374363676031
INFO:root:eval perplexity: 4.688204288482666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.93s/it]
INFO:root:eval mean loss: 2363.114306294326
INFO:root:eval perplexity: 6.907583236694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [5:26:00<10:31:35, 574.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1738.8019052480722
INFO:root:current train perplexity3.9165003299713135
INFO:root:current mean train loss 1735.698806331656
INFO:root:current train perplexity3.9392552375793457
INFO:root:current mean train loss 1735.024205617526
INFO:root:current train perplexity3.935568332672119
INFO:root:current mean train loss 1735.3167021976542
INFO:root:current train perplexity3.9361042976379395
INFO:root:current mean train loss 1736.6508384720585
INFO:root:current train perplexity3.935678243637085
INFO:root:current mean train loss 1738.0210572346864
INFO:root:current train perplexity3.944225788116455
INFO:root:current mean train loss 1736.1152222941862
INFO:root:current train perplexity3.9395205974578857
INFO:root:current mean train loss 1736.6866297973477
INFO:root:current train perplexity3.936689853668213
INFO:root:current mean train loss 1739.84542056772
INFO:root:current train perplexity3.944131851196289
INFO:root:current mean train loss 1740.9469707571009
INFO:root:current train perplexity3.945464611053467
INFO:root:current mean train loss 1739.3252889337425
INFO:root:current train perplexity3.942262887954712
INFO:root:current mean train loss 1739.5523788465111
INFO:root:current train perplexity3.947744846343994
INFO:root:current mean train loss 1739.8291897934307
INFO:root:current train perplexity3.9475953578948975
INFO:root:current mean train loss 1739.291070587668
INFO:root:current train perplexity3.9460196495056152
INFO:root:current mean train loss 1740.2178136868176
INFO:root:current train perplexity3.9465644359588623
INFO:root:current mean train loss 1741.5687918460437
INFO:root:current train perplexity3.94828200340271
INFO:root:current mean train loss 1741.2318198215983
INFO:root:current train perplexity3.946812868118286
INFO:root:current mean train loss 1741.7603964475547
INFO:root:current train perplexity3.948331356048584
INFO:root:current mean train loss 1742.4945355813175
INFO:root:current train perplexity3.9492766857147217
INFO:root:current mean train loss 1742.1409289717494
INFO:root:current train perplexity3.9495134353637695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.50s/it]
INFO:root:final mean train loss: 1741.5713002661294
INFO:root:final train perplexity: 3.9491801261901855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 1878.6519320873504
INFO:root:eval perplexity: 4.569223403930664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it]
INFO:root:eval mean loss: 2335.8696622375055
INFO:root:eval perplexity: 6.755374431610107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:35:41<10:24:11, 576.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1747.1603900016623
INFO:root:current train perplexity3.91378116607666
INFO:root:current mean train loss 1739.0904157186292
INFO:root:current train perplexity3.9121034145355225
INFO:root:current mean train loss 1737.3729746293047
INFO:root:current train perplexity3.923646926879883
INFO:root:current mean train loss 1731.3858180941663
INFO:root:current train perplexity3.914304733276367
INFO:root:current mean train loss 1732.9538070122724
INFO:root:current train perplexity3.921779155731201
INFO:root:current mean train loss 1732.060486661866
INFO:root:current train perplexity3.920302152633667
INFO:root:current mean train loss 1736.8140826926108
INFO:root:current train perplexity3.933420181274414
INFO:root:current mean train loss 1739.905546788905
INFO:root:current train perplexity3.9353089332580566
INFO:root:current mean train loss 1738.9053731146007
INFO:root:current train perplexity3.9293181896209717
INFO:root:current mean train loss 1736.679001008001
INFO:root:current train perplexity3.923687219619751
INFO:root:current mean train loss 1735.596539540962
INFO:root:current train perplexity3.9256722927093506
INFO:root:current mean train loss 1734.9743321097676
INFO:root:current train perplexity3.9261534214019775
INFO:root:current mean train loss 1735.2472904918736
INFO:root:current train perplexity3.927077293395996
INFO:root:current mean train loss 1735.585829353059
INFO:root:current train perplexity3.9267079830169678
INFO:root:current mean train loss 1736.3378137386787
INFO:root:current train perplexity3.927820920944214
INFO:root:current mean train loss 1736.7293240919316
INFO:root:current train perplexity3.9280457496643066
INFO:root:current mean train loss 1737.372940513854
INFO:root:current train perplexity3.928184747695923
INFO:root:current mean train loss 1737.182366786859
INFO:root:current train perplexity3.9278063774108887
INFO:root:current mean train loss 1736.118281621238
INFO:root:current train perplexity3.9285271167755127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.26s/it]
INFO:root:final mean train loss: 1734.7894954094668
INFO:root:final train perplexity: 3.9281134605407715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 1873.5212774614915
INFO:root:eval perplexity: 4.550303936004639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it]
INFO:root:eval mean loss: 2332.6561642910574
INFO:root:eval perplexity: 6.737644672393799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:45:12<10:13:08, 574.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.146806196733
INFO:root:current train perplexity3.9936797618865967
INFO:root:current mean train loss 1724.2924848676803
INFO:root:current train perplexity3.8953542709350586
INFO:root:current mean train loss 1726.3674374259479
INFO:root:current train perplexity3.904301643371582
INFO:root:current mean train loss 1726.365035765424
INFO:root:current train perplexity3.9003474712371826
INFO:root:current mean train loss 1729.6855545972096
INFO:root:current train perplexity3.900874137878418
INFO:root:current mean train loss 1730.4749846635732
INFO:root:current train perplexity3.904646873474121
INFO:root:current mean train loss 1728.7674702396175
INFO:root:current train perplexity3.898932695388794
INFO:root:current mean train loss 1726.9591667078719
INFO:root:current train perplexity3.899055004119873
INFO:root:current mean train loss 1726.9575776313002
INFO:root:current train perplexity3.8990800380706787
INFO:root:current mean train loss 1730.0283213844675
INFO:root:current train perplexity3.904466390609741
INFO:root:current mean train loss 1730.5836221485533
INFO:root:current train perplexity3.907504081726074
INFO:root:current mean train loss 1728.6403052658782
INFO:root:current train perplexity3.9056081771850586
INFO:root:current mean train loss 1729.1864567070731
INFO:root:current train perplexity3.9073684215545654
INFO:root:current mean train loss 1729.5992404638039
INFO:root:current train perplexity3.9084982872009277
INFO:root:current mean train loss 1728.9329899734507
INFO:root:current train perplexity3.908071517944336
INFO:root:current mean train loss 1728.6507529581247
INFO:root:current train perplexity3.9072651863098145
INFO:root:current mean train loss 1727.5211568840684
INFO:root:current train perplexity3.9048409461975098
INFO:root:current mean train loss 1728.1005707411373
INFO:root:current train perplexity3.9054014682769775
INFO:root:current mean train loss 1729.127426914192
INFO:root:current train perplexity3.90744686126709
INFO:root:current mean train loss 1728.6280634474342
INFO:root:current train perplexity3.90696382522583

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.38s/it]
INFO:root:final mean train loss: 1728.309023950897
INFO:root:final train perplexity: 3.9080886840820312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.43s/it]
INFO:root:eval mean loss: 1869.4360035564882
INFO:root:eval perplexity: 4.535294532775879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.95s/it]
INFO:root:eval mean loss: 2331.034375779172
INFO:root:eval perplexity: 6.728713512420654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [5:54:53<10:05:31, 576.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.2671203613281
INFO:root:current train perplexity3.874004364013672
INFO:root:current mean train loss 1734.5487661361694
INFO:root:current train perplexity3.9007649421691895
INFO:root:current mean train loss 1728.0326934279058
INFO:root:current train perplexity3.901315450668335
INFO:root:current mean train loss 1719.3395538330078
INFO:root:current train perplexity3.8897435665130615
INFO:root:current mean train loss 1715.6068557311442
INFO:root:current train perplexity3.882071018218994
INFO:root:current mean train loss 1716.7205588600852
INFO:root:current train perplexity3.8758180141448975
INFO:root:current mean train loss 1719.3379792620422
INFO:root:current train perplexity3.8813769817352295
INFO:root:current mean train loss 1718.2024259462462
INFO:root:current train perplexity3.879668951034546
INFO:root:current mean train loss 1720.2404842653136
INFO:root:current train perplexity3.8820197582244873
INFO:root:current mean train loss 1722.4279478665055
INFO:root:current train perplexity3.8834221363067627
INFO:root:current mean train loss 1724.4894168126443
INFO:root:current train perplexity3.8857686519622803
INFO:root:current mean train loss 1724.523580348238
INFO:root:current train perplexity3.8892552852630615
INFO:root:current mean train loss 1723.6294584491743
INFO:root:current train perplexity3.8913116455078125
INFO:root:current mean train loss 1723.214301787227
INFO:root:current train perplexity3.8877484798431396
INFO:root:current mean train loss 1723.3557833289565
INFO:root:current train perplexity3.887327194213867
INFO:root:current mean train loss 1723.490904084051
INFO:root:current train perplexity3.8865513801574707
INFO:root:current mean train loss 1722.5116132506575
INFO:root:current train perplexity3.885106086730957
INFO:root:current mean train loss 1723.155105944033
INFO:root:current train perplexity3.884976625442505
INFO:root:current mean train loss 1722.0184764236017
INFO:root:current train perplexity3.885457754135132
INFO:root:current mean train loss 1721.40215412314
INFO:root:current train perplexity3.8849616050720215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:22<00:00, 502.57s/it]
INFO:root:final mean train loss: 1721.0094065856165
INFO:root:final train perplexity: 3.885655403137207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 1863.2549161437555
INFO:root:eval perplexity: 4.512679100036621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.11s/it]
INFO:root:eval mean loss: 2326.9788857317985
INFO:root:eval perplexity: 6.7064337730407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [6:04:27<9:55:00, 575.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.6654459635417
INFO:root:current train perplexity3.8491742610931396
INFO:root:current mean train loss 1715.0049787850216
INFO:root:current train perplexity3.8684401512145996
INFO:root:current mean train loss 1717.798767837213
INFO:root:current train perplexity3.868769884109497
INFO:root:current mean train loss 1721.1182995782383
INFO:root:current train perplexity3.871284246444702
INFO:root:current mean train loss 1718.9140090085148
INFO:root:current train perplexity3.8765761852264404
INFO:root:current mean train loss 1716.8528062732942
INFO:root:current train perplexity3.876314163208008
INFO:root:current mean train loss 1717.0637678279434
INFO:root:current train perplexity3.871145009994507
INFO:root:current mean train loss 1717.2944863543414
INFO:root:current train perplexity3.8744044303894043
INFO:root:current mean train loss 1716.7289826703495
INFO:root:current train perplexity3.8719844818115234
INFO:root:current mean train loss 1713.9928585637815
INFO:root:current train perplexity3.8647518157958984
INFO:root:current mean train loss 1713.6181696695573
INFO:root:current train perplexity3.8651845455169678
INFO:root:current mean train loss 1713.274026849072
INFO:root:current train perplexity3.8639585971832275
INFO:root:current mean train loss 1712.050702811245
INFO:root:current train perplexity3.8629701137542725
INFO:root:current mean train loss 1713.498336667199
INFO:root:current train perplexity3.8645431995391846
INFO:root:current mean train loss 1714.5629306674416
INFO:root:current train perplexity3.86692476272583
INFO:root:current mean train loss 1715.2565360948877
INFO:root:current train perplexity3.868791103363037
INFO:root:current mean train loss 1716.2601644869633
INFO:root:current train perplexity3.869615077972412
INFO:root:current mean train loss 1716.779636153519
INFO:root:current train perplexity3.8704135417938232
INFO:root:current mean train loss 1717.2345620421536
INFO:root:current train perplexity3.8717708587646484
INFO:root:current mean train loss 1717.117010388215
INFO:root:current train perplexity3.871551513671875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.17s/it]
INFO:root:final mean train loss: 1716.9973085742974
INFO:root:final train perplexity: 3.8733792304992676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 1877.6034550227173
INFO:root:eval perplexity: 4.565350532531738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it]
INFO:root:eval mean loss: 2340.4426122354275
INFO:root:eval perplexity: 6.780685901641846
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [6:13:57<9:43:43, 574.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.8457523469
INFO:root:current train perplexity3.8379945755004883
INFO:root:current mean train loss 1710.9708862304688
INFO:root:current train perplexity3.825731039047241
INFO:root:current mean train loss 1700.8604824852398
INFO:root:current train perplexity3.8154518604278564
INFO:root:current mean train loss 1699.8143988340598
INFO:root:current train perplexity3.814587354660034
INFO:root:current mean train loss 1701.4893804112555
INFO:root:current train perplexity3.8156092166900635
INFO:root:current mean train loss 1701.3455810546875
INFO:root:current train perplexity3.822845220565796
INFO:root:current mean train loss 1704.569079626723
INFO:root:current train perplexity3.832225799560547
INFO:root:current mean train loss 1707.7579356916933
INFO:root:current train perplexity3.835946798324585
INFO:root:current mean train loss 1709.3332944369924
INFO:root:current train perplexity3.8386359214782715
INFO:root:current mean train loss 1711.386904393313
INFO:root:current train perplexity3.842507839202881
INFO:root:current mean train loss 1715.0172206497912
INFO:root:current train perplexity3.8535730838775635
INFO:root:current mean train loss 1713.6202940949065
INFO:root:current train perplexity3.8502426147460938
INFO:root:current mean train loss 1712.2900611164075
INFO:root:current train perplexity3.847700357437134
INFO:root:current mean train loss 1713.1212057822252
INFO:root:current train perplexity3.849425792694092
INFO:root:current mean train loss 1713.5115270445024
INFO:root:current train perplexity3.851799964904785
INFO:root:current mean train loss 1713.7127600363367
INFO:root:current train perplexity3.852606773376465
INFO:root:current mean train loss 1712.4536064506008
INFO:root:current train perplexity3.8511483669281006
INFO:root:current mean train loss 1712.4554800841108
INFO:root:current train perplexity3.851919174194336
INFO:root:current mean train loss 1711.5368244568592
INFO:root:current train perplexity3.8518238067626953
INFO:root:current mean train loss 1710.562066594395
INFO:root:current train perplexity3.8512251377105713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.12s/it]
INFO:root:final mean train loss: 1709.7343003604367
INFO:root:final train perplexity: 3.8512558937072754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it]
INFO:root:eval mean loss: 1866.49581887536
INFO:root:eval perplexity: 4.524524211883545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2331.9684946046655
INFO:root:eval perplexity: 6.733855724334717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [6:23:24<9:32:01, 572.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1699.1503890798062
INFO:root:current train perplexity3.8308277130126953
INFO:root:current mean train loss 1693.3896845812237
INFO:root:current train perplexity3.8231558799743652
INFO:root:current mean train loss 1695.3351101345486
INFO:root:current train perplexity3.8214075565338135
INFO:root:current mean train loss 1699.501405902148
INFO:root:current train perplexity3.8300693035125732
INFO:root:current mean train loss 1698.8192357837781
INFO:root:current train perplexity3.829881191253662
INFO:root:current mean train loss 1698.5160021740744
INFO:root:current train perplexity3.827090263366699
INFO:root:current mean train loss 1696.4820695070875
INFO:root:current train perplexity3.821190357208252
INFO:root:current mean train loss 1699.6626407491074
INFO:root:current train perplexity3.825096607208252
INFO:root:current mean train loss 1703.9270094523251
INFO:root:current train perplexity3.8321125507354736
INFO:root:current mean train loss 1704.0241383756145
INFO:root:current train perplexity3.834764242172241
INFO:root:current mean train loss 1703.9471199099282
INFO:root:current train perplexity3.835685968399048
INFO:root:current mean train loss 1705.6922702676063
INFO:root:current train perplexity3.8352115154266357
INFO:root:current mean train loss 1704.4843633560765
INFO:root:current train perplexity3.83141827583313
INFO:root:current mean train loss 1705.2724747467594
INFO:root:current train perplexity3.8338749408721924
INFO:root:current mean train loss 1704.843553730086
INFO:root:current train perplexity3.8324646949768066
INFO:root:current mean train loss 1705.8676366630878
INFO:root:current train perplexity3.8355588912963867
INFO:root:current mean train loss 1705.0760157064287
INFO:root:current train perplexity3.8349130153656006
INFO:root:current mean train loss 1705.540141919947
INFO:root:current train perplexity3.8357536792755127
INFO:root:current mean train loss 1705.223068976288
INFO:root:current train perplexity3.8360838890075684
INFO:root:current mean train loss 1704.7959510529506
INFO:root:current train perplexity3.835062026977539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:33<00:00, 513.21s/it]
INFO:root:final mean train loss: 1704.475503233786
INFO:root:final train perplexity: 3.8353166580200195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 38.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 38.00s/it]
INFO:root:eval mean loss: 1869.6406578983822
INFO:root:eval perplexity: 4.536045074462891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it]
INFO:root:eval mean loss: 2336.574883210744
INFO:root:eval perplexity: 6.759271621704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:33:11<9:26:55, 576.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1694.3485196431477
INFO:root:current train perplexity3.7936716079711914
INFO:root:current mean train loss 1700.7689869160554
INFO:root:current train perplexity3.8131144046783447
INFO:root:current mean train loss 1711.94040205672
INFO:root:current train perplexity3.827728509902954
INFO:root:current mean train loss 1708.1652906013258
INFO:root:current train perplexity3.8186190128326416
INFO:root:current mean train loss 1702.6690376035629
INFO:root:current train perplexity3.8191871643066406
INFO:root:current mean train loss 1704.6478306303088
INFO:root:current train perplexity3.8194997310638428
INFO:root:current mean train loss 1705.2852155312723
INFO:root:current train perplexity3.8198018074035645
INFO:root:current mean train loss 1702.3095381080207
INFO:root:current train perplexity3.810563802719116
INFO:root:current mean train loss 1701.602674484253
INFO:root:current train perplexity3.8127152919769287
INFO:root:current mean train loss 1700.137588807378
INFO:root:current train perplexity3.8106777667999268
INFO:root:current mean train loss 1700.5933096112997
INFO:root:current train perplexity3.813234329223633
INFO:root:current mean train loss 1700.0895591914455
INFO:root:current train perplexity3.8116567134857178
INFO:root:current mean train loss 1701.547619289822
INFO:root:current train perplexity3.8150525093078613
INFO:root:current mean train loss 1701.8332155768715
INFO:root:current train perplexity3.81620192527771
INFO:root:current mean train loss 1700.8643336984562
INFO:root:current train perplexity3.8166747093200684
INFO:root:current mean train loss 1700.1504368985206
INFO:root:current train perplexity3.814918041229248
INFO:root:current mean train loss 1699.151892823993
INFO:root:current train perplexity3.814626932144165
INFO:root:current mean train loss 1697.9859114139276
INFO:root:current train perplexity3.814317226409912
INFO:root:current mean train loss 1698.2084716925642
INFO:root:current train perplexity3.814119577407837

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.76s/it]
INFO:root:final mean train loss: 1697.414560107348
INFO:root:final train perplexity: 3.8140180110931396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 1877.5612074398825
INFO:root:eval perplexity: 4.565195083618164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2343.4977512224345
INFO:root:eval perplexity: 6.797649383544922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:42:46<9:16:40, 575.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1669.536386343149
INFO:root:current train perplexity3.778203248977661
INFO:root:current mean train loss 1691.417754856886
INFO:root:current train perplexity3.7579824924468994
INFO:root:current mean train loss 1678.8092700080692
INFO:root:current train perplexity3.767690658569336
INFO:root:current mean train loss 1680.0567474852735
INFO:root:current train perplexity3.7703568935394287
INFO:root:current mean train loss 1684.306539244571
INFO:root:current train perplexity3.7748019695281982
INFO:root:current mean train loss 1685.2941654197887
INFO:root:current train perplexity3.7815542221069336
INFO:root:current mean train loss 1688.2038247635858
INFO:root:current train perplexity3.788487195968628
INFO:root:current mean train loss 1689.1278730181123
INFO:root:current train perplexity3.7898991107940674
INFO:root:current mean train loss 1686.8667786470346
INFO:root:current train perplexity3.7836198806762695
INFO:root:current mean train loss 1686.1145946089043
INFO:root:current train perplexity3.783763885498047
INFO:root:current mean train loss 1687.390836484105
INFO:root:current train perplexity3.7856922149658203
INFO:root:current mean train loss 1688.9737566376418
INFO:root:current train perplexity3.7885489463806152
INFO:root:current mean train loss 1690.3877065836252
INFO:root:current train perplexity3.7891194820404053
INFO:root:current mean train loss 1688.9537213130118
INFO:root:current train perplexity3.7868354320526123
INFO:root:current mean train loss 1688.7568735175325
INFO:root:current train perplexity3.7875614166259766
INFO:root:current mean train loss 1688.191640950951
INFO:root:current train perplexity3.7853267192840576
INFO:root:current mean train loss 1689.9136847101674
INFO:root:current train perplexity3.79034423828125
INFO:root:current mean train loss 1691.2903234656624
INFO:root:current train perplexity3.7936363220214844
INFO:root:current mean train loss 1692.599912025885
INFO:root:current train perplexity3.7978005409240723
INFO:root:current mean train loss 1693.9496459003774
INFO:root:current train perplexity3.8010308742523193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.78s/it]
INFO:root:final mean train loss: 1692.5889513070572
INFO:root:final train perplexity: 3.799530506134033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 1856.6900950763243
INFO:root:eval perplexity: 4.4887847900390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.41s/it]
INFO:root:eval mean loss: 2321.443613904588
INFO:root:eval perplexity: 6.676141738891602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [6:52:15<9:05:14, 573.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1696.2139444986979
INFO:root:current train perplexity3.774153470993042
INFO:root:current mean train loss 1673.6407733623798
INFO:root:current train perplexity3.7397162914276123
INFO:root:current mean train loss 1677.6949558423912
INFO:root:current train perplexity3.7428741455078125
INFO:root:current mean train loss 1681.790263597893
INFO:root:current train perplexity3.7577171325683594
INFO:root:current mean train loss 1683.7210784202398
INFO:root:current train perplexity3.762533664703369
INFO:root:current mean train loss 1686.6040891251473
INFO:root:current train perplexity3.770719051361084
INFO:root:current mean train loss 1685.1322492327008
INFO:root:current train perplexity3.7678685188293457
INFO:root:current mean train loss 1686.110250060199
INFO:root:current train perplexity3.774953603744507
INFO:root:current mean train loss 1686.961963773061
INFO:root:current train perplexity3.777769088745117
INFO:root:current mean train loss 1685.4024587323588
INFO:root:current train perplexity3.7751173973083496
INFO:root:current mean train loss 1683.5521947768127
INFO:root:current train perplexity3.7750439643859863
INFO:root:current mean train loss 1682.7657970867326
INFO:root:current train perplexity3.7721614837646484
INFO:root:current mean train loss 1682.484494886941
INFO:root:current train perplexity3.7701873779296875
INFO:root:current mean train loss 1682.557520449072
INFO:root:current train perplexity3.773463010787964
INFO:root:current mean train loss 1683.9248012729458
INFO:root:current train perplexity3.7755777835845947
INFO:root:current mean train loss 1686.3763762031506
INFO:root:current train perplexity3.7785463333129883
INFO:root:current mean train loss 1686.7449089190711
INFO:root:current train perplexity3.7807388305664062
INFO:root:current mean train loss 1688.630148826996
INFO:root:current train perplexity3.7831692695617676
INFO:root:current mean train loss 1688.899679281933
INFO:root:current train perplexity3.7834372520446777
INFO:root:current mean train loss 1687.6923049531451
INFO:root:current train perplexity3.7822930812835693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.52s/it]
INFO:root:final mean train loss: 1687.1114717715327
INFO:root:final train perplexity: 3.7831525802612305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it]
INFO:root:eval mean loss: 1857.9352854194372
INFO:root:eval perplexity: 4.493307113647461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2328.59329808012
INFO:root:eval perplexity: 6.715293884277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [7:01:47<8:55:02, 573.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1651.7342451379654
INFO:root:current train perplexity3.707050085067749
INFO:root:current mean train loss 1676.5604023836097
INFO:root:current train perplexity3.746889114379883
INFO:root:current mean train loss 1677.053381298235
INFO:root:current train perplexity3.7526028156280518
INFO:root:current mean train loss 1676.944582188851
INFO:root:current train perplexity3.7584738731384277
INFO:root:current mean train loss 1677.2633332459452
INFO:root:current train perplexity3.758340358734131
INFO:root:current mean train loss 1673.7281590100833
INFO:root:current train perplexity3.7555088996887207
INFO:root:current mean train loss 1678.1065143661854
INFO:root:current train perplexity3.7612102031707764
INFO:root:current mean train loss 1678.915390892999
INFO:root:current train perplexity3.7639412879943848
INFO:root:current mean train loss 1679.5330624631051
INFO:root:current train perplexity3.7650179862976074
INFO:root:current mean train loss 1679.5504945716737
INFO:root:current train perplexity3.767165184020996
INFO:root:current mean train loss 1680.2586887946215
INFO:root:current train perplexity3.768353223800659
INFO:root:current mean train loss 1681.5796812634521
INFO:root:current train perplexity3.769620656967163
INFO:root:current mean train loss 1680.383495682607
INFO:root:current train perplexity3.7658169269561768
INFO:root:current mean train loss 1680.908609844794
INFO:root:current train perplexity3.7657957077026367
INFO:root:current mean train loss 1681.4876232344939
INFO:root:current train perplexity3.764936685562134
INFO:root:current mean train loss 1682.7827528772928
INFO:root:current train perplexity3.768491506576538
INFO:root:current mean train loss 1682.6662851876756
INFO:root:current train perplexity3.768634080886841
INFO:root:current mean train loss 1683.2058607165857
INFO:root:current train perplexity3.768049955368042
INFO:root:current mean train loss 1682.5883816820774
INFO:root:current train perplexity3.7673521041870117
INFO:root:current mean train loss 1683.0258399089546
INFO:root:current train perplexity3.7689619064331055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.31s/it]
INFO:root:final mean train loss: 1682.450810619514
INFO:root:final train perplexity: 3.7692720890045166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 1856.297708714262
INFO:root:eval perplexity: 4.487360000610352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 2325.083654092559
INFO:root:eval perplexity: 6.696047306060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [7:11:20<8:45:34, 573.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.8539237976074
INFO:root:current train perplexity3.7945966720581055
INFO:root:current mean train loss 1683.5082010408728
INFO:root:current train perplexity3.742621421813965
INFO:root:current mean train loss 1672.1141583991773
INFO:root:current train perplexity3.72709321975708
INFO:root:current mean train loss 1667.6968595064604
INFO:root:current train perplexity3.7165262699127197
INFO:root:current mean train loss 1664.0659661128602
INFO:root:current train perplexity3.71673583984375
INFO:root:current mean train loss 1668.81542903819
INFO:root:current train perplexity3.728461503982544
INFO:root:current mean train loss 1672.3061821259648
INFO:root:current train perplexity3.731874942779541
INFO:root:current mean train loss 1669.8356030848638
INFO:root:current train perplexity3.7332136631011963
INFO:root:current mean train loss 1673.3927390487106
INFO:root:current train perplexity3.7385647296905518
INFO:root:current mean train loss 1674.82814437423
INFO:root:current train perplexity3.739838123321533
INFO:root:current mean train loss 1674.5994907465197
INFO:root:current train perplexity3.7419166564941406
INFO:root:current mean train loss 1676.2676132569197
INFO:root:current train perplexity3.7461023330688477
INFO:root:current mean train loss 1675.5730424711976
INFO:root:current train perplexity3.745936632156372
INFO:root:current mean train loss 1675.5164172041102
INFO:root:current train perplexity3.748795986175537
INFO:root:current mean train loss 1675.1002414890977
INFO:root:current train perplexity3.7493364810943604
INFO:root:current mean train loss 1675.2742574940557
INFO:root:current train perplexity3.751143455505371
INFO:root:current mean train loss 1676.9816514528716
INFO:root:current train perplexity3.7548747062683105
INFO:root:current mean train loss 1676.9993785763004
INFO:root:current train perplexity3.753065347671509
INFO:root:current mean train loss 1677.8674293485321
INFO:root:current train perplexity3.7545018196105957
INFO:root:current mean train loss 1678.100920077011
INFO:root:current train perplexity3.755117177963257

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.31s/it]
INFO:root:final mean train loss: 1677.7785206851006
INFO:root:final train perplexity: 3.75540828704834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 1861.538001960051
INFO:root:eval perplexity: 4.506418228149414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 2331.6063414228724
INFO:root:eval perplexity: 6.731860160827637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [7:20:58<8:37:15, 574.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1663.9207251277971
INFO:root:current train perplexity3.719667911529541
INFO:root:current mean train loss 1662.7078715793336
INFO:root:current train perplexity3.7112317085266113
INFO:root:current mean train loss 1653.5730745037256
INFO:root:current train perplexity3.697368621826172
INFO:root:current mean train loss 1657.984670724143
INFO:root:current train perplexity3.700784206390381
INFO:root:current mean train loss 1658.205415912081
INFO:root:current train perplexity3.7140371799468994
INFO:root:current mean train loss 1660.5963613802307
INFO:root:current train perplexity3.7125985622406006
INFO:root:current mean train loss 1661.4133281063578
INFO:root:current train perplexity3.712637424468994
INFO:root:current mean train loss 1662.8974726600013
INFO:root:current train perplexity3.717557430267334
INFO:root:current mean train loss 1663.480582368225
INFO:root:current train perplexity3.7236738204956055
INFO:root:current mean train loss 1665.0630570935668
INFO:root:current train perplexity3.726257085800171
INFO:root:current mean train loss 1667.0575851172237
INFO:root:current train perplexity3.7316982746124268
INFO:root:current mean train loss 1668.4173311109164
INFO:root:current train perplexity3.7339837551116943
INFO:root:current mean train loss 1669.7253144477886
INFO:root:current train perplexity3.7353878021240234
INFO:root:current mean train loss 1670.6032980021837
INFO:root:current train perplexity3.7349956035614014
INFO:root:current mean train loss 1670.824036509986
INFO:root:current train perplexity3.7325613498687744
INFO:root:current mean train loss 1671.7824635997292
INFO:root:current train perplexity3.7336084842681885
INFO:root:current mean train loss 1672.9441715310827
INFO:root:current train perplexity3.7358038425445557
INFO:root:current mean train loss 1673.0349826373658
INFO:root:current train perplexity3.735844373703003
INFO:root:current mean train loss 1671.6923144764878
INFO:root:current train perplexity3.7357237339019775
INFO:root:current mean train loss 1672.0331399023141
INFO:root:current train perplexity3.7372398376464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.00s/it]
INFO:root:final mean train loss: 1671.766771709925
INFO:root:final train perplexity: 3.737645387649536
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.98s/it]
INFO:root:eval mean loss: 1853.643201462766
INFO:root:eval perplexity: 4.477736949920654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.45s/it]
INFO:root:eval mean loss: 2319.778612502078
INFO:root:eval perplexity: 6.667059421539307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [7:30:28<8:26:21, 573.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.315174336336
INFO:root:current train perplexity3.7272984981536865
INFO:root:current mean train loss 1661.4073640457307
INFO:root:current train perplexity3.7019741535186768
INFO:root:current mean train loss 1654.6535349596268
INFO:root:current train perplexity3.68621563911438
INFO:root:current mean train loss 1654.8043203689344
INFO:root:current train perplexity3.697540521621704
INFO:root:current mean train loss 1655.2781222546437
INFO:root:current train perplexity3.701470375061035
INFO:root:current mean train loss 1658.4071798165107
INFO:root:current train perplexity3.7079765796661377
INFO:root:current mean train loss 1661.9403506391027
INFO:root:current train perplexity3.715548515319824
INFO:root:current mean train loss 1662.7661415807586
INFO:root:current train perplexity3.717167854309082
INFO:root:current mean train loss 1666.4286454164637
INFO:root:current train perplexity3.7246432304382324
INFO:root:current mean train loss 1666.3380994166066
INFO:root:current train perplexity3.71980881690979
INFO:root:current mean train loss 1666.8810030132913
INFO:root:current train perplexity3.7204532623291016
INFO:root:current mean train loss 1669.4409320302718
INFO:root:current train perplexity3.7239885330200195
INFO:root:current mean train loss 1669.3612510081616
INFO:root:current train perplexity3.721989154815674
INFO:root:current mean train loss 1668.5451701195625
INFO:root:current train perplexity3.7222437858581543
INFO:root:current mean train loss 1668.8459422133158
INFO:root:current train perplexity3.72489070892334
INFO:root:current mean train loss 1669.2785606336533
INFO:root:current train perplexity3.7264020442962646
INFO:root:current mean train loss 1669.0317238312307
INFO:root:current train perplexity3.7280139923095703
INFO:root:current mean train loss 1670.0476977864946
INFO:root:current train perplexity3.7286486625671387
INFO:root:current mean train loss 1668.9095999232334
INFO:root:current train perplexity3.727342128753662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.63s/it]
INFO:root:final mean train loss: 1667.686488903236
INFO:root:final train perplexity: 3.725637674331665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 1863.209649268617
INFO:root:eval perplexity: 4.512514591217041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it]
INFO:root:eval mean loss: 2333.494859627798
INFO:root:eval perplexity: 6.74226713180542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:39:57<8:15:35, 571.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1630.4210774739583
INFO:root:current train perplexity3.6264684200286865
INFO:root:current mean train loss 1669.7570938773777
INFO:root:current train perplexity3.7147018909454346
INFO:root:current mean train loss 1655.7784043422964
INFO:root:current train perplexity3.6991138458251953
INFO:root:current mean train loss 1662.8689817398313
INFO:root:current train perplexity3.7121379375457764
INFO:root:current mean train loss 1662.2806884765625
INFO:root:current train perplexity3.707210063934326
INFO:root:current mean train loss 1659.8279417760164
INFO:root:current train perplexity3.7016842365264893
INFO:root:current mean train loss 1657.9072452204014
INFO:root:current train perplexity3.6968564987182617
INFO:root:current mean train loss 1659.964148376038
INFO:root:current train perplexity3.7019782066345215
INFO:root:current mean train loss 1658.1406811673216
INFO:root:current train perplexity3.7015745639801025
INFO:root:current mean train loss 1658.7184755752646
INFO:root:current train perplexity3.703998327255249
INFO:root:current mean train loss 1658.8928970712745
INFO:root:current train perplexity3.706662654876709
INFO:root:current mean train loss 1660.1279430440723
INFO:root:current train perplexity3.707894802093506
INFO:root:current mean train loss 1660.431362726659
INFO:root:current train perplexity3.7067081928253174
INFO:root:current mean train loss 1660.5601710098324
INFO:root:current train perplexity3.7075350284576416
INFO:root:current mean train loss 1662.9116890735424
INFO:root:current train perplexity3.7119550704956055
INFO:root:current mean train loss 1663.1595227735663
INFO:root:current train perplexity3.713677167892456
INFO:root:current mean train loss 1662.5806671614987
INFO:root:current train perplexity3.711698532104492
INFO:root:current mean train loss 1663.353857137163
INFO:root:current train perplexity3.7138097286224365
INFO:root:current mean train loss 1663.2312746158316
INFO:root:current train perplexity3.714113712310791
INFO:root:current mean train loss 1664.2434657004733
INFO:root:current train perplexity3.7145135402679443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.40s/it]
INFO:root:final mean train loss: 1664.2071861309412
INFO:root:final train perplexity: 3.715428113937378
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 1853.3442222649323
INFO:root:eval perplexity: 4.476655006408691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.39s/it]
INFO:root:eval mean loss: 2325.838256403064
INFO:root:eval perplexity: 6.7001800537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [7:49:40<8:08:58, 575.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1656.7385902404785
INFO:root:current train perplexity3.731823205947876
INFO:root:current mean train loss 1649.7076184821851
INFO:root:current train perplexity3.6663599014282227
INFO:root:current mean train loss 1656.836204791891
INFO:root:current train perplexity3.676016092300415
INFO:root:current mean train loss 1656.7453550775367
INFO:root:current train perplexity3.6796071529388428
INFO:root:current mean train loss 1660.764693931297
INFO:root:current train perplexity3.69000506401062
INFO:root:current mean train loss 1661.3158431662653
INFO:root:current train perplexity3.685542583465576
INFO:root:current mean train loss 1664.2196019812475
INFO:root:current train perplexity3.6952433586120605
INFO:root:current mean train loss 1665.255745976349
INFO:root:current train perplexity3.700390338897705
INFO:root:current mean train loss 1664.1163875873272
INFO:root:current train perplexity3.6989357471466064
INFO:root:current mean train loss 1663.6050133439094
INFO:root:current train perplexity3.698450803756714
INFO:root:current mean train loss 1662.4088257782219
INFO:root:current train perplexity3.6987404823303223
INFO:root:current mean train loss 1661.271685273403
INFO:root:current train perplexity3.6977012157440186
INFO:root:current mean train loss 1661.1635231909813
INFO:root:current train perplexity3.6976656913757324
INFO:root:current mean train loss 1660.170612690327
INFO:root:current train perplexity3.697030544281006
INFO:root:current mean train loss 1660.0064406581432
INFO:root:current train perplexity3.6975550651550293
INFO:root:current mean train loss 1660.0005865271346
INFO:root:current train perplexity3.698166847229004
INFO:root:current mean train loss 1659.1918316261442
INFO:root:current train perplexity3.7004013061523438
INFO:root:current mean train loss 1659.5209712145236
INFO:root:current train perplexity3.7005155086517334
INFO:root:current mean train loss 1659.8519212481237
INFO:root:current train perplexity3.7007882595062256
INFO:root:current mean train loss 1659.7780378195564
INFO:root:current train perplexity3.7006306648254395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.75s/it]
INFO:root:final mean train loss: 1659.241589921806
INFO:root:final train perplexity: 3.7009060382843018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it]
INFO:root:eval mean loss: 1866.3772202079178
INFO:root:eval perplexity: 4.524089336395264
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.62s/it]
INFO:root:eval mean loss: 2338.608062527704
INFO:root:eval perplexity: 6.7705206871032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [7:59:14<7:59:04, 574.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1629.3913051060267
INFO:root:current train perplexity3.640501022338867
INFO:root:current mean train loss 1647.6172120779152
INFO:root:current train perplexity3.6557774543762207
INFO:root:current mean train loss 1648.4364474499562
INFO:root:current train perplexity3.6629350185394287
INFO:root:current mean train loss 1647.6264592474033
INFO:root:current train perplexity3.6693756580352783
INFO:root:current mean train loss 1648.748880704952
INFO:root:current train perplexity3.6723365783691406
INFO:root:current mean train loss 1647.1719454850438
INFO:root:current train perplexity3.670884132385254
INFO:root:current mean train loss 1648.5294962502408
INFO:root:current train perplexity3.669520378112793
INFO:root:current mean train loss 1648.9757482633095
INFO:root:current train perplexity3.6684064865112305
INFO:root:current mean train loss 1648.7660612324241
INFO:root:current train perplexity3.6664516925811768
INFO:root:current mean train loss 1648.7750282729764
INFO:root:current train perplexity3.6683928966522217
INFO:root:current mean train loss 1649.590356817691
INFO:root:current train perplexity3.6736810207366943
INFO:root:current mean train loss 1648.9466518737422
INFO:root:current train perplexity3.672422170639038
INFO:root:current mean train loss 1651.849164194637
INFO:root:current train perplexity3.679185628890991
INFO:root:current mean train loss 1651.6771476411925
INFO:root:current train perplexity3.680628538131714
INFO:root:current mean train loss 1651.298324342758
INFO:root:current train perplexity3.680049419403076
INFO:root:current mean train loss 1651.738649115861
INFO:root:current train perplexity3.681950330734253
INFO:root:current mean train loss 1652.028579036419
INFO:root:current train perplexity3.682497262954712
INFO:root:current mean train loss 1652.7776926519396
INFO:root:current train perplexity3.6838014125823975
INFO:root:current mean train loss 1653.1615837266343
INFO:root:current train perplexity3.6834394931793213
INFO:root:current mean train loss 1654.7909707176557
INFO:root:current train perplexity3.687242269515991

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.49s/it]
INFO:root:final mean train loss: 1654.531460375841
INFO:root:final train perplexity: 3.6871843338012695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 1847.9161675635805
INFO:root:eval perplexity: 4.457045555114746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.79s/it]
INFO:root:eval mean loss: 2320.797593137051
INFO:root:eval perplexity: 6.6726155281066895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [8:08:59<7:51:58, 577.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1630.737227006392
INFO:root:current train perplexity3.63875675201416
INFO:root:current mean train loss 1640.4423820771367
INFO:root:current train perplexity3.636068344116211
INFO:root:current mean train loss 1641.506610612224
INFO:root:current train perplexity3.6477930545806885
INFO:root:current mean train loss 1634.456415895556
INFO:root:current train perplexity3.6334893703460693
INFO:root:current mean train loss 1643.1891482111723
INFO:root:current train perplexity3.645372152328491
INFO:root:current mean train loss 1644.329477910018
INFO:root:current train perplexity3.650094509124756
INFO:root:current mean train loss 1645.03534063849
INFO:root:current train perplexity3.6563048362731934
INFO:root:current mean train loss 1645.848413850869
INFO:root:current train perplexity3.655938148498535
INFO:root:current mean train loss 1646.7102641398583
INFO:root:current train perplexity3.6583900451660156
INFO:root:current mean train loss 1648.3759715078286
INFO:root:current train perplexity3.6634132862091064
INFO:root:current mean train loss 1651.0689964079722
INFO:root:current train perplexity3.6663246154785156
INFO:root:current mean train loss 1651.7042676032509
INFO:root:current train perplexity3.669846296310425
INFO:root:current mean train loss 1652.2307002593368
INFO:root:current train perplexity3.6728036403656006
INFO:root:current mean train loss 1652.5575254113573
INFO:root:current train perplexity3.6736035346984863
INFO:root:current mean train loss 1653.5941991454745
INFO:root:current train perplexity3.6767375469207764
INFO:root:current mean train loss 1653.2987037941261
INFO:root:current train perplexity3.6756887435913086
INFO:root:current mean train loss 1650.9179927097791
INFO:root:current train perplexity3.6726388931274414
INFO:root:current mean train loss 1651.9476412365957
INFO:root:current train perplexity3.6741623878479004
INFO:root:current mean train loss 1651.1473238210076
INFO:root:current train perplexity3.6727168560028076
INFO:root:current mean train loss 1650.301748374714
INFO:root:current train perplexity3.6736626625061035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:19<00:00, 499.44s/it]
INFO:root:final mean train loss: 1649.8014201954406
INFO:root:final train perplexity: 3.673454761505127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 1845.649804947224
INFO:root:eval perplexity: 4.448884010314941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.19s/it]
INFO:root:eval mean loss: 2318.7634701559728
INFO:root:eval perplexity: 6.661525249481201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [8:18:29<7:40:30, 575.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1612.7101947830383
INFO:root:current train perplexity3.614278793334961
INFO:root:current mean train loss 1629.2651020321039
INFO:root:current train perplexity3.64582896232605
INFO:root:current mean train loss 1631.9867008060953
INFO:root:current train perplexity3.645817279815674
INFO:root:current mean train loss 1635.3429681763014
INFO:root:current train perplexity3.642423629760742
INFO:root:current mean train loss 1636.617199125744
INFO:root:current train perplexity3.646239995956421
INFO:root:current mean train loss 1639.6748245788888
INFO:root:current train perplexity3.649364948272705
INFO:root:current mean train loss 1639.5095109395018
INFO:root:current train perplexity3.649437665939331
INFO:root:current mean train loss 1642.1036174282108
INFO:root:current train perplexity3.6499552726745605
INFO:root:current mean train loss 1643.4205036098529
INFO:root:current train perplexity3.653219699859619
INFO:root:current mean train loss 1644.3109905751287
INFO:root:current train perplexity3.6559391021728516
INFO:root:current mean train loss 1645.1728275542114
INFO:root:current train perplexity3.6565818786621094
INFO:root:current mean train loss 1644.8730411997108
INFO:root:current train perplexity3.655855417251587
INFO:root:current mean train loss 1645.5215167241086
INFO:root:current train perplexity3.655860185623169
INFO:root:current mean train loss 1645.4738085478523
INFO:root:current train perplexity3.6580677032470703
INFO:root:current mean train loss 1646.4749501511926
INFO:root:current train perplexity3.6606240272521973
INFO:root:current mean train loss 1646.7932135846445
INFO:root:current train perplexity3.6611688137054443
INFO:root:current mean train loss 1646.2507562121677
INFO:root:current train perplexity3.6607754230499268
INFO:root:current mean train loss 1647.080981020839
INFO:root:current train perplexity3.66257643699646
INFO:root:current mean train loss 1647.439838071105
INFO:root:current train perplexity3.661997079849243
INFO:root:current mean train loss 1646.4491648248393
INFO:root:current train perplexity3.6637561321258545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:30<00:00, 510.77s/it]
INFO:root:final mean train loss: 1646.4491648248393
INFO:root:final train perplexity: 3.6637561321258545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 1859.5120975142675
INFO:root:eval perplexity: 4.4990410804748535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.28s/it]
INFO:root:eval mean loss: 2336.8924209919383
INFO:root:eval perplexity: 6.761026859283447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [8:28:13<7:32:50, 578.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1609.3878051757813
INFO:root:current train perplexity3.6012396812438965
INFO:root:current mean train loss 1615.7149627685546
INFO:root:current train perplexity3.5997884273529053
INFO:root:current mean train loss 1623.548575032552
INFO:root:current train perplexity3.6084389686584473
INFO:root:current mean train loss 1624.3575790405273
INFO:root:current train perplexity3.6182973384857178
INFO:root:current mean train loss 1629.5911437988282
INFO:root:current train perplexity3.6273179054260254
INFO:root:current mean train loss 1631.625165201823
INFO:root:current train perplexity3.624274730682373
INFO:root:current mean train loss 1632.15842023577
INFO:root:current train perplexity3.6249892711639404
INFO:root:current mean train loss 1632.1832336425782
INFO:root:current train perplexity3.6255762577056885
INFO:root:current mean train loss 1634.4290420193142
INFO:root:current train perplexity3.630977153778076
INFO:root:current mean train loss 1635.797986328125
INFO:root:current train perplexity3.633183479309082
INFO:root:current mean train loss 1635.8574823552913
INFO:root:current train perplexity3.6350502967834473
INFO:root:current mean train loss 1638.2815329996745
INFO:root:current train perplexity3.6407604217529297
INFO:root:current mean train loss 1638.2316597806491
INFO:root:current train perplexity3.6405434608459473
INFO:root:current mean train loss 1639.8983284214564
INFO:root:current train perplexity3.6445066928863525
INFO:root:current mean train loss 1639.850628092448
INFO:root:current train perplexity3.6449246406555176
INFO:root:current mean train loss 1640.8859811401367
INFO:root:current train perplexity3.647763967514038
INFO:root:current mean train loss 1642.4304660931755
INFO:root:current train perplexity3.6497011184692383
INFO:root:current mean train loss 1642.1752434624566
INFO:root:current train perplexity3.6484079360961914
INFO:root:current mean train loss 1642.9000537751851
INFO:root:current train perplexity3.6504993438720703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:18<00:00, 498.41s/it]
INFO:root:final mean train loss: 1641.706398952867
INFO:root:final train perplexity: 3.6500775814056396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 1858.3853361522051
INFO:root:eval perplexity: 4.494942665100098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2332.258226327017
INFO:root:eval perplexity: 6.735451698303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [8:37:46<7:21:55, 576.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1616.0526194852941
INFO:root:current train perplexity3.634948492050171
INFO:root:current mean train loss 1640.4000765808628
INFO:root:current train perplexity3.63207745552063
INFO:root:current mean train loss 1638.9793026128673
INFO:root:current train perplexity3.631279230117798
INFO:root:current mean train loss 1634.7908438793868
INFO:root:current train perplexity3.6261377334594727
INFO:root:current mean train loss 1633.4001447279677
INFO:root:current train perplexity3.628471851348877
INFO:root:current mean train loss 1639.2657605287416
INFO:root:current train perplexity3.63893461227417
INFO:root:current mean train loss 1640.8159870166253
INFO:root:current train perplexity3.639012575149536
INFO:root:current mean train loss 1640.5173697371863
INFO:root:current train perplexity3.6382834911346436
INFO:root:current mean train loss 1640.9386453990398
INFO:root:current train perplexity3.6379647254943848
INFO:root:current mean train loss 1642.0289481026787
INFO:root:current train perplexity3.6403937339782715
INFO:root:current mean train loss 1639.601503805425
INFO:root:current train perplexity3.6371989250183105
INFO:root:current mean train loss 1640.6193302328713
INFO:root:current train perplexity3.640143394470215
INFO:root:current mean train loss 1639.4693046826853
INFO:root:current train perplexity3.6385586261749268
INFO:root:current mean train loss 1639.7449507195568
INFO:root:current train perplexity3.6400671005249023
INFO:root:current mean train loss 1639.210566809418
INFO:root:current train perplexity3.6392934322357178
INFO:root:current mean train loss 1638.921370946976
INFO:root:current train perplexity3.639630079269409
INFO:root:current mean train loss 1637.5976570049183
INFO:root:current train perplexity3.638075828552246
INFO:root:current mean train loss 1637.18525638036
INFO:root:current train perplexity3.637847661972046
INFO:root:current mean train loss 1637.7016557222155
INFO:root:current train perplexity3.6394708156585693
INFO:root:current mean train loss 1639.0866095553354
INFO:root:current train perplexity3.641416311264038

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.48s/it]
INFO:root:final mean train loss: 1638.8609143294173
INFO:root:final train perplexity: 3.6418955326080322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 1848.4906265583445
INFO:root:eval perplexity: 4.459116458892822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it]
INFO:root:eval mean loss: 2323.7584323747783
INFO:root:eval perplexity: 6.688793659210205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:47:29<7:13:57, 578.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1600.9627111098346
INFO:root:current train perplexity3.575321912765503
INFO:root:current mean train loss 1625.0851431319963
INFO:root:current train perplexity3.622091770172119
INFO:root:current mean train loss 1630.1815425514155
INFO:root:current train perplexity3.617894172668457
INFO:root:current mean train loss 1630.0798412939746
INFO:root:current train perplexity3.6098294258117676
INFO:root:current mean train loss 1627.9909639841949
INFO:root:current train perplexity3.610710859298706
INFO:root:current mean train loss 1628.899773872747
INFO:root:current train perplexity3.608672618865967
INFO:root:current mean train loss 1628.3752160297959
INFO:root:current train perplexity3.6114819049835205
INFO:root:current mean train loss 1628.101407168022
INFO:root:current train perplexity3.613358497619629
INFO:root:current mean train loss 1630.522176253138
INFO:root:current train perplexity3.6196513175964355
INFO:root:current mean train loss 1632.8680860368293
INFO:root:current train perplexity3.624688148498535
INFO:root:current mean train loss 1633.4019726987503
INFO:root:current train perplexity3.6264259815216064
INFO:root:current mean train loss 1633.2475352346162
INFO:root:current train perplexity3.62487530708313
INFO:root:current mean train loss 1633.4171392851943
INFO:root:current train perplexity3.626161813735962
INFO:root:current mean train loss 1634.2335328612548
INFO:root:current train perplexity3.6285054683685303
INFO:root:current mean train loss 1634.652431514639
INFO:root:current train perplexity3.629582405090332
INFO:root:current mean train loss 1635.5885846114377
INFO:root:current train perplexity3.631244659423828
INFO:root:current mean train loss 1634.6178299006226
INFO:root:current train perplexity3.629173994064331
INFO:root:current mean train loss 1635.2678936493026
INFO:root:current train perplexity3.6300244331359863
INFO:root:current mean train loss 1633.6934689321072
INFO:root:current train perplexity3.6277387142181396
INFO:root:current mean train loss 1634.1796770855215
INFO:root:current train perplexity3.6290056705474854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.40s/it]
INFO:root:final mean train loss: 1634.543671654621
INFO:root:final train perplexity: 3.629517078399658
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 1848.4669990269006
INFO:root:eval perplexity: 4.459031581878662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it]
INFO:root:eval mean loss: 2326.1285755346853
INFO:root:eval perplexity: 6.701771259307861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [8:56:59<7:02:16, 575.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1617.1942928538604
INFO:root:current train perplexity3.593291759490967
INFO:root:current mean train loss 1608.3098726588369
INFO:root:current train perplexity3.5778234004974365
INFO:root:current mean train loss 1620.2058810655815
INFO:root:current train perplexity3.59244704246521
INFO:root:current mean train loss 1627.5016783798521
INFO:root:current train perplexity3.6016364097595215
INFO:root:current mean train loss 1630.1744926097388
INFO:root:current train perplexity3.6088573932647705
INFO:root:current mean train loss 1625.7598464882742
INFO:root:current train perplexity3.598191499710083
INFO:root:current mean train loss 1627.9358572073613
INFO:root:current train perplexity3.603501081466675
INFO:root:current mean train loss 1628.0189148843208
INFO:root:current train perplexity3.6025235652923584
INFO:root:current mean train loss 1627.057584338967
INFO:root:current train perplexity3.6033201217651367
INFO:root:current mean train loss 1626.2035611671104
INFO:root:current train perplexity3.6015572547912598
INFO:root:current mean train loss 1626.5270682497323
INFO:root:current train perplexity3.6034095287323
INFO:root:current mean train loss 1628.3504952597266
INFO:root:current train perplexity3.605468511581421
INFO:root:current mean train loss 1627.4609610163432
INFO:root:current train perplexity3.6041760444641113
INFO:root:current mean train loss 1629.0911875173483
INFO:root:current train perplexity3.608739137649536
INFO:root:current mean train loss 1630.2505279898562
INFO:root:current train perplexity3.610941171646118
INFO:root:current mean train loss 1630.801062460333
INFO:root:current train perplexity3.6116514205932617
INFO:root:current mean train loss 1630.9615918441948
INFO:root:current train perplexity3.612889528274536
INFO:root:current mean train loss 1632.1212389655689
INFO:root:current train perplexity3.616727590560913
INFO:root:current mean train loss 1631.1935133642921
INFO:root:current train perplexity3.6162426471710205
INFO:root:current mean train loss 1630.5930805841756
INFO:root:current train perplexity3.6169166564941406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.68s/it]
INFO:root:final mean train loss: 1630.0896218935168
INFO:root:final train perplexity: 3.6167893409729004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 1859.66775664201
INFO:root:eval perplexity: 4.499607086181641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 2337.3160387404423
INFO:root:eval perplexity: 6.763370037078857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [9:06:37<6:53:11, 576.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.3873614142922
INFO:root:current train perplexity3.5992186069488525
INFO:root:current mean train loss 1629.701179867699
INFO:root:current train perplexity3.6082732677459717
INFO:root:current mean train loss 1627.047902576959
INFO:root:current train perplexity3.611463785171509
INFO:root:current mean train loss 1627.5566800988238
INFO:root:current train perplexity3.61429762840271
INFO:root:current mean train loss 1627.3745518871863
INFO:root:current train perplexity3.610212802886963
INFO:root:current mean train loss 1626.7451934814453
INFO:root:current train perplexity3.6024951934814453
INFO:root:current mean train loss 1626.768523073482
INFO:root:current train perplexity3.6022236347198486
INFO:root:current mean train loss 1623.1563946406047
INFO:root:current train perplexity3.5988006591796875
INFO:root:current mean train loss 1622.059569046794
INFO:root:current train perplexity3.5965945720672607
INFO:root:current mean train loss 1624.4450908061888
INFO:root:current train perplexity3.6035091876983643
INFO:root:current mean train loss 1627.1891793811812
INFO:root:current train perplexity3.608229398727417
INFO:root:current mean train loss 1626.7188065411294
INFO:root:current train perplexity3.6093974113464355
INFO:root:current mean train loss 1626.418279701979
INFO:root:current train perplexity3.6082727909088135
INFO:root:current mean train loss 1625.8136245995238
INFO:root:current train perplexity3.607631206512451
INFO:root:current mean train loss 1626.3671543214887
INFO:root:current train perplexity3.6080191135406494
INFO:root:current mean train loss 1626.5593113023408
INFO:root:current train perplexity3.607471227645874
INFO:root:current mean train loss 1627.0328314252895
INFO:root:current train perplexity3.6082372665405273
INFO:root:current mean train loss 1627.2604623509749
INFO:root:current train perplexity3.607043743133545
INFO:root:current mean train loss 1627.6680546174468
INFO:root:current train perplexity3.6078591346740723
INFO:root:current mean train loss 1628.120836335469
INFO:root:current train perplexity3.6093122959136963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.91s/it]
INFO:root:final mean train loss: 1627.5640942087332
INFO:root:final train perplexity: 3.6095926761627197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.14s/it]
INFO:root:eval mean loss: 1848.330196732325
INFO:root:eval perplexity: 4.458538055419922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it]
INFO:root:eval mean loss: 2325.464441610566
INFO:root:eval perplexity: 6.698131561279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [9:16:03<6:41:26, 573.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.2130040785846
INFO:root:current train perplexity3.5829575061798096
INFO:root:current mean train loss 1613.4985193201014
INFO:root:current train perplexity3.5809340476989746
INFO:root:current mean train loss 1618.929586417215
INFO:root:current train perplexity3.593473434448242
INFO:root:current mean train loss 1621.3750072925122
INFO:root:current train perplexity3.6035690307617188
INFO:root:current mean train loss 1621.4887033364207
INFO:root:current train perplexity3.5997471809387207
INFO:root:current mean train loss 1621.444513513288
INFO:root:current train perplexity3.5968871116638184
INFO:root:current mean train loss 1619.8721415944342
INFO:root:current train perplexity3.5930685997009277
INFO:root:current mean train loss 1618.936677386047
INFO:root:current train perplexity3.5927114486694336
INFO:root:current mean train loss 1620.349213784428
INFO:root:current train perplexity3.5904383659362793
INFO:root:current mean train loss 1620.015296587484
INFO:root:current train perplexity3.588731288909912
INFO:root:current mean train loss 1618.3514579808107
INFO:root:current train perplexity3.5858542919158936
INFO:root:current mean train loss 1620.3839957064215
INFO:root:current train perplexity3.59014892578125
INFO:root:current mean train loss 1622.2273092663243
INFO:root:current train perplexity3.5919833183288574
INFO:root:current mean train loss 1621.7878346577447
INFO:root:current train perplexity3.592197895050049
INFO:root:current mean train loss 1621.4789209641992
INFO:root:current train perplexity3.5918874740600586
INFO:root:current mean train loss 1622.9398883422466
INFO:root:current train perplexity3.5944926738739014
INFO:root:current mean train loss 1623.5674740211193
INFO:root:current train perplexity3.597588539123535
INFO:root:current mean train loss 1624.0439427138042
INFO:root:current train perplexity3.597811222076416
INFO:root:current mean train loss 1623.763485369695
INFO:root:current train perplexity3.598494052886963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.66s/it]
INFO:root:final mean train loss: 1623.3157130100483
INFO:root:final train perplexity: 3.5975186824798584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.41s/it]
INFO:root:eval mean loss: 1842.7410763138575
INFO:root:eval perplexity: 4.4384307861328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 2318.3039949024824
INFO:root:eval perplexity: 6.659021854400635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [9:25:30<6:30:26, 571.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1667.590087890625
INFO:root:current train perplexity3.6190967559814453
INFO:root:current mean train loss 1591.9204939299939
INFO:root:current train perplexity3.5162062644958496
INFO:root:current mean train loss 1607.115752871674
INFO:root:current train perplexity3.558607339859009
INFO:root:current mean train loss 1606.9247412271056
INFO:root:current train perplexity3.5518651008605957
INFO:root:current mean train loss 1607.1366999232355
INFO:root:current train perplexity3.5516974925994873
INFO:root:current mean train loss 1607.5063872926264
INFO:root:current train perplexity3.5556249618530273
INFO:root:current mean train loss 1611.9042530756851
INFO:root:current train perplexity3.5675747394561768
INFO:root:current mean train loss 1614.277719003183
INFO:root:current train perplexity3.5733795166015625
INFO:root:current mean train loss 1615.4543348964016
INFO:root:current train perplexity3.5737369060516357
INFO:root:current mean train loss 1617.5143673509822
INFO:root:current train perplexity3.577932119369507
INFO:root:current mean train loss 1618.1199850055748
INFO:root:current train perplexity3.5822832584381104
INFO:root:current mean train loss 1621.220750092162
INFO:root:current train perplexity3.5874996185302734
INFO:root:current mean train loss 1621.4480958453034
INFO:root:current train perplexity3.5869858264923096
INFO:root:current mean train loss 1621.0282129618795
INFO:root:current train perplexity3.5893898010253906
INFO:root:current mean train loss 1620.2475553722081
INFO:root:current train perplexity3.5893778800964355
INFO:root:current mean train loss 1620.4095084321166
INFO:root:current train perplexity3.5898048877716064
INFO:root:current mean train loss 1619.6474658142165
INFO:root:current train perplexity3.58970308303833
INFO:root:current mean train loss 1619.3442504022153
INFO:root:current train perplexity3.587794542312622
INFO:root:current mean train loss 1619.969341587147
INFO:root:current train perplexity3.5882394313812256
INFO:root:current mean train loss 1620.0276258209904
INFO:root:current train perplexity3.588550090789795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:31<00:00, 511.51s/it]
INFO:root:final mean train loss: 1620.3404325253423
INFO:root:final train perplexity: 3.5890872478485107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 1836.2079935276763
INFO:root:eval perplexity: 4.415041446685791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.01s/it]
INFO:root:eval mean loss: 2313.956651187112
INFO:root:eval perplexity: 6.635389804840088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [9:35:14<6:23:29, 575.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1617.8809942948192
INFO:root:current train perplexity3.605952501296997
INFO:root:current mean train loss 1619.1209491120667
INFO:root:current train perplexity3.5915615558624268
INFO:root:current mean train loss 1623.4605835518337
INFO:root:current train perplexity3.5871078968048096
INFO:root:current mean train loss 1617.3210659684805
INFO:root:current train perplexity3.576429843902588
INFO:root:current mean train loss 1612.4183297168668
INFO:root:current train perplexity3.5680038928985596
INFO:root:current mean train loss 1616.4415793593448
INFO:root:current train perplexity3.5749809741973877
INFO:root:current mean train loss 1614.314505187298
INFO:root:current train perplexity3.5762572288513184
INFO:root:current mean train loss 1616.2287714803003
INFO:root:current train perplexity3.5816445350646973
INFO:root:current mean train loss 1615.7556900564714
INFO:root:current train perplexity3.580049753189087
INFO:root:current mean train loss 1614.6272968877515
INFO:root:current train perplexity3.57749080657959
INFO:root:current mean train loss 1615.0818249643492
INFO:root:current train perplexity3.5785303115844727
INFO:root:current mean train loss 1614.6279587051079
INFO:root:current train perplexity3.577129602432251
INFO:root:current mean train loss 1615.0954446643957
INFO:root:current train perplexity3.5770976543426514
INFO:root:current mean train loss 1615.7145195556825
INFO:root:current train perplexity3.578932046890259
INFO:root:current mean train loss 1615.7773787624153
INFO:root:current train perplexity3.5775864124298096
INFO:root:current mean train loss 1615.7412310280715
INFO:root:current train perplexity3.576512098312378
INFO:root:current mean train loss 1617.0350316161355
INFO:root:current train perplexity3.5797722339630127
INFO:root:current mean train loss 1617.3819786724205
INFO:root:current train perplexity3.5805094242095947
INFO:root:current mean train loss 1617.0826595866333
INFO:root:current train perplexity3.5807838439941406
INFO:root:current mean train loss 1616.567214178629
INFO:root:current train perplexity3.5780563354492188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:20<00:00, 500.72s/it]
INFO:root:final mean train loss: 1616.4591508904791
INFO:root:final train perplexity: 3.5781173706054688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 1838.8888125588708
INFO:root:eval perplexity: 4.424623489379883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2317.6950666278813
INFO:root:eval perplexity: 6.655706882476807
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [9:44:49<6:13:53, 575.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1584.5745510525173
INFO:root:current train perplexity3.4991424083709717
INFO:root:current mean train loss 1597.5886131735408
INFO:root:current train perplexity3.5364952087402344
INFO:root:current mean train loss 1607.6441660735566
INFO:root:current train perplexity3.566850423812866
INFO:root:current mean train loss 1611.7256375267393
INFO:root:current train perplexity3.5679268836975098
INFO:root:current mean train loss 1608.5110529628369
INFO:root:current train perplexity3.563084363937378
INFO:root:current mean train loss 1607.4392558994577
INFO:root:current train perplexity3.55808424949646
INFO:root:current mean train loss 1607.5112556121635
INFO:root:current train perplexity3.5573198795318604
INFO:root:current mean train loss 1610.4910547007685
INFO:root:current train perplexity3.561206579208374
INFO:root:current mean train loss 1611.2569261760802
INFO:root:current train perplexity3.565633773803711
INFO:root:current mean train loss 1610.957511054145
INFO:root:current train perplexity3.5632176399230957
INFO:root:current mean train loss 1609.1296445632993
INFO:root:current train perplexity3.5576155185699463
INFO:root:current mean train loss 1608.4023390219245
INFO:root:current train perplexity3.5561861991882324
INFO:root:current mean train loss 1609.5745282713262
INFO:root:current train perplexity3.5621020793914795
INFO:root:current mean train loss 1611.0604103682283
INFO:root:current train perplexity3.564772605895996
INFO:root:current mean train loss 1610.636001799432
INFO:root:current train perplexity3.565932512283325
INFO:root:current mean train loss 1612.154784520467
INFO:root:current train perplexity3.569852352142334
INFO:root:current mean train loss 1612.504858786436
INFO:root:current train perplexity3.5694918632507324
INFO:root:current mean train loss 1612.917759345973
INFO:root:current train perplexity3.569988489151001
INFO:root:current mean train loss 1613.8133599441296
INFO:root:current train perplexity3.570157527923584
INFO:root:current mean train loss 1614.153584693089
INFO:root:current train perplexity3.5699286460876465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.50s/it]
INFO:root:final mean train loss: 1613.1676442756595
INFO:root:final train perplexity: 3.5688416957855225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.16s/it]
INFO:root:eval mean loss: 1860.1448182450963
INFO:root:eval perplexity: 4.501344203948975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2339.8948282011856
INFO:root:eval perplexity: 6.777649402618408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [9:54:18<6:03:00, 573.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1616.0783944759728
INFO:root:current train perplexity3.5591533184051514
INFO:root:current mean train loss 1616.9578881357231
INFO:root:current train perplexity3.576679229736328
INFO:root:current mean train loss 1621.9922690410388
INFO:root:current train perplexity3.583916187286377
INFO:root:current mean train loss 1616.8718185640935
INFO:root:current train perplexity3.573091983795166
INFO:root:current mean train loss 1617.6098042671254
INFO:root:current train perplexity3.5756027698516846
INFO:root:current mean train loss 1615.4172343414473
INFO:root:current train perplexity3.5705111026763916
INFO:root:current mean train loss 1614.899787190132
INFO:root:current train perplexity3.56583571434021
INFO:root:current mean train loss 1613.7639192578645
INFO:root:current train perplexity3.5583043098449707
INFO:root:current mean train loss 1612.5166185922387
INFO:root:current train perplexity3.5562820434570312
INFO:root:current mean train loss 1610.2214682099702
INFO:root:current train perplexity3.552833318710327
INFO:root:current mean train loss 1610.712566727134
INFO:root:current train perplexity3.5557737350463867
INFO:root:current mean train loss 1610.0555364868483
INFO:root:current train perplexity3.5558793544769287
INFO:root:current mean train loss 1609.9841819087314
INFO:root:current train perplexity3.5559847354888916
INFO:root:current mean train loss 1610.2591326277254
INFO:root:current train perplexity3.5584044456481934
INFO:root:current mean train loss 1609.9151518914261
INFO:root:current train perplexity3.558264970779419
INFO:root:current mean train loss 1609.072898221185
INFO:root:current train perplexity3.558884620666504
INFO:root:current mean train loss 1609.75039944242
INFO:root:current train perplexity3.558727264404297
INFO:root:current mean train loss 1609.8355831966628
INFO:root:current train perplexity3.5592808723449707
INFO:root:current mean train loss 1610.003442211532
INFO:root:current train perplexity3.560074806213379
INFO:root:current mean train loss 1609.9976357861904
INFO:root:current train perplexity3.5595850944519043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:16<00:00, 496.60s/it]
INFO:root:final mean train loss: 1609.8731570337616
INFO:root:final train perplexity: 3.5595810413360596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 1837.5224414581949
INFO:root:eval perplexity: 4.419737339019775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it]
INFO:root:eval mean loss: 2316.2363034512136
INFO:root:eval perplexity: 6.647770881652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [10:03:45<5:52:25, 571.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1626.13037109375
INFO:root:current train perplexity3.5797104835510254
INFO:root:current mean train loss 1618.3801348517923
INFO:root:current train perplexity3.5560920238494873
INFO:root:current mean train loss 1608.2192943431712
INFO:root:current train perplexity3.5408003330230713
INFO:root:current mean train loss 1601.7913795264992
INFO:root:current train perplexity3.537118673324585
INFO:root:current mean train loss 1606.2580428752494
INFO:root:current train perplexity3.54714298248291
INFO:root:current mean train loss 1606.994668097245
INFO:root:current train perplexity3.551701307296753
INFO:root:current mean train loss 1605.213645456798
INFO:root:current train perplexity3.5460495948791504
INFO:root:current mean train loss 1605.5090748972707
INFO:root:current train perplexity3.546203136444092
INFO:root:current mean train loss 1604.679075464709
INFO:root:current train perplexity3.547173500061035
INFO:root:current mean train loss 1603.3793358871617
INFO:root:current train perplexity3.5429022312164307
INFO:root:current mean train loss 1602.3521761600102
INFO:root:current train perplexity3.543222665786743
INFO:root:current mean train loss 1602.5891771626268
INFO:root:current train perplexity3.5450284481048584
INFO:root:current mean train loss 1602.3222628375677
INFO:root:current train perplexity3.54533314704895
INFO:root:current mean train loss 1604.2238456781763
INFO:root:current train perplexity3.5483005046844482
INFO:root:current mean train loss 1604.8866592095824
INFO:root:current train perplexity3.5486605167388916
INFO:root:current mean train loss 1604.663097056006
INFO:root:current train perplexity3.5485637187957764
INFO:root:current mean train loss 1605.1896233655737
INFO:root:current train perplexity3.5484392642974854
INFO:root:current mean train loss 1605.5644369179247
INFO:root:current train perplexity3.5475730895996094
INFO:root:current mean train loss 1606.4157051616812
INFO:root:current train perplexity3.548593282699585
INFO:root:current mean train loss 1607.9178403592957
INFO:root:current train perplexity3.5524253845214844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:28<00:00, 508.30s/it]
INFO:root:final mean train loss: 1607.1665374555794
INFO:root:final train perplexity: 3.5519909858703613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 1839.160346281444
INFO:root:eval perplexity: 4.425595760345459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.14s/it]
INFO:root:eval mean loss: 2321.1454861688276
INFO:root:eval perplexity: 6.6745147705078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [10:13:26<5:44:31, 574.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.5810392533226
INFO:root:current train perplexity3.526649236679077
INFO:root:current mean train loss 1601.941340971758
INFO:root:current train perplexity3.5336573123931885
INFO:root:current mean train loss 1604.0569970532993
INFO:root:current train perplexity3.544785976409912
INFO:root:current mean train loss 1602.3423018738897
INFO:root:current train perplexity3.5389912128448486
INFO:root:current mean train loss 1601.8922758317826
INFO:root:current train perplexity3.542161464691162
INFO:root:current mean train loss 1605.0485960458368
INFO:root:current train perplexity3.5420355796813965
INFO:root:current mean train loss 1602.0951338189138
INFO:root:current train perplexity3.5394279956817627
INFO:root:current mean train loss 1601.7535349204852
INFO:root:current train perplexity3.53975510597229
INFO:root:current mean train loss 1601.7325773873486
INFO:root:current train perplexity3.5390846729278564
INFO:root:current mean train loss 1601.2080095439937
INFO:root:current train perplexity3.54005765914917
INFO:root:current mean train loss 1602.2292927423528
INFO:root:current train perplexity3.544363498687744
INFO:root:current mean train loss 1604.0185620919335
INFO:root:current train perplexity3.548285722732544
INFO:root:current mean train loss 1604.6866235977564
INFO:root:current train perplexity3.5499048233032227
INFO:root:current mean train loss 1603.6901489345823
INFO:root:current train perplexity3.5484085083007812
INFO:root:current mean train loss 1604.642988419164
INFO:root:current train perplexity3.548693895339966
INFO:root:current mean train loss 1608.167250250448
INFO:root:current train perplexity3.5576155185699463
INFO:root:current mean train loss 2091.949617739747
INFO:root:current train perplexity5.208168983459473
INFO:root:current mean train loss 2316.2340009333902
INFO:root:current train perplexity6.220519065856934
INFO:root:current mean train loss 2739.498132007237
INFO:root:current train perplexity8.678145408630371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.52s/it]
INFO:root:final mean train loss: 3119.55569681157
INFO:root:final train perplexity: 11.707962989807129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it]
INFO:root:eval mean loss: 10984.87084787788
INFO:root:eval perplexity: 7215.00927734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it]
INFO:root:eval mean loss: 10879.297818664118
INFO:root:eval perplexity: 7312.8505859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [10:22:51<5:33:26, 571.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10566.0791015625
INFO:root:current train perplexity4993.44140625
INFO:root:current mean train loss 10267.438030536357
INFO:root:current train perplexity3383.3486328125
INFO:root:current mean train loss 9279.203227922028
INFO:root:current train perplexity1550.3585205078125
INFO:root:current mean train loss 8563.144715961656
INFO:root:current train perplexity885.3766479492188
INFO:root:current mean train loss 8144.2083571028
INFO:root:current train perplexity629.1224365234375
INFO:root:current mean train loss 7874.210722423735
INFO:root:current train perplexity505.032958984375
INFO:root:current mean train loss 7694.9677847552775
INFO:root:current train perplexity434.5749816894531
INFO:root:current mean train loss 7554.857911543412
INFO:root:current train perplexity388.71734619140625
INFO:root:current mean train loss 7449.790688282222
INFO:root:current train perplexity357.14874267578125
INFO:root:current mean train loss 7365.72514086698
INFO:root:current train perplexity334.3918762207031
INFO:root:current mean train loss 7296.593697962058
INFO:root:current train perplexity316.5374450683594
INFO:root:current mean train loss 7242.830059549083
INFO:root:current train perplexity302.42071533203125
INFO:root:current mean train loss 7196.8432690186355
INFO:root:current train perplexity291.1170959472656
INFO:root:current mean train loss 7154.582315082199
INFO:root:current train perplexity281.5404052734375
INFO:root:current mean train loss 7117.399606036325
INFO:root:current train perplexity273.4514465332031
INFO:root:current mean train loss 7086.702142269053
INFO:root:current train perplexity266.5231628417969
INFO:root:current mean train loss 7057.438292695994
INFO:root:current train perplexity260.5143127441406
INFO:root:current mean train loss 6965.2212969999355
INFO:root:current train perplexity242.5120086669922
INFO:root:current mean train loss 6749.750000135333
INFO:root:current train perplexity204.75381469726562
INFO:root:current mean train loss 6539.928844419848
INFO:root:current train perplexity173.57296752929688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.51s/it]
INFO:root:final mean train loss: 6386.851170003624
INFO:root:final train perplexity: 154.01583862304688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2430.82916562777
INFO:root:eval perplexity: 7.141421794891357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.73s/it]
INFO:root:eval mean loss: 2857.522012913481
INFO:root:eval perplexity: 10.349726676940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [10:32:27<5:24:41, 572.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2850.284493582589
INFO:root:current train perplexity9.403907775878906
INFO:root:current mean train loss 2680.6296164772725
INFO:root:current train perplexity8.269613265991211
INFO:root:current mean train loss 2631.420299685379
INFO:root:current train perplexity7.906591892242432
INFO:root:current mean train loss 2585.526374032564
INFO:root:current train perplexity7.6670122146606445
INFO:root:current mean train loss 2555.2619791280063
INFO:root:current train perplexity7.499610424041748
INFO:root:current mean train loss 2531.276601018924
INFO:root:current train perplexity7.364030838012695
INFO:root:current mean train loss 2512.1582074495523
INFO:root:current train perplexity7.258725166320801
INFO:root:current mean train loss 2497.1190878012308
INFO:root:current train perplexity7.1633758544921875
INFO:root:current mean train loss 2480.6370225132746
INFO:root:current train perplexity7.0717034339904785
INFO:root:current mean train loss 2467.690114372328
INFO:root:current train perplexity7.010226726531982
INFO:root:current mean train loss 2456.2718357605518
INFO:root:current train perplexity6.95509672164917
INFO:root:current mean train loss 2448.59246526713
INFO:root:current train perplexity6.902403831481934
INFO:root:current mean train loss 2438.8701151879864
INFO:root:current train perplexity6.856457710266113
INFO:root:current mean train loss 2432.4087123827535
INFO:root:current train perplexity6.825382232666016
INFO:root:current mean train loss 2427.614565092942
INFO:root:current train perplexity6.793869972229004
INFO:root:current mean train loss 2425.7896646653876
INFO:root:current train perplexity6.7714643478393555
INFO:root:current mean train loss 2422.208663422704
INFO:root:current train perplexity6.748128890991211
INFO:root:current mean train loss 2418.607217455104
INFO:root:current train perplexity6.732962131500244
INFO:root:current mean train loss 2415.579001010348
INFO:root:current train perplexity6.717861652374268
INFO:root:current mean train loss 2413.0024386102614
INFO:root:current train perplexity6.7032341957092285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.74s/it]
INFO:root:final mean train loss: 2412.179052463518
INFO:root:final train perplexity: 6.701889514923096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2266.7132057568706
INFO:root:eval perplexity: 6.25377082824707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.35s/it]
INFO:root:eval mean loss: 2710.6208045905364
INFO:root:eval perplexity: 9.17809772491455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [10:41:55<5:14:17, 571.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2363.4377184416117
INFO:root:current train perplexity6.573326587677002
INFO:root:current mean train loss 2394.997908882473
INFO:root:current train perplexity6.624443531036377
INFO:root:current mean train loss 2403.7771457704175
INFO:root:current train perplexity6.6562323570251465
INFO:root:current mean train loss 2412.266305415588
INFO:root:current train perplexity6.696286678314209
INFO:root:current mean train loss 2416.7738329743684
INFO:root:current train perplexity6.729460716247559
INFO:root:current mean train loss 2425.495699630794
INFO:root:current train perplexity6.769336700439453
INFO:root:current mean train loss 2435.0463103769716
INFO:root:current train perplexity6.821680068969727
INFO:root:current mean train loss 2450.4925049158937
INFO:root:current train perplexity6.920798301696777
INFO:root:current mean train loss 2504.374913909839
INFO:root:current train perplexity7.219552993774414
INFO:root:current mean train loss 2718.9193374210836
INFO:root:current train perplexity8.547785758972168
INFO:root:current mean train loss 2780.299010289657
INFO:root:current train perplexity8.976099967956543
INFO:root:current mean train loss 2786.1700888903574
INFO:root:current train perplexity9.011874198913574
INFO:root:current mean train loss 2782.729569196316
INFO:root:current train perplexity8.976834297180176
INFO:root:current mean train loss 2845.8607264406123
INFO:root:current train perplexity9.433106422424316
INFO:root:current mean train loss 2936.925296449197
INFO:root:current train perplexity10.126646995544434
INFO:root:current mean train loss 2914.5885455028597
INFO:root:current train perplexity9.948243141174316
INFO:root:current mean train loss 2893.031276605068
INFO:root:current train perplexity9.780193328857422
INFO:root:current mean train loss 2941.386680752279
INFO:root:current train perplexity10.170248031616211
INFO:root:current mean train loss 2922.1845606823613
INFO:root:current train perplexity10.02320671081543
INFO:root:current mean train loss 2907.341017401255
INFO:root:current train perplexity9.897350311279297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.34s/it]
INFO:root:final mean train loss: 2899.6478425995965
INFO:root:final train perplexity: 9.843749046325684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2309.283957623421
INFO:root:eval perplexity: 6.472828388214111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.36s/it]
INFO:root:eval mean loss: 2728.309534816877
INFO:root:eval perplexity: 9.311840057373047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [10:51:34<5:05:57, 573.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2561.3829811789774
INFO:root:current train perplexity7.470085620880127
INFO:root:current mean train loss 2575.707218686996
INFO:root:current train perplexity7.576803684234619
INFO:root:current mean train loss 2569.3675120634193
INFO:root:current train perplexity7.548614025115967
INFO:root:current mean train loss 2627.338875440141
INFO:root:current train perplexity7.916139602661133
INFO:root:current mean train loss 2634.6118088942308
INFO:root:current train perplexity7.937291145324707
INFO:root:current mean train loss 2604.3637774493245
INFO:root:current train perplexity7.7426838874816895
INFO:root:current mean train loss 2582.860976637047
INFO:root:current train perplexity7.633817195892334
INFO:root:current mean train loss 2569.4973610176944
INFO:root:current train perplexity7.556434154510498
INFO:root:current mean train loss 2556.8535627398574
INFO:root:current train perplexity7.4861531257629395
INFO:root:current mean train loss 2547.016679022824
INFO:root:current train perplexity7.429071426391602
INFO:root:current mean train loss 2541.78279583827
INFO:root:current train perplexity7.393625736236572
INFO:root:current mean train loss 2535.5727376302084
INFO:root:current train perplexity7.363813877105713
INFO:root:current mean train loss 2533.050603834661
INFO:root:current train perplexity7.356007099151611
INFO:root:current mean train loss 2530.3680056864046
INFO:root:current train perplexity7.34682035446167
INFO:root:current mean train loss 2528.408637040915
INFO:root:current train perplexity7.332057476043701
INFO:root:current mean train loss 2528.574180284114
INFO:root:current train perplexity7.330875873565674
INFO:root:current mean train loss 2527.363475234847
INFO:root:current train perplexity7.327881336212158
INFO:root:current mean train loss 2529.290907813613
INFO:root:current train perplexity7.335361003875732
INFO:root:current mean train loss 2528.1395624947354
INFO:root:current train perplexity7.338820457458496
INFO:root:current mean train loss 2530.2107083449887
INFO:root:current train perplexity7.352798938751221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.92s/it]
INFO:root:final mean train loss: 2529.6150375727866
INFO:root:final train perplexity: 7.352251052856445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.47s/it]
INFO:root:eval mean loss: 2352.199640368739
INFO:root:eval perplexity: 6.701430320739746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.98s/it]
INFO:root:eval mean loss: 2768.7677144801364
INFO:root:eval perplexity: 9.625102043151855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [11:01:01<4:55:18, 571.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2562.661431206597
INFO:root:current train perplexity7.451866626739502
INFO:root:current mean train loss 2565.699176167333
INFO:root:current train perplexity7.495111465454102
INFO:root:current mean train loss 2569.485787784352
INFO:root:current train perplexity7.5486016273498535
INFO:root:current mean train loss 2570.1880749117945
INFO:root:current train perplexity7.5592217445373535
INFO:root:current mean train loss 2566.0115599551445
INFO:root:current train perplexity7.55961275100708
INFO:root:current mean train loss 2569.2737896259014
INFO:root:current train perplexity7.587002277374268
INFO:root:current mean train loss 2575.126303173247
INFO:root:current train perplexity7.6193413734436035
INFO:root:current mean train loss 2581.3171209621923
INFO:root:current train perplexity7.651862144470215
INFO:root:current mean train loss 2587.7327015728033
INFO:root:current train perplexity7.696598052978516
INFO:root:current mean train loss 2595.119491012008
INFO:root:current train perplexity7.732823371887207
INFO:root:current mean train loss 2598.4199574029267
INFO:root:current train perplexity7.771694660186768
INFO:root:current mean train loss 2604.4179581261333
INFO:root:current train perplexity7.804646015167236
INFO:root:current mean train loss 2610.3343674761695
INFO:root:current train perplexity7.850726127624512
INFO:root:current mean train loss 2618.588540124476
INFO:root:current train perplexity7.898073673248291
INFO:root:current mean train loss 2625.6510318258534
INFO:root:current train perplexity7.93988037109375
INFO:root:current mean train loss 2631.448500616253
INFO:root:current train perplexity7.9749064445495605
INFO:root:current mean train loss 2637.8748760314647
INFO:root:current train perplexity8.009714126586914
INFO:root:current mean train loss 2645.5148540006
INFO:root:current train perplexity8.051300048828125
INFO:root:current mean train loss 2651.322952009674
INFO:root:current train perplexity8.086248397827148
INFO:root:current mean train loss 2656.6861314754215
INFO:root:current train perplexity8.122753143310547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:11<00:00, 491.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:11<00:00, 491.83s/it]
INFO:root:final mean train loss: 2656.7601894546024
INFO:root:final train perplexity: 8.127723693847656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it]
INFO:root:eval mean loss: 2455.9980338887967
INFO:root:eval perplexity: 7.2882771492004395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.01s/it]
INFO:root:eval mean loss: 2838.244033272385
INFO:root:eval perplexity: 10.187832832336426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [11:10:23<4:44:26, 568.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2765.5576528484903
INFO:root:current train perplexity9.028454780578613
INFO:root:current mean train loss 2766.79283182457
INFO:root:current train perplexity8.969265937805176
INFO:root:current mean train loss 2789.582546564122
INFO:root:current train perplexity9.009581565856934
INFO:root:current mean train loss 2778.7164742830173
INFO:root:current train perplexity8.96540641784668
INFO:root:current mean train loss 2779.510352760736
INFO:root:current train perplexity8.971404075622559
INFO:root:current mean train loss 2781.8042448137735
INFO:root:current train perplexity8.990267753601074
INFO:root:current mean train loss 2781.378945227458
INFO:root:current train perplexity8.981820106506348
INFO:root:current mean train loss 2782.6619741538934
INFO:root:current train perplexity8.971694946289062
INFO:root:current mean train loss 2781.655579368497
INFO:root:current train perplexity8.967110633850098
INFO:root:current mean train loss 2782.81115241287
INFO:root:current train perplexity8.974544525146484
INFO:root:current mean train loss 2779.5045135750256
INFO:root:current train perplexity8.959088325500488
INFO:root:current mean train loss 2781.05792395461
INFO:root:current train perplexity8.968803405761719
INFO:root:current mean train loss 2782.813002486484
INFO:root:current train perplexity8.982433319091797
INFO:root:current mean train loss 2786.9937135107316
INFO:root:current train perplexity9.015987396240234
INFO:root:current mean train loss 2798.3573220216485
INFO:root:current train perplexity9.092300415039062
INFO:root:current mean train loss 2811.95054147287
INFO:root:current train perplexity9.191067695617676
INFO:root:current mean train loss 2825.34737004607
INFO:root:current train perplexity9.287703514099121
INFO:root:current mean train loss 2845.046759821304
INFO:root:current train perplexity9.422746658325195
INFO:root:current mean train loss 2862.928893429063
INFO:root:current train perplexity9.557672500610352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:27<00:00, 507.53s/it]
INFO:root:final mean train loss: 2879.282978867739
INFO:root:final train perplexity: 9.686912536621094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 2576.7336776408742
INFO:root:eval perplexity: 8.035835266113281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.34s/it]
INFO:root:eval mean loss: 2966.476721797429
INFO:root:eval perplexity: 11.31428337097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [11:20:03<4:36:32, 572.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.116943359375
INFO:root:current train perplexity12.732344627380371
INFO:root:current mean train loss 3195.3620144826064
INFO:root:current train perplexity12.519862174987793
INFO:root:current mean train loss 3239.7375784568417
INFO:root:current train perplexity12.76058578491211
INFO:root:current mean train loss 3280.3897689121222
INFO:root:current train perplexity13.185026168823242
INFO:root:current mean train loss 3303.7981480189733
INFO:root:current train perplexity13.409497261047363
INFO:root:current mean train loss 3304.3861532701335
INFO:root:current train perplexity13.491406440734863
INFO:root:current mean train loss 3326.210700611077
INFO:root:current train perplexity13.716426849365234
INFO:root:current mean train loss 3321.33721456987
INFO:root:current train perplexity13.692506790161133
INFO:root:current mean train loss 3319.2148146712157
INFO:root:current train perplexity13.723358154296875
INFO:root:current mean train loss 3319.24984532371
INFO:root:current train perplexity13.744622230529785
INFO:root:current mean train loss 3318.159926185077
INFO:root:current train perplexity13.704802513122559
INFO:root:current mean train loss 3319.1234965264043
INFO:root:current train perplexity13.701565742492676
INFO:root:current mean train loss 3314.620015158582
INFO:root:current train perplexity13.647289276123047
INFO:root:current mean train loss 3314.2670522692742
INFO:root:current train perplexity13.651714324951172
INFO:root:current mean train loss 3318.2671108544296
INFO:root:current train perplexity13.690825462341309
INFO:root:current mean train loss 3318.4214253013984
INFO:root:current train perplexity13.686823844909668
INFO:root:current mean train loss 3312.8847849312638
INFO:root:current train perplexity13.626419067382812
INFO:root:current mean train loss 3308.8053131640168
INFO:root:current train perplexity13.566561698913574
INFO:root:current mean train loss 3303.7621909444647
INFO:root:current train perplexity13.515704154968262
INFO:root:current mean train loss 3301.908664635321
INFO:root:current train perplexity13.496724128723145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.50s/it]
INFO:root:final mean train loss: 3298.8760487705063
INFO:root:final train perplexity: 13.486536979675293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 2543.803855517232
INFO:root:eval perplexity: 7.824652671813965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.04s/it]
INFO:root:eval mean loss: 2941.125088739057
INFO:root:eval perplexity: 11.082120895385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [11:29:42<4:27:54, 574.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3329.7514329993205
INFO:root:current train perplexity13.29159927368164
INFO:root:current mean train loss 3257.1624547446645
INFO:root:current train perplexity12.876490592956543
INFO:root:current mean train loss 3224.3414147894478
INFO:root:current train perplexity12.613192558288574
INFO:root:current mean train loss 3200.4499609979684
INFO:root:current train perplexity12.393363952636719
INFO:root:current mean train loss 3163.994572921284
INFO:root:current train perplexity12.028661727905273
INFO:root:current mean train loss 3134.0294014400097
INFO:root:current train perplexity11.775671005249023
INFO:root:current mean train loss 3103.3339342144864
INFO:root:current train perplexity11.507248878479004
INFO:root:current mean train loss 3078.0662110725707
INFO:root:current train perplexity11.309224128723145
INFO:root:current mean train loss 3059.955834278649
INFO:root:current train perplexity11.160669326782227
INFO:root:current mean train loss 3050.6811470535954
INFO:root:current train perplexity11.081755638122559
INFO:root:current mean train loss 3046.277900046967
INFO:root:current train perplexity11.065803527832031
INFO:root:current mean train loss 3052.162187421736
INFO:root:current train perplexity11.111055374145508
INFO:root:current mean train loss 3053.901714533933
INFO:root:current train perplexity11.124757766723633
INFO:root:current mean train loss 3060.896328996008
INFO:root:current train perplexity11.184499740600586
INFO:root:current mean train loss 3071.6773356520116
INFO:root:current train perplexity11.280630111694336
INFO:root:current mean train loss 3082.143894368383
INFO:root:current train perplexity11.359145164489746
INFO:root:current mean train loss 3090.2863515312115
INFO:root:current train perplexity11.44364070892334
INFO:root:current mean train loss 3100.7320792562937
INFO:root:current train perplexity11.536768913269043
INFO:root:current mean train loss 3111.4500738448387
INFO:root:current train perplexity11.639190673828125
INFO:root:current mean train loss 3127.46378733079
INFO:root:current train perplexity11.780253410339355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.38s/it]
INFO:root:final mean train loss: 3134.419276619823
INFO:root:final train perplexity: 11.846014976501465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.44s/it]
INFO:root:eval mean loss: 2810.4706139530695
INFO:root:eval perplexity: 9.707934379577637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.30s/it]
INFO:root:eval mean loss: 3171.410089587489
INFO:root:eval perplexity: 13.378732681274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [11:39:07<4:17:10, 571.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.3985961914063
INFO:root:current train perplexity13.935711860656738
INFO:root:current mean train loss 3392.180369349888
INFO:root:current train perplexity14.439781188964844
INFO:root:current mean train loss 3453.1242563883466
INFO:root:current train perplexity15.017796516418457
INFO:root:current mean train loss 3489.5190372242646
INFO:root:current train perplexity15.590579986572266
INFO:root:current mean train loss 3482.8412425648085
INFO:root:current train perplexity15.508512496948242
INFO:root:current mean train loss 3506.1331601743345
INFO:root:current train perplexity15.757134437561035
INFO:root:current mean train loss 3519.411697769165
INFO:root:current train perplexity15.958539009094238
INFO:root:current mean train loss 3526.0212785050676
INFO:root:current train perplexity16.059831619262695
INFO:root:current mean train loss 3531.012242780413
INFO:root:current train perplexity16.119338989257812
INFO:root:current mean train loss 3541.514037306765
INFO:root:current train perplexity16.25362205505371
INFO:root:current mean train loss 3545.6809549184945
INFO:root:current train perplexity16.335079193115234
INFO:root:current mean train loss 3555.2574308696544
INFO:root:current train perplexity16.46291160583496
INFO:root:current mean train loss 3564.0270909463206
INFO:root:current train perplexity16.578657150268555
INFO:root:current mean train loss 3573.458127514284
INFO:root:current train perplexity16.70935821533203
INFO:root:current mean train loss 3580.8777386135525
INFO:root:current train perplexity16.809309005737305
INFO:root:current mean train loss 3593.0264344054385
INFO:root:current train perplexity16.97623634338379
INFO:root:current mean train loss 3606.490009140387
INFO:root:current train perplexity17.17782974243164
INFO:root:current mean train loss 3624.086791571255
INFO:root:current train perplexity17.393756866455078
INFO:root:current mean train loss 3639.487222157354
INFO:root:current train perplexity17.605409622192383
INFO:root:current mean train loss 3654.7993789515544
INFO:root:current train perplexity17.828105926513672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.28s/it]
INFO:root:final mean train loss: 3658.5565723567315
INFO:root:final train perplexity: 17.909975051879883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.36s/it]
INFO:root:eval mean loss: 2897.7936284491357
INFO:root:eval perplexity: 10.418316841125488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it]
INFO:root:eval mean loss: 3269.079332284048
INFO:root:eval perplexity: 14.491220474243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [11:48:44<4:08:22, 573.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3856.4925901178726
INFO:root:current train perplexity21.76042366027832
INFO:root:current mean train loss 3946.4731305359273
INFO:root:current train perplexity22.543420791625977
INFO:root:current mean train loss 3989.341448238388
INFO:root:current train perplexity23.154651641845703
INFO:root:current mean train loss 4013.765143557423
INFO:root:current train perplexity23.783193588256836
INFO:root:current mean train loss 4050.6865779284053
INFO:root:current train perplexity24.358436584472656
INFO:root:current mean train loss 4061.491891200067
INFO:root:current train perplexity24.748992919921875
INFO:root:current mean train loss 4077.201022120553
INFO:root:current train perplexity24.991151809692383
INFO:root:current mean train loss 4091.873253926891
INFO:root:current train perplexity25.272438049316406
INFO:root:current mean train loss 4116.519230988368
INFO:root:current train perplexity25.810466766357422
INFO:root:current mean train loss 4145.511987381221
INFO:root:current train perplexity26.341567993164062
INFO:root:current mean train loss 4182.3928273470765
INFO:root:current train perplexity27.09336280822754
INFO:root:current mean train loss 4109.773060421956
INFO:root:current train perplexity25.6025333404541
INFO:root:current mean train loss 4068.2768370173903
INFO:root:current train perplexity24.758560180664062
INFO:root:current mean train loss 4037.460248796748
INFO:root:current train perplexity24.150962829589844
INFO:root:current mean train loss 4014.61145564114
INFO:root:current train perplexity23.70785140991211
INFO:root:current mean train loss 3995.2219349610627
INFO:root:current train perplexity23.363784790039062
INFO:root:current mean train loss 3977.4675077853894
INFO:root:current train perplexity23.04084587097168
INFO:root:current mean train loss 3960.9252696246267
INFO:root:current train perplexity22.72524642944336
INFO:root:current mean train loss 3947.066841548659
INFO:root:current train perplexity22.461244583129883
INFO:root:current mean train loss 3931.5612406236028
INFO:root:current train perplexity22.194726943969727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.25s/it]
INFO:root:final mean train loss: 3926.559030937776
INFO:root:final train perplexity: 22.125276565551758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 3199.8441257341533
INFO:root:eval perplexity: 13.301091194152832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.36s/it]
INFO:root:eval mean loss: 3543.6556751440603
INFO:root:eval perplexity: 18.139633178710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [11:58:10<3:57:52, 570.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3663.230280695735
INFO:root:current train perplexity17.884647369384766
INFO:root:current mean train loss 3651.8983561197915
INFO:root:current train perplexity17.84514045715332
INFO:root:current mean train loss 3643.663268597457
INFO:root:current train perplexity17.839921951293945
INFO:root:current mean train loss 3637.5423675373913
INFO:root:current train perplexity17.722820281982422
INFO:root:current mean train loss 3632.597502245682
INFO:root:current train perplexity17.61015510559082
INFO:root:current mean train loss 3633.4063597356817
INFO:root:current train perplexity17.544321060180664
INFO:root:current mean train loss 3631.3117150552903
INFO:root:current train perplexity17.51715850830078
INFO:root:current mean train loss 3630.9871498127623
INFO:root:current train perplexity17.479114532470703
INFO:root:current mean train loss 3626.9457063653103
INFO:root:current train perplexity17.465417861938477
INFO:root:current mean train loss 3631.4441334060575
INFO:root:current train perplexity17.489086151123047
INFO:root:current mean train loss 3632.440301706893
INFO:root:current train perplexity17.474977493286133
INFO:root:current mean train loss 3628.903749534178
INFO:root:current train perplexity17.460514068603516
INFO:root:current mean train loss 3624.073240654435
INFO:root:current train perplexity17.421754837036133
INFO:root:current mean train loss 3625.9790625426444
INFO:root:current train perplexity17.42076873779297
INFO:root:current mean train loss 3626.32124036688
INFO:root:current train perplexity17.433055877685547
INFO:root:current mean train loss 3627.265241261813
INFO:root:current train perplexity17.45937728881836
INFO:root:current mean train loss 3631.0018142827807
INFO:root:current train perplexity17.495838165283203
INFO:root:current mean train loss 3634.8264413379898
INFO:root:current train perplexity17.53963851928711
INFO:root:current mean train loss 3636.878510856832
INFO:root:current train perplexity17.57891082763672
INFO:root:current mean train loss 3637.3300391663897
INFO:root:current train perplexity17.600444793701172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.44s/it]
INFO:root:final mean train loss: 3636.484879778902
INFO:root:final train perplexity: 17.60091209411621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it]
INFO:root:eval mean loss: 3034.9176432291665
INFO:root:eval perplexity: 11.64018440246582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it]
INFO:root:eval mean loss: 3394.0388568851117
INFO:root:eval perplexity: 16.050472259521484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [12:07:46<3:49:00, 572.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3626.206776377919
INFO:root:current train perplexity18.260114669799805
INFO:root:current mean train loss 3688.907096183737
INFO:root:current train perplexity18.6151180267334
INFO:root:current mean train loss 3690.548371724656
INFO:root:current train perplexity18.76522445678711
INFO:root:current mean train loss 3688.040615384231
INFO:root:current train perplexity18.569700241088867
INFO:root:current mean train loss 3690.131220862239
INFO:root:current train perplexity18.61957359313965
INFO:root:current mean train loss 3692.169393523292
INFO:root:current train perplexity18.613759994506836
INFO:root:current mean train loss 3709.512123295609
INFO:root:current train perplexity18.76792335510254
INFO:root:current mean train loss 3726.6663687183946
INFO:root:current train perplexity19.046537399291992
INFO:root:current mean train loss 3742.221377183291
INFO:root:current train perplexity19.25773811340332
INFO:root:current mean train loss 3759.7191449116267
INFO:root:current train perplexity19.487380981445312
INFO:root:current mean train loss 3776.4228204575074
INFO:root:current train perplexity19.755878448486328
INFO:root:current mean train loss 3791.215637668254
INFO:root:current train perplexity19.951316833496094
INFO:root:current mean train loss 3804.6093506048483
INFO:root:current train perplexity20.1622314453125
INFO:root:current mean train loss 3822.104726148286
INFO:root:current train perplexity20.397693634033203
INFO:root:current mean train loss 3834.5205931225373
INFO:root:current train perplexity20.58622169494629
INFO:root:current mean train loss 3846.635478251689
INFO:root:current train perplexity20.78594398498535
INFO:root:current mean train loss 3858.260799504962
INFO:root:current train perplexity20.986478805541992
INFO:root:current mean train loss 3871.5396524724315
INFO:root:current train perplexity21.170555114746094
INFO:root:current mean train loss 3885.360554518112
INFO:root:current train perplexity21.41970443725586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.22s/it]
INFO:root:final mean train loss: 3903.903933988216
INFO:root:final train perplexity: 21.73346710205078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.29s/it]
INFO:root:eval mean loss: 2937.0951724221522
INFO:root:eval perplexity: 10.754778861999512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.88s/it]
INFO:root:eval mean loss: 3310.517537434896
INFO:root:eval perplexity: 14.990730285644531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [12:17:15<3:39:01, 571.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4112.739166259766
INFO:root:current train perplexity27.169063568115234
INFO:root:current mean train loss 4410.621765136719
INFO:root:current train perplexity32.069297790527344
INFO:root:current mean train loss 4800.058984609751
INFO:root:current train perplexity44.18727493286133
INFO:root:current mean train loss 5327.0828833641945
INFO:root:current train perplexity67.57230377197266
INFO:root:current mean train loss 5670.315304625268
INFO:root:current train perplexity88.16326141357422
INFO:root:current mean train loss 5859.539500319113
INFO:root:current train perplexity102.31146240234375
INFO:root:current mean train loss 5921.852810909873
INFO:root:current train perplexity107.7869644165039
INFO:root:current mean train loss 5905.889475676973
INFO:root:current train perplexity106.5077896118164
INFO:root:current mean train loss 5875.964975187094
INFO:root:current train perplexity103.24703979492188
INFO:root:current mean train loss 5817.418803614141
INFO:root:current train perplexity98.39342498779297
INFO:root:current mean train loss 5765.374382866754
INFO:root:current train perplexity94.4422378540039
INFO:root:current mean train loss 5710.598123818959
INFO:root:current train perplexity90.3455810546875
INFO:root:current mean train loss 5656.847632401827
INFO:root:current train perplexity86.56706237792969
INFO:root:current mean train loss 5602.239172699255
INFO:root:current train perplexity82.79119873046875
INFO:root:current mean train loss 5548.853577527133
INFO:root:current train perplexity79.43779754638672
INFO:root:current mean train loss 5493.9260681314245
INFO:root:current train perplexity76.0449447631836
INFO:root:current mean train loss 5443.834407673547
INFO:root:current train perplexity72.95133209228516
INFO:root:current mean train loss 5387.602996754702
INFO:root:current train perplexity69.8423843383789
INFO:root:current mean train loss 5335.126177897496
INFO:root:current train perplexity67.10767364501953
INFO:root:current mean train loss 5294.234896038063
INFO:root:current train perplexity65.02279663085938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.44s/it]
INFO:root:final mean train loss: 5265.113526252443
INFO:root:final train perplexity: 63.585487365722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 3260.0608299742353
INFO:root:eval perplexity: 13.96488094329834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.97s/it]
INFO:root:eval mean loss: 3590.449636472878
INFO:root:eval perplexity: 18.84727668762207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [12:26:39<3:28:44, 569.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4596.95021484375
INFO:root:current train perplexity37.73199462890625
INFO:root:current mean train loss 4473.105029296875
INFO:root:current train perplexity35.165802001953125
INFO:root:current mean train loss 4478.05513780382
INFO:root:current train perplexity34.70228958129883
INFO:root:current mean train loss 4510.119703275241
INFO:root:current train perplexity35.437705993652344
INFO:root:current mean train loss 4538.053068704045
INFO:root:current train perplexity36.22819137573242
INFO:root:current mean train loss 4565.994292689732
INFO:root:current train perplexity36.889339447021484
INFO:root:current mean train loss 4574.453151953125
INFO:root:current train perplexity37.4293212890625
INFO:root:current mean train loss 4610.567805091595
INFO:root:current train perplexity38.405860900878906
INFO:root:current mean train loss 4656.8894122869315
INFO:root:current train perplexity39.60474395751953
INFO:root:current mean train loss 4696.027963999155
INFO:root:current train perplexity40.838741302490234
INFO:root:current mean train loss 4743.837753429878
INFO:root:current train perplexity42.54087448120117
INFO:root:current mean train loss 4837.159388888889
INFO:root:current train perplexity45.628448486328125
INFO:root:current mean train loss 4929.540114795918
INFO:root:current train perplexity48.948970794677734
INFO:root:current mean train loss 5004.023800117924
INFO:root:current train perplexity51.863834381103516
INFO:root:current mean train loss 5079.010524945175
INFO:root:current train perplexity54.95698547363281
INFO:root:current mean train loss 5141.7125918929305
INFO:root:current train perplexity57.68234634399414
INFO:root:current mean train loss 5189.776119290866
INFO:root:current train perplexity59.983097076416016
INFO:root:current mean train loss 5229.78534618433
INFO:root:current train perplexity61.77748489379883
INFO:root:current mean train loss 5258.297586419092
INFO:root:current train perplexity63.09381866455078
INFO:root:current mean train loss 5289.025786069399
INFO:root:current train perplexity64.68867492675781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 493.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 493.00s/it]
INFO:root:final mean train loss: 5310.721301842024
INFO:root:final train perplexity: 65.9142074584961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.85s/it]
INFO:root:eval mean loss: 4584.325656755596
INFO:root:eval perplexity: 40.753150939941406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.71s/it]
INFO:root:eval mean loss: 4844.212436973626
INFO:root:eval perplexity: 52.54815673828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [12:36:03<3:18:41, 567.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6105.101795014881
INFO:root:current train perplexity121.29936981201172
INFO:root:current mean train loss 6189.086205710827
INFO:root:current train perplexity128.03228759765625
INFO:root:current mean train loss 6239.998892287577
INFO:root:current train perplexity134.44696044921875
INFO:root:current mean train loss 6290.368483872441
INFO:root:current train perplexity141.13038635253906
INFO:root:current mean train loss 6292.240163673642
INFO:root:current train perplexity142.81448364257812
INFO:root:current mean train loss 6270.566927864103
INFO:root:current train perplexity140.34320068359375
INFO:root:current mean train loss 6262.577176578319
INFO:root:current train perplexity138.9326171875
INFO:root:current mean train loss 6243.489865202788
INFO:root:current train perplexity136.912109375
INFO:root:current mean train loss 6207.9980010623885
INFO:root:current train perplexity133.6241455078125
INFO:root:current mean train loss 6175.892119907776
INFO:root:current train perplexity130.5761260986328
INFO:root:current mean train loss 6155.858346422895
INFO:root:current train perplexity128.0579376220703
INFO:root:current mean train loss 6129.930457120184
INFO:root:current train perplexity126.02299499511719
INFO:root:current mean train loss 6123.292071602003
INFO:root:current train perplexity125.41584777832031
INFO:root:current mean train loss 6124.605967218937
INFO:root:current train perplexity125.63060760498047
INFO:root:current mean train loss 6132.64242811904
INFO:root:current train perplexity126.42613983154297
INFO:root:current mean train loss 6150.242863240718
INFO:root:current train perplexity127.89981842041016
INFO:root:current mean train loss 6169.651520332959
INFO:root:current train perplexity129.71778869628906
INFO:root:current mean train loss 6193.0083187204
INFO:root:current train perplexity132.24627685546875
INFO:root:current mean train loss 6218.016839606236
INFO:root:current train perplexity134.6175994873047
INFO:root:current mean train loss 6231.198378212297
INFO:root:current train perplexity136.1350860595703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.20s/it]
INFO:root:final mean train loss: 6232.704054654997
INFO:root:final train perplexity: 136.38555908203125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 4870.609304008754
INFO:root:eval perplexity: 51.37042236328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.97s/it]
INFO:root:eval mean loss: 5110.527638103945
INFO:root:eval perplexity: 65.33514404296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [12:45:41<3:10:10, 570.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6296.7468965174785
INFO:root:current train perplexity141.3160400390625
INFO:root:current mean train loss 6211.906996241156
INFO:root:current train perplexity133.5096893310547
INFO:root:current mean train loss 6154.594387216457
INFO:root:current train perplexity129.0638427734375
INFO:root:current mean train loss 6148.931746713963
INFO:root:current train perplexity127.3515625
INFO:root:current mean train loss 6168.027463958674
INFO:root:current train perplexity129.66262817382812
INFO:root:current mean train loss 6210.732369465563
INFO:root:current train perplexity133.06942749023438
INFO:root:current mean train loss 6254.528547781914
INFO:root:current train perplexity137.6119842529297
INFO:root:current mean train loss 6294.462676398839
INFO:root:current train perplexity142.48226928710938
INFO:root:current mean train loss 6319.280581526485
INFO:root:current train perplexity145.95297241210938
INFO:root:current mean train loss 6327.524708864214
INFO:root:current train perplexity146.8142547607422
INFO:root:current mean train loss 6329.317389267588
INFO:root:current train perplexity146.9418487548828
INFO:root:current mean train loss 6332.20395368785
INFO:root:current train perplexity147.3162078857422
INFO:root:current mean train loss 6341.848462166154
INFO:root:current train perplexity148.10760498046875
INFO:root:current mean train loss 6345.176959736019
INFO:root:current train perplexity148.4644775390625
INFO:root:current mean train loss 6345.599489229031
INFO:root:current train perplexity148.39942932128906
INFO:root:current mean train loss 6340.257445427758
INFO:root:current train perplexity148.0853729248047
INFO:root:current mean train loss 6339.489325801029
INFO:root:current train perplexity147.72377014160156
INFO:root:current mean train loss 6334.951141617663
INFO:root:current train perplexity147.5237274169922
INFO:root:current mean train loss 6334.018153346053
INFO:root:current train perplexity147.60260009765625
INFO:root:current mean train loss 6337.172358046994
INFO:root:current train perplexity148.05747985839844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.94s/it]
INFO:root:final mean train loss: 6338.065033743854
INFO:root:final train perplexity: 148.2025604248047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 5314.972808621454
INFO:root:eval perplexity: 73.58477020263672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.60s/it]
INFO:root:eval mean loss: 5492.557903749723
INFO:root:eval perplexity: 89.29668426513672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [12:55:08<3:00:20, 569.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6462.105372378701
INFO:root:current train perplexity166.36471557617188
INFO:root:current mean train loss 6435.4157825816765
INFO:root:current train perplexity159.4131622314453
INFO:root:current mean train loss 6389.6945606176405
INFO:root:current train perplexity154.42074584960938
INFO:root:current mean train loss 6396.939125872673
INFO:root:current train perplexity155.57986450195312
INFO:root:current mean train loss 6412.558094184939
INFO:root:current train perplexity156.23406982421875
INFO:root:current mean train loss 6436.089359707303
INFO:root:current train perplexity158.12811279296875
INFO:root:current mean train loss 6442.4717071352625
INFO:root:current train perplexity159.352294921875
INFO:root:current mean train loss 6463.115778657579
INFO:root:current train perplexity161.93637084960938
INFO:root:current mean train loss 6466.533403788528
INFO:root:current train perplexity162.4547119140625
INFO:root:current mean train loss 6470.201847764312
INFO:root:current train perplexity162.73995971679688
INFO:root:current mean train loss 6464.839473454926
INFO:root:current train perplexity162.55807495117188
INFO:root:current mean train loss 6462.870159123219
INFO:root:current train perplexity162.43116760253906
INFO:root:current mean train loss 6470.65019431757
INFO:root:current train perplexity163.36863708496094
INFO:root:current mean train loss 6482.05427196414
INFO:root:current train perplexity164.9982147216797
INFO:root:current mean train loss 6488.552902097625
INFO:root:current train perplexity166.48605346679688
INFO:root:current mean train loss 6497.307705487092
INFO:root:current train perplexity167.64913940429688
INFO:root:current mean train loss 6503.011263098523
INFO:root:current train perplexity168.6200408935547
INFO:root:current mean train loss 6508.606670757672
INFO:root:current train perplexity169.57737731933594
INFO:root:current mean train loss 6515.494932129947
INFO:root:current train perplexity170.3582763671875
INFO:root:current mean train loss 6522.072508530096
INFO:root:current train perplexity171.1534423828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.66s/it]
INFO:root:final mean train loss: 6521.286459441385
INFO:root:final train perplexity: 171.2422637939453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.10s/it]
INFO:root:eval mean loss: 5822.763824246454
INFO:root:eval perplexity: 110.9533462524414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it]
INFO:root:eval mean loss: 5976.201452376995
INFO:root:eval perplexity: 132.6219024658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [13:04:33<2:50:26, 568.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6560.05967531922
INFO:root:current train perplexity176.51698303222656
INFO:root:current mean train loss 6539.414070089864
INFO:root:current train perplexity174.6664276123047
INFO:root:current mean train loss 6550.426669488588
INFO:root:current train perplexity175.92735290527344
INFO:root:current mean train loss 6574.877611621342
INFO:root:current train perplexity177.97744750976562
INFO:root:current mean train loss 6597.491384262487
INFO:root:current train perplexity180.85984802246094
INFO:root:current mean train loss 6622.193582518707
INFO:root:current train perplexity183.87510681152344
INFO:root:current mean train loss 6618.718529463158
INFO:root:current train perplexity185.00338745117188
INFO:root:current mean train loss 6626.231242734277
INFO:root:current train perplexity186.31031799316406
INFO:root:current mean train loss 6633.819245170773
INFO:root:current train perplexity187.05958557128906
INFO:root:current mean train loss 6645.449066807496
INFO:root:current train perplexity188.22337341308594
INFO:root:current mean train loss 6652.9098529170005
INFO:root:current train perplexity189.03720092773438
INFO:root:current mean train loss 6653.167568056501
INFO:root:current train perplexity189.5293731689453
INFO:root:current mean train loss 6651.649924624178
INFO:root:current train perplexity189.7244110107422
INFO:root:current mean train loss 6655.535504671797
INFO:root:current train perplexity190.42156982421875
INFO:root:current mean train loss 6661.529160823426
INFO:root:current train perplexity191.17068481445312
INFO:root:current mean train loss 6672.528260541725
INFO:root:current train perplexity192.0790252685547
INFO:root:current mean train loss 6670.924999942317
INFO:root:current train perplexity192.37620544433594
INFO:root:current mean train loss 6673.871706212092
INFO:root:current train perplexity192.9601287841797
INFO:root:current mean train loss 6680.864612222663
INFO:root:current train perplexity193.8219757080078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.61s/it]
INFO:root:final mean train loss: 6683.010339103079
INFO:root:final train perplexity: 194.53726196289062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 6426.401935117465
INFO:root:eval perplexity: 180.78285217285156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it]
INFO:root:eval mean loss: 6558.70739399795
INFO:root:eval perplexity: 213.5543975830078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [13:14:08<2:41:35, 570.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6718.90859375
INFO:root:current train perplexity208.62124633789062
INFO:root:current mean train loss 6768.100967684659
INFO:root:current train perplexity209.04734802246094
INFO:root:current mean train loss 6792.8337890625
INFO:root:current train perplexity211.0891571044922
INFO:root:current mean train loss 6802.217891570061
INFO:root:current train perplexity211.90362548828125
INFO:root:current mean train loss 6794.393735708842
INFO:root:current train perplexity211.85067749023438
INFO:root:current mean train loss 6794.0093682981005
INFO:root:current train perplexity211.65782165527344
INFO:root:current mean train loss 6784.620488601435
INFO:root:current train perplexity211.54864501953125
INFO:root:current mean train loss 6780.698521401849
INFO:root:current train perplexity211.5998992919922
INFO:root:current mean train loss 6780.563761694637
INFO:root:current train perplexity211.84249877929688
INFO:root:current mean train loss 6781.016091818338
INFO:root:current train perplexity212.1363525390625
INFO:root:current mean train loss 6793.504928256498
INFO:root:current train perplexity212.80015563964844
INFO:root:current mean train loss 6794.3141869897245
INFO:root:current train perplexity212.98501586914062
INFO:root:current mean train loss 6799.350675926524
INFO:root:current train perplexity213.5047149658203
INFO:root:current mean train loss 6799.390491934041
INFO:root:current train perplexity213.94374084472656
INFO:root:current mean train loss 6800.138783036901
INFO:root:current train perplexity214.28311157226562
INFO:root:current mean train loss 6804.668890340438
INFO:root:current train perplexity214.6562957763672
INFO:root:current mean train loss 6807.674508382667
INFO:root:current train perplexity215.09010314941406
INFO:root:current mean train loss 6805.192992735746
INFO:root:current train perplexity215.0673370361328
INFO:root:current mean train loss 6810.107015063882
INFO:root:current train perplexity215.3942108154297
INFO:root:current mean train loss 6807.834709383181
INFO:root:current train perplexity214.4539337158203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:12<00:00, 492.44s/it]
INFO:root:final mean train loss: 6802.011871537956
INFO:root:final train perplexity: 213.67918395996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 6448.912355247119
INFO:root:eval perplexity: 184.10409545898438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it]
INFO:root:eval mean loss: 6563.064890327183
INFO:root:eval perplexity: 214.31663513183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [13:23:31<2:31:31, 568.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6608.435998987268
INFO:root:current train perplexity191.22256469726562
INFO:root:current mean train loss 6657.778958538386
INFO:root:current train perplexity190.88238525390625
INFO:root:current mean train loss 6534.999146045568
INFO:root:current train perplexity171.06875610351562
INFO:root:current mean train loss 6333.266921110474
INFO:root:current train perplexity148.1334686279297
INFO:root:current mean train loss 6254.6647852019905
INFO:root:current train perplexity138.70074462890625
INFO:root:current mean train loss 6210.013054806096
INFO:root:current train perplexity133.44158935546875
INFO:root:current mean train loss 6165.317681076805
INFO:root:current train perplexity128.68199157714844
INFO:root:current mean train loss 6123.980116139744
INFO:root:current train perplexity124.23270416259766
INFO:root:current mean train loss 6084.537540385051
INFO:root:current train perplexity120.4840316772461
INFO:root:current mean train loss 6035.230996536206
INFO:root:current train perplexity116.05741882324219
INFO:root:current mean train loss 5988.215880693921
INFO:root:current train perplexity111.8399887084961
INFO:root:current mean train loss 5952.109796992846
INFO:root:current train perplexity108.27969360351562
INFO:root:current mean train loss 5926.39847769267
INFO:root:current train perplexity106.31355285644531
INFO:root:current mean train loss 5914.5464812841465
INFO:root:current train perplexity105.40747833251953
INFO:root:current mean train loss 5913.000291531623
INFO:root:current train perplexity105.20396423339844
INFO:root:current mean train loss 5910.668586855865
INFO:root:current train perplexity105.2573471069336
INFO:root:current mean train loss 5914.8795992072255
INFO:root:current train perplexity105.70665740966797
INFO:root:current mean train loss 5916.959135637576
INFO:root:current train perplexity106.04061126708984
INFO:root:current mean train loss 5923.1225516450295
INFO:root:current train perplexity106.63605499267578
INFO:root:current mean train loss 5929.644612587977
INFO:root:current train perplexity107.15637969970703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.04s/it]
INFO:root:final mean train loss: 5931.199945631619
INFO:root:final train perplexity: 107.52259063720703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 4414.987994687777
INFO:root:eval perplexity: 35.53730010986328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it]
INFO:root:eval mean loss: 4632.653301266068
INFO:root:eval perplexity: 44.199405670166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [13:33:07<2:22:37, 570.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6093.9519153941765
INFO:root:current train perplexity123.06147766113281
INFO:root:current mean train loss 6106.560560438368
INFO:root:current train perplexity125.0945816040039
INFO:root:current mean train loss 6111.842415231173
INFO:root:current train perplexity125.45927429199219
INFO:root:current mean train loss 6131.197539573492
INFO:root:current train perplexity126.23379516601562
INFO:root:current mean train loss 6158.259360923424
INFO:root:current train perplexity128.6298370361328
INFO:root:current mean train loss 6177.830194809858
INFO:root:current train perplexity130.451904296875
INFO:root:current mean train loss 6191.596057204726
INFO:root:current train perplexity131.41525268554688
INFO:root:current mean train loss 6207.831241730721
INFO:root:current train perplexity132.55955505371094
INFO:root:current mean train loss 6226.54793487115
INFO:root:current train perplexity134.31629943847656
INFO:root:current mean train loss 6244.2376812433795
INFO:root:current train perplexity136.1345672607422
INFO:root:current mean train loss 6251.218043769456
INFO:root:current train perplexity137.27537536621094
INFO:root:current mean train loss 6252.5543106185805
INFO:root:current train perplexity137.68798828125
INFO:root:current mean train loss 6263.375803858521
INFO:root:current train perplexity138.6260223388672
INFO:root:current mean train loss 6272.135102771577
INFO:root:current train perplexity139.59002685546875
INFO:root:current mean train loss 6283.137365959357
INFO:root:current train perplexity140.73858642578125
INFO:root:current mean train loss 6290.021997323308
INFO:root:current train perplexity141.6085205078125
INFO:root:current mean train loss 6294.318677470632
INFO:root:current train perplexity142.3577880859375
INFO:root:current mean train loss 6297.171526147685
INFO:root:current train perplexity143.01966857910156
INFO:root:current mean train loss 6299.457939495492
INFO:root:current train perplexity143.53945922851562
INFO:root:current mean train loss 6303.491140106578
INFO:root:current train perplexity144.14283752441406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.12s/it]
INFO:root:final mean train loss: 6305.6927738314735
INFO:root:final train perplexity: 144.4667205810547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.61s/it]
INFO:root:eval mean loss: 5657.332749819925
INFO:root:eval perplexity: 97.05892944335938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.82s/it]
INFO:root:eval mean loss: 5791.70754463791
INFO:root:eval perplexity: 114.04779052734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [13:42:31<2:12:38, 568.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6443.126777023565
INFO:root:current train perplexity160.0926513671875
INFO:root:current mean train loss 6410.35544752038
INFO:root:current train perplexity158.93499755859375
INFO:root:current mean train loss 6420.092870719588
INFO:root:current train perplexity160.00961303710938
INFO:root:current mean train loss 6435.302201458622
INFO:root:current train perplexity161.53164672851562
INFO:root:current mean train loss 6431.201421841106
INFO:root:current train perplexity160.95169067382812
INFO:root:current mean train loss 6417.99435821914
INFO:root:current train perplexity160.10853576660156
INFO:root:current mean train loss 6424.410193185042
INFO:root:current train perplexity159.99900817871094
INFO:root:current mean train loss 6428.964073151076
INFO:root:current train perplexity160.3905792236328
INFO:root:current mean train loss 6430.550781817109
INFO:root:current train perplexity160.48016357421875
INFO:root:current mean train loss 6428.813538042241
INFO:root:current train perplexity160.45237731933594
INFO:root:current mean train loss 6429.427500589067
INFO:root:current train perplexity160.3019561767578
INFO:root:current mean train loss 6429.132571934216
INFO:root:current train perplexity159.81381225585938
INFO:root:current mean train loss 6427.727912727374
INFO:root:current train perplexity159.69406127929688
INFO:root:current mean train loss 6433.1640068911875
INFO:root:current train perplexity159.80419921875
INFO:root:current mean train loss 6437.819498697917
INFO:root:current train perplexity160.1988067626953
INFO:root:current mean train loss 6439.257642023843
INFO:root:current train perplexity160.1916961669922
INFO:root:current mean train loss 6436.308589928412
INFO:root:current train perplexity160.06150817871094
INFO:root:current mean train loss 6435.687189452015
INFO:root:current train perplexity159.99534606933594
INFO:root:current mean train loss 6433.321777606126
INFO:root:current train perplexity159.95973205566406
INFO:root:current mean train loss 6435.253178185556
INFO:root:current train perplexity159.70806884765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.11s/it]
INFO:root:final mean train loss: 6432.053745779556
INFO:root:final train perplexity: 159.6055145263672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 5549.138488336658
INFO:root:eval perplexity: 88.92717742919922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.20s/it]
INFO:root:eval mean loss: 5656.229683517564
INFO:root:eval perplexity: 102.08646392822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [13:51:56<2:02:57, 567.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6454.7957419371
INFO:root:current train perplexity160.9642791748047
INFO:root:current mean train loss 6489.315575074614
INFO:root:current train perplexity163.22630310058594
INFO:root:current mean train loss 6466.914167884443
INFO:root:current train perplexity162.069091796875
INFO:root:current mean train loss 6474.8149181547615
INFO:root:current train perplexity162.61328125
INFO:root:current mean train loss 6472.328550969208
INFO:root:current train perplexity162.94192504882812
INFO:root:current mean train loss 6475.276558107158
INFO:root:current train perplexity163.2319793701172
INFO:root:current mean train loss 6481.416863995667
INFO:root:current train perplexity164.098876953125
INFO:root:current mean train loss 6483.122406084311
INFO:root:current train perplexity164.51771545410156
INFO:root:current mean train loss 6476.975222785272
INFO:root:current train perplexity164.7969970703125
INFO:root:current mean train loss 6480.514030347329
INFO:root:current train perplexity165.4119415283203
INFO:root:current mean train loss 6475.781910402656
INFO:root:current train perplexity165.43505859375
INFO:root:current mean train loss 6479.830293665111
INFO:root:current train perplexity165.29335021972656
INFO:root:current mean train loss 6479.661662356954
INFO:root:current train perplexity165.47386169433594
INFO:root:current mean train loss 6477.657516058713
INFO:root:current train perplexity165.05392456054688
INFO:root:current mean train loss 6478.63594238942
INFO:root:current train perplexity164.83700561523438
INFO:root:current mean train loss 6474.256234714136
INFO:root:current train perplexity164.46791076660156
INFO:root:current mean train loss 6474.392625556373
INFO:root:current train perplexity164.4213409423828
INFO:root:current mean train loss 6471.628820018103
INFO:root:current train perplexity164.1251678466797
INFO:root:current mean train loss 6467.170736457086
INFO:root:current train perplexity163.76524353027344
INFO:root:current mean train loss 6464.115001836609
INFO:root:current train perplexity163.4824981689453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.06s/it]
INFO:root:final mean train loss: 6462.168534717955
INFO:root:final train perplexity: 163.44149780273438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.27s/it]
INFO:root:eval mean loss: 5386.281556474401
INFO:root:eval perplexity: 77.95320129394531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it]
INFO:root:eval mean loss: 5485.403360136857
INFO:root:eval perplexity: 88.77571105957031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [14:01:21<1:53:21, 566.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6366.857884457237
INFO:root:current train perplexity151.43238830566406
INFO:root:current mean train loss 6362.869418569711
INFO:root:current train perplexity151.4212646484375
INFO:root:current mean train loss 6382.73159096928
INFO:root:current train perplexity152.7382354736328
INFO:root:current mean train loss 6355.881395866298
INFO:root:current train perplexity151.4693603515625
INFO:root:current mean train loss 6381.317836568813
INFO:root:current train perplexity153.51712036132812
INFO:root:current mean train loss 6396.459946165966
INFO:root:current train perplexity155.0091552734375
INFO:root:current mean train loss 6399.927761072392
INFO:root:current train perplexity155.72325134277344
INFO:root:current mean train loss 6400.404978626179
INFO:root:current train perplexity155.49472045898438
INFO:root:current mean train loss 6414.841043448848
INFO:root:current train perplexity156.0423583984375
INFO:root:current mean train loss 6409.962685497801
INFO:root:current train perplexity156.3961944580078
INFO:root:current mean train loss 6413.0891463327625
INFO:root:current train perplexity156.26231384277344
INFO:root:current mean train loss 6403.116050356302
INFO:root:current train perplexity155.56317138671875
INFO:root:current mean train loss 6402.164211812259
INFO:root:current train perplexity155.33694458007812
INFO:root:current mean train loss 6403.837817470318
INFO:root:current train perplexity155.23423767089844
INFO:root:current mean train loss 6402.549481670673
INFO:root:current train perplexity155.32850646972656
INFO:root:current mean train loss 6396.149491207876
INFO:root:current train perplexity155.0566864013672
INFO:root:current mean train loss 6397.728816371681
INFO:root:current train perplexity155.0508575439453
INFO:root:current mean train loss 6395.039879112987
INFO:root:current train perplexity154.81045532226562
INFO:root:current mean train loss 6393.015256276797
INFO:root:current train perplexity154.64378356933594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.66s/it]
INFO:root:final mean train loss: 6391.463633019336
INFO:root:final train perplexity: 154.5770721435547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.26s/it]
INFO:root:eval mean loss: 5532.501485621676
INFO:root:eval perplexity: 87.73867797851562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.90s/it]
INFO:root:eval mean loss: 5621.24323678524
INFO:root:eval perplexity: 99.20684814453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [14:10:49<1:43:59, 567.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6595.0504150390625
INFO:root:current train perplexity159.04969787597656
INFO:root:current mean train loss 6422.400111607143
INFO:root:current train perplexity155.59388732910156
INFO:root:current mean train loss 6392.541427900206
INFO:root:current train perplexity152.0152130126953
INFO:root:current mean train loss 6368.119677421374
INFO:root:current train perplexity150.88926696777344
INFO:root:current mean train loss 6356.0367905700095
INFO:root:current train perplexity149.96946716308594
INFO:root:current mean train loss 6355.616041183472
INFO:root:current train perplexity150.00315856933594
INFO:root:current mean train loss 6369.372899273641
INFO:root:current train perplexity150.8082733154297
INFO:root:current mean train loss 6365.094040088439
INFO:root:current train perplexity150.8966827392578
INFO:root:current mean train loss 6359.607045441426
INFO:root:current train perplexity151.1893768310547
INFO:root:current mean train loss 6364.657520494963
INFO:root:current train perplexity151.83309936523438
INFO:root:current mean train loss 6374.269079638093
INFO:root:current train perplexity152.5672607421875
INFO:root:current mean train loss 6373.910237044739
INFO:root:current train perplexity152.13450622558594
INFO:root:current mean train loss 6370.340593495384
INFO:root:current train perplexity151.49847412109375
INFO:root:current mean train loss 6364.6945186708035
INFO:root:current train perplexity150.86668395996094
INFO:root:current mean train loss 6363.81748966725
INFO:root:current train perplexity150.76283264160156
INFO:root:current mean train loss 6363.57177734375
INFO:root:current train perplexity150.78591918945312
INFO:root:current mean train loss 6358.560751941009
INFO:root:current train perplexity150.48452758789062
INFO:root:current mean train loss 6356.9545633191265
INFO:root:current train perplexity150.33799743652344
INFO:root:current mean train loss 6355.8427327473955
INFO:root:current train perplexity150.0643310546875
INFO:root:current mean train loss 6352.434749587311
INFO:root:current train perplexity149.75938415527344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:24<00:00, 504.44s/it]
INFO:root:final mean train loss: 6350.939194702825
INFO:root:final train perplexity: 149.7148895263672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 5336.677072944371
INFO:root:eval perplexity: 74.88783264160156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 5415.938463576296
INFO:root:eval perplexity: 83.8729476928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [14:20:29<1:35:08, 570.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6192.233752020474
INFO:root:current train perplexity142.68357849121094
INFO:root:current mean train loss 6318.317572068799
INFO:root:current train perplexity147.50473022460938
INFO:root:current mean train loss 6319.218221206332
INFO:root:current train perplexity148.62660217285156
INFO:root:current mean train loss 6314.594947698994
INFO:root:current train perplexity148.18362426757812
INFO:root:current mean train loss 6332.685082495629
INFO:root:current train perplexity148.2294158935547
INFO:root:current mean train loss 6347.769160193171
INFO:root:current train perplexity148.5823211669922
INFO:root:current mean train loss 6358.840636333714
INFO:root:current train perplexity149.8120880126953
INFO:root:current mean train loss 6355.459139767661
INFO:root:current train perplexity149.7266082763672
INFO:root:current mean train loss 6360.628196504636
INFO:root:current train perplexity150.3138427734375
INFO:root:current mean train loss 6365.382729455396
INFO:root:current train perplexity150.677734375
INFO:root:current mean train loss 6364.812502372601
INFO:root:current train perplexity150.81747436523438
INFO:root:current mean train loss 6364.736618325814
INFO:root:current train perplexity151.14865112304688
INFO:root:current mean train loss 6366.351234727802
INFO:root:current train perplexity151.33558654785156
INFO:root:current mean train loss 6359.5231935430775
INFO:root:current train perplexity150.74774169921875
INFO:root:current mean train loss 6359.284521381866
INFO:root:current train perplexity150.66632080078125
INFO:root:current mean train loss 6359.334725259565
INFO:root:current train perplexity150.44512939453125
INFO:root:current mean train loss 6356.85395804558
INFO:root:current train perplexity149.86618041992188
INFO:root:current mean train loss 6357.322940294697
INFO:root:current train perplexity149.92442321777344
INFO:root:current mean train loss 6357.232709397639
INFO:root:current train perplexity150.18280029296875
INFO:root:current mean train loss 6357.859600535819
INFO:root:current train perplexity150.31942749023438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:26<00:00, 506.99s/it]
INFO:root:final mean train loss: 6355.262662440313
INFO:root:final train perplexity: 150.2262725830078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 5435.759422789229
INFO:root:eval perplexity: 81.13568878173828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it]
INFO:root:eval mean loss: 5520.94918238863
INFO:root:eval perplexity: 91.39437103271484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [14:30:08<1:26:01, 573.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6343.050940472147
INFO:root:current train perplexity150.28695678710938
INFO:root:current mean train loss 6304.625428082192
INFO:root:current train perplexity147.1472930908203
INFO:root:current mean train loss 6332.0667516196645
INFO:root:current train perplexity148.75352478027344
INFO:root:current mean train loss 6332.058216954932
INFO:root:current train perplexity149.53231811523438
INFO:root:current mean train loss 6351.916222542391
INFO:root:current train perplexity150.74349975585938
INFO:root:current mean train loss 6354.321566291781
INFO:root:current train perplexity151.49197387695312
INFO:root:current mean train loss 6361.695219530041
INFO:root:current train perplexity151.758544921875
INFO:root:current mean train loss 6367.044470247571
INFO:root:current train perplexity151.8470001220703
INFO:root:current mean train loss 6360.965170425163
INFO:root:current train perplexity151.631591796875
INFO:root:current mean train loss 6359.194979580966
INFO:root:current train perplexity151.53900146484375
INFO:root:current mean train loss 6365.4727491448075
INFO:root:current train perplexity151.4517364501953
INFO:root:current mean train loss 6358.295404617283
INFO:root:current train perplexity150.9271240234375
INFO:root:current mean train loss 6363.115779870586
INFO:root:current train perplexity151.22715759277344
INFO:root:current mean train loss 6367.5866470677
INFO:root:current train perplexity151.57875061035156
INFO:root:current mean train loss 6375.074110355615
INFO:root:current train perplexity152.18899536132812
INFO:root:current mean train loss 6373.236795876961
INFO:root:current train perplexity152.07510375976562
INFO:root:current mean train loss 6370.787521714573
INFO:root:current train perplexity151.80421447753906
INFO:root:current mean train loss 6365.563406648232
INFO:root:current train perplexity151.3401336669922
INFO:root:current mean train loss 6361.5588251942545
INFO:root:current train perplexity150.9464874267578
INFO:root:current mean train loss 6360.901998239578
INFO:root:current train perplexity150.80230712890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.91s/it]
INFO:root:final mean train loss: 6360.213294448122
INFO:root:final train perplexity: 150.81394958496094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.84s/it]
INFO:root:eval mean loss: 5322.613009405474
INFO:root:eval perplexity: 74.04084777832031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.33s/it]
INFO:root:eval mean loss: 5407.534227303579
INFO:root:eval perplexity: 83.29841613769531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [14:39:37<1:16:15, 571.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6260.6479569692465
INFO:root:current train perplexity144.0658721923828
INFO:root:current mean train loss 6268.66998178681
INFO:root:current train perplexity144.83505249023438
INFO:root:current mean train loss 6310.509067549905
INFO:root:current train perplexity147.4866485595703
INFO:root:current mean train loss 6343.618312026515
INFO:root:current train perplexity150.78160095214844
INFO:root:current mean train loss 6371.540572691684
INFO:root:current train perplexity153.54566955566406
INFO:root:current mean train loss 6375.594452500555
INFO:root:current train perplexity154.2661895751953
INFO:root:current mean train loss 6383.761125889659
INFO:root:current train perplexity155.03761291503906
INFO:root:current mean train loss 6394.647299030349
INFO:root:current train perplexity155.79232788085938
INFO:root:current mean train loss 6399.077122976716
INFO:root:current train perplexity155.9261016845703
INFO:root:current mean train loss 6401.88075492439
INFO:root:current train perplexity155.9078826904297
INFO:root:current mean train loss 6408.912559990152
INFO:root:current train perplexity156.16525268554688
INFO:root:current mean train loss 6403.32336940093
INFO:root:current train perplexity155.4178466796875
INFO:root:current mean train loss 6402.208406401549
INFO:root:current train perplexity155.29214477539062
INFO:root:current mean train loss 6399.699196539114
INFO:root:current train perplexity154.8216094970703
INFO:root:current mean train loss 6389.280359545882
INFO:root:current train perplexity153.90609741210938
INFO:root:current mean train loss 6387.273895790847
INFO:root:current train perplexity153.5304412841797
INFO:root:current mean train loss 6383.309405007422
INFO:root:current train perplexity153.4467010498047
INFO:root:current mean train loss 6382.439022728481
INFO:root:current train perplexity153.3246307373047
INFO:root:current mean train loss 6379.6424040945385
INFO:root:current train perplexity152.89804077148438
INFO:root:current mean train loss 6379.909599315859
INFO:root:current train perplexity152.893310546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:21<00:00, 501.56s/it]
INFO:root:final mean train loss: 6377.516190721721
INFO:root:final train perplexity: 152.88609313964844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 5618.199490594526
INFO:root:eval perplexity: 94.03524780273438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.59s/it]
INFO:root:eval mean loss: 5721.134560442985
INFO:root:eval perplexity: 107.65166473388672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [14:49:10<1:06:47, 572.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6369.442846679687
INFO:root:current train perplexity152.60894775390625
INFO:root:current mean train loss 6415.046470811632
INFO:root:current train perplexity155.0382843017578
INFO:root:current mean train loss 6385.336204310825
INFO:root:current train perplexity152.05821228027344
INFO:root:current mean train loss 6374.639541786595
INFO:root:current train perplexity150.4538116455078
INFO:root:current mean train loss 6352.954234822591
INFO:root:current train perplexity149.2813262939453
INFO:root:current mean train loss 6346.628533304149
INFO:root:current train perplexity148.75628662109375
INFO:root:current mean train loss 6341.038178567325
INFO:root:current train perplexity147.87001037597656
INFO:root:current mean train loss 6343.371396108774
INFO:root:current train perplexity148.02769470214844
INFO:root:current mean train loss 6335.628204900569
INFO:root:current train perplexity147.70257568359375
INFO:root:current mean train loss 6341.578597835619
INFO:root:current train perplexity148.12611389160156
INFO:root:current mean train loss 6345.074159523293
INFO:root:current train perplexity148.6935272216797
INFO:root:current mean train loss 6350.401923331568
INFO:root:current train perplexity149.19786071777344
INFO:root:current mean train loss 6349.642028808594
INFO:root:current train perplexity149.31051635742188
INFO:root:current mean train loss 6351.706958007812
INFO:root:current train perplexity149.2827606201172
INFO:root:current mean train loss 6348.121614693307
INFO:root:current train perplexity149.1641387939453
INFO:root:current mean train loss 6352.3725743547275
INFO:root:current train perplexity149.52447509765625
INFO:root:current mean train loss 6352.705709402901
INFO:root:current train perplexity149.57440185546875
INFO:root:current mean train loss 6354.18916948297
INFO:root:current train perplexity149.76687622070312
INFO:root:current mean train loss 6355.050620480802
INFO:root:current train perplexity149.92034912109375
INFO:root:current mean train loss 6354.171145044192
INFO:root:current train perplexity149.89947509765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:17<00:00, 497.09s/it]
INFO:root:final mean train loss: 6352.5095514017585
INFO:root:final train perplexity: 149.90040588378906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 5418.297920822251
INFO:root:eval perplexity: 79.99797821044922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.36s/it]
INFO:root:eval mean loss: 5508.8917755776265
INFO:root:eval perplexity: 90.49756622314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [14:58:39<57:07, 571.21s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6306.414143041237
INFO:root:current train perplexity147.23355102539062
INFO:root:current mean train loss 6342.28711928934
INFO:root:current train perplexity150.14700317382812
INFO:root:current mean train loss 6342.183907762521
INFO:root:current train perplexity150.65000915527344
INFO:root:current mean train loss 6354.690498563445
INFO:root:current train perplexity151.5872039794922
INFO:root:current mean train loss 6355.08084444165
INFO:root:current train perplexity152.59359741210938
INFO:root:current mean train loss 6351.17574444488
INFO:root:current train perplexity152.1606903076172
INFO:root:current mean train loss 6346.00631753273
INFO:root:current train perplexity151.23617553710938
INFO:root:current mean train loss 6352.250003675894
INFO:root:current train perplexity151.07911682128906
INFO:root:current mean train loss 6356.232143712548
INFO:root:current train perplexity150.99319458007812
INFO:root:current mean train loss 6362.267690767615
INFO:root:current train perplexity151.7069549560547
INFO:root:current mean train loss 6368.024617475929
INFO:root:current train perplexity152.02825927734375
INFO:root:current mean train loss 6367.247010756057
INFO:root:current train perplexity151.643310546875
INFO:root:current mean train loss 6365.15657978749
INFO:root:current train perplexity151.37405395507812
INFO:root:current mean train loss 6367.431923038207
INFO:root:current train perplexity151.31033325195312
INFO:root:current mean train loss 6368.288986175476
INFO:root:current train perplexity151.2531280517578
INFO:root:current mean train loss 6372.4397457268515
INFO:root:current train perplexity151.61886596679688
INFO:root:current mean train loss 6369.9346523161275
INFO:root:current train perplexity151.8075408935547
INFO:root:current mean train loss 6371.976707055162
INFO:root:current train perplexity152.05995178222656
INFO:root:current mean train loss 6373.509620968141
INFO:root:current train perplexity152.1576385498047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.35s/it]
INFO:root:final mean train loss: 6372.593417953976
INFO:root:final train perplexity: 152.29359436035156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.19s/it]
INFO:root:eval mean loss: 5660.156151304854
INFO:root:eval perplexity: 97.28082275390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.68s/it]
INFO:root:eval mean loss: 5761.69104350205
INFO:root:eval perplexity: 111.28221893310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [15:08:03<47:26, 569.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6551.363316127232
INFO:root:current train perplexity161.8621063232422
INFO:root:current mean train loss 6399.920273094846
INFO:root:current train perplexity159.9199981689453
INFO:root:current mean train loss 6442.367963273949
INFO:root:current train perplexity159.392333984375
INFO:root:current mean train loss 6430.339238841063
INFO:root:current train perplexity159.17398071289062
INFO:root:current mean train loss 6426.041937934027
INFO:root:current train perplexity157.44667053222656
INFO:root:current mean train loss 6416.6691381550945
INFO:root:current train perplexity156.3674774169922
INFO:root:current mean train loss 6410.296440000255
INFO:root:current train perplexity156.49295043945312
INFO:root:current mean train loss 6412.3830662147675
INFO:root:current train perplexity156.65615844726562
INFO:root:current mean train loss 6412.098771378801
INFO:root:current train perplexity156.44952392578125
INFO:root:current mean train loss 6406.124422503248
INFO:root:current train perplexity155.76046752929688
INFO:root:current mean train loss 6400.724244849452
INFO:root:current train perplexity155.4970245361328
INFO:root:current mean train loss 6407.13273009706
INFO:root:current train perplexity155.74880981445312
INFO:root:current mean train loss 6401.146364919044
INFO:root:current train perplexity155.31776428222656
INFO:root:current mean train loss 6399.656689601765
INFO:root:current train perplexity155.2124786376953
INFO:root:current mean train loss 6404.328805969325
INFO:root:current train perplexity155.24267578125
INFO:root:current mean train loss 6401.198178975396
INFO:root:current train perplexity155.18666076660156
INFO:root:current mean train loss 6400.189536017851
INFO:root:current train perplexity155.2416534423828
INFO:root:current mean train loss 6396.45268771195
INFO:root:current train perplexity155.04434204101562
INFO:root:current mean train loss 6396.198739620659
INFO:root:current train perplexity154.9725799560547
INFO:root:current mean train loss 6396.554224474677
INFO:root:current train perplexity154.99732971191406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:23<00:00, 503.90s/it]
INFO:root:final mean train loss: 6394.3357712923125
INFO:root:final train perplexity: 154.92758178710938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 5623.952451448914
INFO:root:eval perplexity: 94.47380828857422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.66s/it]
INFO:root:eval mean loss: 5728.800492090536
INFO:root:eval perplexity: 108.32870483398438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [15:17:40<38:05, 571.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6500.0333606350805
INFO:root:current train perplexity159.7196502685547
INFO:root:current mean train loss 6432.785454437023
INFO:root:current train perplexity156.91497802734375
INFO:root:current mean train loss 6427.188755580357
INFO:root:current train perplexity156.4713897705078
INFO:root:current mean train loss 6422.609917862538
INFO:root:current train perplexity156.555419921875
INFO:root:current mean train loss 6438.149954457294
INFO:root:current train perplexity157.34190368652344
INFO:root:current mean train loss 6425.28295944415
INFO:root:current train perplexity157.33619689941406
INFO:root:current mean train loss 6430.644547500247
INFO:root:current train perplexity157.91246032714844
INFO:root:current mean train loss 6438.718211621494
INFO:root:current train perplexity158.19688415527344
INFO:root:current mean train loss 6439.882969384589
INFO:root:current train perplexity158.48538208007812
INFO:root:current mean train loss 6429.4200986212745
INFO:root:current train perplexity157.99598693847656
INFO:root:current mean train loss 6427.547702852206
INFO:root:current train perplexity157.64439392089844
INFO:root:current mean train loss 6421.6069884228555
INFO:root:current train perplexity157.29441833496094
INFO:root:current mean train loss 6412.457873346745
INFO:root:current train perplexity156.63912963867188
INFO:root:current mean train loss 6403.699230122441
INFO:root:current train perplexity155.92431640625
INFO:root:current mean train loss 6400.773701943025
INFO:root:current train perplexity155.4923553466797
INFO:root:current mean train loss 6399.580984522983
INFO:root:current train perplexity155.43800354003906
INFO:root:current mean train loss 6400.714939849498
INFO:root:current train perplexity155.35243225097656
INFO:root:current mean train loss 6402.23211102235
INFO:root:current train perplexity155.32508850097656
INFO:root:current mean train loss 6398.318797254745
INFO:root:current train perplexity155.06016540527344
INFO:root:current mean train loss 6394.312426416445
INFO:root:current train perplexity154.81503295898438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:13<00:00, 493.79s/it]
INFO:root:final mean train loss: 6392.896196281676
INFO:root:final train perplexity: 154.7517852783203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.17s/it]
INFO:root:eval mean loss: 5407.484368074025
INFO:root:eval perplexity: 79.30143737792969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.39s/it]
INFO:root:eval mean loss: 5489.372997527427
INFO:root:eval perplexity: 89.06441497802734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [15:27:05<28:28, 569.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6411.338317871094
INFO:root:current train perplexity150.83798217773438
INFO:root:current mean train loss 6414.033391179265
INFO:root:current train perplexity152.18572998046875
INFO:root:current mean train loss 6401.003797961819
INFO:root:current train perplexity153.4001007080078
INFO:root:current mean train loss 6377.896950206537
INFO:root:current train perplexity153.12510681152344
INFO:root:current mean train loss 6375.878859383719
INFO:root:current train perplexity153.37216186523438
INFO:root:current mean train loss 6388.627036881273
INFO:root:current train perplexity154.0420684814453
INFO:root:current mean train loss 6378.280348036024
INFO:root:current train perplexity153.70799255371094
INFO:root:current mean train loss 6380.040413106826
INFO:root:current train perplexity153.9541015625
INFO:root:current mean train loss 6388.39417310031
INFO:root:current train perplexity154.1111297607422
INFO:root:current mean train loss 6389.733692024328
INFO:root:current train perplexity154.01194763183594
INFO:root:current mean train loss 6384.06715125164
INFO:root:current train perplexity153.49127197265625
INFO:root:current mean train loss 6380.375467014645
INFO:root:current train perplexity153.040283203125
INFO:root:current mean train loss 6382.824520795773
INFO:root:current train perplexity153.06968688964844
INFO:root:current mean train loss 6385.602586514165
INFO:root:current train perplexity153.12911987304688
INFO:root:current mean train loss 6379.911891874029
INFO:root:current train perplexity152.99490356445312
INFO:root:current mean train loss 6375.214256109193
INFO:root:current train perplexity152.79251098632812
INFO:root:current mean train loss 6373.558261612086
INFO:root:current train perplexity152.72972106933594
INFO:root:current mean train loss 6376.230119299288
INFO:root:current train perplexity152.71800231933594
INFO:root:current mean train loss 6377.093989384639
INFO:root:current train perplexity152.67379760742188
INFO:root:current mean train loss 6379.097677305249
INFO:root:current train perplexity152.6729278564453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:14<00:00, 494.25s/it]
INFO:root:final mean train loss: 6374.867111906282
INFO:root:final train perplexity: 152.5669708251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 5523.624574052526
INFO:root:eval perplexity: 87.11099243164062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 5613.498884052249
INFO:root:eval perplexity: 98.58052062988281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [15:36:34<18:58, 569.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6316.100518329327
INFO:root:current train perplexity150.24827575683594
INFO:root:current mean train loss 6395.371715198864
INFO:root:current train perplexity153.5196075439453
INFO:root:current mean train loss 6394.494713664505
INFO:root:current train perplexity153.64981079101562
INFO:root:current mean train loss 6395.743371414812
INFO:root:current train perplexity153.2362060546875
INFO:root:current mean train loss 6392.793862357191
INFO:root:current train perplexity153.41818237304688
INFO:root:current mean train loss 6374.003253767975
INFO:root:current train perplexity152.8992919921875
INFO:root:current mean train loss 6370.78702052984
INFO:root:current train perplexity152.8272705078125
INFO:root:current mean train loss 6376.696954146242
INFO:root:current train perplexity153.5300750732422
INFO:root:current mean train loss 6378.924176413476
INFO:root:current train perplexity153.65281677246094
INFO:root:current mean train loss 6381.729556954339
INFO:root:current train perplexity153.90733337402344
INFO:root:current mean train loss 6387.413567800029
INFO:root:current train perplexity154.16140747070312
INFO:root:current mean train loss 6390.142585250134
INFO:root:current train perplexity154.56417846679688
INFO:root:current mean train loss 6391.340076503829
INFO:root:current train perplexity154.78085327148438
INFO:root:current mean train loss 6388.800083705357
INFO:root:current train perplexity154.84005737304688
INFO:root:current mean train loss 6394.301452845029
INFO:root:current train perplexity155.10520935058594
INFO:root:current mean train loss 6393.129038850339
INFO:root:current train perplexity155.19515991210938
INFO:root:current mean train loss 6396.712903235267
INFO:root:current train perplexity155.26414489746094
INFO:root:current mean train loss 6396.840270892351
INFO:root:current train perplexity155.33465576171875
INFO:root:current mean train loss 6396.632064238438
INFO:root:current train perplexity155.205078125
INFO:root:current mean train loss 6397.84528193583
INFO:root:current train perplexity155.17230224609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:25<00:00, 505.49s/it]
INFO:root:final mean train loss: 6396.133317648252
INFO:root:final train perplexity: 155.14736938476562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it]
INFO:root:eval mean loss: 5662.097874418218
INFO:root:eval perplexity: 97.43374633789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.24s/it]
INFO:root:eval mean loss: 5762.97636164672
INFO:root:eval perplexity: 111.3992919921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [15:46:11<09:31, 571.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6348.973031392911
INFO:root:current train perplexity153.2615509033203
INFO:root:current mean train loss 6350.426215873969
INFO:root:current train perplexity153.14694213867188
INFO:root:current mean train loss 6385.596648520612
INFO:root:current train perplexity154.1422119140625
INFO:root:current mean train loss 6401.268342502454
INFO:root:current train perplexity154.52540588378906
INFO:root:current mean train loss 6397.276724787668
INFO:root:current train perplexity154.88059997558594
INFO:root:current mean train loss 6395.293097951568
INFO:root:current train perplexity154.96031188964844
INFO:root:current mean train loss 6387.367213274377
INFO:root:current train perplexity154.7118682861328
INFO:root:current mean train loss 6382.917900065937
INFO:root:current train perplexity154.30702209472656
INFO:root:current mean train loss 6388.988156688457
INFO:root:current train perplexity154.5166473388672
INFO:root:current mean train loss 6395.23616652479
INFO:root:current train perplexity154.49998474121094
INFO:root:current mean train loss 6393.527305842768
INFO:root:current train perplexity154.4913787841797
INFO:root:current mean train loss 6397.063252250555
INFO:root:current train perplexity154.54087829589844
INFO:root:current mean train loss 6399.768165052774
INFO:root:current train perplexity154.71017456054688
INFO:root:current mean train loss 6399.565033974764
INFO:root:current train perplexity154.71665954589844
INFO:root:current mean train loss 6397.389210565852
INFO:root:current train perplexity154.60743713378906
INFO:root:current mean train loss 6395.516145689297
INFO:root:current train perplexity154.6126708984375
INFO:root:current mean train loss 6397.827823960965
INFO:root:current train perplexity154.74868774414062
INFO:root:current mean train loss 6397.711424685221
INFO:root:current train perplexity154.76055908203125
INFO:root:current mean train loss 6393.043061372958
INFO:root:current train perplexity154.59645080566406
INFO:root:current mean train loss 6393.686818081484
INFO:root:current train perplexity154.6053009033203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:15<00:00, 495.53s/it]
INFO:root:final mean train loss: 6391.640561348611
INFO:root:final train perplexity: 154.5985870361328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it]
INFO:root:eval mean loss: 5621.754129612699
INFO:root:eval perplexity: 94.30602264404297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.09s/it]
INFO:root:eval mean loss: 5723.531787628823
INFO:root:eval perplexity: 107.86295318603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll6_alll12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [15:55:42<00:00, 571.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [15:55:42<00:00, 573.42s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.30s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.30s/it]
INFO:root:eval mean loss: 5621.754129612699
INFO:root:eval perplexity: 94.30602264404297
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.15s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.15s/it]
INFO:root:eval mean loss: 5723.531787628823
INFO:root:eval perplexity: 107.86295318603516
INFO:root:evalaution complete
INFO:root:save model final: alll6_alll12_not_concat_100e/final
