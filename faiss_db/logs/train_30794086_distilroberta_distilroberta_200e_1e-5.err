INFO:root:in update config, concat_self: False
INFO:root:Output: distilroberta_distilroberta_not_concat
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models_roberta.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModelRoberta were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models_roberta.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10378.254325481375
INFO:root:current train perplexity3611.654541015625
INFO:root:current mean train loss 9246.204064757381
INFO:root:current train perplexity1470.7379150390625
INFO:root:current mean train loss 8632.150540865385
INFO:root:current train perplexity909.2925415039062
INFO:root:current mean train loss 8180.177605879934
INFO:root:current train perplexity639.9222412109375
INFO:root:current mean train loss 7809.470137540707
INFO:root:current train perplexity480.64935302734375
INFO:root:current mean train loss 7489.299763929465
INFO:root:current train perplexity370.2310791015625
INFO:root:current mean train loss 7185.941474008629
INFO:root:current train perplexity290.76348876953125
INFO:root:current mean train loss 6912.209522767717
INFO:root:current train perplexity234.7322540283203
INFO:root:current mean train loss 6672.974448334521
INFO:root:current train perplexity194.12905883789062
INFO:root:current mean train loss 6459.646263939721
INFO:root:current train perplexity164.44760131835938
INFO:root:current mean train loss 6272.676516115503
INFO:root:current train perplexity141.51564025878906
INFO:root:current mean train loss 6101.244471915073
INFO:root:current train perplexity123.6719741821289
INFO:root:current mean train loss 5946.289542511668
INFO:root:current train perplexity109.3658676147461
INFO:root:current mean train loss 5809.602062473475
INFO:root:current train perplexity97.97305297851562
INFO:root:current mean train loss 5683.195937916945
INFO:root:current train perplexity88.51532745361328
INFO:root:current mean train loss 5567.509349715642
INFO:root:current train perplexity80.77964782714844
INFO:root:current mean train loss 5460.131896577491
INFO:root:current train perplexity74.21981048583984
INFO:root:current mean train loss 5360.098037592499
INFO:root:current train perplexity68.62901306152344
INFO:root:current mean train loss 5266.830321751374
INFO:root:current train perplexity63.77140426635742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:07<00:00, 787.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:07<00:00, 787.34s/it]
INFO:root:final mean train loss: 5193.931893137567
INFO:root:final train perplexity: 60.2823600769043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.96s/it]
INFO:root:eval mean loss: 3157.7371462558176
INFO:root:eval perplexity: 12.875001907348633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.29s/it]
INFO:root:eval mean loss: 3421.0297375401706
INFO:root:eval perplexity: 16.651939392089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/1
  0%|          | 1/200 [15:05<50:03:49, 905.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3535.5687561035156
INFO:root:current train perplexity16.08735466003418
INFO:root:current mean train loss 3480.872539651805
INFO:root:current train perplexity15.653634071350098
INFO:root:current mean train loss 3445.7785734953704
INFO:root:current train perplexity15.252800941467285
INFO:root:current mean train loss 3422.054789482793
INFO:root:current train perplexity14.957535743713379
INFO:root:current mean train loss 3416.8199873704175
INFO:root:current train perplexity14.809839248657227
INFO:root:current mean train loss 3393.1314957493037
INFO:root:current train perplexity14.569037437438965
INFO:root:current mean train loss 3376.375456178343
INFO:root:current train perplexity14.368610382080078
INFO:root:current mean train loss 3359.568082841415
INFO:root:current train perplexity14.189040184020996
INFO:root:current mean train loss 3343.687706741632
INFO:root:current train perplexity14.000164985656738
INFO:root:current mean train loss 3329.3727214430096
INFO:root:current train perplexity13.833465576171875
INFO:root:current mean train loss 3315.115927388349
INFO:root:current train perplexity13.666812896728516
INFO:root:current mean train loss 3299.783218657244
INFO:root:current train perplexity13.510725975036621
INFO:root:current mean train loss 3283.9836056357935
INFO:root:current train perplexity13.345123291015625
INFO:root:current mean train loss 3268.8329582794095
INFO:root:current train perplexity13.195463180541992
INFO:root:current mean train loss 3254.810516357422
INFO:root:current train perplexity13.040307998657227
INFO:root:current mean train loss 3241.190885116054
INFO:root:current train perplexity12.894831657409668
INFO:root:current mean train loss 3224.7484017551537
INFO:root:current train perplexity12.739838600158691
INFO:root:current mean train loss 3210.5861908883758
INFO:root:current train perplexity12.5986909866333
INFO:root:current mean train loss 3197.5704251596057
INFO:root:current train perplexity12.473564147949219
INFO:root:current mean train loss 3184.105408861642
INFO:root:current train perplexity12.343783378601074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:02<00:00, 782.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:02<00:00, 782.03s/it]
INFO:root:final mean train loss: 3176.7392355899165
INFO:root:final train perplexity: 12.269000053405762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.41s/it]
INFO:root:eval mean loss: 2660.6110796556404
INFO:root:eval perplexity: 8.610701560974121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.17s/it]
INFO:root:eval mean loss: 2972.4074075036015
INFO:root:eval perplexity: 11.515586853027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/2
  1%|          | 2/200 [30:06<49:39:49, 902.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2912.9914032907195
INFO:root:current train perplexity9.998440742492676
INFO:root:current mean train loss 2912.9907079710997
INFO:root:current train perplexity9.996543884277344
INFO:root:current mean train loss 2890.1428526522263
INFO:root:current train perplexity9.864842414855957
INFO:root:current mean train loss 2894.3550464527025
INFO:root:current train perplexity9.866682052612305
INFO:root:current mean train loss 2886.729223238128
INFO:root:current train perplexity9.778403282165527
INFO:root:current mean train loss 2880.578135077099
INFO:root:current train perplexity9.720489501953125
INFO:root:current mean train loss 2873.1772468651266
INFO:root:current train perplexity9.662992477416992
INFO:root:current mean train loss 2868.0067456754136
INFO:root:current train perplexity9.613767623901367
INFO:root:current mean train loss 2858.4277232377326
INFO:root:current train perplexity9.55739688873291
INFO:root:current mean train loss 2850.8634898031382
INFO:root:current train perplexity9.506699562072754
INFO:root:current mean train loss 2845.683684741424
INFO:root:current train perplexity9.462213516235352
INFO:root:current mean train loss 2836.473472925171
INFO:root:current train perplexity9.398721694946289
INFO:root:current mean train loss 2833.299945865331
INFO:root:current train perplexity9.363778114318848
INFO:root:current mean train loss 2828.0230157026563
INFO:root:current train perplexity9.325153350830078
INFO:root:current mean train loss 2822.6572735847
INFO:root:current train perplexity9.286746978759766
INFO:root:current mean train loss 2818.513145849896
INFO:root:current train perplexity9.251805305480957
INFO:root:current mean train loss 2812.4184523966146
INFO:root:current train perplexity9.212238311767578
INFO:root:current mean train loss 2807.6776891533377
INFO:root:current train perplexity9.168691635131836
INFO:root:current mean train loss 2804.553470659438
INFO:root:current train perplexity9.137474060058594
INFO:root:current mean train loss 2798.842854144101
INFO:root:current train perplexity9.094675064086914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.38s/it]
INFO:root:final mean train loss: 2794.600513914169
INFO:root:final train perplexity: 9.07471752166748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.06s/it]
INFO:root:eval mean loss: 2457.5712466409022
INFO:root:eval perplexity: 7.306050777435303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it]
INFO:root:eval mean loss: 2790.2005372825242
INFO:root:eval perplexity: 9.913565635681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/3
  2%|â–         | 3/200 [45:09<49:24:19, 902.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2641.9466796875
INFO:root:current train perplexity8.131011009216309
INFO:root:current mean train loss 2657.433701171875
INFO:root:current train perplexity8.187063217163086
INFO:root:current mean train loss 2662.69255859375
INFO:root:current train perplexity8.184722900390625
INFO:root:current mean train loss 2662.497047293527
INFO:root:current train perplexity8.153377532958984
INFO:root:current mean train loss 2654.574869249132
INFO:root:current train perplexity8.117988586425781
INFO:root:current mean train loss 2650.039716352983
INFO:root:current train perplexity8.10244369506836
INFO:root:current mean train loss 2645.4930690354568
INFO:root:current train perplexity8.071076393127441
INFO:root:current mean train loss 2644.8992731119793
INFO:root:current train perplexity8.054398536682129
INFO:root:current mean train loss 2637.96083984375
INFO:root:current train perplexity8.025293350219727
INFO:root:current mean train loss 2636.432679636102
INFO:root:current train perplexity8.004120826721191
INFO:root:current mean train loss 2632.630534551711
INFO:root:current train perplexity7.976629257202148
INFO:root:current mean train loss 2629.8565729025136
INFO:root:current train perplexity7.96250581741333
INFO:root:current mean train loss 2624.8728880859376
INFO:root:current train perplexity7.948604583740234
INFO:root:current mean train loss 2624.4508297164352
INFO:root:current train perplexity7.924002647399902
INFO:root:current mean train loss 2621.1838094356144
INFO:root:current train perplexity7.904049396514893
INFO:root:current mean train loss 2616.940730059224
INFO:root:current train perplexity7.881168842315674
INFO:root:current mean train loss 2613.182844830137
INFO:root:current train perplexity7.859889984130859
INFO:root:current mean train loss 2609.3671172572544
INFO:root:current train perplexity7.837697982788086
INFO:root:current mean train loss 2605.633839408256
INFO:root:current train perplexity7.816614627838135
INFO:root:current mean train loss 2602.8630274063503
INFO:root:current train perplexity7.7971062660217285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:05<00:00, 785.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:05<00:00, 785.87s/it]
INFO:root:final mean train loss: 2601.3410059418634
INFO:root:final train perplexity: 7.7910261154174805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.25s/it]
INFO:root:eval mean loss: 2330.66904573914
INFO:root:eval perplexity: 6.593021392822266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.10s/it]
INFO:root:eval mean loss: 2669.3128592849625
INFO:root:eval perplexity: 8.975678443908691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/4
  2%|â–         | 4/200 [1:00:21<49:20:54, 906.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2473.8359119927704
INFO:root:current train perplexity7.295306205749512
INFO:root:current mean train loss 2500.5884388449663
INFO:root:current train perplexity7.270674228668213
INFO:root:current mean train loss 2500.106037497074
INFO:root:current train perplexity7.266406059265137
INFO:root:current mean train loss 2503.8787678814715
INFO:root:current train perplexity7.25139856338501
INFO:root:current mean train loss 2504.8554556803733
INFO:root:current train perplexity7.244920253753662
INFO:root:current mean train loss 2500.7990658068784
INFO:root:current train perplexity7.2070536613464355
INFO:root:current mean train loss 2499.9672599003234
INFO:root:current train perplexity7.196902275085449
INFO:root:current mean train loss 2494.140503725452
INFO:root:current train perplexity7.16548490524292
INFO:root:current mean train loss 2492.7656030357916
INFO:root:current train perplexity7.151605606079102
INFO:root:current mean train loss 2491.399437163707
INFO:root:current train perplexity7.1389336585998535
INFO:root:current mean train loss 2488.3969074453053
INFO:root:current train perplexity7.1191864013671875
INFO:root:current mean train loss 2484.449035278425
INFO:root:current train perplexity7.106287479400635
INFO:root:current mean train loss 2485.5598132969735
INFO:root:current train perplexity7.103077411651611
INFO:root:current mean train loss 2481.861047550807
INFO:root:current train perplexity7.085155963897705
INFO:root:current mean train loss 2479.006612599587
INFO:root:current train perplexity7.0675883293151855
INFO:root:current mean train loss 2475.971384054548
INFO:root:current train perplexity7.052931785583496
INFO:root:current mean train loss 2474.8688130782048
INFO:root:current train perplexity7.038454532623291
INFO:root:current mean train loss 2472.5795246981334
INFO:root:current train perplexity7.029307842254639
INFO:root:current mean train loss 2470.1836089842704
INFO:root:current train perplexity7.018402099609375
INFO:root:current mean train loss 2467.09680337135
INFO:root:current train perplexity7.003787517547607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:04<00:00, 784.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:04<00:00, 784.21s/it]
INFO:root:final mean train loss: 2466.2533637357974
INFO:root:final train perplexity: 7.003161430358887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.27s/it]
INFO:root:eval mean loss: 2241.2731617596132
INFO:root:eval perplexity: 6.132920742034912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it]
INFO:root:eval mean loss: 2591.6219001932345
INFO:root:eval perplexity: 8.420310974121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/5
  2%|â–Ž         | 5/200 [1:15:31<49:09:41, 907.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2374.7817804245724
INFO:root:current train perplexity6.4900803565979
INFO:root:current mean train loss 2382.8519068178925
INFO:root:current train perplexity6.560606956481934
INFO:root:current mean train loss 2384.675987566021
INFO:root:current train perplexity6.558786392211914
INFO:root:current mean train loss 2383.549273173014
INFO:root:current train perplexity6.562949180603027
INFO:root:current mean train loss 2388.407253044696
INFO:root:current train perplexity6.5832953453063965
INFO:root:current mean train loss 2394.9493909861944
INFO:root:current train perplexity6.600754261016846
INFO:root:current mean train loss 2393.425425390054
INFO:root:current train perplexity6.592158317565918
INFO:root:current mean train loss 2391.084399943449
INFO:root:current train perplexity6.57373571395874
INFO:root:current mean train loss 2389.9334193441123
INFO:root:current train perplexity6.569839954376221
INFO:root:current mean train loss 2388.0781299622076
INFO:root:current train perplexity6.560760974884033
INFO:root:current mean train loss 2384.5340017621365
INFO:root:current train perplexity6.546452522277832
INFO:root:current mean train loss 2380.7721197798446
INFO:root:current train perplexity6.533084869384766
INFO:root:current mean train loss 2377.8433914897596
INFO:root:current train perplexity6.517593860626221
INFO:root:current mean train loss 2374.500073030505
INFO:root:current train perplexity6.507506847381592
INFO:root:current mean train loss 2371.6574030051015
INFO:root:current train perplexity6.492332935333252
INFO:root:current mean train loss 2369.1190640227965
INFO:root:current train perplexity6.482120037078857
INFO:root:current mean train loss 2368.0863014638
INFO:root:current train perplexity6.480041027069092
INFO:root:current mean train loss 2368.0896640657843
INFO:root:current train perplexity6.476663112640381
INFO:root:current mean train loss 2366.088303098253
INFO:root:current train perplexity6.467525005340576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.42s/it]
INFO:root:final mean train loss: 2364.227342629637
INFO:root:final train perplexity: 6.4613800048828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.39s/it]
INFO:root:eval mean loss: 2166.302103245512
INFO:root:eval perplexity: 5.77191162109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.34s/it]
INFO:root:eval mean loss: 2528.506511715287
INFO:root:eval perplexity: 7.994529724121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/6
  3%|â–Ž         | 6/200 [1:30:33<48:49:18, 905.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2175.636474609375
INFO:root:current train perplexity5.984511375427246
INFO:root:current mean train loss 2330.24850735806
INFO:root:current train perplexity6.272305965423584
INFO:root:current mean train loss 2324.854065245064
INFO:root:current train perplexity6.267394065856934
INFO:root:current mean train loss 2323.018887643402
INFO:root:current train perplexity6.240976810455322
INFO:root:current mean train loss 2316.6571522853023
INFO:root:current train perplexity6.2164788246154785
INFO:root:current mean train loss 2315.1856248440617
INFO:root:current train perplexity6.202581405639648
INFO:root:current mean train loss 2309.9559364763154
INFO:root:current train perplexity6.183886528015137
INFO:root:current mean train loss 2310.075399575662
INFO:root:current train perplexity6.181542873382568
INFO:root:current mean train loss 2308.7304180016677
INFO:root:current train perplexity6.173950672149658
INFO:root:current mean train loss 2305.820280796944
INFO:root:current train perplexity6.158777236938477
INFO:root:current mean train loss 2304.198108166248
INFO:root:current train perplexity6.151658058166504
INFO:root:current mean train loss 2302.440723609751
INFO:root:current train perplexity6.145309925079346
INFO:root:current mean train loss 2302.800292257266
INFO:root:current train perplexity6.143355846405029
INFO:root:current mean train loss 2300.0459235834214
INFO:root:current train perplexity6.129766941070557
INFO:root:current mean train loss 2298.863888551983
INFO:root:current train perplexity6.127353191375732
INFO:root:current mean train loss 2297.7349790081353
INFO:root:current train perplexity6.124404430389404
INFO:root:current mean train loss 2295.281161020578
INFO:root:current train perplexity6.110654830932617
INFO:root:current mean train loss 2293.2661925085426
INFO:root:current train perplexity6.102014064788818
INFO:root:current mean train loss 2292.3202460763987
INFO:root:current train perplexity6.09700870513916
INFO:root:current mean train loss 2289.633375526039
INFO:root:current train perplexity6.089352130889893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:04<00:00, 784.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [13:04<00:00, 784.74s/it]
INFO:root:final mean train loss: 2287.4258100593324
INFO:root:final train perplexity: 6.081377983093262
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.59s/it]
INFO:root:eval mean loss: 2116.20514219027
INFO:root:eval perplexity: 5.542603015899658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.13s/it]
INFO:root:eval mean loss: 2478.99258790794
INFO:root:eval perplexity: 7.675633907318115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/7
  4%|â–Ž         | 7/200 [1:45:41<48:36:20, 906.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2270.771240234375
INFO:root:current train perplexity5.830023765563965
INFO:root:current mean train loss 2272.079875364142
INFO:root:current train perplexity5.936874866485596
INFO:root:current mean train loss 2263.8332681918364
INFO:root:current train perplexity5.924114227294922
INFO:root:current mean train loss 2258.3225650427476
INFO:root:current train perplexity5.8979172706604
INFO:root:current mean train loss 2250.8620695999366
INFO:root:current train perplexity5.878360748291016
INFO:root:current mean train loss 2247.7394446884805
INFO:root:current train perplexity5.87249755859375
INFO:root:current mean train loss 2245.612823190041
INFO:root:current train perplexity5.8687920570373535
INFO:root:current mean train loss 2240.138385910842
INFO:root:current train perplexity5.852930068969727
INFO:root:current mean train loss 2242.2277993199878
INFO:root:current train perplexity5.850448131561279
INFO:root:current mean train loss 2238.0629291077325
INFO:root:current train perplexity5.833112716674805
INFO:root:current mean train loss 2236.8957646637864
INFO:root:current train perplexity5.831709384918213
INFO:root:current mean train loss 2233.542653965822
INFO:root:current train perplexity5.819044589996338
INFO:root:current mean train loss 2231.947725944331
INFO:root:current train perplexity5.811088562011719
INFO:root:current mean train loss 2231.2247268144206
INFO:root:current train perplexity5.810663223266602
INFO:root:current mean train loss 2229.826193999168
INFO:root:current train perplexity5.804491996765137
INFO:root:current mean train loss 2229.4162473012652
INFO:root:current train perplexity5.806016445159912
INFO:root:current mean train loss 2227.7549943959316
INFO:root:current train perplexity5.800713539123535
INFO:root:current mean train loss 2226.155158969937
INFO:root:current train perplexity5.795556545257568
INFO:root:current mean train loss 2227.3602950260847
INFO:root:current train perplexity5.7971978187561035
INFO:root:current mean train loss 2226.5389833261374
INFO:root:current train perplexity5.791930675506592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:55<00:00, 775.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:55<00:00, 775.22s/it]
INFO:root:final mean train loss: 2224.945610288773
INFO:root:final train perplexity: 5.788783550262451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.48s/it]
INFO:root:eval mean loss: 2068.6715105205562
INFO:root:eval perplexity: 5.3334574699401855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.12s/it]
INFO:root:eval mean loss: 2441.731500287428
INFO:root:eval perplexity: 7.4440693855285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/8
  4%|â–         | 8/200 [2:00:36<48:08:40, 902.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2189.20126953125
INFO:root:current train perplexity5.606115818023682
INFO:root:current mean train loss 2201.38683629919
INFO:root:current train perplexity5.638696193695068
INFO:root:current mean train loss 2193.1421334773936
INFO:root:current train perplexity5.632653713226318
INFO:root:current mean train loss 2197.769174877565
INFO:root:current train perplexity5.640964508056641
INFO:root:current mean train loss 2197.401425837374
INFO:root:current train perplexity5.632362365722656
INFO:root:current mean train loss 2193.0860689252336
INFO:root:current train perplexity5.629464626312256
INFO:root:current mean train loss 2192.59737616111
INFO:root:current train perplexity5.631385803222656
INFO:root:current mean train loss 2192.6736138791453
INFO:root:current train perplexity5.635269641876221
INFO:root:current mean train loss 2185.3763116345435
INFO:root:current train perplexity5.615936279296875
INFO:root:current mean train loss 2186.106119965742
INFO:root:current train perplexity5.617124080657959
INFO:root:current mean train loss 2186.6110223005358
INFO:root:current train perplexity5.613100528717041
INFO:root:current mean train loss 2185.135142591031
INFO:root:current train perplexity5.604873180389404
INFO:root:current mean train loss 2185.0200263513725
INFO:root:current train perplexity5.6015191078186035
INFO:root:current mean train loss 2180.7867766305303
INFO:root:current train perplexity5.591150760650635
INFO:root:current mean train loss 2180.2784813432327
INFO:root:current train perplexity5.588134765625
INFO:root:current mean train loss 2179.774311714297
INFO:root:current train perplexity5.581892490386963
INFO:root:current mean train loss 2177.9269446136755
INFO:root:current train perplexity5.574483871459961
INFO:root:current mean train loss 2176.338454892381
INFO:root:current train perplexity5.568638324737549
INFO:root:current mean train loss 2174.997919283251
INFO:root:current train perplexity5.563328266143799
INFO:root:current mean train loss 2174.2049573163963
INFO:root:current train perplexity5.556880950927734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.09s/it]
INFO:root:final mean train loss: 2172.7636947439464
INFO:root:final train perplexity: 5.555233001708984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.55s/it]
INFO:root:eval mean loss: 2032.4466777828568
INFO:root:eval perplexity: 5.179382801055908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.77s/it]
INFO:root:eval mean loss: 2410.2040682312445
INFO:root:eval perplexity: 7.253601551055908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/9
  4%|â–         | 9/200 [2:15:27<47:41:52, 899.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2150.2984947791465
INFO:root:current train perplexity5.4163031578063965
INFO:root:current mean train loss 2152.2563155324838
INFO:root:current train perplexity5.4137959480285645
INFO:root:current mean train loss 2142.5745728507873
INFO:root:current train perplexity5.403264045715332
INFO:root:current mean train loss 2139.137010054155
INFO:root:current train perplexity5.406606197357178
INFO:root:current mean train loss 2139.0926338128284
INFO:root:current train perplexity5.392704486846924
INFO:root:current mean train loss 2137.3447407155795
INFO:root:current train perplexity5.386559963226318
INFO:root:current mean train loss 2135.219706716713
INFO:root:current train perplexity5.386877536773682
INFO:root:current mean train loss 2134.8743328337973
INFO:root:current train perplexity5.38918924331665
INFO:root:current mean train loss 2134.778741397768
INFO:root:current train perplexity5.384896755218506
INFO:root:current mean train loss 2133.432236487124
INFO:root:current train perplexity5.381616115570068
INFO:root:current mean train loss 2133.6616655356984
INFO:root:current train perplexity5.3803935050964355
INFO:root:current mean train loss 2131.486027929518
INFO:root:current train perplexity5.371035575866699
INFO:root:current mean train loss 2133.740462623084
INFO:root:current train perplexity5.3747663497924805
INFO:root:current mean train loss 2133.456226145727
INFO:root:current train perplexity5.375479698181152
INFO:root:current mean train loss 2131.026009299538
INFO:root:current train perplexity5.373331546783447
INFO:root:current mean train loss 2131.952465568621
INFO:root:current train perplexity5.374602317810059
INFO:root:current mean train loss 2130.6420247445094
INFO:root:current train perplexity5.371152877807617
INFO:root:current mean train loss 2129.2058850292747
INFO:root:current train perplexity5.364636421203613
INFO:root:current mean train loss 2129.1373700333465
INFO:root:current train perplexity5.364560127258301
INFO:root:current mean train loss 2129.3599184380205
INFO:root:current train perplexity5.363808631896973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.80s/it]
INFO:root:final mean train loss: 2128.285397743614
INFO:root:final train perplexity: 5.363614082336426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.07s/it]
INFO:root:eval mean loss: 2004.5354557984265
INFO:root:eval perplexity: 5.063709735870361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.13s/it]
INFO:root:eval mean loss: 2385.2859942929963
INFO:root:eval perplexity: 7.1065144538879395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/10
  5%|â–Œ         | 10/200 [2:30:16<47:17:35, 896.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2070.1005187103715
INFO:root:current train perplexity5.255290985107422
INFO:root:current mean train loss 2083.2518592247598
INFO:root:current train perplexity5.217410087585449
INFO:root:current mean train loss 2089.5346566239255
INFO:root:current train perplexity5.225933074951172
INFO:root:current mean train loss 2087.0192110221883
INFO:root:current train perplexity5.217706680297852
INFO:root:current mean train loss 2088.182908958972
INFO:root:current train perplexity5.220118045806885
INFO:root:current mean train loss 2085.751855726192
INFO:root:current train perplexity5.2061614990234375
INFO:root:current mean train loss 2084.528571934265
INFO:root:current train perplexity5.191705703735352
INFO:root:current mean train loss 2084.6335873051953
INFO:root:current train perplexity5.176962375640869
INFO:root:current mean train loss 2085.7359013705586
INFO:root:current train perplexity5.189273357391357
INFO:root:current mean train loss 2089.8179685988293
INFO:root:current train perplexity5.199230194091797
INFO:root:current mean train loss 2088.981627447344
INFO:root:current train perplexity5.195138454437256
INFO:root:current mean train loss 2088.6598084174843
INFO:root:current train perplexity5.194454193115234
INFO:root:current mean train loss 2085.969527729296
INFO:root:current train perplexity5.1922783851623535
INFO:root:current mean train loss 2085.4942696503776
INFO:root:current train perplexity5.193706512451172
INFO:root:current mean train loss 2085.5478424217686
INFO:root:current train perplexity5.19687032699585
INFO:root:current mean train loss 2086.9705062875937
INFO:root:current train perplexity5.199953079223633
INFO:root:current mean train loss 2086.938054765321
INFO:root:current train perplexity5.197903156280518
INFO:root:current mean train loss 2088.5056498750178
INFO:root:current train perplexity5.200110912322998
INFO:root:current mean train loss 2088.085121150703
INFO:root:current train perplexity5.1954755783081055
INFO:root:current mean train loss 2089.7606085239177
INFO:root:current train perplexity5.201391696929932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.75s/it]
INFO:root:final mean train loss: 2089.3853542772254
INFO:root:final train perplexity: 5.2014546394348145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it]
INFO:root:eval mean loss: 1977.5973887342088
INFO:root:eval perplexity: 4.95452356338501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.75s/it]
INFO:root:eval mean loss: 2361.9068525598404
INFO:root:eval perplexity: 6.971228122711182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/11
  6%|â–Œ         | 11/200 [2:45:01<46:51:58, 892.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2060.9938751930413
INFO:root:current train perplexity5.066131114959717
INFO:root:current mean train loss 2072.01609359249
INFO:root:current train perplexity5.093155860900879
INFO:root:current mean train loss 2073.8763922844732
INFO:root:current train perplexity5.106611728668213
INFO:root:current mean train loss 2067.6068333442963
INFO:root:current train perplexity5.105907917022705
INFO:root:current mean train loss 2070.347921238024
INFO:root:current train perplexity5.097360134124756
INFO:root:current mean train loss 2067.8501355688727
INFO:root:current train perplexity5.0922346115112305
INFO:root:current mean train loss 2067.2801207606367
INFO:root:current train perplexity5.094801425933838
INFO:root:current mean train loss 2065.2553022933066
INFO:root:current train perplexity5.094419956207275
INFO:root:current mean train loss 2063.6159421348143
INFO:root:current train perplexity5.094597339630127
INFO:root:current mean train loss 2061.198502174981
INFO:root:current train perplexity5.090113162994385
INFO:root:current mean train loss 2059.9054207986233
INFO:root:current train perplexity5.082388401031494
INFO:root:current mean train loss 2058.0419440181017
INFO:root:current train perplexity5.077019691467285
INFO:root:current mean train loss 2058.780209080057
INFO:root:current train perplexity5.073193073272705
INFO:root:current mean train loss 2057.255901562359
INFO:root:current train perplexity5.072632312774658
INFO:root:current mean train loss 2055.7857707910553
INFO:root:current train perplexity5.065784931182861
INFO:root:current mean train loss 2055.238671012965
INFO:root:current train perplexity5.063676834106445
INFO:root:current mean train loss 2054.309119318445
INFO:root:current train perplexity5.062655925750732
INFO:root:current mean train loss 2054.497619082119
INFO:root:current train perplexity5.060547828674316
INFO:root:current mean train loss 2054.941924175048
INFO:root:current train perplexity5.0618062019348145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.07s/it]
INFO:root:final mean train loss: 2055.5874493743695
INFO:root:final train perplexity: 5.064548969268799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.33s/it]
INFO:root:eval mean loss: 1950.744313341506
INFO:root:eval perplexity: 4.848022937774658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.37s/it]
INFO:root:eval mean loss: 2336.2822282939937
INFO:root:eval perplexity: 6.825901985168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/12
  6%|â–Œ         | 12/200 [2:59:51<46:34:50, 891.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1926.882568359375
INFO:root:current train perplexity4.966022491455078
INFO:root:current mean train loss 2022.2674287962682
INFO:root:current train perplexity4.932882308959961
INFO:root:current mean train loss 2033.340602630465
INFO:root:current train perplexity4.9434404373168945
INFO:root:current mean train loss 2031.4070295579363
INFO:root:current train perplexity4.943857669830322
INFO:root:current mean train loss 2034.7398442346464
INFO:root:current train perplexity4.956160068511963
INFO:root:current mean train loss 2034.3396988673428
INFO:root:current train perplexity4.956449031829834
INFO:root:current mean train loss 2031.7779619966573
INFO:root:current train perplexity4.9539570808410645
INFO:root:current mean train loss 2031.576245325558
INFO:root:current train perplexity4.952915191650391
INFO:root:current mean train loss 2027.6432581007257
INFO:root:current train perplexity4.95044469833374
INFO:root:current mean train loss 2026.2467980537963
INFO:root:current train perplexity4.945685386657715
INFO:root:current mean train loss 2026.9461612720434
INFO:root:current train perplexity4.9474005699157715
INFO:root:current mean train loss 2028.569179891135
INFO:root:current train perplexity4.953423500061035
INFO:root:current mean train loss 2027.6703077714244
INFO:root:current train perplexity4.951798439025879
INFO:root:current mean train loss 2026.2159613069898
INFO:root:current train perplexity4.948276519775391
INFO:root:current mean train loss 2023.8507770910828
INFO:root:current train perplexity4.9403910636901855
INFO:root:current mean train loss 2024.9047952272538
INFO:root:current train perplexity4.941501617431641
INFO:root:current mean train loss 2024.8217398012273
INFO:root:current train perplexity4.943000793457031
INFO:root:current mean train loss 2022.9024934169481
INFO:root:current train perplexity4.937480926513672
INFO:root:current mean train loss 2023.0382501874046
INFO:root:current train perplexity4.935220241546631
INFO:root:current mean train loss 2023.1491765289386
INFO:root:current train perplexity4.935296535491943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.27s/it]
INFO:root:final mean train loss: 2022.4368970970042
INFO:root:final train perplexity: 4.933766841888428
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it]
INFO:root:eval mean loss: 1934.0415476264684
INFO:root:eval perplexity: 4.782937049865723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.91s/it]
INFO:root:eval mean loss: 2321.413288522274
INFO:root:eval perplexity: 6.742969036102295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/13
  6%|â–‹         | 13/200 [3:14:44<46:20:22, 892.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2025.3725219726562
INFO:root:current train perplexity4.803411483764648
INFO:root:current mean train loss 2011.0546905517579
INFO:root:current train perplexity4.844902038574219
INFO:root:current mean train loss 1999.3510686700995
INFO:root:current train perplexity4.821239948272705
INFO:root:current mean train loss 2007.9223621368408
INFO:root:current train perplexity4.844114780426025
INFO:root:current mean train loss 2001.8175589425223
INFO:root:current train perplexity4.834479331970215
INFO:root:current mean train loss 1999.6505396916316
INFO:root:current train perplexity4.825839519500732
INFO:root:current mean train loss 1994.9576032084804
INFO:root:current train perplexity4.813494682312012
INFO:root:current mean train loss 1995.7980066935222
INFO:root:current train perplexity4.817131996154785
INFO:root:current mean train loss 1996.1645352991616
INFO:root:current train perplexity4.825775146484375
INFO:root:current mean train loss 1995.0800231933595
INFO:root:current train perplexity4.824223518371582
INFO:root:current mean train loss 1996.1060522939645
INFO:root:current train perplexity4.826392650604248
INFO:root:current mean train loss 1998.6333944048201
INFO:root:current train perplexity4.83413028717041
INFO:root:current mean train loss 2000.6436366347016
INFO:root:current train perplexity4.841245174407959
INFO:root:current mean train loss 2000.2765485358962
INFO:root:current train perplexity4.841102600097656
INFO:root:current mean train loss 1999.5804045341383
INFO:root:current train perplexity4.838547706604004
INFO:root:current mean train loss 1998.0563613891602
INFO:root:current train perplexity4.834141731262207
INFO:root:current mean train loss 1998.0422418288242
INFO:root:current train perplexity4.833149433135986
INFO:root:current mean train loss 1997.1376625238463
INFO:root:current train perplexity4.832406997680664
INFO:root:current mean train loss 1996.426984648652
INFO:root:current train perplexity4.83068323135376
INFO:root:current mean train loss 1995.2895420074462
INFO:root:current train perplexity4.827531814575195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.10s/it]
INFO:root:final mean train loss: 1994.946541451951
INFO:root:final train perplexity: 4.827878952026367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.67s/it]
INFO:root:eval mean loss: 1918.1374576649766
INFO:root:eval perplexity: 4.721776485443115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.96s/it]
INFO:root:eval mean loss: 2312.265705081588
INFO:root:eval perplexity: 6.692450046539307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/14
  7%|â–‹         | 14/200 [3:29:35<46:04:39, 891.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.1409978093327
INFO:root:current train perplexity4.641937732696533
INFO:root:current mean train loss 1972.3891129319686
INFO:root:current train perplexity4.721453666687012
INFO:root:current mean train loss 1968.6549108320148
INFO:root:current train perplexity4.733683109283447
INFO:root:current mean train loss 1962.9508487690096
INFO:root:current train perplexity4.719777584075928
INFO:root:current mean train loss 1963.1818881176703
INFO:root:current train perplexity4.724715232849121
INFO:root:current mean train loss 1964.2221059106582
INFO:root:current train perplexity4.726299285888672
INFO:root:current mean train loss 1966.695463315284
INFO:root:current train perplexity4.725717544555664
INFO:root:current mean train loss 1969.8528905322464
INFO:root:current train perplexity4.7349958419799805
INFO:root:current mean train loss 1969.85580447982
INFO:root:current train perplexity4.730063438415527
INFO:root:current mean train loss 1972.3151490690868
INFO:root:current train perplexity4.734222888946533
INFO:root:current mean train loss 1972.4776895020943
INFO:root:current train perplexity4.734907150268555
INFO:root:current mean train loss 1972.0113573703413
INFO:root:current train perplexity4.731594085693359
INFO:root:current mean train loss 1971.9067447942982
INFO:root:current train perplexity4.733907222747803
INFO:root:current mean train loss 1972.1759376497348
INFO:root:current train perplexity4.735093593597412
INFO:root:current mean train loss 1971.5512947608136
INFO:root:current train perplexity4.73459529876709
INFO:root:current mean train loss 1971.2887255954681
INFO:root:current train perplexity4.732559680938721
INFO:root:current mean train loss 1971.6360648498348
INFO:root:current train perplexity4.732482433319092
INFO:root:current mean train loss 1971.4803045840529
INFO:root:current train perplexity4.734053611755371
INFO:root:current mean train loss 1971.9479216947852
INFO:root:current train perplexity4.735089302062988
INFO:root:current mean train loss 1970.3448752273773
INFO:root:current train perplexity4.73142671585083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.78s/it]
INFO:root:final mean train loss: 1968.8642467012082
INFO:root:final train perplexity: 4.729517936706543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.19s/it]
INFO:root:eval mean loss: 1897.6667047595301
INFO:root:eval perplexity: 4.644203186035156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.90s/it]
INFO:root:eval mean loss: 2290.577819391345
INFO:root:eval perplexity: 6.5741777420043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/15
  8%|â–Š         | 15/200 [3:44:30<45:53:06, 892.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1952.4050903320312
INFO:root:current train perplexity4.6102375984191895
INFO:root:current mean train loss 1940.9172981559457
INFO:root:current train perplexity4.6110029220581055
INFO:root:current mean train loss 1952.8417877437562
INFO:root:current train perplexity4.666444301605225
INFO:root:current mean train loss 1951.7818020750574
INFO:root:current train perplexity4.677881717681885
INFO:root:current mean train loss 1954.0266608015556
INFO:root:current train perplexity4.674631118774414
INFO:root:current mean train loss 1954.1568621143108
INFO:root:current train perplexity4.671908378601074
INFO:root:current mean train loss 1948.5499627816203
INFO:root:current train perplexity4.665407657623291
INFO:root:current mean train loss 1947.328910200286
INFO:root:current train perplexity4.662763595581055
INFO:root:current mean train loss 1946.8491189496578
INFO:root:current train perplexity4.659130573272705
INFO:root:current mean train loss 1945.9911193207874
INFO:root:current train perplexity4.658050537109375
INFO:root:current mean train loss 1946.984098430829
INFO:root:current train perplexity4.661107063293457
INFO:root:current mean train loss 1948.0097817035853
INFO:root:current train perplexity4.662014484405518
INFO:root:current mean train loss 1948.2690886234363
INFO:root:current train perplexity4.660115718841553
INFO:root:current mean train loss 1947.9812411106848
INFO:root:current train perplexity4.657487392425537
INFO:root:current mean train loss 1948.222619729652
INFO:root:current train perplexity4.657439231872559
INFO:root:current mean train loss 1948.8051481308316
INFO:root:current train perplexity4.655768394470215
INFO:root:current mean train loss 1948.508638135179
INFO:root:current train perplexity4.655360698699951
INFO:root:current mean train loss 1948.137630032025
INFO:root:current train perplexity4.654443740844727
INFO:root:current mean train loss 1948.3299757413236
INFO:root:current train perplexity4.6522064208984375
INFO:root:current mean train loss 1948.4491122352185
INFO:root:current train perplexity4.652125358581543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.26s/it]
INFO:root:final mean train loss: 1947.848932140233
INFO:root:final train perplexity: 4.651724815368652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.33s/it]
INFO:root:eval mean loss: 1884.0408814342309
INFO:root:eval perplexity: 4.593276023864746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.84s/it]
INFO:root:eval mean loss: 2280.695888221687
INFO:root:eval perplexity: 6.5209856033325195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/16
  8%|â–Š         | 16/200 [3:59:28<45:42:56, 894.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1937.9155239051497
INFO:root:current train perplexity4.561662673950195
INFO:root:current mean train loss 1918.278751484832
INFO:root:current train perplexity4.544765949249268
INFO:root:current mean train loss 1929.8386392628574
INFO:root:current train perplexity4.569901466369629
INFO:root:current mean train loss 1935.0738334552939
INFO:root:current train perplexity4.578146457672119
INFO:root:current mean train loss 1931.7395143934116
INFO:root:current train perplexity4.580206394195557
INFO:root:current mean train loss 1933.4199964854013
INFO:root:current train perplexity4.58486270904541
INFO:root:current mean train loss 1937.425293150673
INFO:root:current train perplexity4.595391273498535
INFO:root:current mean train loss 1930.9973233194512
INFO:root:current train perplexity4.592228412628174
INFO:root:current mean train loss 1933.394214792175
INFO:root:current train perplexity4.595774173736572
INFO:root:current mean train loss 1930.4859645541
INFO:root:current train perplexity4.588959217071533
INFO:root:current mean train loss 1929.8010151326155
INFO:root:current train perplexity4.588834762573242
INFO:root:current mean train loss 1929.1712737177093
INFO:root:current train perplexity4.586724758148193
INFO:root:current mean train loss 1928.8231679464682
INFO:root:current train perplexity4.5845723152160645
INFO:root:current mean train loss 1928.3451651608657
INFO:root:current train perplexity4.58536434173584
INFO:root:current mean train loss 1929.375614334822
INFO:root:current train perplexity4.589115619659424
INFO:root:current mean train loss 1929.493654907926
INFO:root:current train perplexity4.589763641357422
INFO:root:current mean train loss 1928.3287893371764
INFO:root:current train perplexity4.585296154022217
INFO:root:current mean train loss 1929.4902037023353
INFO:root:current train perplexity4.587599754333496
INFO:root:current mean train loss 1930.4476260945225
INFO:root:current train perplexity4.5875020027160645
INFO:root:current mean train loss 1930.4980146078094
INFO:root:current train perplexity4.586596488952637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.10s/it]
INFO:root:final mean train loss: 1930.3184927720586
INFO:root:final train perplexity: 4.5878119468688965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.19s/it]
INFO:root:eval mean loss: 1875.6416128172098
INFO:root:eval perplexity: 4.562162399291992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.55s/it]
INFO:root:eval mean loss: 2275.2704692867633
INFO:root:eval perplexity: 6.491963863372803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/17
  8%|â–Š         | 17/200 [4:14:22<45:27:03, 894.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.0752202814276
INFO:root:current train perplexity4.5719475746154785
INFO:root:current mean train loss 1907.3099592492936
INFO:root:current train perplexity4.547287464141846
INFO:root:current mean train loss 1905.441384633382
INFO:root:current train perplexity4.529628276824951
INFO:root:current mean train loss 1908.8724462764778
INFO:root:current train perplexity4.532113552093506
INFO:root:current mean train loss 1904.5044262995486
INFO:root:current train perplexity4.526613712310791
INFO:root:current mean train loss 1907.398851044324
INFO:root:current train perplexity4.52212381362915
INFO:root:current mean train loss 1907.496524012366
INFO:root:current train perplexity4.516478538513184
INFO:root:current mean train loss 1909.7006876214507
INFO:root:current train perplexity4.521179676055908
INFO:root:current mean train loss 1913.3379328272365
INFO:root:current train perplexity4.533575057983398
INFO:root:current mean train loss 1913.077335249557
INFO:root:current train perplexity4.533729076385498
INFO:root:current mean train loss 1912.8916045918183
INFO:root:current train perplexity4.536113262176514
INFO:root:current mean train loss 1914.6687271683304
INFO:root:current train perplexity4.536848545074463
INFO:root:current mean train loss 1915.220832303444
INFO:root:current train perplexity4.53870153427124
INFO:root:current mean train loss 1914.6413085233926
INFO:root:current train perplexity4.536110877990723
INFO:root:current mean train loss 1915.1537434567688
INFO:root:current train perplexity4.537301540374756
INFO:root:current mean train loss 1916.3597520496744
INFO:root:current train perplexity4.539804458618164
INFO:root:current mean train loss 1918.1107394683982
INFO:root:current train perplexity4.5447492599487305
INFO:root:current mean train loss 1918.7960181865649
INFO:root:current train perplexity4.545964241027832
INFO:root:current mean train loss 1919.8123004072804
INFO:root:current train perplexity4.549584865570068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.48s/it]
INFO:root:final mean train loss: 1919.9837459346832
INFO:root:final train perplexity: 4.5505452156066895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.81s/it]
INFO:root:eval mean loss: 1888.10237586921
INFO:root:eval perplexity: 4.608397483825684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.39s/it]
INFO:root:eval mean loss: 2291.448407112284
INFO:root:eval perplexity: 6.578886985778809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/18
  9%|â–‰         | 18/200 [4:29:13<45:09:28, 893.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1968.007958984375
INFO:root:current train perplexity4.625218868255615
INFO:root:current mean train loss 1941.2703973679315
INFO:root:current train perplexity4.582248687744141
INFO:root:current mean train loss 1937.647245974657
INFO:root:current train perplexity4.589437961578369
INFO:root:current mean train loss 1926.7214995837603
INFO:root:current train perplexity4.560572624206543
INFO:root:current mean train loss 1933.2912443938078
INFO:root:current train perplexity4.57047700881958
INFO:root:current mean train loss 1934.368041025294
INFO:root:current train perplexity4.5827789306640625
INFO:root:current mean train loss 1932.6981731824637
INFO:root:current train perplexity4.582911968231201
INFO:root:current mean train loss 1929.9456075465425
INFO:root:current train perplexity4.5841498374938965
INFO:root:current mean train loss 1929.4079494310463
INFO:root:current train perplexity4.581985950469971
INFO:root:current mean train loss 1931.9046715836498
INFO:root:current train perplexity4.5860724449157715
INFO:root:current mean train loss 1932.8966510222326
INFO:root:current train perplexity4.587306499481201
INFO:root:current mean train loss 1935.6575056119202
INFO:root:current train perplexity4.602237701416016
INFO:root:current mean train loss 1936.8961007399182
INFO:root:current train perplexity4.608044147491455
INFO:root:current mean train loss 1937.3888845860272
INFO:root:current train perplexity4.616551876068115
INFO:root:current mean train loss 1938.9411562882285
INFO:root:current train perplexity4.620932579040527
INFO:root:current mean train loss 1942.8693371541476
INFO:root:current train perplexity4.633187770843506
INFO:root:current mean train loss 1945.8271596177717
INFO:root:current train perplexity4.644076347351074
INFO:root:current mean train loss 1948.1980731505453
INFO:root:current train perplexity4.6531243324279785
INFO:root:current mean train loss 1950.2215451058257
INFO:root:current train perplexity4.660416603088379
INFO:root:current mean train loss 1953.4371464126066
INFO:root:current train perplexity4.672135353088379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.08s/it]
INFO:root:final mean train loss: 1954.2427402021183
INFO:root:final train perplexity: 4.675256252288818
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.43s/it]
INFO:root:eval mean loss: 1917.0491432568706
INFO:root:eval perplexity: 4.717618942260742
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.48s/it]
INFO:root:eval mean loss: 2322.9490261213155
INFO:root:eval perplexity: 6.751488208770752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/19
 10%|â–‰         | 19/200 [4:44:04<44:53:04, 892.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2060.21933815696
INFO:root:current train perplexity4.983742713928223
INFO:root:current mean train loss 1976.8544521644467
INFO:root:current train perplexity4.7503461837768555
INFO:root:current mean train loss 1976.0426564259571
INFO:root:current train perplexity4.755025386810303
INFO:root:current mean train loss 1981.9344778120148
INFO:root:current train perplexity4.750049591064453
INFO:root:current mean train loss 1986.0691392365225
INFO:root:current train perplexity4.766534328460693
INFO:root:current mean train loss 1982.1411869443696
INFO:root:current train perplexity4.763986587524414
INFO:root:current mean train loss 1978.599627430416
INFO:root:current train perplexity4.765732288360596
INFO:root:current mean train loss 1975.2324007409431
INFO:root:current train perplexity4.767308235168457
INFO:root:current mean train loss 1976.4660772244715
INFO:root:current train perplexity4.771602630615234
INFO:root:current mean train loss 1978.706244412834
INFO:root:current train perplexity4.776986122131348
INFO:root:current mean train loss 1979.3398689523835
INFO:root:current train perplexity4.7764387130737305
INFO:root:current mean train loss 1978.30234858059
INFO:root:current train perplexity4.772404193878174
INFO:root:current mean train loss 1976.4925686950185
INFO:root:current train perplexity4.766206741333008
INFO:root:current mean train loss 1975.3675856597486
INFO:root:current train perplexity4.76442289352417
INFO:root:current mean train loss 1976.1604209073653
INFO:root:current train perplexity4.763893127441406
INFO:root:current mean train loss 1977.660421885266
INFO:root:current train perplexity4.7680206298828125
INFO:root:current mean train loss 1979.227257367568
INFO:root:current train perplexity4.770991325378418
INFO:root:current mean train loss 1978.9413408906341
INFO:root:current train perplexity4.770585536956787
INFO:root:current mean train loss 1979.9812727927115
INFO:root:current train perplexity4.773303508758545
INFO:root:current mean train loss 1981.207273421749
INFO:root:current train perplexity4.775379657745361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.17s/it]
INFO:root:final mean train loss: 1981.0991823443608
INFO:root:final train perplexity: 4.775406837463379
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.29s/it]
INFO:root:eval mean loss: 1908.1926914512687
INFO:root:eval perplexity: 4.68393087387085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.18s/it]
INFO:root:eval mean loss: 2318.3980777821644
INFO:root:eval perplexity: 6.7262749671936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/20
 10%|â–ˆ         | 20/200 [4:59:03<44:43:02, 894.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1952.1172501001602
INFO:root:current train perplexity4.662808895111084
INFO:root:current mean train loss 1968.8974512772595
INFO:root:current train perplexity4.7195353507995605
INFO:root:current mean train loss 1961.745783211297
INFO:root:current train perplexity4.707287311553955
INFO:root:current mean train loss 1963.5760332405744
INFO:root:current train perplexity4.715880393981934
INFO:root:current mean train loss 1965.242515059973
INFO:root:current train perplexity4.71766471862793
INFO:root:current mean train loss 1965.678907518263
INFO:root:current train perplexity4.718973636627197
INFO:root:current mean train loss 1961.7219232550249
INFO:root:current train perplexity4.7143330574035645
INFO:root:current mean train loss 1962.8145238233678
INFO:root:current train perplexity4.715675354003906
INFO:root:current mean train loss 1966.1165170589989
INFO:root:current train perplexity4.722084045410156
INFO:root:current mean train loss 1965.732023033979
INFO:root:current train perplexity4.721578121185303
INFO:root:current mean train loss 1965.4199465475367
INFO:root:current train perplexity4.723374366760254
INFO:root:current mean train loss 1968.08895271174
INFO:root:current train perplexity4.726624011993408
INFO:root:current mean train loss 1968.5161761390864
INFO:root:current train perplexity4.725155830383301
INFO:root:current mean train loss 1968.8734430793152
INFO:root:current train perplexity4.729303359985352
INFO:root:current mean train loss 1968.5911234099472
INFO:root:current train perplexity4.72682523727417
INFO:root:current mean train loss 1969.6746293155306
INFO:root:current train perplexity4.731022357940674
INFO:root:current mean train loss 1969.1157762807925
INFO:root:current train perplexity4.7279791831970215
INFO:root:current mean train loss 1969.879945286668
INFO:root:current train perplexity4.72989559173584
INFO:root:current mean train loss 1970.0281218403768
INFO:root:current train perplexity4.729201793670654
INFO:root:current mean train loss 1969.626300278615
INFO:root:current train perplexity4.730323314666748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:54<00:00, 774.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:54<00:00, 774.95s/it]
INFO:root:final mean train loss: 1968.8220188065845
INFO:root:final train perplexity: 4.729360580444336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it]
INFO:root:eval mean loss: 1897.0322789401873
INFO:root:eval perplexity: 4.641819953918457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.33s/it]
INFO:root:eval mean loss: 2307.0173984825187
INFO:root:eval perplexity: 6.663634777069092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/21
 10%|â–ˆ         | 21/200 [5:13:57<44:28:15, 894.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1964.3784681047712
INFO:root:current train perplexity4.6280107498168945
INFO:root:current mean train loss 1950.1965042505508
INFO:root:current train perplexity4.629171848297119
INFO:root:current mean train loss 1940.4984006881714
INFO:root:current train perplexity4.634711742401123
INFO:root:current mean train loss 1942.837570704771
INFO:root:current train perplexity4.649348735809326
INFO:root:current mean train loss 1943.8889505486738
INFO:root:current train perplexity4.652248859405518
INFO:root:current mean train loss 1948.2381233928872
INFO:root:current train perplexity4.655204772949219
INFO:root:current mean train loss 1950.9670715332031
INFO:root:current train perplexity4.6591620445251465
INFO:root:current mean train loss 1951.759090040096
INFO:root:current train perplexity4.65998649597168
INFO:root:current mean train loss 1952.357952224874
INFO:root:current train perplexity4.664323806762695
INFO:root:current mean train loss 1954.6044010178314
INFO:root:current train perplexity4.6670355796813965
INFO:root:current mean train loss 1958.0109487591367
INFO:root:current train perplexity4.676971435546875
INFO:root:current mean train loss 1957.0044305398803
INFO:root:current train perplexity4.674036026000977
INFO:root:current mean train loss 1956.5063451293167
INFO:root:current train perplexity4.673989772796631
INFO:root:current mean train loss 1955.7216958015015
INFO:root:current train perplexity4.675079345703125
INFO:root:current mean train loss 1955.5620218633296
INFO:root:current train perplexity4.6770853996276855
INFO:root:current mean train loss 1956.3342314967765
INFO:root:current train perplexity4.67854118347168
INFO:root:current mean train loss 1956.1356449587909
INFO:root:current train perplexity4.677688121795654
INFO:root:current mean train loss 1955.657443591837
INFO:root:current train perplexity4.678591251373291
INFO:root:current mean train loss 1955.3784139567408
INFO:root:current train perplexity4.679031848907471
INFO:root:current mean train loss 1954.4339487898812
INFO:root:current train perplexity4.674833297729492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.74s/it]
INFO:root:final mean train loss: 1954.176920018891
INFO:root:final train perplexity: 4.675013542175293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.91s/it]
INFO:root:eval mean loss: 1890.1335384287734
INFO:root:eval perplexity: 4.615978717803955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.45s/it]
INFO:root:eval mean loss: 2297.6982988939217
INFO:root:eval perplexity: 6.612775802612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/22
 11%|â–ˆ         | 22/200 [5:28:45<44:07:22, 892.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1924.9606314881207
INFO:root:current train perplexity4.588284969329834
INFO:root:current mean train loss 1925.1444458713422
INFO:root:current train perplexity4.589646339416504
INFO:root:current mean train loss 1932.1498719379579
INFO:root:current train perplexity4.601768970489502
INFO:root:current mean train loss 1938.4169349159056
INFO:root:current train perplexity4.617971420288086
INFO:root:current mean train loss 1939.9819844348738
INFO:root:current train perplexity4.622068881988525
INFO:root:current mean train loss 1937.8333972444916
INFO:root:current train perplexity4.624276638031006
INFO:root:current mean train loss 1935.0308389876254
INFO:root:current train perplexity4.618372917175293
INFO:root:current mean train loss 1933.5705419542874
INFO:root:current train perplexity4.6157660484313965
INFO:root:current mean train loss 1935.027370597079
INFO:root:current train perplexity4.611384868621826
INFO:root:current mean train loss 1935.5679768545654
INFO:root:current train perplexity4.614604473114014
INFO:root:current mean train loss 1934.0816104316534
INFO:root:current train perplexity4.613345146179199
INFO:root:current mean train loss 1935.2281905204338
INFO:root:current train perplexity4.613306045532227
INFO:root:current mean train loss 1935.1877179621526
INFO:root:current train perplexity4.612641334533691
INFO:root:current mean train loss 1937.2211745137813
INFO:root:current train perplexity4.615672588348389
INFO:root:current mean train loss 1937.7094673524482
INFO:root:current train perplexity4.61513090133667
INFO:root:current mean train loss 1940.4412192255543
INFO:root:current train perplexity4.622071743011475
INFO:root:current mean train loss 1940.0549320054497
INFO:root:current train perplexity4.6200103759765625
INFO:root:current mean train loss 1939.6314481077932
INFO:root:current train perplexity4.6178483963012695
INFO:root:current mean train loss 1939.5171829117726
INFO:root:current train perplexity4.617510795593262
INFO:root:current mean train loss 1939.1906193821671
INFO:root:current train perplexity4.6185688972473145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.13s/it]
INFO:root:final mean train loss: 1938.9176703764222
INFO:root:final train perplexity: 4.619052886962891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.80s/it]
INFO:root:eval mean loss: 1897.0166656277704
INFO:root:eval perplexity: 4.64176082611084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.48s/it]
INFO:root:eval mean loss: 2306.7965512106603
INFO:root:eval perplexity: 6.6624250411987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/23
 12%|â–ˆâ–        | 23/200 [5:43:35<43:50:16, 891.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1920.5748277452258
INFO:root:current train perplexity4.599190711975098
INFO:root:current mean train loss 1919.2088083367598
INFO:root:current train perplexity4.562403678894043
INFO:root:current mean train loss 1921.8860376818427
INFO:root:current train perplexity4.549904823303223
INFO:root:current mean train loss 1921.1094798552683
INFO:root:current train perplexity4.549825668334961
INFO:root:current mean train loss 1923.384165238361
INFO:root:current train perplexity4.55610990524292
INFO:root:current mean train loss 1920.37550069518
INFO:root:current train perplexity4.550675868988037
INFO:root:current mean train loss 1918.4721271017324
INFO:root:current train perplexity4.545855522155762
INFO:root:current mean train loss 1919.480693112144
INFO:root:current train perplexity4.54874849319458
INFO:root:current mean train loss 1921.3171287965238
INFO:root:current train perplexity4.557097434997559
INFO:root:current mean train loss 1920.7928460631708
INFO:root:current train perplexity4.561553001403809
INFO:root:current mean train loss 1920.4840435063074
INFO:root:current train perplexity4.560759544372559
INFO:root:current mean train loss 1923.1083658170298
INFO:root:current train perplexity4.563695907592773
INFO:root:current mean train loss 1922.5612747547239
INFO:root:current train perplexity4.5640153884887695
INFO:root:current mean train loss 1922.7463912854091
INFO:root:current train perplexity4.563056945800781
INFO:root:current mean train loss 1923.4340360705485
INFO:root:current train perplexity4.563833236694336
INFO:root:current mean train loss 1923.7386759440103
INFO:root:current train perplexity4.563699245452881
INFO:root:current mean train loss 1924.6621937407544
INFO:root:current train perplexity4.5650105476379395
INFO:root:current mean train loss 1925.4701023208363
INFO:root:current train perplexity4.568404674530029
INFO:root:current mean train loss 1926.419436500186
INFO:root:current train perplexity4.57231330871582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.27s/it]
INFO:root:final mean train loss: 1925.8379905650668
INFO:root:final train perplexity: 4.571618556976318
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.05s/it]
INFO:root:eval mean loss: 1877.236099567819
INFO:root:eval perplexity: 4.568052768707275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.49s/it]
INFO:root:eval mean loss: 2293.8356106805463
INFO:root:eval perplexity: 6.591811180114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/24
 12%|â–ˆâ–        | 24/200 [5:58:27<43:36:01, 891.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1956.73828125
INFO:root:current train perplexity4.513941764831543
INFO:root:current mean train loss 1908.6050375109521
INFO:root:current train perplexity4.523777484893799
INFO:root:current mean train loss 1901.942203540157
INFO:root:current train perplexity4.519504070281982
INFO:root:current mean train loss 1901.1613447456484
INFO:root:current train perplexity4.515401363372803
INFO:root:current mean train loss 1907.7908971538122
INFO:root:current train perplexity4.511044025421143
INFO:root:current mean train loss 1904.4787462825136
INFO:root:current train perplexity4.509923458099365
INFO:root:current mean train loss 1908.1844818266063
INFO:root:current train perplexity4.505927562713623
INFO:root:current mean train loss 1911.2154385622016
INFO:root:current train perplexity4.514386177062988
INFO:root:current mean train loss 1911.8125662537755
INFO:root:current train perplexity4.51389217376709
INFO:root:current mean train loss 1914.2147094322802
INFO:root:current train perplexity4.52051305770874
INFO:root:current mean train loss 1915.1279578109484
INFO:root:current train perplexity4.529101848602295
INFO:root:current mean train loss 1917.9521486580425
INFO:root:current train perplexity4.53496789932251
INFO:root:current mean train loss 1916.3355718958744
INFO:root:current train perplexity4.531888961791992
INFO:root:current mean train loss 1915.4095458984375
INFO:root:current train perplexity4.531036853790283
INFO:root:current mean train loss 1914.362415565865
INFO:root:current train perplexity4.531768321990967
INFO:root:current mean train loss 1916.1253992598342
INFO:root:current train perplexity4.533812999725342
INFO:root:current mean train loss 1915.9678952799277
INFO:root:current train perplexity4.535680770874023
INFO:root:current mean train loss 1916.2060251532064
INFO:root:current train perplexity4.536805152893066
INFO:root:current mean train loss 1917.4542122161645
INFO:root:current train perplexity4.5400800704956055
INFO:root:current mean train loss 1918.205361376774
INFO:root:current train perplexity4.5420756340026855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.79s/it]
INFO:root:final mean train loss: 1917.7816702899943
INFO:root:final train perplexity: 4.542643070220947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.35s/it]
INFO:root:eval mean loss: 1883.5751840577902
INFO:root:eval perplexity: 4.591546058654785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.12s/it]
INFO:root:eval mean loss: 2296.311407427416
INFO:root:eval perplexity: 6.6052398681640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/25
 12%|â–ˆâ–Ž        | 25/200 [6:13:20<43:22:01, 892.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1904.0734049479167
INFO:root:current train perplexity4.466342449188232
INFO:root:current mean train loss 1898.443595640121
INFO:root:current train perplexity4.489630222320557
INFO:root:current mean train loss 1897.1249694824219
INFO:root:current train perplexity4.487726211547852
INFO:root:current mean train loss 1898.5026034131463
INFO:root:current train perplexity4.486080646514893
INFO:root:current mean train loss 1905.188667441314
INFO:root:current train perplexity4.487231731414795
INFO:root:current mean train loss 1905.8132249671994
INFO:root:current train perplexity4.501910209655762
INFO:root:current mean train loss 1906.9208804399539
INFO:root:current train perplexity4.505677223205566
INFO:root:current mean train loss 1906.8471268290314
INFO:root:current train perplexity4.502039432525635
INFO:root:current mean train loss 1905.5198799799946
INFO:root:current train perplexity4.4985671043396
INFO:root:current mean train loss 1904.8699967025163
INFO:root:current train perplexity4.5034966468811035
INFO:root:current mean train loss 1906.4529610872269
INFO:root:current train perplexity4.50632381439209
INFO:root:current mean train loss 1909.2750882729092
INFO:root:current train perplexity4.513701438903809
INFO:root:current mean train loss 1908.9625807618784
INFO:root:current train perplexity4.511639595031738
INFO:root:current mean train loss 1908.7702291897776
INFO:root:current train perplexity4.511755466461182
INFO:root:current mean train loss 1909.5098345467213
INFO:root:current train perplexity4.5127716064453125
INFO:root:current mean train loss 1909.8967676838552
INFO:root:current train perplexity4.513898849487305
INFO:root:current mean train loss 1909.9001216042805
INFO:root:current train perplexity4.512164115905762
INFO:root:current mean train loss 1910.539073616612
INFO:root:current train perplexity4.513671398162842
INFO:root:current mean train loss 1910.4434050175182
INFO:root:current train perplexity4.512746334075928
INFO:root:current mean train loss 1910.677499560953
INFO:root:current train perplexity4.514553070068359

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.68s/it]
INFO:root:final mean train loss: 1909.6960664673159
INFO:root:final train perplexity: 4.513748645782471
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it]
INFO:root:eval mean loss: 1884.7732080770722
INFO:root:eval perplexity: 4.595999717712402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it]
INFO:root:eval mean loss: 2298.0094504931294
INFO:root:eval perplexity: 6.614467620849609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/26
 13%|â–ˆâ–Ž        | 26/200 [6:28:04<43:00:10, 889.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1930.2218732136052
INFO:root:current train perplexity4.463351726531982
INFO:root:current mean train loss 1907.424064473903
INFO:root:current train perplexity4.500938892364502
INFO:root:current mean train loss 1904.4470022367739
INFO:root:current train perplexity4.496269702911377
INFO:root:current mean train loss 1901.1538293564424
INFO:root:current train perplexity4.485389709472656
INFO:root:current mean train loss 1892.9958548686402
INFO:root:current train perplexity4.468601226806641
INFO:root:current mean train loss 1892.4527874451248
INFO:root:current train perplexity4.4750590324401855
INFO:root:current mean train loss 1892.6073171344822
INFO:root:current train perplexity4.474745750427246
INFO:root:current mean train loss 1896.6109507119286
INFO:root:current train perplexity4.476070404052734
INFO:root:current mean train loss 1898.3560454269934
INFO:root:current train perplexity4.47719669342041
INFO:root:current mean train loss 1897.9848521249835
INFO:root:current train perplexity4.4771223068237305
INFO:root:current mean train loss 1899.8415915482783
INFO:root:current train perplexity4.483388423919678
INFO:root:current mean train loss 1902.053972195785
INFO:root:current train perplexity4.487673759460449
INFO:root:current mean train loss 1901.4812388454686
INFO:root:current train perplexity4.48758602142334
INFO:root:current mean train loss 1900.4299818888073
INFO:root:current train perplexity4.483610153198242
INFO:root:current mean train loss 1900.4628665667287
INFO:root:current train perplexity4.482655048370361
INFO:root:current mean train loss 1900.5993352911057
INFO:root:current train perplexity4.481847286224365
INFO:root:current mean train loss 1902.544891971121
INFO:root:current train perplexity4.484569072723389
INFO:root:current mean train loss 1903.016357421875
INFO:root:current train perplexity4.485297203063965
INFO:root:current mean train loss 1903.1355541421951
INFO:root:current train perplexity4.485592365264893
INFO:root:current mean train loss 1902.225051180227
INFO:root:current train perplexity4.485177516937256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.35s/it]
INFO:root:final mean train loss: 1901.4192280810228
INFO:root:final train perplexity: 4.484360694885254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.58s/it]
INFO:root:eval mean loss: 1884.0724573879377
INFO:root:eval perplexity: 4.5933942794799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.63s/it]
INFO:root:eval mean loss: 2302.116413522274
INFO:root:eval perplexity: 6.6368408203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/27
 14%|â–ˆâ–Ž        | 27/200 [6:42:47<42:39:38, 887.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1881.6525668440195
INFO:root:current train perplexity4.435520172119141
INFO:root:current mean train loss 1880.415320287777
INFO:root:current train perplexity4.4280242919921875
INFO:root:current mean train loss 1880.787021843962
INFO:root:current train perplexity4.444733619689941
INFO:root:current mean train loss 1883.177335430124
INFO:root:current train perplexity4.438222408294678
INFO:root:current mean train loss 1886.7618733368586
INFO:root:current train perplexity4.447642803192139
INFO:root:current mean train loss 1891.4529749278954
INFO:root:current train perplexity4.4464030265808105
INFO:root:current mean train loss 1891.7438404581828
INFO:root:current train perplexity4.453639507293701
INFO:root:current mean train loss 1890.336653012399
INFO:root:current train perplexity4.4512224197387695
INFO:root:current mean train loss 1893.5193406040573
INFO:root:current train perplexity4.46036434173584
INFO:root:current mean train loss 1893.723954298302
INFO:root:current train perplexity4.457498550415039
INFO:root:current mean train loss 1893.42131887627
INFO:root:current train perplexity4.455373764038086
INFO:root:current mean train loss 1895.1550015727885
INFO:root:current train perplexity4.459848880767822
INFO:root:current mean train loss 1895.5582533504323
INFO:root:current train perplexity4.46103572845459
INFO:root:current mean train loss 1894.949170658971
INFO:root:current train perplexity4.460526943206787
INFO:root:current mean train loss 1894.9080606259108
INFO:root:current train perplexity4.459385395050049
INFO:root:current mean train loss 1895.0632034321345
INFO:root:current train perplexity4.458810329437256
INFO:root:current mean train loss 1894.6607554105567
INFO:root:current train perplexity4.459376335144043
INFO:root:current mean train loss 1895.1456063436567
INFO:root:current train perplexity4.458365440368652
INFO:root:current mean train loss 1895.3102273766524
INFO:root:current train perplexity4.459028720855713
INFO:root:current mean train loss 1894.9412713990878
INFO:root:current train perplexity4.459214687347412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.32s/it]
INFO:root:final mean train loss: 1894.5714811554956
INFO:root:final train perplexity: 4.460191249847412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.60s/it]
INFO:root:eval mean loss: 1907.4593852158134
INFO:root:eval perplexity: 4.68115234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.97s/it]
INFO:root:eval mean loss: 2326.773895912982
INFO:root:eval perplexity: 6.77275276184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/28
 14%|â–ˆâ–        | 28/200 [6:57:30<42:21:09, 886.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1892.8221891276041
INFO:root:current train perplexity4.463739395141602
INFO:root:current mean train loss 1901.2056236049107
INFO:root:current train perplexity4.456916332244873
INFO:root:current mean train loss 1892.2335422585227
INFO:root:current train perplexity4.42631196975708
INFO:root:current mean train loss 1892.487916015625
INFO:root:current train perplexity4.429535388946533
INFO:root:current mean train loss 1891.6681514699835
INFO:root:current train perplexity4.418231010437012
INFO:root:current mean train loss 1888.3914270550272
INFO:root:current train perplexity4.414915084838867
INFO:root:current mean train loss 1887.5199466507522
INFO:root:current train perplexity4.423686504364014
INFO:root:current mean train loss 1888.4462807144657
INFO:root:current train perplexity4.428255081176758
INFO:root:current mean train loss 1886.270425920759
INFO:root:current train perplexity4.427018642425537
INFO:root:current mean train loss 1887.260337540064
INFO:root:current train perplexity4.42820405960083
INFO:root:current mean train loss 1888.4931490734011
INFO:root:current train perplexity4.434978008270264
INFO:root:current mean train loss 1888.8838935754654
INFO:root:current train perplexity4.435325622558594
INFO:root:current mean train loss 1889.2272811351104
INFO:root:current train perplexity4.437503814697266
INFO:root:current mean train loss 1890.1697699751421
INFO:root:current train perplexity4.439679145812988
INFO:root:current mean train loss 1889.1770324086335
INFO:root:current train perplexity4.4378252029418945
INFO:root:current mean train loss 1888.4174231150794
INFO:root:current train perplexity4.438228607177734
INFO:root:current mean train loss 1889.1962244198928
INFO:root:current train perplexity4.439266681671143
INFO:root:current mean train loss 1888.8800230386223
INFO:root:current train perplexity4.438417434692383
INFO:root:current mean train loss 1888.479208203125
INFO:root:current train perplexity4.438695907592773
INFO:root:current mean train loss 1888.6490534142604
INFO:root:current train perplexity4.438207149505615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.96s/it]
INFO:root:final mean train loss: 1888.360495547604
INFO:root:final train perplexity: 4.438382148742676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.70s/it]
INFO:root:eval mean loss: 1878.105347978308
INFO:root:eval perplexity: 4.571267127990723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.14s/it]
INFO:root:eval mean loss: 2297.602782337378
INFO:root:eval perplexity: 6.6122589111328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/29
 14%|â–ˆâ–        | 29/200 [7:12:19<42:07:58, 887.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.4767509128737
INFO:root:current train perplexity4.354123592376709
INFO:root:current mean train loss 1860.9111773173015
INFO:root:current train perplexity4.3625335693359375
INFO:root:current mean train loss 1870.8511645173373
INFO:root:current train perplexity4.371524810791016
INFO:root:current mean train loss 1870.2514863306162
INFO:root:current train perplexity4.372827529907227
INFO:root:current mean train loss 1872.297401986471
INFO:root:current train perplexity4.383873462677002
INFO:root:current mean train loss 1869.8211276080158
INFO:root:current train perplexity4.382410049438477
INFO:root:current mean train loss 1873.0852475910517
INFO:root:current train perplexity4.390748977661133
INFO:root:current mean train loss 1873.869647401752
INFO:root:current train perplexity4.39235258102417
INFO:root:current mean train loss 1876.3755564326127
INFO:root:current train perplexity4.400414943695068
INFO:root:current mean train loss 1874.38457082933
INFO:root:current train perplexity4.3942975997924805
INFO:root:current mean train loss 1874.9420719356328
INFO:root:current train perplexity4.395236968994141
INFO:root:current mean train loss 1874.7682114159502
INFO:root:current train perplexity4.399651050567627
INFO:root:current mean train loss 1877.7227907918925
INFO:root:current train perplexity4.403817653656006
INFO:root:current mean train loss 1879.7826289034438
INFO:root:current train perplexity4.408539295196533
INFO:root:current mean train loss 1881.70248363996
INFO:root:current train perplexity4.409115314483643
INFO:root:current mean train loss 1881.5162170256801
INFO:root:current train perplexity4.4086432456970215
INFO:root:current mean train loss 1881.2706438069085
INFO:root:current train perplexity4.407993316650391
INFO:root:current mean train loss 1880.6601363590785
INFO:root:current train perplexity4.409068584442139
INFO:root:current mean train loss 1881.7005338447038
INFO:root:current train perplexity4.410428524017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:52<00:00, 772.22s/it]
INFO:root:final mean train loss: 1880.783191059553
INFO:root:final train perplexity: 4.411919593811035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.16s/it]
INFO:root:eval mean loss: 1872.22365791916
INFO:root:eval perplexity: 4.549562454223633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.99s/it]
INFO:root:eval mean loss: 2294.4382562299147
INFO:root:eval perplexity: 6.5950775146484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/30
 15%|â–ˆâ–Œ        | 30/200 [7:27:12<41:58:18, 888.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.5738525390625
INFO:root:current train perplexity4.245852947235107
INFO:root:current mean train loss 1864.6378655389908
INFO:root:current train perplexity4.342923164367676
INFO:root:current mean train loss 1871.530033969423
INFO:root:current train perplexity4.367885589599609
INFO:root:current mean train loss 1864.8387901528367
INFO:root:current train perplexity4.3489532470703125
INFO:root:current mean train loss 1864.5025688488502
INFO:root:current train perplexity4.354677200317383
INFO:root:current mean train loss 1865.3296212606674
INFO:root:current train perplexity4.357322692871094
INFO:root:current mean train loss 1863.9332257350677
INFO:root:current train perplexity4.361429214477539
INFO:root:current mean train loss 1867.197685209417
INFO:root:current train perplexity4.373075485229492
INFO:root:current mean train loss 1868.59941563176
INFO:root:current train perplexity4.376443386077881
INFO:root:current mean train loss 1871.3351564648653
INFO:root:current train perplexity4.380220890045166
INFO:root:current mean train loss 1873.24010431991
INFO:root:current train perplexity4.382721424102783
INFO:root:current mean train loss 1872.2740108672297
INFO:root:current train perplexity4.380767822265625
INFO:root:current mean train loss 1873.846683019444
INFO:root:current train perplexity4.385595798492432
INFO:root:current mean train loss 1874.0429933692226
INFO:root:current train perplexity4.38397741317749
INFO:root:current mean train loss 1873.7269521026935
INFO:root:current train perplexity4.3834638595581055
INFO:root:current mean train loss 1873.3042551979788
INFO:root:current train perplexity4.382967948913574
INFO:root:current mean train loss 1872.1771731853783
INFO:root:current train perplexity4.384230613708496
INFO:root:current mean train loss 1872.5437132431932
INFO:root:current train perplexity4.385227680206299
INFO:root:current mean train loss 1873.466486469562
INFO:root:current train perplexity4.387459754943848
INFO:root:current mean train loss 1874.3637999688974
INFO:root:current train perplexity4.388945579528809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:57<00:00, 777.03s/it]
INFO:root:final mean train loss: 1873.9789449948587
INFO:root:final train perplexity: 4.38829231262207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.36s/it]
INFO:root:eval mean loss: 1871.4224550504211
INFO:root:eval perplexity: 4.5466132164001465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it]
INFO:root:eval mean loss: 2294.7078770847183
INFO:root:eval perplexity: 6.596538066864014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/31
 16%|â–ˆâ–Œ        | 31/200 [7:42:13<41:54:09, 892.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.9906005859375
INFO:root:current train perplexity4.408853530883789
INFO:root:current mean train loss 1865.3028641958085
INFO:root:current train perplexity4.3725385665893555
INFO:root:current mean train loss 1856.1456855166275
INFO:root:current train perplexity4.339417457580566
INFO:root:current mean train loss 1857.603487915788
INFO:root:current train perplexity4.340754508972168
INFO:root:current mean train loss 1859.7702671104753
INFO:root:current train perplexity4.344175338745117
INFO:root:current mean train loss 1858.7587103898081
INFO:root:current train perplexity4.342479705810547
INFO:root:current mean train loss 1861.1495150727585
INFO:root:current train perplexity4.342384338378906
INFO:root:current mean train loss 1863.5728213307614
INFO:root:current train perplexity4.347456455230713
INFO:root:current mean train loss 1864.7917147952764
INFO:root:current train perplexity4.3533244132995605
INFO:root:current mean train loss 1866.9389411151794
INFO:root:current train perplexity4.3585028648376465
INFO:root:current mean train loss 1866.2275766592045
INFO:root:current train perplexity4.359560489654541
INFO:root:current mean train loss 1867.7706860394926
INFO:root:current train perplexity4.361753940582275
INFO:root:current mean train loss 1866.9028795251645
INFO:root:current train perplexity4.3610005378723145
INFO:root:current mean train loss 1867.8984194564243
INFO:root:current train perplexity4.3621649742126465
INFO:root:current mean train loss 1866.707883944518
INFO:root:current train perplexity4.359537124633789
INFO:root:current mean train loss 1865.7389205592644
INFO:root:current train perplexity4.360571384429932
INFO:root:current mean train loss 1866.7869669596355
INFO:root:current train perplexity4.361804962158203
INFO:root:current mean train loss 1865.7786673571254
INFO:root:current train perplexity4.360106468200684
INFO:root:current mean train loss 1867.0487668892902
INFO:root:current train perplexity4.363597869873047
INFO:root:current mean train loss 1868.2802332544377
INFO:root:current train perplexity4.36722993850708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.54s/it]
INFO:root:final mean train loss: 1867.8893208544603
INFO:root:final train perplexity: 4.367252826690674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.46s/it]
INFO:root:eval mean loss: 1876.6519173696531
INFO:root:eval perplexity: 4.56589412689209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it]
INFO:root:eval mean loss: 2300.9843728356327
INFO:root:eval perplexity: 6.630665302276611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/32
 16%|â–ˆâ–Œ        | 32/200 [7:57:10<41:43:05, 893.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.7553909656613
INFO:root:current train perplexity4.401130676269531
INFO:root:current mean train loss 1865.0322163188373
INFO:root:current train perplexity4.316762924194336
INFO:root:current mean train loss 1866.9298055515367
INFO:root:current train perplexity4.321191787719727
INFO:root:current mean train loss 1859.649164227633
INFO:root:current train perplexity4.315903186798096
INFO:root:current mean train loss 1862.6475692301249
INFO:root:current train perplexity4.327950954437256
INFO:root:current mean train loss 1859.6847359954104
INFO:root:current train perplexity4.329910755157471
INFO:root:current mean train loss 1857.961805281335
INFO:root:current train perplexity4.323202133178711
INFO:root:current mean train loss 1859.2109064484669
INFO:root:current train perplexity4.325573444366455
INFO:root:current mean train loss 1857.9698361796134
INFO:root:current train perplexity4.3297343254089355
INFO:root:current mean train loss 1857.2984387427095
INFO:root:current train perplexity4.327326774597168
INFO:root:current mean train loss 1856.7482368271737
INFO:root:current train perplexity4.32875394821167
INFO:root:current mean train loss 1859.2642250895397
INFO:root:current train perplexity4.33870792388916
INFO:root:current mean train loss 1860.3464842571525
INFO:root:current train perplexity4.340652942657471
INFO:root:current mean train loss 1860.2238671365994
INFO:root:current train perplexity4.3436970710754395
INFO:root:current mean train loss 1860.543164079419
INFO:root:current train perplexity4.3460001945495605
INFO:root:current mean train loss 1861.9545339113386
INFO:root:current train perplexity4.347845554351807
INFO:root:current mean train loss 1864.3558446195746
INFO:root:current train perplexity4.352965354919434
INFO:root:current mean train loss 1864.3206082561271
INFO:root:current train perplexity4.351458549499512
INFO:root:current mean train loss 1865.1511336444062
INFO:root:current train perplexity4.353506088256836
INFO:root:current mean train loss 1864.7108391777977
INFO:root:current train perplexity4.353308200836182

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.80s/it]
INFO:root:final mean train loss: 1863.8512051534724
INFO:root:final train perplexity: 4.353357315063477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.91s/it]
INFO:root:eval mean loss: 1876.7378531381594
INFO:root:eval perplexity: 4.566211700439453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.03s/it]
INFO:root:eval mean loss: 2304.1982235739415
INFO:root:eval perplexity: 6.648207664489746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/33
 16%|â–ˆâ–‹        | 33/200 [8:12:02<41:25:56, 893.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1864.9345418294272
INFO:root:current train perplexity4.381326198577881
INFO:root:current mean train loss 1864.933992767334
INFO:root:current train perplexity4.359057426452637
INFO:root:current mean train loss 1855.1235755333535
INFO:root:current train perplexity4.34287691116333
INFO:root:current mean train loss 1858.8336385091145
INFO:root:current train perplexity4.3475728034973145
INFO:root:current mean train loss 1859.5698430600373
INFO:root:current train perplexity4.341704845428467
INFO:root:current mean train loss 1862.4473942347936
INFO:root:current train perplexity4.342280864715576
INFO:root:current mean train loss 1863.824814120206
INFO:root:current train perplexity4.3470458984375
INFO:root:current mean train loss 1862.7131249678762
INFO:root:current train perplexity4.348083019256592
INFO:root:current mean train loss 1860.5469287961027
INFO:root:current train perplexity4.341617107391357
INFO:root:current mean train loss 1861.5565755208333
INFO:root:current train perplexity4.3466362953186035
INFO:root:current mean train loss 1861.5168173735997
INFO:root:current train perplexity4.344133377075195
INFO:root:current mean train loss 1860.7842748181574
INFO:root:current train perplexity4.341952323913574
INFO:root:current mean train loss 1857.2804501488095
INFO:root:current train perplexity4.338135242462158
INFO:root:current mean train loss 1860.0188668643727
INFO:root:current train perplexity4.339462757110596
INFO:root:current mean train loss 1860.165708609803
INFO:root:current train perplexity4.339934349060059
INFO:root:current mean train loss 1861.392568030724
INFO:root:current train perplexity4.338924407958984
INFO:root:current mean train loss 1862.0612127464938
INFO:root:current train perplexity4.340660095214844
INFO:root:current mean train loss 1862.1066013682973
INFO:root:current train perplexity4.340603351593018
INFO:root:current mean train loss 1861.8628688361055
INFO:root:current train perplexity4.341418266296387
INFO:root:current mean train loss 1861.1308368916414
INFO:root:current train perplexity4.340713977813721

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.48s/it]
INFO:root:final mean train loss: 1860.2204848081249
INFO:root:final train perplexity: 4.340901851654053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.18s/it]
INFO:root:eval mean loss: 1881.449826504322
INFO:root:eval perplexity: 4.583655834197998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it]
INFO:root:eval mean loss: 2310.9312809071644
INFO:root:eval perplexity: 6.685110092163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/34
 17%|â–ˆâ–‹        | 34/200 [8:26:31<40:51:28, 886.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1828.0767283253856
INFO:root:current train perplexity4.279501438140869
INFO:root:current mean train loss 1839.4942585573358
INFO:root:current train perplexity4.284665584564209
INFO:root:current mean train loss 1844.3479255097868
INFO:root:current train perplexity4.291622161865234
INFO:root:current mean train loss 1845.3186630937087
INFO:root:current train perplexity4.28828239440918
INFO:root:current mean train loss 1846.0190483429146
INFO:root:current train perplexity4.294987201690674
INFO:root:current mean train loss 1847.2802004491848
INFO:root:current train perplexity4.300097942352295
INFO:root:current mean train loss 1847.4281187973136
INFO:root:current train perplexity4.301429271697998
INFO:root:current mean train loss 1849.5604177349783
INFO:root:current train perplexity4.3057732582092285
INFO:root:current mean train loss 1848.778086193611
INFO:root:current train perplexity4.305524826049805
INFO:root:current mean train loss 1850.4044543044715
INFO:root:current train perplexity4.31056022644043
INFO:root:current mean train loss 1851.8530734743138
INFO:root:current train perplexity4.310007572174072
INFO:root:current mean train loss 1853.8804620501342
INFO:root:current train perplexity4.31618595123291
INFO:root:current mean train loss 1854.430182472653
INFO:root:current train perplexity4.316869258880615
INFO:root:current mean train loss 1854.0405690089983
INFO:root:current train perplexity4.319092273712158
INFO:root:current mean train loss 1855.17213955455
INFO:root:current train perplexity4.321691989898682
INFO:root:current mean train loss 1857.175543843755
INFO:root:current train perplexity4.32633638381958
INFO:root:current mean train loss 1857.888580304068
INFO:root:current train perplexity4.330674171447754
INFO:root:current mean train loss 1858.7546351684502
INFO:root:current train perplexity4.33052396774292
INFO:root:current mean train loss 1858.034096117787
INFO:root:current train perplexity4.330682277679443
INFO:root:current mean train loss 1857.7944866946448
INFO:root:current train perplexity4.331045150756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.82s/it]
INFO:root:final mean train loss: 1857.2661461226578
INFO:root:final train perplexity: 4.330791473388672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.42s/it]
INFO:root:eval mean loss: 1880.5463958090925
INFO:root:eval perplexity: 4.580305576324463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.65s/it]
INFO:root:eval mean loss: 2313.6086815367353
INFO:root:eval perplexity: 6.69984245300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/35
 18%|â–ˆâ–Š        | 35/200 [8:41:12<40:32:45, 884.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1854.351250831117
INFO:root:current train perplexity4.318521022796631
INFO:root:current mean train loss 1843.0832028733087
INFO:root:current train perplexity4.299624919891357
INFO:root:current mean train loss 1855.1680430717208
INFO:root:current train perplexity4.325704097747803
INFO:root:current mean train loss 1860.6688158064323
INFO:root:current train perplexity4.336419582366943
INFO:root:current mean train loss 1856.0758076409097
INFO:root:current train perplexity4.329927921295166
INFO:root:current mean train loss 1857.0896456426242
INFO:root:current train perplexity4.3351874351501465
INFO:root:current mean train loss 1860.686917615555
INFO:root:current train perplexity4.340484142303467
INFO:root:current mean train loss 1857.1840216110575
INFO:root:current train perplexity4.329690456390381
INFO:root:current mean train loss 1855.2556324389157
INFO:root:current train perplexity4.326172351837158
INFO:root:current mean train loss 1854.6581639495175
INFO:root:current train perplexity4.3253655433654785
INFO:root:current mean train loss 1855.785959079889
INFO:root:current train perplexity4.324441432952881
INFO:root:current mean train loss 1856.2933299513518
INFO:root:current train perplexity4.324870586395264
INFO:root:current mean train loss 1855.0653018627138
INFO:root:current train perplexity4.322244167327881
INFO:root:current mean train loss 1856.4523001059226
INFO:root:current train perplexity4.324945449829102
INFO:root:current mean train loss 1857.1531529764893
INFO:root:current train perplexity4.329830169677734
INFO:root:current mean train loss 1857.790238939235
INFO:root:current train perplexity4.333047389984131
INFO:root:current mean train loss 1857.7267526673877
INFO:root:current train perplexity4.333581447601318
INFO:root:current mean train loss 1857.6211555336365
INFO:root:current train perplexity4.332793712615967
INFO:root:current mean train loss 1858.0101576808136
INFO:root:current train perplexity4.332695960998535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.13s/it]
INFO:root:final mean train loss: 1857.5619687202056
INFO:root:final train perplexity: 4.3318023681640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.84s/it]
INFO:root:eval mean loss: 1882.1963436045546
INFO:root:eval perplexity: 4.58642578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it]
INFO:root:eval mean loss: 2314.629541275349
INFO:root:eval perplexity: 6.705467224121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/36
 18%|â–ˆâ–Š        | 36/200 [8:55:48<40:10:51, 882.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.2224564985795
INFO:root:current train perplexity4.3844075202941895
INFO:root:current mean train loss 1844.3742664783924
INFO:root:current train perplexity4.275902271270752
INFO:root:current mean train loss 1830.6745640180686
INFO:root:current train perplexity4.259768962860107
INFO:root:current mean train loss 1841.6105305466237
INFO:root:current train perplexity4.282083511352539
INFO:root:current mean train loss 1847.1859932781135
INFO:root:current train perplexity4.3003034591674805
INFO:root:current mean train loss 1849.6571226474591
INFO:root:current train perplexity4.305910587310791
INFO:root:current mean train loss 1847.7342293547335
INFO:root:current train perplexity4.301778316497803
INFO:root:current mean train loss 1847.4695468049513
INFO:root:current train perplexity4.305375099182129
INFO:root:current mean train loss 1849.5018701894362
INFO:root:current train perplexity4.310789585113525
INFO:root:current mean train loss 1851.7844629549431
INFO:root:current train perplexity4.314344882965088
INFO:root:current mean train loss 1852.3724339878524
INFO:root:current train perplexity4.315741062164307
INFO:root:current mean train loss 1854.5953562519337
INFO:root:current train perplexity4.323225975036621
INFO:root:current mean train loss 1854.6002710343982
INFO:root:current train perplexity4.32526969909668
INFO:root:current mean train loss 1857.2565608835694
INFO:root:current train perplexity4.331792831420898
INFO:root:current mean train loss 1856.5189650202371
INFO:root:current train perplexity4.329283237457275
INFO:root:current mean train loss 1858.329614564806
INFO:root:current train perplexity4.330935955047607
INFO:root:current mean train loss 1858.066340100166
INFO:root:current train perplexity4.331239223480225
INFO:root:current mean train loss 1859.2175841607384
INFO:root:current train perplexity4.336883544921875
INFO:root:current mean train loss 1859.8783824463565
INFO:root:current train perplexity4.336489677429199
INFO:root:current mean train loss 1859.332215856595
INFO:root:current train perplexity4.337630271911621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.15s/it]
INFO:root:final mean train loss: 1860.6195538973363
INFO:root:final train perplexity: 4.342268466949463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.76s/it]
INFO:root:eval mean loss: 1879.2731444446754
INFO:root:eval perplexity: 4.575589656829834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.41s/it]
INFO:root:eval mean loss: 2310.290887494459
INFO:root:eval perplexity: 6.681591987609863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/37
 18%|â–ˆâ–Š        | 37/200 [9:10:27<39:53:28, 881.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.234143938337
INFO:root:current train perplexity4.283921241760254
INFO:root:current mean train loss 1862.6873931884766
INFO:root:current train perplexity4.362971305847168
INFO:root:current mean train loss 1852.162238940858
INFO:root:current train perplexity4.343460559844971
INFO:root:current mean train loss 1846.6118417135099
INFO:root:current train perplexity4.320385932922363
INFO:root:current mean train loss 1854.4330863596124
INFO:root:current train perplexity4.345972061157227
INFO:root:current mean train loss 1853.3165297074752
INFO:root:current train perplexity4.342131614685059
INFO:root:current mean train loss 1854.6228917601761
INFO:root:current train perplexity4.337259769439697
INFO:root:current mean train loss 1855.1798602093706
INFO:root:current train perplexity4.333407878875732
INFO:root:current mean train loss 1858.7418482683706
INFO:root:current train perplexity4.345463275909424
INFO:root:current mean train loss 1858.4594618698645
INFO:root:current train perplexity4.345329761505127
INFO:root:current mean train loss 1859.1803448747569
INFO:root:current train perplexity4.3459601402282715
INFO:root:current mean train loss 1857.8797224328873
INFO:root:current train perplexity4.345200538635254
INFO:root:current mean train loss 1858.8370131700747
INFO:root:current train perplexity4.348150730133057
INFO:root:current mean train loss 1858.9386104905461
INFO:root:current train perplexity4.347715377807617
INFO:root:current mean train loss 1860.7497542351903
INFO:root:current train perplexity4.350874900817871
INFO:root:current mean train loss 1861.6133406873773
INFO:root:current train perplexity4.353114128112793
INFO:root:current mean train loss 1863.344653005389
INFO:root:current train perplexity4.356777667999268
INFO:root:current mean train loss 1864.5963533895988
INFO:root:current train perplexity4.357292175292969
INFO:root:current mean train loss 1865.613179546999
INFO:root:current train perplexity4.357412815093994
INFO:root:current mean train loss 1865.8081600458295
INFO:root:current train perplexity4.359378814697266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.29s/it]
INFO:root:final mean train loss: 1865.9835646759664
INFO:root:final train perplexity: 4.360689163208008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.45s/it]
INFO:root:eval mean loss: 1900.4323011898825
INFO:root:eval perplexity: 4.654607772827148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.04s/it]
INFO:root:eval mean loss: 2331.8785348445813
INFO:root:eval perplexity: 6.801235198974609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/38
 19%|â–ˆâ–‰        | 38/200 [9:25:01<39:33:18, 879.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.3221245659722
INFO:root:current train perplexity4.3549652099609375
INFO:root:current mean train loss 1857.0500420932112
INFO:root:current train perplexity4.355717182159424
INFO:root:current mean train loss 1855.388507952009
INFO:root:current train perplexity4.34529972076416
INFO:root:current mean train loss 1856.651856530231
INFO:root:current train perplexity4.348338603973389
INFO:root:current mean train loss 1857.3410411363238
INFO:root:current train perplexity4.343742847442627
INFO:root:current mean train loss 1860.5422302806048
INFO:root:current train perplexity4.352601528167725
INFO:root:current mean train loss 1862.280494678113
INFO:root:current train perplexity4.351859092712402
INFO:root:current mean train loss 1863.7494548618392
INFO:root:current train perplexity4.356241703033447
INFO:root:current mean train loss 1865.5148850661058
INFO:root:current train perplexity4.362908363342285
INFO:root:current mean train loss 1865.0879546957672
INFO:root:current train perplexity4.364340305328369
INFO:root:current mean train loss 1867.34479419763
INFO:root:current train perplexity4.372499942779541
INFO:root:current mean train loss 1868.096921802504
INFO:root:current train perplexity4.370795249938965
INFO:root:current mean train loss 1868.5450033532568
INFO:root:current train perplexity4.369776725769043
INFO:root:current mean train loss 1869.4934359752556
INFO:root:current train perplexity4.373831272125244
INFO:root:current mean train loss 1869.5299448191502
INFO:root:current train perplexity4.374335289001465
INFO:root:current mean train loss 1869.652265688208
INFO:root:current train perplexity4.372272491455078
INFO:root:current mean train loss 1869.6345634112604
INFO:root:current train perplexity4.372644424438477
INFO:root:current mean train loss 1871.024253727167
INFO:root:current train perplexity4.374601364135742
INFO:root:current mean train loss 1871.4640568761645
INFO:root:current train perplexity4.37669038772583
INFO:root:current mean train loss 1871.8716423446538
INFO:root:current train perplexity4.378073692321777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.35s/it]
INFO:root:final mean train loss: 1870.4995811566282
INFO:root:final train perplexity: 4.376258850097656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.04s/it]
INFO:root:eval mean loss: 1886.5106006378824
INFO:root:eval perplexity: 4.602465629577637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.65s/it]
INFO:root:eval mean loss: 2319.747762044271
INFO:root:eval perplexity: 6.733743190765381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/39
 20%|â–ˆâ–‰        | 39/200 [9:39:42<39:19:44, 879.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1886.3409246629285
INFO:root:current train perplexity4.412080764770508
INFO:root:current mean train loss 1869.648784119406
INFO:root:current train perplexity4.390079498291016
INFO:root:current mean train loss 1862.7601970643489
INFO:root:current train perplexity4.38393497467041
INFO:root:current mean train loss 1862.42249681673
INFO:root:current train perplexity4.363626480102539
INFO:root:current mean train loss 1863.79497630462
INFO:root:current train perplexity4.356268882751465
INFO:root:current mean train loss 1866.928194853759
INFO:root:current train perplexity4.370421886444092
INFO:root:current mean train loss 1867.6190773770888
INFO:root:current train perplexity4.380016803741455
INFO:root:current mean train loss 1867.607229958682
INFO:root:current train perplexity4.376161098480225
INFO:root:current mean train loss 1869.7961850619924
INFO:root:current train perplexity4.380776405334473
INFO:root:current mean train loss 1869.6138267596398
INFO:root:current train perplexity4.384644985198975
INFO:root:current mean train loss 1869.5656348621778
INFO:root:current train perplexity4.379977226257324
INFO:root:current mean train loss 1870.584970812379
INFO:root:current train perplexity4.383390426635742
INFO:root:current mean train loss 1870.3875706305405
INFO:root:current train perplexity4.382196426391602
INFO:root:current mean train loss 1870.9472495819853
INFO:root:current train perplexity4.384792804718018
INFO:root:current mean train loss 1870.6606324244133
INFO:root:current train perplexity4.3835906982421875
INFO:root:current mean train loss 1871.3673265288642
INFO:root:current train perplexity4.382994651794434
INFO:root:current mean train loss 1871.55799896938
INFO:root:current train perplexity4.383793354034424
INFO:root:current mean train loss 1873.556019258012
INFO:root:current train perplexity4.389288902282715
INFO:root:current mean train loss 1875.0553967140927
INFO:root:current train perplexity4.3918280601501465
INFO:root:current mean train loss 1875.9799705139844
INFO:root:current train perplexity4.393717288970947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.10s/it]
INFO:root:final mean train loss: 1875.5600866951609
INFO:root:final train perplexity: 4.393770694732666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it]
INFO:root:eval mean loss: 1887.9436472358434
INFO:root:eval perplexity: 4.6078057289123535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.34s/it]
INFO:root:eval mean loss: 2326.4775684978945
INFO:root:eval perplexity: 6.771102428436279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/40
 20%|â–ˆâ–ˆ        | 40/200 [9:54:21<39:05:06, 879.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.2121103021163
INFO:root:current train perplexity4.35992431640625
INFO:root:current mean train loss 1879.3895836515799
INFO:root:current train perplexity4.395766258239746
INFO:root:current mean train loss 1882.8087757616488
INFO:root:current train perplexity4.397584438323975
INFO:root:current mean train loss 1881.4864199192982
INFO:root:current train perplexity4.400708198547363
INFO:root:current mean train loss 1880.0924877572907
INFO:root:current train perplexity4.397485733032227
INFO:root:current mean train loss 1882.34412443329
INFO:root:current train perplexity4.401569843292236
INFO:root:current mean train loss 1883.8005372891546
INFO:root:current train perplexity4.406749248504639
INFO:root:current mean train loss 1888.0690776937581
INFO:root:current train perplexity4.42308235168457
INFO:root:current mean train loss 1883.021502706378
INFO:root:current train perplexity4.417123317718506
INFO:root:current mean train loss 1882.0774934513454
INFO:root:current train perplexity4.413311958312988
INFO:root:current mean train loss 1881.991410503794
INFO:root:current train perplexity4.415457725524902
INFO:root:current mean train loss 1882.817588954987
INFO:root:current train perplexity4.416022777557373
INFO:root:current mean train loss 1882.5636746046412
INFO:root:current train perplexity4.417374610900879
INFO:root:current mean train loss 1884.71561432438
INFO:root:current train perplexity4.421219348907471
INFO:root:current mean train loss 1885.520886568865
INFO:root:current train perplexity4.422983169555664
INFO:root:current mean train loss 1885.8296179067795
INFO:root:current train perplexity4.425648212432861
INFO:root:current mean train loss 1886.5942211230642
INFO:root:current train perplexity4.430251598358154
INFO:root:current mean train loss 1886.950666096319
INFO:root:current train perplexity4.432168960571289
INFO:root:current mean train loss 1888.8768502195317
INFO:root:current train perplexity4.439101219177246
INFO:root:current mean train loss 1890.4562618184295
INFO:root:current train perplexity4.443890571594238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.94s/it]
INFO:root:final mean train loss: 1890.0393635205892
INFO:root:final train perplexity: 4.4442667961120605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.88s/it]
INFO:root:eval mean loss: 1896.5510972476175
INFO:root:eval perplexity: 4.640012741088867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it]
INFO:root:eval mean loss: 2333.7004862034573
INFO:root:eval perplexity: 6.811429977416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/41
 20%|â–ˆâ–ˆ        | 41/200 [10:08:58<38:48:24, 878.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1919.7117716471355
INFO:root:current train perplexity4.5179524421691895
INFO:root:current mean train loss 1910.3836887904577
INFO:root:current train perplexity4.479575157165527
INFO:root:current mean train loss 1911.919807227882
INFO:root:current train perplexity4.46885871887207
INFO:root:current mean train loss 1909.1448416661735
INFO:root:current train perplexity4.469221115112305
INFO:root:current mean train loss 1910.341077743038
INFO:root:current train perplexity4.47353458404541
INFO:root:current mean train loss 1907.686788469353
INFO:root:current train perplexity4.471018314361572
INFO:root:current mean train loss 1903.2829628429195
INFO:root:current train perplexity4.467258453369141
INFO:root:current mean train loss 1902.8314439016372
INFO:root:current train perplexity4.467277526855469
INFO:root:current mean train loss 1899.12797328404
INFO:root:current train perplexity4.464553356170654
INFO:root:current mean train loss 1900.2051546027863
INFO:root:current train perplexity4.459857940673828
INFO:root:current mean train loss 1899.952138079344
INFO:root:current train perplexity4.4609575271606445
INFO:root:current mean train loss 1899.802478905107
INFO:root:current train perplexity4.460814952850342
INFO:root:current mean train loss 1898.425147821874
INFO:root:current train perplexity4.457809925079346
INFO:root:current mean train loss 1898.1281840589463
INFO:root:current train perplexity4.45973014831543
INFO:root:current mean train loss 1897.4580678684827
INFO:root:current train perplexity4.4592461585998535
INFO:root:current mean train loss 1897.9221638079573
INFO:root:current train perplexity4.462850570678711
INFO:root:current mean train loss 1898.2677432366138
INFO:root:current train perplexity4.466729164123535
INFO:root:current mean train loss 1896.7782643069668
INFO:root:current train perplexity4.465253829956055
INFO:root:current mean train loss 1897.2843060070954
INFO:root:current train perplexity4.469094753265381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.63s/it]
INFO:root:final mean train loss: 1897.495013246137
INFO:root:final train perplexity: 4.470494747161865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.84s/it]
INFO:root:eval mean loss: 1910.8203782967641
INFO:root:eval perplexity: 4.6939005851745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it]
INFO:root:eval mean loss: 2346.041159338985
INFO:root:eval perplexity: 6.88088846206665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/42
 21%|â–ˆâ–ˆ        | 42/200 [10:23:39<38:35:44, 879.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1894.1741661658655
INFO:root:current train perplexity4.445254802703857
INFO:root:current mean train loss 1902.9174178131914
INFO:root:current train perplexity4.473925590515137
INFO:root:current mean train loss 1892.620908065581
INFO:root:current train perplexity4.454916000366211
INFO:root:current mean train loss 1894.859637470672
INFO:root:current train perplexity4.454711437225342
INFO:root:current mean train loss 1891.9650145893236
INFO:root:current train perplexity4.450355529785156
INFO:root:current mean train loss 1894.691732008787
INFO:root:current train perplexity4.449995040893555
INFO:root:current mean train loss 1899.9242962935232
INFO:root:current train perplexity4.460521697998047
INFO:root:current mean train loss 1897.5554699142049
INFO:root:current train perplexity4.458982467651367
INFO:root:current mean train loss 1901.4015707881688
INFO:root:current train perplexity4.466120719909668
INFO:root:current mean train loss 1898.503256589925
INFO:root:current train perplexity4.460593223571777
INFO:root:current mean train loss 1898.7229424464385
INFO:root:current train perplexity4.467684268951416
INFO:root:current mean train loss 1897.7798867169952
INFO:root:current train perplexity4.465614318847656
INFO:root:current mean train loss 1897.1905047612454
INFO:root:current train perplexity4.466360569000244
INFO:root:current mean train loss 1898.6027653527822
INFO:root:current train perplexity4.470297336578369
INFO:root:current mean train loss 1897.7971386649638
INFO:root:current train perplexity4.471854209899902
INFO:root:current mean train loss 1897.5609548786817
INFO:root:current train perplexity4.472856521606445
INFO:root:current mean train loss 1899.0253256923725
INFO:root:current train perplexity4.472097873687744
INFO:root:current mean train loss 1899.6758775950452
INFO:root:current train perplexity4.474414825439453
INFO:root:current mean train loss 1899.7630036191524
INFO:root:current train perplexity4.474740028381348
INFO:root:current mean train loss 1900.1259019037097
INFO:root:current train perplexity4.475536823272705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:36<00:00, 756.89s/it]
INFO:root:final mean train loss: 1898.8927483955417
INFO:root:final train perplexity: 4.475427627563477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it]
INFO:root:eval mean loss: 1892.470481060921
INFO:root:eval perplexity: 4.624715328216553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.50s/it]
INFO:root:eval mean loss: 2330.171045181599
INFO:root:eval perplexity: 6.791694164276123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/43
 22%|â–ˆâ–ˆâ–       | 43/200 [10:38:13<38:16:52, 877.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1893.2944213867188
INFO:root:current train perplexity4.4662861824035645
INFO:root:current mean train loss 1894.6840444711538
INFO:root:current train perplexity4.458856582641602
INFO:root:current mean train loss 1890.950458029042
INFO:root:current train perplexity4.44394063949585
INFO:root:current mean train loss 1885.8742139411695
INFO:root:current train perplexity4.427840232849121
INFO:root:current mean train loss 1887.0419771416243
INFO:root:current train perplexity4.434178829193115
INFO:root:current mean train loss 1889.1221776422465
INFO:root:current train perplexity4.442895412445068
INFO:root:current mean train loss 1891.4320639958457
INFO:root:current train perplexity4.451668739318848
INFO:root:current mean train loss 1893.5323270614833
INFO:root:current train perplexity4.4562458992004395
INFO:root:current mean train loss 1895.6409063500093
INFO:root:current train perplexity4.4644775390625
INFO:root:current mean train loss 1895.3483632077453
INFO:root:current train perplexity4.4649553298950195
INFO:root:current mean train loss 1894.956353700508
INFO:root:current train perplexity4.467038154602051
INFO:root:current mean train loss 1895.5621015970685
INFO:root:current train perplexity4.47276496887207
INFO:root:current mean train loss 1896.766560376175
INFO:root:current train perplexity4.4717206954956055
INFO:root:current mean train loss 1897.603640356996
INFO:root:current train perplexity4.473623275756836
INFO:root:current mean train loss 1897.4756630210609
INFO:root:current train perplexity4.474910736083984
INFO:root:current mean train loss 1898.118900473601
INFO:root:current train perplexity4.475550174713135
INFO:root:current mean train loss 1898.4980911348496
INFO:root:current train perplexity4.477476119995117
INFO:root:current mean train loss 1900.826478320877
INFO:root:current train perplexity4.483786106109619
INFO:root:current mean train loss 1945.5507321550547
INFO:root:current train perplexity4.6473894119262695
INFO:root:current mean train loss 2084.43805190961
INFO:root:current train perplexity5.181005477905273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:38<00:00, 758.74s/it]
INFO:root:final mean train loss: 2139.7832050948687
INFO:root:final train perplexity: 5.412506103515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.49s/it]
INFO:root:eval mean loss: 3366.216748393174
INFO:root:eval perplexity: 15.241044998168945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.88s/it]
INFO:root:eval mean loss: 3709.757543252715
INFO:root:eval perplexity: 21.11319351196289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/44
 22%|â–ˆâ–ˆâ–       | 44/200 [10:52:49<38:00:31, 877.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4845.481642702793
INFO:root:current train perplexity45.71599578857422
INFO:root:current mean train loss 4663.483775443771
INFO:root:current train perplexity40.40286636352539
INFO:root:current mean train loss 4610.027817204897
INFO:root:current train perplexity38.46443557739258
INFO:root:current mean train loss 4564.3711795861855
INFO:root:current train perplexity36.48670196533203
INFO:root:current mean train loss 4475.531378351336
INFO:root:current train perplexity34.25905990600586
INFO:root:current mean train loss 4658.637257466151
INFO:root:current train perplexity39.51355743408203
INFO:root:current mean train loss 4596.180948201434
INFO:root:current train perplexity37.50583267211914
INFO:root:current mean train loss 4310.619254851437
INFO:root:current train perplexity29.967803955078125
INFO:root:current mean train loss 4066.6128841972127
INFO:root:current train perplexity24.707529067993164
INFO:root:current mean train loss 3871.870866753358
INFO:root:current train perplexity21.20432472229004
INFO:root:current mean train loss 3714.0853805469123
INFO:root:current train perplexity18.693010330200195
INFO:root:current mean train loss 3585.802658812732
INFO:root:current train perplexity16.91021728515625
INFO:root:current mean train loss 3482.7722812092775
INFO:root:current train perplexity15.609567642211914
INFO:root:current mean train loss 3398.780725106719
INFO:root:current train perplexity14.611309051513672
INFO:root:current mean train loss 3328.101741429601
INFO:root:current train perplexity13.827032089233398
INFO:root:current mean train loss 3266.4453760207507
INFO:root:current train perplexity13.163180351257324
INFO:root:current mean train loss 3212.1186745787795
INFO:root:current train perplexity12.599679946899414
INFO:root:current mean train loss 3160.8140869839367
INFO:root:current train perplexity12.096710205078125
INFO:root:current mean train loss 3113.3083714855384
INFO:root:current train perplexity11.6581392288208
INFO:root:current mean train loss 3071.257916325597
INFO:root:current train perplexity11.279594421386719

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.73s/it]
INFO:root:final mean train loss: 3055.930967976334
INFO:root:final train perplexity: 11.153285026550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.46s/it]
INFO:root:eval mean loss: 2097.181711183372
INFO:root:eval perplexity: 5.457934379577637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it]
INFO:root:eval mean loss: 2535.118118610788
INFO:root:eval perplexity: 8.038104057312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [11:07:26<37:45:39, 877.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2266.314987182617
INFO:root:current train perplexity5.9228034019470215
INFO:root:current mean train loss 2274.263307152725
INFO:root:current train perplexity5.9793477058410645
INFO:root:current mean train loss 2270.4640290231414
INFO:root:current train perplexity5.98391056060791
INFO:root:current mean train loss 2259.0157849657667
INFO:root:current train perplexity5.93198299407959
INFO:root:current mean train loss 2260.814402350064
INFO:root:current train perplexity5.936129093170166
INFO:root:current mean train loss 2258.3324000581783
INFO:root:current train perplexity5.927342891693115
INFO:root:current mean train loss 2234.1168058464327
INFO:root:current train perplexity5.818517208099365
INFO:root:current mean train loss 2213.823922042447
INFO:root:current train perplexity5.7298173904418945
INFO:root:current mean train loss 2196.6126338817453
INFO:root:current train perplexity5.649292945861816
INFO:root:current mean train loss 2312.676435668439
INFO:root:current train perplexity6.192767143249512
INFO:root:current mean train loss 2350.649892247709
INFO:root:current train perplexity6.387237071990967
INFO:root:current mean train loss 2357.3904502842433
INFO:root:current train perplexity6.413800239562988
INFO:root:current mean train loss 2347.527301160595
INFO:root:current train perplexity6.366032600402832
INFO:root:current mean train loss 2336.038142229455
INFO:root:current train perplexity6.307524681091309
INFO:root:current mean train loss 2322.768730705553
INFO:root:current train perplexity6.2434234619140625
INFO:root:current mean train loss 2311.066931214784
INFO:root:current train perplexity6.189699172973633
INFO:root:current mean train loss 2298.547030889071
INFO:root:current train perplexity6.135270118713379
INFO:root:current mean train loss 2287.797447913899
INFO:root:current train perplexity6.083836078643799
INFO:root:current mean train loss 2278.654218419939
INFO:root:current train perplexity6.037219524383545
INFO:root:current mean train loss 2270.1445245995296
INFO:root:current train perplexity5.994945526123047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.71s/it]
INFO:root:final mean train loss: 2267.9031034730265
INFO:root:final train perplexity: 5.988399982452393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.16s/it]
INFO:root:eval mean loss: 2001.0758160530252
INFO:root:eval perplexity: 5.049554347991943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.56s/it]
INFO:root:eval mean loss: 2438.700773631427
INFO:root:eval perplexity: 7.425544261932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [11:22:04<37:32:30, 877.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2132.800635067033
INFO:root:current train perplexity5.389644622802734
INFO:root:current mean train loss 2130.172674189615
INFO:root:current train perplexity5.392559051513672
INFO:root:current mean train loss 2107.6658375152915
INFO:root:current train perplexity5.289193153381348
INFO:root:current mean train loss 2105.365424368951
INFO:root:current train perplexity5.26559591293335
INFO:root:current mean train loss 2110.408022176699
INFO:root:current train perplexity5.2685770988464355
INFO:root:current mean train loss 2112.4923070490668
INFO:root:current train perplexity5.281533718109131
INFO:root:current mean train loss 2119.833506311089
INFO:root:current train perplexity5.31226110458374
INFO:root:current mean train loss 2182.6266855393724
INFO:root:current train perplexity5.588066101074219
INFO:root:current mean train loss 2346.7646523171466
INFO:root:current train perplexity6.361076831817627
INFO:root:current mean train loss 2469.158680456008
INFO:root:current train perplexity7.009153842926025
INFO:root:current mean train loss 2562.7891261888585
INFO:root:current train perplexity7.544088840484619
INFO:root:current mean train loss 2644.855754235354
INFO:root:current train perplexity8.04679012298584
INFO:root:current mean train loss 2697.3361715395686
INFO:root:current train perplexity8.396384239196777
INFO:root:current mean train loss 2744.0567466962348
INFO:root:current train perplexity8.724507331848145
INFO:root:current mean train loss 2782.7587806552265
INFO:root:current train perplexity8.991189956665039
INFO:root:current mean train loss 2804.9012719093434
INFO:root:current train perplexity9.151008605957031
INFO:root:current mean train loss 2819.509661346018
INFO:root:current train perplexity9.259568214416504
INFO:root:current mean train loss 2833.965868290725
INFO:root:current train perplexity9.36350154876709
INFO:root:current mean train loss 2841.717155103668
INFO:root:current train perplexity9.418314933776855
INFO:root:current mean train loss 2846.8164986808274
INFO:root:current train perplexity9.450185775756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.76s/it]
INFO:root:final mean train loss: 2845.828565450371
INFO:root:final train perplexity: 9.449119567871094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.16s/it]
INFO:root:eval mean loss: 2437.6284456726507
INFO:root:eval perplexity: 7.189092636108398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.02s/it]
INFO:root:eval mean loss: 2848.4822803253824
INFO:root:eval perplexity: 10.400137901306152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [11:36:41<37:16:54, 877.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2916.292891521843
INFO:root:current train perplexity9.960063934326172
INFO:root:current mean train loss 2877.1822965988003
INFO:root:current train perplexity9.710248947143555
INFO:root:current mean train loss 2881.260374338035
INFO:root:current train perplexity9.702207565307617
INFO:root:current mean train loss 2867.2799428048447
INFO:root:current train perplexity9.613924026489258
INFO:root:current mean train loss 2868.6094882459524
INFO:root:current train perplexity9.624424934387207
INFO:root:current mean train loss 2872.0503819698474
INFO:root:current train perplexity9.671238899230957
INFO:root:current mean train loss 2880.812556313239
INFO:root:current train perplexity9.738174438476562
INFO:root:current mean train loss 2887.304921544584
INFO:root:current train perplexity9.780074119567871
INFO:root:current mean train loss 2889.130554063283
INFO:root:current train perplexity9.786481857299805
INFO:root:current mean train loss 2883.39440453172
INFO:root:current train perplexity9.74692440032959
INFO:root:current mean train loss 2872.1274507449625
INFO:root:current train perplexity9.656668663024902
INFO:root:current mean train loss 2853.8899632933144
INFO:root:current train perplexity9.519981384277344
INFO:root:current mean train loss 2841.431837555073
INFO:root:current train perplexity9.399933815002441
INFO:root:current mean train loss 2824.859448870876
INFO:root:current train perplexity9.275915145874023
INFO:root:current mean train loss 2808.081773093291
INFO:root:current train perplexity9.15896224975586
INFO:root:current mean train loss 2791.9735947705626
INFO:root:current train perplexity9.041000366210938
INFO:root:current mean train loss 2774.5284536696436
INFO:root:current train perplexity8.924659729003906
INFO:root:current mean train loss 2757.7241409861867
INFO:root:current train perplexity8.810141563415527
INFO:root:current mean train loss 2743.744929772911
INFO:root:current train perplexity8.709066390991211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.57s/it]
INFO:root:final mean train loss: 2729.518733822452
INFO:root:final train perplexity: 8.620388984680176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.12s/it]
INFO:root:eval mean loss: 2118.7315063476562
INFO:root:eval perplexity: 5.553946495056152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.82s/it]
INFO:root:eval mean loss: 2555.8369240185893
INFO:root:eval perplexity: 8.176194190979004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/48
 24%|â–ˆâ–ˆâ–       | 48/200 [11:51:18<37:02:07, 877.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2366.41396484375
INFO:root:current train perplexity6.737443447113037
INFO:root:current mean train loss 2427.7525093410327
INFO:root:current train perplexity6.832168102264404
INFO:root:current mean train loss 2412.4922476835027
INFO:root:current train perplexity6.731229782104492
INFO:root:current mean train loss 2431.9089518229166
INFO:root:current train perplexity6.8235883712768555
INFO:root:current mean train loss 2433.466673333961
INFO:root:current train perplexity6.813017845153809
INFO:root:current mean train loss 2429.131994036332
INFO:root:current train perplexity6.8215012550354
INFO:root:current mean train loss 2429.8875867393926
INFO:root:current train perplexity6.82241153717041
INFO:root:current mean train loss 2418.2104883153957
INFO:root:current train perplexity6.762353420257568
INFO:root:current mean train loss 2403.6945308006616
INFO:root:current train perplexity6.682008266448975
INFO:root:current mean train loss 2380.708309586322
INFO:root:current train perplexity6.547425746917725
INFO:root:current mean train loss 2350.796573011276
INFO:root:current train perplexity6.396642208099365
INFO:root:current mean train loss 2366.11945516133
INFO:root:current train perplexity6.478126525878906
INFO:root:current mean train loss 2342.9690791377316
INFO:root:current train perplexity6.363650798797607
INFO:root:current mean train loss 2335.518539463522
INFO:root:current train perplexity6.317322254180908
INFO:root:current mean train loss 2348.2886792078457
INFO:root:current train perplexity6.375011920928955
INFO:root:current mean train loss 2383.157433719446
INFO:root:current train perplexity6.553632736206055
INFO:root:current mean train loss 2414.430712210357
INFO:root:current train perplexity6.718005180358887
INFO:root:current mean train loss 2438.6438575499956
INFO:root:current train perplexity6.847159385681152
INFO:root:current mean train loss 2454.371233306969
INFO:root:current train perplexity6.936667442321777
INFO:root:current mean train loss 2468.7673991947822
INFO:root:current train perplexity7.016408443450928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.70s/it]
INFO:root:final mean train loss: 2477.1636738202455
INFO:root:final train perplexity: 7.063722133636475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.92s/it]
INFO:root:eval mean loss: 2313.1611622478945
INFO:root:eval perplexity: 6.500270843505859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.12s/it]
INFO:root:eval mean loss: 2761.544989836131
INFO:root:eval perplexity: 9.682743072509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/49
 24%|â–ˆâ–ˆâ–       | 49/200 [12:05:55<36:47:31, 877.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2640.770767211914
INFO:root:current train perplexity7.948403835296631
INFO:root:current mean train loss 2658.0338856090198
INFO:root:current train perplexity8.162517547607422
INFO:root:current mean train loss 2628.185270112136
INFO:root:current train perplexity8.005987167358398
INFO:root:current mean train loss 2617.281395601939
INFO:root:current train perplexity7.907373905181885
INFO:root:current mean train loss 2598.14399267126
INFO:root:current train perplexity7.762185573577881
INFO:root:current mean train loss 2585.21470837127
INFO:root:current train perplexity7.67230224609375
INFO:root:current mean train loss 2621.262591398215
INFO:root:current train perplexity7.9125075340271
INFO:root:current mean train loss 2702.3007785817963
INFO:root:current train perplexity8.417144775390625
INFO:root:current mean train loss 2783.189496260423
INFO:root:current train perplexity8.989860534667969
INFO:root:current mean train loss 2852.5720131018643
INFO:root:current train perplexity9.49033260345459
INFO:root:current mean train loss 2894.8916450914485
INFO:root:current train perplexity9.80090045928955
INFO:root:current mean train loss 2912.4013316016317
INFO:root:current train perplexity9.927655220031738
INFO:root:current mean train loss 2896.7247288691533
INFO:root:current train perplexity9.808144569396973
INFO:root:current mean train loss 2872.9230385170326
INFO:root:current train perplexity9.621991157531738
INFO:root:current mean train loss 2847.031573418132
INFO:root:current train perplexity9.431496620178223
INFO:root:current mean train loss 2829.7498734675873
INFO:root:current train perplexity9.308788299560547
INFO:root:current mean train loss 2807.4723752339683
INFO:root:current train perplexity9.15365982055664
INFO:root:current mean train loss 2779.8753010879764
INFO:root:current train perplexity8.96059799194336
INFO:root:current mean train loss 2756.494202859537
INFO:root:current train perplexity8.79615306854248
INFO:root:current mean train loss 2730.241295476878
INFO:root:current train perplexity8.624467849731445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.44s/it]
INFO:root:final mean train loss: 2717.704872981623
INFO:root:final train perplexity: 8.54039192199707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.05s/it]
INFO:root:eval mean loss: 2102.745130606577
INFO:root:eval perplexity: 5.482560634613037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it]
INFO:root:eval mean loss: 2527.220093206311
INFO:root:eval perplexity: 7.986082553863525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [12:20:31<36:31:48, 876.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2240.4611716757017
INFO:root:current train perplexity5.765687465667725
INFO:root:current mean train loss 2213.991657436294
INFO:root:current train perplexity5.699118614196777
INFO:root:current mean train loss 2210.158693857461
INFO:root:current train perplexity5.688310623168945
INFO:root:current mean train loss 2205.673062824588
INFO:root:current train perplexity5.684273719787598
INFO:root:current mean train loss 2208.1007017547677
INFO:root:current train perplexity5.691373825073242
INFO:root:current mean train loss 2207.452991145122
INFO:root:current train perplexity5.684911727905273
INFO:root:current mean train loss 2205.4228888042903
INFO:root:current train perplexity5.683705806732178
INFO:root:current mean train loss 2205.3440433598967
INFO:root:current train perplexity5.67726469039917
INFO:root:current mean train loss 2207.828845488028
INFO:root:current train perplexity5.685538291931152
INFO:root:current mean train loss 2207.750725733091
INFO:root:current train perplexity5.684385299682617
INFO:root:current mean train loss 2204.865472348107
INFO:root:current train perplexity5.675886154174805
INFO:root:current mean train loss 2205.9172757433435
INFO:root:current train perplexity5.685406684875488
INFO:root:current mean train loss 2206.3451330400258
INFO:root:current train perplexity5.692334175109863
INFO:root:current mean train loss 2209.130513524196
INFO:root:current train perplexity5.703456401824951
INFO:root:current mean train loss 2208.920617987486
INFO:root:current train perplexity5.7107415199279785
INFO:root:current mean train loss 2209.7962198866962
INFO:root:current train perplexity5.719668388366699
INFO:root:current mean train loss 2210.142745203651
INFO:root:current train perplexity5.725074768066406
INFO:root:current mean train loss 2209.5220479643503
INFO:root:current train perplexity5.720914840698242
INFO:root:current mean train loss 2208.783113668389
INFO:root:current train perplexity5.7190375328063965
INFO:root:current mean train loss 2209.5665848146286
INFO:root:current train perplexity5.719569206237793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.66s/it]
INFO:root:final mean train loss: 2209.732856169531
INFO:root:final train perplexity: 5.719699382781982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.35s/it]
INFO:root:eval mean loss: 2078.0611234624334
INFO:root:eval perplexity: 5.374135494232178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.36s/it]
INFO:root:eval mean loss: 2498.9806505568486
INFO:root:eval perplexity: 7.8028059005737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [12:35:02<36:12:47, 874.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2201.668875029593
INFO:root:current train perplexity5.590521335601807
INFO:root:current mean train loss 2207.0338333313725
INFO:root:current train perplexity5.661805629730225
INFO:root:current mean train loss 2197.7974408372006
INFO:root:current train perplexity5.628589153289795
INFO:root:current mean train loss 2186.46408898192
INFO:root:current train perplexity5.597405910491943
INFO:root:current mean train loss 2186.08459603633
INFO:root:current train perplexity5.59086799621582
INFO:root:current mean train loss 2183.5015278199535
INFO:root:current train perplexity5.5947394371032715
INFO:root:current mean train loss 2176.1495069899
INFO:root:current train perplexity5.566514492034912
INFO:root:current mean train loss 2166.77648208658
INFO:root:current train perplexity5.532807350158691
INFO:root:current mean train loss 2185.232000690134
INFO:root:current train perplexity5.6107378005981445
INFO:root:current mean train loss 2169.1437724174675
INFO:root:current train perplexity5.544990539550781
INFO:root:current mean train loss 2164.389572859258
INFO:root:current train perplexity5.527754306793213
INFO:root:current mean train loss 2154.295701722134
INFO:root:current train perplexity5.494571685791016
INFO:root:current mean train loss 2148.7984994222393
INFO:root:current train perplexity5.462082862854004
INFO:root:current mean train loss 2143.682004512491
INFO:root:current train perplexity5.439809799194336
INFO:root:current mean train loss 2137.47977338221
INFO:root:current train perplexity5.409300327301025
INFO:root:current mean train loss 2131.5274287159264
INFO:root:current train perplexity5.3860344886779785
INFO:root:current mean train loss 2127.0497363984655
INFO:root:current train perplexity5.361924648284912
INFO:root:current mean train loss 2127.289977197874
INFO:root:current train perplexity5.362171649932861
INFO:root:current mean train loss 2146.394062463366
INFO:root:current train perplexity5.442242622375488
INFO:root:current mean train loss 2174.5103724994833
INFO:root:current train perplexity5.559986114501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.02s/it]
INFO:root:final mean train loss: 2177.38104589696
INFO:root:final train perplexity: 5.5755133628845215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it]
INFO:root:eval mean loss: 2452.2872708367963
INFO:root:eval perplexity: 7.274877548217773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.14s/it]
INFO:root:eval mean loss: 2853.620313279172
INFO:root:eval perplexity: 10.444158554077148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [12:49:43<36:02:41, 876.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2682.6409603256775
INFO:root:current train perplexity8.368451118469238
INFO:root:current mean train loss 2713.401800770577
INFO:root:current train perplexity8.56020450592041
INFO:root:current mean train loss 2704.7856221013694
INFO:root:current train perplexity8.497756958007812
INFO:root:current mean train loss 2695.6942881292834
INFO:root:current train perplexity8.432382583618164
INFO:root:current mean train loss 2678.214229607434
INFO:root:current train perplexity8.327116966247559
INFO:root:current mean train loss 2644.3597659181364
INFO:root:current train perplexity8.090078353881836
INFO:root:current mean train loss 2604.6554264275255
INFO:root:current train perplexity7.834650993347168
INFO:root:current mean train loss 2574.129927711925
INFO:root:current train perplexity7.638521671295166
INFO:root:current mean train loss 2552.0958774519127
INFO:root:current train perplexity7.505373954772949
INFO:root:current mean train loss 2532.721063251049
INFO:root:current train perplexity7.39628791809082
INFO:root:current mean train loss 2518.541300343014
INFO:root:current train perplexity7.3158345222473145
INFO:root:current mean train loss 2507.299744529434
INFO:root:current train perplexity7.245895862579346
INFO:root:current mean train loss 2497.744219690027
INFO:root:current train perplexity7.186868667602539
INFO:root:current mean train loss 2489.4096428132625
INFO:root:current train perplexity7.133738994598389
INFO:root:current mean train loss 2483.7294644479884
INFO:root:current train perplexity7.101258754730225
INFO:root:current mean train loss 2481.339063826348
INFO:root:current train perplexity7.087806701660156
INFO:root:current mean train loss 2479.899986480151
INFO:root:current train perplexity7.078358173370361
INFO:root:current mean train loss 2479.8412152096184
INFO:root:current train perplexity7.075521945953369
INFO:root:current mean train loss 2477.457635183633
INFO:root:current train perplexity7.063296318054199
INFO:root:current mean train loss 2474.864197239032
INFO:root:current train perplexity7.050914287567139

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.42s/it]
INFO:root:final mean train loss: 2474.864197239032
INFO:root:final train perplexity: 7.050914287567139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.46s/it]
INFO:root:eval mean loss: 2141.0752701996066
INFO:root:eval perplexity: 5.655280590057373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.01s/it]
INFO:root:eval mean loss: 2560.044674704261
INFO:root:eval perplexity: 8.20452880859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [13:04:31<35:56:41, 880.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2411.9685473632812
INFO:root:current train perplexity6.760460376739502
INFO:root:current mean train loss 2393.65296875
INFO:root:current train perplexity6.600831985473633
INFO:root:current mean train loss 2365.125048014323
INFO:root:current train perplexity6.44289493560791
INFO:root:current mean train loss 2343.0387371826173
INFO:root:current train perplexity6.3449907302856445
INFO:root:current mean train loss 2324.579084472656
INFO:root:current train perplexity6.254323959350586
INFO:root:current mean train loss 2318.9340865071613
INFO:root:current train perplexity6.210679054260254
INFO:root:current mean train loss 2313.6406487165177
INFO:root:current train perplexity6.187410831451416
INFO:root:current mean train loss 2331.3506791687014
INFO:root:current train perplexity6.285661697387695
INFO:root:current mean train loss 2303.215716281467
INFO:root:current train perplexity6.149906635284424
INFO:root:current mean train loss 2321.6164454345703
INFO:root:current train perplexity6.244254112243652
INFO:root:current mean train loss 2309.2342449396306
INFO:root:current train perplexity6.1833014488220215
INFO:root:current mean train loss 2295.2134196980796
INFO:root:current train perplexity6.1120500564575195
INFO:root:current mean train loss 2279.8639211801383
INFO:root:current train perplexity6.0379414558410645
INFO:root:current mean train loss 2264.44944745745
INFO:root:current train perplexity5.964332103729248
INFO:root:current mean train loss 2249.339544108073
INFO:root:current train perplexity5.895664691925049
INFO:root:current mean train loss 2234.7405474090574
INFO:root:current train perplexity5.833914279937744
INFO:root:current mean train loss 2222.1491065889245
INFO:root:current train perplexity5.778883457183838
INFO:root:current mean train loss 2210.9059134250215
INFO:root:current train perplexity5.726850986480713
INFO:root:current mean train loss 2201.2541004060445
INFO:root:current train perplexity5.683461666107178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.75s/it]
INFO:root:final mean train loss: 2194.3432734148464
INFO:root:final train perplexity: 5.650651454925537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.74s/it]
INFO:root:eval mean loss: 1967.31655688996
INFO:root:eval perplexity: 4.913475036621094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.11s/it]
INFO:root:eval mean loss: 2399.1631084469195
INFO:root:eval perplexity: 7.188056468963623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [13:19:19<35:47:40, 882.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2052.0249669692093
INFO:root:current train perplexity4.832404613494873
INFO:root:current mean train loss 2025.450180705796
INFO:root:current train perplexity4.8634562492370605
INFO:root:current mean train loss 2013.8453408518146
INFO:root:current train perplexity4.8629889488220215
INFO:root:current mean train loss 2010.2279145153539
INFO:root:current train perplexity4.861639499664307
INFO:root:current mean train loss 2010.4385386222273
INFO:root:current train perplexity4.865884780883789
INFO:root:current mean train loss 2006.1020656563558
INFO:root:current train perplexity4.863328456878662
INFO:root:current mean train loss 2003.75680131464
INFO:root:current train perplexity4.853306770324707
INFO:root:current mean train loss 2004.3920755426254
INFO:root:current train perplexity4.858780384063721
INFO:root:current mean train loss 2003.2489635229404
INFO:root:current train perplexity4.856164455413818
INFO:root:current mean train loss 2002.4401110001193
INFO:root:current train perplexity4.855712890625
INFO:root:current mean train loss 2000.6368647062438
INFO:root:current train perplexity4.850229263305664
INFO:root:current mean train loss 2002.4515872637714
INFO:root:current train perplexity4.8513407707214355
INFO:root:current mean train loss 2002.8154579733077
INFO:root:current train perplexity4.851338863372803
INFO:root:current mean train loss 2001.9494039409524
INFO:root:current train perplexity4.847071170806885
INFO:root:current mean train loss 2001.9926552782617
INFO:root:current train perplexity4.8485565185546875
INFO:root:current mean train loss 1999.581508045536
INFO:root:current train perplexity4.844017505645752
INFO:root:current mean train loss 1999.4523558890885
INFO:root:current train perplexity4.842926502227783
INFO:root:current mean train loss 1998.361499250942
INFO:root:current train perplexity4.843088626861572
INFO:root:current mean train loss 1998.3089334910953
INFO:root:current train perplexity4.840286731719971
INFO:root:current mean train loss 1998.9041095349587
INFO:root:current train perplexity4.839641571044922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.04s/it]
INFO:root:final mean train loss: 1998.7203254949789
INFO:root:final train perplexity: 4.842280387878418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.04s/it]
INFO:root:eval mean loss: 1956.212293259641
INFO:root:eval perplexity: 4.8695220947265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.94s/it]
INFO:root:eval mean loss: 2390.1591299070533
INFO:root:eval perplexity: 7.135042190551758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [13:34:07<35:36:30, 884.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2005.4780309340533
INFO:root:current train perplexity4.872600078582764
INFO:root:current mean train loss 1980.0397184001865
INFO:root:current train perplexity4.81461238861084
INFO:root:current mean train loss 1988.0408158261553
INFO:root:current train perplexity4.796934127807617
INFO:root:current mean train loss 1987.7202221533496
INFO:root:current train perplexity4.790494918823242
INFO:root:current mean train loss 1983.5930780507451
INFO:root:current train perplexity4.780331134796143
INFO:root:current mean train loss 1982.4020072565543
INFO:root:current train perplexity4.776149749755859
INFO:root:current mean train loss 1982.38787495225
INFO:root:current train perplexity4.778985023498535
INFO:root:current mean train loss 1984.8247597509899
INFO:root:current train perplexity4.789478778839111
INFO:root:current mean train loss 1985.0625242969686
INFO:root:current train perplexity4.797952651977539
INFO:root:current mean train loss 1985.5445744843248
INFO:root:current train perplexity4.798793792724609
INFO:root:current mean train loss 1987.4212607525765
INFO:root:current train perplexity4.806642532348633
INFO:root:current mean train loss 1988.6576472422014
INFO:root:current train perplexity4.805694580078125
INFO:root:current mean train loss 1987.023583014935
INFO:root:current train perplexity4.800973892211914
INFO:root:current mean train loss 1988.7379095486438
INFO:root:current train perplexity4.805932998657227
INFO:root:current mean train loss 1989.95596854025
INFO:root:current train perplexity4.80723237991333
INFO:root:current mean train loss 1988.950978504166
INFO:root:current train perplexity4.804561614990234
INFO:root:current mean train loss 1989.7376076967946
INFO:root:current train perplexity4.804898738861084
INFO:root:current mean train loss 1990.3181383249532
INFO:root:current train perplexity4.8049702644348145
INFO:root:current mean train loss 1989.7200390598375
INFO:root:current train perplexity4.805749893188477
INFO:root:current mean train loss 1989.2644160999507
INFO:root:current train perplexity4.8048248291015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.92s/it]
INFO:root:final mean train loss: 1988.4334695559226
INFO:root:final train perplexity: 4.803127765655518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.02s/it]
INFO:root:eval mean loss: 1943.716921542553
INFO:root:eval perplexity: 4.82053279876709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.27s/it]
INFO:root:eval mean loss: 2378.6539878033577
INFO:root:eval perplexity: 7.067873954772949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [13:48:55<35:25:09, 885.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1975.1640337775734
INFO:root:current train perplexity4.81281852722168
INFO:root:current mean train loss 1985.2494834243066
INFO:root:current train perplexity4.802030086517334
INFO:root:current mean train loss 1993.872677259711
INFO:root:current train perplexity4.810240745544434
INFO:root:current mean train loss 1992.4229680683538
INFO:root:current train perplexity4.806018352508545
INFO:root:current mean train loss 1989.0158399087097
INFO:root:current train perplexity4.798369884490967
INFO:root:current mean train loss 1986.027577699637
INFO:root:current train perplexity4.785512924194336
INFO:root:current mean train loss 1986.7712535477272
INFO:root:current train perplexity4.78698205947876
INFO:root:current mean train loss 1984.7545180644556
INFO:root:current train perplexity4.785148620605469
INFO:root:current mean train loss 1982.941787522492
INFO:root:current train perplexity4.781225681304932
INFO:root:current mean train loss 1981.3476087568185
INFO:root:current train perplexity4.773557186126709
INFO:root:current mean train loss 1980.2836515678891
INFO:root:current train perplexity4.773203372955322
INFO:root:current mean train loss 1981.2592943126901
INFO:root:current train perplexity4.772842884063721
INFO:root:current mean train loss 1982.597073317908
INFO:root:current train perplexity4.77397346496582
INFO:root:current mean train loss 1981.9602170954097
INFO:root:current train perplexity4.769484996795654
INFO:root:current mean train loss 1982.264263297672
INFO:root:current train perplexity4.768733024597168
INFO:root:current mean train loss 1981.8674407703195
INFO:root:current train perplexity4.771146297454834
INFO:root:current mean train loss 1980.0977913332592
INFO:root:current train perplexity4.76842737197876
INFO:root:current mean train loss 1980.0413110755908
INFO:root:current train perplexity4.769667148590088
INFO:root:current mean train loss 1980.8723567259885
INFO:root:current train perplexity4.7704596519470215
INFO:root:current mean train loss 1980.9303027318722
INFO:root:current train perplexity4.770642280578613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.38s/it]
INFO:root:final mean train loss: 1979.4687564636322
INFO:root:final train perplexity: 4.769266128540039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.48s/it]
INFO:root:eval mean loss: 1939.4120522357048
INFO:root:eval perplexity: 4.803769588470459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.95s/it]
INFO:root:eval mean loss: 2373.1424196933176
INFO:root:eval perplexity: 7.035920143127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [14:03:42<35:10:59, 885.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1984.5671997070312
INFO:root:current train perplexity4.775862693786621
INFO:root:current mean train loss 1970.743179321289
INFO:root:current train perplexity4.758607864379883
INFO:root:current mean train loss 1980.773662965689
INFO:root:current train perplexity4.785337924957275
INFO:root:current mean train loss 1978.669266410496
INFO:root:current train perplexity4.783877849578857
INFO:root:current mean train loss 1984.4434861403245
INFO:root:current train perplexity4.78770112991333
INFO:root:current mean train loss 1984.9153556286449
INFO:root:current train perplexity4.775723457336426
INFO:root:current mean train loss 1984.4020444218984
INFO:root:current train perplexity4.7752156257629395
INFO:root:current mean train loss 1983.210698445638
INFO:root:current train perplexity4.773110389709473
INFO:root:current mean train loss 1982.06198499829
INFO:root:current train perplexity4.775416374206543
INFO:root:current mean train loss 1982.3639455747998
INFO:root:current train perplexity4.775832176208496
INFO:root:current mean train loss 1981.8039868529816
INFO:root:current train perplexity4.775667190551758
INFO:root:current mean train loss 1980.769391308092
INFO:root:current train perplexity4.7743449211120605
INFO:root:current mean train loss 1981.8431867244492
INFO:root:current train perplexity4.7742228507995605
INFO:root:current mean train loss 1983.354626304225
INFO:root:current train perplexity4.775339126586914
INFO:root:current mean train loss 1983.2073893949837
INFO:root:current train perplexity4.775118350982666
INFO:root:current mean train loss 1984.3195201328822
INFO:root:current train perplexity4.77977991104126
INFO:root:current mean train loss 1984.4961198765598
INFO:root:current train perplexity4.782158851623535
INFO:root:current mean train loss 1983.5511514655066
INFO:root:current train perplexity4.779295444488525
INFO:root:current mean train loss 1983.4165076964416
INFO:root:current train perplexity4.780779838562012
INFO:root:current mean train loss 1983.5598480100555
INFO:root:current train perplexity4.78236722946167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.32s/it]
INFO:root:final mean train loss: 1983.085204616437
INFO:root:final train perplexity: 4.782896995544434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.75s/it]
INFO:root:eval mean loss: 1944.9459414651208
INFO:root:eval perplexity: 4.825328826904297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.80s/it]
INFO:root:eval mean loss: 2379.551202002992
INFO:root:eval perplexity: 7.073088645935059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [14:18:28<34:56:43, 885.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.2684512867647
INFO:root:current train perplexity4.829487323760986
INFO:root:current mean train loss 1977.4298669763514
INFO:root:current train perplexity4.771488666534424
INFO:root:current mean train loss 1979.3248732182017
INFO:root:current train perplexity4.776105880737305
INFO:root:current mean train loss 1981.9616591416395
INFO:root:current train perplexity4.777879238128662
INFO:root:current mean train loss 1989.7595859173648
INFO:root:current train perplexity4.792563438415527
INFO:root:current mean train loss 1987.8827930939503
INFO:root:current train perplexity4.795926094055176
INFO:root:current mean train loss 1986.8425909557482
INFO:root:current train perplexity4.789151668548584
INFO:root:current mean train loss 1988.1248889704418
INFO:root:current train perplexity4.790369510650635
INFO:root:current mean train loss 1990.604921709481
INFO:root:current train perplexity4.802009582519531
INFO:root:current mean train loss 1991.623613603466
INFO:root:current train perplexity4.808279037475586
INFO:root:current mean train loss 1995.93469890823
INFO:root:current train perplexity4.820586204528809
INFO:root:current mean train loss 1995.6572393361023
INFO:root:current train perplexity4.820638656616211
INFO:root:current mean train loss 1995.0366056093446
INFO:root:current train perplexity4.824941635131836
INFO:root:current mean train loss 1995.2080108973094
INFO:root:current train perplexity4.825376987457275
INFO:root:current mean train loss 1995.7099001900515
INFO:root:current train perplexity4.824484825134277
INFO:root:current mean train loss 1995.8543778958006
INFO:root:current train perplexity4.826286315917969
INFO:root:current mean train loss 1997.152148944617
INFO:root:current train perplexity4.832343578338623
INFO:root:current mean train loss 1997.036414155506
INFO:root:current train perplexity4.832467079162598
INFO:root:current mean train loss 1997.250296012413
INFO:root:current train perplexity4.834920883178711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.52s/it]
INFO:root:final mean train loss: 1996.8093784965172
INFO:root:final train perplexity: 4.8349833488464355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.93s/it]
INFO:root:eval mean loss: 1967.8476878497618
INFO:root:eval perplexity: 4.915587902069092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.89s/it]
INFO:root:eval mean loss: 2401.589179289256
INFO:root:eval perplexity: 7.202407360076904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [14:33:08<34:37:44, 884.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.3692626953125
INFO:root:current train perplexity5.153426170349121
INFO:root:current mean train loss 1990.7207162894454
INFO:root:current train perplexity4.845598220825195
INFO:root:current mean train loss 1985.8296321453433
INFO:root:current train perplexity4.819435119628906
INFO:root:current mean train loss 1984.6889632269247
INFO:root:current train perplexity4.817234992980957
INFO:root:current mean train loss 2007.3638159908467
INFO:root:current train perplexity4.896236896514893
INFO:root:current mean train loss 2055.422767669556
INFO:root:current train perplexity5.0783867835998535
INFO:root:current mean train loss 2138.333337726783
INFO:root:current train perplexity5.424622058868408
INFO:root:current mean train loss 2246.6251215486445
INFO:root:current train perplexity5.898589134216309
INFO:root:current mean train loss 2330.913062649772
INFO:root:current train perplexity6.307987213134766
INFO:root:current mean train loss 2434.7450677909765
INFO:root:current train perplexity6.852859973907471
INFO:root:current mean train loss 2455.132277315486
INFO:root:current train perplexity6.964197158813477
INFO:root:current mean train loss 2466.848822342722
INFO:root:current train perplexity7.0113091468811035
INFO:root:current mean train loss 2474.881494404671
INFO:root:current train perplexity7.054680824279785
INFO:root:current mean train loss 2482.609398532756
INFO:root:current train perplexity7.102423667907715
INFO:root:current mean train loss 2496.585390099105
INFO:root:current train perplexity7.181998252868652
INFO:root:current mean train loss 2507.1040511251927
INFO:root:current train perplexity7.242048263549805
INFO:root:current mean train loss 2520.1721941963415
INFO:root:current train perplexity7.311782360076904
INFO:root:current mean train loss 2529.6165295969586
INFO:root:current train perplexity7.361212253570557
INFO:root:current mean train loss 2539.9793735720077
INFO:root:current train perplexity7.412861347198486
INFO:root:current mean train loss 2548.736640874018
INFO:root:current train perplexity7.468456268310547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:58<00:00, 778.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:58<00:00, 778.08s/it]
INFO:root:final mean train loss: 2554.9108405947627
INFO:root:final train perplexity: 7.5107102394104
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.92s/it]
INFO:root:eval mean loss: 2389.910976112312
INFO:root:eval perplexity: 6.916784763336182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it]
INFO:root:eval mean loss: 2820.44423680948
INFO:root:eval perplexity: 10.163146018981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [14:48:06<34:32:39, 888.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2738.5373021175988
INFO:root:current train perplexity8.857621192932129
INFO:root:current mean train loss 2757.142842781644
INFO:root:current train perplexity8.779975891113281
INFO:root:current mean train loss 2758.286040284318
INFO:root:current train perplexity8.749746322631836
INFO:root:current mean train loss 2766.7141434720315
INFO:root:current train perplexity8.821889877319336
INFO:root:current mean train loss 2774.178994117318
INFO:root:current train perplexity8.849536895751953
INFO:root:current mean train loss 2783.7823356966524
INFO:root:current train perplexity8.944515228271484
INFO:root:current mean train loss 2792.8049714761714
INFO:root:current train perplexity8.996641159057617
INFO:root:current mean train loss 2802.0555438597444
INFO:root:current train perplexity9.07498550415039
INFO:root:current mean train loss 2810.7845174302693
INFO:root:current train perplexity9.141247749328613
INFO:root:current mean train loss 2818.5049022056073
INFO:root:current train perplexity9.198988914489746
INFO:root:current mean train loss 2825.4865626820874
INFO:root:current train perplexity9.264016151428223
INFO:root:current mean train loss 2833.5813976625336
INFO:root:current train perplexity9.330316543579102
INFO:root:current mean train loss 2842.50841313801
INFO:root:current train perplexity9.396120071411133
INFO:root:current mean train loss 2849.259085770174
INFO:root:current train perplexity9.448383331298828
INFO:root:current mean train loss 2853.888500167922
INFO:root:current train perplexity9.48682689666748
INFO:root:current mean train loss 2855.067999834132
INFO:root:current train perplexity9.503554344177246
INFO:root:current mean train loss 2857.1423611278665
INFO:root:current train perplexity9.525503158569336
INFO:root:current mean train loss 2861.0872498091185
INFO:root:current train perplexity9.558077812194824
INFO:root:current mean train loss 2864.5108754649277
INFO:root:current train perplexity9.584656715393066
INFO:root:current mean train loss 2867.167223733064
INFO:root:current train perplexity9.602598190307617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.80s/it]
INFO:root:final mean train loss: 2868.51467232216
INFO:root:final train perplexity: 9.619818687438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.77s/it]
INFO:root:eval mean loss: 2511.0799924160574
INFO:root:eval perplexity: 7.62935209274292
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.22s/it]
INFO:root:eval mean loss: 2924.8144496620125
INFO:root:eval perplexity: 11.073711395263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [15:02:57<34:19:53, 889.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2925.90084499783
INFO:root:current train perplexity10.33066463470459
INFO:root:current mean train loss 2930.1828720990347
INFO:root:current train perplexity10.161721229553223
INFO:root:current mean train loss 2935.7395785056938
INFO:root:current train perplexity10.142616271972656
INFO:root:current mean train loss 2934.6209084647044
INFO:root:current train perplexity10.11678409576416
INFO:root:current mean train loss 2934.997451082282
INFO:root:current train perplexity10.133979797363281
INFO:root:current mean train loss 2930.9789966184703
INFO:root:current train perplexity10.148520469665527
INFO:root:current mean train loss 2928.3210153639693
INFO:root:current train perplexity10.129141807556152
INFO:root:current mean train loss 2934.053695346998
INFO:root:current train perplexity10.160027503967285
INFO:root:current mean train loss 2933.842654579564
INFO:root:current train perplexity10.177083015441895
INFO:root:current mean train loss 2937.684284438435
INFO:root:current train perplexity10.216693878173828
INFO:root:current mean train loss 2942.943927543964
INFO:root:current train perplexity10.24574089050293
INFO:root:current mean train loss 2949.201968125894
INFO:root:current train perplexity10.290818214416504
INFO:root:current mean train loss 2954.2867431640625
INFO:root:current train perplexity10.326621055603027
INFO:root:current mean train loss 2961.405125783589
INFO:root:current train perplexity10.366259574890137
INFO:root:current mean train loss 2968.6361486918413
INFO:root:current train perplexity10.419779777526855
INFO:root:current mean train loss 2973.1901483535767
INFO:root:current train perplexity10.462913513183594
INFO:root:current mean train loss 2979.862554648103
INFO:root:current train perplexity10.50668716430664
INFO:root:current mean train loss 2985.1440283428137
INFO:root:current train perplexity10.552749633789062
INFO:root:current mean train loss 2988.5958690767975
INFO:root:current train perplexity10.583885192871094
INFO:root:current mean train loss 2995.28668729924
INFO:root:current train perplexity10.62551212310791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.60s/it]
INFO:root:final mean train loss: 2996.583929033996
INFO:root:final train perplexity: 10.642948150634766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.27s/it]
INFO:root:eval mean loss: 2618.394438615082
INFO:root:eval perplexity: 8.321508407592773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.30s/it]
INFO:root:eval mean loss: 3018.585372167276
INFO:root:eval perplexity: 11.961167335510254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [15:17:48<34:06:05, 889.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3063.425283755896
INFO:root:current train perplexity11.4075927734375
INFO:root:current mean train loss 3081.510954414318
INFO:root:current train perplexity11.37327766418457
INFO:root:current mean train loss 3080.726678297925
INFO:root:current train perplexity11.367541313171387
INFO:root:current mean train loss 3084.4645933848265
INFO:root:current train perplexity11.433021545410156
INFO:root:current mean train loss 3098.3825419512277
INFO:root:current train perplexity11.491632461547852
INFO:root:current mean train loss 3105.5618642631102
INFO:root:current train perplexity11.597896575927734
INFO:root:current mean train loss 3108.559351595401
INFO:root:current train perplexity11.626124382019043
INFO:root:current mean train loss 3104.801073051544
INFO:root:current train perplexity11.592843055725098
INFO:root:current mean train loss 3109.3100356966224
INFO:root:current train perplexity11.624974250793457
INFO:root:current mean train loss 3111.8595499717176
INFO:root:current train perplexity11.628954887390137
INFO:root:current mean train loss 3115.312753878428
INFO:root:current train perplexity11.645058631896973
INFO:root:current mean train loss 3122.699837888931
INFO:root:current train perplexity11.726643562316895
INFO:root:current mean train loss 3127.078872619775
INFO:root:current train perplexity11.781486511230469
INFO:root:current mean train loss 3128.0735151991526
INFO:root:current train perplexity11.787134170532227
INFO:root:current mean train loss 3128.9732450103234
INFO:root:current train perplexity11.795421600341797
INFO:root:current mean train loss 3131.2149663705327
INFO:root:current train perplexity11.825201034545898
INFO:root:current mean train loss 3134.0788274396928
INFO:root:current train perplexity11.850004196166992
INFO:root:current mean train loss 3136.067792684639
INFO:root:current train perplexity11.87037181854248
INFO:root:current mean train loss 3139.0280039705463
INFO:root:current train perplexity11.900655746459961
INFO:root:current mean train loss 3140.5842656430013
INFO:root:current train perplexity11.918194770812988

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.71s/it]
INFO:root:final mean train loss: 3141.094166011685
INFO:root:final train perplexity: 11.928668022155762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.78s/it]
INFO:root:eval mean loss: 2658.833451940658
INFO:root:eval perplexity: 8.598320960998535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.05s/it]
INFO:root:eval mean loss: 3049.381594826989
INFO:root:eval perplexity: 12.267874717712402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [15:32:37<33:50:51, 889.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.0064871651784
INFO:root:current train perplexity12.589503288269043
INFO:root:current mean train loss 3272.8255658318017
INFO:root:current train perplexity13.280383110046387
INFO:root:current mean train loss 3275.599735966435
INFO:root:current train perplexity13.319144248962402
INFO:root:current mean train loss 3286.2783500052788
INFO:root:current train perplexity13.395163536071777
INFO:root:current mean train loss 3277.5843801944816
INFO:root:current train perplexity13.326465606689453
INFO:root:current mean train loss 3291.3389340049343
INFO:root:current train perplexity13.444202423095703
INFO:root:current mean train loss 3292.4979277197995
INFO:root:current train perplexity13.46255874633789
INFO:root:current mean train loss 3293.965994698661
INFO:root:current train perplexity13.458562850952148
INFO:root:current mean train loss 3301.4472468233657
INFO:root:current train perplexity13.546160697937012
INFO:root:current mean train loss 3315.6280819607764
INFO:root:current train perplexity13.697054862976074
INFO:root:current mean train loss 3330.643105651285
INFO:root:current train perplexity13.869932174682617
INFO:root:current mean train loss 3339.970544120593
INFO:root:current train perplexity13.954343795776367
INFO:root:current mean train loss 3354.4253589059426
INFO:root:current train perplexity14.1002197265625
INFO:root:current mean train loss 3364.81784935276
INFO:root:current train perplexity14.236837387084961
INFO:root:current mean train loss 3378.881930438191
INFO:root:current train perplexity14.37597370147705
INFO:root:current mean train loss 3396.5763973551952
INFO:root:current train perplexity14.555865287780762
INFO:root:current mean train loss 3406.7163012841506
INFO:root:current train perplexity14.679097175598145
INFO:root:current mean train loss 3422.570179395083
INFO:root:current train perplexity14.871387481689453
INFO:root:current mean train loss 3438.1333899513284
INFO:root:current train perplexity15.068984031677246
INFO:root:current mean train loss 3456.203862255116
INFO:root:current train perplexity15.281331062316895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.87s/it]
INFO:root:final mean train loss: 3455.967896308072
INFO:root:final train perplexity: 15.293719291687012
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 61.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 61.00s/it]
INFO:root:eval mean loss: 2813.922794423205
INFO:root:eval perplexity: 9.748056411743164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.54s/it]
INFO:root:eval mean loss: 3179.0315911042776
INFO:root:eval perplexity: 13.647725105285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [15:47:28<33:37:00, 889.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.8766191855243
INFO:root:current train perplexity18.341278076171875
INFO:root:current mean train loss 3695.6080498516876
INFO:root:current train perplexity18.403032302856445
INFO:root:current mean train loss 3676.9193825538982
INFO:root:current train perplexity18.120431900024414
INFO:root:current mean train loss 3714.0220527747497
INFO:root:current train perplexity18.66607093811035
INFO:root:current mean train loss 3744.650904473338
INFO:root:current train perplexity19.046188354492188
INFO:root:current mean train loss 3759.6617329742066
INFO:root:current train perplexity19.343387603759766
INFO:root:current mean train loss 3765.048763802652
INFO:root:current train perplexity19.50922966003418
INFO:root:current mean train loss 3764.077050098773
INFO:root:current train perplexity19.50928497314453
INFO:root:current mean train loss 3784.6513850783012
INFO:root:current train perplexity19.81265640258789
INFO:root:current mean train loss 3821.117020781883
INFO:root:current train perplexity20.377702713012695
INFO:root:current mean train loss 3844.4439381702077
INFO:root:current train perplexity20.716358184814453
INFO:root:current mean train loss 3860.966065892876
INFO:root:current train perplexity20.95914077758789
INFO:root:current mean train loss 3863.9715015615893
INFO:root:current train perplexity21.02918243408203
INFO:root:current mean train loss 3870.565987848943
INFO:root:current train perplexity21.140283584594727
INFO:root:current mean train loss 3875.7639596883932
INFO:root:current train perplexity21.244199752807617
INFO:root:current mean train loss 3883.123278708599
INFO:root:current train perplexity21.36420440673828
INFO:root:current mean train loss 3895.894126326782
INFO:root:current train perplexity21.609643936157227
INFO:root:current mean train loss 3914.5079877839516
INFO:root:current train perplexity21.94287109375
INFO:root:current mean train loss 3931.6753169041053
INFO:root:current train perplexity22.234825134277344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.57s/it]
INFO:root:final mean train loss: 3938.2745683894154
INFO:root:final train perplexity: 22.377992630004883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it]
INFO:root:eval mean loss: 3025.7950681862258
INFO:root:eval perplexity: 11.571183204650879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.06s/it]
INFO:root:eval mean loss: 3362.020667975676
INFO:root:eval perplexity: 15.863390922546387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [16:02:05<33:13:48, 886.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4225.940490722656
INFO:root:current train perplexity28.614709854125977
INFO:root:current mean train loss 4127.369774451623
INFO:root:current train perplexity25.780712127685547
INFO:root:current mean train loss 4156.346163880591
INFO:root:current train perplexity26.386497497558594
INFO:root:current mean train loss 4217.0173010575145
INFO:root:current train perplexity27.963722229003906
INFO:root:current mean train loss 4242.541470669284
INFO:root:current train perplexity28.50718879699707
INFO:root:current mean train loss 4248.339734274244
INFO:root:current train perplexity28.692596435546875
INFO:root:current mean train loss 4256.449527967845
INFO:root:current train perplexity28.836471557617188
INFO:root:current mean train loss 4294.020916678689
INFO:root:current train perplexity29.655885696411133
INFO:root:current mean train loss 4308.446954983384
INFO:root:current train perplexity29.997034072875977
INFO:root:current mean train loss 4335.4690873137615
INFO:root:current train perplexity30.607004165649414
INFO:root:current mean train loss 4365.869753165074
INFO:root:current train perplexity31.374135971069336
INFO:root:current mean train loss 4388.2819381935005
INFO:root:current train perplexity31.934280395507812
INFO:root:current mean train loss 4429.551292242006
INFO:root:current train perplexity33.045265197753906
INFO:root:current mean train loss 4468.466065389247
INFO:root:current train perplexity34.08979034423828
INFO:root:current mean train loss 4497.318226523549
INFO:root:current train perplexity34.78955078125
INFO:root:current mean train loss 4532.501807679521
INFO:root:current train perplexity35.796730041503906
INFO:root:current mean train loss 4558.482550946852
INFO:root:current train perplexity36.52040100097656
INFO:root:current mean train loss 4593.962257062885
INFO:root:current train perplexity37.523460388183594
INFO:root:current mean train loss 4621.072815618071
INFO:root:current train perplexity38.343589782714844
INFO:root:current mean train loss 4647.225292045529
INFO:root:current train perplexity39.1209602355957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.93s/it]
INFO:root:final mean train loss: 4661.639367854301
INFO:root:final train perplexity: 39.60501480102539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.38s/it]
INFO:root:eval mean loss: 3515.5441833928967
INFO:root:eval perplexity: 17.198638916015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.24s/it]
INFO:root:eval mean loss: 3797.647600755624
INFO:root:eval perplexity: 22.695234298706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [16:16:55<33:01:38, 887.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5099.0278552827385
INFO:root:current train perplexity57.603790283203125
INFO:root:current mean train loss 5258.163872837035
INFO:root:current train perplexity64.53192138671875
INFO:root:current mean train loss 5262.708169099972
INFO:root:current train perplexity64.48953247070312
INFO:root:current mean train loss 5354.764872042932
INFO:root:current train perplexity68.2783203125
INFO:root:current mean train loss 5425.757149086995
INFO:root:current train perplexity72.36736297607422
INFO:root:current mean train loss 5474.399971696557
INFO:root:current train perplexity75.47809600830078
INFO:root:current mean train loss 5497.596257453955
INFO:root:current train perplexity76.69003295898438
INFO:root:current mean train loss 5530.412302384925
INFO:root:current train perplexity78.80367279052734
INFO:root:current mean train loss 5550.991917488201
INFO:root:current train perplexity79.98749542236328
INFO:root:current mean train loss 5590.653856838694
INFO:root:current train perplexity82.52357482910156
INFO:root:current mean train loss 5605.133367734605
INFO:root:current train perplexity83.41444396972656
INFO:root:current mean train loss 5625.645420697201
INFO:root:current train perplexity84.74516296386719
INFO:root:current mean train loss 5663.364322996647
INFO:root:current train perplexity87.06456756591797
INFO:root:current mean train loss 5693.500640938446
INFO:root:current train perplexity89.15062713623047
INFO:root:current mean train loss 5717.228481950431
INFO:root:current train perplexity90.8500747680664
INFO:root:current mean train loss 5715.821818114111
INFO:root:current train perplexity90.96524810791016
INFO:root:current mean train loss 5725.299667932603
INFO:root:current train perplexity91.7548828125
INFO:root:current mean train loss 5737.864140352629
INFO:root:current train perplexity92.6167984008789
INFO:root:current mean train loss 5752.468436813564
INFO:root:current train perplexity93.54344177246094
INFO:root:current mean train loss 5772.356511145318
INFO:root:current train perplexity95.0269546508789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.48s/it]
INFO:root:final mean train loss: 5776.272768606396
INFO:root:final train perplexity: 95.45184326171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it]
INFO:root:eval mean loss: 4069.024886760306
INFO:root:eval perplexity: 26.915822982788086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.83s/it]
INFO:root:eval mean loss: 4278.4562953651375
INFO:root:eval perplexity: 33.6981086730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [16:31:34<32:41:33, 884.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5940.188566509046
INFO:root:current train perplexity104.69002532958984
INFO:root:current mean train loss 6253.771123471467
INFO:root:current train perplexity137.982177734375
INFO:root:current mean train loss 6167.985749573267
INFO:root:current train perplexity127.8231201171875
INFO:root:current mean train loss 6212.39908324473
INFO:root:current train perplexity133.50645446777344
INFO:root:current mean train loss 6247.409360284674
INFO:root:current train perplexity137.78355407714844
INFO:root:current mean train loss 6321.23665667112
INFO:root:current train perplexity145.50595092773438
INFO:root:current mean train loss 6374.135937346934
INFO:root:current train perplexity151.94773864746094
INFO:root:current mean train loss 6447.507470438474
INFO:root:current train perplexity160.2803192138672
INFO:root:current mean train loss 6532.066505887344
INFO:root:current train perplexity171.7173309326172
INFO:root:current mean train loss 6587.838117066731
INFO:root:current train perplexity180.0183868408203
INFO:root:current mean train loss 6623.451376031129
INFO:root:current train perplexity185.016357421875
INFO:root:current mean train loss 6627.661251235721
INFO:root:current train perplexity185.74366760253906
INFO:root:current mean train loss 6648.402268417432
INFO:root:current train perplexity188.74339294433594
INFO:root:current mean train loss 6676.693508632871
INFO:root:current train perplexity193.8479461669922
INFO:root:current mean train loss 6684.019216481767
INFO:root:current train perplexity195.1119384765625
INFO:root:current mean train loss 6703.091596228869
INFO:root:current train perplexity198.17721557617188
INFO:root:current mean train loss 6731.587626511943
INFO:root:current train perplexity202.94515991210938
INFO:root:current mean train loss 6750.310108882785
INFO:root:current train perplexity206.68606567382812
INFO:root:current mean train loss 6772.393889949163
INFO:root:current train perplexity209.96673583984375
INFO:root:current mean train loss 6823.007859362906
INFO:root:current train perplexity217.8121795654297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.52s/it]
INFO:root:final mean train loss: 6846.824696812555
INFO:root:final train perplexity: 222.18260192871094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.71s/it]
INFO:root:eval mean loss: 6537.9221676224515
INFO:root:eval perplexity: 198.45912170410156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.71s/it]
INFO:root:eval mean loss: 6497.146149330951
INFO:root:eval perplexity: 208.8236846923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [16:46:25<32:30:30, 886.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7788.203542258523
INFO:root:current train perplexity497.4611511230469
INFO:root:current mean train loss 7517.588473412298
INFO:root:current train perplexity395.4875183105469
INFO:root:current mean train loss 7401.189734604779
INFO:root:current train perplexity349.5489807128906
INFO:root:current mean train loss 7467.632126155369
INFO:root:current train perplexity363.1773376464844
INFO:root:current mean train loss 7518.111308808379
INFO:root:current train perplexity380.909423828125
INFO:root:current mean train loss 7583.6843116554055
INFO:root:current train perplexity399.61187744140625
INFO:root:current mean train loss 7589.357049886689
INFO:root:current train perplexity402.38134765625
INFO:root:current mean train loss 7597.30171124793
INFO:root:current train perplexity404.3206481933594
INFO:root:current mean train loss 7622.464937979715
INFO:root:current train perplexity412.28118896484375
INFO:root:current mean train loss 7640.923643549575
INFO:root:current train perplexity420.95513916015625
INFO:root:current mean train loss 7696.8518489891885
INFO:root:current train perplexity438.5622863769531
INFO:root:current mean train loss 7739.546254396645
INFO:root:current train perplexity452.87249755859375
INFO:root:current mean train loss 7758.829353289965
INFO:root:current train perplexity458.9818420410156
INFO:root:current mean train loss 7777.414255290014
INFO:root:current train perplexity462.9402770996094
INFO:root:current mean train loss 7803.912913445017
INFO:root:current train perplexity472.9273376464844
INFO:root:current mean train loss 7814.822953614851
INFO:root:current train perplexity476.0516662597656
INFO:root:current mean train loss 7821.212528028229
INFO:root:current train perplexity477.66107177734375
INFO:root:current mean train loss 7829.958296886129
INFO:root:current train perplexity480.7038879394531
INFO:root:current mean train loss 7840.169063500252
INFO:root:current train perplexity485.9636535644531
INFO:root:current mean train loss 7841.8083414921675
INFO:root:current train perplexity486.1298522949219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.86s/it]
INFO:root:final mean train loss: 7844.2600041022515
INFO:root:final train perplexity: 488.1744689941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.88s/it]
INFO:root:eval mean loss: 6893.0084600786795
INFO:root:eval perplexity: 264.5219421386719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.65s/it]
INFO:root:eval mean loss: 6854.088941641733
INFO:root:eval perplexity: 280.04296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [17:01:16<32:18:33, 887.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8101.5990804036455
INFO:root:current train perplexity612.4461059570312
INFO:root:current mean train loss 7996.440736282703
INFO:root:current train perplexity548.099609375
INFO:root:current mean train loss 8085.626428940717
INFO:root:current train perplexity594.4639282226562
INFO:root:current mean train loss 8149.507803311912
INFO:root:current train perplexity621.5637817382812
INFO:root:current mean train loss 8111.1841575493245
INFO:root:current train perplexity603.2822875976562
INFO:root:current mean train loss 8055.010346099213
INFO:root:current train perplexity575.4495849609375
INFO:root:current mean train loss 8039.038238525391
INFO:root:current train perplexity572.1744384765625
INFO:root:current mean train loss 8042.004495729437
INFO:root:current train perplexity570.8968505859375
INFO:root:current mean train loss 8051.687060994839
INFO:root:current train perplexity575.6985473632812
INFO:root:current mean train loss 8077.591474368249
INFO:root:current train perplexity586.0842895507812
INFO:root:current mean train loss 8078.520263216389
INFO:root:current train perplexity589.72216796875
INFO:root:current mean train loss 8073.011761245467
INFO:root:current train perplexity586.4916381835938
INFO:root:current mean train loss 8064.024237098934
INFO:root:current train perplexity582.1398315429688
INFO:root:current mean train loss 8049.260629370331
INFO:root:current train perplexity574.5552368164062
INFO:root:current mean train loss 8042.694789057193
INFO:root:current train perplexity573.5965576171875
INFO:root:current mean train loss 8022.029022915673
INFO:root:current train perplexity565.0081787109375
INFO:root:current mean train loss 7993.023185766485
INFO:root:current train perplexity551.1641845703125
INFO:root:current mean train loss 7984.217271654116
INFO:root:current train perplexity547.2962646484375
INFO:root:current mean train loss 7978.137452997713
INFO:root:current train perplexity541.9905395507812
INFO:root:current mean train loss 7957.1699184085
INFO:root:current train perplexity532.724365234375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.63s/it]
INFO:root:final mean train loss: 7953.925193490371
INFO:root:final train perplexity: 532.3071899414062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.08s/it]
INFO:root:eval mean loss: 6272.492942431294
INFO:root:eval perplexity: 160.09913635253906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.43s/it]
INFO:root:eval mean loss: 6318.708942819149
INFO:root:eval perplexity: 180.33050537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [17:15:56<31:58:23, 885.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7547.074575359901
INFO:root:current train perplexity385.3559265136719
INFO:root:current mean train loss 7597.109426669974
INFO:root:current train perplexity393.38232421875
INFO:root:current mean train loss 7653.6816592100995
INFO:root:current train perplexity418.2554016113281
INFO:root:current mean train loss 7674.810989968268
INFO:root:current train perplexity424.2550964355469
INFO:root:current mean train loss 7688.520587694913
INFO:root:current train perplexity428.1634521484375
INFO:root:current mean train loss 7704.325710121763
INFO:root:current train perplexity432.576171875
INFO:root:current mean train loss 7714.801311343433
INFO:root:current train perplexity434.3218078613281
INFO:root:current mean train loss 7719.871016392388
INFO:root:current train perplexity436.22821044921875
INFO:root:current mean train loss 7722.838266859709
INFO:root:current train perplexity440.3428039550781
INFO:root:current mean train loss 7732.461732870165
INFO:root:current train perplexity445.8228759765625
INFO:root:current mean train loss 7741.268251137081
INFO:root:current train perplexity447.24774169921875
INFO:root:current mean train loss 7755.3819772064235
INFO:root:current train perplexity451.5216064453125
INFO:root:current mean train loss 7757.804405668154
INFO:root:current train perplexity453.6501159667969
INFO:root:current mean train loss 7764.7787294985155
INFO:root:current train perplexity455.6144104003906
INFO:root:current mean train loss 7751.213062458026
INFO:root:current train perplexity451.9386291503906
INFO:root:current mean train loss 7739.512366206635
INFO:root:current train perplexity447.9082946777344
INFO:root:current mean train loss 7728.493933054877
INFO:root:current train perplexity444.6081237792969
INFO:root:current mean train loss 7714.23799848903
INFO:root:current train perplexity439.98345947265625
INFO:root:current mean train loss 7705.52996635538
INFO:root:current train perplexity437.634765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.13s/it]
INFO:root:final mean train loss: 7701.215477555314
INFO:root:final train perplexity: 436.0610046386719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.24s/it]
INFO:root:eval mean loss: 6363.897679105718
INFO:root:eval perplexity: 172.39007568359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.04s/it]
INFO:root:eval mean loss: 6447.322382500831
INFO:root:eval perplexity: 200.44281005859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [17:30:46<31:47:12, 887.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7580.0615234375
INFO:root:current train perplexity440.35791015625
INFO:root:current mean train loss 7726.520065595519
INFO:root:current train perplexity448.64703369140625
INFO:root:current mean train loss 7718.358919902913
INFO:root:current train perplexity435.915283203125
INFO:root:current mean train loss 7667.553688597835
INFO:root:current train perplexity426.1937255859375
INFO:root:current mean train loss 7677.987906019089
INFO:root:current train perplexity430.41473388671875
INFO:root:current mean train loss 7666.358871279027
INFO:root:current train perplexity424.8958740234375
INFO:root:current mean train loss 7665.308690439357
INFO:root:current train perplexity423.534912109375
INFO:root:current mean train loss 7661.12739990926
INFO:root:current train perplexity421.80023193359375
INFO:root:current mean train loss 7662.316156657103
INFO:root:current train perplexity423.1588439941406
INFO:root:current mean train loss 7681.652902093681
INFO:root:current train perplexity426.9458923339844
INFO:root:current mean train loss 7665.195203777336
INFO:root:current train perplexity423.787841796875
INFO:root:current mean train loss 7653.958239591574
INFO:root:current train perplexity420.4582214355469
INFO:root:current mean train loss 7650.216231262309
INFO:root:current train perplexity419.5513916015625
INFO:root:current mean train loss 7653.50351106372
INFO:root:current train perplexity420.2962646484375
INFO:root:current mean train loss 7658.095637835615
INFO:root:current train perplexity422.9990539550781
INFO:root:current mean train loss 7673.037267920506
INFO:root:current train perplexity429.190185546875
INFO:root:current mean train loss 7693.846095939057
INFO:root:current train perplexity435.22467041015625
INFO:root:current mean train loss 7715.673847587559
INFO:root:current train perplexity442.0626525878906
INFO:root:current mean train loss 7748.581806035005
INFO:root:current train perplexity452.8852233886719
INFO:root:current mean train loss 7774.128033440861
INFO:root:current train perplexity461.55078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:50<00:00, 770.35s/it]
INFO:root:final mean train loss: 7785.901593845539
INFO:root:final train perplexity: 466.20086669921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.12s/it]
INFO:root:eval mean loss: 7347.450621259974
INFO:root:eval perplexity: 382.093505859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.33s/it]
INFO:root:eval mean loss: 7407.734886656416
INFO:root:eval perplexity: 441.47052001953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [17:45:37<31:34:34, 888.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8275.795771059782
INFO:root:current train perplexity700.6718139648438
INFO:root:current mean train loss 8207.994049320376
INFO:root:current train perplexity644.7529907226562
INFO:root:current mean train loss 8047.60986328125
INFO:root:current train perplexity553.54248046875
INFO:root:current mean train loss 7901.780386815499
INFO:root:current train perplexity511.7207946777344
INFO:root:current mean train loss 7844.995987551714
INFO:root:current train perplexity484.79925537109375
INFO:root:current mean train loss 7811.70966218033
INFO:root:current train perplexity474.5263977050781
INFO:root:current mean train loss 7799.764349825692
INFO:root:current train perplexity467.5901184082031
INFO:root:current mean train loss 7813.596138053251
INFO:root:current train perplexity473.3320617675781
INFO:root:current mean train loss 7834.479512952802
INFO:root:current train perplexity480.2005615234375
INFO:root:current mean train loss 7856.545086398802
INFO:root:current train perplexity488.7726135253906
INFO:root:current mean train loss 7864.216801648033
INFO:root:current train perplexity491.3901672363281
INFO:root:current mean train loss 7871.026794596644
INFO:root:current train perplexity495.6413269042969
INFO:root:current mean train loss 7892.901648258637
INFO:root:current train perplexity503.8358154296875
INFO:root:current mean train loss 7913.549700978481
INFO:root:current train perplexity512.00048828125
INFO:root:current mean train loss 7925.7983017557535
INFO:root:current train perplexity518.30859375
INFO:root:current mean train loss 7936.052278795449
INFO:root:current train perplexity522.0465087890625
INFO:root:current mean train loss 7950.510036390942
INFO:root:current train perplexity529.647705078125
INFO:root:current mean train loss 7966.40405344285
INFO:root:current train perplexity536.2222900390625
INFO:root:current mean train loss 7979.725961723892
INFO:root:current train perplexity542.0256958007812
INFO:root:current mean train loss 7978.950399207374
INFO:root:current train perplexity542.872802734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.93s/it]
INFO:root:final mean train loss: 7986.940950964054
INFO:root:final train perplexity: 546.359130859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.31s/it]
INFO:root:eval mean loss: 7369.79918827571
INFO:root:eval perplexity: 389.06634521484375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.95s/it]
INFO:root:eval mean loss: 7338.0665802651265
INFO:root:eval perplexity: 416.895263671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [18:00:22<31:17:41, 887.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8483.492895507812
INFO:root:current train perplexity852.9765625
INFO:root:current mean train loss 8510.27615094866
INFO:root:current train perplexity824.6040649414062
INFO:root:current mean train loss 8388.325758870442
INFO:root:current train perplexity757.7933349609375
INFO:root:current mean train loss 8341.413578527114
INFO:root:current train perplexity735.0975952148438
INFO:root:current mean train loss 8344.129949396307
INFO:root:current train perplexity725.0968017578125
INFO:root:current mean train loss 8371.61047905816
INFO:root:current train perplexity741.0545043945312
INFO:root:current mean train loss 8405.845446014404
INFO:root:current train perplexity765.4083251953125
INFO:root:current mean train loss 8418.131876187712
INFO:root:current train perplexity777.1533813476562
INFO:root:current mean train loss 8422.45253092448
INFO:root:current train perplexity776.7958374023438
INFO:root:current mean train loss 8413.699362117686
INFO:root:current train perplexity769.474365234375
INFO:root:current mean train loss 8407.406357046275
INFO:root:current train perplexity766.4806518554688
INFO:root:current mean train loss 8418.724640642133
INFO:root:current train perplexity771.2691650390625
INFO:root:current mean train loss 8419.630241147934
INFO:root:current train perplexity771.6727294921875
INFO:root:current mean train loss 8406.159239082906
INFO:root:current train perplexity764.884765625
INFO:root:current mean train loss 8412.939918348524
INFO:root:current train perplexity766.2095336914062
INFO:root:current mean train loss 8407.973009778307
INFO:root:current train perplexity762.2047729492188
INFO:root:current mean train loss 8408.807507621952
INFO:root:current train perplexity760.3621215820312
INFO:root:current mean train loss 8420.535384956447
INFO:root:current train perplexity767.6031494140625
INFO:root:current mean train loss 8434.740475065812
INFO:root:current train perplexity776.0916748046875
INFO:root:current mean train loss 8433.45812761759
INFO:root:current train perplexity774.7339477539062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:48<00:00, 768.87s/it]
INFO:root:final mean train loss: 8428.957714548269
INFO:root:final train perplexity: 774.4207763671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.15s/it]
INFO:root:eval mean loss: 7608.482757784796
INFO:root:eval perplexity: 471.96112060546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.14s/it]
INFO:root:eval mean loss: 7557.76929403535
INFO:root:eval perplexity: 499.42578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [18:15:11<31:04:31, 887.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8408.675849780702
INFO:root:current train perplexity761.6503295898438
INFO:root:current mean train loss 8439.694534982085
INFO:root:current train perplexity800.8977661132812
INFO:root:current mean train loss 8415.88729062804
INFO:root:current train perplexity787.2175903320312
INFO:root:current mean train loss 8458.450006565126
INFO:root:current train perplexity796.8355712890625
INFO:root:current mean train loss 8430.408866631906
INFO:root:current train perplexity782.3778076171875
INFO:root:current mean train loss 8414.952252756115
INFO:root:current train perplexity774.2243041992188
INFO:root:current mean train loss 8431.531747942827
INFO:root:current train perplexity783.4212646484375
INFO:root:current mean train loss 8440.891101670864
INFO:root:current train perplexity788.13818359375
INFO:root:current mean train loss 8436.209713093458
INFO:root:current train perplexity788.5501708984375
INFO:root:current mean train loss 8428.909664397204
INFO:root:current train perplexity785.3912963867188
INFO:root:current mean train loss 8437.885417436584
INFO:root:current train perplexity792.8604736328125
INFO:root:current mean train loss 8454.130099732605
INFO:root:current train perplexity803.104736328125
INFO:root:current mean train loss 8462.017311260068
INFO:root:current train perplexity804.2939453125
INFO:root:current mean train loss 8471.760271897452
INFO:root:current train perplexity809.56494140625
INFO:root:current mean train loss 8479.65147509866
INFO:root:current train perplexity811.4110717773438
INFO:root:current mean train loss 8488.604335071954
INFO:root:current train perplexity814.7511596679688
INFO:root:current mean train loss 8489.47315425562
INFO:root:current train perplexity814.9512939453125
INFO:root:current mean train loss 8487.880884108654
INFO:root:current train perplexity813.6924438476562
INFO:root:current mean train loss 8483.981732706903
INFO:root:current train perplexity809.9649658203125
INFO:root:current mean train loss 8490.63095144234
INFO:root:current train perplexity811.6478881835938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:53<00:00, 773.04s/it]
INFO:root:final mean train loss: 8489.183161979363
INFO:root:final train perplexity: 812.1171264648438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.17s/it]
INFO:root:eval mean loss: 7803.801172567598
INFO:root:eval perplexity: 552.7749633789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.85s/it]
INFO:root:eval mean loss: 7740.340184854277
INFO:root:eval perplexity: 580.3062133789062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [18:30:05<30:53:19, 889.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8498.066762563345
INFO:root:current train perplexity809.8151245117188
INFO:root:current mean train loss 8446.964377918463
INFO:root:current train perplexity777.99951171875
INFO:root:current mean train loss 8410.388459811245
INFO:root:current train perplexity764.7757568359375
INFO:root:current mean train loss 8414.087480677641
INFO:root:current train perplexity763.8001098632812
INFO:root:current mean train loss 8419.88901490803
INFO:root:current train perplexity768.607421875
INFO:root:current mean train loss 8421.075914123749
INFO:root:current train perplexity770.01025390625
INFO:root:current mean train loss 8406.728143256212
INFO:root:current train perplexity764.527099609375
INFO:root:current mean train loss 8383.468373379967
INFO:root:current train perplexity751.1768798828125
INFO:root:current mean train loss 8356.971560131222
INFO:root:current train perplexity737.831787109375
INFO:root:current mean train loss 8337.775365057912
INFO:root:current train perplexity724.7984619140625
INFO:root:current mean train loss 8329.634977940963
INFO:root:current train perplexity721.1036376953125
INFO:root:current mean train loss 8324.487587923899
INFO:root:current train perplexity719.4760131835938
INFO:root:current mean train loss 8335.217571456167
INFO:root:current train perplexity721.4537963867188
INFO:root:current mean train loss 8348.609674934043
INFO:root:current train perplexity728.52294921875
INFO:root:current mean train loss 8365.901988636364
INFO:root:current train perplexity736.8213500976562
INFO:root:current mean train loss 8378.187922825504
INFO:root:current train perplexity742.16845703125
INFO:root:current mean train loss 8394.19247469338
INFO:root:current train perplexity751.2550048828125
INFO:root:current mean train loss 8404.723261234321
INFO:root:current train perplexity759.1991577148438
INFO:root:current mean train loss 8421.278035785752
INFO:root:current train perplexity766.56396484375
INFO:root:current mean train loss 8431.310860275376
INFO:root:current train perplexity774.4728393554688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:51<00:00, 771.45s/it]
INFO:root:final mean train loss: 8430.70942525628
INFO:root:final train perplexity: 775.4920043945312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.07s/it]
INFO:root:eval mean loss: 8096.59558884641
INFO:root:eval perplexity: 700.563232421875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.21s/it]
INFO:root:eval mean loss: 8031.337568567154
INFO:root:eval perplexity: 737.1513671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [18:44:57<30:40:10, 890.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8554.939206301511
INFO:root:current train perplexity884.4963989257812
INFO:root:current mean train loss 8549.178992146597
INFO:root:current train perplexity869.1250610351562
INFO:root:current mean train loss 8582.74271605187
INFO:root:current train perplexity878.3759765625
INFO:root:current mean train loss 8585.558299032928
INFO:root:current train perplexity885.4872436523438
INFO:root:current mean train loss 8594.626863623345
INFO:root:current train perplexity884.9009399414062
INFO:root:current mean train loss 8584.346865581378
INFO:root:current train perplexity885.7418823242188
INFO:root:current mean train loss 8584.264488739147
INFO:root:current train perplexity890.3970336914062
INFO:root:current mean train loss 8576.32471320421
INFO:root:current train perplexity882.42333984375
INFO:root:current mean train loss 8563.939779193848
INFO:root:current train perplexity872.7659912109375
INFO:root:current mean train loss 8553.903120762645
INFO:root:current train perplexity865.1626586914062
INFO:root:current mean train loss 8541.238542173895
INFO:root:current train perplexity856.7589721679688
INFO:root:current mean train loss 8539.459785057856
INFO:root:current train perplexity853.5205688476562
INFO:root:current mean train loss 8541.412232296307
INFO:root:current train perplexity853.0969848632812
INFO:root:current mean train loss 8545.140074586629
INFO:root:current train perplexity851.0987548828125
INFO:root:current mean train loss 8548.588426064198
INFO:root:current train perplexity851.27490234375
INFO:root:current mean train loss 8552.841657848347
INFO:root:current train perplexity852.22607421875
INFO:root:current mean train loss 8552.216164794778
INFO:root:current train perplexity851.9729614257812
INFO:root:current mean train loss 8554.957092046605
INFO:root:current train perplexity852.5980224609375
INFO:root:current mean train loss 8553.350978938062
INFO:root:current train perplexity852.7695922851562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.29s/it]
INFO:root:final mean train loss: 8551.430828300317
INFO:root:final train perplexity: 853.009521484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.73s/it]
INFO:root:eval mean loss: 7924.431547124335
INFO:root:eval perplexity: 609.4559326171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.79s/it]
INFO:root:eval mean loss: 7908.811339899158
INFO:root:eval perplexity: 666.5134887695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [18:59:43<30:22:14, 888.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8515.855651855469
INFO:root:current train perplexity864.3428955078125
INFO:root:current mean train loss 8614.71497938368
INFO:root:current train perplexity884.14892578125
INFO:root:current mean train loss 8562.446467472957
INFO:root:current train perplexity869.55908203125
INFO:root:current mean train loss 8569.928775935978
INFO:root:current train perplexity870.2149047851562
INFO:root:current mean train loss 8568.07401410271
INFO:root:current train perplexity866.0950927734375
INFO:root:current mean train loss 8574.548879067728
INFO:root:current train perplexity862.8197021484375
INFO:root:current mean train loss 8559.055786935907
INFO:root:current train perplexity857.6431274414062
INFO:root:current mean train loss 8562.541089418917
INFO:root:current train perplexity853.0611572265625
INFO:root:current mean train loss 8546.053457127939
INFO:root:current train perplexity846.0784301757812
INFO:root:current mean train loss 8541.012765220608
INFO:root:current train perplexity840.9557495117188
INFO:root:current mean train loss 8522.059393019903
INFO:root:current train perplexity833.4566040039062
INFO:root:current mean train loss 8512.237453199035
INFO:root:current train perplexity825.4408569335938
INFO:root:current mean train loss 8506.054708114523
INFO:root:current train perplexity822.2070922851562
INFO:root:current mean train loss 8510.959916514359
INFO:root:current train perplexity821.9942016601562
INFO:root:current mean train loss 8504.045697645708
INFO:root:current train perplexity817.2145385742188
INFO:root:current mean train loss 8494.780898035995
INFO:root:current train perplexity810.267822265625
INFO:root:current mean train loss 8488.920451150012
INFO:root:current train perplexity806.2610473632812
INFO:root:current mean train loss 8483.09498042301
INFO:root:current train perplexity802.6070556640625
INFO:root:current mean train loss 8472.73271057669
INFO:root:current train perplexity797.7909545898438
INFO:root:current mean train loss 8466.02091855223
INFO:root:current train perplexity795.6221313476562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:47<00:00, 767.89s/it]
INFO:root:final mean train loss: 8461.268518244926
INFO:root:final train perplexity: 794.4219360351562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.96s/it]
INFO:root:eval mean loss: 7899.251452723293
INFO:root:eval perplexity: 597.1635131835938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.59s/it]
INFO:root:eval mean loss: 7858.053474588597
INFO:root:eval perplexity: 639.2725830078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [19:14:30<30:06:18, 888.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8422.46564453125
INFO:root:current train perplexity779.7064208984375
INFO:root:current mean train loss 8434.60652734375
INFO:root:current train perplexity802.2523803710938
INFO:root:current mean train loss 8427.005670572917
INFO:root:current train perplexity802.7196044921875
INFO:root:current mean train loss 8406.25655498798
INFO:root:current train perplexity786.0537109375
INFO:root:current mean train loss 8398.549225643383
INFO:root:current train perplexity776.1483154296875
INFO:root:current mean train loss 8372.43609654018
INFO:root:current train perplexity759.2857055664062
INFO:root:current mean train loss 8370.1202109375
INFO:root:current train perplexity752.1317138671875
INFO:root:current mean train loss 8361.557161907327
INFO:root:current train perplexity739.0458984375
INFO:root:current mean train loss 8356.178090672349
INFO:root:current train perplexity734.9248046875
INFO:root:current mean train loss 8349.572375422298
INFO:root:current train perplexity729.7652587890625
INFO:root:current mean train loss 8339.69577410442
INFO:root:current train perplexity727.6751708984375
INFO:root:current mean train loss 8340.982840711806
INFO:root:current train perplexity726.1219482421875
INFO:root:current mean train loss 8337.364286910077
INFO:root:current train perplexity722.1325073242188
INFO:root:current mean train loss 8329.477442511792
INFO:root:current train perplexity718.1234741210938
INFO:root:current mean train loss 8316.5453368284
INFO:root:current train perplexity712.80859375
INFO:root:current mean train loss 8310.646613089139
INFO:root:current train perplexity708.2972412109375
INFO:root:current mean train loss 8316.12291015625
INFO:root:current train perplexity708.2503051757812
INFO:root:current mean train loss 8315.402399513134
INFO:root:current train perplexity705.1917724609375
INFO:root:current mean train loss 8312.44628504923
INFO:root:current train perplexity703.3145751953125
INFO:root:current mean train loss 8308.570489549513
INFO:root:current train perplexity703.4390258789062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:35<00:00, 755.82s/it]
INFO:root:final mean train loss: 8305.461034516042
INFO:root:final train perplexity: 702.5047607421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.33s/it]
INFO:root:eval mean loss: 7611.938552748227
INFO:root:eval perplexity: 473.28265380859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.05s/it]
INFO:root:eval mean loss: 7594.926582931626
INFO:root:eval perplexity: 514.91796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [19:29:03<29:42:07, 883.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8249.436790829614
INFO:root:current train perplexity656.0625610351562
INFO:root:current mean train loss 8221.059883225133
INFO:root:current train perplexity639.2119140625
INFO:root:current mean train loss 8211.64939590328
INFO:root:current train perplexity640.9174194335938
INFO:root:current mean train loss 8205.858883863304
INFO:root:current train perplexity634.1422729492188
INFO:root:current mean train loss 8197.593077232395
INFO:root:current train perplexity630.8789672851562
INFO:root:current mean train loss 8193.01710245618
INFO:root:current train perplexity630.8885498046875
INFO:root:current mean train loss 8196.620027441102
INFO:root:current train perplexity636.6834716796875
INFO:root:current mean train loss 8206.260559246546
INFO:root:current train perplexity644.0250854492188
INFO:root:current mean train loss 8207.095365619432
INFO:root:current train perplexity646.9598999023438
INFO:root:current mean train loss 8207.846126094746
INFO:root:current train perplexity649.6453247070312
INFO:root:current mean train loss 8216.207958140894
INFO:root:current train perplexity652.3917236328125
INFO:root:current mean train loss 8213.731053233772
INFO:root:current train perplexity654.933837890625
INFO:root:current mean train loss 8225.998990020506
INFO:root:current train perplexity659.3014526367188
INFO:root:current mean train loss 8238.200762912165
INFO:root:current train perplexity663.1569213867188
INFO:root:current mean train loss 8246.749930245536
INFO:root:current train perplexity668.8478393554688
INFO:root:current mean train loss 8255.90799096648
INFO:root:current train perplexity674.5731201171875
INFO:root:current mean train loss 8262.819415335243
INFO:root:current train perplexity679.1578369140625
INFO:root:current mean train loss 8271.76534329928
INFO:root:current train perplexity683.9778442382812
INFO:root:current mean train loss 8277.49687812797
INFO:root:current train perplexity687.4912719726562
INFO:root:current mean train loss 8284.549649302427
INFO:root:current train perplexity689.815185546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:55<00:00, 775.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:55<00:00, 775.97s/it]
INFO:root:final mean train loss: 8284.817833543124
INFO:root:final train perplexity: 691.1522216796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it]
INFO:root:eval mean loss: 7998.625386123116
INFO:root:eval perplexity: 647.1675415039062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.09s/it]
INFO:root:eval mean loss: 7969.236045891512
INFO:root:eval perplexity: 700.4603881835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [19:44:00<29:35:22, 887.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8408.639416710805
INFO:root:current train perplexity771.406005859375
INFO:root:current mean train loss 8376.186105788129
INFO:root:current train perplexity753.020263671875
INFO:root:current mean train loss 8335.426603221526
INFO:root:current train perplexity734.5078735351562
INFO:root:current mean train loss 8334.939016528117
INFO:root:current train perplexity725.5789184570312
INFO:root:current mean train loss 8327.638071895424
INFO:root:current train perplexity724.8057250976562
INFO:root:current mean train loss 8342.753637214893
INFO:root:current train perplexity727.6123657226562
INFO:root:current mean train loss 8340.546372640838
INFO:root:current train perplexity727.9628295898438
INFO:root:current mean train loss 8356.854878180584
INFO:root:current train perplexity728.8412475585938
INFO:root:current mean train loss 8354.966809380458
INFO:root:current train perplexity726.3941650390625
INFO:root:current mean train loss 8343.80094978086
INFO:root:current train perplexity722.0918579101562
INFO:root:current mean train loss 8332.664011781457
INFO:root:current train perplexity718.8895874023438
INFO:root:current mean train loss 8336.909469538665
INFO:root:current train perplexity718.8367919921875
INFO:root:current mean train loss 8337.815397885226
INFO:root:current train perplexity715.5892333984375
INFO:root:current mean train loss 8338.827086279549
INFO:root:current train perplexity715.2743530273438
INFO:root:current mean train loss 8335.35761230134
INFO:root:current train perplexity716.0677490234375
INFO:root:current mean train loss 8329.913247549512
INFO:root:current train perplexity715.2365112304688
INFO:root:current mean train loss 8331.99685810588
INFO:root:current train perplexity715.8359375
INFO:root:current mean train loss 8331.23493101327
INFO:root:current train perplexity714.6344604492188
INFO:root:current mean train loss 8329.04858989418
INFO:root:current train perplexity713.3577270507812
INFO:root:current mean train loss 8323.377956108026
INFO:root:current train perplexity711.6331787109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.93s/it]
INFO:root:final mean train loss: 8321.434362121981
INFO:root:final train perplexity: 711.4163818359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.13s/it]
INFO:root:eval mean loss: 7914.963358128324
INFO:root:eval perplexity: 604.803955078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.36s/it]
INFO:root:eval mean loss: 7889.0316265999
INFO:root:eval perplexity: 655.762939453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [19:58:35<29:12:59, 883.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8300.26697419819
INFO:root:current train perplexity722.6870727539062
INFO:root:current mean train loss 8318.447357177734
INFO:root:current train perplexity725.6664428710938
INFO:root:current mean train loss 8343.109672214674
INFO:root:current train perplexity734.2567749023438
INFO:root:current mean train loss 8334.765097760139
INFO:root:current train perplexity729.8880615234375
INFO:root:current mean train loss 8330.673374720982
INFO:root:current train perplexity729.4169921875
INFO:root:current mean train loss 8348.844885932074
INFO:root:current train perplexity731.0713500976562
INFO:root:current mean train loss 8347.436299521542
INFO:root:current train perplexity729.262939453125
INFO:root:current mean train loss 8343.47247754913
INFO:root:current train perplexity725.4609375
INFO:root:current mean train loss 8339.48325853043
INFO:root:current train perplexity724.6719970703125
INFO:root:current mean train loss 8336.768905889792
INFO:root:current train perplexity725.6214599609375
INFO:root:current mean train loss 8337.857245803323
INFO:root:current train perplexity726.86572265625
INFO:root:current mean train loss 8339.392631686464
INFO:root:current train perplexity727.8969116210938
INFO:root:current mean train loss 8339.248613220023
INFO:root:current train perplexity727.5675659179688
INFO:root:current mean train loss 8344.401093239008
INFO:root:current train perplexity729.3606567382812
INFO:root:current mean train loss 8347.766233035865
INFO:root:current train perplexity731.0995483398438
INFO:root:current mean train loss 8353.439981683257
INFO:root:current train perplexity732.6644287109375
INFO:root:current mean train loss 8352.327414428419
INFO:root:current train perplexity732.6504516601562
INFO:root:current mean train loss 8352.757323119018
INFO:root:current train perplexity732.8230590820312
INFO:root:current mean train loss 8359.040922185251
INFO:root:current train perplexity734.1689453125
INFO:root:current mean train loss 8361.850462878763
INFO:root:current train perplexity733.3543701171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.81s/it]
INFO:root:final mean train loss: 8359.69454671347
INFO:root:final train perplexity: 733.2250366210938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.82s/it]
INFO:root:eval mean loss: 7857.631557166999
INFO:root:eval perplexity: 577.385986328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.87s/it]
INFO:root:eval mean loss: 7846.519301827072
INFO:root:eval perplexity: 633.2394409179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [20:13:13<28:54:48, 882.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8328.639874201948
INFO:root:current train perplexity722.4276733398438
INFO:root:current mean train loss 8305.22223374757
INFO:root:current train perplexity714.000244140625
INFO:root:current mean train loss 8322.35871840337
INFO:root:current train perplexity708.1587524414062
INFO:root:current mean train loss 8340.088905703324
INFO:root:current train perplexity715.2146606445312
INFO:root:current mean train loss 8332.638492607442
INFO:root:current train perplexity712.9353637695312
INFO:root:current mean train loss 8332.280807006218
INFO:root:current train perplexity713.1846313476562
INFO:root:current mean train loss 8331.623963547303
INFO:root:current train perplexity712.4429321289062
INFO:root:current mean train loss 8324.21037101986
INFO:root:current train perplexity709.6575927734375
INFO:root:current mean train loss 8315.494647497026
INFO:root:current train perplexity706.9064331054688
INFO:root:current mean train loss 8315.234355331067
INFO:root:current train perplexity707.8245239257812
INFO:root:current mean train loss 8309.855733663799
INFO:root:current train perplexity706.5488891601562
INFO:root:current mean train loss 8315.49592348596
INFO:root:current train perplexity707.6710205078125
INFO:root:current mean train loss 8312.434066925875
INFO:root:current train perplexity709.0734252929688
INFO:root:current mean train loss 8319.11970041334
INFO:root:current train perplexity710.2378540039062
INFO:root:current mean train loss 8323.211656676469
INFO:root:current train perplexity710.521728515625
INFO:root:current mean train loss 8314.287783711943
INFO:root:current train perplexity710.7030029296875
INFO:root:current mean train loss 8316.391389579796
INFO:root:current train perplexity712.4483642578125
INFO:root:current mean train loss 8321.862784254305
INFO:root:current train perplexity713.8095703125
INFO:root:current mean train loss 8327.470932691991
INFO:root:current train perplexity714.6460571289062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:49<00:00, 769.83s/it]
INFO:root:final mean train loss: 8328.811522575683
INFO:root:final train perplexity: 715.57080078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.17s/it]
INFO:root:eval mean loss: 7931.221297027371
INFO:root:eval perplexity: 612.8138427734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.97s/it]
INFO:root:eval mean loss: 7912.168063982159
INFO:root:eval perplexity: 668.3555908203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [20:28:02<28:44:21, 884.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8465.610205078125
INFO:root:current train perplexity765.2594604492188
INFO:root:current mean train loss 8418.793634588068
INFO:root:current train perplexity743.3226928710938
INFO:root:current mean train loss 8377.640025111607
INFO:root:current train perplexity742.962646484375
INFO:root:current mean train loss 8386.920079385081
INFO:root:current train perplexity741.150634765625
INFO:root:current mean train loss 8395.026923351754
INFO:root:current train perplexity742.7398681640625
INFO:root:current mean train loss 8396.71751876532
INFO:root:current train perplexity742.8514404296875
INFO:root:current mean train loss 8385.84601130251
INFO:root:current train perplexity741.1460571289062
INFO:root:current mean train loss 8369.561645851672
INFO:root:current train perplexity738.3748779296875
INFO:root:current mean train loss 8369.42786518615
INFO:root:current train perplexity738.2875366210938
INFO:root:current mean train loss 8381.489556146978
INFO:root:current train perplexity740.79833984375
INFO:root:current mean train loss 8381.112495165533
INFO:root:current train perplexity741.4832763671875
INFO:root:current mean train loss 8377.205774915541
INFO:root:current train perplexity741.0626220703125
INFO:root:current mean train loss 8378.016479290418
INFO:root:current train perplexity740.3173828125
INFO:root:current mean train loss 8374.099740950023
INFO:root:current train perplexity739.66357421875
INFO:root:current mean train loss 8374.297679105717
INFO:root:current train perplexity738.7774047851562
INFO:root:current mean train loss 8369.822821166184
INFO:root:current train perplexity737.6678466796875
INFO:root:current mean train loss 8369.410979959239
INFO:root:current train perplexity736.699462890625
INFO:root:current mean train loss 8367.10804150676
INFO:root:current train perplexity734.1241455078125
INFO:root:current mean train loss 8365.804298223844
INFO:root:current train perplexity733.6597290039062
INFO:root:current mean train loss 8358.614953932836
INFO:root:current train perplexity731.65478515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.16s/it]
INFO:root:final mean train loss: 8355.126799967695
INFO:root:final train perplexity: 730.5866088867188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.13s/it]
INFO:root:eval mean loss: 7808.363899393285
INFO:root:eval perplexity: 554.8193969726562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.44s/it]
INFO:root:eval mean loss: 7811.483205375942
INFO:root:eval perplexity: 615.259033203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [20:42:44<28:28:26, 883.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8381.902615017361
INFO:root:current train perplexity701.682861328125
INFO:root:current mean train loss 8306.564641516978
INFO:root:current train perplexity702.6558837890625
INFO:root:current mean train loss 8318.339228558645
INFO:root:current train perplexity713.0740966796875
INFO:root:current mean train loss 8287.258832365731
INFO:root:current train perplexity706.010009765625
INFO:root:current mean train loss 8300.252955988364
INFO:root:current train perplexity708.115234375
INFO:root:current mean train loss 8317.86661675759
INFO:root:current train perplexity710.0841064453125
INFO:root:current mean train loss 8319.340835887659
INFO:root:current train perplexity710.8331298828125
INFO:root:current mean train loss 8315.035408786107
INFO:root:current train perplexity709.40625
INFO:root:current mean train loss 8329.301478541604
INFO:root:current train perplexity711.8673706054688
INFO:root:current mean train loss 8326.635359779531
INFO:root:current train perplexity712.1943359375
INFO:root:current mean train loss 8328.89622620877
INFO:root:current train perplexity713.1451416015625
INFO:root:current mean train loss 8334.319737133985
INFO:root:current train perplexity714.1231689453125
INFO:root:current mean train loss 8328.931317889797
INFO:root:current train perplexity715.1304321289062
INFO:root:current mean train loss 8330.111189404555
INFO:root:current train perplexity716.095458984375
INFO:root:current mean train loss 8328.201221490124
INFO:root:current train perplexity715.7987670898438
INFO:root:current mean train loss 8328.338157309061
INFO:root:current train perplexity715.4537963867188
INFO:root:current mean train loss 8327.574881696086
INFO:root:current train perplexity715.1072387695312
INFO:root:current mean train loss 8328.979663241442
INFO:root:current train perplexity715.9642944335938
INFO:root:current mean train loss 8329.357864455049
INFO:root:current train perplexity715.7120971679688
INFO:root:current mean train loss 8330.580111825782
INFO:root:current train perplexity715.8854370117188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.04s/it]
INFO:root:final mean train loss: 8329.47368833818
INFO:root:final train perplexity: 715.9441528320312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.91s/it]
INFO:root:eval mean loss: 7822.920143506206
INFO:root:eval perplexity: 561.3936767578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.37s/it]
INFO:root:eval mean loss: 7825.633454884198
INFO:root:eval perplexity: 622.459228515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [20:57:26<28:12:38, 883.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8284.388216885653
INFO:root:current train perplexity687.7529296875
INFO:root:current mean train loss 8351.580335828992
INFO:root:current train perplexity712.2530517578125
INFO:root:current mean train loss 8329.94251889088
INFO:root:current train perplexity706.8585815429688
INFO:root:current mean train loss 8321.317743345748
INFO:root:current train perplexity705.5048828125
INFO:root:current mean train loss 8304.346081432996
INFO:root:current train perplexity701.8257446289062
INFO:root:current mean train loss 8295.409297269933
INFO:root:current train perplexity704.0265502929688
INFO:root:current mean train loss 8290.961571355785
INFO:root:current train perplexity704.8717041015625
INFO:root:current mean train loss 8286.5496077999
INFO:root:current train perplexity704.9029541015625
INFO:root:current mean train loss 8296.533189818758
INFO:root:current train perplexity707.0439453125
INFO:root:current mean train loss 8305.061488781945
INFO:root:current train perplexity707.3488159179688
INFO:root:current mean train loss 8305.132861141044
INFO:root:current train perplexity707.167724609375
INFO:root:current mean train loss 8308.732568274012
INFO:root:current train perplexity707.4588012695312
INFO:root:current mean train loss 8312.639686510876
INFO:root:current train perplexity709.7046508789062
INFO:root:current mean train loss 8315.23457445417
INFO:root:current train perplexity710.6027221679688
INFO:root:current mean train loss 8316.568146343707
INFO:root:current train perplexity710.9232788085938
INFO:root:current mean train loss 8321.621949507165
INFO:root:current train perplexity712.3128662109375
INFO:root:current mean train loss 8323.099953310333
INFO:root:current train perplexity712.4232177734375
INFO:root:current mean train loss 8327.08420639738
INFO:root:current train perplexity713.0758056640625
INFO:root:current mean train loss 8329.051993479698
INFO:root:current train perplexity712.5717163085938
INFO:root:current mean train loss 8325.7817671662
INFO:root:current train perplexity712.40625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.59s/it]
INFO:root:final mean train loss: 8323.208343059561
INFO:root:final train perplexity: 712.4127197265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.02s/it]
INFO:root:eval mean loss: 7899.449210092531
INFO:root:eval perplexity: 597.2594604492188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.19s/it]
INFO:root:eval mean loss: 7890.443819086602
INFO:root:eval perplexity: 656.5241088867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [21:12:06<27:56:18, 882.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8372.903136206454
INFO:root:current train perplexity731.0922241210938
INFO:root:current mean train loss 8362.108513684007
INFO:root:current train perplexity732.2188110351562
INFO:root:current mean train loss 8318.947458318367
INFO:root:current train perplexity718.638671875
INFO:root:current mean train loss 8322.46923422351
INFO:root:current train perplexity715.6646118164062
INFO:root:current mean train loss 8319.430847300366
INFO:root:current train perplexity711.9352416992188
INFO:root:current mean train loss 8324.961689505348
INFO:root:current train perplexity712.7096557617188
INFO:root:current mean train loss 8318.054475492861
INFO:root:current train perplexity711.2776489257812
INFO:root:current mean train loss 8321.89893155593
INFO:root:current train perplexity712.4205322265625
INFO:root:current mean train loss 8319.840825983594
INFO:root:current train perplexity711.897216796875
INFO:root:current mean train loss 8323.628524669128
INFO:root:current train perplexity710.8077392578125
INFO:root:current mean train loss 8319.620207388372
INFO:root:current train perplexity709.3139038085938
INFO:root:current mean train loss 8311.637491336267
INFO:root:current train perplexity709.0971069335938
INFO:root:current mean train loss 8309.194331678107
INFO:root:current train perplexity708.1084594726562
INFO:root:current mean train loss 8307.003907685066
INFO:root:current train perplexity706.4629516601562
INFO:root:current mean train loss 8306.68577915116
INFO:root:current train perplexity705.866943359375
INFO:root:current mean train loss 8303.695178308677
INFO:root:current train perplexity704.3499145507812
INFO:root:current mean train loss 8303.388795047693
INFO:root:current train perplexity704.4570922851562
INFO:root:current mean train loss 8307.113005638665
INFO:root:current train perplexity705.2872924804688
INFO:root:current mean train loss 8306.019653517094
INFO:root:current train perplexity704.9806518554688
INFO:root:current mean train loss 8310.606856902967
INFO:root:current train perplexity704.5884399414062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.04s/it]
INFO:root:final mean train loss: 8310.133923752284
INFO:root:final train perplexity: 705.099609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.94s/it]
INFO:root:eval mean loss: 7831.055071891622
INFO:root:eval perplexity: 565.1013793945312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.49s/it]
INFO:root:eval mean loss: 7836.002721908245
INFO:root:eval perplexity: 627.7880249023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [21:26:39<27:36:19, 879.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8205.385147485978
INFO:root:current train perplexity692.767333984375
INFO:root:current mean train loss 8320.2905712342
INFO:root:current train perplexity711.3024291992188
INFO:root:current mean train loss 8312.96856909004
INFO:root:current train perplexity709.1116333007812
INFO:root:current mean train loss 8316.088705718832
INFO:root:current train perplexity708.473876953125
INFO:root:current mean train loss 8341.275599012813
INFO:root:current train perplexity713.919189453125
INFO:root:current mean train loss 8350.90329243485
INFO:root:current train perplexity712.1915893554688
INFO:root:current mean train loss 8343.937891057107
INFO:root:current train perplexity710.1129150390625
INFO:root:current mean train loss 8338.69082382712
INFO:root:current train perplexity706.770263671875
INFO:root:current mean train loss 8335.689414195971
INFO:root:current train perplexity705.2421875
INFO:root:current mean train loss 8328.076361096466
INFO:root:current train perplexity704.2763671875
INFO:root:current mean train loss 8320.92779869405
INFO:root:current train perplexity703.4225463867188
INFO:root:current mean train loss 8316.314748663652
INFO:root:current train perplexity703.1475830078125
INFO:root:current mean train loss 8309.703567051178
INFO:root:current train perplexity701.76318359375
INFO:root:current mean train loss 8305.833288095859
INFO:root:current train perplexity700.3124389648438
INFO:root:current mean train loss 8303.43464860929
INFO:root:current train perplexity699.4700927734375
INFO:root:current mean train loss 8298.20137857454
INFO:root:current train perplexity698.031005859375
INFO:root:current mean train loss 8301.29311279006
INFO:root:current train perplexity697.36962890625
INFO:root:current mean train loss 8299.214862424424
INFO:root:current train perplexity697.8353271484375
INFO:root:current mean train loss 8300.796760599707
INFO:root:current train perplexity698.161865234375
INFO:root:current mean train loss 8298.926232009131
INFO:root:current train perplexity697.8004150390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.13s/it]
INFO:root:final mean train loss: 8296.908461054707
INFO:root:final train perplexity: 697.7784423828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.45s/it]
INFO:root:eval mean loss: 7777.547879266401
INFO:root:eval perplexity: 541.1553344726562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.59s/it]
INFO:root:eval mean loss: 7794.89729904283
INFO:root:eval perplexity: 606.9273681640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [21:41:18<27:21:18, 879.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8245.317989309211
INFO:root:current train perplexity683.1218872070312
INFO:root:current mean train loss 8249.58814853766
INFO:root:current train perplexity686.3193359375
INFO:root:current mean train loss 8231.023415982521
INFO:root:current train perplexity681.663818359375
INFO:root:current mean train loss 8252.907948477057
INFO:root:current train perplexity685.4228515625
INFO:root:current mean train loss 8261.112273121844
INFO:root:current train perplexity688.9348754882812
INFO:root:current mean train loss 8268.750811613709
INFO:root:current train perplexity687.6270141601562
INFO:root:current mean train loss 8285.095563314973
INFO:root:current train perplexity693.3305053710938
INFO:root:current mean train loss 8285.305635195558
INFO:root:current train perplexity693.76171875
INFO:root:current mean train loss 8281.373325659044
INFO:root:current train perplexity691.8004760742188
INFO:root:current mean train loss 8281.391914160648
INFO:root:current train perplexity692.8529052734375
INFO:root:current mean train loss 8285.393923016552
INFO:root:current train perplexity694.2395629882812
INFO:root:current mean train loss 8289.934894743725
INFO:root:current train perplexity696.83447265625
INFO:root:current mean train loss 8294.645900322756
INFO:root:current train perplexity699.2042846679688
INFO:root:current mean train loss 8298.58267109095
INFO:root:current train perplexity700.5028076171875
INFO:root:current mean train loss 8294.888531106291
INFO:root:current train perplexity700.5588989257812
INFO:root:current mean train loss 8299.709333365987
INFO:root:current train perplexity702.0255737304688
INFO:root:current mean train loss 8302.501424801807
INFO:root:current train perplexity702.1206665039062
INFO:root:current mean train loss 8303.201948772632
INFO:root:current train perplexity701.7227172851562
INFO:root:current mean train loss 8304.383705578
INFO:root:current train perplexity700.8860473632812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.21s/it]
INFO:root:final mean train loss: 8301.457494046072
INFO:root:final train perplexity: 700.2886962890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.77s/it]
INFO:root:eval mean loss: 7869.815076462766
INFO:root:eval perplexity: 583.1066284179688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.57s/it]
INFO:root:eval mean loss: 7879.864928766346
INFO:root:eval perplexity: 650.8397216796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [21:55:58<27:07:03, 879.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8269.040812174479
INFO:root:current train perplexity703.9168090820312
INFO:root:current mean train loss 8328.368643624442
INFO:root:current train perplexity720.9898681640625
INFO:root:current mean train loss 8318.928084463443
INFO:root:current train perplexity714.0723876953125
INFO:root:current mean train loss 8298.36787453676
INFO:root:current train perplexity703.899658203125
INFO:root:current mean train loss 8294.640096423695
INFO:root:current train perplexity701.3129272460938
INFO:root:current mean train loss 8301.690655708313
INFO:root:current train perplexity700.9127807617188
INFO:root:current mean train loss 8283.972230200674
INFO:root:current train perplexity695.8224487304688
INFO:root:current mean train loss 8280.647160562237
INFO:root:current train perplexity694.6707153320312
INFO:root:current mean train loss 8285.140021263085
INFO:root:current train perplexity695.5347900390625
INFO:root:current mean train loss 8283.910584566886
INFO:root:current train perplexity697.99072265625
INFO:root:current mean train loss 8290.541158924932
INFO:root:current train perplexity699.234619140625
INFO:root:current mean train loss 8285.320867963832
INFO:root:current train perplexity698.21044921875
INFO:root:current mean train loss 8301.152868289759
INFO:root:current train perplexity699.71923828125
INFO:root:current mean train loss 8308.062264047017
INFO:root:current train perplexity701.4761352539062
INFO:root:current mean train loss 8313.809233495263
INFO:root:current train perplexity701.7922973632812
INFO:root:current mean train loss 8316.004032518498
INFO:root:current train perplexity701.8529052734375
INFO:root:current mean train loss 8314.816513478016
INFO:root:current train perplexity702.6468505859375
INFO:root:current mean train loss 8317.007214412512
INFO:root:current train perplexity704.21826171875
INFO:root:current mean train loss 8314.886434188742
INFO:root:current train perplexity705.0001220703125
INFO:root:current mean train loss 8313.302091335154
INFO:root:current train perplexity704.973876953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.73s/it]
INFO:root:final mean train loss: 8310.676954183804
INFO:root:final train perplexity: 705.4019775390625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.72s/it]
INFO:root:eval mean loss: 7904.223580867686
INFO:root:eval perplexity: 599.571044921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.18s/it]
INFO:root:eval mean loss: 7916.1667515098625
INFO:root:eval perplexity: 670.5562744140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [22:10:38<26:52:46, 879.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8234.99755859375
INFO:root:current train perplexity724.6118774414062
INFO:root:current mean train loss 8376.731131147044
INFO:root:current train perplexity724.47021484375
INFO:root:current mean train loss 8394.718954694323
INFO:root:current train perplexity723.3314208984375
INFO:root:current mean train loss 8361.269755354768
INFO:root:current train perplexity717.6603393554688
INFO:root:current mean train loss 8340.041437891536
INFO:root:current train perplexity715.25830078125
INFO:root:current mean train loss 8312.69959257591
INFO:root:current train perplexity713.6976318359375
INFO:root:current mean train loss 8317.303789341962
INFO:root:current train perplexity714.3639526367188
INFO:root:current mean train loss 8318.73467640818
INFO:root:current train perplexity715.0414428710938
INFO:root:current mean train loss 8316.786870240878
INFO:root:current train perplexity715.0738525390625
INFO:root:current mean train loss 8320.63385265995
INFO:root:current train perplexity716.002197265625
INFO:root:current mean train loss 8330.139565870992
INFO:root:current train perplexity715.6049194335938
INFO:root:current mean train loss 8338.13953426013
INFO:root:current train perplexity715.6349487304688
INFO:root:current mean train loss 8329.219646307974
INFO:root:current train perplexity714.1010131835938
INFO:root:current mean train loss 8325.921038786211
INFO:root:current train perplexity713.9910278320312
INFO:root:current mean train loss 8331.925392743506
INFO:root:current train perplexity715.6520385742188
INFO:root:current mean train loss 8330.000009580404
INFO:root:current train perplexity717.2080688476562
INFO:root:current mean train loss 8334.941747357467
INFO:root:current train perplexity718.5831909179688
INFO:root:current mean train loss 8336.229825992265
INFO:root:current train perplexity719.3405151367188
INFO:root:current mean train loss 8339.29204050839
INFO:root:current train perplexity719.8267211914062
INFO:root:current mean train loss 8336.991104371193
INFO:root:current train perplexity719.904296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.20s/it]
INFO:root:final mean train loss: 8337.034918142099
INFO:root:final train perplexity: 720.2294311523438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.28s/it]
INFO:root:eval mean loss: 7945.266904573914
INFO:root:eval perplexity: 619.819091796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.93s/it]
INFO:root:eval mean loss: 7955.926323207557
INFO:root:eval perplexity: 692.83740234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [22:25:07<26:32:10, 876.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8367.382409137228
INFO:root:current train perplexity748.7451171875
INFO:root:current mean train loss 8356.143621575342
INFO:root:current train perplexity737.7793579101562
INFO:root:current mean train loss 8367.258447662602
INFO:root:current train perplexity737.332763671875
INFO:root:current mean train loss 8376.918667302656
INFO:root:current train perplexity734.8477172851562
INFO:root:current mean train loss 8366.510856046805
INFO:root:current train perplexity730.9768676757812
INFO:root:current mean train loss 8361.951969579899
INFO:root:current train perplexity728.5994262695312
INFO:root:current mean train loss 8366.447243705254
INFO:root:current train perplexity728.9065551757812
INFO:root:current mean train loss 8360.62711741266
INFO:root:current train perplexity728.3600463867188
INFO:root:current mean train loss 8351.01298274047
INFO:root:current train perplexity727.2055053710938
INFO:root:current mean train loss 8352.314425768862
INFO:root:current train perplexity727.1798095703125
INFO:root:current mean train loss 8357.042578498447
INFO:root:current train perplexity727.4711303710938
INFO:root:current mean train loss 8355.792869900743
INFO:root:current train perplexity726.9430541992188
INFO:root:current mean train loss 8353.779740090164
INFO:root:current train perplexity726.8386840820312
INFO:root:current mean train loss 8351.237621018296
INFO:root:current train perplexity726.99365234375
INFO:root:current mean train loss 8345.214325415478
INFO:root:current train perplexity726.4208374023438
INFO:root:current mean train loss 8348.38879536657
INFO:root:current train perplexity726.0499877929688
INFO:root:current mean train loss 8357.002505185392
INFO:root:current train perplexity727.343505859375
INFO:root:current mean train loss 8353.514594463684
INFO:root:current train perplexity726.9222412109375
INFO:root:current mean train loss 8351.343644725928
INFO:root:current train perplexity726.355712890625
INFO:root:current mean train loss 8350.857422878662
INFO:root:current train perplexity725.9672241210938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:32<00:00, 752.06s/it]
INFO:root:final mean train loss: 8346.425983407795
INFO:root:final train perplexity: 725.5868530273438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.67s/it]
INFO:root:eval mean loss: 7918.101971132535
INFO:root:eval perplexity: 606.3421630859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.54s/it]
INFO:root:eval mean loss: 7936.163430504765
INFO:root:eval perplexity: 681.671630859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [22:39:35<26:12:48, 873.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8390.895523313493
INFO:root:current train perplexity724.8859252929688
INFO:root:current mean train loss 8415.412990078605
INFO:root:current train perplexity731.052490234375
INFO:root:current mean train loss 8405.997044320342
INFO:root:current train perplexity736.4324951171875
INFO:root:current mean train loss 8398.122363550276
INFO:root:current train perplexity741.4192504882812
INFO:root:current mean train loss 8380.378691110962
INFO:root:current train perplexity736.2868041992188
INFO:root:current mean train loss 8380.093754336423
INFO:root:current train perplexity733.8031616210938
INFO:root:current mean train loss 8383.150909101621
INFO:root:current train perplexity733.4935913085938
INFO:root:current mean train loss 8381.581939737262
INFO:root:current train perplexity731.6690673828125
INFO:root:current mean train loss 8374.734580383654
INFO:root:current train perplexity730.5374755859375
INFO:root:current mean train loss 8375.109541816752
INFO:root:current train perplexity730.2355346679688
INFO:root:current mean train loss 8372.12111763582
INFO:root:current train perplexity729.153076171875
INFO:root:current mean train loss 8369.314212972915
INFO:root:current train perplexity727.5426025390625
INFO:root:current mean train loss 8361.605954711624
INFO:root:current train perplexity726.1326904296875
INFO:root:current mean train loss 8356.150676142355
INFO:root:current train perplexity725.2430419921875
INFO:root:current mean train loss 8351.879859116007
INFO:root:current train perplexity725.0369873046875
INFO:root:current mean train loss 8348.012807776511
INFO:root:current train perplexity724.9688720703125
INFO:root:current mean train loss 8347.855889499868
INFO:root:current train perplexity725.4440307617188
INFO:root:current mean train loss 8349.383678001364
INFO:root:current train perplexity725.3447265625
INFO:root:current mean train loss 8348.215079110474
INFO:root:current train perplexity724.2543334960938
INFO:root:current mean train loss 8345.234643641747
INFO:root:current train perplexity723.2893676757812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.38s/it]
INFO:root:final mean train loss: 8342.327875072886
INFO:root:final train perplexity: 723.2442016601562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.63s/it]
INFO:root:eval mean loss: 7858.636162940492
INFO:root:eval perplexity: 577.8558349609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.64s/it]
INFO:root:eval mean loss: 7890.890772176973
INFO:root:eval perplexity: 656.765869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [22:54:03<25:55:12, 872.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8272.009985351562
INFO:root:current train perplexity693.3463745117188
INFO:root:current mean train loss 8358.611265733507
INFO:root:current train perplexity706.6182861328125
INFO:root:current mean train loss 8356.890696498325
INFO:root:current train perplexity714.682861328125
INFO:root:current mean train loss 8322.557515676399
INFO:root:current train perplexity714.15478515625
INFO:root:current mean train loss 8329.95114440918
INFO:root:current train perplexity715.51416015625
INFO:root:current mean train loss 8335.758461577318
INFO:root:current train perplexity716.8344116210938
INFO:root:current mean train loss 8331.238060087317
INFO:root:current train perplexity715.5779418945312
INFO:root:current mean train loss 8324.21478928786
INFO:root:current train perplexity715.6220092773438
INFO:root:current mean train loss 8329.163335626776
INFO:root:current train perplexity715.685791015625
INFO:root:current mean train loss 8336.826714465084
INFO:root:current train perplexity715.92333984375
INFO:root:current mean train loss 8332.128100585938
INFO:root:current train perplexity714.701904296875
INFO:root:current mean train loss 8339.306909179688
INFO:root:current train perplexity715.2978515625
INFO:root:current mean train loss 8336.952779769897
INFO:root:current train perplexity715.4906005859375
INFO:root:current mean train loss 8335.17864158741
INFO:root:current train perplexity716.18798828125
INFO:root:current mean train loss 8332.69815838788
INFO:root:current train perplexity715.159423828125
INFO:root:current mean train loss 8330.765268060226
INFO:root:current train perplexity714.555419921875
INFO:root:current mean train loss 8327.528711809431
INFO:root:current train perplexity714.33837890625
INFO:root:current mean train loss 8330.771623727176
INFO:root:current train perplexity715.0421142578125
INFO:root:current mean train loss 8327.830183053524
INFO:root:current train perplexity714.4971313476562
INFO:root:current mean train loss 8328.818108822601
INFO:root:current train perplexity714.533935546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.55s/it]
INFO:root:final mean train loss: 8326.926810875842
INFO:root:final train perplexity: 714.5066528320312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.05s/it]
INFO:root:eval mean loss: 7875.169189453125
INFO:root:eval perplexity: 585.63818359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.94s/it]
INFO:root:eval mean loss: 7917.240476784131
INFO:root:eval perplexity: 671.1484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [23:08:44<25:45:25, 874.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8433.61376953125
INFO:root:current train perplexity717.091796875
INFO:root:current mean train loss 8351.613578680202
INFO:root:current train perplexity712.34716796875
INFO:root:current mean train loss 8323.356019504945
INFO:root:current train perplexity707.2911376953125
INFO:root:current mean train loss 8342.665503975126
INFO:root:current train perplexity713.1972045898438
INFO:root:current mean train loss 8337.471746494593
INFO:root:current train perplexity715.0574340820312
INFO:root:current mean train loss 8344.761852066322
INFO:root:current train perplexity716.8319702148438
INFO:root:current mean train loss 8338.655493409255
INFO:root:current train perplexity716.5452880859375
INFO:root:current mean train loss 8326.777378670993
INFO:root:current train perplexity714.679443359375
INFO:root:current mean train loss 8330.499688087897
INFO:root:current train perplexity713.9818115234375
INFO:root:current mean train loss 8332.651226139356
INFO:root:current train perplexity712.9513549804688
INFO:root:current mean train loss 8328.44961533942
INFO:root:current train perplexity713.3638305664062
INFO:root:current mean train loss 8327.508145363408
INFO:root:current train perplexity713.0567626953125
INFO:root:current mean train loss 8330.364737811416
INFO:root:current train perplexity714.5908203125
INFO:root:current mean train loss 8335.6625787821
INFO:root:current train perplexity715.076904296875
INFO:root:current mean train loss 8334.987528768474
INFO:root:current train perplexity715.40771484375
INFO:root:current mean train loss 8330.195036408599
INFO:root:current train perplexity715.8536987304688
INFO:root:current mean train loss 8333.399323426911
INFO:root:current train perplexity716.012451171875
INFO:root:current mean train loss 8330.193557730767
INFO:root:current train perplexity716.6071166992188
INFO:root:current mean train loss 8331.52660347753
INFO:root:current train perplexity717.30078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:43<00:00, 763.75s/it]
INFO:root:final mean train loss: 8333.362480990765
INFO:root:final train perplexity: 718.1447143554688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.20s/it]
INFO:root:eval mean loss: 7925.642392855164
INFO:root:eval perplexity: 610.0531616210938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.22s/it]
INFO:root:eval mean loss: 7968.89794921875
INFO:root:eval perplexity: 700.2656860351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [23:23:26<25:34:58, 877.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8432.772251674107
INFO:root:current train perplexity732.8482055664062
INFO:root:current mean train loss 8371.708654570997
INFO:root:current train perplexity726.28125
INFO:root:current mean train loss 8326.705821955315
INFO:root:current train perplexity723.8362426757812
INFO:root:current mean train loss 8334.434092916501
INFO:root:current train perplexity723.0272827148438
INFO:root:current mean train loss 8349.338217325256
INFO:root:current train perplexity724.61669921875
INFO:root:current mean train loss 8354.559028833293
INFO:root:current train perplexity722.7050170898438
INFO:root:current mean train loss 8354.789285168974
INFO:root:current train perplexity725.2845458984375
INFO:root:current mean train loss 8356.388627423627
INFO:root:current train perplexity727.0768432617188
INFO:root:current mean train loss 8359.000100175637
INFO:root:current train perplexity727.5613403320312
INFO:root:current mean train loss 8358.121141295986
INFO:root:current train perplexity728.7932739257812
INFO:root:current mean train loss 8350.98479779185
INFO:root:current train perplexity727.5263061523438
INFO:root:current mean train loss 8357.783355219788
INFO:root:current train perplexity728.9024047851562
INFO:root:current mean train loss 8350.546202104999
INFO:root:current train perplexity729.91455078125
INFO:root:current mean train loss 8348.411966309337
INFO:root:current train perplexity730.212158203125
INFO:root:current mean train loss 8353.387050601685
INFO:root:current train perplexity731.390380859375
INFO:root:current mean train loss 8346.64021186375
INFO:root:current train perplexity730.7959594726562
INFO:root:current mean train loss 8354.359529592142
INFO:root:current train perplexity732.3113403320312
INFO:root:current mean train loss 8359.412868575426
INFO:root:current train perplexity733.4487915039062
INFO:root:current mean train loss 8365.217917983824
INFO:root:current train perplexity734.2151489257812
INFO:root:current mean train loss 8365.699165431932
INFO:root:current train perplexity735.3622436523438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.63s/it]
INFO:root:final mean train loss: 8364.20274616959
INFO:root:final train perplexity: 735.838623046875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.32s/it]
INFO:root:eval mean loss: 7962.5269039505765
INFO:root:eval perplexity: 628.5362548828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it]
INFO:root:eval mean loss: 8010.559554729056
INFO:root:eval perplexity: 724.665771484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [23:38:07<25:22:16, 878.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8459.69181577621
INFO:root:current train perplexity769.5557861328125
INFO:root:current mean train loss 8396.931293982585
INFO:root:current train perplexity742.1061401367188
INFO:root:current mean train loss 8368.60180769751
INFO:root:current train perplexity742.4653930664062
INFO:root:current mean train loss 8368.648095260574
INFO:root:current train perplexity741.7506103515625
INFO:root:current mean train loss 8370.30900952545
INFO:root:current train perplexity740.6838989257812
INFO:root:current mean train loss 8365.318046727873
INFO:root:current train perplexity737.4853515625
INFO:root:current mean train loss 8370.284345285261
INFO:root:current train perplexity737.0863037109375
INFO:root:current mean train loss 8368.783089571221
INFO:root:current train perplexity736.5371704101562
INFO:root:current mean train loss 8372.671327372895
INFO:root:current train perplexity735.9540405273438
INFO:root:current mean train loss 8372.406989502215
INFO:root:current train perplexity735.538330078125
INFO:root:current mean train loss 8375.8157100585
INFO:root:current train perplexity733.650634765625
INFO:root:current mean train loss 8371.88385079921
INFO:root:current train perplexity733.0439453125
INFO:root:current mean train loss 8375.593832504062
INFO:root:current train perplexity733.6566162109375
INFO:root:current mean train loss 8370.457681680246
INFO:root:current train perplexity734.2515258789062
INFO:root:current mean train loss 8366.589815429004
INFO:root:current train perplexity734.1885375976562
INFO:root:current mean train loss 8365.68746683132
INFO:root:current train perplexity734.6630249023438
INFO:root:current mean train loss 8371.37657052326
INFO:root:current train perplexity734.6774291992188
INFO:root:current mean train loss 8369.135146997762
INFO:root:current train perplexity734.7639770507812
INFO:root:current mean train loss 8369.638056656626
INFO:root:current train perplexity734.745361328125
INFO:root:current mean train loss 8366.892274940526
INFO:root:current train perplexity734.7877807617188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:34<00:00, 754.36s/it]
INFO:root:final mean train loss: 8362.378247205741
INFO:root:final train perplexity: 734.7800903320312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.46s/it]
INFO:root:eval mean loss: 8006.81128622285
INFO:root:eval perplexity: 651.46875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.13s/it]
INFO:root:eval mean loss: 8053.399753435284
INFO:root:eval perplexity: 750.6441040039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [23:52:38<25:03:36, 875.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8505.200744628906
INFO:root:current train perplexity775.6306762695312
INFO:root:current mean train loss 8458.435507284628
INFO:root:current train perplexity767.4819946289062
INFO:root:current mean train loss 8417.606528005292
INFO:root:current train perplexity760.2758178710938
INFO:root:current mean train loss 8424.656450644306
INFO:root:current train perplexity759.1901245117188
INFO:root:current mean train loss 8413.775058201381
INFO:root:current train perplexity756.4546508789062
INFO:root:current mean train loss 8420.153355062443
INFO:root:current train perplexity755.870849609375
INFO:root:current mean train loss 8419.035120834538
INFO:root:current train perplexity754.49853515625
INFO:root:current mean train loss 8416.949867615725
INFO:root:current train perplexity754.4888305664062
INFO:root:current mean train loss 8413.734859250626
INFO:root:current train perplexity754.7532958984375
INFO:root:current mean train loss 8407.990172052183
INFO:root:current train perplexity754.2974243164062
INFO:root:current mean train loss 8407.497871690124
INFO:root:current train perplexity755.3995971679688
INFO:root:current mean train loss 8403.533676944959
INFO:root:current train perplexity755.17626953125
INFO:root:current mean train loss 8404.467457697941
INFO:root:current train perplexity755.9360961914062
INFO:root:current mean train loss 8408.536554444085
INFO:root:current train perplexity756.132568359375
INFO:root:current mean train loss 8405.054339498447
INFO:root:current train perplexity755.9436645507812
INFO:root:current mean train loss 8401.256614192203
INFO:root:current train perplexity754.6863403320312
INFO:root:current mean train loss 8397.78987077139
INFO:root:current train perplexity753.689453125
INFO:root:current mean train loss 8395.030984629755
INFO:root:current train perplexity752.2113037109375
INFO:root:current mean train loss 8391.557853665703
INFO:root:current train perplexity751.1808471679688
INFO:root:current mean train loss 8393.387685536849
INFO:root:current train perplexity751.2245483398438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.93s/it]
INFO:root:final mean train loss: 8390.845807281818
INFO:root:final train perplexity: 751.4742431640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.60s/it]
INFO:root:eval mean loss: 8002.415889225953
INFO:root:eval perplexity: 649.1551513671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.93s/it]
INFO:root:eval mean loss: 8055.176111965315
INFO:root:eval perplexity: 751.7401733398438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [24:07:16<24:50:03, 876.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8352.850262920672
INFO:root:current train perplexity760.7222290039062
INFO:root:current mean train loss 8438.946561316288
INFO:root:current train perplexity759.1824951171875
INFO:root:current mean train loss 8372.72392393868
INFO:root:current train perplexity749.6178588867188
INFO:root:current mean train loss 8388.788044467037
INFO:root:current train perplexity752.7086181640625
INFO:root:current mean train loss 8397.61802125336
INFO:root:current train perplexity750.5166625976562
INFO:root:current mean train loss 8391.735027482024
INFO:root:current train perplexity749.03759765625
INFO:root:current mean train loss 8392.189762981672
INFO:root:current train perplexity749.2569580078125
INFO:root:current mean train loss 8391.944775709762
INFO:root:current train perplexity750.2218627929688
INFO:root:current mean train loss 8396.621252935332
INFO:root:current train perplexity751.3112182617188
INFO:root:current mean train loss 8395.794080412079
INFO:root:current train perplexity749.6132202148438
INFO:root:current mean train loss 8392.22021530223
INFO:root:current train perplexity748.6669311523438
INFO:root:current mean train loss 8387.633284854479
INFO:root:current train perplexity747.968994140625
INFO:root:current mean train loss 8378.254793648099
INFO:root:current train perplexity745.781982421875
INFO:root:current mean train loss 8375.551953482714
INFO:root:current train perplexity745.3638916015625
INFO:root:current mean train loss 8378.79001039889
INFO:root:current train perplexity745.5515747070312
INFO:root:current mean train loss 8382.883353821386
INFO:root:current train perplexity746.3020629882812
INFO:root:current mean train loss 8384.053534687031
INFO:root:current train perplexity746.552978515625
INFO:root:current mean train loss 8381.340094115174
INFO:root:current train perplexity745.9576416015625
INFO:root:current mean train loss 8383.552982311914
INFO:root:current train perplexity746.1522827148438
INFO:root:current mean train loss 8382.40835892772
INFO:root:current train perplexity745.6030883789062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.77s/it]
INFO:root:final mean train loss: 8380.931720527808
INFO:root:final train perplexity: 745.61767578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.87s/it]
INFO:root:eval mean loss: 8005.70556640625
INFO:root:eval perplexity: 650.88623046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it]
INFO:root:eval mean loss: 8063.72835113309
INFO:root:eval perplexity: 757.0449829101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [24:21:54<24:36:29, 877.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8326.848210032393
INFO:root:current train perplexity728.8818969726562
INFO:root:current mean train loss 8375.288732507726
INFO:root:current train perplexity739.9464721679688
INFO:root:current mean train loss 8387.041387896166
INFO:root:current train perplexity738.4815673828125
INFO:root:current mean train loss 8373.493932274623
INFO:root:current train perplexity735.0120239257812
INFO:root:current mean train loss 8376.98456038479
INFO:root:current train perplexity735.402587890625
INFO:root:current mean train loss 8370.972049673808
INFO:root:current train perplexity736.8561401367188
INFO:root:current mean train loss 8361.173938382057
INFO:root:current train perplexity737.2047729492188
INFO:root:current mean train loss 8356.732283882473
INFO:root:current train perplexity736.1898803710938
INFO:root:current mean train loss 8351.37515002746
INFO:root:current train perplexity734.1416015625
INFO:root:current mean train loss 8342.574411675789
INFO:root:current train perplexity731.828857421875
INFO:root:current mean train loss 8346.34062400719
INFO:root:current train perplexity732.8450927734375
INFO:root:current mean train loss 8353.538706823048
INFO:root:current train perplexity733.8374633789062
INFO:root:current mean train loss 8354.074826245003
INFO:root:current train perplexity734.0250854492188
INFO:root:current mean train loss 8355.365378527496
INFO:root:current train perplexity733.458251953125
INFO:root:current mean train loss 8360.990457429256
INFO:root:current train perplexity734.2694091796875
INFO:root:current mean train loss 8359.558531403089
INFO:root:current train perplexity734.6399536132812
INFO:root:current mean train loss 8365.143266421577
INFO:root:current train perplexity735.0698852539062
INFO:root:current mean train loss 8363.1208137144
INFO:root:current train perplexity735.1049194335938
INFO:root:current mean train loss 8364.19890429895
INFO:root:current train perplexity735.2027587890625
INFO:root:current mean train loss 8366.6945416463
INFO:root:current train perplexity735.896484375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.70s/it]
INFO:root:final mean train loss: 8364.312201072396
INFO:root:final train perplexity: 735.902099609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.43s/it]
INFO:root:eval mean loss: 7974.660628947806
INFO:root:eval perplexity: 634.73828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.51s/it]
INFO:root:eval mean loss: 8033.320128961658
INFO:root:eval perplexity: 738.3533935546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [24:36:35<24:23:53, 878.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8410.426836726641
INFO:root:current train perplexity733.2677001953125
INFO:root:current mean train loss 8417.547297032035
INFO:root:current train perplexity740.46923828125
INFO:root:current mean train loss 8423.212947781669
INFO:root:current train perplexity739.8067626953125
INFO:root:current mean train loss 8423.37979592536
INFO:root:current train perplexity741.4917602539062
INFO:root:current mean train loss 8405.462917045028
INFO:root:current train perplexity739.5090942382812
INFO:root:current mean train loss 8398.550319869053
INFO:root:current train perplexity739.6653442382812
INFO:root:current mean train loss 8391.093349735112
INFO:root:current train perplexity737.1467895507812
INFO:root:current mean train loss 8376.506472323803
INFO:root:current train perplexity734.2298583984375
INFO:root:current mean train loss 8370.632152587075
INFO:root:current train perplexity733.3729248046875
INFO:root:current mean train loss 8365.041409084866
INFO:root:current train perplexity732.3703002929688
INFO:root:current mean train loss 8365.997295570547
INFO:root:current train perplexity733.149169921875
INFO:root:current mean train loss 8361.55415930919
INFO:root:current train perplexity733.076416015625
INFO:root:current mean train loss 8363.186840688752
INFO:root:current train perplexity734.5362548828125
INFO:root:current mean train loss 8359.116697822663
INFO:root:current train perplexity734.2732543945312
INFO:root:current mean train loss 8363.179401176305
INFO:root:current train perplexity735.4488525390625
INFO:root:current mean train loss 8365.674240369957
INFO:root:current train perplexity736.530517578125
INFO:root:current mean train loss 8364.967611922455
INFO:root:current train perplexity737.095458984375
INFO:root:current mean train loss 8365.049566110947
INFO:root:current train perplexity736.6056518554688
INFO:root:current mean train loss 8369.726873878933
INFO:root:current train perplexity736.9225463867188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.39s/it]
INFO:root:final mean train loss: 8365.939194702825
INFO:root:final train perplexity: 736.8477172851562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it]
INFO:root:eval mean loss: 7993.639745401152
INFO:root:eval perplexity: 644.5621337890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.55s/it]
INFO:root:eval mean loss: 8048.988056155807
INFO:root:eval perplexity: 747.9254760742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [24:51:20<24:12:30, 880.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8479.337768554688
INFO:root:current train perplexity744.608642578125
INFO:root:current mean train loss 8394.749208647629
INFO:root:current train perplexity743.9130859375
INFO:root:current mean train loss 8371.698441116898
INFO:root:current train perplexity741.2347412109375
INFO:root:current mean train loss 8378.391575294205
INFO:root:current train perplexity740.517578125
INFO:root:current mean train loss 8394.988331721379
INFO:root:current train perplexity744.45703125
INFO:root:current mean train loss 8413.801541114039
INFO:root:current train perplexity749.203369140625
INFO:root:current mean train loss 8406.858995313769
INFO:root:current train perplexity748.0546264648438
INFO:root:current mean train loss 8403.178851420653
INFO:root:current train perplexity748.8344116210938
INFO:root:current mean train loss 8388.981897690717
INFO:root:current train perplexity745.8203735351562
INFO:root:current mean train loss 8391.332281787323
INFO:root:current train perplexity745.00537109375
INFO:root:current mean train loss 8393.962992029867
INFO:root:current train perplexity744.64306640625
INFO:root:current mean train loss 8389.206863676774
INFO:root:current train perplexity743.9208374023438
INFO:root:current mean train loss 8390.546007256758
INFO:root:current train perplexity743.803466796875
INFO:root:current mean train loss 8385.889552710629
INFO:root:current train perplexity743.7300415039062
INFO:root:current mean train loss 8380.763468079647
INFO:root:current train perplexity741.8312377929688
INFO:root:current mean train loss 8379.352303940263
INFO:root:current train perplexity741.3552856445312
INFO:root:current mean train loss 8376.607584736135
INFO:root:current train perplexity740.6160888671875
INFO:root:current mean train loss 8375.28129012101
INFO:root:current train perplexity739.5870361328125
INFO:root:current mean train loss 8371.097397858875
INFO:root:current train perplexity738.9144897460938
INFO:root:current mean train loss 8372.910492899025
INFO:root:current train perplexity739.4960327148438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:40<00:00, 760.96s/it]
INFO:root:final mean train loss: 8372.093098588983
INFO:root:final train perplexity: 740.4346313476562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.09s/it]
INFO:root:eval mean loss: 7996.631257618573
INFO:root:eval perplexity: 646.1240844726562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.05s/it]
INFO:root:eval mean loss: 8049.920536555297
INFO:root:eval perplexity: 748.4998779296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [25:06:00<23:57:28, 880.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8395.201793323864
INFO:root:current train perplexity738.4579467773438
INFO:root:current mean train loss 8358.10302734375
INFO:root:current train perplexity737.56201171875
INFO:root:current mean train loss 8381.396698129023
INFO:root:current train perplexity745.4655151367188
INFO:root:current mean train loss 8377.537887985642
INFO:root:current train perplexity748.7197875976562
INFO:root:current mean train loss 8400.90819861432
INFO:root:current train perplexity751.1156616210938
INFO:root:current mean train loss 8428.914829275622
INFO:root:current train perplexity755.1201171875
INFO:root:current mean train loss 8429.455895012588
INFO:root:current train perplexity753.9061889648438
INFO:root:current mean train loss 8421.370902567573
INFO:root:current train perplexity752.6185302734375
INFO:root:current mean train loss 8403.842151509041
INFO:root:current train perplexity750.38818359375
INFO:root:current mean train loss 8405.136080268623
INFO:root:current train perplexity751.0733642578125
INFO:root:current mean train loss 8399.519368647145
INFO:root:current train perplexity750.8141479492188
INFO:root:current mean train loss 8390.682996866037
INFO:root:current train perplexity749.840576171875
INFO:root:current mean train loss 8384.821643096107
INFO:root:current train perplexity749.4134521484375
INFO:root:current mean train loss 8382.191614309828
INFO:root:current train perplexity748.6173706054688
INFO:root:current mean train loss 8383.80026979839
INFO:root:current train perplexity748.6319580078125
INFO:root:current mean train loss 8384.615010459984
INFO:root:current train perplexity748.5245361328125
INFO:root:current mean train loss 8380.897048006449
INFO:root:current train perplexity748.4420776367188
INFO:root:current mean train loss 8376.496143620618
INFO:root:current train perplexity747.8499145507812
INFO:root:current mean train loss 8379.930118508762
INFO:root:current train perplexity747.13134765625
INFO:root:current mean train loss 8381.95062448469
INFO:root:current train perplexity746.0252685546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:39<00:00, 759.70s/it]
INFO:root:final mean train loss: 8380.935348287592
INFO:root:final train perplexity: 745.6198120117188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.06s/it]
INFO:root:eval mean loss: 7952.686173675754
INFO:root:eval perplexity: 623.5515747070312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.01s/it]
INFO:root:eval mean loss: 8005.750176612367
INFO:root:eval perplexity: 721.8068237304688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [25:20:37<23:41:27, 879.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8509.42310546875
INFO:root:current train perplexity740.640869140625
INFO:root:current mean train loss 8439.691741536459
INFO:root:current train perplexity748.0706787109375
INFO:root:current mean train loss 8420.605103515625
INFO:root:current train perplexity742.263671875
INFO:root:current mean train loss 8384.634481026786
INFO:root:current train perplexity736.2169189453125
INFO:root:current mean train loss 8384.260783420139
INFO:root:current train perplexity734.7229614257812
INFO:root:current mean train loss 8377.030556640624
INFO:root:current train perplexity734.6637573242188
INFO:root:current mean train loss 8367.386094501202
INFO:root:current train perplexity735.2760009765625
INFO:root:current mean train loss 8363.000637369792
INFO:root:current train perplexity734.7586669921875
INFO:root:current mean train loss 8362.11762522978
INFO:root:current train perplexity735.01171875
INFO:root:current mean train loss 8367.872236328125
INFO:root:current train perplexity736.24609375
INFO:root:current mean train loss 8370.947037295387
INFO:root:current train perplexity736.4321899414062
INFO:root:current mean train loss 8367.1438671875
INFO:root:current train perplexity735.9761352539062
INFO:root:current mean train loss 8370.63116015625
INFO:root:current train perplexity735.9522705078125
INFO:root:current mean train loss 8368.674309534144
INFO:root:current train perplexity736.0691528320312
INFO:root:current mean train loss 8367.85385775862
INFO:root:current train perplexity736.1337280273438
INFO:root:current mean train loss 8372.150746912803
INFO:root:current train perplexity736.6446533203125
INFO:root:current mean train loss 8367.949164003314
INFO:root:current train perplexity736.3012084960938
INFO:root:current mean train loss 8369.206462611608
INFO:root:current train perplexity736.877197265625
INFO:root:current mean train loss 8370.254134554476
INFO:root:current train perplexity736.9232788085938
INFO:root:current mean train loss 8368.097658253206
INFO:root:current train perplexity736.15869140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:41<00:00, 761.16s/it]
INFO:root:final mean train loss: 8364.4576070673
INFO:root:final train perplexity: 735.9866943359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.82s/it]
INFO:root:eval mean loss: 7932.004488031915
INFO:root:eval perplexity: 613.2020263671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.63s/it]
INFO:root:eval mean loss: 7984.441011469415
INFO:root:eval perplexity: 709.2713012695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [25:35:14<23:25:45, 878.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8280.1698854361
INFO:root:current train perplexity716.212890625
INFO:root:current mean train loss 8336.514087060254
INFO:root:current train perplexity728.0569458007812
INFO:root:current mean train loss 8338.312832835909
INFO:root:current train perplexity732.1636352539062
INFO:root:current mean train loss 8341.011434030142
INFO:root:current train perplexity728.789794921875
INFO:root:current mean train loss 8353.056772366836
INFO:root:current train perplexity729.996337890625
INFO:root:current mean train loss 8360.691286547895
INFO:root:current train perplexity730.8046875
INFO:root:current mean train loss 8353.800618001545
INFO:root:current train perplexity732.9680786132812
INFO:root:current mean train loss 8354.130676030802
INFO:root:current train perplexity732.1056518554688
INFO:root:current mean train loss 8355.723666040405
INFO:root:current train perplexity732.1161499023438
INFO:root:current mean train loss 8360.285777331632
INFO:root:current train perplexity732.3790283203125
INFO:root:current mean train loss 8363.019249813291
INFO:root:current train perplexity732.18701171875
INFO:root:current mean train loss 8358.833102372537
INFO:root:current train perplexity730.5203857421875
INFO:root:current mean train loss 8353.366260652008
INFO:root:current train perplexity728.9065551757812
INFO:root:current mean train loss 8348.314193089338
INFO:root:current train perplexity728.1541137695312
INFO:root:current mean train loss 8346.678670330606
INFO:root:current train perplexity728.03955078125
INFO:root:current mean train loss 8346.94595627094
INFO:root:current train perplexity727.8594360351562
INFO:root:current mean train loss 8344.770737454071
INFO:root:current train perplexity728.1124877929688
INFO:root:current mean train loss 8344.463080466097
INFO:root:current train perplexity726.9697265625
INFO:root:current mean train loss 8344.711648083909
INFO:root:current train perplexity725.9983520507812
INFO:root:current mean train loss 8349.392561244917
INFO:root:current train perplexity726.3065185546875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:37<00:00, 757.34s/it]
INFO:root:final mean train loss: 8347.907294522976
INFO:root:final train perplexity: 726.4357299804688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.20s/it]
INFO:root:eval mean loss: 7920.609833845855
INFO:root:eval perplexity: 607.573974609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.09s/it]
INFO:root:eval mean loss: 7971.900923925089
INFO:root:eval perplexity: 701.9964599609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [25:49:49<23:09:28, 877.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8292.154965355283
INFO:root:current train perplexity724.8689575195312
INFO:root:current mean train loss 8259.24070142663
INFO:root:current train perplexity718.9300537109375
INFO:root:current mean train loss 8289.85244278169
INFO:root:current train perplexity721.0177001953125
INFO:root:current mean train loss 8306.667953491211
INFO:root:current train perplexity721.7538452148438
INFO:root:current mean train loss 8312.249062782477
INFO:root:current train perplexity720.6766967773438
INFO:root:current mean train loss 8314.733565657107
INFO:root:current train perplexity721.50537109375
INFO:root:current mean train loss 8317.178163405748
INFO:root:current train perplexity720.8688354492188
INFO:root:current mean train loss 8331.397091612524
INFO:root:current train perplexity721.4290161132812
INFO:root:current mean train loss 8332.163854814762
INFO:root:current train perplexity722.5596313476562
INFO:root:current mean train loss 8331.33638806847
INFO:root:current train perplexity722.6629638671875
INFO:root:current mean train loss 8331.481921431763
INFO:root:current train perplexity722.0753173828125
INFO:root:current mean train loss 8334.710111463392
INFO:root:current train perplexity722.072265625
INFO:root:current mean train loss 8333.868529893156
INFO:root:current train perplexity722.25439453125
INFO:root:current mean train loss 8339.571002232546
INFO:root:current train perplexity722.6660766601562
INFO:root:current mean train loss 8339.187930700913
INFO:root:current train perplexity722.2440795898438
INFO:root:current mean train loss 8338.381780142736
INFO:root:current train perplexity721.9259033203125
INFO:root:current mean train loss 8338.736110660073
INFO:root:current train perplexity721.4644165039062
INFO:root:current mean train loss 8338.826124251156
INFO:root:current train perplexity721.4231567382812
INFO:root:current mean train loss 8337.880213257613
INFO:root:current train perplexity721.0242309570312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.24s/it]
INFO:root:final mean train loss: 8337.933167273386
INFO:root:final train perplexity: 720.7399291992188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.65s/it]
INFO:root:eval mean loss: 7867.692668508976
INFO:root:eval perplexity: 582.10595703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.31s/it]
INFO:root:eval mean loss: 7919.553863308954
INFO:root:eval perplexity: 672.4262084960938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [26:04:33<22:57:45, 879.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8082.9814453125
INFO:root:current train perplexity695.7039794921875
INFO:root:current mean train loss 8343.76373955755
INFO:root:current train perplexity713.914794921875
INFO:root:current mean train loss 8318.713213716574
INFO:root:current train perplexity710.4577026367188
INFO:root:current mean train loss 8349.198268142649
INFO:root:current train perplexity718.3516235351562
INFO:root:current mean train loss 8367.173533451527
INFO:root:current train perplexity719.0294799804688
INFO:root:current mean train loss 8355.79530002495
INFO:root:current train perplexity716.9793090820312
INFO:root:current mean train loss 8350.802324088758
INFO:root:current train perplexity716.4793090820312
INFO:root:current mean train loss 8346.030818139265
INFO:root:current train perplexity716.3905029296875
INFO:root:current mean train loss 8348.322071165925
INFO:root:current train perplexity717.651123046875
INFO:root:current mean train loss 8342.948947783712
INFO:root:current train perplexity718.5040283203125
INFO:root:current mean train loss 8339.648749687813
INFO:root:current train perplexity717.4622192382812
INFO:root:current mean train loss 8335.94352878775
INFO:root:current train perplexity717.0989990234375
INFO:root:current mean train loss 8335.055748220884
INFO:root:current train perplexity716.8111572265625
INFO:root:current mean train loss 8331.93148937416
INFO:root:current train perplexity716.4407348632812
INFO:root:current mean train loss 8328.965908837437
INFO:root:current train perplexity715.692626953125
INFO:root:current mean train loss 8329.497073890843
INFO:root:current train perplexity714.7918701171875
INFO:root:current mean train loss 8324.436132141533
INFO:root:current train perplexity713.0210571289062
INFO:root:current mean train loss 8325.247808906066
INFO:root:current train perplexity711.6738891601562
INFO:root:current mean train loss 8320.8268456001
INFO:root:current train perplexity711.0222778320312
INFO:root:current mean train loss 8322.68393973361
INFO:root:current train perplexity710.0560302734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:31<00:00, 751.92s/it]
INFO:root:final mean train loss: 8318.827697169101
INFO:root:final train perplexity: 709.9541015625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.65s/it]
INFO:root:eval mean loss: 7845.299361425089
INFO:root:eval perplexity: 571.6527709960938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.65s/it]
INFO:root:eval mean loss: 7896.895280986813
INFO:root:eval perplexity: 660.01611328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [26:19:02<22:38:07, 876.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8231.583197699652
INFO:root:current train perplexity700.48974609375
INFO:root:current mean train loss 8316.77680581303
INFO:root:current train perplexity698.753662109375
INFO:root:current mean train loss 8365.709595846474
INFO:root:current train perplexity709.981201171875
INFO:root:current mean train loss 8374.454717288227
INFO:root:current train perplexity715.9414672851562
INFO:root:current mean train loss 8348.216242009943
INFO:root:current train perplexity711.4991455078125
INFO:root:current mean train loss 8335.631171384834
INFO:root:current train perplexity709.4478149414062
INFO:root:current mean train loss 8334.336156357453
INFO:root:current train perplexity709.802490234375
INFO:root:current mean train loss 8317.581107051923
INFO:root:current train perplexity705.70947265625
INFO:root:current mean train loss 8318.522791631647
INFO:root:current train perplexity704.9923706054688
INFO:root:current mean train loss 8318.973110489856
INFO:root:current train perplexity705.706787109375
INFO:root:current mean train loss 8315.418466624202
INFO:root:current train perplexity706.6344604492188
INFO:root:current mean train loss 8309.722106824407
INFO:root:current train perplexity706.4208374023438
INFO:root:current mean train loss 8306.01500602935
INFO:root:current train perplexity704.5205688476562
INFO:root:current mean train loss 8299.536788546804
INFO:root:current train perplexity702.89111328125
INFO:root:current mean train loss 8297.871812742418
INFO:root:current train perplexity701.7186889648438
INFO:root:current mean train loss 8298.327758306572
INFO:root:current train perplexity701.4373168945312
INFO:root:current mean train loss 8300.324831364918
INFO:root:current train perplexity700.61767578125
INFO:root:current mean train loss 8301.845930781159
INFO:root:current train perplexity700.7921142578125
INFO:root:current mean train loss 8304.390217830376
INFO:root:current train perplexity701.1229858398438
INFO:root:current mean train loss 8303.55861666205
INFO:root:current train perplexity700.9268188476562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:26<00:00, 746.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:26<00:00, 746.10s/it]
INFO:root:final mean train loss: 8302.434379235217
INFO:root:final train perplexity: 700.8285522460938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.10s/it]
INFO:root:eval mean loss: 7819.148082543772
INFO:root:eval perplexity: 559.6824951171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.49s/it]
INFO:root:eval mean loss: 7866.183359998337
INFO:root:eval perplexity: 643.5593872070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [26:33:22<22:16:11, 871.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8234.8029296875
INFO:root:current train perplexity698.9072875976562
INFO:root:current mean train loss 8266.883373119214
INFO:root:current train perplexity693.2339477539062
INFO:root:current mean train loss 8312.997084857048
INFO:root:current train perplexity700.94482421875
INFO:root:current mean train loss 8307.278189132463
INFO:root:current train perplexity699.492431640625
INFO:root:current mean train loss 8292.662937769397
INFO:root:current train perplexity695.3753051757812
INFO:root:current mean train loss 8281.637940822138
INFO:root:current train perplexity693.768310546875
INFO:root:current mean train loss 8279.90478284941
INFO:root:current train perplexity692.6289672851562
INFO:root:current mean train loss 8276.168594547195
INFO:root:current train perplexity690.856689453125
INFO:root:current mean train loss 8282.677934950412
INFO:root:current train perplexity690.5335693359375
INFO:root:current mean train loss 8286.465548755014
INFO:root:current train perplexity690.755859375
INFO:root:current mean train loss 8288.921096108847
INFO:root:current train perplexity691.0797119140625
INFO:root:current mean train loss 8287.282836161206
INFO:root:current train perplexity691.1275024414062
INFO:root:current mean train loss 8285.154886766195
INFO:root:current train perplexity690.8257446289062
INFO:root:current mean train loss 8285.280399256788
INFO:root:current train perplexity691.83544921875
INFO:root:current mean train loss 8286.04355230564
INFO:root:current train perplexity692.8846435546875
INFO:root:current mean train loss 8289.622092897496
INFO:root:current train perplexity693.4862060546875
INFO:root:current mean train loss 8291.50218069094
INFO:root:current train perplexity693.31494140625
INFO:root:current mean train loss 8292.807612966048
INFO:root:current train perplexity694.2587890625
INFO:root:current mean train loss 8293.326757546407
INFO:root:current train perplexity694.1680908203125
INFO:root:current mean train loss 8293.874578336967
INFO:root:current train perplexity694.9437255859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:42<00:00, 762.43s/it]
INFO:root:final mean train loss: 8291.321678850305
INFO:root:final train perplexity: 694.7091674804688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.19s/it]
INFO:root:eval mean loss: 7809.459900335217
INFO:root:eval perplexity: 555.3117065429688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.45s/it]
INFO:root:eval mean loss: 7853.049134599401
INFO:root:eval perplexity: 636.6476440429688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [26:48:03<22:05:48, 874.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8336.365591195914
INFO:root:current train perplexity715.4602661132812
INFO:root:current mean train loss 8294.02476742393
INFO:root:current train perplexity701.4862060546875
INFO:root:current mean train loss 8302.9512687562
INFO:root:current train perplexity698.3243408203125
INFO:root:current mean train loss 8296.11177479137
INFO:root:current train perplexity691.8060913085938
INFO:root:current mean train loss 8282.772931934458
INFO:root:current train perplexity689.5928344726562
INFO:root:current mean train loss 8277.16278341542
INFO:root:current train perplexity688.103271484375
INFO:root:current mean train loss 8285.160535192197
INFO:root:current train perplexity686.3311157226562
INFO:root:current mean train loss 8292.712678949883
INFO:root:current train perplexity687.59814453125
INFO:root:current mean train loss 8297.418377943442
INFO:root:current train perplexity689.55078125
INFO:root:current mean train loss 8287.932743873916
INFO:root:current train perplexity688.8494262695312
INFO:root:current mean train loss 8284.63827595874
INFO:root:current train perplexity690.3943481445312
INFO:root:current mean train loss 8287.164240519205
INFO:root:current train perplexity690.5596313476562
INFO:root:current mean train loss 8287.16426569052
INFO:root:current train perplexity690.774658203125
INFO:root:current mean train loss 8285.684518306212
INFO:root:current train perplexity690.5204467773438
INFO:root:current mean train loss 8285.716889352509
INFO:root:current train perplexity690.4910888671875
INFO:root:current mean train loss 8283.729148628785
INFO:root:current train perplexity690.0303344726562
INFO:root:current mean train loss 8289.15534910336
INFO:root:current train perplexity690.536865234375
INFO:root:current mean train loss 8286.123069449646
INFO:root:current train perplexity689.512939453125
INFO:root:current mean train loss 8285.820971626958
INFO:root:current train perplexity688.8579711914062
INFO:root:current mean train loss 8281.70849734447
INFO:root:current train perplexity688.1314697265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:45<00:00, 765.77s/it]
INFO:root:final mean train loss: 8279.616876014483
INFO:root:final train perplexity: 688.32080078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.23s/it]
INFO:root:eval mean loss: 7760.53936377992
INFO:root:eval perplexity: 533.7579956054688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.70s/it]
INFO:root:eval mean loss: 7805.817271996897
INFO:root:eval perplexity: 612.4002685546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [27:02:47<21:55:43, 877.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8358.986214900362
INFO:root:current train perplexity693.21875
INFO:root:current mean train loss 8345.573869152182
INFO:root:current train perplexity699.14892578125
INFO:root:current mean train loss 8343.084966383016
INFO:root:current train perplexity694.6213989257812
INFO:root:current mean train loss 8322.950328961297
INFO:root:current train perplexity691.9845581054688
INFO:root:current mean train loss 8303.661268156982
INFO:root:current train perplexity689.4853515625
INFO:root:current mean train loss 8294.609424772078
INFO:root:current train perplexity688.8494262695312
INFO:root:current mean train loss 8277.345170321842
INFO:root:current train perplexity685.4085083007812
INFO:root:current mean train loss 8263.214353563882
INFO:root:current train perplexity683.6882934570312
INFO:root:current mean train loss 8267.730954221806
INFO:root:current train perplexity683.3636474609375
INFO:root:current mean train loss 8271.945649610585
INFO:root:current train perplexity683.3235473632812
INFO:root:current mean train loss 8276.485178448755
INFO:root:current train perplexity684.1611328125
INFO:root:current mean train loss 8272.003227083778
INFO:root:current train perplexity682.6559448242188
INFO:root:current mean train loss 8275.693781089933
INFO:root:current train perplexity682.0347900390625
INFO:root:current mean train loss 8274.588056833227
INFO:root:current train perplexity681.4889526367188
INFO:root:current mean train loss 8271.761380709135
INFO:root:current train perplexity680.868896484375
INFO:root:current mean train loss 8272.194661458334
INFO:root:current train perplexity680.8201904296875
INFO:root:current mean train loss 8272.601616916005
INFO:root:current train perplexity681.8283081054688
INFO:root:current mean train loss 8270.851991712743
INFO:root:current train perplexity681.7792358398438
INFO:root:current mean train loss 8270.430508878411
INFO:root:current train perplexity682.0263671875
INFO:root:current mean train loss 8270.246282962084
INFO:root:current train perplexity682.1148071289062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:33<00:00, 753.76s/it]
INFO:root:final mean train loss: 8268.156206539768
INFO:root:final train perplexity: 682.1235961914062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.17s/it]
INFO:root:eval mean loss: 7768.285251482159
INFO:root:eval perplexity: 537.1143798828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.55s/it]
INFO:root:eval mean loss: 7812.328234949856
INFO:root:eval perplexity: 615.6871948242188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [27:17:17<21:37:54, 875.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8215.848871275435
INFO:root:current train perplexity683.3176879882812
INFO:root:current mean train loss 8227.237273185483
INFO:root:current train perplexity680.3226928710938
INFO:root:current mean train loss 8223.822096604566
INFO:root:current train perplexity680.6458740234375
INFO:root:current mean train loss 8240.468743675114
INFO:root:current train perplexity682.2644653320312
INFO:root:current mean train loss 8235.068314163773
INFO:root:current train perplexity680.1011962890625
INFO:root:current mean train loss 8243.485315732989
INFO:root:current train perplexity677.8277587890625
INFO:root:current mean train loss 8255.164822681305
INFO:root:current train perplexity678.5473022460938
INFO:root:current mean train loss 8271.659102655853
INFO:root:current train perplexity679.6541137695312
INFO:root:current mean train loss 8278.376805428188
INFO:root:current train perplexity679.7678833007812
INFO:root:current mean train loss 8284.744981498796
INFO:root:current train perplexity681.6989135742188
INFO:root:current mean train loss 8271.082709268532
INFO:root:current train perplexity678.5919799804688
INFO:root:current mean train loss 8280.076973874895
INFO:root:current train perplexity680.1621704101562
INFO:root:current mean train loss 8283.605699981168
INFO:root:current train perplexity681.2973022460938
INFO:root:current mean train loss 8275.909536562613
INFO:root:current train perplexity681.2647705078125
INFO:root:current mean train loss 8273.807570528053
INFO:root:current train perplexity679.96826171875
INFO:root:current mean train loss 8269.281356215026
INFO:root:current train perplexity679.4205322265625
INFO:root:current mean train loss 8266.694609328662
INFO:root:current train perplexity679.4030151367188
INFO:root:current mean train loss 8266.35453948462
INFO:root:current train perplexity679.0408935546875
INFO:root:current mean train loss 8266.065917709851
INFO:root:current train perplexity678.3742065429688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:28<00:00, 748.66s/it]
INFO:root:final mean train loss: 8260.700960606562
INFO:root:final train perplexity: 678.122314453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.63s/it]
INFO:root:eval mean loss: 7752.867670586768
INFO:root:eval perplexity: 530.4544677734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 55.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.00s/it]
INFO:root:eval mean loss: 7796.184745193374
INFO:root:eval perplexity: 607.569580078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [27:31:43<21:19:41, 872.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8255.349446614584
INFO:root:current train perplexity676.8033447265625
INFO:root:current mean train loss 8245.423738053702
INFO:root:current train perplexity678.119384765625
INFO:root:current mean train loss 8287.316290794335
INFO:root:current train perplexity679.9403686523438
INFO:root:current mean train loss 8285.878530773
INFO:root:current train perplexity679.2174072265625
INFO:root:current mean train loss 8301.590809407957
INFO:root:current train perplexity681.299560546875
INFO:root:current mean train loss 8294.98645917464
INFO:root:current train perplexity682.8851318359375
INFO:root:current mean train loss 8280.631599489532
INFO:root:current train perplexity681.1465454101562
INFO:root:current mean train loss 8275.941716721862
INFO:root:current train perplexity681.059814453125
INFO:root:current mean train loss 8275.302477160842
INFO:root:current train perplexity679.5614624023438
INFO:root:current mean train loss 8269.958108929437
INFO:root:current train perplexity678.8948974609375
INFO:root:current mean train loss 8268.618617779473
INFO:root:current train perplexity680.0570678710938
INFO:root:current mean train loss 8276.49664489248
INFO:root:current train perplexity680.8575439453125
INFO:root:current mean train loss 8279.887451780705
INFO:root:current train perplexity680.5731811523438
INFO:root:current mean train loss 8275.271220935461
INFO:root:current train perplexity680.0736083984375
INFO:root:current mean train loss 8274.678441912976
INFO:root:current train perplexity681.4857177734375
INFO:root:current mean train loss 8273.896429146915
INFO:root:current train perplexity681.5669555664062
INFO:root:current mean train loss 8279.975395559595
INFO:root:current train perplexity683.1153564453125
INFO:root:current mean train loss 8278.309586082007
INFO:root:current train perplexity683.3590698242188
INFO:root:current mean train loss 8276.498612067995
INFO:root:current train perplexity684.0838012695312
INFO:root:current mean train loss 8278.053294243464
INFO:root:current train perplexity684.4476318359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:46<00:00, 766.99s/it]
INFO:root:final mean train loss: 8272.09849787648
INFO:root:final train perplexity: 684.2492065429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.11s/it]
INFO:root:eval mean loss: 7741.162814092974
INFO:root:eval perplexity: 525.4537353515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.25s/it]
INFO:root:eval mean loss: 7783.743407337378
INFO:root:eval perplexity: 601.3872680664062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [27:46:30<21:11:23, 876.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8371.840258789063
INFO:root:current train perplexity676.7713623046875
INFO:root:current mean train loss 8214.847635904947
INFO:root:current train perplexity673.4976806640625
INFO:root:current mean train loss 8225.95028852983
INFO:root:current train perplexity679.3084106445312
INFO:root:current mean train loss 8254.558058166504
INFO:root:current train perplexity678.7495727539062
INFO:root:current mean train loss 8236.303261021205
INFO:root:current train perplexity678.2315673828125
INFO:root:current mean train loss 8233.095051457332
INFO:root:current train perplexity675.7572021484375
INFO:root:current mean train loss 8229.651178962953
INFO:root:current train perplexity676.3003540039062
INFO:root:current mean train loss 8234.700223795573
INFO:root:current train perplexity674.9296264648438
INFO:root:current mean train loss 8246.048811451981
INFO:root:current train perplexity676.1172485351562
INFO:root:current mean train loss 8250.153028405231
INFO:root:current train perplexity676.939208984375
INFO:root:current mean train loss 8253.878833007813
INFO:root:current train perplexity677.7460327148438
INFO:root:current mean train loss 8259.770137241909
INFO:root:current train perplexity678.4104614257812
INFO:root:current mean train loss 8259.764885373976
INFO:root:current train perplexity677.8313598632812
INFO:root:current mean train loss 8263.250311094342
INFO:root:current train perplexity679.0519409179688
INFO:root:current mean train loss 8262.344744443222
INFO:root:current train perplexity678.5333862304688
INFO:root:current mean train loss 8260.728727963096
INFO:root:current train perplexity677.8348999023438
INFO:root:current mean train loss 8257.420811631944
INFO:root:current train perplexity677.0634765625
INFO:root:current mean train loss 8257.656726925872
INFO:root:current train perplexity675.7575073242188
INFO:root:current mean train loss 8254.229590112036
INFO:root:current train perplexity675.13818359375
INFO:root:current mean train loss 8257.43030649821
INFO:root:current train perplexity675.05322265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [12:44<00:00, 764.20s/it]
INFO:root:final mean train loss: 8253.721036402192
INFO:root:final train perplexity: 674.3971557617188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.98s/it]
INFO:root:eval mean loss: 7712.542989527926
INFO:root:eval perplexity: 513.4248657226562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.39s/it]
INFO:root:eval mean loss: 7759.513103945035
INFO:root:eval perplexity: 589.525634765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: distilroberta_distilroberta_not_concat/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [28:01:12<20:59:02, 878.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][Aslurmstepd: error: *** JOB 30794086 ON gr059 CANCELLED AT 2023-03-07T13:33:34 ***
