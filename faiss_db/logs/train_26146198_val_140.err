INFO:root:Output: small_val_140
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24464.629399463385
INFO:root:current train perplexity15560.1982421875
INFO:root:current mean train loss 20554.47547306847
INFO:root:current train perplexity3296.968017578125
INFO:root:current mean train loss 17761.045431385868
INFO:root:current train perplexity1099.2718505859375
INFO:root:current mean train loss 15867.495342359805
INFO:root:current train perplexity516.6851196289062
INFO:root:current mean train loss 14492.359680298096
INFO:root:current train perplexity300.4779052734375
INFO:root:current mean train loss 13448.160086146181
INFO:root:current train perplexity199.72744750976562
INFO:root:current mean train loss 12636.390615220404
INFO:root:current train perplexity145.01797485351562
INFO:root:current mean train loss 11984.695968838001
INFO:root:current train perplexity112.43206787109375
INFO:root:current mean train loss 11451.047599003232
INFO:root:current train perplexity91.14686584472656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it]
INFO:root:final mean train loss: 11021.238068365281
INFO:root:final train perplexity: 77.33892822265625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it]
INFO:root:eval mean loss: 6414.967738807624
INFO:root:eval perplexity: 13.383527755737305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/1

  0%|          | 1/200 [05:17<17:34:38, 317.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6814.399065290178
INFO:root:current train perplexity14.458259582519531
INFO:root:current mean train loss 6735.277042567173
INFO:root:current train perplexity14.422361373901367
INFO:root:current mean train loss 6706.380080955616
INFO:root:current train perplexity14.182073593139648
INFO:root:current mean train loss 6635.129307054153
INFO:root:current train perplexity13.764016151428223
INFO:root:current mean train loss 6580.382468183738
INFO:root:current train perplexity13.457144737243652
INFO:root:current mean train loss 6530.131553755239
INFO:root:current train perplexity13.18538761138916
INFO:root:current mean train loss 6487.284951928027
INFO:root:current train perplexity12.91374397277832
INFO:root:current mean train loss 6439.551817898028
INFO:root:current train perplexity12.671562194824219
INFO:root:current mean train loss 6395.26810694509
INFO:root:current train perplexity12.444940567016602
INFO:root:current mean train loss 6350.877487165794
INFO:root:current train perplexity12.241189956665039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.56s/it]
INFO:root:final mean train loss: 6313.629727640459
INFO:root:final train perplexity: 12.072251319885254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.64s/it]
INFO:root:eval mean loss: 5543.73710383422
INFO:root:eval perplexity: 9.409543991088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/2

  1%|          | 2/200 [11:15<18:47:02, 341.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6001.561067708333
INFO:root:current train perplexity10.698436737060547
INFO:root:current mean train loss 5888.652564538043
INFO:root:current train perplexity10.268610954284668
INFO:root:current mean train loss 5862.5726607921515
INFO:root:current train perplexity10.112289428710938
INFO:root:current mean train loss 5842.500249565972
INFO:root:current train perplexity9.999773979187012
INFO:root:current mean train loss 5817.829886342244
INFO:root:current train perplexity9.908671379089355
INFO:root:current mean train loss 5792.836854331007
INFO:root:current train perplexity9.823768615722656
INFO:root:current mean train loss 5767.126029757368
INFO:root:current train perplexity9.739974021911621
INFO:root:current mean train loss 5748.193889996722
INFO:root:current train perplexity9.661587715148926
INFO:root:current mean train loss 5735.127456384203
INFO:root:current train perplexity9.591038703918457
INFO:root:current mean train loss 5716.322454533812
INFO:root:current train perplexity9.507442474365234


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.73s/it]
INFO:root:final mean train loss: 5692.427482974144
INFO:root:final train perplexity: 9.448229789733887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.56s/it]
INFO:root:eval mean loss: 5178.896425504211
INFO:root:eval perplexity: 8.118891716003418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/3

  2%|â–         | 3/200 [16:45<18:23:07, 335.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5562.9775390625
INFO:root:current train perplexity8.814858436584473
INFO:root:current mean train loss 5481.171573297765
INFO:root:current train perplexity8.702889442443848
INFO:root:current mean train loss 5481.125376611547
INFO:root:current train perplexity8.646068572998047
INFO:root:current mean train loss 5454.828199073626
INFO:root:current train perplexity8.56754207611084
INFO:root:current mean train loss 5442.605618812796
INFO:root:current train perplexity8.543784141540527
INFO:root:current mean train loss 5426.141220647108
INFO:root:current train perplexity8.489699363708496
INFO:root:current mean train loss 5417.192984738664
INFO:root:current train perplexity8.460015296936035
INFO:root:current mean train loss 5407.492132796291
INFO:root:current train perplexity8.425572395324707
INFO:root:current mean train loss 5396.830465546211
INFO:root:current train perplexity8.389790534973145
INFO:root:current mean train loss 5386.170328687873
INFO:root:current train perplexity8.354940414428711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.46s/it]
INFO:root:final mean train loss: 5374.957061275359
INFO:root:final train perplexity: 8.335938453674316
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.17s/it]
INFO:root:eval mean loss: 4957.129643866357
INFO:root:eval perplexity: 7.422512054443359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/4

  2%|â–         | 4/200 [22:11<18:04:56, 332.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5315.095246345766
INFO:root:current train perplexity7.9521284103393555
INFO:root:current mean train loss 5238.547128458969
INFO:root:current train perplexity7.878311634063721
INFO:root:current mean train loss 5241.332976105925
INFO:root:current train perplexity7.9015679359436035
INFO:root:current mean train loss 5230.696485260102
INFO:root:current train perplexity7.855485439300537
INFO:root:current mean train loss 5223.319533062645
INFO:root:current train perplexity7.820849895477295
INFO:root:current mean train loss 5213.264931659016
INFO:root:current train perplexity7.792304039001465
INFO:root:current mean train loss 5205.92381651768
INFO:root:current train perplexity7.768773078918457
INFO:root:current mean train loss 5198.163734529968
INFO:root:current train perplexity7.753281593322754
INFO:root:current mean train loss 5184.666468651286
INFO:root:current train perplexity7.727976322174072
INFO:root:current mean train loss 5176.769883693609
INFO:root:current train perplexity7.69890832901001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.60s/it]
INFO:root:final mean train loss: 5167.376863048923
INFO:root:final train perplexity: 7.680462837219238
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.29s/it]
INFO:root:eval mean loss: 4816.6113835328015
INFO:root:eval perplexity: 7.012514591217041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/5

  2%|â–Ž         | 5/200 [27:33<17:47:29, 328.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5075.644844250802
INFO:root:current train perplexity7.3254170417785645
INFO:root:current mean train loss 5066.496877107689
INFO:root:current train perplexity7.383081912994385
INFO:root:current mean train loss 5073.222680766214
INFO:root:current train perplexity7.390641689300537
INFO:root:current mean train loss 5057.2003134218285
INFO:root:current train perplexity7.331757545471191
INFO:root:current mean train loss 5055.272495417497
INFO:root:current train perplexity7.322763442993164
INFO:root:current mean train loss 5042.843226388567
INFO:root:current train perplexity7.298601150512695
INFO:root:current mean train loss 5034.766758973983
INFO:root:current train perplexity7.277724266052246
INFO:root:current mean train loss 5034.065588924011
INFO:root:current train perplexity7.27099609375
INFO:root:current mean train loss 5029.579126005661
INFO:root:current train perplexity7.252941131591797
INFO:root:current mean train loss 5021.389184076311
INFO:root:current train perplexity7.236952781677246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.92s/it]
INFO:root:final mean train loss: 5012.794520654986
INFO:root:final train perplexity: 7.22605037689209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.32s/it]
INFO:root:eval mean loss: 4696.547311336436
INFO:root:eval perplexity: 6.680186748504639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/6

  3%|â–Ž         | 6/200 [33:28<18:10:36, 337.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4880.08796334774
INFO:root:current train perplexity6.901000499725342
INFO:root:current mean train loss 4935.821710910927
INFO:root:current train perplexity6.982802391052246
INFO:root:current mean train loss 4919.310782119813
INFO:root:current train perplexity6.970357894897461
INFO:root:current mean train loss 4920.441364035482
INFO:root:current train perplexity6.965145111083984
INFO:root:current mean train loss 4917.786356744617
INFO:root:current train perplexity6.95517635345459
INFO:root:current mean train loss 4909.033667304616
INFO:root:current train perplexity6.933835983276367
INFO:root:current mean train loss 4908.630974087133
INFO:root:current train perplexity6.930710315704346
INFO:root:current mean train loss 4905.544809446118
INFO:root:current train perplexity6.918661594390869
INFO:root:current mean train loss 4901.9569280595115
INFO:root:current train perplexity6.909982204437256
INFO:root:current mean train loss 4899.228995140906
INFO:root:current train perplexity6.897745132446289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.64s/it]
INFO:root:final mean train loss: 4894.148798296528
INFO:root:final train perplexity: 6.895598411560059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.42s/it]
INFO:root:eval mean loss: 4611.854142425754
INFO:root:eval perplexity: 6.4552812576293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/7

  4%|â–Ž         | 7/200 [39:29<18:30:12, 345.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4788.306795987216
INFO:root:current train perplexity6.701501369476318
INFO:root:current mean train loss 4838.098520980343
INFO:root:current train perplexity6.756722450256348
INFO:root:current mean train loss 4831.667843328738
INFO:root:current train perplexity6.714517593383789
INFO:root:current mean train loss 4831.638840366417
INFO:root:current train perplexity6.709175109863281
INFO:root:current mean train loss 4824.295822244162
INFO:root:current train perplexity6.688193321228027
INFO:root:current mean train loss 4817.821348008164
INFO:root:current train perplexity6.669220924377441
INFO:root:current mean train loss 4816.128851830868
INFO:root:current train perplexity6.666443347930908
INFO:root:current mean train loss 4817.34140754346
INFO:root:current train perplexity6.660276412963867
INFO:root:current mean train loss 4808.19296875
INFO:root:current train perplexity6.643349647521973
INFO:root:current mean train loss 4800.891176681119
INFO:root:current train perplexity6.6351423263549805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.52s/it]
INFO:root:final mean train loss: 4796.513176148937
INFO:root:final train perplexity: 6.6350297927856445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.01s/it]
INFO:root:eval mean loss: 4537.608602753768
INFO:root:eval perplexity: 6.264355659484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/8

  4%|â–         | 8/200 [45:22<18:32:17, 347.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4738.718501984127
INFO:root:current train perplexity6.428354740142822
INFO:root:current mean train loss 4730.044098087615
INFO:root:current train perplexity6.456353187561035
INFO:root:current mean train loss 4725.743980958888
INFO:root:current train perplexity6.459362506866455
INFO:root:current mean train loss 4734.589309734418
INFO:root:current train perplexity6.454684734344482
INFO:root:current mean train loss 4739.013898614673
INFO:root:current train perplexity6.464484214782715
INFO:root:current mean train loss 4730.986890125444
INFO:root:current train perplexity6.451325416564941
INFO:root:current mean train loss 4728.331318344645
INFO:root:current train perplexity6.448964595794678
INFO:root:current mean train loss 4726.713938221863
INFO:root:current train perplexity6.442447185516357
INFO:root:current mean train loss 4721.716148473711
INFO:root:current train perplexity6.433725833892822
INFO:root:current mean train loss 4718.09585270233
INFO:root:current train perplexity6.42423152923584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.84s/it]
INFO:root:final mean train loss: 4715.687290868452
INFO:root:final train perplexity: 6.4267897605896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.95s/it]
INFO:root:eval mean loss: 4482.425883408134
INFO:root:eval perplexity: 6.126118183135986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/9

  4%|â–         | 9/200 [51:19<18:36:21, 350.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4638.775500660211
INFO:root:current train perplexity6.206085681915283
INFO:root:current mean train loss 4651.020564921419
INFO:root:current train perplexity6.25923490524292
INFO:root:current mean train loss 4672.426340701395
INFO:root:current train perplexity6.293023586273193
INFO:root:current mean train loss 4666.962421427518
INFO:root:current train perplexity6.281893730163574
INFO:root:current mean train loss 4660.189517918159
INFO:root:current train perplexity6.277419567108154
INFO:root:current mean train loss 4660.612432529964
INFO:root:current train perplexity6.272982120513916
INFO:root:current mean train loss 4661.852920373044
INFO:root:current train perplexity6.277498245239258
INFO:root:current mean train loss 4652.270542644495
INFO:root:current train perplexity6.264036655426025
INFO:root:current mean train loss 4654.413419493578
INFO:root:current train perplexity6.260646820068359
INFO:root:current mean train loss 4649.927122389128
INFO:root:current train perplexity6.253056049346924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.62s/it]
INFO:root:final mean train loss: 4645.624206419914
INFO:root:final train perplexity: 6.2515740394592285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.97s/it]
INFO:root:eval mean loss: 4432.596087516622
INFO:root:eval perplexity: 6.003915309906006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/10

  5%|â–Œ         | 10/200 [57:12<18:32:25, 351.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4635.131526898735
INFO:root:current train perplexity6.137846946716309
INFO:root:current mean train loss 4595.952220724947
INFO:root:current train perplexity6.101162433624268
INFO:root:current mean train loss 4605.232217111895
INFO:root:current train perplexity6.113163948059082
INFO:root:current mean train loss 4598.895935541722
INFO:root:current train perplexity6.114484786987305
INFO:root:current mean train loss 4601.765393601579
INFO:root:current train perplexity6.111121654510498
INFO:root:current mean train loss 4595.737714118496
INFO:root:current train perplexity6.111840724945068
INFO:root:current mean train loss 4595.77662499137
INFO:root:current train perplexity6.1104607582092285
INFO:root:current mean train loss 4593.222398319661
INFO:root:current train perplexity6.105718612670898
INFO:root:current mean train loss 4587.940820479149
INFO:root:current train perplexity6.102160930633545
INFO:root:current mean train loss 4587.474385433957
INFO:root:current train perplexity6.1028594970703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.50s/it]
INFO:root:final mean train loss: 4584.6572023207145
INFO:root:final train perplexity: 6.102996826171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it]
INFO:root:eval mean loss: 4388.815890264849
INFO:root:eval perplexity: 5.898561000823975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/11

  6%|â–Œ         | 11/200 [1:03:09<18:31:55, 352.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4535.335721421516
INFO:root:current train perplexity5.967483043670654
INFO:root:current mean train loss 4555.7387199197865
INFO:root:current train perplexity5.998584270477295
INFO:root:current mean train loss 4543.229952396831
INFO:root:current train perplexity5.973348140716553
INFO:root:current mean train loss 4543.616954714753
INFO:root:current train perplexity5.986770153045654
INFO:root:current mean train loss 4540.644501171073
INFO:root:current train perplexity5.984837532043457
INFO:root:current mean train loss 4536.453485596119
INFO:root:current train perplexity5.976881980895996
INFO:root:current mean train loss 4535.325144849663
INFO:root:current train perplexity5.976847171783447
INFO:root:current mean train loss 4532.130915524242
INFO:root:current train perplexity5.969846725463867
INFO:root:current mean train loss 4533.117031437166
INFO:root:current train perplexity5.971395969390869
INFO:root:current mean train loss 4532.9212610617715
INFO:root:current train perplexity5.971684455871582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.96s/it]
INFO:root:final mean train loss: 4529.528419986848
INFO:root:final train perplexity: 5.9716901779174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.72s/it]
INFO:root:eval mean loss: 4353.991882757092
INFO:root:eval perplexity: 5.816080570220947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/12

  6%|â–Œ         | 12/200 [1:08:39<18:04:28, 346.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4498.652292351973
INFO:root:current train perplexity5.885182857513428
INFO:root:current mean train loss 4482.5828200120195
INFO:root:current train perplexity5.877340316772461
INFO:root:current mean train loss 4485.34575278072
INFO:root:current train perplexity5.8829121589660645
INFO:root:current mean train loss 4478.187242879747
INFO:root:current train perplexity5.866505146026611
INFO:root:current mean train loss 4484.076866319445
INFO:root:current train perplexity5.867537498474121
INFO:root:current mean train loss 4478.240179392069
INFO:root:current train perplexity5.862851142883301
INFO:root:current mean train loss 4476.2828743255395
INFO:root:current train perplexity5.860135555267334
INFO:root:current mean train loss 4480.449746646521
INFO:root:current train perplexity5.855018138885498
INFO:root:current mean train loss 4481.477551064944
INFO:root:current train perplexity5.855926036834717


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.62s/it]
INFO:root:final mean train loss: 4480.571291154431
INFO:root:final train perplexity: 5.857454299926758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it]
INFO:root:eval mean loss: 4318.5501561807405
INFO:root:eval perplexity: 5.733321666717529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/13

  6%|â–‹         | 13/200 [1:14:29<18:02:50, 347.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4697.660970052083
INFO:root:current train perplexity6.018435001373291
INFO:root:current mean train loss 4455.753015018204
INFO:root:current train perplexity5.755980491638184
INFO:root:current mean train loss 4453.4278762892545
INFO:root:current train perplexity5.755141735076904
INFO:root:current mean train loss 4451.923514690337
INFO:root:current train perplexity5.761782169342041
INFO:root:current mean train loss 4453.378867478288
INFO:root:current train perplexity5.765697002410889
INFO:root:current mean train loss 4450.048962086854
INFO:root:current train perplexity5.769052028656006
INFO:root:current mean train loss 4445.191671444211
INFO:root:current train perplexity5.767724990844727
INFO:root:current mean train loss 4441.718509332215
INFO:root:current train perplexity5.761127471923828
INFO:root:current mean train loss 4440.645668039287
INFO:root:current train perplexity5.759410858154297
INFO:root:current mean train loss 4440.601699575634
INFO:root:current train perplexity5.758106708526611


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.34s/it]
INFO:root:final mean train loss: 4437.114418398949
INFO:root:final train perplexity: 5.757882595062256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it]
INFO:root:eval mean loss: 4293.370551792443
INFO:root:eval perplexity: 5.675241470336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/14

  7%|â–‹         | 14/200 [1:19:40<17:22:47, 336.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4376.15673828125
INFO:root:current train perplexity5.563012599945068
INFO:root:current mean train loss 4391.532871005771
INFO:root:current train perplexity5.675722122192383
INFO:root:current mean train loss 4382.218677104932
INFO:root:current train perplexity5.670744895935059
INFO:root:current mean train loss 4386.309096946594
INFO:root:current train perplexity5.667790412902832
INFO:root:current mean train loss 4384.792624814667
INFO:root:current train perplexity5.664850234985352
INFO:root:current mean train loss 4388.328254475752
INFO:root:current train perplexity5.66938591003418
INFO:root:current mean train loss 4395.678815226704
INFO:root:current train perplexity5.674260139465332
INFO:root:current mean train loss 4396.605083138295
INFO:root:current train perplexity5.670446395874023
INFO:root:current mean train loss 4398.373358447808
INFO:root:current train perplexity5.6732869148254395
INFO:root:current mean train loss 4401.006800830561
INFO:root:current train perplexity5.670437812805176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.98s/it]
INFO:root:final mean train loss: 4397.330802056097
INFO:root:final train perplexity: 5.668214321136475
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it]
INFO:root:eval mean loss: 4265.6162109375
INFO:root:eval perplexity: 5.611903667449951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/15

  8%|â–Š         | 15/200 [1:24:59<17:00:22, 330.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4412.0409513774675
INFO:root:current train perplexity5.643059253692627
INFO:root:current mean train loss 4360.656943441439
INFO:root:current train perplexity5.5671281814575195
INFO:root:current mean train loss 4360.015099930437
INFO:root:current train perplexity5.584899425506592
INFO:root:current mean train loss 4358.044737430202
INFO:root:current train perplexity5.584603309631348
INFO:root:current mean train loss 4363.72090414771
INFO:root:current train perplexity5.591863632202148
INFO:root:current mean train loss 4360.866736851216
INFO:root:current train perplexity5.586370944976807
INFO:root:current mean train loss 4359.718405284481
INFO:root:current train perplexity5.585972309112549
INFO:root:current mean train loss 4362.211388430112
INFO:root:current train perplexity5.588074207305908
INFO:root:current mean train loss 4361.854633186908
INFO:root:current train perplexity5.58867883682251
INFO:root:current mean train loss 4362.03137007787
INFO:root:current train perplexity5.5864057540893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.48s/it]
INFO:root:final mean train loss: 4362.483393884474
INFO:root:final train perplexity: 5.590819835662842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4244.157004931294
INFO:root:eval perplexity: 5.563416957855225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/16

  8%|â–Š         | 16/200 [1:30:40<17:04:08, 333.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.715277777777
INFO:root:current train perplexity5.591329097747803
INFO:root:current mean train loss 4309.6087809885585
INFO:root:current train perplexity5.5225114822387695
INFO:root:current mean train loss 4321.607611164648
INFO:root:current train perplexity5.517485618591309
INFO:root:current mean train loss 4319.202028980313
INFO:root:current train perplexity5.508776664733887
INFO:root:current mean train loss 4325.491110879867
INFO:root:current train perplexity5.511470317840576
INFO:root:current mean train loss 4325.069004239801
INFO:root:current train perplexity5.50551176071167
INFO:root:current mean train loss 4325.292654131778
INFO:root:current train perplexity5.503328800201416
INFO:root:current mean train loss 4324.966580271557
INFO:root:current train perplexity5.509875297546387
INFO:root:current mean train loss 4325.01043870919
INFO:root:current train perplexity5.506403923034668
INFO:root:current mean train loss 4327.188970374444
INFO:root:current train perplexity5.511448860168457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.19s/it]
INFO:root:final mean train loss: 4327.506700823384
INFO:root:final train perplexity: 5.514199733734131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it]
INFO:root:eval mean loss: 4224.125226825687
INFO:root:eval perplexity: 5.518533229827881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/17

  8%|â–Š         | 17/200 [1:36:29<17:12:53, 338.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4255.404408482143
INFO:root:current train perplexity5.407318115234375
INFO:root:current mean train loss 4291.487366174769
INFO:root:current train perplexity5.430596828460693
INFO:root:current mean train loss 4287.377364527925
INFO:root:current train perplexity5.43637228012085
INFO:root:current mean train loss 4291.313932777519
INFO:root:current train perplexity5.43736457824707
INFO:root:current mean train loss 4292.140954449533
INFO:root:current train perplexity5.443211078643799
INFO:root:current mean train loss 4303.261255567319
INFO:root:current train perplexity5.4461870193481445
INFO:root:current mean train loss 4298.772636257382
INFO:root:current train perplexity5.439905643463135
INFO:root:current mean train loss 4297.305068160076
INFO:root:current train perplexity5.436219692230225
INFO:root:current mean train loss 4298.4765858907185
INFO:root:current train perplexity5.444104194641113
INFO:root:current mean train loss 4297.5593781333555
INFO:root:current train perplexity5.446638584136963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it]
INFO:root:final mean train loss: 4296.339903616136
INFO:root:final train perplexity: 5.446811199188232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it]
INFO:root:eval mean loss: 4207.772892079455
INFO:root:eval perplexity: 5.48216438293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/18

  9%|â–‰         | 18/200 [1:41:51<16:51:29, 333.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4256.552302870639
INFO:root:current train perplexity5.37978458404541
INFO:root:current mean train loss 4276.721452619646
INFO:root:current train perplexity5.394585132598877
INFO:root:current mean train loss 4271.894990395126
INFO:root:current train perplexity5.38899564743042
INFO:root:current mean train loss 4278.227939082999
INFO:root:current train perplexity5.402703762054443
INFO:root:current mean train loss 4278.941061256702
INFO:root:current train perplexity5.398588180541992
INFO:root:current mean train loss 4280.1200699779865
INFO:root:current train perplexity5.398102760314941
INFO:root:current mean train loss 4275.942183475287
INFO:root:current train perplexity5.3918585777282715
INFO:root:current mean train loss 4273.060989482567
INFO:root:current train perplexity5.3883376121521
INFO:root:current mean train loss 4269.6843730885785
INFO:root:current train perplexity5.386227607727051
INFO:root:current mean train loss 4268.742722382854
INFO:root:current train perplexity5.383440971374512


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.90s/it]
INFO:root:final mean train loss: 4268.139337847309
INFO:root:final train perplexity: 5.3865461349487305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.79s/it]
INFO:root:eval mean loss: 4187.654804202682
INFO:root:eval perplexity: 5.437746047973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/19

 10%|â–‰         | 19/200 [1:47:17<16:39:49, 331.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4212.305740655637
INFO:root:current train perplexity5.249361515045166
INFO:root:current mean train loss 4209.133840800911
INFO:root:current train perplexity5.25799036026001
INFO:root:current mean train loss 4239.116591252179
INFO:root:current train perplexity5.287712574005127
INFO:root:current mean train loss 4231.385309550837
INFO:root:current train perplexity5.299265384674072
INFO:root:current mean train loss 4237.675605858509
INFO:root:current train perplexity5.304283142089844
INFO:root:current mean train loss 4235.845682299938
INFO:root:current train perplexity5.309101581573486
INFO:root:current mean train loss 4243.143702446957
INFO:root:current train perplexity5.321387767791748
INFO:root:current mean train loss 4244.422617174497
INFO:root:current train perplexity5.322789669036865
INFO:root:current mean train loss 4244.338603251689
INFO:root:current train perplexity5.325876235961914
INFO:root:current mean train loss 4246.231693047203
INFO:root:current train perplexity5.328152656555176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it]
INFO:root:final mean train loss: 4239.456217181298
INFO:root:final train perplexity: 5.325933933258057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it]
INFO:root:eval mean loss: 4172.611175753546
INFO:root:eval perplexity: 5.404768943786621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/20

 10%|â–ˆ         | 20/200 [1:53:03<16:47:13, 335.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4249.327814651748
INFO:root:current train perplexity5.283790588378906
INFO:root:current mean train loss 4234.95043791765
INFO:root:current train perplexity5.26773738861084
INFO:root:current mean train loss 4227.769615143883
INFO:root:current train perplexity5.269802570343018
INFO:root:current mean train loss 4227.616448957608
INFO:root:current train perplexity5.282924175262451
INFO:root:current mean train loss 4223.196449163433
INFO:root:current train perplexity5.2772626876831055
INFO:root:current mean train loss 4219.7098748986755
INFO:root:current train perplexity5.273561477661133
INFO:root:current mean train loss 4221.265512006235
INFO:root:current train perplexity5.273767471313477
INFO:root:current mean train loss 4224.701147750432
INFO:root:current train perplexity5.282516002655029
INFO:root:current mean train loss 4222.875711105755
INFO:root:current train perplexity5.281736373901367
INFO:root:current mean train loss 4219.822342253079
INFO:root:current train perplexity5.277154445648193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.94s/it]
INFO:root:final mean train loss: 4215.368924848495
INFO:root:final train perplexity: 5.2755608558654785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.66s/it]
INFO:root:eval mean loss: 4164.865478515625
INFO:root:eval perplexity: 5.387866020202637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/21

 10%|â–ˆ         | 21/200 [1:58:20<16:24:30, 330.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4170.599664033349
INFO:root:current train perplexity5.218862056732178
INFO:root:current mean train loss 4184.301820675056
INFO:root:current train perplexity5.239253520965576
INFO:root:current mean train loss 4187.830624926849
INFO:root:current train perplexity5.225283145904541
INFO:root:current mean train loss 4184.872435525587
INFO:root:current train perplexity5.215172290802002
INFO:root:current mean train loss 4189.697356589601
INFO:root:current train perplexity5.220970153808594
INFO:root:current mean train loss 4188.943076481894
INFO:root:current train perplexity5.215303897857666
INFO:root:current mean train loss 4190.939178604057
INFO:root:current train perplexity5.21681547164917
INFO:root:current mean train loss 4191.863576319569
INFO:root:current train perplexity5.216905117034912
INFO:root:current mean train loss 4193.534194330306
INFO:root:current train perplexity5.218226909637451
INFO:root:current mean train loss 4192.473260163521
INFO:root:current train perplexity5.2214250564575195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.01s/it]
INFO:root:final mean train loss: 4190.842696159117
INFO:root:final train perplexity: 5.224759578704834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 4143.590221215647
INFO:root:eval perplexity: 5.34171199798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/22

 11%|â–ˆ         | 22/200 [2:03:55<16:23:32, 331.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.270524088542
INFO:root:current train perplexity5.171497344970703
INFO:root:current mean train loss 4170.045255301339
INFO:root:current train perplexity5.176994800567627
INFO:root:current mean train loss 4163.354508167614
INFO:root:current train perplexity5.159029483795166
INFO:root:current mean train loss 4162.957626953125
INFO:root:current train perplexity5.164896011352539
INFO:root:current mean train loss 4162.9524933182565
INFO:root:current train perplexity5.1660943031311035
INFO:root:current mean train loss 4168.788678243885
INFO:root:current train perplexity5.173123836517334
INFO:root:current mean train loss 4166.896912254051
INFO:root:current train perplexity5.175597190856934
INFO:root:current mean train loss 4171.535647996472
INFO:root:current train perplexity5.178895473480225
INFO:root:current mean train loss 4171.521199497768
INFO:root:current train perplexity5.17824649810791
INFO:root:current mean train loss 4172.748620042067
INFO:root:current train perplexity5.178147315979004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.28s/it]
INFO:root:final mean train loss: 4167.682159546883
INFO:root:final train perplexity: 5.177235126495361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.81s/it]
INFO:root:eval mean loss: 4135.070729790004
INFO:root:eval perplexity: 5.3233418464660645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/23

 12%|â–ˆâ–        | 23/200 [2:09:04<15:58:12, 324.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.350685946913
INFO:root:current train perplexity5.100789546966553
INFO:root:current mean train loss 4147.8866427061985
INFO:root:current train perplexity5.113128185272217
INFO:root:current mean train loss 4148.26096562362
INFO:root:current train perplexity5.115902900695801
INFO:root:current mean train loss 4153.512484956348
INFO:root:current train perplexity5.12451171875
INFO:root:current mean train loss 4155.466987436109
INFO:root:current train perplexity5.130245685577393
INFO:root:current mean train loss 4148.942113127144
INFO:root:current train perplexity5.123992443084717
INFO:root:current mean train loss 4143.674669212687
INFO:root:current train perplexity5.117744445800781
INFO:root:current mean train loss 4148.980887811303
INFO:root:current train perplexity5.128808498382568
INFO:root:current mean train loss 4148.475705934138
INFO:root:current train perplexity5.1322550773620605
INFO:root:current mean train loss 4149.108484122663
INFO:root:current train perplexity5.133153915405273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.27s/it]
INFO:root:final mean train loss: 4145.780412550896
INFO:root:final train perplexity: 5.132692337036133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.61s/it]
INFO:root:eval mean loss: 4124.529379986702
INFO:root:eval perplexity: 5.300698280334473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/24

 12%|â–ˆâ–        | 24/200 [2:14:41<16:03:57, 328.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4095.664108108688
INFO:root:current train perplexity5.052346229553223
INFO:root:current mean train loss 4108.97594128354
INFO:root:current train perplexity5.071640491485596
INFO:root:current mean train loss 4106.611069721865
INFO:root:current train perplexity5.061239719390869
INFO:root:current mean train loss 4117.635825857177
INFO:root:current train perplexity5.081207275390625
INFO:root:current mean train loss 4117.801258592159
INFO:root:current train perplexity5.084080219268799
INFO:root:current mean train loss 4124.542285899825
INFO:root:current train perplexity5.089599609375
INFO:root:current mean train loss 4127.24667636634
INFO:root:current train perplexity5.093223571777344
INFO:root:current mean train loss 4130.659950381736
INFO:root:current train perplexity5.093003749847412
INFO:root:current mean train loss 4129.405840632891
INFO:root:current train perplexity5.095495700836182
INFO:root:current mean train loss 4128.464923569942
INFO:root:current train perplexity5.091166973114014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.64s/it]
INFO:root:final mean train loss: 4125.126821579472
INFO:root:final train perplexity: 5.091038227081299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.83s/it]
INFO:root:eval mean loss: 4114.585373033023
INFO:root:eval perplexity: 5.279426097869873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/25

 12%|â–ˆâ–Ž        | 25/200 [2:20:30<16:16:06, 334.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4075.389774206913
INFO:root:current train perplexity5.05245304107666
INFO:root:current mean train loss 4089.6503452320194
INFO:root:current train perplexity5.03170919418335
INFO:root:current mean train loss 4103.497074395119
INFO:root:current train perplexity5.042930603027344
INFO:root:current mean train loss 4109.581935796523
INFO:root:current train perplexity5.052280426025391
INFO:root:current mean train loss 4108.640823150206
INFO:root:current train perplexity5.0484113693237305
INFO:root:current mean train loss 4107.258618286337
INFO:root:current train perplexity5.043572902679443
INFO:root:current mean train loss 4107.588387987304
INFO:root:current train perplexity5.044995307922363
INFO:root:current mean train loss 4110.967523796836
INFO:root:current train perplexity5.048456192016602
INFO:root:current mean train loss 4111.000159139495
INFO:root:current train perplexity5.053123474121094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it]
INFO:root:final mean train loss: 4104.955411234209
INFO:root:final train perplexity: 5.05068302154541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it]
INFO:root:eval mean loss: 4108.269313081782
INFO:root:eval perplexity: 5.265960693359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/26

 13%|â–ˆâ–Ž        | 26/200 [2:25:43<15:51:25, 328.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4143.41472516741
INFO:root:current train perplexity5.107527256011963
INFO:root:current mean train loss 4074.7191378869743
INFO:root:current train perplexity5.009970188140869
INFO:root:current mean train loss 4085.687107252038
INFO:root:current train perplexity5.021249771118164
INFO:root:current mean train loss 4088.453426398361
INFO:root:current train perplexity5.0190749168396
INFO:root:current mean train loss 4095.5109575351275
INFO:root:current train perplexity5.030276298522949
INFO:root:current mean train loss 4086.65858113366
INFO:root:current train perplexity5.018359661102295
INFO:root:current mean train loss 4089.9296090693215
INFO:root:current train perplexity5.013045310974121
INFO:root:current mean train loss 4090.990208130746
INFO:root:current train perplexity5.016267776489258
INFO:root:current mean train loss 4088.7103545272807
INFO:root:current train perplexity5.012916564941406
INFO:root:current mean train loss 4087.136994114784
INFO:root:current train perplexity5.0109639167785645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.99s/it]
INFO:root:final mean train loss: 4085.5357577416203
INFO:root:final train perplexity: 5.0121355056762695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 4095.359773243573
INFO:root:eval perplexity: 5.238542556762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/27

 14%|â–ˆâ–Ž        | 27/200 [2:31:16<15:50:15, 329.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.137337239584
INFO:root:current train perplexity4.941359996795654
INFO:root:current mean train loss 4050.315092136549
INFO:root:current train perplexity4.960132598876953
INFO:root:current mean train loss 4045.582681913154
INFO:root:current train perplexity4.952014923095703
INFO:root:current mean train loss 4057.611416480655
INFO:root:current train perplexity4.963405609130859
INFO:root:current mean train loss 4069.762197618599
INFO:root:current train perplexity4.980314254760742
INFO:root:current mean train loss 4064.6912621359224
INFO:root:current train perplexity4.970452308654785
INFO:root:current mean train loss 4067.687547637195
INFO:root:current train perplexity4.971919059753418
INFO:root:current mean train loss 4068.845205965909
INFO:root:current train perplexity4.971261978149414
INFO:root:current mean train loss 4072.044901504985
INFO:root:current train perplexity4.974547386169434
INFO:root:current mean train loss 4068.498074624317
INFO:root:current train perplexity4.972318649291992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.27s/it]
INFO:root:final mean train loss: 4067.3335629124795
INFO:root:final train perplexity: 4.9762701988220215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
INFO:root:eval mean loss: 4089.48678004488
INFO:root:eval perplexity: 5.226116180419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/28

 14%|â–ˆâ–        | 28/200 [2:36:56<15:53:53, 332.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4087.0855659816575
INFO:root:current train perplexity4.963965892791748
INFO:root:current mean train loss 4054.2612542873476
INFO:root:current train perplexity4.929393768310547
INFO:root:current mean train loss 4062.4622293651905
INFO:root:current train perplexity4.953070163726807
INFO:root:current mean train loss 4051.56056274792
INFO:root:current train perplexity4.941259860992432
INFO:root:current mean train loss 4062.4765832779253
INFO:root:current train perplexity4.948832035064697
INFO:root:current mean train loss 4063.77293708174
INFO:root:current train perplexity4.949079513549805
INFO:root:current mean train loss 4056.190948535313
INFO:root:current train perplexity4.9439263343811035
INFO:root:current mean train loss 4053.0788304076978
INFO:root:current train perplexity4.94249153137207
INFO:root:current mean train loss 4056.596827417793
INFO:root:current train perplexity4.945154666900635
INFO:root:current mean train loss 4054.228222550447
INFO:root:current train perplexity4.943739891052246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.81s/it]
INFO:root:final mean train loss: 4050.055465944352
INFO:root:final train perplexity: 4.942463397979736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.68s/it]
INFO:root:eval mean loss: 4081.9663276401816
INFO:root:eval perplexity: 5.21024751663208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/29

 14%|â–ˆâ–        | 29/200 [2:42:11<15:32:44, 327.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4060.164290889617
INFO:root:current train perplexity4.906847953796387
INFO:root:current mean train loss 4037.2462242068227
INFO:root:current train perplexity4.894543647766113
INFO:root:current mean train loss 4054.455941600717
INFO:root:current train perplexity4.912324905395508
INFO:root:current mean train loss 4057.4607354017185
INFO:root:current train perplexity4.914059638977051
INFO:root:current mean train loss 4053.305312862529
INFO:root:current train perplexity4.907392978668213
INFO:root:current mean train loss 4048.419928771628
INFO:root:current train perplexity4.907249450683594
INFO:root:current mean train loss 4042.5535317978656
INFO:root:current train perplexity4.90270471572876
INFO:root:current mean train loss 4042.798908280609
INFO:root:current train perplexity4.9066009521484375
INFO:root:current mean train loss 4040.148440144122
INFO:root:current train perplexity4.904266357421875
INFO:root:current mean train loss 4035.2680810914003
INFO:root:current train perplexity4.906744003295898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it]
INFO:root:final mean train loss: 4032.315552003922
INFO:root:final train perplexity: 4.907992362976074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it]
INFO:root:eval mean loss: 4073.1340868794327
INFO:root:eval perplexity: 5.191671848297119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/30

 15%|â–ˆâ–Œ        | 30/200 [2:47:58<15:43:58, 333.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4019.3367826021636
INFO:root:current train perplexity4.902287483215332
INFO:root:current mean train loss 4011.9378161533273
INFO:root:current train perplexity4.882691383361816
INFO:root:current mean train loss 4015.982938758499
INFO:root:current train perplexity4.867302894592285
INFO:root:current mean train loss 4011.690925890717
INFO:root:current train perplexity4.863360404968262
INFO:root:current mean train loss 4018.448820561646
INFO:root:current train perplexity4.86711311340332
INFO:root:current mean train loss 4016.6542823805657
INFO:root:current train perplexity4.869523525238037
INFO:root:current mean train loss 4015.9099839379155
INFO:root:current train perplexity4.87083625793457
INFO:root:current mean train loss 4020.6183024859397
INFO:root:current train perplexity4.874849319458008
INFO:root:current mean train loss 4020.1791593531175
INFO:root:current train perplexity4.877554416656494
INFO:root:current mean train loss 4019.2480723550652
INFO:root:current train perplexity4.877162933349609


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.66s/it]
INFO:root:final mean train loss: 4015.749566478114
INFO:root:final train perplexity: 4.876020431518555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it]
INFO:root:eval mean loss: 4066.41758089539
INFO:root:eval perplexity: 5.177591323852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/31

 16%|â–ˆâ–Œ        | 31/200 [2:53:32<15:39:51, 333.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3988.5874231216753
INFO:root:current train perplexity4.8152971267700195
INFO:root:current mean train loss 3986.2327739689626
INFO:root:current train perplexity4.809770107269287
INFO:root:current mean train loss 3981.248618183831
INFO:root:current train perplexity4.801958084106445
INFO:root:current mean train loss 3993.400173220236
INFO:root:current train perplexity4.8178582191467285
INFO:root:current mean train loss 3997.3381467814947
INFO:root:current train perplexity4.825281143188477
INFO:root:current mean train loss 4000.098089633084
INFO:root:current train perplexity4.836952209472656
INFO:root:current mean train loss 4004.159961541248
INFO:root:current train perplexity4.842776298522949
INFO:root:current mean train loss 3999.6158595972433
INFO:root:current train perplexity4.842911243438721
INFO:root:current mean train loss 4002.1344917954916
INFO:root:current train perplexity4.846844673156738
INFO:root:current mean train loss 4002.2911143640276
INFO:root:current train perplexity4.846194744110107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.27s/it]
INFO:root:final mean train loss: 4001.1074600835
INFO:root:final train perplexity: 4.847934246063232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it]
INFO:root:eval mean loss: 4058.783329524047
INFO:root:eval perplexity: 5.1616315841674805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/32

 16%|â–ˆâ–Œ        | 32/200 [2:59:12<15:38:54, 335.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.9429465553976
INFO:root:current train perplexity4.748467922210693
INFO:root:current mean train loss 4001.0912959929437
INFO:root:current train perplexity4.807626247406006
INFO:root:current mean train loss 3980.047830499387
INFO:root:current train perplexity4.795852184295654
INFO:root:current mean train loss 3973.5375529544453
INFO:root:current train perplexity4.802252292633057
INFO:root:current mean train loss 3983.1240883628093
INFO:root:current train perplexity4.813706874847412
INFO:root:current mean train loss 3983.7949605855856
INFO:root:current train perplexity4.813401222229004
INFO:root:current mean train loss 3987.9591822966363
INFO:root:current train perplexity4.81531286239624
INFO:root:current mean train loss 3989.2616877069536
INFO:root:current train perplexity4.81502103805542
INFO:root:current mean train loss 3989.8257172880117
INFO:root:current train perplexity4.815405368804932
INFO:root:current mean train loss 3989.091611276996
INFO:root:current train perplexity4.818889141082764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.32s/it]
INFO:root:final mean train loss: 3984.962063266385
INFO:root:final train perplexity: 4.8171515464782715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.93s/it]
INFO:root:eval mean loss: 4054.163622700576
INFO:root:eval perplexity: 5.151998996734619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/33

 16%|â–ˆâ–‹        | 33/200 [3:04:19<15:09:52, 326.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3922.6278173053074
INFO:root:current train perplexity4.743079662322998
INFO:root:current mean train loss 3951.925372351898
INFO:root:current train perplexity4.784553527832031
INFO:root:current mean train loss 3950.115211167716
INFO:root:current train perplexity4.782148838043213
INFO:root:current mean train loss 3958.899356222021
INFO:root:current train perplexity4.781430244445801
INFO:root:current mean train loss 3968.5778355114403
INFO:root:current train perplexity4.784367561340332
INFO:root:current mean train loss 3965.556336208093
INFO:root:current train perplexity4.7789716720581055
INFO:root:current mean train loss 3968.457914648732
INFO:root:current train perplexity4.785709381103516
INFO:root:current mean train loss 3966.5047497030637
INFO:root:current train perplexity4.78165864944458
INFO:root:current mean train loss 3968.9449206868303
INFO:root:current train perplexity4.7840704917907715
INFO:root:current mean train loss 3976.200098213996
INFO:root:current train perplexity4.7946271896362305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it]
INFO:root:final mean train loss: 3972.9272612294844
INFO:root:final train perplexity: 4.794333457946777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 4049.4295905363474
INFO:root:eval perplexity: 5.142146587371826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/34

 17%|â–ˆâ–‹        | 34/200 [3:09:56<15:12:53, 329.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.084245708627
INFO:root:current train perplexity4.768390655517578
INFO:root:current mean train loss 3953.8274953741775
INFO:root:current train perplexity4.746291637420654
INFO:root:current mean train loss 3949.273788846287
INFO:root:current train perplexity4.748176574707031
INFO:root:current mean train loss 3951.964438384434
INFO:root:current train perplexity4.744441509246826
INFO:root:current mean train loss 3952.295250505905
INFO:root:current train perplexity4.745978355407715
INFO:root:current mean train loss 3956.6334068178085
INFO:root:current train perplexity4.756185054779053
INFO:root:current mean train loss 3959.5635220432423
INFO:root:current train perplexity4.761124134063721
INFO:root:current mean train loss 3957.789558697613
INFO:root:current train perplexity4.759388446807861
INFO:root:current mean train loss 3960.9015432154133
INFO:root:current train perplexity4.762396812438965
INFO:root:current mean train loss 3959.5774702706617
INFO:root:current train perplexity4.763800621032715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.54s/it]
INFO:root:final mean train loss: 3956.9250047745245
INFO:root:final train perplexity: 4.764161109924316
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.52s/it]
INFO:root:eval mean loss: 4044.686859347296
INFO:root:eval perplexity: 5.132294178009033
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/35

 18%|â–ˆâ–Š        | 35/200 [3:15:15<14:58:04, 326.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3967.7034185868274
INFO:root:current train perplexity4.755741596221924
INFO:root:current mean train loss 3948.9948444046786
INFO:root:current train perplexity4.727839469909668
INFO:root:current mean train loss 3952.8601730510754
INFO:root:current train perplexity4.740220546722412
INFO:root:current mean train loss 3949.8109617208115
INFO:root:current train perplexity4.735416412353516
INFO:root:current mean train loss 3948.9697790603796
INFO:root:current train perplexity4.739850044250488
INFO:root:current mean train loss 3951.4533973917855
INFO:root:current train perplexity4.737569332122803
INFO:root:current mean train loss 3952.1771141355625
INFO:root:current train perplexity4.7415666580200195
INFO:root:current mean train loss 3949.404164619103
INFO:root:current train perplexity4.740467071533203
INFO:root:current mean train loss 3947.7339755981584
INFO:root:current train perplexity4.739339828491211
INFO:root:current mean train loss 3947.616970042773
INFO:root:current train perplexity4.741458892822266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.50s/it]
INFO:root:final mean train loss: 3944.552624364053
INFO:root:final train perplexity: 4.740962028503418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it]
INFO:root:eval mean loss: 4042.113972116024
INFO:root:eval perplexity: 5.126955986022949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/36

 18%|â–ˆâ–Š        | 36/200 [3:20:28<14:41:29, 322.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.619280935704
INFO:root:current train perplexity4.69028902053833
INFO:root:current mean train loss 3908.0400377569354
INFO:root:current train perplexity4.684467792510986
INFO:root:current mean train loss 3920.639235865364
INFO:root:current train perplexity4.695343494415283
INFO:root:current mean train loss 3925.9221973665617
INFO:root:current train perplexity4.704405784606934
INFO:root:current mean train loss 3921.750439653651
INFO:root:current train perplexity4.706673622131348
INFO:root:current mean train loss 3923.255230515332
INFO:root:current train perplexity4.709891319274902
INFO:root:current mean train loss 3928.2809482890966
INFO:root:current train perplexity4.712348937988281
INFO:root:current mean train loss 3930.707671847701
INFO:root:current train perplexity4.713733196258545
INFO:root:current mean train loss 3931.731305764251
INFO:root:current train perplexity4.711612701416016
INFO:root:current mean train loss 3933.9525011675214
INFO:root:current train perplexity4.716135501861572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.97s/it]
INFO:root:final mean train loss: 3931.054862422328
INFO:root:final train perplexity: 4.715782642364502
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.05s/it]
INFO:root:eval mean loss: 4035.6764097822474
INFO:root:eval perplexity: 5.113627910614014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/37

 18%|â–ˆâ–Š        | 37/200 [3:26:12<14:54:11, 329.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.861839535362
INFO:root:current train perplexity4.637149333953857
INFO:root:current mean train loss 3891.5781700721154
INFO:root:current train perplexity4.648108005523682
INFO:root:current mean train loss 3901.1978060447564
INFO:root:current train perplexity4.665093898773193
INFO:root:current mean train loss 3895.5460059829907
INFO:root:current train perplexity4.668341159820557
INFO:root:current mean train loss 3902.7811927872476
INFO:root:current train perplexity4.674839019775391
INFO:root:current mean train loss 3907.197259059874
INFO:root:current train perplexity4.6784515380859375
INFO:root:current mean train loss 3908.6472083661197
INFO:root:current train perplexity4.679863929748535
INFO:root:current mean train loss 3914.97916267443
INFO:root:current train perplexity4.686209678649902
INFO:root:current mean train loss 3920.8122474031074
INFO:root:current train perplexity4.690836429595947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.80s/it]
INFO:root:final mean train loss: 3917.8276443481445
INFO:root:final train perplexity: 4.691237449645996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4033.0247309258643
INFO:root:eval perplexity: 5.108147621154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/38

 19%|â–ˆâ–‰        | 38/200 [3:31:25<14:35:48, 324.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.3135579427085
INFO:root:current train perplexity4.533492088317871
INFO:root:current mean train loss 3913.497722144266
INFO:root:current train perplexity4.66253137588501
INFO:root:current mean train loss 3902.6602067618533
INFO:root:current train perplexity4.653040885925293
INFO:root:current mean train loss 3904.2923209313117
INFO:root:current train perplexity4.651514053344727
INFO:root:current mean train loss 3898.8399400734725
INFO:root:current train perplexity4.646330833435059
INFO:root:current mean train loss 3901.4989753859654
INFO:root:current train perplexity4.646719932556152
INFO:root:current mean train loss 3906.6878016331107
INFO:root:current train perplexity4.655531406402588
INFO:root:current mean train loss 3904.5697481635625
INFO:root:current train perplexity4.659879207611084
INFO:root:current mean train loss 3906.3665836852038
INFO:root:current train perplexity4.660606384277344
INFO:root:current mean train loss 3908.6520376955286
INFO:root:current train perplexity4.6641845703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.64s/it]
INFO:root:final mean train loss: 3905.4821786572857
INFO:root:final train perplexity: 4.66844367980957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 4027.7074571974736
INFO:root:eval perplexity: 5.0971760749816895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/39

 20%|â–ˆâ–‰        | 39/200 [3:36:38<14:20:35, 320.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3839.4257590553975
INFO:root:current train perplexity4.565064430236816
INFO:root:current mean train loss 3871.436301291526
INFO:root:current train perplexity4.604435920715332
INFO:root:current mean train loss 3883.2584465713862
INFO:root:current train perplexity4.615386009216309
INFO:root:current mean train loss 3883.0460303205386
INFO:root:current train perplexity4.629018783569336
INFO:root:current mean train loss 3885.7913565902522
INFO:root:current train perplexity4.635923862457275
INFO:root:current mean train loss 3889.7530892627815
INFO:root:current train perplexity4.63700008392334
INFO:root:current mean train loss 3888.3182474938626
INFO:root:current train perplexity4.633322715759277
INFO:root:current mean train loss 3890.696258845376
INFO:root:current train perplexity4.6385416984558105
INFO:root:current mean train loss 3892.0837887012563
INFO:root:current train perplexity4.639063358306885
INFO:root:current mean train loss 3893.9314991252745
INFO:root:current train perplexity4.64204216003418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.55s/it]
INFO:root:final mean train loss: 3891.503573694537
INFO:root:final train perplexity: 4.642767906188965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it]
INFO:root:eval mean loss: 4025.877349637079
INFO:root:eval perplexity: 5.093405246734619
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/40

 20%|â–ˆâ–ˆ        | 40/200 [3:41:49<14:08:03, 318.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3882.1898386101975
INFO:root:current train perplexity4.620406150817871
INFO:root:current mean train loss 3874.6494263721115
INFO:root:current train perplexity4.615262508392334
INFO:root:current mean train loss 3874.2262302903823
INFO:root:current train perplexity4.615287780761719
INFO:root:current mean train loss 3883.9840527956017
INFO:root:current train perplexity4.61866569519043
INFO:root:current mean train loss 3883.8454001342484
INFO:root:current train perplexity4.619851589202881
INFO:root:current mean train loss 3886.6525728376387
INFO:root:current train perplexity4.6220855712890625
INFO:root:current mean train loss 3884.8706512204667
INFO:root:current train perplexity4.619846343994141
INFO:root:current mean train loss 3889.9722494621437
INFO:root:current train perplexity4.6278462409973145
INFO:root:current mean train loss 3886.489736256582
INFO:root:current train perplexity4.62401008605957
INFO:root:current mean train loss 3883.601664778717
INFO:root:current train perplexity4.623680114746094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.31s/it]
INFO:root:final mean train loss: 3880.41632504617
INFO:root:final train perplexity: 4.622503280639648
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.31s/it]
INFO:root:eval mean loss: 4020.607040946365
INFO:root:eval perplexity: 5.082561492919922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/41

 20%|â–ˆâ–ˆ        | 41/200 [3:47:29<14:19:53, 324.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3827.9315954137733
INFO:root:current train perplexity4.581564426422119
INFO:root:current mean train loss 3846.732206569882
INFO:root:current train perplexity4.56500768661499
INFO:root:current mean train loss 3852.1690689960765
INFO:root:current train perplexity4.577111721038818
INFO:root:current mean train loss 3855.048686269591
INFO:root:current train perplexity4.5744452476501465
INFO:root:current mean train loss 3856.5225907265444
INFO:root:current train perplexity4.581203460693359
INFO:root:current mean train loss 3858.0754593735173
INFO:root:current train perplexity4.578982830047607
INFO:root:current mean train loss 3861.3766914623207
INFO:root:current train perplexity4.580199718475342
INFO:root:current mean train loss 3866.5259511073978
INFO:root:current train perplexity4.588723182678223
INFO:root:current mean train loss 3871.423961265776
INFO:root:current train perplexity4.596142292022705
INFO:root:current mean train loss 3871.3124944693063
INFO:root:current train perplexity4.59733772277832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.68s/it]
INFO:root:final mean train loss: 3867.636221977972
INFO:root:final train perplexity: 4.599255084991455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.25s/it]
INFO:root:eval mean loss: 4018.805430310838
INFO:root:eval perplexity: 5.078860282897949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/42

 21%|â–ˆâ–ˆ        | 42/200 [3:53:00<14:19:41, 326.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.263267299107
INFO:root:current train perplexity4.549182891845703
INFO:root:current mean train loss 3819.7308648003473
INFO:root:current train perplexity4.551285743713379
INFO:root:current mean train loss 3838.641795836104
INFO:root:current train perplexity4.556736946105957
INFO:root:current mean train loss 3851.3545687091882
INFO:root:current train perplexity4.57120418548584
INFO:root:current mean train loss 3854.624149155891
INFO:root:current train perplexity4.57182502746582
INFO:root:current mean train loss 3857.1184876058705
INFO:root:current train perplexity4.5742387771606445
INFO:root:current mean train loss 3857.203651344119
INFO:root:current train perplexity4.577354431152344
INFO:root:current mean train loss 3861.1110736872874
INFO:root:current train perplexity4.578527927398682
INFO:root:current mean train loss 3858.144451136789
INFO:root:current train perplexity4.575932502746582
INFO:root:current mean train loss 3858.4928183489305
INFO:root:current train perplexity4.577093601226807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.58s/it]
INFO:root:final mean train loss: 3857.3176135401573
INFO:root:final train perplexity: 4.580569744110107
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.54s/it]
INFO:root:eval mean loss: 4014.402535945811
INFO:root:eval perplexity: 5.069826126098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:58:32<14:18:48, 328.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.7026991733287
INFO:root:current train perplexity4.568586826324463
INFO:root:current mean train loss 3864.0566474541083
INFO:root:current train perplexity4.568507671356201
INFO:root:current mean train loss 3854.611136228459
INFO:root:current train perplexity4.549581050872803
INFO:root:current mean train loss 3850.2976942590653
INFO:root:current train perplexity4.547955513000488
INFO:root:current mean train loss 3850.615340187641
INFO:root:current train perplexity4.546677589416504
INFO:root:current mean train loss 3850.7349482583736
INFO:root:current train perplexity4.55075216293335
INFO:root:current mean train loss 3849.4338576345012
INFO:root:current train perplexity4.55085563659668
INFO:root:current mean train loss 3846.843852847935
INFO:root:current train perplexity4.5523600578308105
INFO:root:current mean train loss 3848.4969785063577
INFO:root:current train perplexity4.557745456695557
INFO:root:current mean train loss 3848.153479275749
INFO:root:current train perplexity4.5585618019104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.64s/it]
INFO:root:final mean train loss: 3845.149048774473
INFO:root:final train perplexity: 4.558631420135498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it]
INFO:root:eval mean loss: 4012.3351271609044
INFO:root:eval perplexity: 5.065589427947998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:04:04<14:16:12, 329.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3784.35302734375
INFO:root:current train perplexity4.487392902374268
INFO:root:current mean train loss 3825.0955640780217
INFO:root:current train perplexity4.512603759765625
INFO:root:current mean train loss 3830.363477729706
INFO:root:current train perplexity4.527393817901611
INFO:root:current mean train loss 3828.2520261585205
INFO:root:current train perplexity4.524654388427734
INFO:root:current mean train loss 3835.481797178146
INFO:root:current train perplexity4.526440620422363
INFO:root:current mean train loss 3838.8689899756127
INFO:root:current train perplexity4.535655498504639
INFO:root:current mean train loss 3834.370784355199
INFO:root:current train perplexity4.533732891082764
INFO:root:current mean train loss 3837.3644028014733
INFO:root:current train perplexity4.538120269775391
INFO:root:current mean train loss 3835.4179899796195
INFO:root:current train perplexity4.538206100463867
INFO:root:current mean train loss 3838.078369140625
INFO:root:current train perplexity4.540020942687988


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.84s/it]
INFO:root:final mean train loss: 3836.116460000315
INFO:root:final train perplexity: 4.542415618896484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it]
INFO:root:eval mean loss: 4009.257907732159
INFO:root:eval perplexity: 5.059289932250977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:09:33<14:10:32, 329.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.264362917108
INFO:root:current train perplexity4.487129211425781
INFO:root:current mean train loss 3825.274777970224
INFO:root:current train perplexity4.513401508331299
INFO:root:current mean train loss 3822.28919258265
INFO:root:current train perplexity4.515754222869873
INFO:root:current mean train loss 3820.345074751915
INFO:root:current train perplexity4.513580799102783
INFO:root:current mean train loss 3821.243022046058
INFO:root:current train perplexity4.51666259765625
INFO:root:current mean train loss 3822.5978540956226
INFO:root:current train perplexity4.517155647277832
INFO:root:current mean train loss 3827.664535962396
INFO:root:current train perplexity4.519892692565918
INFO:root:current mean train loss 3829.876709627697
INFO:root:current train perplexity4.517177581787109
INFO:root:current mean train loss 3827.410196892735
INFO:root:current train perplexity4.518898010253906
INFO:root:current mean train loss 3827.023878175101
INFO:root:current train perplexity4.519755840301514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it]
INFO:root:final mean train loss: 3823.3108014137515
INFO:root:final train perplexity: 4.519524574279785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 4009.6643793633643
INFO:root:eval perplexity: 5.060122013092041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:14:42<13:49:30, 323.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3833.3410097947763
INFO:root:current train perplexity4.506328105926514
INFO:root:current mean train loss 3817.0697525846745
INFO:root:current train perplexity4.47644567489624
INFO:root:current mean train loss 3811.012280181999
INFO:root:current train perplexity4.482414722442627
INFO:root:current mean train loss 3817.7478739143394
INFO:root:current train perplexity4.493011474609375
INFO:root:current mean train loss 3821.7860983086857
INFO:root:current train perplexity4.4953107833862305
INFO:root:current mean train loss 3819.7451843584654
INFO:root:current train perplexity4.495476722717285
INFO:root:current mean train loss 3821.294470928598
INFO:root:current train perplexity4.502589225769043
INFO:root:current mean train loss 3817.9723057952046
INFO:root:current train perplexity4.500548839569092
INFO:root:current mean train loss 3817.517509979635
INFO:root:current train perplexity4.5011091232299805
INFO:root:current mean train loss 3816.6334166659935
INFO:root:current train perplexity4.50115442276001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.57s/it]
INFO:root:final mean train loss: 3812.9616618002615
INFO:root:final train perplexity: 4.501108646392822
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it]
INFO:root:eval mean loss: 4007.965835895944
INFO:root:eval perplexity: 5.0566487312316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:19:56<13:37:03, 320.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3799.1291861979166
INFO:root:current train perplexity4.423740386962891
INFO:root:current mean train loss 3793.266216517857
INFO:root:current train perplexity4.4630608558654785
INFO:root:current mean train loss 3794.935225497159
INFO:root:current train perplexity4.46429967880249
INFO:root:current mean train loss 3804.5200032552084
INFO:root:current train perplexity4.478701114654541
INFO:root:current mean train loss 3802.887437294408
INFO:root:current train perplexity4.47817325592041
INFO:root:current mean train loss 3804.300668733016
INFO:root:current train perplexity4.478842735290527
INFO:root:current mean train loss 3803.5545829716434
INFO:root:current train perplexity4.480348587036133
INFO:root:current mean train loss 3803.1666859879033
INFO:root:current train perplexity4.483220100402832
INFO:root:current mean train loss 3804.8355245535713
INFO:root:current train perplexity4.485631465911865
INFO:root:current mean train loss 3805.5222165464743
INFO:root:current train perplexity4.483757019042969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.72s/it]
INFO:root:final mean train loss: 3803.0014228205528
INFO:root:final train perplexity: 4.483455181121826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it]
INFO:root:eval mean loss: 4004.021065353502
INFO:root:eval perplexity: 5.048587322235107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:25:41<13:49:59, 327.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.597138554217
INFO:root:current train perplexity4.442227840423584
INFO:root:current mean train loss 3801.1023763020835
INFO:root:current train perplexity4.443277359008789
INFO:root:current mean train loss 3788.4144300049693
INFO:root:current train perplexity4.438652992248535
INFO:root:current mean train loss 3786.5490257322945
INFO:root:current train perplexity4.449750900268555
INFO:root:current mean train loss 3787.1730982304607
INFO:root:current train perplexity4.454250335693359
INFO:root:current mean train loss 3791.254784821237
INFO:root:current train perplexity4.449063301086426
INFO:root:current mean train loss 3792.6320243154055
INFO:root:current train perplexity4.453050136566162
INFO:root:current mean train loss 3792.0786079806235
INFO:root:current train perplexity4.45719051361084
INFO:root:current mean train loss 3792.3954768456256
INFO:root:current train perplexity4.4585041999816895
INFO:root:current mean train loss 3795.551440901577
INFO:root:current train perplexity4.466169834136963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.37s/it]
INFO:root:final mean train loss: 3793.1317768712197
INFO:root:final train perplexity: 4.466031074523926
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it]
INFO:root:eval mean loss: 4002.911891206782
INFO:root:eval perplexity: 5.046323776245117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:31:22<13:54:55, 331.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3787.5184956644916
INFO:root:current train perplexity4.403029441833496
INFO:root:current mean train loss 3782.387430720304
INFO:root:current train perplexity4.419349193572998
INFO:root:current mean train loss 3774.002445601106
INFO:root:current train perplexity4.427640914916992
INFO:root:current mean train loss 3778.6148160266143
INFO:root:current train perplexity4.434559345245361
INFO:root:current mean train loss 3779.2548266253502
INFO:root:current train perplexity4.437486171722412
INFO:root:current mean train loss 3781.987150602131
INFO:root:current train perplexity4.440755844116211
INFO:root:current mean train loss 3779.8440824693607
INFO:root:current train perplexity4.438602447509766
INFO:root:current mean train loss 3782.342579297863
INFO:root:current train perplexity4.441168308258057
INFO:root:current mean train loss 3781.5922119962647
INFO:root:current train perplexity4.44231653213501
INFO:root:current mean train loss 3785.9459037588294
INFO:root:current train perplexity4.448232173919678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.06s/it]
INFO:root:final mean train loss: 3783.068004854264
INFO:root:final train perplexity: 4.448334693908691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it]
INFO:root:eval mean loss: 4001.926465190049
INFO:root:eval perplexity: 5.044312477111816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:37:14<14:04:11, 337.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.7189127604165
INFO:root:current train perplexity4.389854431152344
INFO:root:current mean train loss 3767.037325298367
INFO:root:current train perplexity4.401163101196289
INFO:root:current mean train loss 3770.2447040264424
INFO:root:current train perplexity4.410469055175781
INFO:root:current mean train loss 3771.9831200315243
INFO:root:current train perplexity4.412575721740723
INFO:root:current mean train loss 3775.7081169174285
INFO:root:current train perplexity4.42363977432251
INFO:root:current mean train loss 3775.00144079651
INFO:root:current train perplexity4.429202079772949
INFO:root:current mean train loss 3770.3746465374643
INFO:root:current train perplexity4.428624629974365
INFO:root:current mean train loss 3770.4758105224305
INFO:root:current train perplexity4.428801536560059
INFO:root:current mean train loss 3772.262591844671
INFO:root:current train perplexity4.430267333984375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.08s/it]
INFO:root:final mean train loss: 3774.2005660764635
INFO:root:final train perplexity: 4.432799816131592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.12s/it]
INFO:root:eval mean loss: 4003.011337821365
INFO:root:eval perplexity: 5.04652738571167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:43:07<14:10:18, 342.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3701.6159319196427
INFO:root:current train perplexity4.363707065582275
INFO:root:current mean train loss 3761.9442903037384
INFO:root:current train perplexity4.3933610916137695
INFO:root:current mean train loss 3763.0621402758907
INFO:root:current train perplexity4.4053168296813965
INFO:root:current mean train loss 3771.5263950211215
INFO:root:current train perplexity4.404431343078613
INFO:root:current mean train loss 3772.1756162901183
INFO:root:current train perplexity4.409952640533447
INFO:root:current mean train loss 3768.7463239259737
INFO:root:current train perplexity4.407968521118164
INFO:root:current mean train loss 3765.5883805150843
INFO:root:current train perplexity4.408625602722168
INFO:root:current mean train loss 3762.44251368845
INFO:root:current train perplexity4.410350322723389
INFO:root:current mean train loss 3765.965507800399
INFO:root:current train perplexity4.414577484130859
INFO:root:current mean train loss 3766.2803361549923
INFO:root:current train perplexity4.4134368896484375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.63s/it]
INFO:root:final mean train loss: 3763.8732294267224
INFO:root:final train perplexity: 4.4147748947143555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.99s/it]
INFO:root:eval mean loss: 4000.176953471299
INFO:root:eval perplexity: 5.040747165679932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:49:11<14:20:28, 348.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3769.8267415364585
INFO:root:current train perplexity4.466460704803467
INFO:root:current mean train loss 3735.9451787533967
INFO:root:current train perplexity4.372077941894531
INFO:root:current mean train loss 3739.3864995912063
INFO:root:current train perplexity4.376901626586914
INFO:root:current mean train loss 3739.9452543712796
INFO:root:current train perplexity4.383062839508057
INFO:root:current mean train loss 3744.960665709714
INFO:root:current train perplexity4.381485462188721
INFO:root:current mean train loss 3747.5576584306737
INFO:root:current train perplexity4.384517669677734
INFO:root:current mean train loss 3745.759665983867
INFO:root:current train perplexity4.389794826507568
INFO:root:current mean train loss 3750.2034777234485
INFO:root:current train perplexity4.394118309020996
INFO:root:current mean train loss 3755.9913304615607
INFO:root:current train perplexity4.396407127380371
INFO:root:current mean train loss 3757.213801816513
INFO:root:current train perplexity4.397853851318359


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.29s/it]
INFO:root:final mean train loss: 3755.0234746625347
INFO:root:final train perplexity: 4.399388313293457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.14s/it]
INFO:root:eval mean loss: 3997.5988146193486
INFO:root:eval perplexity: 5.035493850708008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:55:21<14:29:57, 355.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3751.4201872452445
INFO:root:current train perplexity4.442678928375244
INFO:root:current mean train loss 3752.287593686484
INFO:root:current train perplexity4.397319316864014
INFO:root:current mean train loss 3741.21618926044
INFO:root:current train perplexity4.383378505706787
INFO:root:current mean train loss 3749.4502769446594
INFO:root:current train perplexity4.386332035064697
INFO:root:current mean train loss 3743.922864260121
INFO:root:current train perplexity4.383518695831299
INFO:root:current mean train loss 3750.3036297128942
INFO:root:current train perplexity4.390230178833008
INFO:root:current mean train loss 3752.832457614366
INFO:root:current train perplexity4.390201568603516
INFO:root:current mean train loss 3748.3980880040845
INFO:root:current train perplexity4.384246826171875
INFO:root:current mean train loss 3750.856260797957
INFO:root:current train perplexity4.387409210205078
INFO:root:current mean train loss 3752.8089555965603
INFO:root:current train perplexity4.388551235198975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.78s/it]
INFO:root:final mean train loss: 3747.439945836221
INFO:root:final train perplexity: 4.386245250701904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.74s/it]
INFO:root:eval mean loss: 3996.2049309480276
INFO:root:eval perplexity: 5.032656669616699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:00:56<14:09:54, 349.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3714.344450919859
INFO:root:current train perplexity4.3657732009887695
INFO:root:current mean train loss 3726.3945722507156
INFO:root:current train perplexity4.349737167358398
INFO:root:current mean train loss 3737.867656757305
INFO:root:current train perplexity4.3643083572387695
INFO:root:current mean train loss 3729.6383215221394
INFO:root:current train perplexity4.356786727905273
INFO:root:current mean train loss 3732.8059008392547
INFO:root:current train perplexity4.363175868988037
INFO:root:current mean train loss 3735.052946791137
INFO:root:current train perplexity4.368276119232178
INFO:root:current mean train loss 3733.2856178344146
INFO:root:current train perplexity4.369497776031494
INFO:root:current mean train loss 3734.9872963379576
INFO:root:current train perplexity4.3696370124816895
INFO:root:current mean train loss 3736.416045297928
INFO:root:current train perplexity4.3696722984313965
INFO:root:current mean train loss 3738.1453237236506
INFO:root:current train perplexity4.36821174621582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.29s/it]
INFO:root:final mean train loss: 3736.9644606190345
INFO:root:final train perplexity: 4.368154048919678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it]
INFO:root:eval mean loss: 3999.236016456117
INFO:root:eval perplexity: 5.038828372955322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:06:41<14:00:40, 347.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3688.047125400641
INFO:root:current train perplexity4.304896354675293
INFO:root:current mean train loss 3726.2511328827563
INFO:root:current train perplexity4.332781791687012
INFO:root:current mean train loss 3727.8966835692336
INFO:root:current train perplexity4.3364129066467285
INFO:root:current mean train loss 3723.5548747464973
INFO:root:current train perplexity4.331122398376465
INFO:root:current mean train loss 3720.8813793556023
INFO:root:current train perplexity4.332705497741699
INFO:root:current mean train loss 3718.3314863498667
INFO:root:current train perplexity4.337704181671143
INFO:root:current mean train loss 3720.3692468395443
INFO:root:current train perplexity4.341348648071289
INFO:root:current mean train loss 3724.0822638278078
INFO:root:current train perplexity4.3482537269592285
INFO:root:current mean train loss 3726.3800550785904
INFO:root:current train perplexity4.349674224853516
INFO:root:current mean train loss 3730.0341544674357
INFO:root:current train perplexity4.352080345153809


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it]
INFO:root:final mean train loss: 3727.8985304063367
INFO:root:final train perplexity: 4.352558135986328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it]
INFO:root:eval mean loss: 3992.3806706421765
INFO:root:eval perplexity: 5.0248799324035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:11:59<13:33:08, 338.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3718.998748129987
INFO:root:current train perplexity4.329275608062744
INFO:root:current mean train loss 3706.232916799532
INFO:root:current train perplexity4.314788818359375
INFO:root:current mean train loss 3712.732751020053
INFO:root:current train perplexity4.318292617797852
INFO:root:current mean train loss 3714.692197068624
INFO:root:current train perplexity4.320446968078613
INFO:root:current mean train loss 3713.0202112389893
INFO:root:current train perplexity4.325829982757568
INFO:root:current mean train loss 3716.0837335394767
INFO:root:current train perplexity4.328265190124512
INFO:root:current mean train loss 3721.570560036708
INFO:root:current train perplexity4.3331708908081055
INFO:root:current mean train loss 3721.6048696740086
INFO:root:current train perplexity4.334717750549316
INFO:root:current mean train loss 3723.1058547054863
INFO:root:current train perplexity4.33662748336792
INFO:root:current mean train loss 3723.2918096620906
INFO:root:current train perplexity4.337275505065918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it]
INFO:root:final mean train loss: 3719.1024886715795
INFO:root:final train perplexity: 4.337480068206787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.26s/it]
INFO:root:eval mean loss: 3994.1364867298316
INFO:root:eval perplexity: 5.028449058532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:17:11<13:08:48, 330.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3673.1979181463066
INFO:root:current train perplexity4.254227161407471
INFO:root:current mean train loss 3686.989305065524
INFO:root:current train perplexity4.287487030029297
INFO:root:current mean train loss 3696.7497501148896
INFO:root:current train perplexity4.292767524719238
INFO:root:current mean train loss 3695.2143238336266
INFO:root:current train perplexity4.293421268463135
INFO:root:current mean train loss 3706.0119317694025
INFO:root:current train perplexity4.305468559265137
INFO:root:current mean train loss 3705.8644746797577
INFO:root:current train perplexity4.309238910675049
INFO:root:current mean train loss 3706.600550155057
INFO:root:current train perplexity4.313619613647461
INFO:root:current mean train loss 3708.0633717922187
INFO:root:current train perplexity4.319860935211182
INFO:root:current mean train loss 3709.6746964661
INFO:root:current train perplexity4.319502353668213
INFO:root:current mean train loss 3712.8797526893813
INFO:root:current train perplexity4.322375774383545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it]
INFO:root:final mean train loss: 3710.6249871407786
INFO:root:final train perplexity: 4.322997093200684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it]
INFO:root:eval mean loss: 3993.822902814716
INFO:root:eval perplexity: 5.0278120040893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:22:22<12:49:08, 324.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3703.738974919395
INFO:root:current train perplexity4.3158159255981445
INFO:root:current mean train loss 3680.369293400115
INFO:root:current train perplexity4.266902446746826
INFO:root:current mean train loss 3689.0802934885933
INFO:root:current train perplexity4.274604797363281
INFO:root:current mean train loss 3682.391664783488
INFO:root:current train perplexity4.277398109436035
INFO:root:current mean train loss 3689.410030224926
INFO:root:current train perplexity4.2871270179748535
INFO:root:current mean train loss 3692.771839094416
INFO:root:current train perplexity4.290404796600342
INFO:root:current mean train loss 3694.6978901536577
INFO:root:current train perplexity4.293025493621826
INFO:root:current mean train loss 3696.506606515707
INFO:root:current train perplexity4.299288749694824
INFO:root:current mean train loss 3698.4901715717338
INFO:root:current train perplexity4.303485870361328
INFO:root:current mean train loss 3703.249611605984
INFO:root:current train perplexity4.307363033294678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it]
INFO:root:final mean train loss: 3702.0988528343937
INFO:root:final train perplexity: 4.3084797859191895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.25s/it]
INFO:root:eval mean loss: 3989.972093514517
INFO:root:eval perplexity: 5.019988059997559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:27:36<12:35:36, 321.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.904571963028
INFO:root:current train perplexity4.2762250900268555
INFO:root:current mean train loss 3674.3601973684213
INFO:root:current train perplexity4.252858638763428
INFO:root:current mean train loss 3689.87765311491
INFO:root:current train perplexity4.270825386047363
INFO:root:current mean train loss 3693.7918145110343
INFO:root:current train perplexity4.281906604766846
INFO:root:current mean train loss 3691.777574931993
INFO:root:current train perplexity4.288426876068115
INFO:root:current mean train loss 3692.671458549967
INFO:root:current train perplexity4.291022777557373
INFO:root:current mean train loss 3693.1242890450353
INFO:root:current train perplexity4.292017936706543
INFO:root:current mean train loss 3695.6910436805892
INFO:root:current train perplexity4.292181491851807
INFO:root:current mean train loss 3696.079571344001
INFO:root:current train perplexity4.2935566902160645
INFO:root:current mean train loss 3696.131547041951
INFO:root:current train perplexity4.29460334777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.68s/it]
INFO:root:final mean train loss: 3694.5604726729853
INFO:root:final train perplexity: 4.295684814453125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.54s/it]
INFO:root:eval mean loss: 3993.0866249030364
INFO:root:eval perplexity: 5.0263142585754395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:33:28<12:51:55, 330.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3678.4040125593356
INFO:root:current train perplexity4.273558139801025
INFO:root:current mean train loss 3690.961839047224
INFO:root:current train perplexity4.281275272369385
INFO:root:current mean train loss 3687.1276006664425
INFO:root:current train perplexity4.282660961151123
INFO:root:current mean train loss 3678.1497793071817
INFO:root:current train perplexity4.277078151702881
INFO:root:current mean train loss 3678.916152221425
INFO:root:current train perplexity4.273571491241455
INFO:root:current mean train loss 3683.1345935880827
INFO:root:current train perplexity4.279508590698242
INFO:root:current mean train loss 3681.222162934923
INFO:root:current train perplexity4.275454998016357
INFO:root:current mean train loss 3684.201220452403
INFO:root:current train perplexity4.278592109680176
INFO:root:current mean train loss 3685.2485779294652
INFO:root:current train perplexity4.277363300323486
INFO:root:current mean train loss 3689.631414240057
INFO:root:current train perplexity4.281660079956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it]
INFO:root:final mean train loss: 3686.2574360139906
INFO:root:final train perplexity: 4.2816362380981445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it]
INFO:root:eval mean loss: 3993.0380322611923
INFO:root:eval perplexity: 5.02621603012085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:39:27<13:06:05, 339.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3664.7480244252874
INFO:root:current train perplexity4.224813938140869
INFO:root:current mean train loss 3672.322005817597
INFO:root:current train perplexity4.251016139984131
INFO:root:current mean train loss 3679.1533279684777
INFO:root:current train perplexity4.260643005371094
INFO:root:current mean train loss 3681.1426601360627
INFO:root:current train perplexity4.263304710388184
INFO:root:current mean train loss 3682.759386129203
INFO:root:current train perplexity4.267618656158447
INFO:root:current mean train loss 3682.8669758005485
INFO:root:current train perplexity4.265936374664307
INFO:root:current mean train loss 3681.9479198650156
INFO:root:current train perplexity4.265964508056641
INFO:root:current mean train loss 3680.0607978403946
INFO:root:current train perplexity4.267191410064697
INFO:root:current mean train loss 3679.0073019240594
INFO:root:current train perplexity4.265997409820557
INFO:root:current mean train loss 3680.8052024957256
INFO:root:current train perplexity4.267585277557373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.61s/it]
INFO:root:final mean train loss: 3677.980805181688
INFO:root:final train perplexity: 4.2676777839660645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.33s/it]
INFO:root:eval mean loss: 3995.284487893395
INFO:root:eval perplexity: 5.030783653259277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:45:11<13:03:40, 340.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3642.9767372532897
INFO:root:current train perplexity4.21537446975708
INFO:root:current mean train loss 3658.0848357371797
INFO:root:current train perplexity4.2359089851379395
INFO:root:current mean train loss 3664.4768082958158
INFO:root:current train perplexity4.2417473793029785
INFO:root:current mean train loss 3666.8411818878562
INFO:root:current train perplexity4.244174480438232
INFO:root:current mean train loss 3670.988461272885
INFO:root:current train perplexity4.244656562805176
INFO:root:current mean train loss 3672.0694594439337
INFO:root:current train perplexity4.250448703765869
INFO:root:current mean train loss 3671.7783312022257
INFO:root:current train perplexity4.249963760375977
INFO:root:current mean train loss 3673.924019445263
INFO:root:current train perplexity4.256556034088135
INFO:root:current mean train loss 3673.8949657930343
INFO:root:current train perplexity4.256041049957275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it]
INFO:root:final mean train loss: 3670.643845773512
INFO:root:final train perplexity: 4.25534200668335
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it]
INFO:root:eval mean loss: 3993.5814200326904
INFO:root:eval perplexity: 5.027320384979248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:50:55<12:59:59, 341.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3661.4088541666665
INFO:root:current train perplexity4.263382434844971
INFO:root:current mean train loss 3670.1239546988772
INFO:root:current train perplexity4.238071441650391
INFO:root:current mean train loss 3658.3681388065734
INFO:root:current train perplexity4.22999906539917
INFO:root:current mean train loss 3658.772830774288
INFO:root:current train perplexity4.239480018615723
INFO:root:current mean train loss 3666.289306640625
INFO:root:current train perplexity4.243696212768555
INFO:root:current mean train loss 3670.255563785257
INFO:root:current train perplexity4.24075174331665
INFO:root:current mean train loss 3670.0239844883654
INFO:root:current train perplexity4.239611625671387
INFO:root:current mean train loss 3666.2000525787917
INFO:root:current train perplexity4.236441612243652
INFO:root:current mean train loss 3666.9379843287866
INFO:root:current train perplexity4.238539695739746
INFO:root:current mean train loss 3666.8886053649294
INFO:root:current train perplexity4.239473819732666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it]
INFO:root:final mean train loss: 3663.3101394407213
INFO:root:final train perplexity: 4.24304723739624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 3988.147715467088
INFO:root:eval perplexity: 5.016286373138428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/64
###############best###########
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [5:56:22<12:44:19, 337.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3639.6309925426135
INFO:root:current train perplexity4.211915016174316
INFO:root:current mean train loss 3671.196702561937
INFO:root:current train perplexity4.228403091430664
INFO:root:current mean train loss 3648.697663655213
INFO:root:current train perplexity4.220145225524902
INFO:root:current mean train loss 3636.618477284717
INFO:root:current train perplexity4.211838245391846
INFO:root:current mean train loss 3642.3900345479774
INFO:root:current train perplexity4.211575031280518
INFO:root:current mean train loss 3649.0115907075588
INFO:root:current train perplexity4.217498302459717
INFO:root:current mean train loss 3654.0838772887682
INFO:root:current train perplexity4.2245025634765625
INFO:root:current mean train loss 3655.95303709564
INFO:root:current train perplexity4.227729797363281
INFO:root:current mean train loss 3659.904489237342
INFO:root:current train perplexity4.230950832366943
INFO:root:current mean train loss 3658.0824340418326
INFO:root:current train perplexity4.229904651641846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.98s/it]
INFO:root:final mean train loss: 3656.345900197183
INFO:root:final train perplexity: 4.231406211853027
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.01s/it]
INFO:root:eval mean loss: 3989.813982158688
INFO:root:eval perplexity: 5.019667148590088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:02:04<12:42:12, 338.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.3547748766446
INFO:root:current train perplexity4.193955898284912
INFO:root:current mean train loss 3645.463360441833
INFO:root:current train perplexity4.204709529876709
INFO:root:current mean train loss 3645.27709737978
INFO:root:current train perplexity4.203033924102783
INFO:root:current mean train loss 3647.8135094717377
INFO:root:current train perplexity4.20465087890625
INFO:root:current mean train loss 3649.4584553065333
INFO:root:current train perplexity4.209564208984375
INFO:root:current mean train loss 3645.701723190631
INFO:root:current train perplexity4.203877925872803
INFO:root:current mean train loss 3650.6140120942296
INFO:root:current train perplexity4.210704326629639
INFO:root:current mean train loss 3648.740893113265
INFO:root:current train perplexity4.212892055511475
INFO:root:current mean train loss 3647.683303106399
INFO:root:current train perplexity4.210188865661621
INFO:root:current mean train loss 3648.3285729010813
INFO:root:current train perplexity4.215108394622803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it]
INFO:root:final mean train loss: 3648.1309489588584
INFO:root:final train perplexity: 4.217713832855225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it]
INFO:root:eval mean loss: 3993.10306370512
INFO:root:eval perplexity: 5.0263471603393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:07:48<12:39:43, 340.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3611.330304181134
INFO:root:current train perplexity4.1190900802612305
INFO:root:current mean train loss 3624.804597148745
INFO:root:current train perplexity4.170906066894531
INFO:root:current mean train loss 3641.344066199752
INFO:root:current train perplexity4.202707767486572
INFO:root:current mean train loss 3643.594253213398
INFO:root:current train perplexity4.201310634613037
INFO:root:current mean train loss 3645.1800602861535
INFO:root:current train perplexity4.198385715484619
INFO:root:current mean train loss 3638.7515023682104
INFO:root:current train perplexity4.192889213562012
INFO:root:current mean train loss 3638.7518744704444
INFO:root:current train perplexity4.1963419914245605
INFO:root:current mean train loss 3639.1983741644817
INFO:root:current train perplexity4.200819969177246
INFO:root:current mean train loss 3639.6799493533667
INFO:root:current train perplexity4.202378273010254
INFO:root:current mean train loss 3642.653485443214
INFO:root:current train perplexity4.204594612121582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.60s/it]
INFO:root:final mean train loss: 3640.9089720326087
INFO:root:final train perplexity: 4.205713748931885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it]
INFO:root:eval mean loss: 3988.873439924091
INFO:root:eval perplexity: 5.017759323120117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:13:37<12:39:45, 342.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3612.7773507254465
INFO:root:current train perplexity4.159853935241699
INFO:root:current mean train loss 3604.977079716435
INFO:root:current train perplexity4.157860279083252
INFO:root:current mean train loss 3615.632249418218
INFO:root:current train perplexity4.168844223022461
INFO:root:current mean train loss 3624.3930336112408
INFO:root:current train perplexity4.174356460571289
INFO:root:current mean train loss 3624.4534218974495
INFO:root:current train perplexity4.175187587738037
INFO:root:current mean train loss 3632.3709956374123
INFO:root:current train perplexity4.181947231292725
INFO:root:current mean train loss 3633.0267574280265
INFO:root:current train perplexity4.180108070373535
INFO:root:current mean train loss 3634.3878006085247
INFO:root:current train perplexity4.185501575469971
INFO:root:current mean train loss 3635.9923936307073
INFO:root:current train perplexity4.189454078674316
INFO:root:current mean train loss 3637.825128206467
INFO:root:current train perplexity4.191809177398682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.71s/it]
INFO:root:final mean train loss: 3633.1660134100143
INFO:root:final train perplexity: 4.192884922027588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.79s/it]
INFO:root:eval mean loss: 3990.526197501108
INFO:root:eval perplexity: 5.021113872528076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:19:28<12:39:44, 345.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.7959608920787
INFO:root:current train perplexity4.1593098640441895
INFO:root:current mean train loss 3634.892941775022
INFO:root:current train perplexity4.1823906898498535
INFO:root:current mean train loss 3632.59288596322
INFO:root:current train perplexity4.180527210235596
INFO:root:current mean train loss 3629.363519696383
INFO:root:current train perplexity4.173610210418701
INFO:root:current mean train loss 3624.0479380863785
INFO:root:current train perplexity4.170164585113525
INFO:root:current mean train loss 3626.4540799810084
INFO:root:current train perplexity4.173063278198242
INFO:root:current mean train loss 3629.9439923181135
INFO:root:current train perplexity4.175935745239258
INFO:root:current mean train loss 3630.2342576942083
INFO:root:current train perplexity4.1781182289123535
INFO:root:current mean train loss 3632.363384061295
INFO:root:current train perplexity4.1821465492248535
INFO:root:current mean train loss 3629.2911854619565
INFO:root:current train perplexity4.179785251617432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.83s/it]
INFO:root:final mean train loss: 3626.0338196908274
INFO:root:final train perplexity: 4.1811041831970215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.87s/it]
INFO:root:eval mean loss: 3991.061776235594
INFO:root:eval perplexity: 5.0222015380859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:24:56<12:22:32, 340.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3608.77445714614
INFO:root:current train perplexity4.155435085296631
INFO:root:current mean train loss 3600.9383407491723
INFO:root:current train perplexity4.153517246246338
INFO:root:current mean train loss 3604.0900956719993
INFO:root:current train perplexity4.148482322692871
INFO:root:current mean train loss 3615.673849687277
INFO:root:current train perplexity4.163872718811035
INFO:root:current mean train loss 3608.876011207733
INFO:root:current train perplexity4.161864757537842
INFO:root:current mean train loss 3609.2860202685456
INFO:root:current train perplexity4.163920879364014
INFO:root:current mean train loss 3613.325487456197
INFO:root:current train perplexity4.165377140045166
INFO:root:current mean train loss 3615.262964159766
INFO:root:current train perplexity4.167440414428711
INFO:root:current mean train loss 3619.0717690240344
INFO:root:current train perplexity4.168431282043457
INFO:root:current mean train loss 3621.800660591647
INFO:root:current train perplexity4.16981315612793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.68s/it]
INFO:root:final mean train loss: 3619.5505257268105
INFO:root:final train perplexity: 4.1704230308532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 3992.908696600731
INFO:root:eval perplexity: 5.0259528160095215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:30:34<12:15:45, 339.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.695295948093
INFO:root:current train perplexity4.146522045135498
INFO:root:current mean train loss 3583.707505711969
INFO:root:current train perplexity4.136992931365967
INFO:root:current mean train loss 3600.0593120324565
INFO:root:current train perplexity4.146383285522461
INFO:root:current mean train loss 3598.787642540042
INFO:root:current train perplexity4.1462578773498535
INFO:root:current mean train loss 3601.3859804772605
INFO:root:current train perplexity4.1431355476379395
INFO:root:current mean train loss 3602.245131600095
INFO:root:current train perplexity4.144622325897217
INFO:root:current mean train loss 3604.7390258974297
INFO:root:current train perplexity4.1473259925842285
INFO:root:current mean train loss 3606.245549178092
INFO:root:current train perplexity4.151553153991699
INFO:root:current mean train loss 3608.847191558589
INFO:root:current train perplexity4.153721332550049
INFO:root:current mean train loss 3613.7494327994655
INFO:root:current train perplexity4.155693531036377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.33s/it]
INFO:root:final mean train loss: 3611.7294833890855
INFO:root:final train perplexity: 4.157574653625488
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.82s/it]
INFO:root:eval mean loss: 3993.153699509641
INFO:root:eval perplexity: 5.026450157165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:35:47<11:52:34, 331.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3579.589125903685
INFO:root:current train perplexity4.09032678604126
INFO:root:current mean train loss 3582.633936716411
INFO:root:current train perplexity4.103692531585693
INFO:root:current mean train loss 3582.4550086317886
INFO:root:current train perplexity4.113393306732178
INFO:root:current mean train loss 3595.796256333021
INFO:root:current train perplexity4.126414775848389
INFO:root:current mean train loss 3595.911391068322
INFO:root:current train perplexity4.126029014587402
INFO:root:current mean train loss 3591.899364114859
INFO:root:current train perplexity4.128039836883545
INFO:root:current mean train loss 3598.0322346151142
INFO:root:current train perplexity4.13178825378418
INFO:root:current mean train loss 3601.0383673199153
INFO:root:current train perplexity4.137231826782227
INFO:root:current mean train loss 3600.6374770783773
INFO:root:current train perplexity4.138391971588135
INFO:root:current mean train loss 3606.9784752294468
INFO:root:current train perplexity4.145777702331543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it]
INFO:root:final mean train loss: 3604.5379784491756
INFO:root:final train perplexity: 4.1457953453063965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 3995.199840356272
INFO:root:eval perplexity: 5.03061056137085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:40:55<11:32:09, 324.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.531669921875
INFO:root:current train perplexity4.125957489013672
INFO:root:current mean train loss 3594.4260770089286
INFO:root:current train perplexity4.113309383392334
INFO:root:current mean train loss 3597.5346155894886
INFO:root:current train perplexity4.118241310119629
INFO:root:current mean train loss 3595.0435546875
INFO:root:current train perplexity4.126020431518555
INFO:root:current mean train loss 3598.116551192434
INFO:root:current train perplexity4.131284236907959
INFO:root:current mean train loss 3598.563397588315
INFO:root:current train perplexity4.129889965057373
INFO:root:current mean train loss 3598.8217353877317
INFO:root:current train perplexity4.131112098693848
INFO:root:current mean train loss 3601.071869329637
INFO:root:current train perplexity4.136175155639648
INFO:root:current mean train loss 3602.3496531808037
INFO:root:current train perplexity4.13638162612915
INFO:root:current mean train loss 3602.649143379407
INFO:root:current train perplexity4.137868404388428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.03s/it]
INFO:root:final mean train loss: 3599.369051594888
INFO:root:final train perplexity: 4.1373491287231445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it]
INFO:root:eval mean loss: 3993.104088749446
INFO:root:eval perplexity: 5.026350021362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [6:46:37<11:37:59, 329.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3560.792318688818
INFO:root:current train perplexity4.0918803215026855
INFO:root:current mean train loss 3579.979301410946
INFO:root:current train perplexity4.110267639160156
INFO:root:current mean train loss 3589.620617546378
INFO:root:current train perplexity4.120752334594727
INFO:root:current mean train loss 3587.9179719372146
INFO:root:current train perplexity4.115141868591309
INFO:root:current mean train loss 3589.7166967925077
INFO:root:current train perplexity4.121279716491699
INFO:root:current mean train loss 3589.402125991638
INFO:root:current train perplexity4.123340129852295
INFO:root:current mean train loss 3591.9445815079384
INFO:root:current train perplexity4.124719619750977
INFO:root:current mean train loss 3591.732544101213
INFO:root:current train perplexity4.123025417327881
INFO:root:current mean train loss 3593.4128500915735
INFO:root:current train perplexity4.123481273651123
INFO:root:current mean train loss 3594.1690213115144
INFO:root:current train perplexity4.1251983642578125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.69s/it]
INFO:root:final mean train loss: 3592.1769259668167
INFO:root:final train perplexity: 4.125626087188721
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.36s/it]
INFO:root:eval mean loss: 3996.29263110871
INFO:root:eval perplexity: 5.032834529876709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [6:51:51<11:22:50, 325.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.9966571514424
INFO:root:current train perplexity4.1102471351623535
INFO:root:current mean train loss 3575.94960605162
INFO:root:current train perplexity4.0914626121521
INFO:root:current mean train loss 3581.607322876396
INFO:root:current train perplexity4.097610950469971
INFO:root:current mean train loss 3578.229360438979
INFO:root:current train perplexity4.098744869232178
INFO:root:current mean train loss 3578.183220826438
INFO:root:current train perplexity4.098890781402588
INFO:root:current mean train loss 3580.1816224487097
INFO:root:current train perplexity4.0977091789245605
INFO:root:current mean train loss 3581.025904344926
INFO:root:current train perplexity4.10286283493042
INFO:root:current mean train loss 3582.66511591587
INFO:root:current train perplexity4.1073689460754395
INFO:root:current mean train loss 3584.2656789794646
INFO:root:current train perplexity4.110116958618164
INFO:root:current mean train loss 3587.915404164827
INFO:root:current train perplexity4.114171504974365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.56s/it]
INFO:root:final mean train loss: 3585.1466170895483
INFO:root:final train perplexity: 4.114198207855225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
INFO:root:eval mean loss: 3992.38203679078
INFO:root:eval perplexity: 5.024882793426514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [6:57:40<11:32:12, 332.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3566.879340277778
INFO:root:current train perplexity4.086790084838867
INFO:root:current mean train loss 3576.25141454342
INFO:root:current train perplexity4.085976600646973
INFO:root:current mean train loss 3575.4089477947323
INFO:root:current train perplexity4.092216968536377
INFO:root:current mean train loss 3574.4628759398497
INFO:root:current train perplexity4.09352445602417
INFO:root:current mean train loss 3577.888578426384
INFO:root:current train perplexity4.09502649307251
INFO:root:current mean train loss 3578.6084893279162
INFO:root:current train perplexity4.093400955200195
INFO:root:current mean train loss 3582.4243419030536
INFO:root:current train perplexity4.101876735687256
INFO:root:current mean train loss 3580.4776154519323
INFO:root:current train perplexity4.101841926574707
INFO:root:current mean train loss 3580.949374630666
INFO:root:current train perplexity4.104020118713379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.08s/it]
INFO:root:final mean train loss: 3579.1376729780627
INFO:root:final train perplexity: 4.104457378387451
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it]
INFO:root:eval mean loss: 3993.44164346465
INFO:root:eval perplexity: 5.027035713195801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:03:26<11:34:48, 336.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.730782645089
INFO:root:current train perplexity4.125802993774414
INFO:root:current mean train loss 3579.688316844334
INFO:root:current train perplexity4.107455730438232
INFO:root:current mean train loss 3567.085200360432
INFO:root:current train perplexity4.086019992828369
INFO:root:current mean train loss 3564.5156496526365
INFO:root:current train perplexity4.076994895935059
INFO:root:current mean train loss 3567.1352473078546
INFO:root:current train perplexity4.079524517059326
INFO:root:current mean train loss 3568.1341993343194
INFO:root:current train perplexity4.081714630126953
INFO:root:current mean train loss 3573.8028035548805
INFO:root:current train perplexity4.0884318351745605
INFO:root:current mean train loss 3574.6538942328943
INFO:root:current train perplexity4.091127395629883
INFO:root:current mean train loss 3574.7884510895874
INFO:root:current train perplexity4.091385364532471
INFO:root:current mean train loss 3574.278966867937
INFO:root:current train perplexity4.091854572296143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.65s/it]
INFO:root:final mean train loss: 3572.8358954152754
INFO:root:final train perplexity: 4.094264507293701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it]
INFO:root:eval mean loss: 3994.5484783632537
INFO:root:eval perplexity: 5.0292863845825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:09:11<11:35:08, 339.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3521.859765625
INFO:root:current train perplexity4.0085015296936035
INFO:root:current mean train loss 3556.957948369565
INFO:root:current train perplexity4.052573204040527
INFO:root:current mean train loss 3561.7638149527615
INFO:root:current train perplexity4.058901309967041
INFO:root:current mean train loss 3557.8743877108136
INFO:root:current train perplexity4.059793472290039
INFO:root:current mean train loss 3563.072436229292
INFO:root:current train perplexity4.070414066314697
INFO:root:current mean train loss 3563.651632660801
INFO:root:current train perplexity4.0725507736206055
INFO:root:current mean train loss 3560.132450457317
INFO:root:current train perplexity4.0693678855896
INFO:root:current mean train loss 3564.8558539117134
INFO:root:current train perplexity4.076536178588867
INFO:root:current mean train loss 3566.5037142326496
INFO:root:current train perplexity4.080038547515869
INFO:root:current mean train loss 3567.7436502091873
INFO:root:current train perplexity4.081292152404785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.70s/it]
INFO:root:final mean train loss: 3566.5894673255184
INFO:root:final train perplexity: 4.084187030792236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it]
INFO:root:eval mean loss: 3995.3019794437055
INFO:root:eval perplexity: 5.030818939208984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:14:59<11:34:55, 341.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3563.120902683424
INFO:root:current train perplexity4.078834533691406
INFO:root:current mean train loss 3556.0630756161077
INFO:root:current train perplexity4.074418067932129
INFO:root:current mean train loss 3551.098154384459
INFO:root:current train perplexity4.070670127868652
INFO:root:current mean train loss 3555.7828985161086
INFO:root:current train perplexity4.068546772003174
INFO:root:current mean train loss 3554.9718557227025
INFO:root:current train perplexity4.067371368408203
INFO:root:current mean train loss 3554.0853203797205
INFO:root:current train perplexity4.069132328033447
INFO:root:current mean train loss 3558.4723666514096
INFO:root:current train perplexity4.070638179779053
INFO:root:current mean train loss 3558.4600136151453
INFO:root:current train perplexity4.069064617156982
INFO:root:current mean train loss 3560.7638997000304
INFO:root:current train perplexity4.069974899291992
INFO:root:current mean train loss 3561.9087493334405
INFO:root:current train perplexity4.074585914611816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.00s/it]
INFO:root:final mean train loss: 3561.339283666303
INFO:root:final train perplexity: 4.075736045837402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 3995.9698823969416
INFO:root:eval perplexity: 5.0321784019470215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:20:43<11:30:28, 342.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3539.1890908518144
INFO:root:current train perplexity4.025315284729004
INFO:root:current mean train loss 3546.863178748211
INFO:root:current train perplexity4.045053958892822
INFO:root:current mean train loss 3555.0945532332253
INFO:root:current train perplexity4.051531791687012
INFO:root:current mean train loss 3560.398683115795
INFO:root:current train perplexity4.056158065795898
INFO:root:current mean train loss 3558.523418807098
INFO:root:current train perplexity4.061413764953613
INFO:root:current mean train loss 3557.780514819474
INFO:root:current train perplexity4.064144611358643
INFO:root:current mean train loss 3556.4296132131535
INFO:root:current train perplexity4.061913013458252
INFO:root:current mean train loss 3555.811083917579
INFO:root:current train perplexity4.0615081787109375
INFO:root:current mean train loss 3559.553826397507
INFO:root:current train perplexity4.066741943359375
INFO:root:current mean train loss 3556.159269371811
INFO:root:current train perplexity4.0649871826171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.98s/it]
INFO:root:final mean train loss: 3554.1512136151714
INFO:root:final train perplexity: 4.064194202423096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.19s/it]
INFO:root:eval mean loss: 3999.5752403313386
INFO:root:eval perplexity: 5.039520263671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:26:40<11:33:12, 346.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3511.302972255609
INFO:root:current train perplexity4.056643486022949
INFO:root:current mean train loss 3529.5598530940874
INFO:root:current train perplexity4.0299072265625
INFO:root:current mean train loss 3531.171850483787
INFO:root:current train perplexity4.028420448303223
INFO:root:current mean train loss 3536.4048434907354
INFO:root:current train perplexity4.028400897979736
INFO:root:current mean train loss 3537.6052980184013
INFO:root:current train perplexity4.03793478012085
INFO:root:current mean train loss 3538.30072598997
INFO:root:current train perplexity4.040671348571777
INFO:root:current mean train loss 3545.154990326071
INFO:root:current train perplexity4.047056198120117
INFO:root:current mean train loss 3547.029083458432
INFO:root:current train perplexity4.051188945770264
INFO:root:current mean train loss 3548.078332766873
INFO:root:current train perplexity4.051973819732666
INFO:root:current mean train loss 3547.672691142089
INFO:root:current train perplexity4.050953388214111


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.92s/it]
INFO:root:final mean train loss: 3546.9597713716566
INFO:root:final train perplexity: 4.052679538726807
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it]
INFO:root:eval mean loss: 3998.0350159990026
INFO:root:eval perplexity: 5.03638219833374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:32:39<11:35:01, 350.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3552.1769396193486
INFO:root:current train perplexity4.084963321685791
INFO:root:current mean train loss 3556.707858338648
INFO:root:current train perplexity4.0548858642578125
INFO:root:current mean train loss 3539.8557089369306
INFO:root:current train perplexity4.037510871887207
INFO:root:current mean train loss 3537.60776381259
INFO:root:current train perplexity4.033907413482666
INFO:root:current mean train loss 3544.1897349517617
INFO:root:current train perplexity4.035614967346191
INFO:root:current mean train loss 3538.293479793904
INFO:root:current train perplexity4.035221099853516
INFO:root:current mean train loss 3540.541430701797
INFO:root:current train perplexity4.03765869140625
INFO:root:current mean train loss 3543.5559807589734
INFO:root:current train perplexity4.037735462188721
INFO:root:current mean train loss 3546.1291452022765
INFO:root:current train perplexity4.0410847663879395
INFO:root:current mean train loss 3543.7085110463963
INFO:root:current train perplexity4.0435919761657715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it]
INFO:root:final mean train loss: 3540.4139263399184
INFO:root:final train perplexity: 4.042226314544678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it]
INFO:root:eval mean loss: 4000.8011033078456
INFO:root:eval perplexity: 5.042018413543701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:38:23<11:25:34, 348.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.622518643466
INFO:root:current train perplexity4.031246185302734
INFO:root:current mean train loss 3532.507886529738
INFO:root:current train perplexity4.026333332061768
INFO:root:current mean train loss 3526.323086128983
INFO:root:current train perplexity4.020461559295654
INFO:root:current mean train loss 3531.4246245048416
INFO:root:current train perplexity4.029839992523193
INFO:root:current mean train loss 3528.2393211280905
INFO:root:current train perplexity4.032661437988281
INFO:root:current mean train loss 3532.5098333685246
INFO:root:current train perplexity4.03531551361084
INFO:root:current mean train loss 3533.9140453542464
INFO:root:current train perplexity4.035177707672119
INFO:root:current mean train loss 3535.974589973096
INFO:root:current train perplexity4.034607887268066
INFO:root:current mean train loss 3537.002660418951
INFO:root:current train perplexity4.033786296844482
INFO:root:current mean train loss 3539.534055444208
INFO:root:current train perplexity4.035292625427246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.09s/it]
INFO:root:final mean train loss: 3535.0465927739297
INFO:root:final train perplexity: 4.0336761474609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it]
INFO:root:eval mean loss: 3999.245537940492
INFO:root:eval perplexity: 5.038847923278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [7:44:08<11:17:36, 347.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.066658141121
INFO:root:current train perplexity3.9759280681610107
INFO:root:current mean train loss 3525.673203544383
INFO:root:current train perplexity4.005043029785156
INFO:root:current mean train loss 3516.6881349512832
INFO:root:current train perplexity4.011463165283203
INFO:root:current mean train loss 3518.9226349969867
INFO:root:current train perplexity4.016414165496826
INFO:root:current mean train loss 3523.7574439162054
INFO:root:current train perplexity4.017094612121582
INFO:root:current mean train loss 3525.419200294183
INFO:root:current train perplexity4.019608020782471
INFO:root:current mean train loss 3529.377351188372
INFO:root:current train perplexity4.022844314575195
INFO:root:current mean train loss 3532.830358102781
INFO:root:current train perplexity4.026862621307373
INFO:root:current mean train loss 3532.2732315505505
INFO:root:current train perplexity4.025411128997803
INFO:root:current mean train loss 3532.167103736695
INFO:root:current train perplexity4.025513172149658


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it]
INFO:root:final mean train loss: 3529.8681296686973
INFO:root:final train perplexity: 4.0254435539245605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 4001.3962748642507
INFO:root:eval perplexity: 5.043232440948486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [7:49:50<11:08:23, 345.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.4716384242956
INFO:root:current train perplexity3.9944252967834473
INFO:root:current mean train loss 3511.5265770627743
INFO:root:current train perplexity3.9973554611206055
INFO:root:current mean train loss 3507.74551898351
INFO:root:current train perplexity3.9962456226348877
INFO:root:current mean train loss 3510.8312810604784
INFO:root:current train perplexity4.002802848815918
INFO:root:current mean train loss 3515.168612534833
INFO:root:current train perplexity4.005204200744629
INFO:root:current mean train loss 3519.8615307916484
INFO:root:current train perplexity4.007770538330078
INFO:root:current mean train loss 3524.573401915867
INFO:root:current train perplexity4.01287841796875
INFO:root:current mean train loss 3527.836109760052
INFO:root:current train perplexity4.013803958892822
INFO:root:current mean train loss 3528.8257374112013
INFO:root:current train perplexity4.016867637634277
INFO:root:current mean train loss 3527.6284466320158
INFO:root:current train perplexity4.017601490020752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.02s/it]
INFO:root:final mean train loss: 3524.9059175675916
INFO:root:final train perplexity: 4.017570972442627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it]
INFO:root:eval mean loss: 4001.4853740719195
INFO:root:eval perplexity: 5.043414115905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [7:55:39<11:04:36, 346.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.0536522201346
INFO:root:current train perplexity4.001428604125977
INFO:root:current mean train loss 3502.7728278303944
INFO:root:current train perplexity4.000040054321289
INFO:root:current mean train loss 3517.6891556059586
INFO:root:current train perplexity4.005185127258301
INFO:root:current mean train loss 3519.9990511368323
INFO:root:current train perplexity4.001251220703125
INFO:root:current mean train loss 3519.1013611731796
INFO:root:current train perplexity4.001575469970703
INFO:root:current mean train loss 3517.4814621788646
INFO:root:current train perplexity4.002938747406006
INFO:root:current mean train loss 3516.101237458579
INFO:root:current train perplexity4.003806114196777
INFO:root:current mean train loss 3518.910831632602
INFO:root:current train perplexity4.005319118499756
INFO:root:current mean train loss 3520.910732577414
INFO:root:current train perplexity4.006147384643555
INFO:root:current mean train loss 3521.7037980700175
INFO:root:current train perplexity4.006743907928467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.17s/it]
INFO:root:final mean train loss: 3518.5475200530022
INFO:root:final train perplexity: 4.007504940032959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.91s/it]
INFO:root:eval mean loss: 4000.6399220135195
INFO:root:eval perplexity: 5.041689872741699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:01:16<10:53:06, 343.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3484.5642847521553
INFO:root:current train perplexity3.9725818634033203
INFO:root:current mean train loss 3492.713299266795
INFO:root:current train perplexity3.9773716926574707
INFO:root:current mean train loss 3495.324179619447
INFO:root:current train perplexity3.9904837608337402
INFO:root:current mean train loss 3499.57597946443
INFO:root:current train perplexity3.989588499069214
INFO:root:current mean train loss 3503.4478200798894
INFO:root:current train perplexity3.9900827407836914
INFO:root:current mean train loss 3510.076273773557
INFO:root:current train perplexity3.9946892261505127
INFO:root:current mean train loss 3509.839146865334
INFO:root:current train perplexity3.99320125579834
INFO:root:current mean train loss 3513.247667790065
INFO:root:current train perplexity3.9979424476623535
INFO:root:current mean train loss 3514.3903993006625
INFO:root:current train perplexity3.998215675354004
INFO:root:current mean train loss 3516.2871974338273
INFO:root:current train perplexity3.9994707107543945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.85s/it]
INFO:root:final mean train loss: 3513.694136035058
INFO:root:final train perplexity: 3.999838352203369
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it]
INFO:root:eval mean loss: 4003.567822611924
INFO:root:eval perplexity: 5.047662734985352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:07:11<10:53:40, 347.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.798347553454
INFO:root:current train perplexity3.9579381942749023
INFO:root:current mean train loss 3513.852435146234
INFO:root:current train perplexity3.9763457775115967
INFO:root:current mean train loss 3511.806683659958
INFO:root:current train perplexity3.982043743133545
INFO:root:current mean train loss 3504.022747725475
INFO:root:current train perplexity3.9790585041046143
INFO:root:current mean train loss 3503.850669783775
INFO:root:current train perplexity3.9790403842926025
INFO:root:current mean train loss 3505.875522748162
INFO:root:current train perplexity3.977677822113037
INFO:root:current mean train loss 3504.951164498089
INFO:root:current train perplexity3.9795379638671875
INFO:root:current mean train loss 3506.571711932488
INFO:root:current train perplexity3.9838554859161377
INFO:root:current mean train loss 3508.35936436147
INFO:root:current train perplexity3.9872069358825684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.23s/it]
INFO:root:final mean train loss: 3506.2008328591623
INFO:root:final train perplexity: 3.9880306720733643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.29s/it]
INFO:root:eval mean loss: 4005.02958430297
INFO:root:eval perplexity: 5.050647735595703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:12:55<10:46:16, 346.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3692.8656412760415
INFO:root:current train perplexity4.074889183044434
INFO:root:current mean train loss 3515.4222945426272
INFO:root:current train perplexity3.981898307800293
INFO:root:current mean train loss 3505.1022696659484
INFO:root:current train perplexity3.9750256538391113
INFO:root:current mean train loss 3497.784742903001
INFO:root:current train perplexity3.965677499771118
INFO:root:current mean train loss 3503.5938717674085
INFO:root:current train perplexity3.9769344329833984
INFO:root:current mean train loss 3503.748115797403
INFO:root:current train perplexity3.9798948764801025
INFO:root:current mean train loss 3504.3070345699884
INFO:root:current train perplexity3.978458881378174
INFO:root:current mean train loss 3500.6321623844237
INFO:root:current train perplexity3.977111339569092
INFO:root:current mean train loss 3502.93880279275
INFO:root:current train perplexity3.9775607585906982
INFO:root:current mean train loss 3503.6630864782323
INFO:root:current train perplexity3.981940269470215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.46s/it]
INFO:root:final mean train loss: 3502.9508435649254
INFO:root:final train perplexity: 3.9829213619232178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]
INFO:root:eval mean loss: 4006.766863018063
INFO:root:eval perplexity: 5.054196357727051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:18:39<10:39:33, 345.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3499.898859197443
INFO:root:current train perplexity3.926621913909912
INFO:root:current mean train loss 3486.9792326506195
INFO:root:current train perplexity3.9576542377471924
INFO:root:current mean train loss 3486.0390497722897
INFO:root:current train perplexity3.959184169769287
INFO:root:current mean train loss 3485.205522445237
INFO:root:current train perplexity3.9613749980926514
INFO:root:current mean train loss 3484.4727762412563
INFO:root:current train perplexity3.956334352493286
INFO:root:current mean train loss 3485.73728892108
INFO:root:current train perplexity3.956453323364258
INFO:root:current mean train loss 3487.8107946118043
INFO:root:current train perplexity3.9627633094787598
INFO:root:current mean train loss 3493.5135843140165
INFO:root:current train perplexity3.963845729827881
INFO:root:current mean train loss 3493.8847499711005
INFO:root:current train perplexity3.9661130905151367
INFO:root:current mean train loss 3496.259458774269
INFO:root:current train perplexity3.9693188667297363


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it]
INFO:root:final mean train loss: 3496.2532295103997
INFO:root:final train perplexity: 3.972409963607788
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 4008.717202044548
INFO:root:eval perplexity: 5.0581841468811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:24:24<10:33:13, 345.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3452.3569849917762
INFO:root:current train perplexity3.997732400894165
INFO:root:current mean train loss 3487.3042012703518
INFO:root:current train perplexity3.9419474601745605
INFO:root:current mean train loss 3500.560605959261
INFO:root:current train perplexity3.949097156524658
INFO:root:current mean train loss 3496.5727990607857
INFO:root:current train perplexity3.954566240310669
INFO:root:current mean train loss 3498.093131199657
INFO:root:current train perplexity3.9550483226776123
INFO:root:current mean train loss 3496.4914259129637
INFO:root:current train perplexity3.956401824951172
INFO:root:current mean train loss 3492.983784960622
INFO:root:current train perplexity3.956972599029541
INFO:root:current mean train loss 3490.153947472075
INFO:root:current train perplexity3.960817337036133
INFO:root:current mean train loss 3491.356098626851
INFO:root:current train perplexity3.962057590484619
INFO:root:current mean train loss 3495.102602289343
INFO:root:current train perplexity3.9652791023254395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.91s/it]
INFO:root:final mean train loss: 3491.749746876378
INFO:root:final train perplexity: 3.9653589725494385
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.58s/it]
INFO:root:eval mean loss: 4009.2861103030805
INFO:root:eval perplexity: 5.059347629547119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:30:09<10:27:25, 345.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.785572193287
INFO:root:current train perplexity3.9625766277313232
INFO:root:current mean train loss 3476.2143304779775
INFO:root:current train perplexity3.9408912658691406
INFO:root:current mean train loss 3476.945179136839
INFO:root:current train perplexity3.9463469982147217
INFO:root:current mean train loss 3479.1170732690653
INFO:root:current train perplexity3.946295738220215
INFO:root:current mean train loss 3475.3884117251537
INFO:root:current train perplexity3.946729898452759
INFO:root:current mean train loss 3481.9955660912296
INFO:root:current train perplexity3.9525885581970215
INFO:root:current mean train loss 3483.935094027238
INFO:root:current train perplexity3.9512901306152344
INFO:root:current mean train loss 3487.0519277370618
INFO:root:current train perplexity3.954561948776245
INFO:root:current mean train loss 3487.7634312769233
INFO:root:current train perplexity3.9565324783325195
INFO:root:current mean train loss 3487.838557468649
INFO:root:current train perplexity3.956320285797119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.40s/it]
INFO:root:final mean train loss: 3486.160596293788
INFO:root:final train perplexity: 3.9566245079040527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 4011.073496717088
INFO:root:eval perplexity: 5.0630059242248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:36:00<10:24:25, 346.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3469.6192034040178
INFO:root:current train perplexity3.9355275630950928
INFO:root:current mean train loss 3475.482101779514
INFO:root:current train perplexity3.9360196590423584
INFO:root:current mean train loss 3480.778039810505
INFO:root:current train perplexity3.943922519683838
INFO:root:current mean train loss 3483.732524632696
INFO:root:current train perplexity3.945544958114624
INFO:root:current mean train loss 3487.3320750269395
INFO:root:current train perplexity3.950047254562378
INFO:root:current mean train loss 3488.666372937354
INFO:root:current train perplexity3.9526116847991943
INFO:root:current mean train loss 3484.3909998615895
INFO:root:current train perplexity3.94716477394104
INFO:root:current mean train loss 3481.3564130925806
INFO:root:current train perplexity3.945831775665283
INFO:root:current mean train loss 3483.2434029402134
INFO:root:current train perplexity3.948047637939453
INFO:root:current mean train loss 3482.3351747890206
INFO:root:current train perplexity3.9466495513916016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.56s/it]
INFO:root:final mean train loss: 3481.947351394161
INFO:root:final train perplexity: 3.9500529766082764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it]
INFO:root:eval mean loss: 4010.5944806903813
INFO:root:eval perplexity: 5.062026023864746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:41:49<10:19:36, 347.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.6407101653344
INFO:root:current train perplexity3.9143879413604736
INFO:root:current mean train loss 3472.123589789117
INFO:root:current train perplexity3.910182476043701
INFO:root:current mean train loss 3466.0646229182744
INFO:root:current train perplexity3.925591230392456
INFO:root:current mean train loss 3468.8990275658252
INFO:root:current train perplexity3.9287641048431396
INFO:root:current mean train loss 3468.4969804819766
INFO:root:current train perplexity3.929396867752075
INFO:root:current mean train loss 3469.010913940205
INFO:root:current train perplexity3.9299747943878174
INFO:root:current mean train loss 3470.90109494982
INFO:root:current train perplexity3.934326171875
INFO:root:current mean train loss 3476.474336975837
INFO:root:current train perplexity3.936896800994873
INFO:root:current mean train loss 3476.5721697643276
INFO:root:current train perplexity3.937479257583618
INFO:root:current mean train loss 3477.2115686928355
INFO:root:current train perplexity3.938410997390747


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.01s/it]
INFO:root:final mean train loss: 3474.890216581283
INFO:root:final train perplexity: 3.939070224761963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it]
INFO:root:eval mean loss: 4011.6946683843084
INFO:root:eval perplexity: 5.0642781257629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [8:47:36<10:14:01, 347.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3460.4477874157474
INFO:root:current train perplexity3.9376375675201416
INFO:root:current mean train loss 3472.6468336092717
INFO:root:current train perplexity3.927938461303711
INFO:root:current mean train loss 3474.1351799831923
INFO:root:current train perplexity3.9315109252929688
INFO:root:current mean train loss 3471.8414198829237
INFO:root:current train perplexity3.9190869331359863
INFO:root:current mean train loss 3469.2707514117933
INFO:root:current train perplexity3.9201269149780273
INFO:root:current mean train loss 3471.974106471898
INFO:root:current train perplexity3.9265353679656982
INFO:root:current mean train loss 3471.5858298681114
INFO:root:current train perplexity3.929598808288574
INFO:root:current mean train loss 3472.029856350387
INFO:root:current train perplexity3.9290249347686768
INFO:root:current mean train loss 3472.111351362827
INFO:root:current train perplexity3.9307801723480225
INFO:root:current mean train loss 3473.7128503199756
INFO:root:current train perplexity3.9342610836029053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.86s/it]
INFO:root:final mean train loss: 3470.1998428221673
INFO:root:final train perplexity: 3.9317879676818848
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it]
INFO:root:eval mean loss: 4012.508608987145
INFO:root:eval perplexity: 5.065944671630859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [8:53:19<10:05:39, 346.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.400978217691
INFO:root:current train perplexity3.873063325881958
INFO:root:current mean train loss 3444.845681628341
INFO:root:current train perplexity3.8804965019226074
INFO:root:current mean train loss 3449.3857393596163
INFO:root:current train perplexity3.8909029960632324
INFO:root:current mean train loss 3457.9134395673746
INFO:root:current train perplexity3.901376962661743
INFO:root:current mean train loss 3459.999997340516
INFO:root:current train perplexity3.90651798248291
INFO:root:current mean train loss 3463.9710892078488
INFO:root:current train perplexity3.9100351333618164
INFO:root:current mean train loss 3463.554421872036
INFO:root:current train perplexity3.9129741191864014
INFO:root:current mean train loss 3466.2953651237235
INFO:root:current train perplexity3.9167544841766357
INFO:root:current mean train loss 3469.047167457163
INFO:root:current train perplexity3.921315908432007
INFO:root:current mean train loss 3469.1567212245013
INFO:root:current train perplexity3.9227499961853027


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.97s/it]
INFO:root:final mean train loss: 3464.630105664653
INFO:root:final train perplexity: 3.923157215118408
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it]
INFO:root:eval mean loss: 4009.8130661984706
INFO:root:eval perplexity: 5.060425758361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [8:59:03<9:59:01, 345.59s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3468.513810342817
INFO:root:current train perplexity3.947348117828369
INFO:root:current mean train loss 3463.898570534712
INFO:root:current train perplexity3.9198694229125977
INFO:root:current mean train loss 3469.6938824028557
INFO:root:current train perplexity3.9218170642852783
INFO:root:current mean train loss 3466.5250912700103
INFO:root:current train perplexity3.914952039718628
INFO:root:current mean train loss 3464.0249572361818
INFO:root:current train perplexity3.9143028259277344
INFO:root:current mean train loss 3461.445286665013
INFO:root:current train perplexity3.913921594619751
INFO:root:current mean train loss 3462.8781584549524
INFO:root:current train perplexity3.9145548343658447
INFO:root:current mean train loss 3460.3371878055736
INFO:root:current train perplexity3.9158132076263428
INFO:root:current mean train loss 3464.035617216786
INFO:root:current train perplexity3.917992353439331
INFO:root:current mean train loss 3463.552234984973
INFO:root:current train perplexity3.9180965423583984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.48s/it]
INFO:root:final mean train loss: 3460.9298608841436
INFO:root:final train perplexity: 3.9174346923828125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.30s/it]
INFO:root:eval mean loss: 4015.252695935838
INFO:root:eval perplexity: 5.071569442749023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:04:23<9:39:51, 337.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.28953125
INFO:root:current train perplexity3.9266953468322754
INFO:root:current mean train loss 3453.159662388393
INFO:root:current train perplexity3.9121267795562744
INFO:root:current mean train loss 3461.308973721591
INFO:root:current train perplexity3.9052441120147705
INFO:root:current mean train loss 3462.9574446614583
INFO:root:current train perplexity3.9032764434814453
INFO:root:current mean train loss 3459.760892269737
INFO:root:current train perplexity3.905426263809204
INFO:root:current mean train loss 3455.735489130435
INFO:root:current train perplexity3.907102108001709
INFO:root:current mean train loss 3460.0761606626156
INFO:root:current train perplexity3.9086966514587402
INFO:root:current mean train loss 3458.450725806452
INFO:root:current train perplexity3.9082746505737305
INFO:root:current mean train loss 3459.394888671875
INFO:root:current train perplexity3.908728837966919
INFO:root:current mean train loss 3458.094355969551
INFO:root:current train perplexity3.9101638793945312


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.13s/it]
INFO:root:final mean train loss: 3456.2406534994802
INFO:root:final train perplexity: 3.910193681716919
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.00s/it]
INFO:root:eval mean loss: 4016.1051189882537
INFO:root:eval perplexity: 5.073317527770996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:09:51<9:29:22, 334.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.1187405873493
INFO:root:current train perplexity3.8854596614837646
INFO:root:current mean train loss 3438.7261836150956
INFO:root:current train perplexity3.8917784690856934
INFO:root:current mean train loss 3452.5677520428444
INFO:root:current train perplexity3.892883062362671
INFO:root:current mean train loss 3452.3801046426242
INFO:root:current train perplexity3.8890867233276367
INFO:root:current mean train loss 3452.4841429905864
INFO:root:current train perplexity3.8923542499542236
INFO:root:current mean train loss 3451.7033590902392
INFO:root:current train perplexity3.8936355113983154
INFO:root:current mean train loss 3453.44921875
INFO:root:current train perplexity3.8976497650146484
INFO:root:current mean train loss 3451.213725005987
INFO:root:current train perplexity3.8972809314727783
INFO:root:current mean train loss 3452.2755999278916
INFO:root:current train perplexity3.8977608680725098
INFO:root:current mean train loss 3452.8361905816855
INFO:root:current train perplexity3.9003446102142334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.98s/it]
INFO:root:final mean train loss: 3450.1093475587904
INFO:root:final train perplexity: 3.9007468223571777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it]
INFO:root:eval mean loss: 4017.5252174756206
INFO:root:eval perplexity: 5.076232433319092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:15:34<9:27:32, 337.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3412.5345713856454
INFO:root:current train perplexity3.841191053390503
INFO:root:current mean train loss 3430.6568034706315
INFO:root:current train perplexity3.8579554557800293
INFO:root:current mean train loss 3437.527992274753
INFO:root:current train perplexity3.8738677501678467
INFO:root:current mean train loss 3443.1726124170796
INFO:root:current train perplexity3.882120132446289
INFO:root:current mean train loss 3444.213298851992
INFO:root:current train perplexity3.884692668914795
INFO:root:current mean train loss 3444.304081072864
INFO:root:current train perplexity3.8841664791107178
INFO:root:current mean train loss 3445.9251502295133
INFO:root:current train perplexity3.887016773223877
INFO:root:current mean train loss 3446.5805583814004
INFO:root:current train perplexity3.8890304565429688
INFO:root:current mean train loss 3444.778229890046
INFO:root:current train perplexity3.8895349502563477
INFO:root:current mean train loss 3448.8352693775228
INFO:root:current train perplexity3.8946659564971924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.46s/it]
INFO:root:final mean train loss: 3446.0907830269107
INFO:root:final train perplexity: 3.8945672512054443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
INFO:root:eval mean loss: 4016.7318106576904
INFO:root:eval perplexity: 5.07460355758667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:21:17<9:25:05, 339.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3422.5426432291665
INFO:root:current train perplexity3.855195999145508
INFO:root:current mean train loss 3426.1029022063444
INFO:root:current train perplexity3.8723134994506836
INFO:root:current mean train loss 3429.948324656407
INFO:root:current train perplexity3.874880075454712
INFO:root:current mean train loss 3428.18223537359
INFO:root:current train perplexity3.872061014175415
INFO:root:current mean train loss 3432.7521390437123
INFO:root:current train perplexity3.8731491565704346
INFO:root:current mean train loss 3434.9264354164493
INFO:root:current train perplexity3.8766629695892334
INFO:root:current mean train loss 3440.598853202678
INFO:root:current train perplexity3.8818325996398926
INFO:root:current mean train loss 3444.3488360083893
INFO:root:current train perplexity3.884864330291748
INFO:root:current mean train loss 3444.3195811644014
INFO:root:current train perplexity3.8867948055267334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.58s/it]
INFO:root:final mean train loss: 3441.0452711659095
INFO:root:final train perplexity: 3.886822462081909
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 4018.516255263741
INFO:root:eval perplexity: 5.0782670974731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:27:06<9:24:22, 342.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.198486328125
INFO:root:current train perplexity3.83927845954895
INFO:root:current mean train loss 3459.63714770736
INFO:root:current train perplexity3.880465507507324
INFO:root:current mean train loss 3443.780030476298
INFO:root:current train perplexity3.868969678878784
INFO:root:current mean train loss 3435.1896694320035
INFO:root:current train perplexity3.8742048740386963
INFO:root:current mean train loss 3440.8150319842216
INFO:root:current train perplexity3.877138614654541
INFO:root:current mean train loss 3439.9193204319217
INFO:root:current train perplexity3.8789896965026855
INFO:root:current mean train loss 3438.2465474413098
INFO:root:current train perplexity3.8756840229034424
INFO:root:current mean train loss 3436.9512288526566
INFO:root:current train perplexity3.8758866786956787
INFO:root:current mean train loss 3438.9983463783688
INFO:root:current train perplexity3.8792810440063477
INFO:root:current mean train loss 3438.5521976424684
INFO:root:current train perplexity3.8806848526000977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.75s/it]
INFO:root:final mean train loss: 3437.128980390487
INFO:root:final train perplexity: 3.8808212280273438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it]
INFO:root:eval mean loss: 4024.305530737478
INFO:root:eval perplexity: 5.090169429779053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:32:50<9:19:35, 342.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3410.9698404947917
INFO:root:current train perplexity3.81683349609375
INFO:root:current mean train loss 3409.8582710597825
INFO:root:current train perplexity3.821512460708618
INFO:root:current mean train loss 3412.6466933139536
INFO:root:current train perplexity3.8379030227661133
INFO:root:current mean train loss 3429.0289209759426
INFO:root:current train perplexity3.854842185974121
INFO:root:current mean train loss 3435.0462290568526
INFO:root:current train perplexity3.8608198165893555
INFO:root:current mean train loss 3431.014494842233
INFO:root:current train perplexity3.8588924407958984
INFO:root:current mean train loss 3432.5088152629573
INFO:root:current train perplexity3.861926317214966
INFO:root:current mean train loss 3430.072939999454
INFO:root:current train perplexity3.8633739948272705
INFO:root:current mean train loss 3430.4112631206863
INFO:root:current train perplexity3.866340160369873
INFO:root:current mean train loss 3431.5812158469944
INFO:root:current train perplexity3.868931770324707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.95s/it]
INFO:root:final mean train loss: 3431.09458732605
INFO:root:final train perplexity: 3.8715929985046387
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.11s/it]
INFO:root:eval mean loss: 4020.259658272385
INFO:root:eval perplexity: 5.081848621368408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:37:58<8:57:06, 332.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.19921875
INFO:root:current train perplexity3.8072404861450195
INFO:root:current mean train loss 3412.028151597434
INFO:root:current train perplexity3.8265068531036377
INFO:root:current mean train loss 3417.8098527711604
INFO:root:current train perplexity3.840579032897949
INFO:root:current mean train loss 3415.278868306163
INFO:root:current train perplexity3.842148780822754
INFO:root:current mean train loss 3415.2748700225325
INFO:root:current train perplexity3.8458738327026367
INFO:root:current mean train loss 3420.385701108389
INFO:root:current train perplexity3.855194091796875
INFO:root:current mean train loss 3423.7316694672954
INFO:root:current train perplexity3.859426975250244
INFO:root:current mean train loss 3426.3158825126425
INFO:root:current train perplexity3.8640079498291016
INFO:root:current mean train loss 3427.2040618117785
INFO:root:current train perplexity3.86421799659729
INFO:root:current mean train loss 3427.579058976757
INFO:root:current train perplexity3.8624143600463867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.42s/it]
INFO:root:final mean train loss: 3426.9754981379356
INFO:root:final train perplexity: 3.865307092666626
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.16s/it]
INFO:root:eval mean loss: 4022.003527052859
INFO:root:eval perplexity: 5.085433006286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:44:52<9:31:00, 356.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.867628528226
INFO:root:current train perplexity3.8117282390594482
INFO:root:current mean train loss 3396.5128071326335
INFO:root:current train perplexity3.8274214267730713
INFO:root:current mean train loss 3394.2846521154624
INFO:root:current train perplexity3.8361058235168457
INFO:root:current mean train loss 3402.6107764114427
INFO:root:current train perplexity3.843263864517212
INFO:root:current mean train loss 3404.087027919265
INFO:root:current train perplexity3.843108892440796
INFO:root:current mean train loss 3410.312018155603
INFO:root:current train perplexity3.847693920135498
INFO:root:current mean train loss 3416.966825119478
INFO:root:current train perplexity3.8526742458343506
INFO:root:current mean train loss 3419.2275771364143
INFO:root:current train perplexity3.85467267036438
INFO:root:current mean train loss 3425.1256116736236
INFO:root:current train perplexity3.8603131771087646
INFO:root:current mean train loss 3424.4992652180117
INFO:root:current train perplexity3.8578357696533203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it]
INFO:root:final mean train loss: 3423.0349192465505
INFO:root:final train perplexity: 3.859301805496216
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 4020.8513218223625
INFO:root:eval perplexity: 5.083064556121826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [9:50:42<9:21:27, 354.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3399.0977376302085
INFO:root:current train perplexity3.8404507637023926
INFO:root:current mean train loss 3420.335932230778
INFO:root:current train perplexity3.845625400543213
INFO:root:current mean train loss 3415.738988134153
INFO:root:current train perplexity3.8477447032928467
INFO:root:current mean train loss 3426.7200952940634
INFO:root:current train perplexity3.851973533630371
INFO:root:current mean train loss 3421.1280264539437
INFO:root:current train perplexity3.846055746078491
INFO:root:current mean train loss 3421.127888921904
INFO:root:current train perplexity3.8476126194000244
INFO:root:current mean train loss 3423.413033976428
INFO:root:current train perplexity3.8484039306640625
INFO:root:current mean train loss 3424.511743527465
INFO:root:current train perplexity3.850385904312134
INFO:root:current mean train loss 3422.117499150309
INFO:root:current train perplexity3.8498306274414062
INFO:root:current mean train loss 3421.5649473862654
INFO:root:current train perplexity3.851381540298462


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.73s/it]
INFO:root:final mean train loss: 3418.1650911146594
INFO:root:final train perplexity: 3.8518941402435303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.28s/it]
INFO:root:eval mean loss: 4024.306301252216
INFO:root:eval perplexity: 5.090170383453369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [9:56:31<9:12:54, 352.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.9288667719416
INFO:root:current train perplexity3.802121162414551
INFO:root:current mean train loss 3392.4366313908376
INFO:root:current train perplexity3.8275701999664307
INFO:root:current mean train loss 3393.526035077176
INFO:root:current train perplexity3.822943687438965
INFO:root:current mean train loss 3398.0146596947047
INFO:root:current train perplexity3.829827308654785
INFO:root:current mean train loss 3403.63003847263
INFO:root:current train perplexity3.828333616256714
INFO:root:current mean train loss 3410.5862994708355
INFO:root:current train perplexity3.8342208862304688
INFO:root:current mean train loss 3413.2607301125386
INFO:root:current train perplexity3.8372089862823486
INFO:root:current mean train loss 3412.0335691725236
INFO:root:current train perplexity3.8377761840820312
INFO:root:current mean train loss 3415.4546411507526
INFO:root:current train perplexity3.843606948852539
INFO:root:current mean train loss 3415.3537564141698
INFO:root:current train perplexity3.8445146083831787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.59s/it]
INFO:root:final mean train loss: 3414.0454132326186
INFO:root:final train perplexity: 3.8456385135650635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.39s/it]
INFO:root:eval mean loss: 4028.7190911042776
INFO:root:eval perplexity: 5.099262237548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [10:02:15<9:03:07, 350.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.150084339489
INFO:root:current train perplexity3.8124725818634033
INFO:root:current mean train loss 3401.1077746975807
INFO:root:current train perplexity3.8189356327056885
INFO:root:current mean train loss 3394.9186820235905
INFO:root:current train perplexity3.821563959121704
INFO:root:current mean train loss 3405.3624539227553
INFO:root:current train perplexity3.828796863555908
INFO:root:current mean train loss 3407.9289379077954
INFO:root:current train perplexity3.8262240886688232
INFO:root:current mean train loss 3407.147162250141
INFO:root:current train perplexity3.830853223800659
INFO:root:current mean train loss 3407.6529636062737
INFO:root:current train perplexity3.833946704864502
INFO:root:current mean train loss 3410.674777201469
INFO:root:current train perplexity3.83358097076416
INFO:root:current mean train loss 3409.5767001324925
INFO:root:current train perplexity3.83296275138855
INFO:root:current mean train loss 3412.0094013313974
INFO:root:current train perplexity3.837297201156616


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.10s/it]
INFO:root:final mean train loss: 3408.150067298643
INFO:root:final train perplexity: 3.8367044925689697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.64s/it]
INFO:root:eval mean loss: 4029.6668882978724
INFO:root:eval perplexity: 5.101215839385986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [10:07:56<8:52:52, 347.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.2120380704364
INFO:root:current train perplexity3.81888484954834
INFO:root:current mean train loss 3378.3676847680213
INFO:root:current train perplexity3.8249411582946777
INFO:root:current mean train loss 3385.286822532973
INFO:root:current train perplexity3.8190176486968994
INFO:root:current mean train loss 3393.9171946291754
INFO:root:current train perplexity3.826364040374756
INFO:root:current mean train loss 3398.524393497739
INFO:root:current train perplexity3.821587562561035
INFO:root:current mean train loss 3402.705190004718
INFO:root:current train perplexity3.8258814811706543
INFO:root:current mean train loss 3404.73660798454
INFO:root:current train perplexity3.8258495330810547
INFO:root:current mean train loss 3405.075747908646
INFO:root:current train perplexity3.825951337814331
INFO:root:current mean train loss 3405.309928177958
INFO:root:current train perplexity3.8286385536193848
INFO:root:current mean train loss 3407.7353685484004
INFO:root:current train perplexity3.8325953483581543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.47s/it]
INFO:root:final mean train loss: 3405.4213798892115
INFO:root:final train perplexity: 3.832576274871826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.14s/it]
INFO:root:eval mean loss: 4024.876677817487
INFO:root:eval perplexity: 5.091343879699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:13:04<8:28:57, 335.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.5318620708626
INFO:root:current train perplexity3.780897855758667
INFO:root:current mean train loss 3377.9872846993785
INFO:root:current train perplexity3.8030827045440674
INFO:root:current mean train loss 3382.6506807109085
INFO:root:current train perplexity3.8085415363311768
INFO:root:current mean train loss 3388.746016098804
INFO:root:current train perplexity3.806546688079834
INFO:root:current mean train loss 3391.6105506070858
INFO:root:current train perplexity3.813424825668335
INFO:root:current mean train loss 3395.6964301595335
INFO:root:current train perplexity3.8200912475585938
INFO:root:current mean train loss 3397.0062133970987
INFO:root:current train perplexity3.8212332725524902
INFO:root:current mean train loss 3399.139477444066
INFO:root:current train perplexity3.8224501609802246
INFO:root:current mean train loss 3400.4181725275366
INFO:root:current train perplexity3.8233652114868164
INFO:root:current mean train loss 3403.3116227532023
INFO:root:current train perplexity3.827064275741577


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.73s/it]
INFO:root:final mean train loss: 3401.5347815482846
INFO:root:final train perplexity: 3.8267037868499756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it]
INFO:root:eval mean loss: 4027.133124168883
INFO:root:eval perplexity: 5.095992088317871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:18:17<8:13:13, 328.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3386.407742657239
INFO:root:current train perplexity3.7915172576904297
INFO:root:current mean train loss 3391.924073629539
INFO:root:current train perplexity3.7962231636047363
INFO:root:current mean train loss 3400.053039769545
INFO:root:current train perplexity3.8113315105438232
INFO:root:current mean train loss 3401.898642990394
INFO:root:current train perplexity3.8159873485565186
INFO:root:current mean train loss 3403.0737753213075
INFO:root:current train perplexity3.812833786010742
INFO:root:current mean train loss 3399.833236351738
INFO:root:current train perplexity3.810114860534668
INFO:root:current mean train loss 3401.408718373182
INFO:root:current train perplexity3.8129143714904785
INFO:root:current mean train loss 3398.182598383344
INFO:root:current train perplexity3.814216375350952
INFO:root:current mean train loss 3398.0111946392385
INFO:root:current train perplexity3.8178911209106445
INFO:root:current mean train loss 3399.696145421029
INFO:root:current train perplexity3.8204879760742188


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.55s/it]
INFO:root:final mean train loss: 3397.196862251528
INFO:root:final train perplexity: 3.8201611042022705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.23s/it]
INFO:root:eval mean loss: 4027.550299894725
INFO:root:eval perplexity: 5.096852779388428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:23:26<7:58:48, 322.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.3979716684626
INFO:root:current train perplexity3.805187225341797
INFO:root:current mean train loss 3395.8481471423797
INFO:root:current train perplexity3.801758289337158
INFO:root:current mean train loss 3393.8606688602463
INFO:root:current train perplexity3.806367874145508
INFO:root:current mean train loss 3390.8828522438225
INFO:root:current train perplexity3.8021442890167236
INFO:root:current mean train loss 3390.3607897122047
INFO:root:current train perplexity3.8060715198516846
INFO:root:current mean train loss 3390.657674084327
INFO:root:current train perplexity3.809267044067383
INFO:root:current mean train loss 3394.742840318527
INFO:root:current train perplexity3.813110113143921
INFO:root:current mean train loss 3392.743551213072
INFO:root:current train perplexity3.813405752182007
INFO:root:current mean train loss 3395.0005625968856
INFO:root:current train perplexity3.814622402191162
INFO:root:current mean train loss 3396.151323900155
INFO:root:current train perplexity3.8143162727355957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.84s/it]
INFO:root:final mean train loss: 3393.161910210886
INFO:root:final train perplexity: 3.814084053039551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.86s/it]
INFO:root:eval mean loss: 4029.722512536015
INFO:root:eval perplexity: 5.101330757141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:28:42<7:50:45, 320.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3371.4308156866778
INFO:root:current train perplexity3.781972646713257
INFO:root:current mean train loss 3363.3270057091345
INFO:root:current train perplexity3.792039394378662
INFO:root:current mean train loss 3371.350802767479
INFO:root:current train perplexity3.792694091796875
INFO:root:current mean train loss 3379.722673556171
INFO:root:current train perplexity3.7990670204162598
INFO:root:current mean train loss 3380.799616773201
INFO:root:current train perplexity3.7997002601623535
INFO:root:current mean train loss 3378.5774561777835
INFO:root:current train perplexity3.7967989444732666
INFO:root:current mean train loss 3382.475717316772
INFO:root:current train perplexity3.800273895263672
INFO:root:current mean train loss 3386.0951552672955
INFO:root:current train perplexity3.803317070007324
INFO:root:current mean train loss 3387.8761165000874
INFO:root:current train perplexity3.805805206298828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.40s/it]
INFO:root:final mean train loss: 3388.020971851964
INFO:root:final train perplexity: 3.806356430053711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.38s/it]
INFO:root:eval mean loss: 4032.611522052305
INFO:root:eval perplexity: 5.107293605804443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:33:55<7:41:50, 318.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.4588216145835
INFO:root:current train perplexity3.780236005783081
INFO:root:current mean train loss 3358.2368116656553
INFO:root:current train perplexity3.7666869163513184
INFO:root:current mean train loss 3381.7284783424416
INFO:root:current train perplexity3.7954390048980713
INFO:root:current mean train loss 3378.9150978818584
INFO:root:current train perplexity3.79349946975708
INFO:root:current mean train loss 3378.814255025783
INFO:root:current train perplexity3.795073986053467
INFO:root:current mean train loss 3383.5507045616923
INFO:root:current train perplexity3.799164056777954
INFO:root:current mean train loss 3384.68229126179
INFO:root:current train perplexity3.7995598316192627
INFO:root:current mean train loss 3385.5357125989067
INFO:root:current train perplexity3.800571918487549
INFO:root:current mean train loss 3388.9138937602156
INFO:root:current train perplexity3.803757429122925
INFO:root:current mean train loss 3387.5043585725534
INFO:root:current train perplexity3.800835609436035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it]
INFO:root:final mean train loss: 3384.8645067522602
INFO:root:final train perplexity: 3.801619052886963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.36s/it]
INFO:root:eval mean loss: 4032.209479582225
INFO:root:eval perplexity: 5.106464385986328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:39:04<7:32:14, 315.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.9016335227275
INFO:root:current train perplexity3.771754503250122
INFO:root:current mean train loss 3374.319399721988
INFO:root:current train perplexity3.8041305541992188
INFO:root:current mean train loss 3370.156881757257
INFO:root:current train perplexity3.797051429748535
INFO:root:current mean train loss 3378.793929612138
INFO:root:current train perplexity3.7960422039031982
INFO:root:current mean train loss 3378.445126572955
INFO:root:current train perplexity3.7929720878601074
INFO:root:current mean train loss 3376.516375099376
INFO:root:current train perplexity3.7914021015167236
INFO:root:current mean train loss 3382.3261642830657
INFO:root:current train perplexity3.7910332679748535
INFO:root:current mean train loss 3381.1562345480615
INFO:root:current train perplexity3.791508197784424
INFO:root:current mean train loss 3379.2654823086855
INFO:root:current train perplexity3.7902886867523193
INFO:root:current mean train loss 3381.116128931977
INFO:root:current train perplexity3.792084217071533


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.18s/it]
INFO:root:final mean train loss: 3380.7742167442075
INFO:root:final train perplexity: 3.7954888343811035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it]
INFO:root:eval mean loss: 4033.3660135472073
INFO:root:eval perplexity: 5.108852863311768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [10:44:11<7:23:25, 313.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3326.6815506784537
INFO:root:current train perplexity3.740746259689331
INFO:root:current mean train loss 3346.073712004333
INFO:root:current train perplexity3.771141290664673
INFO:root:current mean train loss 3363.718663045805
INFO:root:current train perplexity3.7771849632263184
INFO:root:current mean train loss 3370.928489756808
INFO:root:current train perplexity3.781782865524292
INFO:root:current mean train loss 3370.9377371485307
INFO:root:current train perplexity3.778597831726074
INFO:root:current mean train loss 3372.821093844081
INFO:root:current train perplexity3.777608633041382
INFO:root:current mean train loss 3374.7256281395144
INFO:root:current train perplexity3.781658411026001
INFO:root:current mean train loss 3379.219058995784
INFO:root:current train perplexity3.7852165699005127
INFO:root:current mean train loss 3379.647753369677
INFO:root:current train perplexity3.7861709594726562
INFO:root:current mean train loss 3377.6196129667096
INFO:root:current train perplexity3.787811517715454


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.49s/it]
INFO:root:final mean train loss: 3377.433416551159
INFO:root:final train perplexity: 3.7904891967773438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.31s/it]
INFO:root:eval mean loss: 4035.210137549867
INFO:root:eval perplexity: 5.112663745880127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [10:49:20<7:16:26, 311.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.9107530381943
INFO:root:current train perplexity3.794069766998291
INFO:root:current mean train loss 3381.354080800935
INFO:root:current train perplexity3.7805323600769043
INFO:root:current mean train loss 3378.2875675419878
INFO:root:current train perplexity3.775115966796875
INFO:root:current mean train loss 3372.8847641317852
INFO:root:current train perplexity3.775155782699585
INFO:root:current mean train loss 3377.1273910915543
INFO:root:current train perplexity3.781250476837158
INFO:root:current mean train loss 3375.6695614548744
INFO:root:current train perplexity3.778700351715088
INFO:root:current mean train loss 3375.9752335495164
INFO:root:current train perplexity3.778862237930298
INFO:root:current mean train loss 3376.6843738582143
INFO:root:current train perplexity3.781712532043457
INFO:root:current mean train loss 3376.0608580288317
INFO:root:current train perplexity3.7818005084991455
INFO:root:current mean train loss 3376.4036950828445
INFO:root:current train perplexity3.784862756729126


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it]
INFO:root:final mean train loss: 3373.175109555644
INFO:root:final train perplexity: 3.7841265201568604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.02s/it]
INFO:root:eval mean loss: 4036.988042303856
INFO:root:eval perplexity: 5.116340637207031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [10:54:28<7:09:44, 310.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.349462890625
INFO:root:current train perplexity3.7474284172058105
INFO:root:current mean train loss 3361.3790473090276
INFO:root:current train perplexity3.7495486736297607
INFO:root:current mean train loss 3359.2308011968084
INFO:root:current train perplexity3.7579753398895264
INFO:root:current mean train loss 3367.3339217000935
INFO:root:current train perplexity3.7662057876586914
INFO:root:current mean train loss 3370.759134788075
INFO:root:current train perplexity3.769104480743408
INFO:root:current mean train loss 3370.5085015698014
INFO:root:current train perplexity3.770148277282715
INFO:root:current mean train loss 3369.7379402220718
INFO:root:current train perplexity3.773033857345581
INFO:root:current mean train loss 3371.869726230336
INFO:root:current train perplexity3.7742090225219727
INFO:root:current mean train loss 3371.645527402227
INFO:root:current train perplexity3.775700330734253
INFO:root:current mean train loss 3371.4645442534256
INFO:root:current train perplexity3.777534008026123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it]
INFO:root:final mean train loss: 3368.5304461448422
INFO:root:final train perplexity: 3.7771990299224854
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.07s/it]
INFO:root:eval mean loss: 4036.9152849346187
INFO:root:eval perplexity: 5.116189479827881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [10:59:35<7:03:17, 309.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3361.3024618459303
INFO:root:current train perplexity3.7567014694213867
INFO:root:current mean train loss 3352.165179059222
INFO:root:current train perplexity3.746953010559082
INFO:root:current mean train loss 3354.163935908565
INFO:root:current train perplexity3.755861759185791
INFO:root:current mean train loss 3358.2645516353864
INFO:root:current train perplexity3.7582225799560547
INFO:root:current mean train loss 3364.9063029063204
INFO:root:current train perplexity3.760810375213623
INFO:root:current mean train loss 3364.933630168767
INFO:root:current train perplexity3.761343002319336
INFO:root:current mean train loss 3366.848151365669
INFO:root:current train perplexity3.7656960487365723
INFO:root:current mean train loss 3367.8265096631058
INFO:root:current train perplexity3.768293857574463
INFO:root:current mean train loss 3366.600209445433
INFO:root:current train perplexity3.772292375564575
INFO:root:current mean train loss 3367.5644844516337
INFO:root:current train perplexity3.772238254547119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.15s/it]
INFO:root:final mean train loss: 3365.2320323451872
INFO:root:final train perplexity: 3.7722864151000977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.42s/it]
INFO:root:eval mean loss: 4039.05746654754
INFO:root:eval perplexity: 5.12062406539917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [11:04:48<6:59:16, 310.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.3930807674633
INFO:root:current train perplexity3.7679953575134277
INFO:root:current mean train loss 3352.1361690293875
INFO:root:current train perplexity3.7501637935638428
INFO:root:current mean train loss 3350.129300182084
INFO:root:current train perplexity3.7547364234924316
INFO:root:current mean train loss 3345.8221028645835
INFO:root:current train perplexity3.754652738571167
INFO:root:current mean train loss 3347.742467909853
INFO:root:current train perplexity3.7546961307525635
INFO:root:current mean train loss 3352.6829167139294
INFO:root:current train perplexity3.7566606998443604
INFO:root:current mean train loss 3357.228516375048
INFO:root:current train perplexity3.760101079940796
INFO:root:current mean train loss 3361.5771282820824
INFO:root:current train perplexity3.7640790939331055
INFO:root:current mean train loss 3361.3162189129516
INFO:root:current train perplexity3.764967679977417
INFO:root:current mean train loss 3362.991842981894
INFO:root:current train perplexity3.765669107437134


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it]
INFO:root:final mean train loss: 3361.0885767167615
INFO:root:final train perplexity: 3.766125202178955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it]
INFO:root:eval mean loss: 4044.04559715758
INFO:root:eval perplexity: 5.130961894989014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:09:55<6:52:33, 309.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.7314080707097
INFO:root:current train perplexity3.7405898571014404
INFO:root:current mean train loss 3343.979045364092
INFO:root:current train perplexity3.740387439727783
INFO:root:current mean train loss 3343.8185799499274
INFO:root:current train perplexity3.735772132873535
INFO:root:current mean train loss 3348.8061530238074
INFO:root:current train perplexity3.7445547580718994
INFO:root:current mean train loss 3351.0607644207857
INFO:root:current train perplexity3.749255418777466
INFO:root:current mean train loss 3349.288349731664
INFO:root:current train perplexity3.7523000240325928
INFO:root:current mean train loss 3355.2000934328767
INFO:root:current train perplexity3.756819248199463
INFO:root:current mean train loss 3357.961281355505
INFO:root:current train perplexity3.759866714477539
INFO:root:current mean train loss 3360.2139223251966
INFO:root:current train perplexity3.7611348628997803
INFO:root:current mean train loss 3359.9546005360403
INFO:root:current train perplexity3.760918378829956


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.44s/it]
INFO:root:final mean train loss: 3357.793518743207
INFO:root:final train perplexity: 3.761232614517212
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4041.9694754959
INFO:root:eval perplexity: 5.126657009124756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:15:01<6:46:12, 308.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.1019268889927
INFO:root:current train perplexity3.7523415088653564
INFO:root:current mean train loss 3350.275700552021
INFO:root:current train perplexity3.748777389526367
INFO:root:current mean train loss 3345.6732639498478
INFO:root:current train perplexity3.7411837577819824
INFO:root:current mean train loss 3344.3828045172004
INFO:root:current train perplexity3.742771863937378
INFO:root:current mean train loss 3348.932786569861
INFO:root:current train perplexity3.7428579330444336
INFO:root:current mean train loss 3349.208739803792
INFO:root:current train perplexity3.7446975708007812
INFO:root:current mean train loss 3352.1198470588924
INFO:root:current train perplexity3.7466349601745605
INFO:root:current mean train loss 3352.2983726292578
INFO:root:current train perplexity3.748194694519043
INFO:root:current mean train loss 3353.99960379947
INFO:root:current train perplexity3.749640703201294
INFO:root:current mean train loss 3356.7527991593684
INFO:root:current train perplexity3.754756450653076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.60s/it]
INFO:root:final mean train loss: 3354.7430012610653
INFO:root:final train perplexity: 3.7567086219787598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.20s/it]
INFO:root:eval mean loss: 4040.99883643617
INFO:root:eval perplexity: 5.124646186828613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:20:15<6:43:07, 310.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.3943033854166
INFO:root:current train perplexity3.736396074295044
INFO:root:current mean train loss 3338.004605189732
INFO:root:current train perplexity3.7489869594573975
INFO:root:current mean train loss 3346.0620170454545
INFO:root:current train perplexity3.7502152919769287
INFO:root:current mean train loss 3346.8511764322916
INFO:root:current train perplexity3.746652364730835
INFO:root:current mean train loss 3350.4438486842105
INFO:root:current train perplexity3.749084711074829
INFO:root:current mean train loss 3351.871206266984
INFO:root:current train perplexity3.7474958896636963
INFO:root:current mean train loss 3353.4822858796297
INFO:root:current train perplexity3.7492501735687256
INFO:root:current mean train loss 3354.375632875504
INFO:root:current train perplexity3.7505416870117188
INFO:root:current mean train loss 3353.6560131138394
INFO:root:current train perplexity3.750786542892456
INFO:root:current mean train loss 3353.1534214743588
INFO:root:current train perplexity3.750694990158081


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.40s/it]
INFO:root:final mean train loss: 3350.9785876735564
INFO:root:final train perplexity: 3.7511332035064697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it]
INFO:root:eval mean loss: 4043.7305501302085
INFO:root:eval perplexity: 5.130309581756592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:25:22<6:36:53, 309.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3325.4204983998493
INFO:root:current train perplexity3.728101968765259
INFO:root:current mean train loss 3322.8268175802596
INFO:root:current train perplexity3.730473279953003
INFO:root:current mean train loss 3330.382118036385
INFO:root:current train perplexity3.731255292892456
INFO:root:current mean train loss 3339.6720930054666
INFO:root:current train perplexity3.739738702774048
INFO:root:current mean train loss 3342.316376427439
INFO:root:current train perplexity3.7447712421417236
INFO:root:current mean train loss 3351.1554313123124
INFO:root:current train perplexity3.7464516162872314
INFO:root:current mean train loss 3352.422315739957
INFO:root:current train perplexity3.746445655822754
INFO:root:current mean train loss 3349.9939348359676
INFO:root:current train perplexity3.742534875869751
INFO:root:current mean train loss 3350.307568525269
INFO:root:current train perplexity3.74493145942688
INFO:root:current mean train loss 3350.193451765959
INFO:root:current train perplexity3.745940685272217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.61s/it]
INFO:root:final mean train loss: 3347.3772885722497
INFO:root:final train perplexity: 3.745807647705078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.12s/it]
INFO:root:eval mean loss: 4044.675157912234
INFO:root:eval perplexity: 5.132268905639648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:30:32<6:31:54, 309.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.682807670845
INFO:root:current train perplexity3.685875177383423
INFO:root:current mean train loss 3340.0241750347677
INFO:root:current train perplexity3.7255282402038574
INFO:root:current mean train loss 3342.515536908022
INFO:root:current train perplexity3.7284011840820312
INFO:root:current mean train loss 3342.540989400176
INFO:root:current train perplexity3.725983142852783
INFO:root:current mean train loss 3342.0319893831147
INFO:root:current train perplexity3.727989912033081
INFO:root:current mean train loss 3344.686444948974
INFO:root:current train perplexity3.7340285778045654
INFO:root:current mean train loss 3346.467413056259
INFO:root:current train perplexity3.735990524291992
INFO:root:current mean train loss 3348.9451924359
INFO:root:current train perplexity3.7368736267089844
INFO:root:current mean train loss 3347.547683595942
INFO:root:current train perplexity3.7401506900787354
INFO:root:current mean train loss 3346.9885423893165
INFO:root:current train perplexity3.7412972450256348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.33s/it]
INFO:root:final mean train loss: 3344.284698793965
INFO:root:final train perplexity: 3.741239547729492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.50s/it]
INFO:root:eval mean loss: 4043.7525072030144
INFO:root:eval perplexity: 5.130354881286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:35:45<6:28:03, 310.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.4687228732637
INFO:root:current train perplexity3.7287967205047607
INFO:root:current mean train loss 3332.906577565562
INFO:root:current train perplexity3.7284300327301025
INFO:root:current mean train loss 3336.7887922306127
INFO:root:current train perplexity3.7304697036743164
INFO:root:current mean train loss 3336.4914942385262
INFO:root:current train perplexity3.729321241378784
INFO:root:current mean train loss 3337.1509909467372
INFO:root:current train perplexity3.7283682823181152
INFO:root:current mean train loss 3339.6533504734452
INFO:root:current train perplexity3.728980302810669
INFO:root:current mean train loss 3338.3655410351844
INFO:root:current train perplexity3.729384422302246
INFO:root:current mean train loss 3341.380843791556
INFO:root:current train perplexity3.7316598892211914
INFO:root:current mean train loss 3343.1177966295018
INFO:root:current train perplexity3.735600709915161


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.55s/it]
INFO:root:final mean train loss: 3340.4617075151014
INFO:root:final train perplexity: 3.7356011867523193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 4047.93022599457
INFO:root:eval perplexity: 5.139029026031494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [11:40:52<6:21:52, 309.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.671316964286
INFO:root:current train perplexity3.790729522705078
INFO:root:current mean train loss 3333.685727128359
INFO:root:current train perplexity3.725511074066162
INFO:root:current mean train loss 3334.8388730846164
INFO:root:current train perplexity3.7213661670684814
INFO:root:current mean train loss 3332.973564421315
INFO:root:current train perplexity3.7204842567443848
INFO:root:current mean train loss 3326.9177126122927
INFO:root:current train perplexity3.7216954231262207
INFO:root:current mean train loss 3332.3225699580867
INFO:root:current train perplexity3.7261910438537598
INFO:root:current mean train loss 3334.4146967829747
INFO:root:current train perplexity3.7255873680114746
INFO:root:current mean train loss 3338.290095349518
INFO:root:current train perplexity3.7296323776245117
INFO:root:current mean train loss 3339.4501768582522
INFO:root:current train perplexity3.7305970191955566
INFO:root:current mean train loss 3339.5093500206726
INFO:root:current train perplexity3.7291629314422607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.98s/it]
INFO:root:final mean train loss: 3337.5117418842933
INFO:root:final train perplexity: 3.7312560081481934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.92s/it]
INFO:root:eval mean loss: 4047.898008089539
INFO:root:eval perplexity: 5.138962268829346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [11:46:00<6:16:04, 309.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.358219401042
INFO:root:current train perplexity3.735527276992798
INFO:root:current mean train loss 3316.6639372452446
INFO:root:current train perplexity3.73410964012146
INFO:root:current mean train loss 3321.3292014898257
INFO:root:current train perplexity3.7294938564300537
INFO:root:current mean train loss 3325.001148623512
INFO:root:current train perplexity3.7194297313690186
INFO:root:current mean train loss 3328.090133189006
INFO:root:current train perplexity3.7187421321868896
INFO:root:current mean train loss 3327.965985285194
INFO:root:current train perplexity3.7204391956329346
INFO:root:current mean train loss 3329.697684832317
INFO:root:current train perplexity3.718865394592285
INFO:root:current mean train loss 3330.800349308894
INFO:root:current train perplexity3.7199649810791016
INFO:root:current mean train loss 3330.832841257669
INFO:root:current train perplexity3.7193260192871094
INFO:root:current mean train loss 3333.7814495816256
INFO:root:current train perplexity3.7234034538269043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.09s/it]
INFO:root:final mean train loss: 3333.0299534336214
INFO:root:final train perplexity: 3.7246642112731934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.48s/it]
INFO:root:eval mean loss: 4048.1017616217864
INFO:root:eval perplexity: 5.13938570022583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [11:51:14<6:12:32, 310.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3287.3756050441575
INFO:root:current train perplexity3.7034237384796143
INFO:root:current mean train loss 3330.8226090097814
INFO:root:current train perplexity3.7107348442077637
INFO:root:current mean train loss 3330.1101709203335
INFO:root:current train perplexity3.7123477458953857
INFO:root:current mean train loss 3330.667426803164
INFO:root:current train perplexity3.719796895980835
INFO:root:current mean train loss 3329.237962077977
INFO:root:current train perplexity3.714691162109375
INFO:root:current mean train loss 3328.720930460534
INFO:root:current train perplexity3.717839241027832
INFO:root:current mean train loss 3330.916414165956
INFO:root:current train perplexity3.72031307220459
INFO:root:current mean train loss 3331.7673836229255
INFO:root:current train perplexity3.7207372188568115
INFO:root:current mean train loss 3330.2751829719773
INFO:root:current train perplexity3.7190351486206055
INFO:root:current mean train loss 3331.025972012967
INFO:root:current train perplexity3.7186713218688965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.77s/it]
INFO:root:final mean train loss: 3329.87384199327
INFO:root:final train perplexity: 3.720029830932617
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it]
INFO:root:eval mean loss: 4050.1908781443926
INFO:root:eval perplexity: 5.1437296867370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [11:56:26<6:08:04, 311.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3332.4381536668348
INFO:root:current train perplexity3.690206527709961
INFO:root:current mean train loss 3320.3227576335876
INFO:root:current train perplexity3.7051403522491455
INFO:root:current mean train loss 3329.875113086783
INFO:root:current train perplexity3.712981939315796
INFO:root:current mean train loss 3330.2335312027944
INFO:root:current train perplexity3.7141168117523193
INFO:root:current mean train loss 3329.2198290902334
INFO:root:current train perplexity3.7180418968200684
INFO:root:current mean train loss 3331.369770057233
INFO:root:current train perplexity3.721472978591919
INFO:root:current mean train loss 3330.158634917294
INFO:root:current train perplexity3.7171249389648438
INFO:root:current mean train loss 3331.602381423136
INFO:root:current train perplexity3.717349052429199
INFO:root:current mean train loss 3328.0258501146964
INFO:root:current train perplexity3.7143537998199463
INFO:root:current mean train loss 3328.1189675500136
INFO:root:current train perplexity3.714149236679077


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.58s/it]
INFO:root:final mean train loss: 3327.2294742215063
INFO:root:final train perplexity: 3.7161505222320557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.22s/it]
INFO:root:eval mean loss: 4051.9541032939937
INFO:root:eval perplexity: 5.147398471832275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [12:01:36<6:02:26, 310.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.824231270032
INFO:root:current train perplexity3.711211681365967
INFO:root:current mean train loss 3331.384893842738
INFO:root:current train perplexity3.7190284729003906
INFO:root:current mean train loss 3327.3068398192336
INFO:root:current train perplexity3.7094647884368896
INFO:root:current mean train loss 3329.9910193699297
INFO:root:current train perplexity3.713343858718872
INFO:root:current mean train loss 3328.627034319832
INFO:root:current train perplexity3.713981866836548
INFO:root:current mean train loss 3321.6484257232723
INFO:root:current train perplexity3.710092306137085
INFO:root:current mean train loss 3321.4087361080547
INFO:root:current train perplexity3.7101845741271973
INFO:root:current mean train loss 3321.2126246802054
INFO:root:current train perplexity3.707364797592163
INFO:root:current mean train loss 3325.7642937206683
INFO:root:current train perplexity3.7108712196350098
INFO:root:current mean train loss 3326.112926869093
INFO:root:current train perplexity3.7120003700256348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.51s/it]
INFO:root:final mean train loss: 3324.221011192568
INFO:root:final train perplexity: 3.711742401123047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it]
INFO:root:eval mean loss: 4052.094020113032
INFO:root:eval perplexity: 5.147689342498779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:06:48<5:57:42, 311.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.6204808011967
INFO:root:current train perplexity3.700376510620117
INFO:root:current mean train loss 3320.807751713967
INFO:root:current train perplexity3.699651002883911
INFO:root:current mean train loss 3320.833367598684
INFO:root:current train perplexity3.709152936935425
INFO:root:current mean train loss 3318.5430433289807
INFO:root:current train perplexity3.700544595718384
INFO:root:current mean train loss 3319.9138669690296
INFO:root:current train perplexity3.7002906799316406
INFO:root:current mean train loss 3320.778721560072
INFO:root:current train perplexity3.7014381885528564
INFO:root:current mean train loss 3321.8926841582543
INFO:root:current train perplexity3.705256462097168
INFO:root:current mean train loss 3322.2464055440514
INFO:root:current train perplexity3.7059895992279053
INFO:root:current mean train loss 3321.7791732193587
INFO:root:current train perplexity3.70570969581604
INFO:root:current mean train loss 3323.011472546941
INFO:root:current train perplexity3.7063140869140625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.35s/it]
INFO:root:final mean train loss: 3321.4829951870825
INFO:root:final train perplexity: 3.7077348232269287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.24s/it]
INFO:root:eval mean loss: 4050.358550808954
INFO:root:eval perplexity: 5.144077777862549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:12:02<5:53:23, 311.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.2336647727275
INFO:root:current train perplexity3.6852331161499023
INFO:root:current mean train loss 3296.920539314516
INFO:root:current train perplexity3.6931467056274414
INFO:root:current mean train loss 3298.6578785615807
INFO:root:current train perplexity3.6956498622894287
INFO:root:current mean train loss 3300.6663051551495
INFO:root:current train perplexity3.690432548522949
INFO:root:current mean train loss 3304.895968728537
INFO:root:current train perplexity3.6897521018981934
INFO:root:current mean train loss 3309.116009466498
INFO:root:current train perplexity3.6929032802581787
INFO:root:current mean train loss 3311.4460628130964
INFO:root:current train perplexity3.696779727935791
INFO:root:current mean train loss 3313.4856671668044
INFO:root:current train perplexity3.697890043258667
INFO:root:current mean train loss 3317.050129066155
INFO:root:current train perplexity3.6998746395111084
INFO:root:current mean train loss 3318.9617882853404
INFO:root:current train perplexity3.7022011280059814


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.54s/it]
INFO:root:final mean train loss: 3318.9362570854923
INFO:root:final train perplexity: 3.7040114402770996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 4054.90399559508
INFO:root:eval perplexity: 5.153540134429932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:17:11<5:47:28, 311.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.4154072110614
INFO:root:current train perplexity3.6890830993652344
INFO:root:current mean train loss 3298.171416674655
INFO:root:current train perplexity3.683239698410034
INFO:root:current mean train loss 3306.310011250891
INFO:root:current train perplexity3.6925153732299805
INFO:root:current mean train loss 3310.616936633738
INFO:root:current train perplexity3.6962597370147705
INFO:root:current mean train loss 3312.4643401770045
INFO:root:current train perplexity3.694699287414551
INFO:root:current mean train loss 3319.767444129524
INFO:root:current train perplexity3.6978085041046143
INFO:root:current mean train loss 3316.6757009745
INFO:root:current train perplexity3.694331645965576
INFO:root:current mean train loss 3315.2042621897526
INFO:root:current train perplexity3.6937367916107178
INFO:root:current mean train loss 3315.2342575974976
INFO:root:current train perplexity3.694737672805786
INFO:root:current mean train loss 3317.198331173335
INFO:root:current train perplexity3.6972134113311768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.83s/it]
INFO:root:final mean train loss: 3314.5096284804804
INFO:root:final train perplexity: 3.6975479125976562
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.44s/it]
INFO:root:eval mean loss: 4054.879586727061
INFO:root:eval perplexity: 5.153491497039795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:22:19<5:41:01, 310.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.8681090448945
INFO:root:current train perplexity3.6899492740631104
INFO:root:current mean train loss 3297.5562494289106
INFO:root:current train perplexity3.67317795753479
INFO:root:current mean train loss 3299.4459674455143
INFO:root:current train perplexity3.677088975906372
INFO:root:current mean train loss 3303.4026023679667
INFO:root:current train perplexity3.6817426681518555
INFO:root:current mean train loss 3307.7801500713244
INFO:root:current train perplexity3.6863653659820557
INFO:root:current mean train loss 3314.3877624404827
INFO:root:current train perplexity3.6900384426116943
INFO:root:current mean train loss 3318.4497048481744
INFO:root:current train perplexity3.6967172622680664
INFO:root:current mean train loss 3316.451231089393
INFO:root:current train perplexity3.6954877376556396
INFO:root:current mean train loss 3316.5920326066484
INFO:root:current train perplexity3.69608736038208
INFO:root:current mean train loss 3315.1341978911883
INFO:root:current train perplexity3.6946871280670166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.54s/it]
INFO:root:final mean train loss: 3313.404795308267
INFO:root:final train perplexity: 3.695937156677246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.76s/it]
INFO:root:eval mean loss: 4056.2998756787456
INFO:root:eval perplexity: 5.1564507484436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:27:33<5:37:14, 311.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.8314286244067
INFO:root:current train perplexity3.6768083572387695
INFO:root:current mean train loss 3303.2978829325243
INFO:root:current train perplexity3.6904854774475098
INFO:root:current mean train loss 3302.51361937164
INFO:root:current train perplexity3.684309959411621
INFO:root:current mean train loss 3307.590339761296
INFO:root:current train perplexity3.6866836547851562
INFO:root:current mean train loss 3311.4160298962684
INFO:root:current train perplexity3.689633369445801
INFO:root:current mean train loss 3312.6399583569464
INFO:root:current train perplexity3.689209461212158
INFO:root:current mean train loss 3316.1384367233522
INFO:root:current train perplexity3.6906275749206543
INFO:root:current mean train loss 3315.6140390574856
INFO:root:current train perplexity3.6888070106506348
INFO:root:current mean train loss 3314.038468118956
INFO:root:current train perplexity3.6886069774627686
INFO:root:current mean train loss 3311.312274313314
INFO:root:current train perplexity3.6885716915130615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it]
INFO:root:final mean train loss: 3308.6342204924554
INFO:root:final train perplexity: 3.6889872550964355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it]
INFO:root:eval mean loss: 4058.228751108156
INFO:root:eval perplexity: 5.1604743003845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [12:32:40<5:30:48, 310.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3289.1830297009697
INFO:root:current train perplexity3.676100730895996
INFO:root:current mean train loss 3305.0737853024734
INFO:root:current train perplexity3.684386730194092
INFO:root:current mean train loss 3302.955458371897
INFO:root:current train perplexity3.6803083419799805
INFO:root:current mean train loss 3309.295642941497
INFO:root:current train perplexity3.683875560760498
INFO:root:current mean train loss 3313.5176252486526
INFO:root:current train perplexity3.6870968341827393
INFO:root:current mean train loss 3312.114550614885
INFO:root:current train perplexity3.684340238571167
INFO:root:current mean train loss 3311.0975151672806
INFO:root:current train perplexity3.6839075088500977
INFO:root:current mean train loss 3307.962494478141
INFO:root:current train perplexity3.681922197341919
INFO:root:current mean train loss 3307.593418056828
INFO:root:current train perplexity3.682297468185425
INFO:root:current mean train loss 3308.357057024522
INFO:root:current train perplexity3.685056686401367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.77s/it]
INFO:root:final mean train loss: 3306.007668218305
INFO:root:final train perplexity: 3.685166358947754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4059.2858765514184
INFO:root:eval perplexity: 5.1626811027526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [12:37:48<5:24:53, 309.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.933454975329
INFO:root:current train perplexity3.663944721221924
INFO:root:current mean train loss 3298.8233548677886
INFO:root:current train perplexity3.6684629917144775
INFO:root:current mean train loss 3300.2380966962396
INFO:root:current train perplexity3.6727800369262695
INFO:root:current mean train loss 3301.3418568285206
INFO:root:current train perplexity3.677647829055786
INFO:root:current mean train loss 3300.532800662879
INFO:root:current train perplexity3.6788980960845947
INFO:root:current mean train loss 3302.627157054228
INFO:root:current train perplexity3.680629014968872
INFO:root:current mean train loss 3300.614477363422
INFO:root:current train perplexity3.6786348819732666
INFO:root:current mean train loss 3304.6100490738013
INFO:root:current train perplexity3.6823208332061768
INFO:root:current mean train loss 3304.587106647172
INFO:root:current train perplexity3.6809256076812744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.25s/it]
INFO:root:final mean train loss: 3303.1681036180066
INFO:root:final train perplexity: 3.6810405254364014
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.15s/it]
INFO:root:eval mean loss: 4057.5194083139404
INFO:root:eval perplexity: 5.158995151519775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [12:42:58<5:20:01, 309.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3375.234130859375
INFO:root:current train perplexity3.5602824687957764
INFO:root:current mean train loss 3280.143291584496
INFO:root:current train perplexity3.647298574447632
INFO:root:current mean train loss 3283.221538975908
INFO:root:current train perplexity3.6533420085906982
INFO:root:current mean train loss 3288.7655154187296
INFO:root:current train perplexity3.662259578704834
INFO:root:current mean train loss 3294.2611292988136
INFO:root:current train perplexity3.661428928375244
INFO:root:current mean train loss 3297.0550049313492
INFO:root:current train perplexity3.6643757820129395
INFO:root:current mean train loss 3298.8474222312916
INFO:root:current train perplexity3.6666855812072754
INFO:root:current mean train loss 3298.979751608619
INFO:root:current train perplexity3.669017791748047
INFO:root:current mean train loss 3301.8083672434427
INFO:root:current train perplexity3.6725571155548096
INFO:root:current mean train loss 3302.0089688559833
INFO:root:current train perplexity3.6746766567230225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.06s/it]
INFO:root:final mean train loss: 3300.8160510524626
INFO:root:final train perplexity: 3.677625894546509
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]
INFO:root:eval mean loss: 4060.8976583277927
INFO:root:eval perplexity: 5.166046619415283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [12:48:06<5:14:10, 309.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.831720525568
INFO:root:current train perplexity3.6053264141082764
INFO:root:current mean train loss 3293.4171527484514
INFO:root:current train perplexity3.666283130645752
INFO:root:current mean train loss 3292.415422050874
INFO:root:current train perplexity3.660409450531006
INFO:root:current mean train loss 3282.940675398161
INFO:root:current train perplexity3.650557041168213
INFO:root:current mean train loss 3288.178959236238
INFO:root:current train perplexity3.6564033031463623
INFO:root:current mean train loss 3289.8383793840203
INFO:root:current train perplexity3.663839101791382
INFO:root:current mean train loss 3292.5247049534573
INFO:root:current train perplexity3.6647253036499023
INFO:root:current mean train loss 3295.4177730254482
INFO:root:current train perplexity3.6656594276428223
INFO:root:current mean train loss 3297.243764931412
INFO:root:current train perplexity3.6698362827301025
INFO:root:current mean train loss 3299.6684680189182
INFO:root:current train perplexity3.671227216720581


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it]
INFO:root:final mean train loss: 3297.0242252965127
INFO:root:final train perplexity: 3.672128438949585
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it]
INFO:root:eval mean loss: 4060.6296265514184
INFO:root:eval perplexity: 5.165486812591553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [12:53:13<5:08:23, 308.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.2464278371713
INFO:root:current train perplexity3.6388726234436035
INFO:root:current mean train loss 3272.357081309086
INFO:root:current train perplexity3.6472911834716797
INFO:root:current mean train loss 3272.5743402629137
INFO:root:current train perplexity3.657550573348999
INFO:root:current mean train loss 3281.395852976832
INFO:root:current train perplexity3.659703016281128
INFO:root:current mean train loss 3284.922838160986
INFO:root:current train perplexity3.6605823040008545
INFO:root:current mean train loss 3288.2515537504514
INFO:root:current train perplexity3.662536382675171
INFO:root:current mean train loss 3286.6918302422
INFO:root:current train perplexity3.661102294921875
INFO:root:current mean train loss 3290.5154470727575
INFO:root:current train perplexity3.6636157035827637
INFO:root:current mean train loss 3292.696563012725
INFO:root:current train perplexity3.6651382446289062
INFO:root:current mean train loss 3294.575196640795
INFO:root:current train perplexity3.6655659675598145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.65s/it]
INFO:root:final mean train loss: 3295.0673554943455
INFO:root:final train perplexity: 3.6692943572998047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it]
INFO:root:eval mean loss: 4062.9492048980496
INFO:root:eval perplexity: 5.170335292816162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [12:58:19<5:02:42, 307.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.221851490162
INFO:root:current train perplexity3.6569643020629883
INFO:root:current mean train loss 3283.2095668522393
INFO:root:current train perplexity3.659534215927124
INFO:root:current mean train loss 3284.140330310435
INFO:root:current train perplexity3.659435510635376
INFO:root:current mean train loss 3286.1497418231556
INFO:root:current train perplexity3.66404390335083
INFO:root:current mean train loss 3291.7129695275908
INFO:root:current train perplexity3.6653010845184326
INFO:root:current mean train loss 3291.535422627342
INFO:root:current train perplexity3.6627471446990967
INFO:root:current mean train loss 3292.1752629865678
INFO:root:current train perplexity3.664227247238159
INFO:root:current mean train loss 3292.641987418866
INFO:root:current train perplexity3.664968729019165
INFO:root:current mean train loss 3293.1356081610866
INFO:root:current train perplexity3.665862560272217
INFO:root:current mean train loss 3292.329001483279
INFO:root:current train perplexity3.662855625152588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.97s/it]
INFO:root:final mean train loss: 3290.575001378213
INFO:root:final train perplexity: 3.6627964973449707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 4065.6098182624114
INFO:root:eval perplexity: 5.175900459289551
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:03:33<4:59:23, 309.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.306710379464
INFO:root:current train perplexity3.667572259902954
INFO:root:current mean train loss 3316.0767053674767
INFO:root:current train perplexity3.6504814624786377
INFO:root:current mean train loss 3304.577515167886
INFO:root:current train perplexity3.6519060134887695
INFO:root:current mean train loss 3302.3440837803173
INFO:root:current train perplexity3.653712272644043
INFO:root:current mean train loss 3296.1217055046695
INFO:root:current train perplexity3.656662702560425
INFO:root:current mean train loss 3300.05530218677
INFO:root:current train perplexity3.6604857444763184
INFO:root:current mean train loss 3294.76110474594
INFO:root:current train perplexity3.654907703399658
INFO:root:current mean train loss 3291.7136994446214
INFO:root:current train perplexity3.655348062515259
INFO:root:current mean train loss 3289.8965726749625
INFO:root:current train perplexity3.6573126316070557
INFO:root:current mean train loss 3289.966912286932
INFO:root:current train perplexity3.659011125564575


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.82s/it]
INFO:root:final mean train loss: 3289.2375703627063
INFO:root:final train perplexity: 3.660865068435669
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it]
INFO:root:eval mean loss: 4064.9457124750666
INFO:root:eval perplexity: 5.174509525299072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:08:42<4:53:58, 309.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.2458155432414
INFO:root:current train perplexity3.6337666511535645
INFO:root:current mean train loss 3276.7665759533434
INFO:root:current train perplexity3.6364870071411133
INFO:root:current mean train loss 3273.040220912101
INFO:root:current train perplexity3.636367082595825
INFO:root:current mean train loss 3280.7849049915726
INFO:root:current train perplexity3.641623020172119
INFO:root:current mean train loss 3281.4353754805657
INFO:root:current train perplexity3.644329309463501
INFO:root:current mean train loss 3283.6520146322514
INFO:root:current train perplexity3.6478426456451416
INFO:root:current mean train loss 3286.6853388049185
INFO:root:current train perplexity3.6511921882629395
INFO:root:current mean train loss 3284.4456548883327
INFO:root:current train perplexity3.652461528778076
INFO:root:current mean train loss 3286.811978992901
INFO:root:current train perplexity3.6552836894989014
INFO:root:current mean train loss 3288.048522884494
INFO:root:current train perplexity3.6583142280578613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.56s/it]
INFO:root:final mean train loss: 3287.9594490297377
INFO:root:final train perplexity: 3.6590189933776855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.65s/it]
INFO:root:eval mean loss: 4067.589874916888
INFO:root:eval perplexity: 5.180046558380127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:13:55<4:49:51, 310.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.229856004902
INFO:root:current train perplexity3.624941825866699
INFO:root:current mean train loss 3278.517725256105
INFO:root:current train perplexity3.639770269393921
INFO:root:current mean train loss 3280.0456202533614
INFO:root:current train perplexity3.640033483505249
INFO:root:current mean train loss 3276.712628399884
INFO:root:current train perplexity3.641906976699829
INFO:root:current mean train loss 3281.1766408848393
INFO:root:current train perplexity3.644827365875244
INFO:root:current mean train loss 3282.534371987012
INFO:root:current train perplexity3.6490252017974854
INFO:root:current mean train loss 3286.973142281106
INFO:root:current train perplexity3.652379274368286
INFO:root:current mean train loss 3288.7022846491136
INFO:root:current train perplexity3.654742479324341
INFO:root:current mean train loss 3288.1337144719446
INFO:root:current train perplexity3.6548473834991455
INFO:root:current mean train loss 3286.6749238055336
INFO:root:current train perplexity3.65490984916687


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.74s/it]
INFO:root:final mean train loss: 3285.665623080346
INFO:root:final train perplexity: 3.6557095050811768
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.88s/it]
INFO:root:eval mean loss: 4066.8397294714096
INFO:root:eval perplexity: 5.178474426269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:19:02<4:43:35, 309.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.868275787871
INFO:root:current train perplexity3.639003038406372
INFO:root:current mean train loss 3278.1198837952043
INFO:root:current train perplexity3.635007858276367
INFO:root:current mean train loss 3273.257656966397
INFO:root:current train perplexity3.6375792026519775
INFO:root:current mean train loss 3274.9341643182015
INFO:root:current train perplexity3.641354560852051
INFO:root:current mean train loss 3277.4856935721336
INFO:root:current train perplexity3.6422741413116455
INFO:root:current mean train loss 3278.979869972188
INFO:root:current train perplexity3.6442081928253174
INFO:root:current mean train loss 3283.2688966325636
INFO:root:current train perplexity3.6458797454833984
INFO:root:current mean train loss 3282.7831162765565
INFO:root:current train perplexity3.647305965423584
INFO:root:current mean train loss 3283.2451231560135
INFO:root:current train perplexity3.6478943824768066
INFO:root:current mean train loss 3282.5529334552593
INFO:root:current train perplexity3.6480722427368164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.24s/it]
INFO:root:final mean train loss: 3280.801120142783
INFO:root:final train perplexity: 3.6486997604370117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it]
INFO:root:eval mean loss: 4071.4510575964096
INFO:root:eval perplexity: 5.188140869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [13:24:08<4:37:35, 308.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3273.396772242304
INFO:root:current train perplexity3.6346240043640137
INFO:root:current mean train loss 3287.7141712668413
INFO:root:current train perplexity3.6316065788269043
INFO:root:current mean train loss 3285.108073831051
INFO:root:current train perplexity3.6389336585998535
INFO:root:current mean train loss 3285.808954971688
INFO:root:current train perplexity3.6362595558166504
INFO:root:current mean train loss 3281.8359244303733
INFO:root:current train perplexity3.6367428302764893
INFO:root:current mean train loss 3279.433651017554
INFO:root:current train perplexity3.639024019241333
INFO:root:current mean train loss 3280.6355752787667
INFO:root:current train perplexity3.6403090953826904
INFO:root:current mean train loss 3280.6469802955917
INFO:root:current train perplexity3.640476703643799
INFO:root:current mean train loss 3282.2352026001117
INFO:root:current train perplexity3.6448237895965576
INFO:root:current mean train loss 3282.78369595075
INFO:root:current train perplexity3.6464922428131104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.98s/it]
INFO:root:final mean train loss: 3279.7841781493157
INFO:root:final train perplexity: 3.6472365856170654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.13s/it]
INFO:root:eval mean loss: 4068.0263013907356
INFO:root:eval perplexity: 5.180959701538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [13:29:22<4:33:56, 310.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.3951171875
INFO:root:current train perplexity3.620257616043091
INFO:root:current mean train loss 3274.2902483258927
INFO:root:current train perplexity3.639159679412842
INFO:root:current mean train loss 3280.7979163707387
INFO:root:current train perplexity3.6461966037750244
INFO:root:current mean train loss 3274.5382076822916
INFO:root:current train perplexity3.6395750045776367
INFO:root:current mean train loss 3274.0298468338815
INFO:root:current train perplexity3.636744260787964
INFO:root:current mean train loss 3274.5790671705163
INFO:root:current train perplexity3.6356375217437744
INFO:root:current mean train loss 3277.517472873264
INFO:root:current train perplexity3.6376750469207764
INFO:root:current mean train loss 3278.980603893649
INFO:root:current train perplexity3.6384336948394775
INFO:root:current mean train loss 3282.721798549107
INFO:root:current train perplexity3.64338755607605
INFO:root:current mean train loss 3280.610426181891
INFO:root:current train perplexity3.643686056137085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.75s/it]
INFO:root:final mean train loss: 3277.688323113226
INFO:root:final train perplexity: 3.6442220211029053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it]
INFO:root:eval mean loss: 4070.12968195922
INFO:root:eval perplexity: 5.185368537902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [13:34:30<4:28:10, 309.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3278.5178104998117
INFO:root:current train perplexity3.641195297241211
INFO:root:current mean train loss 3270.4874687820184
INFO:root:current train perplexity3.63734769821167
INFO:root:current mean train loss 3272.058936237025
INFO:root:current train perplexity3.634666919708252
INFO:root:current mean train loss 3274.9168028669633
INFO:root:current train perplexity3.6348912715911865
INFO:root:current mean train loss 3275.081725947852
INFO:root:current train perplexity3.6339237689971924
INFO:root:current mean train loss 3273.917133311669
INFO:root:current train perplexity3.636479377746582
INFO:root:current mean train loss 3274.3237565628433
INFO:root:current train perplexity3.6363449096679688
INFO:root:current mean train loss 3274.289996033884
INFO:root:current train perplexity3.636497974395752
INFO:root:current mean train loss 3274.959005664726
INFO:root:current train perplexity3.6376357078552246
INFO:root:current mean train loss 3276.7327402761
INFO:root:current train perplexity3.639080286026001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.31s/it]
INFO:root:final mean train loss: 3274.5604054850915
INFO:root:final train perplexity: 3.63972806930542
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it]
INFO:root:eval mean loss: 4071.7459967863474
INFO:root:eval perplexity: 5.188758850097656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [13:39:38<4:22:35, 308.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.5378149682347
INFO:root:current train perplexity3.62585711479187
INFO:root:current mean train loss 3266.125425648315
INFO:root:current train perplexity3.6234288215637207
INFO:root:current mean train loss 3267.8214132302405
INFO:root:current train perplexity3.627429485321045
INFO:root:current mean train loss 3268.3930714014546
INFO:root:current train perplexity3.62654447555542
INFO:root:current mean train loss 3268.2042054838657
INFO:root:current train perplexity3.6273996829986572
INFO:root:current mean train loss 3267.944693266841
INFO:root:current train perplexity3.628772497177124
INFO:root:current mean train loss 3271.71594467936
INFO:root:current train perplexity3.6316046714782715
INFO:root:current mean train loss 3271.270156879642
INFO:root:current train perplexity3.634087562561035
INFO:root:current mean train loss 3272.4112887227307
INFO:root:current train perplexity3.6340675354003906
INFO:root:current mean train loss 3274.230537483839
INFO:root:current train perplexity3.6356284618377686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.68s/it]
INFO:root:final mean train loss: 3271.7108257047594
INFO:root:final train perplexity: 3.6356375217437744
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.98s/it]
INFO:root:eval mean loss: 4073.5843947390294
INFO:root:eval perplexity: 5.192617416381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [13:44:47<4:17:22, 308.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3267.738794191919
INFO:root:current train perplexity3.6440231800079346
INFO:root:current mean train loss 3270.6005061930746
INFO:root:current train perplexity3.6308605670928955
INFO:root:current mean train loss 3269.5356077876777
INFO:root:current train perplexity3.628986120223999
INFO:root:current mean train loss 3265.638672486881
INFO:root:current train perplexity3.6245546340942383
INFO:root:current mean train loss 3267.242265781563
INFO:root:current train perplexity3.625187635421753
INFO:root:current mean train loss 3269.383513945769
INFO:root:current train perplexity3.63057541847229
INFO:root:current mean train loss 3267.8397945027496
INFO:root:current train perplexity3.631239414215088
INFO:root:current mean train loss 3265.293292030077
INFO:root:current train perplexity3.6296801567077637
INFO:root:current mean train loss 3269.2430948123783
INFO:root:current train perplexity3.6307685375213623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.77s/it]
INFO:root:final mean train loss: 3269.444691565729
INFO:root:final train perplexity: 3.6323888301849365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.70s/it]
INFO:root:eval mean loss: 4072.0793422401375
INFO:root:eval perplexity: 5.189457893371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [13:49:54<4:11:52, 308.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.60791015625
INFO:root:current train perplexity3.6052145957946777
INFO:root:current mean train loss 3265.9677346488024
INFO:root:current train perplexity3.6237008571624756
INFO:root:current mean train loss 3263.615814651268
INFO:root:current train perplexity3.6250977516174316
INFO:root:current mean train loss 3260.9606233776976
INFO:root:current train perplexity3.6270201206207275
INFO:root:current mean train loss 3261.7274964728576
INFO:root:current train perplexity3.6264917850494385
INFO:root:current mean train loss 3263.9461311174805
INFO:root:current train perplexity3.624171733856201
INFO:root:current mean train loss 3263.902361447179
INFO:root:current train perplexity3.6249547004699707
INFO:root:current mean train loss 3269.393323669002
INFO:root:current train perplexity3.6265525817871094
INFO:root:current mean train loss 3269.9272902629336
INFO:root:current train perplexity3.62729811668396
INFO:root:current mean train loss 3273.154165518192
INFO:root:current train perplexity3.630300998687744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.19s/it]
INFO:root:final mean train loss: 3267.6895689195203
INFO:root:final train perplexity: 3.6298747062683105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.90s/it]
INFO:root:eval mean loss: 4074.580045226618
INFO:root:eval perplexity: 5.194708347320557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [13:55:01<4:06:24, 308.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.0993815104166
INFO:root:current train perplexity3.630424737930298
INFO:root:current mean train loss 3265.498828125
INFO:root:current train perplexity3.6208336353302
INFO:root:current mean train loss 3262.661181640625
INFO:root:current train perplexity3.620514392852783
INFO:root:current mean train loss 3256.4175618489585
INFO:root:current train perplexity3.6164190769195557
INFO:root:current mean train loss 3261.784522072666
INFO:root:current train perplexity3.618295669555664
INFO:root:current mean train loss 3264.107349817961
INFO:root:current train perplexity3.621434211730957
INFO:root:current mean train loss 3265.292825441438
INFO:root:current train perplexity3.6190216541290283
INFO:root:current mean train loss 3267.834019544908
INFO:root:current train perplexity3.622951030731201
INFO:root:current mean train loss 3266.351873442293
INFO:root:current train perplexity3.624096632003784
INFO:root:current mean train loss 3266.896673817452
INFO:root:current train perplexity3.625483274459839


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.91s/it]
INFO:root:final mean train loss: 3264.4816583202733
INFO:root:final train perplexity: 3.6252834796905518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.50s/it]
INFO:root:eval mean loss: 4073.241015278701
INFO:root:eval perplexity: 5.191896915435791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:00:15<4:02:47, 309.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.1492972995925
INFO:root:current train perplexity3.5789313316345215
INFO:root:current mean train loss 3252.6825358072915
INFO:root:current train perplexity3.609044313430786
INFO:root:current mean train loss 3254.3572051044002
INFO:root:current train perplexity3.6066713333129883
INFO:root:current mean train loss 3255.507597837655
INFO:root:current train perplexity3.607513666152954
INFO:root:current mean train loss 3257.5644034888446
INFO:root:current train perplexity3.6124536991119385
INFO:root:current mean train loss 3260.2274120907027
INFO:root:current train perplexity3.6139445304870605
INFO:root:current mean train loss 3259.962374128461
INFO:root:current train perplexity3.6167147159576416
INFO:root:current mean train loss 3263.397768561441
INFO:root:current train perplexity3.6203291416168213
INFO:root:current mean train loss 3265.8412537140225
INFO:root:current train perplexity3.6208202838897705
INFO:root:current mean train loss 3266.5204744845273
INFO:root:current train perplexity3.623023509979248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.58s/it]
INFO:root:final mean train loss: 3264.002346961729
INFO:root:final train perplexity: 3.624598264694214
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.40s/it]
INFO:root:eval mean loss: 4074.3169828374334
INFO:root:eval perplexity: 5.194157123565674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:05:23<3:57:09, 309.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3290.9107784148187
INFO:root:current train perplexity3.6555380821228027
INFO:root:current mean train loss 3263.2686534619515
INFO:root:current train perplexity3.6280457973480225
INFO:root:current mean train loss 3256.733046494521
INFO:root:current train perplexity3.6118197441101074
INFO:root:current mean train loss 3258.9199853073073
INFO:root:current train perplexity3.6161305904388428
INFO:root:current mean train loss 3255.6281783597374
INFO:root:current train perplexity3.618567943572998
INFO:root:current mean train loss 3255.5681428208864
INFO:root:current train perplexity3.6186442375183105
INFO:root:current mean train loss 3259.5136834823197
INFO:root:current train perplexity3.621743679046631
INFO:root:current mean train loss 3262.8170708735893
INFO:root:current train perplexity3.6249582767486572
INFO:root:current mean train loss 3265.3032914034297
INFO:root:current train perplexity3.622253656387329
INFO:root:current mean train loss 3263.295294248456
INFO:root:current train perplexity3.6210274696350098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.12s/it]
INFO:root:final mean train loss: 3261.5666361778012
INFO:root:final train perplexity: 3.6211163997650146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.37s/it]
INFO:root:eval mean loss: 4076.190504141733
INFO:root:eval perplexity: 5.198092937469482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:10:32<3:51:48, 309.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3301.736872746394
INFO:root:current train perplexity3.6237051486968994
INFO:root:current mean train loss 3256.4999297437053
INFO:root:current train perplexity3.6006360054016113
INFO:root:current mean train loss 3261.748592360748
INFO:root:current train perplexity3.611133575439453
INFO:root:current mean train loss 3259.5280603279407
INFO:root:current train perplexity3.6151952743530273
INFO:root:current mean train loss 3255.108925647779
INFO:root:current train perplexity3.6169075965881348
INFO:root:current mean train loss 3257.257162515219
INFO:root:current train perplexity3.615496873855591
INFO:root:current mean train loss 3257.304417378839
INFO:root:current train perplexity3.613880157470703
INFO:root:current mean train loss 3259.4906826819392
INFO:root:current train perplexity3.614440679550171
INFO:root:current mean train loss 3259.856110091999
INFO:root:current train perplexity3.6129817962646484
INFO:root:current mean train loss 3261.8284934209432
INFO:root:current train perplexity3.617781639099121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.65s/it]
INFO:root:final mean train loss: 3259.208045036562
INFO:root:final train perplexity: 3.617748260498047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it]
INFO:root:eval mean loss: 4077.857229679189
INFO:root:eval perplexity: 5.201597213745117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [14:15:42<3:46:49, 309.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.5225752160904
INFO:root:current train perplexity3.5659351348876953
INFO:root:current mean train loss 3260.4953762755104
INFO:root:current train perplexity3.595085382461548
INFO:root:current mean train loss 3252.2268600154985
INFO:root:current train perplexity3.598130702972412
INFO:root:current mean train loss 3253.9741225009006
INFO:root:current train perplexity3.601255416870117
INFO:root:current mean train loss 3256.001174278174
INFO:root:current train perplexity3.6058876514434814
INFO:root:current mean train loss 3252.114871065185
INFO:root:current train perplexity3.605952262878418
INFO:root:current mean train loss 3251.758281159438
INFO:root:current train perplexity3.606790542602539
INFO:root:current mean train loss 3255.053305670599
INFO:root:current train perplexity3.6092536449432373
INFO:root:current mean train loss 3258.2169064068034
INFO:root:current train perplexity3.611276626586914
INFO:root:current mean train loss 3259.1577780057914
INFO:root:current train perplexity3.612783670425415


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it]
INFO:root:final mean train loss: 3256.7556902362453
INFO:root:final train perplexity: 3.6142499446868896
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.87s/it]
INFO:root:eval mean loss: 4078.3960255291445
INFO:root:eval perplexity: 5.202731132507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [14:20:49<3:41:17, 308.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.141690340909
INFO:root:current train perplexity3.626741647720337
INFO:root:current mean train loss 3226.756744581653
INFO:root:current train perplexity3.599364995956421
INFO:root:current mean train loss 3240.553618068321
INFO:root:current train perplexity3.6029727458953857
INFO:root:current mean train loss 3246.3818393761003
INFO:root:current train perplexity3.607159376144409
INFO:root:current mean train loss 3248.454701450893
INFO:root:current train perplexity3.6077356338500977
INFO:root:current mean train loss 3252.5642982826575
INFO:root:current train perplexity3.608304738998413
INFO:root:current mean train loss 3256.3397636122377
INFO:root:current train perplexity3.6113061904907227
INFO:root:current mean train loss 3257.0366721854307
INFO:root:current train perplexity3.6117496490478516
INFO:root:current mean train loss 3258.771992073282
INFO:root:current train perplexity3.613563060760498
INFO:root:current mean train loss 3257.7902857595714
INFO:root:current train perplexity3.6117634773254395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.04s/it]
INFO:root:final mean train loss: 3255.103929150489
INFO:root:final train perplexity: 3.6118950843811035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 4076.709657926086
INFO:root:eval perplexity: 5.199184417724609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [14:25:58<3:36:03, 308.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3267.9227275545636
INFO:root:current train perplexity3.60418963432312
INFO:root:current mean train loss 3261.2388878570746
INFO:root:current train perplexity3.5985631942749023
INFO:root:current mean train loss 3256.543478381951
INFO:root:current train perplexity3.5976576805114746
INFO:root:current mean train loss 3248.602427416925
INFO:root:current train perplexity3.5997278690338135
INFO:root:current mean train loss 3252.267021821848
INFO:root:current train perplexity3.6071903705596924
INFO:root:current mean train loss 3253.153671129135
INFO:root:current train perplexity3.606024742126465
INFO:root:current mean train loss 3252.1357988958803
INFO:root:current train perplexity3.60917329788208
INFO:root:current mean train loss 3256.680556551032
INFO:root:current train perplexity3.6096763610839844
INFO:root:current mean train loss 3255.555499133202
INFO:root:current train perplexity3.609574317932129
INFO:root:current mean train loss 3254.975561092452
INFO:root:current train perplexity3.607935667037964


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it]
INFO:root:final mean train loss: 3252.3314923317203
INFO:root:final train perplexity: 3.6079463958740234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it]
INFO:root:eval mean loss: 4079.6282448193706
INFO:root:eval perplexity: 5.205324649810791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [14:31:06<3:30:48, 308.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.4174048195423
INFO:root:current train perplexity3.607729196548462
INFO:root:current mean train loss 3244.838988543951
INFO:root:current train perplexity3.594148635864258
INFO:root:current mean train loss 3243.9795894833946
INFO:root:current train perplexity3.5921316146850586
INFO:root:current mean train loss 3241.531992950851
INFO:root:current train perplexity3.598599910736084
INFO:root:current mean train loss 3246.3499768818006
INFO:root:current train perplexity3.6007394790649414
INFO:root:current mean train loss 3246.322086046957
INFO:root:current train perplexity3.602370500564575
INFO:root:current mean train loss 3248.855175126327
INFO:root:current train perplexity3.6009082794189453
INFO:root:current mean train loss 3251.377074403676
INFO:root:current train perplexity3.602693557739258
INFO:root:current mean train loss 3253.3975273684164
INFO:root:current train perplexity3.6072566509246826
INFO:root:current mean train loss 3253.712268078978
INFO:root:current train perplexity3.6073076725006104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.32s/it]
INFO:root:final mean train loss: 3251.79113400367
INFO:root:final train perplexity: 3.607177972793579
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.53s/it]
INFO:root:eval mean loss: 4080.142417096077
INFO:root:eval perplexity: 5.2064056396484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [14:36:19<3:26:31, 309.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.285746514043
INFO:root:current train perplexity3.5854477882385254
INFO:root:current mean train loss 3238.756231723551
INFO:root:current train perplexity3.5973291397094727
INFO:root:current mean train loss 3245.729546440972
INFO:root:current train perplexity3.6010360717773438
INFO:root:current mean train loss 3251.222462354675
INFO:root:current train perplexity3.599203586578369
INFO:root:current mean train loss 3249.2745858274075
INFO:root:current train perplexity3.5980887413024902
INFO:root:current mean train loss 3251.6757331808612
INFO:root:current train perplexity3.5994911193847656
INFO:root:current mean train loss 3247.6784890895387
INFO:root:current train perplexity3.600090980529785
INFO:root:current mean train loss 3249.4205734390043
INFO:root:current train perplexity3.6012730598449707
INFO:root:current mean train loss 3248.640891638225
INFO:root:current train perplexity3.602627754211426
INFO:root:current mean train loss 3250.522837996361
INFO:root:current train perplexity3.6029369831085205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.85s/it]
INFO:root:final mean train loss: 3248.5274952919253
INFO:root:final train perplexity: 3.6025359630584717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.84s/it]
INFO:root:eval mean loss: 4081.1897526734265
INFO:root:eval perplexity: 5.208611011505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [14:41:26<3:20:57, 309.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.4398600260415
INFO:root:current train perplexity3.5772907733917236
INFO:root:current mean train loss 3238.0126731178975
INFO:root:current train perplexity3.5811586380004883
INFO:root:current mean train loss 3244.575841817291
INFO:root:current train perplexity3.5855820178985596
INFO:root:current mean train loss 3249.155139065528
INFO:root:current train perplexity3.593226671218872
INFO:root:current mean train loss 3245.6508017036704
INFO:root:current train perplexity3.5921499729156494
INFO:root:current mean train loss 3246.4780693509106
INFO:root:current train perplexity3.5912559032440186
INFO:root:current mean train loss 3245.645816275473
INFO:root:current train perplexity3.5920908451080322
INFO:root:current mean train loss 3246.6882333525255
INFO:root:current train perplexity3.5942041873931885
INFO:root:current mean train loss 3247.0787492513386
INFO:root:current train perplexity3.5964128971099854
INFO:root:current mean train loss 3249.5920298845936
INFO:root:current train perplexity3.600552797317505


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.89s/it]
INFO:root:final mean train loss: 3246.7600134572676
INFO:root:final train perplexity: 3.600024938583374
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 4080.7847303025264
INFO:root:eval perplexity: 5.207759380340576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [14:46:35<3:15:45, 309.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.766177528783
INFO:root:current train perplexity3.597750663757324
INFO:root:current mean train loss 3251.0698642828524
INFO:root:current train perplexity3.604994535446167
INFO:root:current mean train loss 3248.1015467756883
INFO:root:current train perplexity3.596381187438965
INFO:root:current mean train loss 3251.36611328125
INFO:root:current train perplexity3.5938127040863037
INFO:root:current mean train loss 3253.047807666509
INFO:root:current train perplexity3.597088575363159
INFO:root:current mean train loss 3251.9404493828783
INFO:root:current train perplexity3.5964367389678955
INFO:root:current mean train loss 3250.5304891243254
INFO:root:current train perplexity3.5946264266967773
INFO:root:current mean train loss 3248.43861076307
INFO:root:current train perplexity3.5958640575408936
INFO:root:current mean train loss 3249.1173634449196
INFO:root:current train perplexity3.597720146179199


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.74s/it]
INFO:root:final mean train loss: 3246.169857763475
INFO:root:final train perplexity: 3.599186897277832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.78s/it]
INFO:root:eval mean loss: 4079.5482671210107
INFO:root:eval perplexity: 5.2051544189453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [14:51:43<3:10:18, 308.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.1227213541665
INFO:root:current train perplexity3.587315559387207
INFO:root:current mean train loss 3217.9643293954796
INFO:root:current train perplexity3.592247486114502
INFO:root:current mean train loss 3238.3055377828664
INFO:root:current train perplexity3.599529266357422
INFO:root:current mean train loss 3234.6260579427085
INFO:root:current train perplexity3.5934784412384033
INFO:root:current mean train loss 3234.7586309466114
INFO:root:current train perplexity3.595733880996704
INFO:root:current mean train loss 3238.4507947432594
INFO:root:current train perplexity3.596856117248535
INFO:root:current mean train loss 3240.786496391739
INFO:root:current train perplexity3.594284772872925
INFO:root:current mean train loss 3240.3361687911183
INFO:root:current train perplexity3.591453790664673
INFO:root:current mean train loss 3240.2359003468437
INFO:root:current train perplexity3.591480255126953
INFO:root:current mean train loss 3244.6124952956293
INFO:root:current train perplexity3.59338641166687


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.91s/it]
INFO:root:final mean train loss: 3242.449381182271
INFO:root:final train perplexity: 3.5939078330993652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.46s/it]
INFO:root:eval mean loss: 4081.2507566627883
INFO:root:eval perplexity: 5.208739280700684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [14:56:49<3:04:45, 307.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.7195933948865
INFO:root:current train perplexity3.5780222415924072
INFO:root:current mean train loss 3243.683182450028
INFO:root:current train perplexity3.577897787094116
INFO:root:current mean train loss 3246.195641106339
INFO:root:current train perplexity3.5849716663360596
INFO:root:current mean train loss 3246.3244683857515
INFO:root:current train perplexity3.592766284942627
INFO:root:current mean train loss 3250.712971411192
INFO:root:current train perplexity3.5986506938934326
INFO:root:current mean train loss 3247.921448351119
INFO:root:current train perplexity3.5997540950775146
INFO:root:current mean train loss 3244.9734653903693
INFO:root:current train perplexity3.5959441661834717
INFO:root:current mean train loss 3243.6041282085093
INFO:root:current train perplexity3.5944814682006836
INFO:root:current mean train loss 3244.672656490829
INFO:root:current train perplexity3.5939090251922607
INFO:root:current mean train loss 3244.6106956641056
INFO:root:current train perplexity3.5935912132263184


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it]
INFO:root:final mean train loss: 3240.91580372472
INFO:root:final train perplexity: 3.591733694076538
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.80s/it]
INFO:root:eval mean loss: 4083.068840730275
INFO:root:eval perplexity: 5.2125701904296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:01:56<2:59:27, 307.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3263.9581748560854
INFO:root:current train perplexity3.6123464107513428
INFO:root:current mean train loss 3241.773080521271
INFO:root:current train perplexity3.590475559234619
INFO:root:current mean train loss 3244.889177993008
INFO:root:current train perplexity3.5963099002838135
INFO:root:current mean train loss 3245.199606007543
INFO:root:current train perplexity3.5923919677734375
INFO:root:current mean train loss 3241.7112166010966
INFO:root:current train perplexity3.5913431644439697
INFO:root:current mean train loss 3240.031798493196
INFO:root:current train perplexity3.5913047790527344
INFO:root:current mean train loss 3243.1568293902715
INFO:root:current train perplexity3.5927507877349854
INFO:root:current mean train loss 3244.905746099183
INFO:root:current train perplexity3.5920968055725098
INFO:root:current mean train loss 3244.8897012004923
INFO:root:current train perplexity3.5934908390045166
INFO:root:current mean train loss 3242.9371668636086
INFO:root:current train perplexity3.590301752090454


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.62s/it]
INFO:root:final mean train loss: 3239.395622561055
INFO:root:final train perplexity: 3.5895802974700928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it]
INFO:root:eval mean loss: 4085.8948636968084
INFO:root:eval perplexity: 5.218531131744385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:07:09<2:55:13, 309.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.860423900463
INFO:root:current train perplexity3.592066764831543
INFO:root:current mean train loss 3235.162019023745
INFO:root:current train perplexity3.575737953186035
INFO:root:current mean train loss 3240.943367979075
INFO:root:current train perplexity3.585939645767212
INFO:root:current mean train loss 3237.084777272076
INFO:root:current train perplexity3.584263563156128
INFO:root:current mean train loss 3239.0602438433107
INFO:root:current train perplexity3.582688570022583
INFO:root:current mean train loss 3242.715412176085
INFO:root:current train perplexity3.5832583904266357
INFO:root:current mean train loss 3242.651185736892
INFO:root:current train perplexity3.5851614475250244
INFO:root:current mean train loss 3243.2689512900834
INFO:root:current train perplexity3.5864241123199463
INFO:root:current mean train loss 3240.295852974796
INFO:root:current train perplexity3.5867395401000977
INFO:root:current mean train loss 3240.566542937146
INFO:root:current train perplexity3.5874836444854736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it]
INFO:root:final mean train loss: 3237.777953240179
INFO:root:final train perplexity: 3.587290048599243
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.06s/it]
INFO:root:eval mean loss: 4085.6929957613033
INFO:root:eval perplexity: 5.218105792999268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [15:12:16<2:49:47, 308.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3273.287437220982
INFO:root:current train perplexity3.5886363983154297
INFO:root:current mean train loss 3238.734884982639
INFO:root:current train perplexity3.5850741863250732
INFO:root:current mean train loss 3228.3719144780584
INFO:root:current train perplexity3.578342914581299
INFO:root:current mean train loss 3232.630036584655
INFO:root:current train perplexity3.576836585998535
INFO:root:current mean train loss 3234.271878367457
INFO:root:current train perplexity3.578045606613159
INFO:root:current mean train loss 3238.493603515625
INFO:root:current train perplexity3.5802340507507324
INFO:root:current mean train loss 3237.3235778328003
INFO:root:current train perplexity3.5814783573150635
INFO:root:current mean train loss 3238.8962674718323
INFO:root:current train perplexity3.5813958644866943
INFO:root:current mean train loss 3238.534867082242
INFO:root:current train perplexity3.5811471939086914
INFO:root:current mean train loss 3237.683282503342
INFO:root:current train perplexity3.5823464393615723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it]
INFO:root:final mean train loss: 3234.783140182495
INFO:root:final train perplexity: 3.5830538272857666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4085.4745487727173
INFO:root:eval perplexity: 5.2176432609558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [15:17:24<2:44:23, 308.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.6864269167877
INFO:root:current train perplexity3.5593655109405518
INFO:root:current mean train loss 3255.089292299497
INFO:root:current train perplexity3.5935099124908447
INFO:root:current mean train loss 3239.2141937130273
INFO:root:current train perplexity3.5883655548095703
INFO:root:current mean train loss 3234.4247000558034
INFO:root:current train perplexity3.5822908878326416
INFO:root:current mean train loss 3234.268117659248
INFO:root:current train perplexity3.5811991691589355
INFO:root:current mean train loss 3232.0924645524
INFO:root:current train perplexity3.5765488147735596
INFO:root:current mean train loss 3237.1971615899593
INFO:root:current train perplexity3.5783770084381104
INFO:root:current mean train loss 3238.72963906618
INFO:root:current train perplexity3.5831053256988525
INFO:root:current mean train loss 3240.4244910406474
INFO:root:current train perplexity3.584665298461914
INFO:root:current mean train loss 3238.2754965142
INFO:root:current train perplexity3.5836265087127686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.14s/it]
INFO:root:final mean train loss: 3234.8739636328914
INFO:root:final train perplexity: 3.5831828117370605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.56s/it]
INFO:root:eval mean loss: 4086.9382203014184
INFO:root:eval perplexity: 5.220733642578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [15:22:37<2:40:05, 309.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.435068167892
INFO:root:current train perplexity3.5763649940490723
INFO:root:current mean train loss 3231.1789033397145
INFO:root:current train perplexity3.571161985397339
INFO:root:current mean train loss 3232.9106406405626
INFO:root:current train perplexity3.5811893939971924
INFO:root:current mean train loss 3231.7845580706908
INFO:root:current train perplexity3.578615188598633
INFO:root:current mean train loss 3226.0904381322757
INFO:root:current train perplexity3.573395252227783
INFO:root:current mean train loss 3226.318745303284
INFO:root:current train perplexity3.574374198913574
INFO:root:current mean train loss 3229.9985295308898
INFO:root:current train perplexity3.576197624206543
INFO:root:current mean train loss 3232.619066179989
INFO:root:current train perplexity3.578859567642212
INFO:root:current mean train loss 3234.0581195262007
INFO:root:current train perplexity3.578247547149658
INFO:root:current mean train loss 3235.0114758929744
INFO:root:current train perplexity3.5796945095062256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.17s/it]
INFO:root:final mean train loss: 3233.234899520874
INFO:root:final train perplexity: 3.5808660984039307
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.04s/it]
INFO:root:eval mean loss: 4087.074412677305
INFO:root:eval perplexity: 5.221020698547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [15:27:44<2:34:32, 309.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.2742733712926
INFO:root:current train perplexity3.5758211612701416
INFO:root:current mean train loss 3214.905727938286
INFO:root:current train perplexity3.5567586421966553
INFO:root:current mean train loss 3213.7872507691845
INFO:root:current train perplexity3.5640034675598145
INFO:root:current mean train loss 3223.155085061586
INFO:root:current train perplexity3.5734293460845947
INFO:root:current mean train loss 3223.3268399373637
INFO:root:current train perplexity3.572364091873169
INFO:root:current mean train loss 3226.0854470350237
INFO:root:current train perplexity3.5756983757019043
INFO:root:current mean train loss 3230.590613589482
INFO:root:current train perplexity3.578662872314453
INFO:root:current mean train loss 3232.60941070436
INFO:root:current train perplexity3.5791101455688477
INFO:root:current mean train loss 3233.23134384777
INFO:root:current train perplexity3.5794501304626465
INFO:root:current mean train loss 3233.0226765653515
INFO:root:current train perplexity3.578310251235962


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.98s/it]
INFO:root:final mean train loss: 3231.4714189344836
INFO:root:final train perplexity: 3.578375816345215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.18s/it]
INFO:root:eval mean loss: 4086.921765915891
INFO:root:eval perplexity: 5.220698833465576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [15:32:58<2:29:59, 310.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.781111532183
INFO:root:current train perplexity3.563249111175537
INFO:root:current mean train loss 3243.4730392730166
INFO:root:current train perplexity3.5789740085601807
INFO:root:current mean train loss 3235.5437423191715
INFO:root:current train perplexity3.583186626434326
INFO:root:current mean train loss 3235.464165212023
INFO:root:current train perplexity3.5842294692993164
INFO:root:current mean train loss 3228.217375598066
INFO:root:current train perplexity3.579572916030884
INFO:root:current mean train loss 3226.5087124187057
INFO:root:current train perplexity3.5752856731414795
INFO:root:current mean train loss 3226.899123436329
INFO:root:current train perplexity3.575648069381714
INFO:root:current mean train loss 3229.110753264545
INFO:root:current train perplexity3.5759246349334717
INFO:root:current mean train loss 3232.4362840839462
INFO:root:current train perplexity3.5770370960235596
INFO:root:current mean train loss 3232.4796239779926
INFO:root:current train perplexity3.5768468379974365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.31s/it]
INFO:root:final mean train loss: 3230.3597847107917
INFO:root:final train perplexity: 3.5768063068389893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.94s/it]
INFO:root:eval mean loss: 4086.924342378657
INFO:root:eval perplexity: 5.220704555511475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [15:38:06<2:24:31, 309.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.2405501302082
INFO:root:current train perplexity3.573829412460327
INFO:root:current mean train loss 3219.981495535714
INFO:root:current train perplexity3.567178249359131
INFO:root:current mean train loss 3231.377088068182
INFO:root:current train perplexity3.5730481147766113
INFO:root:current mean train loss 3228.0652141927085
INFO:root:current train perplexity3.5707602500915527
INFO:root:current mean train loss 3229.1989910567436
INFO:root:current train perplexity3.5724496841430664
INFO:root:current mean train loss 3230.809253566576
INFO:root:current train perplexity3.572852849960327
INFO:root:current mean train loss 3228.9047594762733
INFO:root:current train perplexity3.5736844539642334
INFO:root:current mean train loss 3230.6918488533265
INFO:root:current train perplexity3.574765920639038
INFO:root:current mean train loss 3232.9307513950894
INFO:root:current train perplexity3.575767755508423
INFO:root:current mean train loss 3232.4944658954328
INFO:root:current train perplexity3.575570821762085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.61s/it]
INFO:root:final mean train loss: 3229.5173293082944
INFO:root:final train perplexity: 3.575617790222168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.27s/it]
INFO:root:eval mean loss: 4088.44781797152
INFO:root:eval perplexity: 5.223920822143555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [15:43:20<2:19:56, 310.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.38575101186
INFO:root:current train perplexity3.5927815437316895
INFO:root:current mean train loss 3234.3259624210214
INFO:root:current train perplexity3.573549747467041
INFO:root:current mean train loss 3230.284299601093
INFO:root:current train perplexity3.5735719203948975
INFO:root:current mean train loss 3231.100675179504
INFO:root:current train perplexity3.5692293643951416
INFO:root:current mean train loss 3238.670231726352
INFO:root:current train perplexity3.5744218826293945
INFO:root:current mean train loss 3231.8523761624947
INFO:root:current train perplexity3.571833848953247
INFO:root:current mean train loss 3230.11626348314
INFO:root:current train perplexity3.5709571838378906
INFO:root:current mean train loss 3231.755998438498
INFO:root:current train perplexity3.5730996131896973
INFO:root:current mean train loss 3233.498542344989
INFO:root:current train perplexity3.575408935546875
INFO:root:current mean train loss 3231.037527121217
INFO:root:current train perplexity3.5741219520568848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.79s/it]
INFO:root:final mean train loss: 3228.6815400277414
INFO:root:final train perplexity: 3.57443904876709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.54s/it]
INFO:root:eval mean loss: 4089.1142456920434
INFO:root:eval perplexity: 5.225329399108887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [15:48:29<2:14:33, 310.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3208.853759765625
INFO:root:current train perplexity3.5604147911071777
INFO:root:current mean train loss 3211.6683164267015
INFO:root:current train perplexity3.5572030544281006
INFO:root:current mean train loss 3221.0320386329468
INFO:root:current train perplexity3.5639712810516357
INFO:root:current mean train loss 3225.6130939298273
INFO:root:current train perplexity3.5669243335723877
INFO:root:current mean train loss 3221.790073868699
INFO:root:current train perplexity3.561948299407959
INFO:root:current mean train loss 3223.5374212636157
INFO:root:current train perplexity3.5624849796295166
INFO:root:current mean train loss 3225.6019006223996
INFO:root:current train perplexity3.564713716506958
INFO:root:current mean train loss 3226.1110691692675
INFO:root:current train perplexity3.565943717956543
INFO:root:current mean train loss 3229.3098380177644
INFO:root:current train perplexity3.5700578689575195
INFO:root:current mean train loss 3229.5544566626986
INFO:root:current train perplexity3.5721242427825928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.32s/it]
INFO:root:final mean train loss: 3227.002597316619
INFO:root:final train perplexity: 3.5720722675323486
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.12s/it]
INFO:root:eval mean loss: 4089.6898704150044
INFO:root:eval perplexity: 5.2265448570251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [15:53:38<2:09:07, 309.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.5516517716223
INFO:root:current train perplexity3.576169729232788
INFO:root:current mean train loss 3223.612155013348
INFO:root:current train perplexity3.565904378890991
INFO:root:current mean train loss 3224.3542496799228
INFO:root:current train perplexity3.5665035247802734
INFO:root:current mean train loss 3224.8494086779447
INFO:root:current train perplexity3.5665078163146973
INFO:root:current mean train loss 3226.064018173065
INFO:root:current train perplexity3.567901611328125
INFO:root:current mean train loss 3227.552106701273
INFO:root:current train perplexity3.571455478668213
INFO:root:current mean train loss 3228.732029294081
INFO:root:current train perplexity3.5701894760131836
INFO:root:current mean train loss 3226.798329760345
INFO:root:current train perplexity3.5688393115997314
INFO:root:current mean train loss 3227.652045023985
INFO:root:current train perplexity3.5702712535858154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.96s/it]
INFO:root:final mean train loss: 3227.0748595576133
INFO:root:final train perplexity: 3.572174549102783
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.16s/it]
INFO:root:eval mean loss: 4089.943494431516
INFO:root:eval perplexity: 5.227080821990967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [15:58:55<2:04:49, 312.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.21142578125
INFO:root:current train perplexity3.446988344192505
INFO:root:current mean train loss 3231.8446581118574
INFO:root:current train perplexity3.5561981201171875
INFO:root:current mean train loss 3224.8312433952296
INFO:root:current train perplexity3.5537049770355225
INFO:root:current mean train loss 3219.9023039876834
INFO:root:current train perplexity3.5531253814697266
INFO:root:current mean train loss 3220.8249799648725
INFO:root:current train perplexity3.551145315170288
INFO:root:current mean train loss 3219.1576845067493
INFO:root:current train perplexity3.5531234741210938
INFO:root:current mean train loss 3219.288758028084
INFO:root:current train perplexity3.556734800338745
INFO:root:current mean train loss 3221.297814268034
INFO:root:current train perplexity3.561436653137207
INFO:root:current mean train loss 3222.7093906709842
INFO:root:current train perplexity3.5630741119384766
INFO:root:current mean train loss 3225.3430321135097
INFO:root:current train perplexity3.5667853355407715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.34s/it]
INFO:root:final mean train loss: 3222.49192988488
INFO:root:final train perplexity: 3.565721273422241
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.99s/it]
INFO:root:eval mean loss: 4089.8673710383423
INFO:root:eval perplexity: 5.2269206047058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:04:02<1:59:04, 310.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.66708984375
INFO:root:current train perplexity3.529184341430664
INFO:root:current mean train loss 3215.820783797554
INFO:root:current train perplexity3.5386133193969727
INFO:root:current mean train loss 3219.7737440952037
INFO:root:current train perplexity3.563624620437622
INFO:root:current mean train loss 3217.3737707713294
INFO:root:current train perplexity3.5643935203552246
INFO:root:current mean train loss 3220.8633777296686
INFO:root:current train perplexity3.562305450439453
INFO:root:current mean train loss 3219.7002242301273
INFO:root:current train perplexity3.559556007385254
INFO:root:current mean train loss 3223.776538284426
INFO:root:current train perplexity3.5623371601104736
INFO:root:current mean train loss 3226.833318536932
INFO:root:current train perplexity3.5656425952911377
INFO:root:current mean train loss 3226.7385595403566
INFO:root:current train perplexity3.5654845237731934
INFO:root:current mean train loss 3225.6972082586235
INFO:root:current train perplexity3.5671029090881348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.34s/it]
INFO:root:final mean train loss: 3223.69298455023
INFO:root:final train perplexity: 3.567411422729492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.90s/it]
INFO:root:eval mean loss: 4089.066257341534
INFO:root:eval perplexity: 5.2252278327941895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [16:09:10<1:53:37, 309.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.154976222826
INFO:root:current train perplexity3.559454917907715
INFO:root:current mean train loss 3232.8972564945375
INFO:root:current train perplexity3.5533394813537598
INFO:root:current mean train loss 3229.1440922347956
INFO:root:current train perplexity3.5523860454559326
INFO:root:current mean train loss 3230.833168809259
INFO:root:current train perplexity3.557543992996216
INFO:root:current mean train loss 3234.5198538850104
INFO:root:current train perplexity3.5631725788116455
INFO:root:current mean train loss 3229.1555815308316
INFO:root:current train perplexity3.563701629638672
INFO:root:current mean train loss 3227.4614438076846
INFO:root:current train perplexity3.562687635421753
INFO:root:current mean train loss 3223.75691833074
INFO:root:current train perplexity3.562607765197754
INFO:root:current mean train loss 3222.291428854515
INFO:root:current train perplexity3.5612995624542236
INFO:root:current mean train loss 3222.7550330528848
INFO:root:current train perplexity3.564237594604492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.27s/it]
INFO:root:final mean train loss: 3221.556155297064
INFO:root:final train perplexity: 3.5644047260284424
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.69s/it]
INFO:root:eval mean loss: 4090.6770417774824
INFO:root:eval perplexity: 5.228631973266602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [16:14:24<1:48:53, 311.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.9825006300402
INFO:root:current train perplexity3.55497407913208
INFO:root:current mean train loss 3214.0248128876433
INFO:root:current train perplexity3.5572478771209717
INFO:root:current mean train loss 3214.5228868624863
INFO:root:current train perplexity3.5662765502929688
INFO:root:current mean train loss 3215.4238930324773
INFO:root:current train perplexity3.5660459995269775
INFO:root:current mean train loss 3217.965188719004
INFO:root:current train perplexity3.5646846294403076
INFO:root:current mean train loss 3220.2460785774188
INFO:root:current train perplexity3.562448501586914
INFO:root:current mean train loss 3220.91841601872
INFO:root:current train perplexity3.563558340072632
INFO:root:current mean train loss 3223.1779384378206
INFO:root:current train perplexity3.565190315246582
INFO:root:current mean train loss 3223.606580162737
INFO:root:current train perplexity3.5637686252593994
INFO:root:current mean train loss 3222.580912818458
INFO:root:current train perplexity3.5628724098205566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.01s/it]
INFO:root:final mean train loss: 3221.3952468749017
INFO:root:final train perplexity: 3.564178705215454
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]
INFO:root:eval mean loss: 4091.2589777953235
INFO:root:eval perplexity: 5.22986364364624
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [16:19:35<1:43:37, 310.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.0069673978364
INFO:root:current train perplexity3.5873796939849854
INFO:root:current mean train loss 3214.6978030856567
INFO:root:current train perplexity3.5612239837646484
INFO:root:current mean train loss 3212.6873222574527
INFO:root:current train perplexity3.557396411895752
INFO:root:current mean train loss 3217.797186117257
INFO:root:current train perplexity3.5558221340179443
INFO:root:current mean train loss 3216.4747578614392
INFO:root:current train perplexity3.556635618209839
INFO:root:current mean train loss 3216.1467661105635
INFO:root:current train perplexity3.5552849769592285
INFO:root:current mean train loss 3215.7653052101673
INFO:root:current train perplexity3.55464768409729
INFO:root:current mean train loss 3218.6571089521312
INFO:root:current train perplexity3.556753158569336
INFO:root:current mean train loss 3220.880419107103
INFO:root:current train perplexity3.560363531112671
INFO:root:current mean train loss 3220.8426605972113
INFO:root:current train perplexity3.5593199729919434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.17s/it]
INFO:root:final mean train loss: 3218.701002490136
INFO:root:final train perplexity: 3.560392379760742
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.56s/it]
INFO:root:eval mean loss: 4091.519706130873
INFO:root:eval perplexity: 5.230414867401123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [16:24:41<1:38:02, 309.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3232.461197224069
INFO:root:current train perplexity3.548640727996826
INFO:root:current mean train loss 3219.4900749362246
INFO:root:current train perplexity3.565077781677246
INFO:root:current mean train loss 3220.882978555162
INFO:root:current train perplexity3.559868574142456
INFO:root:current mean train loss 3227.2669322428856
INFO:root:current train perplexity3.564718723297119
INFO:root:current mean train loss 3223.7898948720635
INFO:root:current train perplexity3.561026096343994
INFO:root:current mean train loss 3222.0143859974864
INFO:root:current train perplexity3.561936378479004
INFO:root:current mean train loss 3224.820249106453
INFO:root:current train perplexity3.5628881454467773
INFO:root:current mean train loss 3223.0871013350275
INFO:root:current train perplexity3.5624430179595947
INFO:root:current mean train loss 3223.1180000530367
INFO:root:current train perplexity3.5625627040863037
INFO:root:current mean train loss 3222.4071920167303
INFO:root:current train perplexity3.5618090629577637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.82s/it]
INFO:root:final mean train loss: 3218.6365918805523
INFO:root:final train perplexity: 3.5603015422821045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 4093.282370276485
INFO:root:eval perplexity: 5.234144687652588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [16:29:54<1:33:10, 310.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.6152388139203
INFO:root:current train perplexity3.572105884552002
INFO:root:current mean train loss 3207.270295173891
INFO:root:current train perplexity3.5638651847839355
INFO:root:current mean train loss 3206.7872931985294
INFO:root:current train perplexity3.5502281188964844
INFO:root:current mean train loss 3215.3851727552815
INFO:root:current train perplexity3.5550973415374756
INFO:root:current mean train loss 3217.637713555975
INFO:root:current train perplexity3.5536553859710693
INFO:root:current mean train loss 3215.916869017455
INFO:root:current train perplexity3.5570898056030273
INFO:root:current mean train loss 3217.423540374523
INFO:root:current train perplexity3.555640697479248
INFO:root:current mean train loss 3218.93833040149
INFO:root:current train perplexity3.558854579925537
INFO:root:current mean train loss 3220.315601299799
INFO:root:current train perplexity3.558882236480713
INFO:root:current mean train loss 3220.9729860315774
INFO:root:current train perplexity3.5589613914489746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it]
INFO:root:final mean train loss: 3217.7871858535273
INFO:root:final train perplexity: 3.5591087341308594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.85s/it]
INFO:root:eval mean loss: 4092.6594515320257
INFO:root:eval perplexity: 5.232824802398682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [16:35:03<1:27:52, 310.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3206.3237963479664
INFO:root:current train perplexity3.5608198642730713
INFO:root:current mean train loss 3226.06045550949
INFO:root:current train perplexity3.5590455532073975
INFO:root:current mean train loss 3219.343914307569
INFO:root:current train perplexity3.558521032333374
INFO:root:current mean train loss 3218.4990772425963
INFO:root:current train perplexity3.5593106746673584
INFO:root:current mean train loss 3218.0426608058856
INFO:root:current train perplexity3.5582029819488525
INFO:root:current mean train loss 3216.288863024534
INFO:root:current train perplexity3.5568230152130127
INFO:root:current mean train loss 3218.3789007264563
INFO:root:current train perplexity3.5572338104248047
INFO:root:current mean train loss 3220.206789349197
INFO:root:current train perplexity3.556788206100464
INFO:root:current mean train loss 3217.801050568511
INFO:root:current train perplexity3.5564799308776855
INFO:root:current mean train loss 3217.785565179209
INFO:root:current train perplexity3.557143211364746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.38s/it]
INFO:root:final mean train loss: 3216.4588405239965
INFO:root:final train perplexity: 3.557244062423706
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.51s/it]
INFO:root:eval mean loss: 4092.875135056516
INFO:root:eval perplexity: 5.233281135559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [16:40:18<1:23:05, 311.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.8339706205984
INFO:root:current train perplexity3.552748203277588
INFO:root:current mean train loss 3221.812308685124
INFO:root:current train perplexity3.548069477081299
INFO:root:current mean train loss 3219.239874920722
INFO:root:current train perplexity3.5471370220184326
INFO:root:current mean train loss 3216.3725204262128
INFO:root:current train perplexity3.5466504096984863
INFO:root:current mean train loss 3216.273949625133
INFO:root:current train perplexity3.547718048095703
INFO:root:current mean train loss 3215.3416720255036
INFO:root:current train perplexity3.5475497245788574
INFO:root:current mean train loss 3214.979818193461
INFO:root:current train perplexity3.5493123531341553
INFO:root:current mean train loss 3214.054328097134
INFO:root:current train perplexity3.55049991607666
INFO:root:current mean train loss 3217.6723733720223
INFO:root:current train perplexity3.5519888401031494
INFO:root:current mean train loss 3217.1315007784337
INFO:root:current train perplexity3.5538291931152344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.14s/it]
INFO:root:final mean train loss: 3213.6456039182603
INFO:root:final train perplexity: 3.553297758102417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.49s/it]
INFO:root:eval mean loss: 4093.7975537455673
INFO:root:eval perplexity: 5.235233783721924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [16:45:32<1:18:02, 312.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.5279092909414
INFO:root:current train perplexity3.5363385677337646
INFO:root:current mean train loss 3200.503724849424
INFO:root:current train perplexity3.54577374458313
INFO:root:current mean train loss 3205.222122465838
INFO:root:current train perplexity3.555502414703369
INFO:root:current mean train loss 3209.849993944797
INFO:root:current train perplexity3.5522732734680176
INFO:root:current mean train loss 3213.2416671083965
INFO:root:current train perplexity3.553504467010498
INFO:root:current mean train loss 3215.1466939395777
INFO:root:current train perplexity3.5520849227905273
INFO:root:current mean train loss 3217.2907042468246
INFO:root:current train perplexity3.5545687675476074
INFO:root:current mean train loss 3217.7575461077904
INFO:root:current train perplexity3.5560357570648193
INFO:root:current mean train loss 3218.9438940401915
INFO:root:current train perplexity3.556094169616699
INFO:root:current mean train loss 3217.9162784689415
INFO:root:current train perplexity3.555161237716675


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it]
INFO:root:final mean train loss: 3214.789929543772
INFO:root:final train perplexity: 3.5549027919769287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.21s/it]
INFO:root:eval mean loss: 4093.3897679105717
INFO:root:eval perplexity: 5.234371185302734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [16:50:40<1:12:32, 310.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.648928587464
INFO:root:current train perplexity3.5744330883026123
INFO:root:current mean train loss 3217.5383339948194
INFO:root:current train perplexity3.561965227127075
INFO:root:current mean train loss 3218.204237668772
INFO:root:current train perplexity3.5522453784942627
INFO:root:current mean train loss 3217.339954780362
INFO:root:current train perplexity3.5487289428710938
INFO:root:current mean train loss 3218.3046649408047
INFO:root:current train perplexity3.5487430095672607
INFO:root:current mean train loss 3216.74555680699
INFO:root:current train perplexity3.5503954887390137
INFO:root:current mean train loss 3218.6963626245224
INFO:root:current train perplexity3.552297830581665
INFO:root:current mean train loss 3216.9499123947744
INFO:root:current train perplexity3.552278518676758
INFO:root:current mean train loss 3216.0528375911604
INFO:root:current train perplexity3.5524466037750244
INFO:root:current mean train loss 3215.6792758991896
INFO:root:current train perplexity3.552633762359619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.19s/it]
INFO:root:final mean train loss: 3212.691294270177
INFO:root:final train perplexity: 3.551959991455078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.25s/it]
INFO:root:eval mean loss: 4094.5612602504434
INFO:root:eval perplexity: 5.236850738525391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [16:55:52<1:07:27, 311.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.8241390830594
INFO:root:current train perplexity3.5469374656677246
INFO:root:current mean train loss 3216.3479179186697
INFO:root:current train perplexity3.550386905670166
INFO:root:current mean train loss 3212.9778800317795
INFO:root:current train perplexity3.548015832901001
INFO:root:current mean train loss 3210.183824910997
INFO:root:current train perplexity3.546146869659424
INFO:root:current mean train loss 3208.831494140625
INFO:root:current train perplexity3.5448882579803467
INFO:root:current mean train loss 3213.219333065257
INFO:root:current train perplexity3.550750970840454
INFO:root:current mean train loss 3216.5295487438175
INFO:root:current train perplexity3.5530407428741455
INFO:root:current mean train loss 3215.944767713247
INFO:root:current train perplexity3.5522217750549316
INFO:root:current mean train loss 3215.030904111383
INFO:root:current train perplexity3.5523195266723633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.26s/it]
INFO:root:final mean train loss: 3212.4141425471153
INFO:root:final train perplexity: 3.551571846008301
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.69s/it]
INFO:root:eval mean loss: 4093.8160738031916
INFO:root:eval perplexity: 5.2352728843688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [17:00:59<1:02:00, 310.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3182.82568359375
INFO:root:current train perplexity3.4947946071624756
INFO:root:current mean train loss 3211.8143369804307
INFO:root:current train perplexity3.532785415649414
INFO:root:current mean train loss 3210.713522023168
INFO:root:current train perplexity3.5428578853607178
INFO:root:current mean train loss 3215.204050800588
INFO:root:current train perplexity3.5506675243377686
INFO:root:current mean train loss 3211.8536810105848
INFO:root:current train perplexity3.549837112426758
INFO:root:current mean train loss 3213.3959262006088
INFO:root:current train perplexity3.5534040927886963
INFO:root:current mean train loss 3210.3356913349917
INFO:root:current train perplexity3.5528197288513184
INFO:root:current mean train loss 3211.7956581169988
INFO:root:current train perplexity3.549485921859741
INFO:root:current mean train loss 3211.6387007583867
INFO:root:current train perplexity3.549212694168091
INFO:root:current mean train loss 3216.288222742767
INFO:root:current train perplexity3.551656484603882


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.44s/it]
INFO:root:final mean train loss: 3212.6315666937057
INFO:root:final train perplexity: 3.551877021789551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.43s/it]
INFO:root:eval mean loss: 4093.943452875665
INFO:root:eval perplexity: 5.2355427742004395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [17:06:12<56:59, 310.86s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3180.5696022727275
INFO:root:current train perplexity3.5374531745910645
INFO:root:current mean train loss 3197.2601109410193
INFO:root:current train perplexity3.5388200283050537
INFO:root:current mean train loss 3212.7613265051095
INFO:root:current train perplexity3.5468740463256836
INFO:root:current mean train loss 3213.9370446895095
INFO:root:current train perplexity3.548434257507324
INFO:root:current mean train loss 3211.450346192594
INFO:root:current train perplexity3.5517284870147705
INFO:root:current mean train loss 3209.5738948217345
INFO:root:current train perplexity3.5497376918792725
INFO:root:current mean train loss 3207.1788455944406
INFO:root:current train perplexity3.546433210372925
INFO:root:current mean train loss 3208.874968752747
INFO:root:current train perplexity3.5478403568267822
INFO:root:current mean train loss 3208.564998904227
INFO:root:current train perplexity3.545957565307617
INFO:root:current mean train loss 3212.1086281065623
INFO:root:current train perplexity3.5483808517456055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.93s/it]
INFO:root:final mean train loss: 3211.1728959237375
INFO:root:final train perplexity: 3.549833297729492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it]
INFO:root:eval mean loss: 4093.3794135776816
INFO:root:eval perplexity: 5.234348773956299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [17:11:19<51:37, 309.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.5578227796054
INFO:root:current train perplexity3.568350076675415
INFO:root:current mean train loss 3229.2727153361343
INFO:root:current train perplexity3.555860757827759
INFO:root:current mean train loss 3223.028371593179
INFO:root:current train perplexity3.5491695404052734
INFO:root:current mean train loss 3224.1914575271844
INFO:root:current train perplexity3.5524351596832275
INFO:root:current mean train loss 3216.5049224343675
INFO:root:current train perplexity3.55057954788208
INFO:root:current mean train loss 3216.4752416004335
INFO:root:current train perplexity3.549748182296753
INFO:root:current mean train loss 3213.7261684830623
INFO:root:current train perplexity3.549201250076294
INFO:root:current mean train loss 3212.9848673559195
INFO:root:current train perplexity3.5485877990722656
INFO:root:current mean train loss 3210.7004045758927
INFO:root:current train perplexity3.5478932857513428
INFO:root:current mean train loss 3211.7589843218684
INFO:root:current train perplexity3.548062801361084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.99s/it]
INFO:root:final mean train loss: 3210.457701959918
INFO:root:final train perplexity: 3.5488321781158447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.10s/it]
INFO:root:eval mean loss: 4095.2325673204787
INFO:root:eval perplexity: 5.2382731437683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [17:16:27<46:22, 309.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.863624855324
INFO:root:current train perplexity3.550039529800415
INFO:root:current mean train loss 3231.471160648376
INFO:root:current train perplexity3.549565076828003
INFO:root:current mean train loss 3223.384786059678
INFO:root:current train perplexity3.552013874053955
INFO:root:current mean train loss 3221.0197417932914
INFO:root:current train perplexity3.5499746799468994
INFO:root:current mean train loss 3216.88988571703
INFO:root:current train perplexity3.54876446723938
INFO:root:current mean train loss 3219.5720557659806
INFO:root:current train perplexity3.5493099689483643
INFO:root:current mean train loss 3214.679988879336
INFO:root:current train perplexity3.547386646270752
INFO:root:current mean train loss 3212.449322182342
INFO:root:current train perplexity3.546201467514038
INFO:root:current mean train loss 3210.9224034301315
INFO:root:current train perplexity3.5463345050811768
INFO:root:current mean train loss 3211.717162164155
INFO:root:current train perplexity3.547511339187622


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.14s/it]
INFO:root:final mean train loss: 3209.933484231272
INFO:root:final train perplexity: 3.548097848892212
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.95s/it]
INFO:root:eval mean loss: 4094.299221174091
INFO:root:eval perplexity: 5.2362961769104
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [17:21:35<41:10, 308.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.043143136161
INFO:root:current train perplexity3.5474298000335693
INFO:root:current mean train loss 3210.3632685908565
INFO:root:current train perplexity3.545055627822876
INFO:root:current mean train loss 3206.7654618932847
INFO:root:current train perplexity3.546318531036377
INFO:root:current mean train loss 3208.6955821478546
INFO:root:current train perplexity3.547020435333252
INFO:root:current mean train loss 3213.021758261494
INFO:root:current train perplexity3.547168016433716
INFO:root:current mean train loss 3207.484826317903
INFO:root:current train perplexity3.5422446727752686
INFO:root:current mean train loss 3209.1935904435286
INFO:root:current train perplexity3.5447328090667725
INFO:root:current mean train loss 3207.7138083944515
INFO:root:current train perplexity3.544712781906128
INFO:root:current mean train loss 3207.909863573634
INFO:root:current train perplexity3.543821334838867
INFO:root:current mean train loss 3209.2365751378675
INFO:root:current train perplexity3.5448501110076904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.45s/it]
INFO:root:final mean train loss: 3208.9886397700157
INFO:root:final train perplexity: 3.546776056289673
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it]
INFO:root:eval mean loss: 4094.1726870705897
INFO:root:eval perplexity: 5.236027717590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [17:26:42<35:59, 308.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.7588174509447
INFO:root:current train perplexity3.5645971298217773
INFO:root:current mean train loss 3211.8018568345715
INFO:root:current train perplexity3.560150384902954
INFO:root:current mean train loss 3210.0002682532795
INFO:root:current train perplexity3.548143148422241
INFO:root:current mean train loss 3206.6676057420736
INFO:root:current train perplexity3.5496487617492676
INFO:root:current mean train loss 3210.9538993060455
INFO:root:current train perplexity3.547006368637085
INFO:root:current mean train loss 3211.037734339031
INFO:root:current train perplexity3.54522705078125
INFO:root:current mean train loss 3210.0528835931423
INFO:root:current train perplexity3.5454299449920654
INFO:root:current mean train loss 3209.6185918836222
INFO:root:current train perplexity3.5444724559783936
INFO:root:current mean train loss 3212.3446605315835
INFO:root:current train perplexity3.545952796936035
INFO:root:current mean train loss 3211.843265343319
INFO:root:current train perplexity3.545301914215088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.39s/it]
INFO:root:final mean train loss: 3208.5082670642482
INFO:root:final train perplexity: 3.5461037158966064
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]
INFO:root:eval mean loss: 4094.8651616522607
INFO:root:eval perplexity: 5.2374958992004395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [17:31:55<30:58, 309.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3181.1660970052085
INFO:root:current train perplexity3.5148541927337646
INFO:root:current mean train loss 3194.3321945493585
INFO:root:current train perplexity3.527602434158325
INFO:root:current mean train loss 3200.384971831424
INFO:root:current train perplexity3.539287567138672
INFO:root:current mean train loss 3202.3590654769855
INFO:root:current train perplexity3.5412211418151855
INFO:root:current mean train loss 3205.214293215597
INFO:root:current train perplexity3.542083263397217
INFO:root:current mean train loss 3207.965684728051
INFO:root:current train perplexity3.5454578399658203
INFO:root:current mean train loss 3211.5418781802036
INFO:root:current train perplexity3.5481605529785156
INFO:root:current mean train loss 3208.710621189976
INFO:root:current train perplexity3.5456130504608154
INFO:root:current mean train loss 3209.852865826509
INFO:root:current train perplexity3.5464165210723877
INFO:root:current mean train loss 3210.487033077846
INFO:root:current train perplexity3.5465826988220215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.46s/it]
INFO:root:final mean train loss: 3208.3514350152786
INFO:root:final train perplexity: 3.5458836555480957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.04s/it]
INFO:root:eval mean loss: 4094.555106521498
INFO:root:eval perplexity: 5.236837863922119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [17:37:03<25:45, 309.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.5338155455506
INFO:root:current train perplexity3.56330943107605
INFO:root:current mean train loss 3219.2307604903694
INFO:root:current train perplexity3.5517215728759766
INFO:root:current mean train loss 3219.181737715673
INFO:root:current train perplexity3.5473713874816895
INFO:root:current mean train loss 3215.670350991252
INFO:root:current train perplexity3.544682502746582
INFO:root:current mean train loss 3212.769636565564
INFO:root:current train perplexity3.544266700744629
INFO:root:current mean train loss 3207.3007650904237
INFO:root:current train perplexity3.542208671569824
INFO:root:current mean train loss 3206.3275741090906
INFO:root:current train perplexity3.5427112579345703
INFO:root:current mean train loss 3207.325970193614
INFO:root:current train perplexity3.543513298034668
INFO:root:current mean train loss 3208.619120161525
INFO:root:current train perplexity3.5424866676330566
INFO:root:current mean train loss 3208.610383130214
INFO:root:current train perplexity3.542827844619751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.79s/it]
INFO:root:final mean train loss: 3206.3011112213135
INFO:root:final train perplexity: 3.5430166721343994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.45s/it]
INFO:root:eval mean loss: 4094.9270746758643
INFO:root:eval perplexity: 5.237626552581787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [17:42:15<20:39, 310.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3219.7187572877797
INFO:root:current train perplexity3.5499839782714844
INFO:root:current mean train loss 3212.4340630262914
INFO:root:current train perplexity3.5508193969726562
INFO:root:current mean train loss 3216.7615486745085
INFO:root:current train perplexity3.5505781173706055
INFO:root:current mean train loss 3215.166811909273
INFO:root:current train perplexity3.547224521636963
INFO:root:current mean train loss 3214.7207726554134
INFO:root:current train perplexity3.5465312004089355
INFO:root:current mean train loss 3213.9011747168483
INFO:root:current train perplexity3.546672821044922
INFO:root:current mean train loss 3210.7035199441293
INFO:root:current train perplexity3.5445289611816406
INFO:root:current mean train loss 3211.352378318021
INFO:root:current train perplexity3.5462989807128906
INFO:root:current mean train loss 3210.4937590672757
INFO:root:current train perplexity3.5458669662475586
INFO:root:current mean train loss 3209.658578551173
INFO:root:current train perplexity3.545060157775879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.99s/it]
INFO:root:final mean train loss: 3207.1551559202135
INFO:root:final train perplexity: 3.544210433959961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.09s/it]
INFO:root:eval mean loss: 4095.3682437112147
INFO:root:eval perplexity: 5.238560676574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [17:47:28<15:32, 310.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.13572265625
INFO:root:current train perplexity3.5363500118255615
INFO:root:current mean train loss 3207.413657924107
INFO:root:current train perplexity3.537964105606079
INFO:root:current mean train loss 3204.039019886364
INFO:root:current train perplexity3.538064479827881
INFO:root:current mean train loss 3201.4121451822916
INFO:root:current train perplexity3.537254810333252
INFO:root:current mean train loss 3204.4579970189143
INFO:root:current train perplexity3.535740613937378
INFO:root:current mean train loss 3206.177882982337
INFO:root:current train perplexity3.5361151695251465
INFO:root:current mean train loss 3208.003752170139
INFO:root:current train perplexity3.538945436477661
INFO:root:current mean train loss 3206.511382938508
INFO:root:current train perplexity3.539081573486328
INFO:root:current mean train loss 3208.5867592075892
INFO:root:current train perplexity3.540109395980835
INFO:root:current mean train loss 3207.7717693309296
INFO:root:current train perplexity3.5418503284454346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it]
INFO:root:final mean train loss: 3205.497598586544
INFO:root:final train perplexity: 3.541893720626831
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.91s/it]
INFO:root:eval mean loss: 4095.502306349734
INFO:root:eval perplexity: 5.23884391784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [17:52:35<10:19, 309.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.5770690182603
INFO:root:current train perplexity3.5410680770874023
INFO:root:current mean train loss 3212.7778667178964
INFO:root:current train perplexity3.5447559356689453
INFO:root:current mean train loss 3214.966583791133
INFO:root:current train perplexity3.550788640975952
INFO:root:current mean train loss 3211.303865836121
INFO:root:current train perplexity3.5476648807525635
INFO:root:current mean train loss 3204.9940172910196
INFO:root:current train perplexity3.546506643295288
INFO:root:current mean train loss 3208.7058704304245
INFO:root:current train perplexity3.549429178237915
INFO:root:current mean train loss 3209.626749019148
INFO:root:current train perplexity3.545976161956787
INFO:root:current mean train loss 3209.143696869013
INFO:root:current train perplexity3.5433003902435303
INFO:root:current mean train loss 3209.064740121567
INFO:root:current train perplexity3.541317939758301
INFO:root:current mean train loss 3208.7944174501686
INFO:root:current train perplexity3.542397975921631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.94s/it]
INFO:root:final mean train loss: 3205.7533765608264
INFO:root:final train perplexity: 3.5422513484954834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.19s/it]
INFO:root:eval mean loss: 4095.365057762633
INFO:root:eval perplexity: 5.238553524017334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [17:57:41<05:08, 308.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3205.2159356756524
INFO:root:current train perplexity3.550790309906006
INFO:root:current mean train loss 3202.3100918275522
INFO:root:current train perplexity3.5343406200408936
INFO:root:current mean train loss 3200.3023140504188
INFO:root:current train perplexity3.537382125854492
INFO:root:current mean train loss 3203.431354025136
INFO:root:current train perplexity3.537295341491699
INFO:root:current mean train loss 3206.2428776572046
INFO:root:current train perplexity3.5402626991271973
INFO:root:current mean train loss 3206.014174614663
INFO:root:current train perplexity3.542797803878784
INFO:root:current mean train loss 3205.089014519831
INFO:root:current train perplexity3.541274070739746
INFO:root:current mean train loss 3207.2861254049462
INFO:root:current train perplexity3.541816473007202
INFO:root:current mean train loss 3209.2328293240566
INFO:root:current train perplexity3.543926239013672
INFO:root:current mean train loss 3208.995270668438
INFO:root:current train perplexity3.543227434158325


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.42s/it]
INFO:root:final mean train loss: 3206.432961986911
INFO:root:final train perplexity: 3.543201208114624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.03s/it]
INFO:root:eval mean loss: 4095.368744112921
INFO:root:eval perplexity: 5.238561153411865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_140/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:02:50<00:00, 308.60s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:02:50<00:00, 324.85s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 4095.368744112921
INFO:root:eval perplexity: 5.238561153411865
INFO:root:evalaution complete
INFO:root:save model final: small_val_140/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x151151e55f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x151151e4d8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x151151d72e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x151151e56a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x151151d70948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x151151e56a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x151151d2bb46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x15115179046a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x15124dfaca27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x15124dfacbe0]
python(+0x24a989) [0x562ca108c989]
python(+0x24a9bd) [0x562ca108c9bd]
python(+0x24aa14) [0x562ca108ca14]
python(+0x108f75) [0x562ca0f4af75]
python(Py_RunMain+0x313) [0x562ca108f983]
python(Py_BytesMain+0x39) [0x562ca108fbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x15124df8a0b3]
python(+0x1d6e13) [0x562ca1018e13]
/opt/slurm/data/slurmd/job26146198/slurm_script: line 132: 654903 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_140_final  --output small_val_140 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
