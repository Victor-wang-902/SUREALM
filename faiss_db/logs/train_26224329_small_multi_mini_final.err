INFO:root:Output: small_multiqa_minilm_final
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.bias', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23771.9817511048
INFO:root:current train perplexity11839.4033203125
INFO:root:current mean train loss 19970.883612397927
INFO:root:current train perplexity2619.5517578125
INFO:root:current mean train loss 17324.50145667851
INFO:root:current train perplexity925.4620971679688
INFO:root:current mean train loss 15534.895172501567
INFO:root:current train perplexity453.26654052734375
INFO:root:current mean train loss 14234.688692815318
INFO:root:current train perplexity271.492431640625
INFO:root:current mean train loss 13241.447453111958
INFO:root:current train perplexity184.1100616455078
INFO:root:current mean train loss 12469.767961624866
INFO:root:current train perplexity135.80674743652344
INFO:root:current mean train loss 11847.35738276361
INFO:root:current train perplexity106.50946807861328
INFO:root:current mean train loss 11336.610965308677
INFO:root:current train perplexity87.12782287597656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.79s/it]
INFO:root:final mean train loss: 10922.777392110516
INFO:root:final train perplexity: 74.39222717285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 6471.565737893396
INFO:root:eval perplexity: 13.69336223602295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 6962.345280640514
INFO:root:eval perplexity: 17.235973358154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/1
  0%|          | 1/200 [04:23<14:35:07, 263.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6884.845145089285
INFO:root:current train perplexity15.263092041015625
INFO:root:current mean train loss 6893.414532527745
INFO:root:current train perplexity14.80628776550293
INFO:root:current mean train loss 6794.109455200785
INFO:root:current train perplexity14.440576553344727
INFO:root:current mean train loss 6704.079349679357
INFO:root:current train perplexity14.038067817687988
INFO:root:current mean train loss 6634.128487551828
INFO:root:current train perplexity13.705397605895996
INFO:root:current mean train loss 6581.338965421598
INFO:root:current train perplexity13.379166603088379
INFO:root:current mean train loss 6528.287027324444
INFO:root:current train perplexity13.093795776367188
INFO:root:current mean train loss 6482.493377469723
INFO:root:current train perplexity12.858641624450684
INFO:root:current mean train loss 6435.100268282412
INFO:root:current train perplexity12.636137962341309
INFO:root:current mean train loss 6389.613798602019
INFO:root:current train perplexity12.423968315124512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.11s/it]
INFO:root:final mean train loss: 6354.254592649399
INFO:root:final train perplexity: 12.267300605773926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 5571.982664284131
INFO:root:eval perplexity: 9.517632484436035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 6175.102881898271
INFO:root:eval perplexity: 12.491950988769531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/2
  1%|          | 2/200 [08:45<14:26:46, 262.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5938.389680989583
INFO:root:current train perplexity10.476872444152832
INFO:root:current mean train loss 5856.292051630435
INFO:root:current train perplexity10.23399543762207
INFO:root:current mean train loss 5861.499400436047
INFO:root:current train perplexity10.157768249511719
INFO:root:current mean train loss 5840.116486855159
INFO:root:current train perplexity10.058449745178223
INFO:root:current mean train loss 5827.064061323419
INFO:root:current train perplexity9.977937698364258
INFO:root:current mean train loss 5817.541706803701
INFO:root:current train perplexity9.906363487243652
INFO:root:current mean train loss 5790.365685340447
INFO:root:current train perplexity9.803821563720703
INFO:root:current mean train loss 5765.661287833261
INFO:root:current train perplexity9.721763610839844
INFO:root:current mean train loss 5752.468157472201
INFO:root:current train perplexity9.659592628479004
INFO:root:current mean train loss 5731.647598083163
INFO:root:current train perplexity9.573853492736816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.79s/it]
INFO:root:final mean train loss: 5710.742683533699
INFO:root:final train perplexity: 9.51675033569336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 5195.203460909796
INFO:root:eval perplexity: 8.172606468200684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it]
INFO:root:eval mean loss: 5858.607390708112
INFO:root:eval perplexity: 10.975496292114258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/3
  2%|â–         | 3/200 [13:06<14:19:05, 261.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5602.93212890625
INFO:root:current train perplexity8.81299114227295
INFO:root:current mean train loss 5505.251258415905
INFO:root:current train perplexity8.74629020690918
INFO:root:current mean train loss 5491.641864314742
INFO:root:current train perplexity8.719969749450684
INFO:root:current mean train loss 5468.307827314725
INFO:root:current train perplexity8.638922691345215
INFO:root:current mean train loss 5462.8477243554225
INFO:root:current train perplexity8.590246200561523
INFO:root:current mean train loss 5444.462767387668
INFO:root:current train perplexity8.539080619812012
INFO:root:current mean train loss 5435.79088473741
INFO:root:current train perplexity8.501214027404785
INFO:root:current mean train loss 5422.489589411523
INFO:root:current train perplexity8.46554183959961
INFO:root:current mean train loss 5404.8249218038045
INFO:root:current train perplexity8.430294036865234
INFO:root:current mean train loss 5392.435994951076
INFO:root:current train perplexity8.382673263549805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.54s/it]
INFO:root:final mean train loss: 5380.490494020523
INFO:root:final train perplexity: 8.354155540466309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 4966.150501440603
INFO:root:eval perplexity: 7.449639320373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 5665.243357989805
INFO:root:eval perplexity: 10.141093254089355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/4
  2%|â–         | 4/200 [17:24<14:10:42, 260.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5199.7044323336695
INFO:root:current train perplexity7.849479675292969
INFO:root:current mean train loss 5219.218198354008
INFO:root:current train perplexity7.852097988128662
INFO:root:current mean train loss 5213.51142282197
INFO:root:current train perplexity7.846408843994141
INFO:root:current mean train loss 5218.15818689813
INFO:root:current train perplexity7.835048675537109
INFO:root:current mean train loss 5218.878913047419
INFO:root:current train perplexity7.819458961486816
INFO:root:current mean train loss 5200.613803554614
INFO:root:current train perplexity7.778290271759033
INFO:root:current mean train loss 5192.331909760053
INFO:root:current train perplexity7.754603385925293
INFO:root:current mean train loss 5190.368695761372
INFO:root:current train perplexity7.738649845123291
INFO:root:current mean train loss 5177.275412365561
INFO:root:current train perplexity7.7024407386779785
INFO:root:current mean train loss 5170.285722152759
INFO:root:current train perplexity7.68179988861084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it]
INFO:root:final mean train loss: 5164.317164390318
INFO:root:final train perplexity: 7.6711955070495605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4808.461889821587
INFO:root:eval perplexity: 6.989442348480225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 5526.325818650266
INFO:root:eval perplexity: 9.58108139038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/5
  2%|â–Ž         | 5/200 [21:45<14:06:41, 260.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5145.298026842948
INFO:root:current train perplexity7.493058204650879
INFO:root:current mean train loss 5070.736939354766
INFO:root:current train perplexity7.360949993133545
INFO:root:current mean train loss 5067.151015788441
INFO:root:current train perplexity7.3397603034973145
INFO:root:current mean train loss 5051.991769796276
INFO:root:current train perplexity7.319794178009033
INFO:root:current mean train loss 5044.227164231564
INFO:root:current train perplexity7.306551933288574
INFO:root:current mean train loss 5039.367370492231
INFO:root:current train perplexity7.287082672119141
INFO:root:current mean train loss 5032.260351715327
INFO:root:current train perplexity7.271961688995361
INFO:root:current mean train loss 5024.72321853328
INFO:root:current train perplexity7.254968643188477
INFO:root:current mean train loss 5017.791449200126
INFO:root:current train perplexity7.236151695251465
INFO:root:current mean train loss 5008.665867424621
INFO:root:current train perplexity7.2101969718933105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.86s/it]
INFO:root:final mean train loss: 5007.439088882938
INFO:root:final train perplexity: 7.210798740386963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 4700.571067431294
INFO:root:eval perplexity: 6.691064834594727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.28s/it]
INFO:root:eval mean loss: 5436.726382424646
INFO:root:eval perplexity: 9.236401557922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/6
  3%|â–Ž         | 6/200 [26:03<13:59:31, 259.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4968.034730302526
INFO:root:current train perplexity7.028501987457275
INFO:root:current mean train loss 4903.169762436224
INFO:root:current train perplexity6.928394317626953
INFO:root:current mean train loss 4906.16118816422
INFO:root:current train perplexity6.937838554382324
INFO:root:current mean train loss 4920.156674959474
INFO:root:current train perplexity6.936407566070557
INFO:root:current mean train loss 4921.922883240702
INFO:root:current train perplexity6.944910049438477
INFO:root:current mean train loss 4910.307580588723
INFO:root:current train perplexity6.9236159324646
INFO:root:current mean train loss 4901.531603947305
INFO:root:current train perplexity6.91370964050293
INFO:root:current mean train loss 4901.155212647465
INFO:root:current train perplexity6.903717517852783
INFO:root:current mean train loss 4897.378414509851
INFO:root:current train perplexity6.893757343292236
INFO:root:current mean train loss 4890.008910230497
INFO:root:current train perplexity6.873903274536133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.77s/it]
INFO:root:final mean train loss: 4886.579164197368
INFO:root:final train perplexity: 6.875037670135498
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 4608.331870221077
INFO:root:eval perplexity: 6.44609260559082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 5355.636091949246
INFO:root:eval perplexity: 8.935152053833008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/7
  4%|â–Ž         | 7/200 [30:21<13:54:00, 259.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4801.969113991478
INFO:root:current train perplexity6.6304755210876465
INFO:root:current mean train loss 4805.307399823589
INFO:root:current train perplexity6.668601989746094
INFO:root:current mean train loss 4799.464125689338
INFO:root:current train perplexity6.663540840148926
INFO:root:current mean train loss 4797.2972697513205
INFO:root:current train perplexity6.657097816467285
INFO:root:current mean train loss 4798.939680631868
INFO:root:current train perplexity6.650317192077637
INFO:root:current mean train loss 4794.419330658784
INFO:root:current train perplexity6.641768455505371
INFO:root:current mean train loss 4793.598378608063
INFO:root:current train perplexity6.637043476104736
INFO:root:current mean train loss 4791.0510599906875
INFO:root:current train perplexity6.625234127044678
INFO:root:current mean train loss 4795.461414930555
INFO:root:current train perplexity6.62706184387207
INFO:root:current mean train loss 4790.723237585897
INFO:root:current train perplexity6.613691329956055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.05s/it]
INFO:root:final mean train loss: 4788.3538945105765
INFO:root:final train perplexity: 6.613706111907959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4537.250727227393
INFO:root:eval perplexity: 6.263449668884277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 5291.683676861702
INFO:root:eval perplexity: 8.70451831817627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/8
  4%|â–         | 8/200 [34:42<13:51:15, 259.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4731.680772569444
INFO:root:current train perplexity6.410019874572754
INFO:root:current mean train loss 4735.4988317197085
INFO:root:current train perplexity6.437315940856934
INFO:root:current mean train loss 4738.097089992277
INFO:root:current train perplexity6.440182685852051
INFO:root:current mean train loss 4736.555767637311
INFO:root:current train perplexity6.446040153503418
INFO:root:current mean train loss 4732.831818220167
INFO:root:current train perplexity6.431138515472412
INFO:root:current mean train loss 4722.592053591252
INFO:root:current train perplexity6.422473430633545
INFO:root:current mean train loss 4720.660245363169
INFO:root:current train perplexity6.42659854888916
INFO:root:current mean train loss 4716.039572539523
INFO:root:current train perplexity6.4165849685668945
INFO:root:current mean train loss 4712.034514072458
INFO:root:current train perplexity6.410016059875488
INFO:root:current mean train loss 4709.741311331775
INFO:root:current train perplexity6.4043288230896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.38s/it]
INFO:root:final mean train loss: 4706.104021749189
INFO:root:final train perplexity: 6.402535438537598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 4480.128017993684
INFO:root:eval perplexity: 6.120429515838623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 5243.035828069592
INFO:root:eval perplexity: 8.53307056427002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/9
  4%|â–         | 9/200 [39:01<13:46:06, 259.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4666.34023575044
INFO:root:current train perplexity6.295820713043213
INFO:root:current mean train loss 4655.5791015625
INFO:root:current train perplexity6.268585205078125
INFO:root:current mean train loss 4649.520743845133
INFO:root:current train perplexity6.2758612632751465
INFO:root:current mean train loss 4637.642689995368
INFO:root:current train perplexity6.254508972167969
INFO:root:current mean train loss 4647.712723717821
INFO:root:current train perplexity6.256398677825928
INFO:root:current mean train loss 4636.832230496114
INFO:root:current train perplexity6.243949890136719
INFO:root:current mean train loss 4634.174291664726
INFO:root:current train perplexity6.241087436676025
INFO:root:current mean train loss 4634.234253404669
INFO:root:current train perplexity6.227378845214844
INFO:root:current mean train loss 4636.895951806472
INFO:root:current train perplexity6.228952884674072
INFO:root:current mean train loss 4638.444015361499
INFO:root:current train perplexity6.2271013259887695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.84s/it]
INFO:root:final mean train loss: 4636.573843433011
INFO:root:final train perplexity: 6.229290008544922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 4431.813015985151
INFO:root:eval perplexity: 6.00201416015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]
INFO:root:eval mean loss: 5201.394354637633
INFO:root:eval perplexity: 8.389002799987793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/10
  5%|â–Œ         | 10/200 [43:22<13:42:45, 259.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4596.047931912579
INFO:root:current train perplexity6.078862190246582
INFO:root:current mean train loss 4587.196996933921
INFO:root:current train perplexity6.085952281951904
INFO:root:current mean train loss 4581.058171973006
INFO:root:current train perplexity6.088556289672852
INFO:root:current mean train loss 4581.731111632173
INFO:root:current train perplexity6.081118583679199
INFO:root:current mean train loss 4585.77947628523
INFO:root:current train perplexity6.088066577911377
INFO:root:current mean train loss 4584.8976380343265
INFO:root:current train perplexity6.085935592651367
INFO:root:current mean train loss 4584.641749700847
INFO:root:current train perplexity6.089870452880859
INFO:root:current mean train loss 4582.0973741876605
INFO:root:current train perplexity6.085431098937988
INFO:root:current mean train loss 4581.284326338524
INFO:root:current train perplexity6.083779811859131
INFO:root:current mean train loss 4577.616301710929
INFO:root:current train perplexity6.077250003814697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.06s/it]
INFO:root:final mean train loss: 4575.147629030289
INFO:root:final train perplexity: 6.080143451690674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4389.308817112699
INFO:root:eval perplexity: 5.899734973907471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 5163.235197459552
INFO:root:eval perplexity: 8.259116172790527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/11
  6%|â–Œ         | 11/200 [47:39<13:36:32, 259.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4520.141323747306
INFO:root:current train perplexity5.992528915405273
INFO:root:current mean train loss 4529.482374874666
INFO:root:current train perplexity5.989808559417725
INFO:root:current mean train loss 4527.522447326873
INFO:root:current train perplexity5.978592395782471
INFO:root:current mean train loss 4523.222095420502
INFO:root:current train perplexity5.96865177154541
INFO:root:current mean train loss 4522.412437736621
INFO:root:current train perplexity5.9628400802612305
INFO:root:current mean train loss 4528.128888781676
INFO:root:current train perplexity5.960538387298584
INFO:root:current mean train loss 4528.490476738764
INFO:root:current train perplexity5.963238716125488
INFO:root:current mean train loss 4529.197419492535
INFO:root:current train perplexity5.965348243713379
INFO:root:current mean train loss 4526.366416544091
INFO:root:current train perplexity5.957719326019287
INFO:root:current mean train loss 4525.239424530617
INFO:root:current train perplexity5.952981472015381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.16s/it]
INFO:root:final mean train loss: 4521.418693234844
INFO:root:final train perplexity: 5.952613830566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 4349.242178842531
INFO:root:eval perplexity: 5.804920196533203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5131.689411569149
INFO:root:eval perplexity: 8.153264999389648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/12
  6%|â–Œ         | 12/200 [51:57<13:30:46, 258.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4472.9131861636515
INFO:root:current train perplexity5.871529579162598
INFO:root:current mean train loss 4470.296797375801
INFO:root:current train perplexity5.86245584487915
INFO:root:current mean train loss 4474.880086400954
INFO:root:current train perplexity5.851310729980469
INFO:root:current mean train loss 4476.136710714992
INFO:root:current train perplexity5.8465752601623535
INFO:root:current mean train loss 4472.711473129735
INFO:root:current train perplexity5.841536045074463
INFO:root:current mean train loss 4476.490104713761
INFO:root:current train perplexity5.838273048400879
INFO:root:current mean train loss 4472.919874803282
INFO:root:current train perplexity5.837380886077881
INFO:root:current mean train loss 4471.4770722779085
INFO:root:current train perplexity5.83583402633667
INFO:root:current mean train loss 4472.07509083668
INFO:root:current train perplexity5.835421085357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.93s/it]
INFO:root:final mean train loss: 4473.251446385538
INFO:root:final train perplexity: 5.84056282043457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4326.2666864056955
INFO:root:eval perplexity: 5.751238822937012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 5114.864347850177
INFO:root:eval perplexity: 8.097362518310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/13
  6%|â–‹         | 13/200 [56:16<13:26:34, 258.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4564.002766927083
INFO:root:current train perplexity5.898662090301514
INFO:root:current mean train loss 4448.683643526244
INFO:root:current train perplexity5.758288860321045
INFO:root:current mean train loss 4438.7934774765245
INFO:root:current train perplexity5.742659568786621
INFO:root:current mean train loss 4432.031739892739
INFO:root:current train perplexity5.741701602935791
INFO:root:current mean train loss 4433.508441328707
INFO:root:current train perplexity5.740207195281982
INFO:root:current mean train loss 4436.349293399758
INFO:root:current train perplexity5.752450942993164
INFO:root:current mean train loss 4435.353290108701
INFO:root:current train perplexity5.752902984619141
INFO:root:current mean train loss 4431.6268284500575
INFO:root:current train perplexity5.748629570007324
INFO:root:current mean train loss 4432.108272262706
INFO:root:current train perplexity5.745815753936768
INFO:root:current mean train loss 4431.888742710928
INFO:root:current train perplexity5.7406511306762695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.45s/it]
INFO:root:final mean train loss: 4427.877525083481
INFO:root:final train perplexity: 5.736939430236816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 4290.685321780807
INFO:root:eval perplexity: 5.6690826416015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.77s/it]
INFO:root:eval mean loss: 5085.261644295767
INFO:root:eval perplexity: 7.999933242797852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/14
  7%|â–‹         | 14/200 [1:00:37<13:24:29, 259.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4490.157559481534
INFO:root:current train perplexity5.6775312423706055
INFO:root:current mean train loss 4402.974624771256
INFO:root:current train perplexity5.672767162322998
INFO:root:current mean train loss 4402.824318257553
INFO:root:current train perplexity5.676624298095703
INFO:root:current mean train loss 4402.6481941443935
INFO:root:current train perplexity5.670296669006348
INFO:root:current mean train loss 4387.585335167655
INFO:root:current train perplexity5.649784088134766
INFO:root:current mean train loss 4392.435796748869
INFO:root:current train perplexity5.651612281799316
INFO:root:current mean train loss 4392.788549045494
INFO:root:current train perplexity5.65451192855835
INFO:root:current mean train loss 4394.090278121154
INFO:root:current train perplexity5.652573108673096
INFO:root:current mean train loss 4395.060775361725
INFO:root:current train perplexity5.6523332595825195
INFO:root:current mean train loss 4396.980552363474
INFO:root:current train perplexity5.657088756561279

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.90s/it]
INFO:root:final mean train loss: 4390.249916999571
INFO:root:final train perplexity: 5.652402400970459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 4265.207439882535
INFO:root:eval perplexity: 5.610975742340088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.34s/it]
INFO:root:eval mean loss: 5061.4805535931955
INFO:root:eval perplexity: 7.922515869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/15
  8%|â–Š         | 15/200 [1:04:56<13:19:01, 259.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4322.94144479852
INFO:root:current train perplexity5.547468662261963
INFO:root:current mean train loss 4383.501438172925
INFO:root:current train perplexity5.579944133758545
INFO:root:current mean train loss 4372.436813284818
INFO:root:current train perplexity5.571845054626465
INFO:root:current mean train loss 4364.549752644984
INFO:root:current train perplexity5.579522609710693
INFO:root:current mean train loss 4362.353038414566
INFO:root:current train perplexity5.576626777648926
INFO:root:current mean train loss 4359.471919594473
INFO:root:current train perplexity5.56925630569458
INFO:root:current mean train loss 4357.870224072975
INFO:root:current train perplexity5.566733360290527
INFO:root:current mean train loss 4360.88214119817
INFO:root:current train perplexity5.573550701141357
INFO:root:current mean train loss 4359.231398809524
INFO:root:current train perplexity5.573049545288086
INFO:root:current mean train loss 4359.138534794954
INFO:root:current train perplexity5.573002815246582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.64s/it]
INFO:root:final mean train loss: 4352.349682838686
INFO:root:final train perplexity: 5.568512439727783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 4249.973703803746
INFO:root:eval perplexity: 5.576518535614014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 5057.267325326906
INFO:root:eval perplexity: 7.908878803253174
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/16
  8%|â–Š         | 16/200 [1:09:14<13:14:01, 258.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4258.243715639467
INFO:root:current train perplexity5.308929920196533
INFO:root:current mean train loss 4320.677234559547
INFO:root:current train perplexity5.454705238342285
INFO:root:current mean train loss 4337.552523575166
INFO:root:current train perplexity5.500368118286133
INFO:root:current mean train loss 4323.652568478832
INFO:root:current train perplexity5.484052658081055
INFO:root:current mean train loss 4311.051545690318
INFO:root:current train perplexity5.479907512664795
INFO:root:current mean train loss 4307.344617695238
INFO:root:current train perplexity5.475123882293701
INFO:root:current mean train loss 4308.75634765625
INFO:root:current train perplexity5.472259998321533
INFO:root:current mean train loss 4306.523351194442
INFO:root:current train perplexity5.47360897064209
INFO:root:current mean train loss 4314.241653165621
INFO:root:current train perplexity5.485893249511719
INFO:root:current mean train loss 4317.632941812888
INFO:root:current train perplexity5.488065242767334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.76s/it]
INFO:root:final mean train loss: 4318.641300324471
INFO:root:final train perplexity: 5.4949469566345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 4226.177831338652
INFO:root:eval perplexity: 5.523115158081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 5029.527499584441
INFO:root:eval perplexity: 7.819674968719482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/17
  8%|â–Š         | 17/200 [1:13:35<13:11:18, 259.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4271.936928013393
INFO:root:current train perplexity5.447912693023682
INFO:root:current mean train loss 4281.217446108218
INFO:root:current train perplexity5.397238731384277
INFO:root:current mean train loss 4291.659239943484
INFO:root:current train perplexity5.409206867218018
INFO:root:current mean train loss 4286.299602815998
INFO:root:current train perplexity5.413527011871338
INFO:root:current mean train loss 4296.12758676814
INFO:root:current train perplexity5.432543754577637
INFO:root:current mean train loss 4290.856553464515
INFO:root:current train perplexity5.433492660522461
INFO:root:current mean train loss 4297.834982468012
INFO:root:current train perplexity5.433101177215576
INFO:root:current mean train loss 4293.100789221939
INFO:root:current train perplexity5.430073261260986
INFO:root:current mean train loss 4291.126344089165
INFO:root:current train perplexity5.426869869232178
INFO:root:current mean train loss 4288.112725079378
INFO:root:current train perplexity5.424386024475098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.81s/it]
INFO:root:final mean train loss: 4286.327703106788
INFO:root:final train perplexity: 5.425338268280029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 4207.920552138741
INFO:root:eval perplexity: 5.482490062713623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5018.122596686613
INFO:root:eval perplexity: 7.783291339874268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/18
  9%|â–‰         | 18/200 [1:17:53<13:06:04, 259.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4193.284020712209
INFO:root:current train perplexity5.2937331199646
INFO:root:current mean train loss 4242.889315518466
INFO:root:current train perplexity5.338271141052246
INFO:root:current mean train loss 4243.924043129501
INFO:root:current train perplexity5.339982509613037
INFO:root:current mean train loss 4253.868922820244
INFO:root:current train perplexity5.3590803146362305
INFO:root:current mean train loss 4249.815524477991
INFO:root:current train perplexity5.354360103607178
INFO:root:current mean train loss 4254.1735268833445
INFO:root:current train perplexity5.3584184646606445
INFO:root:current mean train loss 4258.903273610638
INFO:root:current train perplexity5.36468505859375
INFO:root:current mean train loss 4258.063928041933
INFO:root:current train perplexity5.363630294799805
INFO:root:current mean train loss 4263.06672105529
INFO:root:current train perplexity5.366462707519531
INFO:root:current mean train loss 4260.109038173963
INFO:root:current train perplexity5.36511754989624

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.17s/it]
INFO:root:final mean train loss: 4256.517677860876
INFO:root:final train perplexity: 5.3619065284729
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4188.944202612478
INFO:root:eval perplexity: 5.440581798553467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 5006.6090460161795
INFO:root:eval perplexity: 7.74673318862915
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/19
 10%|â–‰         | 19/200 [1:22:14<13:03:31, 259.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4246.55855066636
INFO:root:current train perplexity5.304812431335449
INFO:root:current mean train loss 4241.876865816432
INFO:root:current train perplexity5.3182806968688965
INFO:root:current mean train loss 4236.453075393738
INFO:root:current train perplexity5.309151649475098
INFO:root:current mean train loss 4228.556383268786
INFO:root:current train perplexity5.294766902923584
INFO:root:current mean train loss 4232.829093983855
INFO:root:current train perplexity5.2976861000061035
INFO:root:current mean train loss 4233.822611675505
INFO:root:current train perplexity5.306420803070068
INFO:root:current mean train loss 4230.624615975423
INFO:root:current train perplexity5.304973602294922
INFO:root:current mean train loss 4231.06899297031
INFO:root:current train perplexity5.308488368988037
INFO:root:current mean train loss 4237.888386135796
INFO:root:current train perplexity5.313022136688232
INFO:root:current mean train loss 4233.13165546341
INFO:root:current train perplexity5.307530403137207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.24s/it]
INFO:root:final mean train loss: 4230.7766353853285
INFO:root:final train perplexity: 5.3077263832092285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 4176.737372215758
INFO:root:eval perplexity: 5.413793563842773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.39s/it]
INFO:root:eval mean loss: 4996.537566489362
INFO:root:eval perplexity: 7.7148942947387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/20
 10%|â–ˆ         | 20/200 [1:26:33<12:58:13, 259.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4199.905720338983
INFO:root:current train perplexity5.249664783477783
INFO:root:current mean train loss 4205.967222201749
INFO:root:current train perplexity5.251321792602539
INFO:root:current mean train loss 4211.218199505309
INFO:root:current train perplexity5.255732536315918
INFO:root:current mean train loss 4211.6426332096535
INFO:root:current train perplexity5.254514694213867
INFO:root:current mean train loss 4215.300492961942
INFO:root:current train perplexity5.2620463371276855
INFO:root:current mean train loss 4215.834527686158
INFO:root:current train perplexity5.261436939239502
INFO:root:current mean train loss 4210.136682814278
INFO:root:current train perplexity5.254507064819336
INFO:root:current mean train loss 4206.630971312994
INFO:root:current train perplexity5.251888751983643
INFO:root:current mean train loss 4204.544132041709
INFO:root:current train perplexity5.252118110656738
INFO:root:current mean train loss 4207.84823948897
INFO:root:current train perplexity5.251743793487549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.41s/it]
INFO:root:final mean train loss: 4204.720096095915
INFO:root:final train perplexity: 5.253443241119385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4158.595323927859
INFO:root:eval perplexity: 5.3742218017578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.48s/it]
INFO:root:eval mean loss: 4977.703786430629
INFO:root:eval perplexity: 7.655707359313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/21
 10%|â–ˆ         | 21/200 [1:30:52<12:53:25, 259.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4199.751796437733
INFO:root:current train perplexity5.213507175445557
INFO:root:current mean train loss 4199.854574055015
INFO:root:current train perplexity5.227323532104492
INFO:root:current mean train loss 4193.822665210967
INFO:root:current train perplexity5.212706565856934
INFO:root:current mean train loss 4186.210505098348
INFO:root:current train perplexity5.2042388916015625
INFO:root:current mean train loss 4189.543206617204
INFO:root:current train perplexity5.206333160400391
INFO:root:current mean train loss 4190.793666294643
INFO:root:current train perplexity5.208609580993652
INFO:root:current mean train loss 4182.49491257789
INFO:root:current train perplexity5.202375411987305
INFO:root:current mean train loss 4182.990775176723
INFO:root:current train perplexity5.199629783630371
INFO:root:current mean train loss 4184.049895078666
INFO:root:current train perplexity5.202686309814453
INFO:root:current mean train loss 4183.445025186627
INFO:root:current train perplexity5.2025275230407715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.77s/it]
INFO:root:final mean train loss: 4179.767468114053
INFO:root:final train perplexity: 5.201980113983154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 4147.890583444149
INFO:root:eval perplexity: 5.351009368896484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.71s/it]
INFO:root:eval mean loss: 4971.2020116494905
INFO:root:eval perplexity: 7.635380744934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/22
 11%|â–ˆ         | 22/200 [1:35:13<12:51:04, 259.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4156.326057942709
INFO:root:current train perplexity5.117618083953857
INFO:root:current mean train loss 4156.5239453125
INFO:root:current train perplexity5.123111724853516
INFO:root:current mean train loss 4166.769102450284
INFO:root:current train perplexity5.1457624435424805
INFO:root:current mean train loss 4153.655706380208
INFO:root:current train perplexity5.1398539543151855
INFO:root:current mean train loss 4160.378019120066
INFO:root:current train perplexity5.140583038330078
INFO:root:current mean train loss 4163.468531759511
INFO:root:current train perplexity5.147547245025635
INFO:root:current mean train loss 4167.952858072917
INFO:root:current train perplexity5.158501148223877
INFO:root:current mean train loss 4164.668929876512
INFO:root:current train perplexity5.158419609069824
INFO:root:current mean train loss 4162.403430245536
INFO:root:current train perplexity5.156356334686279
INFO:root:current mean train loss 4161.178714443109
INFO:root:current train perplexity5.15630578994751

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.01s/it]
INFO:root:final mean train loss: 4157.344406804731
INFO:root:final train perplexity: 5.156163215637207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.17s/it]
INFO:root:eval mean loss: 4135.931524614915
INFO:root:eval perplexity: 5.325194358825684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 4962.2891179078015
INFO:root:eval perplexity: 7.607602596282959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/23
 12%|â–ˆâ–        | 23/200 [1:39:34<12:47:30, 260.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4135.108630812312
INFO:root:current train perplexity5.1088480949401855
INFO:root:current mean train loss 4144.146551080089
INFO:root:current train perplexity5.125560760498047
INFO:root:current mean train loss 4148.35676709502
INFO:root:current train perplexity5.124122142791748
INFO:root:current mean train loss 4156.771465251713
INFO:root:current train perplexity5.129181385040283
INFO:root:current mean train loss 4147.425880321558
INFO:root:current train perplexity5.121830463409424
INFO:root:current mean train loss 4143.978084714703
INFO:root:current train perplexity5.114498615264893
INFO:root:current mean train loss 4145.223493048247
INFO:root:current train perplexity5.113208770751953
INFO:root:current mean train loss 4141.523079551804
INFO:root:current train perplexity5.111303329467773
INFO:root:current mean train loss 4140.734923279569
INFO:root:current train perplexity5.114713668823242
INFO:root:current mean train loss 4139.356462697895
INFO:root:current train perplexity5.1125569343566895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.32s/it]
INFO:root:final mean train loss: 4135.50795924279
INFO:root:final train perplexity: 5.11193323135376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4121.948410142398
INFO:root:eval perplexity: 5.295168399810791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 4953.773354388298
INFO:root:eval perplexity: 7.58115816116333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/24
 12%|â–ˆâ–        | 24/200 [1:43:52<12:41:43, 259.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4130.761946793441
INFO:root:current train perplexity5.046841144561768
INFO:root:current mean train loss 4119.454003139316
INFO:root:current train perplexity5.057066917419434
INFO:root:current mean train loss 4107.3890158532
INFO:root:current train perplexity5.052033424377441
INFO:root:current mean train loss 4104.514742721987
INFO:root:current train perplexity5.057263374328613
INFO:root:current mean train loss 4113.504523811418
INFO:root:current train perplexity5.064473628997803
INFO:root:current mean train loss 4114.266186812606
INFO:root:current train perplexity5.0671844482421875
INFO:root:current mean train loss 4117.180913502849
INFO:root:current train perplexity5.065286636352539
INFO:root:current mean train loss 4119.052184672783
INFO:root:current train perplexity5.066320896148682
INFO:root:current mean train loss 4116.603962531127
INFO:root:current train perplexity5.06671142578125
INFO:root:current mean train loss 4116.241908130203
INFO:root:current train perplexity5.0669331550598145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.98s/it]
INFO:root:final mean train loss: 4113.147536370062
INFO:root:final train perplexity: 5.0670342445373535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4110.201476617908
INFO:root:eval perplexity: 5.270075798034668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.44s/it]
INFO:root:eval mean loss: 4945.542513367132
INFO:root:eval perplexity: 7.555685043334961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/25
 12%|â–ˆâ–Ž        | 25/200 [1:48:14<12:39:06, 260.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4105.235548847853
INFO:root:current train perplexity5.03603982925415
INFO:root:current mean train loss 4096.639571146749
INFO:root:current train perplexity5.02193021774292
INFO:root:current mean train loss 4106.92630790787
INFO:root:current train perplexity5.030778408050537
INFO:root:current mean train loss 4101.722910180725
INFO:root:current train perplexity5.029529094696045
INFO:root:current mean train loss 4096.831931441007
INFO:root:current train perplexity5.026164531707764
INFO:root:current mean train loss 4099.453619802535
INFO:root:current train perplexity5.027420520782471
INFO:root:current mean train loss 4095.909990346142
INFO:root:current train perplexity5.025593280792236
INFO:root:current mean train loss 4095.8752132792943
INFO:root:current train perplexity5.023441791534424
INFO:root:current mean train loss 4094.434268870794
INFO:root:current train perplexity5.026448726654053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.05s/it]
INFO:root:final mean train loss: 4094.8694145448744
INFO:root:final train perplexity: 5.030625820159912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.26s/it]
INFO:root:eval mean loss: 4109.215205632203
INFO:root:eval perplexity: 5.267975330352783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 4942.777445908134
INFO:root:eval perplexity: 7.547145366668701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/26
 13%|â–ˆâ–Ž        | 26/200 [1:52:33<12:33:35, 259.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4070.910470145089
INFO:root:current train perplexity4.917386054992676
INFO:root:current mean train loss 4066.553658458674
INFO:root:current train perplexity4.954716205596924
INFO:root:current mean train loss 4064.3717530476297
INFO:root:current train perplexity4.972546100616455
INFO:root:current mean train loss 4077.4809156784404
INFO:root:current train perplexity4.97627592086792
INFO:root:current mean train loss 4075.9286557509213
INFO:root:current train perplexity4.97722053527832
INFO:root:current mean train loss 4075.026143271542
INFO:root:current train perplexity4.979002952575684
INFO:root:current mean train loss 4073.1976589850187
INFO:root:current train perplexity4.980103969573975
INFO:root:current mean train loss 4077.3374465445986
INFO:root:current train perplexity4.986947059631348
INFO:root:current mean train loss 4076.256200324795
INFO:root:current train perplexity4.988382339477539
INFO:root:current mean train loss 4078.606378288227
INFO:root:current train perplexity4.995064735412598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.68s/it]
INFO:root:final mean train loss: 4075.8108071973247
INFO:root:final train perplexity: 4.992941856384277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 4098.723352310505
INFO:root:eval perplexity: 5.245672702789307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4935.77160731106
INFO:root:eval perplexity: 7.525557041168213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/27
 14%|â–ˆâ–Ž        | 27/200 [1:56:52<12:28:15, 259.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4074.803955078125
INFO:root:current train perplexity4.968079090118408
INFO:root:current mean train loss 4015.487644361413
INFO:root:current train perplexity4.913175106048584
INFO:root:current mean train loss 4042.41485396984
INFO:root:current train perplexity4.92863655090332
INFO:root:current mean train loss 4054.138936166915
INFO:root:current train perplexity4.9473066329956055
INFO:root:current mean train loss 4050.5171927946158
INFO:root:current train perplexity4.949767112731934
INFO:root:current mean train loss 4049.693780339806
INFO:root:current train perplexity4.950778961181641
INFO:root:current mean train loss 4051.897866250635
INFO:root:current train perplexity4.952183723449707
INFO:root:current mean train loss 4057.5123736614946
INFO:root:current train perplexity4.953756332397461
INFO:root:current mean train loss 4059.557378438938
INFO:root:current train perplexity4.95670747756958
INFO:root:current mean train loss 4060.0460233094263
INFO:root:current train perplexity4.9571380615234375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.63s/it]
INFO:root:final mean train loss: 4058.259021266814
INFO:root:final train perplexity: 4.958487033843994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 4090.94243302582
INFO:root:eval perplexity: 5.229193687438965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.16s/it]
INFO:root:eval mean loss: 4932.907507064495
INFO:root:eval perplexity: 7.516748905181885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/28
 14%|â–ˆâ–        | 28/200 [2:01:08<12:21:23, 258.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4049.6520783797555
INFO:root:current train perplexity4.924595832824707
INFO:root:current mean train loss 4031.3327338986282
INFO:root:current train perplexity4.917212009429932
INFO:root:current mean train loss 4037.3583765414796
INFO:root:current train perplexity4.910863876342773
INFO:root:current mean train loss 4054.9627069526414
INFO:root:current train perplexity4.926738739013672
INFO:root:current mean train loss 4051.4686334127514
INFO:root:current train perplexity4.924935340881348
INFO:root:current mean train loss 4048.1446003375954
INFO:root:current train perplexity4.923770427703857
INFO:root:current mean train loss 4047.829502846609
INFO:root:current train perplexity4.9257330894470215
INFO:root:current mean train loss 4045.6583179352524
INFO:root:current train perplexity4.919208526611328
INFO:root:current mean train loss 4042.5034814512455
INFO:root:current train perplexity4.917466163635254
INFO:root:current mean train loss 4043.2888879249053
INFO:root:current train perplexity4.920087814331055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.03s/it]
INFO:root:final mean train loss: 4040.2847779181698
INFO:root:final train perplexity: 4.9234490394592285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4080.1468912760415
INFO:root:eval perplexity: 5.20641565322876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4925.620754377216
INFO:root:eval perplexity: 7.494384288787842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/29
 14%|â–ˆâ–        | 29/200 [2:05:25<12:15:29, 258.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3960.5467017389115
INFO:root:current train perplexity4.847459316253662
INFO:root:current mean train loss 4024.5300218421994
INFO:root:current train perplexity4.886272430419922
INFO:root:current mean train loss 4026.334288758117
INFO:root:current train perplexity4.893721103668213
INFO:root:current mean train loss 4025.5115166517185
INFO:root:current train perplexity4.89532995223999
INFO:root:current mean train loss 4024.8914191650956
INFO:root:current train perplexity4.888140678405762
INFO:root:current mean train loss 4030.0593882415255
INFO:root:current train perplexity4.890204429626465
INFO:root:current mean train loss 4029.789072559677
INFO:root:current train perplexity4.889406204223633
INFO:root:current mean train loss 4027.9323082544247
INFO:root:current train perplexity4.890951633453369
INFO:root:current mean train loss 4025.723582280385
INFO:root:current train perplexity4.888686656951904
INFO:root:current mean train loss 4026.6941274608116
INFO:root:current train perplexity4.889712810516357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.17s/it]
INFO:root:final mean train loss: 4023.242813171879
INFO:root:final train perplexity: 4.890455722808838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 4076.264295212766
INFO:root:eval perplexity: 5.198248386383057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.47s/it]
INFO:root:eval mean loss: 4921.0113897661795
INFO:root:eval perplexity: 7.4802727699279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/30
 15%|â–ˆâ–Œ        | 30/200 [2:09:41<12:09:50, 257.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4011.220678084936
INFO:root:current train perplexity4.876143932342529
INFO:root:current mean train loss 4008.8576168362183
INFO:root:current train perplexity4.855347156524658
INFO:root:current mean train loss 4002.9565225385722
INFO:root:current train perplexity4.857028484344482
INFO:root:current mean train loss 4009.9367099638184
INFO:root:current train perplexity4.851257801055908
INFO:root:current mean train loss 4011.225055946576
INFO:root:current train perplexity4.856616973876953
INFO:root:current mean train loss 4013.036089782149
INFO:root:current train perplexity4.856807231903076
INFO:root:current mean train loss 4013.886342032228
INFO:root:current train perplexity4.8581461906433105
INFO:root:current mean train loss 4017.1979432060853
INFO:root:current train perplexity4.864349842071533
INFO:root:current mean train loss 4011.700148754097
INFO:root:current train perplexity4.858388423919678
INFO:root:current mean train loss 4008.5206053127495
INFO:root:current train perplexity4.857479572296143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.45s/it]
INFO:root:final mean train loss: 4005.6446023756457
INFO:root:final train perplexity: 4.8566203117370605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4069.387568913453
INFO:root:eval perplexity: 5.183812618255615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.37s/it]
INFO:root:eval mean loss: 4922.164528271831
INFO:root:eval perplexity: 7.483801364898682
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/31
 16%|â–ˆâ–Œ        | 31/200 [2:13:57<12:04:07, 257.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3976.8933884640956
INFO:root:current train perplexity4.822139739990234
INFO:root:current mean train loss 3991.338224449936
INFO:root:current train perplexity4.830106258392334
INFO:root:current mean train loss 3989.7359426398025
INFO:root:current train perplexity4.824887752532959
INFO:root:current mean train loss 3994.2221792259547
INFO:root:current train perplexity4.823792457580566
INFO:root:current mean train loss 3999.0435285802923
INFO:root:current train perplexity4.825923442840576
INFO:root:current mean train loss 3997.2214190327927
INFO:root:current train perplexity4.82580041885376
INFO:root:current mean train loss 3999.01948521421
INFO:root:current train perplexity4.829555511474609
INFO:root:current mean train loss 3995.2316067656043
INFO:root:current train perplexity4.826290607452393
INFO:root:current mean train loss 3993.666947510054
INFO:root:current train perplexity4.825043678283691
INFO:root:current mean train loss 3994.798532681329
INFO:root:current train perplexity4.829294204711914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.71s/it]
INFO:root:final mean train loss: 3991.871692411361
INFO:root:final train perplexity: 4.830301284790039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 4063.023681640625
INFO:root:eval perplexity: 5.17048978805542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.81s/it]
INFO:root:eval mean loss: 4916.361873545545
INFO:root:eval perplexity: 7.466065406799316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/32
 16%|â–ˆâ–Œ        | 32/200 [2:18:14<11:59:18, 256.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3940.9713556463066
INFO:root:current train perplexity4.767789363861084
INFO:root:current mean train loss 3968.7393444430445
INFO:root:current train perplexity4.788873672485352
INFO:root:current mean train loss 3971.424595013787
INFO:root:current train perplexity4.785350322723389
INFO:root:current mean train loss 3972.582627503301
INFO:root:current train perplexity4.7859416007995605
INFO:root:current mean train loss 3969.249611521291
INFO:root:current train perplexity4.782649040222168
INFO:root:current mean train loss 3969.7539454004786
INFO:root:current train perplexity4.7849578857421875
INFO:root:current mean train loss 3976.168509586713
INFO:root:current train perplexity4.790818214416504
INFO:root:current mean train loss 3976.3202995653974
INFO:root:current train perplexity4.794828414916992
INFO:root:current mean train loss 3976.519638614766
INFO:root:current train perplexity4.794055938720703
INFO:root:current mean train loss 3976.78483183696
INFO:root:current train perplexity4.797778129577637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.17s/it]
INFO:root:final mean train loss: 3975.572586797899
INFO:root:final train perplexity: 4.79934024810791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it]
INFO:root:eval mean loss: 4053.214549396055
INFO:root:eval perplexity: 5.150021076202393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it]
INFO:root:eval mean loss: 4909.707561087101
INFO:root:eval perplexity: 7.445775508880615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/33
 16%|â–ˆâ–‹        | 33/200 [2:22:31<11:55:00, 256.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3921.8482181609625
INFO:root:current train perplexity4.724897861480713
INFO:root:current mean train loss 3950.5243616396665
INFO:root:current train perplexity4.747972011566162
INFO:root:current mean train loss 3955.6166128876544
INFO:root:current train perplexity4.756233215332031
INFO:root:current mean train loss 3955.741840457128
INFO:root:current train perplexity4.752706050872803
INFO:root:current mean train loss 3964.4280312457818
INFO:root:current train perplexity4.7599945068359375
INFO:root:current mean train loss 3965.361743120698
INFO:root:current train perplexity4.767308235168457
INFO:root:current mean train loss 3958.904482097827
INFO:root:current train perplexity4.76255464553833
INFO:root:current mean train loss 3962.6318314578557
INFO:root:current train perplexity4.7693986892700195
INFO:root:current mean train loss 3959.8812418525495
INFO:root:current train perplexity4.766768455505371
INFO:root:current mean train loss 3963.75097098504
INFO:root:current train perplexity4.771062850952148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.78s/it]
INFO:root:final mean train loss: 3961.1763977543
INFO:root:final train perplexity: 4.772158145904541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 4048.1033840314717
INFO:root:eval perplexity: 5.1393890380859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it]
INFO:root:eval mean loss: 4907.74846243351
INFO:root:eval perplexity: 7.439813137054443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/34
 17%|â–ˆâ–‹        | 34/200 [2:26:47<11:50:06, 256.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3910.907745791153
INFO:root:current train perplexity4.705234527587891
INFO:root:current mean train loss 3921.4107901589914
INFO:root:current train perplexity4.7057576179504395
INFO:root:current mean train loss 3934.9627581944765
INFO:root:current train perplexity4.7175703048706055
INFO:root:current mean train loss 3950.6178475351667
INFO:root:current train perplexity4.739043235778809
INFO:root:current mean train loss 3952.011029350783
INFO:root:current train perplexity4.744611740112305
INFO:root:current mean train loss 3947.855655596678
INFO:root:current train perplexity4.743691444396973
INFO:root:current mean train loss 3945.9492565899777
INFO:root:current train perplexity4.744750022888184
INFO:root:current mean train loss 3948.2504335000203
INFO:root:current train perplexity4.743208408355713
INFO:root:current mean train loss 3948.2918837117
INFO:root:current train perplexity4.745869159698486
INFO:root:current mean train loss 3951.0051392733008
INFO:root:current train perplexity4.746263027191162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.80s/it]
INFO:root:final mean train loss: 3947.487029844715
INFO:root:final train perplexity: 4.746454238891602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4046.6996516234485
INFO:root:eval perplexity: 5.136472702026367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.28s/it]
INFO:root:eval mean loss: 4910.432231064384
INFO:root:eval perplexity: 7.447982311248779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/35
 18%|â–ˆâ–Š        | 35/200 [2:31:03<11:45:17, 256.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3943.1642448328716
INFO:root:current train perplexity4.767795085906982
INFO:root:current mean train loss 3934.078176828736
INFO:root:current train perplexity4.724945068359375
INFO:root:current mean train loss 3933.328384891633
INFO:root:current train perplexity4.724467754364014
INFO:root:current mean train loss 3935.074908656621
INFO:root:current train perplexity4.725285530090332
INFO:root:current mean train loss 3937.6481204739694
INFO:root:current train perplexity4.722761631011963
INFO:root:current mean train loss 3935.237793390409
INFO:root:current train perplexity4.717080116271973
INFO:root:current mean train loss 3932.6504531882824
INFO:root:current train perplexity4.715287208557129
INFO:root:current mean train loss 3936.224857589859
INFO:root:current train perplexity4.716302871704102
INFO:root:current mean train loss 3936.055816268487
INFO:root:current train perplexity4.718176364898682
INFO:root:current mean train loss 3935.411428823656
INFO:root:current train perplexity4.7191691398620605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.08s/it]
INFO:root:final mean train loss: 3932.514658466462
INFO:root:final train perplexity: 4.718499183654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4041.299655779034
INFO:root:eval perplexity: 5.125268459320068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it]
INFO:root:eval mean loss: 4906.290738585993
INFO:root:eval perplexity: 7.435379981994629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/36
 18%|â–ˆâ–Š        | 36/200 [2:35:19<11:40:56, 256.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3916.6213182471265
INFO:root:current train perplexity4.656414985656738
INFO:root:current mean train loss 3925.046168689422
INFO:root:current train perplexity4.6690673828125
INFO:root:current mean train loss 3913.576518095329
INFO:root:current train perplexity4.662703990936279
INFO:root:current mean train loss 3912.1648914425873
INFO:root:current train perplexity4.673699378967285
INFO:root:current mean train loss 3912.274886802971
INFO:root:current train perplexity4.679312705993652
INFO:root:current mean train loss 3917.0919540899167
INFO:root:current train perplexity4.675228595733643
INFO:root:current mean train loss 3918.4008462120178
INFO:root:current train perplexity4.679690361022949
INFO:root:current mean train loss 3918.9094595030574
INFO:root:current train perplexity4.684641361236572
INFO:root:current mean train loss 3919.7460670514197
INFO:root:current train perplexity4.687001705169678
INFO:root:current mean train loss 3922.5292647186866
INFO:root:current train perplexity4.694672584533691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.47s/it]
INFO:root:final mean train loss: 3919.743813730055
INFO:root:final train perplexity: 4.694784641265869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 4035.460094262522
INFO:root:eval perplexity: 5.113180637359619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 4903.362857034021
INFO:root:eval perplexity: 7.426482677459717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/37
 18%|â–ˆâ–Š        | 37/200 [2:39:36<11:36:58, 256.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3880.971728515625
INFO:root:current train perplexity4.633404731750488
INFO:root:current mean train loss 3908.4359662960737
INFO:root:current train perplexity4.653492450714111
INFO:root:current mean train loss 3905.724764962924
INFO:root:current train perplexity4.666103363037109
INFO:root:current mean train loss 3904.489666979826
INFO:root:current train perplexity4.660551071166992
INFO:root:current mean train loss 3906.739613912563
INFO:root:current train perplexity4.660793781280518
INFO:root:current mean train loss 3905.627266609769
INFO:root:current train perplexity4.658094882965088
INFO:root:current mean train loss 3907.4785806120726
INFO:root:current train perplexity4.659504413604736
INFO:root:current mean train loss 3907.9219717349647
INFO:root:current train perplexity4.665381908416748
INFO:root:current mean train loss 3909.473765384951
INFO:root:current train perplexity4.6691107749938965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.15s/it]
INFO:root:final mean train loss: 3906.931647393011
INFO:root:final train perplexity: 4.671114444732666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4031.4389111674423
INFO:root:eval perplexity: 5.104872703552246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 4901.369080022717
INFO:root:eval perplexity: 7.420431137084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/38
 19%|â–ˆâ–‰        | 38/200 [2:43:52<11:32:14, 256.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3960.6089680989585
INFO:root:current train perplexity4.6941046714782715
INFO:root:current mean train loss 3882.8416712492417
INFO:root:current train perplexity4.615688800811768
INFO:root:current mean train loss 3882.9160108143474
INFO:root:current train perplexity4.621447563171387
INFO:root:current mean train loss 3888.212428933323
INFO:root:current train perplexity4.629158973693848
INFO:root:current mean train loss 3895.356263570099
INFO:root:current train perplexity4.642953395843506
INFO:root:current mean train loss 3900.9459196966636
INFO:root:current train perplexity4.644820213317871
INFO:root:current mean train loss 3902.3423033756994
INFO:root:current train perplexity4.646231174468994
INFO:root:current mean train loss 3899.236119754623
INFO:root:current train perplexity4.645042896270752
INFO:root:current mean train loss 3897.9439644059385
INFO:root:current train perplexity4.645199298858643
INFO:root:current mean train loss 3897.5613011965324
INFO:root:current train perplexity4.646525859832764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.21s/it]
INFO:root:final mean train loss: 3893.394262129261
INFO:root:final train perplexity: 4.6462321281433105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 4031.406445658799
INFO:root:eval perplexity: 5.1048054695129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 4902.330323997119
INFO:root:eval perplexity: 7.423347473144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/39
 20%|â–ˆâ–‰        | 39/200 [2:48:09<11:28:12, 256.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3879.597345525568
INFO:root:current train perplexity4.677177906036377
INFO:root:current mean train loss 3866.4956428596565
INFO:root:current train perplexity4.601433753967285
INFO:root:current mean train loss 3866.345727423356
INFO:root:current train perplexity4.600825309753418
INFO:root:current mean train loss 3865.5662625916902
INFO:root:current train perplexity4.608648300170898
INFO:root:current mean train loss 3872.1075127594663
INFO:root:current train perplexity4.606988430023193
INFO:root:current mean train loss 3875.238515835219
INFO:root:current train perplexity4.610211372375488
INFO:root:current mean train loss 3873.5833546440263
INFO:root:current train perplexity4.616052150726318
INFO:root:current mean train loss 3876.6445638707587
INFO:root:current train perplexity4.619858264923096
INFO:root:current mean train loss 3882.8773550087662
INFO:root:current train perplexity4.622183322906494
INFO:root:current mean train loss 3884.2716124751305
INFO:root:current train perplexity4.623085021972656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.10s/it]
INFO:root:final mean train loss: 3881.6138718512752
INFO:root:final train perplexity: 4.624688625335693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4024.2526145556294
INFO:root:eval perplexity: 5.090060710906982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it]
INFO:root:eval mean loss: 4897.488303759419
INFO:root:eval perplexity: 7.408665180206299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/40
 20%|â–ˆâ–ˆ        | 40/200 [2:52:28<11:26:20, 257.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3870.5747841282896
INFO:root:current train perplexity4.625240325927734
INFO:root:current mean train loss 3868.029167624081
INFO:root:current train perplexity4.601656913757324
INFO:root:current mean train loss 3873.206104853382
INFO:root:current train perplexity4.588160514831543
INFO:root:current mean train loss 3873.563355640184
INFO:root:current train perplexity4.593719482421875
INFO:root:current mean train loss 3878.5411513881636
INFO:root:current train perplexity4.602812767028809
INFO:root:current mean train loss 3882.4035414032396
INFO:root:current train perplexity4.603973388671875
INFO:root:current mean train loss 3875.8338242439922
INFO:root:current train perplexity4.600814342498779
INFO:root:current mean train loss 3873.8261416545333
INFO:root:current train perplexity4.600574970245361
INFO:root:current mean train loss 3870.6653642852375
INFO:root:current train perplexity4.599853515625
INFO:root:current mean train loss 3871.3923810060187
INFO:root:current train perplexity4.6001811027526855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.61s/it]
INFO:root:final mean train loss: 3867.7372686939857
INFO:root:final train perplexity: 4.5994391441345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 4021.6533757203015
INFO:root:eval perplexity: 5.084712982177734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.48s/it]
INFO:root:eval mean loss: 4895.233294547872
INFO:root:eval perplexity: 7.401835918426514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/41
 20%|â–ˆâ–ˆ        | 41/200 [2:56:45<11:21:49, 257.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3868.1104329427085
INFO:root:current train perplexity4.588765621185303
INFO:root:current mean train loss 3853.0094849593997
INFO:root:current train perplexity4.582833766937256
INFO:root:current mean train loss 3856.402135101184
INFO:root:current train perplexity4.576033115386963
INFO:root:current mean train loss 3858.3445354310015
INFO:root:current train perplexity4.5753560066223145
INFO:root:current mean train loss 3851.6671499926815
INFO:root:current train perplexity4.570295333862305
INFO:root:current mean train loss 3853.949420733515
INFO:root:current train perplexity4.571303844451904
INFO:root:current mean train loss 3857.7002101089015
INFO:root:current train perplexity4.576288223266602
INFO:root:current mean train loss 3858.0529801947214
INFO:root:current train perplexity4.5748796463012695
INFO:root:current mean train loss 3857.900351656968
INFO:root:current train perplexity4.575845241546631
INFO:root:current mean train loss 3858.4217707069174
INFO:root:current train perplexity4.578121662139893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.11s/it]
INFO:root:final mean train loss: 3855.9029803737517
INFO:root:final train perplexity: 4.578013896942139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4019.5529819786125
INFO:root:eval perplexity: 5.080395221710205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 4896.085876897717
INFO:root:eval perplexity: 7.404417991638184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/42
 21%|â–ˆâ–ˆ        | 42/200 [3:01:03<11:17:52, 257.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3874.0212890625
INFO:root:current train perplexity4.579361915588379
INFO:root:current mean train loss 3835.5871491608796
INFO:root:current train perplexity4.5406880378723145
INFO:root:current mean train loss 3839.3150910073136
INFO:root:current train perplexity4.539381980895996
INFO:root:current mean train loss 3845.0235985599347
INFO:root:current train perplexity4.5453057289123535
INFO:root:current mean train loss 3838.689169697378
INFO:root:current train perplexity4.545703887939453
INFO:root:current mean train loss 3840.799305454147
INFO:root:current train perplexity4.548145294189453
INFO:root:current mean train loss 3848.6278700941193
INFO:root:current train perplexity4.554890155792236
INFO:root:current mean train loss 3848.1843557344814
INFO:root:current train perplexity4.556403636932373
INFO:root:current mean train loss 3849.1878005707335
INFO:root:current train perplexity4.558296203613281
INFO:root:current mean train loss 3849.513549674131
INFO:root:current train perplexity4.5592145919799805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.37s/it]
INFO:root:final mean train loss: 3844.7459080603817
INFO:root:final train perplexity: 4.5579071044921875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4016.363120221077
INFO:root:eval perplexity: 5.073847770690918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.58s/it]
INFO:root:eval mean loss: 4893.829319730718
INFO:root:eval perplexity: 7.397589206695557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/43
 22%|â–ˆâ–ˆâ–       | 43/200 [3:05:23<11:15:38, 258.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3851.259629360465
INFO:root:current train perplexity4.541158199310303
INFO:root:current mean train loss 3820.3925678813375
INFO:root:current train perplexity4.528711318969727
INFO:root:current mean train loss 3814.9213103620114
INFO:root:current train perplexity4.519345283508301
INFO:root:current mean train loss 3818.2843846802116
INFO:root:current train perplexity4.513082504272461
INFO:root:current mean train loss 3824.0821453292538
INFO:root:current train perplexity4.515131950378418
INFO:root:current mean train loss 3827.340770854915
INFO:root:current train perplexity4.518711566925049
INFO:root:current mean train loss 3831.5302836891283
INFO:root:current train perplexity4.5251359939575195
INFO:root:current mean train loss 3831.028264781187
INFO:root:current train perplexity4.5274553298950195
INFO:root:current mean train loss 3831.540853443802
INFO:root:current train perplexity4.531240463256836
INFO:root:current mean train loss 3835.673544890807
INFO:root:current train perplexity4.537756443023682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.25s/it]
INFO:root:final mean train loss: 3834.2254431324623
INFO:root:final train perplexity: 4.539027690887451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 4013.561428205341
INFO:root:eval perplexity: 5.068102836608887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 4890.24297706117
INFO:root:eval perplexity: 7.386748790740967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/44
 22%|â–ˆâ–ˆâ–       | 44/200 [3:09:41<11:11:00, 258.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.7697514552697
INFO:root:current train perplexity4.56869649887085
INFO:root:current mean train loss 3829.3041862841474
INFO:root:current train perplexity4.519273281097412
INFO:root:current mean train loss 3825.4813791708166
INFO:root:current train perplexity4.511838436126709
INFO:root:current mean train loss 3816.467096660212
INFO:root:current train perplexity4.5005950927734375
INFO:root:current mean train loss 3814.440792921113
INFO:root:current train perplexity4.497676849365234
INFO:root:current mean train loss 3812.9593264377268
INFO:root:current train perplexity4.501910209655762
INFO:root:current mean train loss 3817.5092769687258
INFO:root:current train perplexity4.506723403930664
INFO:root:current mean train loss 3821.368477446738
INFO:root:current train perplexity4.510674953460693
INFO:root:current mean train loss 3824.4086389059744
INFO:root:current train perplexity4.518172740936279
INFO:root:current mean train loss 3826.5586594702945
INFO:root:current train perplexity4.519293785095215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.83s/it]
INFO:root:final mean train loss: 3823.3377982724096
INFO:root:final train perplexity: 4.5195722579956055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4013.36126405973
INFO:root:eval perplexity: 5.067691802978516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it]
INFO:root:eval mean loss: 4895.309598016401
INFO:root:eval perplexity: 7.402067184448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [3:13:57<11:05:34, 257.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3784.6019142280193
INFO:root:current train perplexity4.482909679412842
INFO:root:current mean train loss 3814.7434573383453
INFO:root:current train perplexity4.500027656555176
INFO:root:current mean train loss 3811.174300381576
INFO:root:current train perplexity4.502216815948486
INFO:root:current mean train loss 3801.091424203517
INFO:root:current train perplexity4.490397930145264
INFO:root:current mean train loss 3799.800642424939
INFO:root:current train perplexity4.4861345291137695
INFO:root:current mean train loss 3805.274929858704
INFO:root:current train perplexity4.490988731384277
INFO:root:current mean train loss 3803.5584885361345
INFO:root:current train perplexity4.486591339111328
INFO:root:current mean train loss 3806.2463195559535
INFO:root:current train perplexity4.491233825683594
INFO:root:current mean train loss 3810.6699880970787
INFO:root:current train perplexity4.493457794189453
INFO:root:current mean train loss 3813.5430914567582
INFO:root:current train perplexity4.49629545211792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.53s/it]
INFO:root:final mean train loss: 3811.149472944198
INFO:root:final train perplexity: 4.497891902923584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4008.700487934951
INFO:root:eval perplexity: 5.058150291442871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it]
INFO:root:eval mean loss: 4894.600099387744
INFO:root:eval perplexity: 7.399921417236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [3:18:14<11:00:46, 257.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.7892519822763
INFO:root:current train perplexity4.425719738006592
INFO:root:current mean train loss 3795.5342893314933
INFO:root:current train perplexity4.4644341468811035
INFO:root:current mean train loss 3798.686705399988
INFO:root:current train perplexity4.472161293029785
INFO:root:current mean train loss 3793.1927839481864
INFO:root:current train perplexity4.465839862823486
INFO:root:current mean train loss 3791.8521678851043
INFO:root:current train perplexity4.463654041290283
INFO:root:current mean train loss 3796.9781707279267
INFO:root:current train perplexity4.473196029663086
INFO:root:current mean train loss 3797.464150859141
INFO:root:current train perplexity4.475368499755859
INFO:root:current mean train loss 3801.0824444110576
INFO:root:current train perplexity4.477702617645264
INFO:root:current mean train loss 3804.407029729401
INFO:root:current train perplexity4.480470180511475
INFO:root:current mean train loss 3802.6112536456985
INFO:root:current train perplexity4.479109764099121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.57s/it]
INFO:root:final mean train loss: 3800.946938730055
INFO:root:final train perplexity: 4.479822635650635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 4006.7698567708335
INFO:root:eval perplexity: 5.054201602935791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.73s/it]
INFO:root:eval mean loss: 4894.087270750221
INFO:root:eval perplexity: 7.398368835449219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [3:22:32<10:56:13, 257.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.3912890625
INFO:root:current train perplexity4.397122859954834
INFO:root:current mean train loss 3784.1027427455356
INFO:root:current train perplexity4.442825794219971
INFO:root:current mean train loss 3791.8105646306817
INFO:root:current train perplexity4.453650951385498
INFO:root:current mean train loss 3787.7218880208334
INFO:root:current train perplexity4.456017017364502
INFO:root:current mean train loss 3784.9510618832237
INFO:root:current train perplexity4.452941417694092
INFO:root:current mean train loss 3788.3370923913044
INFO:root:current train perplexity4.4544453620910645
INFO:root:current mean train loss 3787.946751302083
INFO:root:current train perplexity4.451847553253174
INFO:root:current mean train loss 3793.8536532888106
INFO:root:current train perplexity4.460504055023193
INFO:root:current mean train loss 3793.2942653459822
INFO:root:current train perplexity4.459898948669434
INFO:root:current mean train loss 3794.3875040064104
INFO:root:current train perplexity4.461411952972412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:42<00:00, 222.95s/it]
INFO:root:final mean train loss: 3790.8107269041
INFO:root:final train perplexity: 4.46194314956665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 4005.147353584885
INFO:root:eval perplexity: 5.050888538360596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.38s/it]
INFO:root:eval mean loss: 4895.136737796432
INFO:root:eval perplexity: 7.401543140411377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/48
 24%|â–ˆâ–ˆâ–       | 48/200 [3:26:47<10:50:19, 256.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3792.2383253718
INFO:root:current train perplexity4.4360785484313965
INFO:root:current mean train loss 3774.5047667456456
INFO:root:current train perplexity4.4296674728393555
INFO:root:current mean train loss 3766.1055377650177
INFO:root:current train perplexity4.426645755767822
INFO:root:current mean train loss 3766.070528593138
INFO:root:current train perplexity4.425013065338135
INFO:root:current mean train loss 3775.387622525233
INFO:root:current train perplexity4.432437419891357
INFO:root:current mean train loss 3776.7342280131056
INFO:root:current train perplexity4.434919834136963
INFO:root:current mean train loss 3779.173800958547
INFO:root:current train perplexity4.438014507293701
INFO:root:current mean train loss 3783.2903652069363
INFO:root:current train perplexity4.44175910949707
INFO:root:current mean train loss 3781.2069889470376
INFO:root:current train perplexity4.441361427307129
INFO:root:current mean train loss 3783.1440928896714
INFO:root:current train perplexity4.443063735961914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.01s/it]
INFO:root:final mean train loss: 3780.346907584898
INFO:root:final train perplexity: 4.44356107711792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 4001.375292622451
INFO:root:eval perplexity: 5.043188571929932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 4893.160625484818
INFO:root:eval perplexity: 7.395566463470459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/49
 24%|â–ˆâ–ˆâ–       | 49/200 [3:31:07<10:48:39, 257.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.0654296875
INFO:root:current train perplexity4.397780895233154
INFO:root:current mean train loss 3770.680932489365
INFO:root:current train perplexity4.410674571990967
INFO:root:current mean train loss 3768.939919592998
INFO:root:current train perplexity4.409000873565674
INFO:root:current mean train loss 3775.5267593110616
INFO:root:current train perplexity4.4170308113098145
INFO:root:current mean train loss 3778.6241054806837
INFO:root:current train perplexity4.4221906661987305
INFO:root:current mean train loss 3774.002569879574
INFO:root:current train perplexity4.420311450958252
INFO:root:current mean train loss 3773.864179376583
INFO:root:current train perplexity4.4235944747924805
INFO:root:current mean train loss 3772.179350456305
INFO:root:current train perplexity4.421086311340332
INFO:root:current mean train loss 3771.2084234817794
INFO:root:current train perplexity4.421595096588135
INFO:root:current mean train loss 3772.083229780919
INFO:root:current train perplexity4.423831939697266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.72s/it]
INFO:root:final mean train loss: 3769.0531854937153
INFO:root:final train perplexity: 4.423806667327881
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 4000.905020639406
INFO:root:eval perplexity: 5.04223108291626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.31s/it]
INFO:root:eval mean loss: 4894.645649794991
INFO:root:eval perplexity: 7.400058746337891
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [3:35:23<10:42:58, 257.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3741.000606652462
INFO:root:current train perplexity4.378803730010986
INFO:root:current mean train loss 3753.3675948099876
INFO:root:current train perplexity4.3950958251953125
INFO:root:current mean train loss 3752.9060524012334
INFO:root:current train perplexity4.390429973602295
INFO:root:current mean train loss 3747.3559790589757
INFO:root:current train perplexity4.383906364440918
INFO:root:current mean train loss 3753.01152744943
INFO:root:current train perplexity4.388847351074219
INFO:root:current mean train loss 3755.659123848993
INFO:root:current train perplexity4.3950934410095215
INFO:root:current mean train loss 3757.9510157507375
INFO:root:current train perplexity4.398963451385498
INFO:root:current mean train loss 3761.1495127576463
INFO:root:current train perplexity4.404812812805176
INFO:root:current mean train loss 3764.4798957391895
INFO:root:current train perplexity4.410215854644775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]
INFO:root:final mean train loss: 3761.302428953109
INFO:root:final train perplexity: 4.410299301147461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.86s/it]
INFO:root:eval mean loss: 3998.6239697611923
INFO:root:eval perplexity: 5.037581920623779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 4891.229573567708
INFO:root:eval perplexity: 7.3897271156311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [3:39:44<10:41:18, 258.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3751.332205636161
INFO:root:current train perplexity4.350483417510986
INFO:root:current mean train loss 3754.8233357367117
INFO:root:current train perplexity4.377717971801758
INFO:root:current mean train loss 3763.7766431725545
INFO:root:current train perplexity4.401822566986084
INFO:root:current mean train loss 3757.4103518805987
INFO:root:current train perplexity4.3940534591674805
INFO:root:current mean train loss 3750.5736656845056
INFO:root:current train perplexity4.380104064941406
INFO:root:current mean train loss 3752.319819403353
INFO:root:current train perplexity4.383195400238037
INFO:root:current mean train loss 3754.136384112438
INFO:root:current train perplexity4.3867621421813965
INFO:root:current mean train loss 3754.815949047472
INFO:root:current train perplexity4.388618469238281
INFO:root:current mean train loss 3757.1564073149007
INFO:root:current train perplexity4.391019344329834
INFO:root:current mean train loss 3755.4891027683984
INFO:root:current train perplexity4.3922529220581055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.54s/it]
INFO:root:final mean train loss: 3750.9582093761815
INFO:root:final train perplexity: 4.392337322235107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 3999.797119140625
INFO:root:eval perplexity: 5.039971828460693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4896.936689660904
INFO:root:eval perplexity: 7.406994342803955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [3:44:02<10:37:05, 258.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.05595703125
INFO:root:current train perplexity4.378222942352295
INFO:root:current mean train loss 3751.3459769870924
INFO:root:current train perplexity4.366650581359863
INFO:root:current mean train loss 3750.6413017805235
INFO:root:current train perplexity4.376038551330566
INFO:root:current mean train loss 3747.9559035528273
INFO:root:current train perplexity4.37260627746582
INFO:root:current mean train loss 3749.6982763083583
INFO:root:current train perplexity4.37673282623291
INFO:root:current mean train loss 3749.6101311248485
INFO:root:current train perplexity4.372631549835205
INFO:root:current mean train loss 3749.3583377000764
INFO:root:current train perplexity4.374270915985107
INFO:root:current mean train loss 3750.04090157889
INFO:root:current train perplexity4.379658222198486
INFO:root:current mean train loss 3747.867814177531
INFO:root:current train perplexity4.380016803741455
INFO:root:current mean train loss 3747.0273725665984
INFO:root:current train perplexity4.380309581756592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.56s/it]
INFO:root:final mean train loss: 3742.3255149472143
INFO:root:final train perplexity: 4.3774027824401855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 4002.76556093473
INFO:root:eval perplexity: 5.046025276184082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 4902.254325271499
INFO:root:eval perplexity: 7.423117160797119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [3:48:19<10:32:04, 257.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.398395040761
INFO:root:current train perplexity4.290155410766602
INFO:root:current mean train loss 3702.0005815707573
INFO:root:current train perplexity4.304224014282227
INFO:root:current mean train loss 3717.7859784455577
INFO:root:current train perplexity4.318386077880859
INFO:root:current mean train loss 3717.4834800696594
INFO:root:current train perplexity4.330885410308838
INFO:root:current mean train loss 3725.831998351618
INFO:root:current train perplexity4.338627815246582
INFO:root:current mean train loss 3729.8073044260873
INFO:root:current train perplexity4.348230361938477
INFO:root:current mean train loss 3727.802906801766
INFO:root:current train perplexity4.349806785583496
INFO:root:current mean train loss 3730.6301782800615
INFO:root:current train perplexity4.354105472564697
INFO:root:current mean train loss 3728.926910585795
INFO:root:current train perplexity4.355923175811768
INFO:root:current mean train loss 3732.7052775638203
INFO:root:current train perplexity4.358384609222412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.17s/it]
INFO:root:final mean train loss: 3732.451499692855
INFO:root:final train perplexity: 4.360383033752441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 4000.110199191046
INFO:root:eval perplexity: 5.040609359741211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 4900.961541791335
INFO:root:eval perplexity: 7.41919469833374
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [3:52:37<10:27:28, 257.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3750.199415637601
INFO:root:current train perplexity4.33986759185791
INFO:root:current mean train loss 3713.12503354604
INFO:root:current train perplexity4.310172080993652
INFO:root:current mean train loss 3720.937595119724
INFO:root:current train perplexity4.321915626525879
INFO:root:current mean train loss 3719.07542986452
INFO:root:current train perplexity4.326876640319824
INFO:root:current mean train loss 3719.7365501740137
INFO:root:current train perplexity4.334595680236816
INFO:root:current mean train loss 3721.8254918674966
INFO:root:current train perplexity4.336673259735107
INFO:root:current mean train loss 3721.5242678102713
INFO:root:current train perplexity4.335731506347656
INFO:root:current mean train loss 3723.50050598228
INFO:root:current train perplexity4.340554714202881
INFO:root:current mean train loss 3725.989493139384
INFO:root:current train perplexity4.343684673309326
INFO:root:current mean train loss 3725.3850810934982
INFO:root:current train perplexity4.3422369956970215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.94s/it]
INFO:root:final mean train loss: 3722.5700295356014
INFO:root:final train perplexity: 4.343417167663574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 3995.5996872922206
INFO:root:eval perplexity: 5.031424522399902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it]
INFO:root:eval mean loss: 4898.505307028479
INFO:root:eval perplexity: 7.411746025085449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [3:56:53<10:21:55, 257.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3763.2860201322114
INFO:root:current train perplexity4.319714546203613
INFO:root:current mean train loss 3732.208717401079
INFO:root:current train perplexity4.309691429138184
INFO:root:current mean train loss 3725.5770799964043
INFO:root:current train perplexity4.311511993408203
INFO:root:current mean train loss 3717.42552774705
INFO:root:current train perplexity4.316043853759766
INFO:root:current mean train loss 3722.1426798966045
INFO:root:current train perplexity4.319911003112793
INFO:root:current mean train loss 3721.9186300585575
INFO:root:current train perplexity4.322915077209473
INFO:root:current mean train loss 3719.7503679302376
INFO:root:current train perplexity4.323613166809082
INFO:root:current mean train loss 3716.914111063832
INFO:root:current train perplexity4.324241638183594
INFO:root:current mean train loss 3715.5146429086894
INFO:root:current train perplexity4.325956344604492
INFO:root:current mean train loss 3717.8267948365947
INFO:root:current train perplexity4.330869197845459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.32s/it]
INFO:root:final mean train loss: 3715.1535885718563
INFO:root:final train perplexity: 4.330728054046631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 3996.681512494459
INFO:root:eval perplexity: 5.033626556396484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 4904.765973030253
INFO:root:eval perplexity: 7.430745601654053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [4:01:14<10:20:10, 258.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3701.626459649269
INFO:root:current train perplexity4.303479194641113
INFO:root:current mean train loss 3701.981287534545
INFO:root:current train perplexity4.29149055480957
INFO:root:current mean train loss 3694.354437824203
INFO:root:current train perplexity4.305222988128662
INFO:root:current mean train loss 3696.0306688468117
INFO:root:current train perplexity4.305996417999268
INFO:root:current mean train loss 3694.183287345323
INFO:root:current train perplexity4.304144859313965
INFO:root:current mean train loss 3695.987610867516
INFO:root:current train perplexity4.302886486053467
INFO:root:current mean train loss 3697.3114230643837
INFO:root:current train perplexity4.306554794311523
INFO:root:current mean train loss 3703.389201336596
INFO:root:current train perplexity4.310521125793457
INFO:root:current mean train loss 3704.708062866643
INFO:root:current train perplexity4.313581466674805
INFO:root:current mean train loss 3706.3595340652223
INFO:root:current train perplexity4.314054012298584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.25s/it]
INFO:root:final mean train loss: 3705.1091757128315
INFO:root:final train perplexity: 4.313599586486816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 3996.6917629377217
INFO:root:eval perplexity: 5.033646583557129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4902.584095190603
INFO:root:eval perplexity: 7.424117565155029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [4:05:32<10:15:29, 258.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.4429243607956
INFO:root:current train perplexity4.301724910736084
INFO:root:current mean train loss 3690.1138876638106
INFO:root:current train perplexity4.2941975593566895
INFO:root:current mean train loss 3693.54929821538
INFO:root:current train perplexity4.291749954223633
INFO:root:current mean train loss 3690.114284633583
INFO:root:current train perplexity4.282401084899902
INFO:root:current mean train loss 3692.7318783267515
INFO:root:current train perplexity4.287113666534424
INFO:root:current mean train loss 3695.255810986768
INFO:root:current train perplexity4.2895121574401855
INFO:root:current mean train loss 3695.7051295622614
INFO:root:current train perplexity4.293721675872803
INFO:root:current mean train loss 3698.5018085808156
INFO:root:current train perplexity4.29559326171875
INFO:root:current mean train loss 3698.462187043129
INFO:root:current train perplexity4.294790267944336
INFO:root:current mean train loss 3698.9944571130563
INFO:root:current train perplexity4.298276424407959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.22s/it]
INFO:root:final mean train loss: 3696.731523267684
INFO:root:final train perplexity: 4.299365520477295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 3992.97134204621
INFO:root:eval perplexity: 5.02608060836792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 4902.4281672484485
INFO:root:eval perplexity: 7.423644542694092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [4:09:52<10:12:20, 258.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3676.6830163380455
INFO:root:current train perplexity4.278252124786377
INFO:root:current mean train loss 3687.782452729582
INFO:root:current train perplexity4.27537727355957
INFO:root:current mean train loss 3692.1681451253567
INFO:root:current train perplexity4.281381130218506
INFO:root:current mean train loss 3686.6487710915976
INFO:root:current train perplexity4.2749714851379395
INFO:root:current mean train loss 3689.9563273024096
INFO:root:current train perplexity4.279385089874268
INFO:root:current mean train loss 3689.877517727298
INFO:root:current train perplexity4.280872344970703
INFO:root:current mean train loss 3688.809901725113
INFO:root:current train perplexity4.282165050506592
INFO:root:current mean train loss 3692.532102092378
INFO:root:current train perplexity4.284936904907227
INFO:root:current mean train loss 3691.9525300663563
INFO:root:current train perplexity4.283510684967041
INFO:root:current mean train loss 3690.9763672889085
INFO:root:current train perplexity4.283360004425049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.86s/it]
INFO:root:final mean train loss: 3687.817588744625
INFO:root:final train perplexity: 4.284272193908691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 3994.1090754515735
INFO:root:eval perplexity: 5.028393268585205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 4903.102771082668
INFO:root:eval perplexity: 7.425694465637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [4:14:09<10:07:16, 258.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.37539200044
INFO:root:current train perplexity4.261702537536621
INFO:root:current mean train loss 3666.0277863441156
INFO:root:current train perplexity4.26057767868042
INFO:root:current mean train loss 3683.6038507553044
INFO:root:current train perplexity4.259739875793457
INFO:root:current mean train loss 3683.2713139372054
INFO:root:current train perplexity4.2653489112854
INFO:root:current mean train loss 3679.3281965316482
INFO:root:current train perplexity4.260996341705322
INFO:root:current mean train loss 3679.8741145092217
INFO:root:current train perplexity4.262917995452881
INFO:root:current mean train loss 3682.068423048039
INFO:root:current train perplexity4.266389846801758
INFO:root:current mean train loss 3681.0374361624513
INFO:root:current train perplexity4.267477035522461
INFO:root:current mean train loss 3680.130243277303
INFO:root:current train perplexity4.2682366371154785
INFO:root:current mean train loss 3682.4142840117306
INFO:root:current train perplexity4.270322322845459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.98s/it]
INFO:root:final mean train loss: 3679.6870003361855
INFO:root:final train perplexity: 4.270551681518555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 3992.957593985483
INFO:root:eval perplexity: 5.026052951812744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 4904.982217558732
INFO:root:eval perplexity: 7.431402683258057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [4:18:27<10:02:27, 258.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3668.9959639537183
INFO:root:current train perplexity4.25801944732666
INFO:root:current mean train loss 3649.1114276907297
INFO:root:current train perplexity4.230245590209961
INFO:root:current mean train loss 3653.3733636452735
INFO:root:current train perplexity4.22614860534668
INFO:root:current mean train loss 3659.8805868908726
INFO:root:current train perplexity4.23226261138916
INFO:root:current mean train loss 3661.2971578769248
INFO:root:current train perplexity4.2399773597717285
INFO:root:current mean train loss 3664.702620695704
INFO:root:current train perplexity4.242211818695068
INFO:root:current mean train loss 3667.9444517155284
INFO:root:current train perplexity4.248736381530762
INFO:root:current mean train loss 3670.392771181001
INFO:root:current train perplexity4.252091884613037
INFO:root:current mean train loss 3671.504390920524
INFO:root:current train perplexity4.253979206085205
INFO:root:current mean train loss 3672.8206928007694
INFO:root:current train perplexity4.255573272705078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.68s/it]
INFO:root:final mean train loss: 3671.18341981211
INFO:root:final train perplexity: 4.256248950958252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 3991.932324565049
INFO:root:eval perplexity: 5.02396821975708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it]
INFO:root:eval mean loss: 4906.499075382314
INFO:root:eval perplexity: 7.4360127449035645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [4:22:47<9:59:36, 258.82s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3619.0407967403016
INFO:root:current train perplexity4.189572811126709
INFO:root:current mean train loss 3643.473102753175
INFO:root:current train perplexity4.2258477210998535
INFO:root:current mean train loss 3632.998676366507
INFO:root:current train perplexity4.217223167419434
INFO:root:current mean train loss 3634.7872513172238
INFO:root:current train perplexity4.22137451171875
INFO:root:current mean train loss 3647.697691743134
INFO:root:current train perplexity4.227740287780762
INFO:root:current mean train loss 3654.979923072828
INFO:root:current train perplexity4.231575965881348
INFO:root:current mean train loss 3656.3494274244904
INFO:root:current train perplexity4.233397006988525
INFO:root:current mean train loss 3662.7414001697507
INFO:root:current train perplexity4.237979888916016
INFO:root:current mean train loss 3666.1608724325324
INFO:root:current train perplexity4.2416300773620605
INFO:root:current mean train loss 3668.006317726143
INFO:root:current train perplexity4.245842933654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.87s/it]
INFO:root:final mean train loss: 3664.729861105642
INFO:root:final train perplexity: 4.245424747467041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 3992.5176750886526
INFO:root:eval perplexity: 5.025158405303955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4907.799917234596
INFO:root:eval perplexity: 7.439972400665283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [4:27:05<9:54:28, 258.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.41220703125
INFO:root:current train perplexity4.193727970123291
INFO:root:current mean train loss 3660.0615434695515
INFO:root:current train perplexity4.209904670715332
INFO:root:current mean train loss 3658.3860483977755
INFO:root:current train perplexity4.213517189025879
INFO:root:current mean train loss 3652.969476859177
INFO:root:current train perplexity4.2146100997924805
INFO:root:current mean train loss 3652.6053168402777
INFO:root:current train perplexity4.214096546173096
INFO:root:current mean train loss 3653.0263803177522
INFO:root:current train perplexity4.219243049621582
INFO:root:current mean train loss 3653.4115353810703
INFO:root:current train perplexity4.2222208976745605
INFO:root:current mean train loss 3659.446382112323
INFO:root:current train perplexity4.226808547973633
INFO:root:current mean train loss 3657.6835318282997
INFO:root:current train perplexity4.226895332336426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.15s/it]
INFO:root:final mean train loss: 3654.723788415232
INFO:root:final train perplexity: 4.228698253631592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 3994.284188344969
INFO:root:eval perplexity: 5.028748512268066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.59s/it]
INFO:root:eval mean loss: 4910.696889890846
INFO:root:eval perplexity: 7.448788642883301
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [4:31:25<9:51:14, 258.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3444.6678059895835
INFO:root:current train perplexity4.09208345413208
INFO:root:current mean train loss 3624.3702783677186
INFO:root:current train perplexity4.197385787963867
INFO:root:current mean train loss 3636.0302794508157
INFO:root:current train perplexity4.191045761108398
INFO:root:current mean train loss 3632.5192814691627
INFO:root:current train perplexity4.1987481117248535
INFO:root:current mean train loss 3632.8934910776597
INFO:root:current train perplexity4.196942329406738
INFO:root:current mean train loss 3636.4659338888546
INFO:root:current train perplexity4.202164649963379
INFO:root:current mean train loss 3642.373447298015
INFO:root:current train perplexity4.206775188446045
INFO:root:current mean train loss 3647.72940363009
INFO:root:current train perplexity4.212244987487793
INFO:root:current mean train loss 3651.6015652363208
INFO:root:current train perplexity4.214596271514893
INFO:root:current mean train loss 3649.481466401059
INFO:root:current train perplexity4.2153544425964355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.98s/it]
INFO:root:final mean train loss: 3647.374464342671
INFO:root:final train perplexity: 4.216454982757568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.36s/it]
INFO:root:eval mean loss: 3990.893478501773
INFO:root:eval perplexity: 5.021858215332031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4905.090037677305
INFO:root:eval perplexity: 7.4317307472229
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [4:35:43<9:46:31, 258.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3656.9375
INFO:root:current train perplexity4.125214576721191
INFO:root:current mean train loss 3626.325146924268
INFO:root:current train perplexity4.180078983306885
INFO:root:current mean train loss 3634.313702190092
INFO:root:current train perplexity4.185854911804199
INFO:root:current mean train loss 3624.8129686557977
INFO:root:current train perplexity4.184115409851074
INFO:root:current mean train loss 3630.841936468788
INFO:root:current train perplexity4.189144611358643
INFO:root:current mean train loss 3629.368398647719
INFO:root:current train perplexity4.183849334716797
INFO:root:current mean train loss 3630.6425965054727
INFO:root:current train perplexity4.189066410064697
INFO:root:current mean train loss 3632.7346737374737
INFO:root:current train perplexity4.190702438354492
INFO:root:current mean train loss 3636.9945193289536
INFO:root:current train perplexity4.19345235824585
INFO:root:current mean train loss 3636.8380892070013
INFO:root:current train perplexity4.195411682128906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.13s/it]
INFO:root:final mean train loss: 3639.4714911676224
INFO:root:final train perplexity: 4.203329086303711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 3991.5445721132537
INFO:root:eval perplexity: 5.023181438446045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it]
INFO:root:eval mean loss: 4910.078045351285
INFO:root:eval perplexity: 7.44690465927124
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [4:40:00<9:40:47, 258.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.3272897820725
INFO:root:current train perplexity4.179709434509277
INFO:root:current mean train loss 3607.540240119485
INFO:root:current train perplexity4.162136554718018
INFO:root:current mean train loss 3612.7609071775114
INFO:root:current train perplexity4.167588710784912
INFO:root:current mean train loss 3618.9736634257447
INFO:root:current train perplexity4.170182704925537
INFO:root:current mean train loss 3615.294343279199
INFO:root:current train perplexity4.168891906738281
INFO:root:current mean train loss 3620.2965753514873
INFO:root:current train perplexity4.171572208404541
INFO:root:current mean train loss 3629.012143531023
INFO:root:current train perplexity4.181192874908447
INFO:root:current mean train loss 3634.7739407217055
INFO:root:current train perplexity4.187097072601318
INFO:root:current mean train loss 3635.8176555703412
INFO:root:current train perplexity4.188226222991943
INFO:root:current mean train loss 3634.4666964558965
INFO:root:current train perplexity4.190262317657471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it]
INFO:root:final mean train loss: 3632.5719363920152
INFO:root:final train perplexity: 4.1919026374816895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.08s/it]
INFO:root:eval mean loss: 3989.6321666528147
INFO:root:eval perplexity: 5.019298076629639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.36s/it]
INFO:root:eval mean loss: 4911.830317071143
INFO:root:eval perplexity: 7.452243328094482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [4:44:20<9:37:55, 258.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3676.2420789930557
INFO:root:current train perplexity4.224538803100586
INFO:root:current mean train loss 3630.6265321265996
INFO:root:current train perplexity4.173152923583984
INFO:root:current mean train loss 3621.122420928552
INFO:root:current train perplexity4.166646480560303
INFO:root:current mean train loss 3622.4903822032684
INFO:root:current train perplexity4.166548728942871
INFO:root:current mean train loss 3622.715892353996
INFO:root:current train perplexity4.1714067459106445
INFO:root:current mean train loss 3627.79520492988
INFO:root:current train perplexity4.17623233795166
INFO:root:current mean train loss 3625.5918182908445
INFO:root:current train perplexity4.173367977142334
INFO:root:current mean train loss 3623.6068083331543
INFO:root:current train perplexity4.172305583953857
INFO:root:current mean train loss 3624.736934786408
INFO:root:current train perplexity4.173032283782959
INFO:root:current mean train loss 3626.320815793133
INFO:root:current train perplexity4.179471492767334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.82s/it]
INFO:root:final mean train loss: 3625.306407989994
INFO:root:final train perplexity: 4.179903984069824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it]
INFO:root:eval mean loss: 3991.918012037345
INFO:root:eval perplexity: 5.0239410400390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 4914.116929507425
INFO:root:eval perplexity: 7.459211349487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [4:48:38<9:33:17, 258.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3620.6421247209823
INFO:root:current train perplexity4.174463748931885
INFO:root:current mean train loss 3611.184333405671
INFO:root:current train perplexity4.130115509033203
INFO:root:current mean train loss 3614.63016747008
INFO:root:current train perplexity4.140894412994385
INFO:root:current mean train loss 3620.7690626457556
INFO:root:current train perplexity4.1558637619018555
INFO:root:current mean train loss 3618.410705706717
INFO:root:current train perplexity4.155068397521973
INFO:root:current mean train loss 3620.033730651285
INFO:root:current train perplexity4.159202575683594
INFO:root:current mean train loss 3620.7341693067174
INFO:root:current train perplexity4.159769535064697
INFO:root:current mean train loss 3619.6781665205144
INFO:root:current train perplexity4.163121223449707
INFO:root:current mean train loss 3620.1507695546406
INFO:root:current train perplexity4.1662445068359375
INFO:root:current mean train loss 3621.3707430752843
INFO:root:current train perplexity4.166831016540527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.49s/it]
INFO:root:final mean train loss: 3617.209476594002
INFO:root:final train perplexity: 4.1665730476379395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.83s/it]
INFO:root:eval mean loss: 3993.6586619708555
INFO:root:eval perplexity: 5.027477264404297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.13s/it]
INFO:root:eval mean loss: 4918.126371343085
INFO:root:eval perplexity: 7.471451759338379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [4:52:54<9:26:50, 257.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.6803517896074
INFO:root:current train perplexity4.132479667663574
INFO:root:current mean train loss 3589.7965864701705
INFO:root:current train perplexity4.143024444580078
INFO:root:current mean train loss 3594.656437877765
INFO:root:current train perplexity4.138370990753174
INFO:root:current mean train loss 3595.660920701986
INFO:root:current train perplexity4.136325359344482
INFO:root:current mean train loss 3603.008531144187
INFO:root:current train perplexity4.140731334686279
INFO:root:current mean train loss 3605.7155851641633
INFO:root:current train perplexity4.14225959777832
INFO:root:current mean train loss 3610.2397506500292
INFO:root:current train perplexity4.148794651031494
INFO:root:current mean train loss 3611.6791949471103
INFO:root:current train perplexity4.152358531951904
INFO:root:current mean train loss 3613.3705979389088
INFO:root:current train perplexity4.153456687927246
INFO:root:current mean train loss 3612.3583655574794
INFO:root:current train perplexity4.155539035797119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.31s/it]
INFO:root:final mean train loss: 3610.293727567119
INFO:root:final train perplexity: 4.155219554901123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 3991.5983921348625
INFO:root:eval perplexity: 5.023290634155273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 4915.183037940492
INFO:root:eval perplexity: 7.46246337890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [4:57:14<9:24:23, 258.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.223211550245
INFO:root:current train perplexity4.099095344543457
INFO:root:current mean train loss 3594.2845984452606
INFO:root:current train perplexity4.12691593170166
INFO:root:current mean train loss 3605.5980482367404
INFO:root:current train perplexity4.139671325683594
INFO:root:current mean train loss 3603.9930513822114
INFO:root:current train perplexity4.136244297027588
INFO:root:current mean train loss 3609.2331201929737
INFO:root:current train perplexity4.143074989318848
INFO:root:current mean train loss 3607.7990749241435
INFO:root:current train perplexity4.143762588500977
INFO:root:current mean train loss 3605.4301431541617
INFO:root:current train perplexity4.13905143737793
INFO:root:current mean train loss 3601.7222290851782
INFO:root:current train perplexity4.138093948364258
INFO:root:current mean train loss 3602.5160088544726
INFO:root:current train perplexity4.138826370239258
INFO:root:current mean train loss 3604.0346969780985
INFO:root:current train perplexity4.140585422515869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.39s/it]
INFO:root:final mean train loss: 3602.532873215214
INFO:root:final train perplexity: 4.142516136169434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 3992.0619840148493
INFO:root:eval perplexity: 5.024232387542725
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.32s/it]
INFO:root:eval mean loss: 4920.325131247229
INFO:root:eval perplexity: 7.478172302246094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [5:01:31<9:18:50, 257.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3587.2285818326272
INFO:root:current train perplexity4.109277725219727
INFO:root:current mean train loss 3601.994906827339
INFO:root:current train perplexity4.122629642486572
INFO:root:current mean train loss 3594.7306525624394
INFO:root:current train perplexity4.121091365814209
INFO:root:current mean train loss 3593.722510037648
INFO:root:current train perplexity4.124549865722656
INFO:root:current mean train loss 3591.009937427662
INFO:root:current train perplexity4.125257968902588
INFO:root:current mean train loss 3593.7175555015933
INFO:root:current train perplexity4.130190849304199
INFO:root:current mean train loss 3588.2601209070326
INFO:root:current train perplexity4.122059345245361
INFO:root:current mean train loss 3596.0016768182845
INFO:root:current train perplexity4.123701095581055
INFO:root:current mean train loss 3595.617050224189
INFO:root:current train perplexity4.125991344451904
INFO:root:current mean train loss 3598.420971246904
INFO:root:current train perplexity4.130160808563232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.60s/it]
INFO:root:final mean train loss: 3595.240428555396
INFO:root:final train perplexity: 4.130615711212158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 3991.336290724734
INFO:root:eval perplexity: 5.022758960723877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.49s/it]
INFO:root:eval mean loss: 4923.164703152704
INFO:root:eval perplexity: 7.486861705780029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [5:05:47<9:13:27, 257.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3580.9681451142724
INFO:root:current train perplexity4.105024337768555
INFO:root:current mean train loss 3576.4881452914483
INFO:root:current train perplexity4.089711666107178
INFO:root:current mean train loss 3587.281932130735
INFO:root:current train perplexity4.101395130157471
INFO:root:current mean train loss 3580.999828369806
INFO:root:current train perplexity4.1027655601501465
INFO:root:current mean train loss 3582.575893753346
INFO:root:current train perplexity4.103201389312744
INFO:root:current mean train loss 3586.4188759886188
INFO:root:current train perplexity4.109271049499512
INFO:root:current mean train loss 3589.90673645111
INFO:root:current train perplexity4.114077091217041
INFO:root:current mean train loss 3590.4411955314945
INFO:root:current train perplexity4.117830276489258
INFO:root:current mean train loss 3590.7347033367573
INFO:root:current train perplexity4.116679668426514
INFO:root:current mean train loss 3590.7193965813244
INFO:root:current train perplexity4.11883020401001

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.64s/it]
INFO:root:final mean train loss: 3588.409435764436
INFO:root:final train perplexity: 4.119497776031494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.92s/it]
INFO:root:eval mean loss: 3992.581939480829
INFO:root:eval perplexity: 5.025288105010986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 4928.923570132425
INFO:root:eval perplexity: 7.50451135635376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [5:10:04<9:08:56, 257.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3581.2876529947916
INFO:root:current train perplexity4.129079818725586
INFO:root:current mean train loss 3583.165
INFO:root:current train perplexity4.1125946044921875
INFO:root:current mean train loss 3588.008947088068
INFO:root:current train perplexity4.1092119216918945
INFO:root:current mean train loss 3584.549040364583
INFO:root:current train perplexity4.102033615112305
INFO:root:current mean train loss 3580.9596104029606
INFO:root:current train perplexity4.101823806762695
INFO:root:current mean train loss 3581.9471403702446
INFO:root:current train perplexity4.101508140563965
INFO:root:current mean train loss 3579.9423093894675
INFO:root:current train perplexity4.1021647453308105
INFO:root:current mean train loss 3580.2331631174393
INFO:root:current train perplexity4.104229927062988
INFO:root:current mean train loss 3584.3974676339285
INFO:root:current train perplexity4.107335090637207
INFO:root:current mean train loss 3583.8297473457533
INFO:root:current train perplexity4.107884883880615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.27s/it]
INFO:root:final mean train loss: 3581.2391826260473
INFO:root:final train perplexity: 4.107861518859863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 3994.1602947695037
INFO:root:eval perplexity: 5.028497695922852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 4928.195986051086
INFO:root:eval perplexity: 7.5022807121276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [5:14:22<9:04:40, 257.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.1766931005272
INFO:root:current train perplexity4.0660905838012695
INFO:root:current mean train loss 3564.2231565381658
INFO:root:current train perplexity4.073060989379883
INFO:root:current mean train loss 3572.729176443794
INFO:root:current train perplexity4.083739280700684
INFO:root:current mean train loss 3577.5832455786963
INFO:root:current train perplexity4.083523273468018
INFO:root:current mean train loss 3580.9464826564117
INFO:root:current train perplexity4.0893425941467285
INFO:root:current mean train loss 3582.333708826919
INFO:root:current train perplexity4.09286642074585
INFO:root:current mean train loss 3582.3890518478906
INFO:root:current train perplexity4.094565391540527
INFO:root:current mean train loss 3582.3791204576746
INFO:root:current train perplexity4.094604969024658
INFO:root:current mean train loss 3580.669932381618
INFO:root:current train perplexity4.095303535461426
INFO:root:current mean train loss 3577.842741895425
INFO:root:current train perplexity4.097817897796631

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.58s/it]
INFO:root:final mean train loss: 3574.103011900379
INFO:root:final train perplexity: 4.096312046051025
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 3994.8147111175754
INFO:root:eval perplexity: 5.029828071594238
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4927.309314051418
INFO:root:eval perplexity: 7.499560356140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [5:18:41<9:01:40, 257.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.1327239654875
INFO:root:current train perplexity4.042975902557373
INFO:root:current mean train loss 3574.848985602094
INFO:root:current train perplexity4.064275741577148
INFO:root:current mean train loss 3574.1366860301223
INFO:root:current train perplexity4.074227809906006
INFO:root:current mean train loss 3575.916266634031
INFO:root:current train perplexity4.079208850860596
INFO:root:current mean train loss 3573.945720229761
INFO:root:current train perplexity4.079861164093018
INFO:root:current mean train loss 3572.8079451869185
INFO:root:current train perplexity4.078702926635742
INFO:root:current mean train loss 3571.6749802850263
INFO:root:current train perplexity4.081470012664795
INFO:root:current mean train loss 3571.2162675435566
INFO:root:current train perplexity4.0813493728637695
INFO:root:current mean train loss 3571.863099857078
INFO:root:current train perplexity4.085443019866943
INFO:root:current mean train loss 3571.9380323793043
INFO:root:current train perplexity4.08843994140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.81s/it]
INFO:root:final mean train loss: 3569.2288403049592
INFO:root:final train perplexity: 4.088442325592041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 3995.4200015237147
INFO:root:eval perplexity: 5.031059265136719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.35s/it]
INFO:root:eval mean loss: 4930.383020279255
INFO:root:eval perplexity: 7.508993148803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [5:22:57<8:56:17, 257.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.055871212121
INFO:root:current train perplexity4.0348358154296875
INFO:root:current mean train loss 3545.981461261385
INFO:root:current train perplexity4.0601630210876465
INFO:root:current mean train loss 3549.7284650005226
INFO:root:current train perplexity4.0625739097595215
INFO:root:current mean train loss 3547.729593147909
INFO:root:current train perplexity4.05924129486084
INFO:root:current mean train loss 3552.732659655248
INFO:root:current train perplexity4.0608601570129395
INFO:root:current mean train loss 3555.3900621315474
INFO:root:current train perplexity4.065326690673828
INFO:root:current mean train loss 3561.7889531780893
INFO:root:current train perplexity4.071784973144531
INFO:root:current mean train loss 3565.7256070209833
INFO:root:current train perplexity4.075164318084717
INFO:root:current mean train loss 3565.4258005314064
INFO:root:current train perplexity4.0768280029296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.33s/it]
INFO:root:final mean train loss: 3562.4449782217703
INFO:root:final train perplexity: 4.0775146484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 3996.5288813164893
INFO:root:eval perplexity: 5.033315658569336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.27s/it]
INFO:root:eval mean loss: 4933.012527357602
INFO:root:eval perplexity: 7.51707124710083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [5:27:17<8:53:18, 258.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.124197823661
INFO:root:current train perplexity4.033822536468506
INFO:root:current mean train loss 3579.6368967216704
INFO:root:current train perplexity4.064053535461426
INFO:root:current mean train loss 3557.26024329144
INFO:root:current train perplexity4.054113864898682
INFO:root:current mean train loss 3552.1337477096904
INFO:root:current train perplexity4.058425426483154
INFO:root:current mean train loss 3549.0264949564266
INFO:root:current train perplexity4.059181213378906
INFO:root:current mean train loss 3550.4674642890163
INFO:root:current train perplexity4.058968544006348
INFO:root:current mean train loss 3550.583552805164
INFO:root:current train perplexity4.056194305419922
INFO:root:current mean train loss 3554.1011339589595
INFO:root:current train perplexity4.058201789855957
INFO:root:current mean train loss 3558.616943056846
INFO:root:current train perplexity4.062849044799805
INFO:root:current mean train loss 3559.236497166138
INFO:root:current train perplexity4.065037250518799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.62s/it]
INFO:root:final mean train loss: 3554.5040368110904
INFO:root:final train perplexity: 4.064760684967041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 3998.9554209607713
INFO:root:eval perplexity: 5.0382561683654785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.42s/it]
INFO:root:eval mean loss: 4937.573560782358
INFO:root:eval perplexity: 7.531105041503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [5:31:33<8:47:53, 257.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.197542317708
INFO:root:current train perplexity4.01120662689209
INFO:root:current mean train loss 3537.8765858525817
INFO:root:current train perplexity4.0372514724731445
INFO:root:current mean train loss 3538.1864587118457
INFO:root:current train perplexity4.037576675415039
INFO:root:current mean train loss 3546.2356212797617
INFO:root:current train perplexity4.037161350250244
INFO:root:current mean train loss 3540.3341279179217
INFO:root:current train perplexity4.035576820373535
INFO:root:current mean train loss 3546.11618439017
INFO:root:current train perplexity4.040679931640625
INFO:root:current mean train loss 3551.7194808339686
INFO:root:current train perplexity4.048534870147705
INFO:root:current mean train loss 3548.2512504097467
INFO:root:current train perplexity4.0455241203308105
INFO:root:current mean train loss 3549.1939608895705
INFO:root:current train perplexity4.0521440505981445
INFO:root:current mean train loss 3551.4642527429132
INFO:root:current train perplexity4.053969383239746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.85s/it]
INFO:root:final mean train loss: 3548.436610498736
INFO:root:final train perplexity: 4.055041313171387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 3995.326474886414
INFO:root:eval perplexity: 5.030869483947754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.72s/it]
INFO:root:eval mean loss: 4934.620363059619
INFO:root:eval perplexity: 7.5220160484313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [5:35:53<8:44:53, 258.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.6639988111415
INFO:root:current train perplexity3.9775803089141846
INFO:root:current mean train loss 3508.2770281535823
INFO:root:current train perplexity4.003112316131592
INFO:root:current mean train loss 3508.1856355538816
INFO:root:current train perplexity4.014563083648682
INFO:root:current mean train loss 3517.3480001632643
INFO:root:current train perplexity4.024035453796387
INFO:root:current mean train loss 3521.659621795582
INFO:root:current train perplexity4.025451183319092
INFO:root:current mean train loss 3526.3788273594346
INFO:root:current train perplexity4.027108669281006
INFO:root:current mean train loss 3532.139868281626
INFO:root:current train perplexity4.0331597328186035
INFO:root:current mean train loss 3536.969119756548
INFO:root:current train perplexity4.037997722625732
INFO:root:current mean train loss 3542.9329479491003
INFO:root:current train perplexity4.044441223144531
INFO:root:current mean train loss 3545.345135755942
INFO:root:current train perplexity4.045102596282959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.89s/it]
INFO:root:final mean train loss: 3542.3962773969097
INFO:root:final train perplexity: 4.045389652252197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 3996.2601829150044
INFO:root:eval perplexity: 5.032768726348877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4936.336034463652
INFO:root:eval perplexity: 7.527294158935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [5:40:11<8:40:57, 258.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3542.4261277721776
INFO:root:current train perplexity4.048801422119141
INFO:root:current mean train loss 3534.6770299081586
INFO:root:current train perplexity4.038305759429932
INFO:root:current mean train loss 3537.1977253703326
INFO:root:current train perplexity4.0176286697387695
INFO:root:current mean train loss 3532.804563585725
INFO:root:current train perplexity4.018981456756592
INFO:root:current mean train loss 3529.3479961209396
INFO:root:current train perplexity4.019311428070068
INFO:root:current mean train loss 3528.6049446062852
INFO:root:current train perplexity4.017787933349609
INFO:root:current mean train loss 3532.798799880522
INFO:root:current train perplexity4.023258209228516
INFO:root:current mean train loss 3536.5029019670187
INFO:root:current train perplexity4.028242588043213
INFO:root:current mean train loss 3537.3410391870675
INFO:root:current train perplexity4.031967639923096
INFO:root:current mean train loss 3536.8324143750838
INFO:root:current train perplexity4.033066749572754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.24s/it]
INFO:root:final mean train loss: 3535.5431351200227
INFO:root:final train perplexity: 4.034466743469238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 3998.35149843473
INFO:root:eval perplexity: 5.037026405334473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]
INFO:root:eval mean loss: 4942.544966893839
INFO:root:eval perplexity: 7.546429634094238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [5:44:29<8:36:11, 258.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.52584760617
INFO:root:current train perplexity3.9962356090545654
INFO:root:current mean train loss 3533.900297535409
INFO:root:current train perplexity4.015766620635986
INFO:root:current mean train loss 3532.411889750588
INFO:root:current train perplexity4.022646427154541
INFO:root:current mean train loss 3543.2184367222067
INFO:root:current train perplexity4.022783279418945
INFO:root:current mean train loss 3541.6577760179384
INFO:root:current train perplexity4.0251970291137695
INFO:root:current mean train loss 3538.3592912040526
INFO:root:current train perplexity4.0269575119018555
INFO:root:current mean train loss 3533.776074524403
INFO:root:current train perplexity4.023775577545166
INFO:root:current mean train loss 3530.48741172615
INFO:root:current train perplexity4.022285461425781
INFO:root:current mean train loss 3531.489694006537
INFO:root:current train perplexity4.025635719299316
INFO:root:current mean train loss 3533.0936641997805
INFO:root:current train perplexity4.026078224182129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.15s/it]
INFO:root:final mean train loss: 3530.302855891566
INFO:root:final train perplexity: 4.026134490966797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 3996.343453914561
INFO:root:eval perplexity: 5.032938480377197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.45s/it]
INFO:root:eval mean loss: 4942.525645154587
INFO:root:eval perplexity: 7.546371936798096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [5:48:46<8:31:30, 257.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3482.185276761968
INFO:root:current train perplexity4.010776519775391
INFO:root:current mean train loss 3495.5628803279124
INFO:root:current train perplexity4.004281520843506
INFO:root:current mean train loss 3501.365017910235
INFO:root:current train perplexity4.001851558685303
INFO:root:current mean train loss 3509.135959592264
INFO:root:current train perplexity4.006372451782227
INFO:root:current mean train loss 3514.991723796665
INFO:root:current train perplexity4.001777648925781
INFO:root:current mean train loss 3519.5834121843577
INFO:root:current train perplexity4.006501197814941
INFO:root:current mean train loss 3521.4139179778062
INFO:root:current train perplexity4.006383895874023
INFO:root:current mean train loss 3523.8452337997824
INFO:root:current train perplexity4.008150577545166
INFO:root:current mean train loss 3522.6057964806855
INFO:root:current train perplexity4.008968353271484
INFO:root:current mean train loss 3524.493691272192
INFO:root:current train perplexity4.012882232666016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.20s/it]
INFO:root:final mean train loss: 3522.662309277442
INFO:root:final train perplexity: 4.014015197753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 4000.6775144752883
INFO:root:eval perplexity: 5.041767120361328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 4950.061109610483
INFO:root:eval perplexity: 7.5696587562561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [5:53:04<8:27:00, 257.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3489.3994939630684
INFO:root:current train perplexity3.995673656463623
INFO:root:current mean train loss 3504.908782762097
INFO:root:current train perplexity4.004618167877197
INFO:root:current mean train loss 3502.8766295189953
INFO:root:current train perplexity3.9975039958953857
INFO:root:current mean train loss 3505.0936495928695
INFO:root:current train perplexity3.9927120208740234
INFO:root:current mean train loss 3511.9820307134273
INFO:root:current train perplexity3.9957218170166016
INFO:root:current mean train loss 3516.615114724099
INFO:root:current train perplexity4.000438213348389
INFO:root:current mean train loss 3516.3967542342557
INFO:root:current train perplexity4.003455638885498
INFO:root:current mean train loss 3518.817001888452
INFO:root:current train perplexity4.00722074508667
INFO:root:current mean train loss 3522.097527754934
INFO:root:current train perplexity4.00805139541626
INFO:root:current mean train loss 3521.71616901178
INFO:root:current train perplexity4.00837516784668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.51s/it]
INFO:root:final mean train loss: 3518.2943341655114
INFO:root:final train perplexity: 4.007104873657227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 3999.1014309064717
INFO:root:eval perplexity: 5.03855562210083
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it]
INFO:root:eval mean loss: 4948.826364070811
INFO:root:eval perplexity: 7.565837383270264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [5:57:24<8:23:53, 258.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3468.7791418650795
INFO:root:current train perplexity3.9473330974578857
INFO:root:current mean train loss 3483.710209571511
INFO:root:current train perplexity3.9692161083221436
INFO:root:current mean train loss 3491.0707515818085
INFO:root:current train perplexity3.971320867538452
INFO:root:current mean train loss 3505.6279781120866
INFO:root:current train perplexity3.9848101139068604
INFO:root:current mean train loss 3505.852540117103
INFO:root:current train perplexity3.9868271350860596
INFO:root:current mean train loss 3509.6575045272257
INFO:root:current train perplexity3.991774559020996
INFO:root:current mean train loss 3508.3473347797653
INFO:root:current train perplexity3.9907257556915283
INFO:root:current mean train loss 3510.312091392427
INFO:root:current train perplexity3.9924583435058594
INFO:root:current mean train loss 3511.494988186196
INFO:root:current train perplexity3.994203567504883
INFO:root:current mean train loss 3512.830630800558
INFO:root:current train perplexity3.994067430496216

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.00s/it]
INFO:root:final mean train loss: 3511.159113299462
INFO:root:final train perplexity: 3.995840311050415
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4000.652251980829
INFO:root:eval perplexity: 5.041714668273926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 4951.391052678967
INFO:root:eval perplexity: 7.57377815246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [6:01:40<8:18:35, 257.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3460.77363350022
INFO:root:current train perplexity3.9360108375549316
INFO:root:current mean train loss 3477.4052334612575
INFO:root:current train perplexity3.958749771118164
INFO:root:current mean train loss 3478.891270936635
INFO:root:current train perplexity3.960963249206543
INFO:root:current mean train loss 3496.055006001516
INFO:root:current train perplexity3.973539113998413
INFO:root:current mean train loss 3498.188050482683
INFO:root:current train perplexity3.979984998703003
INFO:root:current mean train loss 3494.7646069635234
INFO:root:current train perplexity3.9739465713500977
INFO:root:current mean train loss 3497.6621199265323
INFO:root:current train perplexity3.9771862030029297
INFO:root:current mean train loss 3502.4587500506645
INFO:root:current train perplexity3.9810307025909424
INFO:root:current mean train loss 3504.224535656304
INFO:root:current train perplexity3.983578681945801
INFO:root:current mean train loss 3505.123162030928
INFO:root:current train perplexity3.9849162101745605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.52s/it]
INFO:root:final mean train loss: 3504.3252641001054
INFO:root:final train perplexity: 3.9850809574127197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4002.558056986924
INFO:root:eval perplexity: 5.045602321624756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 4955.136150820035
INFO:root:eval perplexity: 7.585383415222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [6:05:58<8:14:00, 257.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3465.4857903975476
INFO:root:current train perplexity3.95100998878479
INFO:root:current mean train loss 3471.0011115899965
INFO:root:current train perplexity3.9515817165374756
INFO:root:current mean train loss 3485.6587920376905
INFO:root:current train perplexity3.9607059955596924
INFO:root:current mean train loss 3486.3323604211328
INFO:root:current train perplexity3.9579145908355713
INFO:root:current mean train loss 3488.511201416525
INFO:root:current train perplexity3.960421323776245
INFO:root:current mean train loss 3492.0062962138386
INFO:root:current train perplexity3.962932825088501
INFO:root:current mean train loss 3492.234455900796
INFO:root:current train perplexity3.9670908451080322
INFO:root:current mean train loss 3494.2648621780727
INFO:root:current train perplexity3.9689342975616455
INFO:root:current mean train loss 3498.731446423493
INFO:root:current train perplexity3.973503589630127
INFO:root:current mean train loss 3501.2857016387097
INFO:root:current train perplexity3.9766652584075928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.46s/it]
INFO:root:final mean train loss: 3498.8726032010973
INFO:root:final train perplexity: 3.9765172004699707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 4002.5505769337324
INFO:root:eval perplexity: 5.045587539672852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.23s/it]
INFO:root:eval mean loss: 4956.397357047872
INFO:root:eval perplexity: 7.589298248291016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [6:10:15<8:09:37, 257.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3478.796426005747
INFO:root:current train perplexity3.9358696937561035
INFO:root:current mean train loss 3475.6453158944687
INFO:root:current train perplexity3.939103603363037
INFO:root:current mean train loss 3483.7547900901022
INFO:root:current train perplexity3.9457669258117676
INFO:root:current mean train loss 3485.0414723635336
INFO:root:current train perplexity3.947519540786743
INFO:root:current mean train loss 3489.104439048062
INFO:root:current train perplexity3.9535696506500244
INFO:root:current mean train loss 3491.4361857165673
INFO:root:current train perplexity3.9589810371398926
INFO:root:current mean train loss 3492.360581488241
INFO:root:current train perplexity3.9626286029815674
INFO:root:current mean train loss 3496.182170785519
INFO:root:current train perplexity3.9678831100463867
INFO:root:current mean train loss 3496.083260485661
INFO:root:current train perplexity3.9678235054016113
INFO:root:current mean train loss 3496.0215885119837
INFO:root:current train perplexity3.968017339706421

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.01s/it]
INFO:root:final mean train loss: 3493.40579125189
INFO:root:final train perplexity: 3.9679503440856934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4004.8027326435063
INFO:root:eval perplexity: 5.05018424987793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 4957.044144434286
INFO:root:eval perplexity: 7.591305255889893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [6:14:33<8:05:04, 257.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.100853207237
INFO:root:current train perplexity3.9598100185394287
INFO:root:current mean train loss 3492.191523938301
INFO:root:current train perplexity3.9480457305908203
INFO:root:current mean train loss 3490.4251886917373
INFO:root:current train perplexity3.9513401985168457
INFO:root:current mean train loss 3490.261946202532
INFO:root:current train perplexity3.9542205333709717
INFO:root:current mean train loss 3492.3411433672663
INFO:root:current train perplexity3.9547815322875977
INFO:root:current mean train loss 3489.601867368041
INFO:root:current train perplexity3.9537878036499023
INFO:root:current mean train loss 3491.7609431205037
INFO:root:current train perplexity3.9571099281311035
INFO:root:current mean train loss 3491.4435651287345
INFO:root:current train perplexity3.9573848247528076
INFO:root:current mean train loss 3491.490261926065
INFO:root:current train perplexity3.9592738151550293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.63s/it]
INFO:root:final mean train loss: 3487.9577130963726
INFO:root:final train perplexity: 3.959430456161499
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 4004.133492977061
INFO:root:eval perplexity: 5.048817157745361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it]
INFO:root:eval mean loss: 4960.576469691932
INFO:root:eval perplexity: 7.602279186248779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [6:18:50<8:00:26, 257.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3582.5463053385415
INFO:root:current train perplexity4.033076286315918
INFO:root:current mean train loss 3454.871352112409
INFO:root:current train perplexity3.91279935836792
INFO:root:current mean train loss 3461.9841958031866
INFO:root:current train perplexity3.9279706478118896
INFO:root:current mean train loss 3473.0254720052085
INFO:root:current train perplexity3.942347526550293
INFO:root:current mean train loss 3470.6715490752945
INFO:root:current train perplexity3.9420974254608154
INFO:root:current mean train loss 3480.7757226174203
INFO:root:current train perplexity3.9504244327545166
INFO:root:current mean train loss 3481.78272334616
INFO:root:current train perplexity3.949406147003174
INFO:root:current mean train loss 3483.7668498705325
INFO:root:current train perplexity3.949155569076538
INFO:root:current mean train loss 3484.1600145693883
INFO:root:current train perplexity3.950059175491333
INFO:root:current mean train loss 3484.5366529969547
INFO:root:current train perplexity3.9511921405792236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.02s/it]
INFO:root:final mean train loss: 3483.5123263328305
INFO:root:final train perplexity: 3.9524919986724854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 4003.946365248227
INFO:root:eval perplexity: 5.048435688018799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]
INFO:root:eval mean loss: 4957.424250609486
INFO:root:eval perplexity: 7.5924835205078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [6:23:09<7:57:32, 258.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3549.8929332386365
INFO:root:current train perplexity4.037386894226074
INFO:root:current mean train loss 3480.336478568412
INFO:root:current train perplexity3.9270455837249756
INFO:root:current mean train loss 3467.1585190036285
INFO:root:current train perplexity3.9175198078155518
INFO:root:current mean train loss 3461.9427870968148
INFO:root:current train perplexity3.9131906032562256
INFO:root:current mean train loss 3470.056800415336
INFO:root:current train perplexity3.9240024089813232
INFO:root:current mean train loss 3474.6990042311336
INFO:root:current train perplexity3.92887544631958
INFO:root:current mean train loss 3477.755912918116
INFO:root:current train perplexity3.9326608180999756
INFO:root:current mean train loss 3477.7410069719144
INFO:root:current train perplexity3.9340569972991943
INFO:root:current mean train loss 3477.179713088105
INFO:root:current train perplexity3.9350340366363525
INFO:root:current mean train loss 3479.5983267657452
INFO:root:current train perplexity3.939251184463501

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.40s/it]
INFO:root:final mean train loss: 3476.8741800861976
INFO:root:final train perplexity: 3.9421544075012207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 4005.9234368074026
INFO:root:eval perplexity: 5.052473545074463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.36s/it]
INFO:root:eval mean loss: 4962.290795725288
INFO:root:eval perplexity: 7.607609748840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [6:27:26<7:52:24, 257.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3473.4637643914475
INFO:root:current train perplexity3.9750216007232666
INFO:root:current mean train loss 3464.9313944327732
INFO:root:current train perplexity3.919832468032837
INFO:root:current mean train loss 3456.09126177226
INFO:root:current train perplexity3.904741048812866
INFO:root:current mean train loss 3459.1833656813283
INFO:root:current train perplexity3.909071922302246
INFO:root:current mean train loss 3463.0308432931834
INFO:root:current train perplexity3.919694662094116
INFO:root:current mean train loss 3463.4446689848264
INFO:root:current train perplexity3.922581672668457
INFO:root:current mean train loss 3466.6551598470314
INFO:root:current train perplexity3.925381660461426
INFO:root:current mean train loss 3472.3228669783334
INFO:root:current train perplexity3.9319660663604736
INFO:root:current mean train loss 3473.8963442698796
INFO:root:current train perplexity3.9345951080322266
INFO:root:current mean train loss 3473.5004420565833
INFO:root:current train perplexity3.9326720237731934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.70s/it]
INFO:root:final mean train loss: 3470.9564715969946
INFO:root:final train perplexity: 3.9329617023468018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4007.958321212877
INFO:root:eval perplexity: 5.0566325187683105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.23s/it]
INFO:root:eval mean loss: 4968.090101742575
INFO:root:eval perplexity: 7.62567138671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [6:31:43<7:47:47, 257.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3443.637080439815
INFO:root:current train perplexity3.91375470161438
INFO:root:current mean train loss 3469.9899787001723
INFO:root:current train perplexity3.913388967514038
INFO:root:current mean train loss 3474.07741731484
INFO:root:current train perplexity3.926344871520996
INFO:root:current mean train loss 3480.18161748017
INFO:root:current train perplexity3.9262773990631104
INFO:root:current mean train loss 3477.8198453737923
INFO:root:current train perplexity3.926234006881714
INFO:root:current mean train loss 3474.470426092564
INFO:root:current train perplexity3.9233336448669434
INFO:root:current mean train loss 3473.474673622533
INFO:root:current train perplexity3.9217891693115234
INFO:root:current mean train loss 3471.2584216761948
INFO:root:current train perplexity3.9227869510650635
INFO:root:current mean train loss 3469.4373048646275
INFO:root:current train perplexity3.924727439880371
INFO:root:current mean train loss 3469.0932509207287
INFO:root:current train perplexity3.9241960048675537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.19s/it]
INFO:root:final mean train loss: 3466.2628008319484
INFO:root:final train perplexity: 3.925685405731201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4010.27236051086
INFO:root:eval perplexity: 5.061366081237793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it]
INFO:root:eval mean loss: 4969.974619763962
INFO:root:eval perplexity: 7.631549835205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [6:36:03<7:44:39, 258.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3456.7129255022323
INFO:root:current train perplexity3.891585350036621
INFO:root:current mean train loss 3456.9955674913194
INFO:root:current train perplexity3.881035566329956
INFO:root:current mean train loss 3452.356079621011
INFO:root:current train perplexity3.889862298965454
INFO:root:current mean train loss 3456.554741429571
INFO:root:current train perplexity3.900017738342285
INFO:root:current mean train loss 3462.466537580819
INFO:root:current train perplexity3.905320405960083
INFO:root:current mean train loss 3459.2064270589954
INFO:root:current train perplexity3.9084861278533936
INFO:root:current mean train loss 3456.801020007997
INFO:root:current train perplexity3.9089338779449463
INFO:root:current mean train loss 3458.664142219388
INFO:root:current train perplexity3.910552978515625
INFO:root:current mean train loss 3460.0014557798468
INFO:root:current train perplexity3.913360357284546
INFO:root:current mean train loss 3461.5658500793784
INFO:root:current train perplexity3.9151148796081543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.69s/it]
INFO:root:final mean train loss: 3460.5658106650076
INFO:root:final train perplexity: 3.916872024536133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 4008.698198900155
INFO:root:eval perplexity: 5.058145046234131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it]
INFO:root:eval mean loss: 4970.09945873504
INFO:root:eval perplexity: 7.631938934326172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [6:40:19<7:39:16, 257.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3406.9203306686045
INFO:root:current train perplexity3.821833610534668
INFO:root:current mean train loss 3442.02273751639
INFO:root:current train perplexity3.881497621536255
INFO:root:current mean train loss 3449.2961777424125
INFO:root:current train perplexity3.8883206844329834
INFO:root:current mean train loss 3452.4480279416453
INFO:root:current train perplexity3.8904995918273926
INFO:root:current mean train loss 3452.8735202763473
INFO:root:current train perplexity3.8919248580932617
INFO:root:current mean train loss 3453.572379377446
INFO:root:current train perplexity3.896533250808716
INFO:root:current mean train loss 3456.5454355954753
INFO:root:current train perplexity3.901439666748047
INFO:root:current mean train loss 3460.8904577488856
INFO:root:current train perplexity3.9046032428741455
INFO:root:current mean train loss 3458.8188864638937
INFO:root:current train perplexity3.9051413536071777
INFO:root:current mean train loss 3459.9996326240225
INFO:root:current train perplexity3.9091954231262207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.32s/it]
INFO:root:final mean train loss: 3455.6398652599705
INFO:root:final train perplexity: 3.9092671871185303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4009.0071770417776
INFO:root:eval perplexity: 5.05877685546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 4969.957183621454
INFO:root:eval perplexity: 7.631494998931885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [6:44:39<7:36:16, 258.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3441.2934426700367
INFO:root:current train perplexity3.891375780105591
INFO:root:current mean train loss 3439.788368881933
INFO:root:current train perplexity3.8944687843322754
INFO:root:current mean train loss 3438.556537521788
INFO:root:current train perplexity3.8864541053771973
INFO:root:current mean train loss 3443.3934879139956
INFO:root:current train perplexity3.8880834579467773
INFO:root:current mean train loss 3444.722920961232
INFO:root:current train perplexity3.8898088932037354
INFO:root:current mean train loss 3443.080007674257
INFO:root:current train perplexity3.8878767490386963
INFO:root:current mean train loss 3448.0235492571524
INFO:root:current train perplexity3.893629550933838
INFO:root:current mean train loss 3448.094848470269
INFO:root:current train perplexity3.893280506134033
INFO:root:current mean train loss 3448.4327167372026
INFO:root:current train perplexity3.89613938331604
INFO:root:current mean train loss 3451.779598264163
INFO:root:current train perplexity3.8987436294555664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.25s/it]
INFO:root:final mean train loss: 3449.9785060267295
INFO:root:final train perplexity: 3.900545120239258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 4012.123940325798
INFO:root:eval perplexity: 5.065157413482666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.22s/it]
INFO:root:eval mean loss: 4974.162595924756
INFO:root:eval perplexity: 7.644628524780273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [6:48:54<7:30:25, 257.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3399.900361659163
INFO:root:current train perplexity3.841256618499756
INFO:root:current mean train loss 3420.1596418656645
INFO:root:current train perplexity3.8583407402038574
INFO:root:current mean train loss 3421.9367458976835
INFO:root:current train perplexity3.8666298389434814
INFO:root:current mean train loss 3433.656204436151
INFO:root:current train perplexity3.876021146774292
INFO:root:current mean train loss 3436.0269602524168
INFO:root:current train perplexity3.8804399967193604
INFO:root:current mean train loss 3444.615647972803
INFO:root:current train perplexity3.886535167694092
INFO:root:current mean train loss 3445.0266687511853
INFO:root:current train perplexity3.888723134994507
INFO:root:current mean train loss 3443.394927857893
INFO:root:current train perplexity3.8884482383728027
INFO:root:current mean train loss 3445.552954925786
INFO:root:current train perplexity3.8923096656799316
INFO:root:current mean train loss 3446.79539182661
INFO:root:current train perplexity3.8929967880249023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.41s/it]
INFO:root:final mean train loss: 3444.9219468639744
INFO:root:final train perplexity: 3.892770767211914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it]
INFO:root:eval mean loss: 4011.321363516733
INFO:root:eval perplexity: 5.06351375579834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it]
INFO:root:eval mean loss: 4972.221544630984
INFO:root:eval perplexity: 7.638563632965088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [6:53:14<7:27:36, 258.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3423.490205223881
INFO:root:current train perplexity3.877089738845825
INFO:root:current mean train loss 3443.018500596463
INFO:root:current train perplexity3.8797407150268555
INFO:root:current mean train loss 3438.0308659585676
INFO:root:current train perplexity3.8777456283569336
INFO:root:current mean train loss 3440.662663514348
INFO:root:current train perplexity3.882425546646118
INFO:root:current mean train loss 3436.16536318924
INFO:root:current train perplexity3.8787333965301514
INFO:root:current mean train loss 3440.1547136794534
INFO:root:current train perplexity3.8840956687927246
INFO:root:current mean train loss 3441.619159658452
INFO:root:current train perplexity3.885143756866455
INFO:root:current mean train loss 3442.2440206236756
INFO:root:current train perplexity3.8863582611083984
INFO:root:current mean train loss 3439.3136742403763
INFO:root:current train perplexity3.8837156295776367
INFO:root:current mean train loss 3441.5870519123255
INFO:root:current train perplexity3.8849639892578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.47s/it]
INFO:root:final mean train loss: 3439.792436476677
INFO:root:final train perplexity: 3.884902000427246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 4012.8799538037456
INFO:root:eval perplexity: 5.066705226898193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.76s/it]
INFO:root:eval mean loss: 4979.426103307846
INFO:root:eval perplexity: 7.661102771759033
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [6:57:31<7:22:41, 257.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3405.776334635417
INFO:root:current train perplexity3.8390886783599854
INFO:root:current mean train loss 3413.182156808036
INFO:root:current train perplexity3.8431272506713867
INFO:root:current mean train loss 3425.5267542613637
INFO:root:current train perplexity3.8516340255737305
INFO:root:current mean train loss 3433.326533854167
INFO:root:current train perplexity3.8644018173217773
INFO:root:current mean train loss 3433.005730365954
INFO:root:current train perplexity3.8648555278778076
INFO:root:current mean train loss 3435.2671395210596
INFO:root:current train perplexity3.869438886642456
INFO:root:current mean train loss 3437.9001801215277
INFO:root:current train perplexity3.8708066940307617
INFO:root:current mean train loss 3437.768956968246
INFO:root:current train perplexity3.8735997676849365
INFO:root:current mean train loss 3436.5614620535716
INFO:root:current train perplexity3.875790596008301
INFO:root:current mean train loss 3437.861088241186
INFO:root:current train perplexity3.878593921661377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.65s/it]
INFO:root:final mean train loss: 3435.645162028651
INFO:root:final train perplexity: 3.8785505294799805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]
INFO:root:eval mean loss: 4013.6399046985816
INFO:root:eval perplexity: 5.068263530731201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 4981.224044908023
INFO:root:eval perplexity: 7.666736125946045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [7:01:50<7:18:38, 258.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.6353892131024
INFO:root:current train perplexity3.850022315979004
INFO:root:current mean train loss 3419.2315333632173
INFO:root:current train perplexity3.8520736694335938
INFO:root:current mean train loss 3429.087256549525
INFO:root:current train perplexity3.8620710372924805
INFO:root:current mean train loss 3427.1434259240373
INFO:root:current train perplexity3.8607351779937744
INFO:root:current mean train loss 3430.706219469785
INFO:root:current train perplexity3.8626883029937744
INFO:root:current mean train loss 3426.0463527986976
INFO:root:current train perplexity3.8598685264587402
INFO:root:current mean train loss 3429.3259334536283
INFO:root:current train perplexity3.8621602058410645
INFO:root:current mean train loss 3432.8203034577546
INFO:root:current train perplexity3.865682601928711
INFO:root:current mean train loss 3432.5426668229757
INFO:root:current train perplexity3.8686764240264893
INFO:root:current mean train loss 3432.903195137653
INFO:root:current train perplexity3.8694963455200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it]
INFO:root:final mean train loss: 3429.507222698581
INFO:root:final train perplexity: 3.869168996810913
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4015.680090938054
INFO:root:eval perplexity: 5.072445392608643
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4983.779092558732
INFO:root:eval perplexity: 7.6747517585754395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [7:06:10<7:15:38, 258.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3403.03419310182
INFO:root:current train perplexity3.847416877746582
INFO:root:current mean train loss 3400.8935891995256
INFO:root:current train perplexity3.8479888439178467
INFO:root:current mean train loss 3405.992942574098
INFO:root:current train perplexity3.8487939834594727
INFO:root:current mean train loss 3405.3411031659607
INFO:root:current train perplexity3.842019557952881
INFO:root:current mean train loss 3409.4111889996498
INFO:root:current train perplexity3.847114086151123
INFO:root:current mean train loss 3412.8900755803193
INFO:root:current train perplexity3.848186492919922
INFO:root:current mean train loss 3417.2508571420494
INFO:root:current train perplexity3.8535075187683105
INFO:root:current mean train loss 3419.58857736696
INFO:root:current train perplexity3.8543219566345215
INFO:root:current mean train loss 3421.6525884386397
INFO:root:current train perplexity3.856843948364258
INFO:root:current mean train loss 3426.7422126285
INFO:root:current train perplexity3.86100435256958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]
INFO:root:final mean train loss: 3424.223685110769
INFO:root:final train perplexity: 3.861112594604492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.12s/it]
INFO:root:eval mean loss: 4016.43755021332
INFO:root:eval perplexity: 5.073998928070068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it]
INFO:root:eval mean loss: 4987.173971838985
INFO:root:eval perplexity: 7.685410499572754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [7:10:30<7:11:51, 259.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.2901130445075
INFO:root:current train perplexity3.822108268737793
INFO:root:current mean train loss 3421.1377333444566
INFO:root:current train perplexity3.8310916423797607
INFO:root:current mean train loss 3412.5983658092077
INFO:root:current train perplexity3.8368539810180664
INFO:root:current mean train loss 3420.6075295661026
INFO:root:current train perplexity3.8449459075927734
INFO:root:current mean train loss 3420.713385266627
INFO:root:current train perplexity3.8523266315460205
INFO:root:current mean train loss 3422.1896320527703
INFO:root:current train perplexity3.8535313606262207
INFO:root:current mean train loss 3418.102190489762
INFO:root:current train perplexity3.8502345085144043
INFO:root:current mean train loss 3420.668539226279
INFO:root:current train perplexity3.8534486293792725
INFO:root:current mean train loss 3422.721710374809
INFO:root:current train perplexity3.854435443878174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.65s/it]
INFO:root:final mean train loss: 3420.4220616740563
INFO:root:final train perplexity: 3.855325222015381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4018.909287040115
INFO:root:eval perplexity: 5.079074859619141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 4989.002531443927
INFO:root:eval perplexity: 7.691158771514893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [7:14:51<7:08:13, 259.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3499.3001534598216
INFO:root:current train perplexity3.871992826461792
INFO:root:current mean train loss 3409.8209719078563
INFO:root:current train perplexity3.8158280849456787
INFO:root:current mean train loss 3407.199031221694
INFO:root:current train perplexity3.837048053741455
INFO:root:current mean train loss 3409.215809179051
INFO:root:current train perplexity3.836310625076294
INFO:root:current mean train loss 3409.2252758129225
INFO:root:current train perplexity3.8319005966186523
INFO:root:current mean train loss 3409.7871763090175
INFO:root:current train perplexity3.836280584335327
INFO:root:current mean train loss 3410.542014711182
INFO:root:current train perplexity3.8395063877105713
INFO:root:current mean train loss 3412.415764232673
INFO:root:current train perplexity3.844280481338501
INFO:root:current mean train loss 3413.678637120508
INFO:root:current train perplexity3.84729266166687
INFO:root:current mean train loss 3416.8249091807643
INFO:root:current train perplexity3.8471567630767822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.44s/it]
INFO:root:final mean train loss: 3416.2786005696944
INFO:root:final train perplexity: 3.8490283489227295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4016.4471340314717
INFO:root:eval perplexity: 5.074019908905029
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 4987.823179853724
INFO:root:eval perplexity: 7.687453746795654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [7:19:15<7:06:09, 260.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3389.90830078125
INFO:root:current train perplexity3.8132193088531494
INFO:root:current mean train loss 3393.6413765285324
INFO:root:current train perplexity3.823307752609253
INFO:root:current mean train loss 3403.649184683866
INFO:root:current train perplexity3.8275465965270996
INFO:root:current mean train loss 3401.31980406746
INFO:root:current train perplexity3.829988956451416
INFO:root:current mean train loss 3411.5197583301956
INFO:root:current train perplexity3.8362607955932617
INFO:root:current mean train loss 3416.782065856341
INFO:root:current train perplexity3.839317798614502
INFO:root:current mean train loss 3415.361608787475
INFO:root:current train perplexity3.8351707458496094
INFO:root:current mean train loss 3413.1476852737105
INFO:root:current train perplexity3.837629795074463
INFO:root:current mean train loss 3412.8691265457246
INFO:root:current train perplexity3.8372538089752197
INFO:root:current mean train loss 3412.00245661501
INFO:root:current train perplexity3.8378288745880127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.53s/it]
INFO:root:final mean train loss: 3410.4241321932886
INFO:root:final train perplexity: 3.8401482105255127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.48s/it]
INFO:root:eval mean loss: 4019.443890943595
INFO:root:eval perplexity: 5.080172538757324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 4990.611906443927
INFO:root:eval perplexity: 7.696223735809326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [7:23:36<7:01:39, 260.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3426.305027173913
INFO:root:current train perplexity3.824510335922241
INFO:root:current mean train loss 3399.408891879446
INFO:root:current train perplexity3.8044075965881348
INFO:root:current mean train loss 3396.907614122057
INFO:root:current train perplexity3.8041813373565674
INFO:root:current mean train loss 3397.985613843605
INFO:root:current train perplexity3.814275026321411
INFO:root:current mean train loss 3392.1302983710107
INFO:root:current train perplexity3.813021183013916
INFO:root:current mean train loss 3396.9288337080247
INFO:root:current train perplexity3.818636178970337
INFO:root:current mean train loss 3398.7001772860654
INFO:root:current train perplexity3.8202617168426514
INFO:root:current mean train loss 3400.707363862055
INFO:root:current train perplexity3.8229732513427734
INFO:root:current mean train loss 3403.003392457093
INFO:root:current train perplexity3.8272275924682617
INFO:root:current mean train loss 3406.031250793523
INFO:root:current train perplexity3.830033540725708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.76s/it]
INFO:root:final mean train loss: 3405.13006025745
INFO:root:final train perplexity: 3.8321356773376465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4020.4752032773713
INFO:root:eval perplexity: 5.0822906494140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 4993.871014101285
INFO:root:eval perplexity: 7.706487655639648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [7:27:57<6:57:51, 261.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3338.4507072202623
INFO:root:current train perplexity3.8029489517211914
INFO:root:current mean train loss 3386.939274212786
INFO:root:current train perplexity3.8027055263519287
INFO:root:current mean train loss 3388.3030588389474
INFO:root:current train perplexity3.8137171268463135
INFO:root:current mean train loss 3390.1477707231875
INFO:root:current train perplexity3.815948724746704
INFO:root:current mean train loss 3393.43688143489
INFO:root:current train perplexity3.8172686100006104
INFO:root:current mean train loss 3399.9521176325625
INFO:root:current train perplexity3.823728561401367
INFO:root:current mean train loss 3401.877616289867
INFO:root:current train perplexity3.825901508331299
INFO:root:current mean train loss 3404.0199951505856
INFO:root:current train perplexity3.8242199420928955
INFO:root:current mean train loss 3406.7344149556257
INFO:root:current train perplexity3.8247768878936768
INFO:root:current mean train loss 3403.1340817165683
INFO:root:current train perplexity3.8258731365203857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.98s/it]
INFO:root:final mean train loss: 3402.2422731461065
INFO:root:final train perplexity: 3.827772855758667
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it]
INFO:root:eval mean loss: 4021.8038321420654
INFO:root:eval perplexity: 5.085022926330566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 4997.151626911569
INFO:root:eval perplexity: 7.716833591461182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [7:32:17<6:52:51, 260.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.397241836939
INFO:root:current train perplexity3.7750251293182373
INFO:root:current mean train loss 3370.27030055643
INFO:root:current train perplexity3.789393663406372
INFO:root:current mean train loss 3374.5979330789096
INFO:root:current train perplexity3.805999279022217
INFO:root:current mean train loss 3377.9837830129977
INFO:root:current train perplexity3.80618953704834
INFO:root:current mean train loss 3388.290272636674
INFO:root:current train perplexity3.8119118213653564
INFO:root:current mean train loss 3388.165636052006
INFO:root:current train perplexity3.810269355773926
INFO:root:current mean train loss 3390.246897236282
INFO:root:current train perplexity3.810392379760742
INFO:root:current mean train loss 3393.6428952765564
INFO:root:current train perplexity3.815462350845337
INFO:root:current mean train loss 3394.5436098010096
INFO:root:current train perplexity3.8150484561920166
INFO:root:current mean train loss 3397.385864127812
INFO:root:current train perplexity3.8174736499786377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.38s/it]
INFO:root:final mean train loss: 3396.9737940757504
INFO:root:final train perplexity: 3.819824457168579
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 4021.9780481216753
INFO:root:eval perplexity: 5.085379600524902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5000.421684535682
INFO:root:eval perplexity: 7.727156162261963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [7:36:35<6:47:13, 259.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.248592295545
INFO:root:current train perplexity3.7929539680480957
INFO:root:current mean train loss 3384.0332047858205
INFO:root:current train perplexity3.8169426918029785
INFO:root:current mean train loss 3383.3815858663334
INFO:root:current train perplexity3.805882453918457
INFO:root:current mean train loss 3388.4521878377163
INFO:root:current train perplexity3.8058922290802
INFO:root:current mean train loss 3394.4963903235107
INFO:root:current train perplexity3.8110835552215576
INFO:root:current mean train loss 3392.1171085002
INFO:root:current train perplexity3.808387517929077
INFO:root:current mean train loss 3391.8001729738216
INFO:root:current train perplexity3.805424928665161
INFO:root:current mean train loss 3394.5750403959587
INFO:root:current train perplexity3.8088202476501465
INFO:root:current mean train loss 3393.781519217643
INFO:root:current train perplexity3.810866355895996
INFO:root:current mean train loss 3394.275317408593
INFO:root:current train perplexity3.813913583755493

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.52s/it]
INFO:root:final mean train loss: 3393.5190459835912
INFO:root:final train perplexity: 3.8146214485168457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it]
INFO:root:eval mean loss: 4025.428052969858
INFO:root:eval perplexity: 5.092479228973389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 5002.0694207806955
INFO:root:eval perplexity: 7.732364177703857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [7:40:56<6:43:08, 260.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.358917791193
INFO:root:current train perplexity3.793515205383301
INFO:root:current mean train loss 3373.419978578629
INFO:root:current train perplexity3.7757439613342285
INFO:root:current mean train loss 3381.6843740425857
INFO:root:current train perplexity3.7812767028808594
INFO:root:current mean train loss 3387.831368287852
INFO:root:current train perplexity3.789367914199829
INFO:root:current mean train loss 3387.533113517342
INFO:root:current train perplexity3.7907283306121826
INFO:root:current mean train loss 3393.117311549831
INFO:root:current train perplexity3.799311637878418
INFO:root:current mean train loss 3393.240714456107
INFO:root:current train perplexity3.803539276123047
INFO:root:current mean train loss 3389.784125685534
INFO:root:current train perplexity3.8008055686950684
INFO:root:current mean train loss 3389.882311940333
INFO:root:current train perplexity3.8031184673309326
INFO:root:current mean train loss 3389.7653281965804
INFO:root:current train perplexity3.804119110107422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.13s/it]
INFO:root:final mean train loss: 3387.9332165871897
INFO:root:final train perplexity: 3.8062243461608887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4027.3512941184617
INFO:root:eval perplexity: 5.096442699432373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 5006.699868060173
INFO:root:eval perplexity: 7.7470197677612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [7:45:18<6:39:41, 260.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3374.3155149429563
INFO:root:current train perplexity3.7575058937072754
INFO:root:current mean train loss 3369.6096625766872
INFO:root:current train perplexity3.777470111846924
INFO:root:current mean train loss 3374.80152388308
INFO:root:current train perplexity3.7774529457092285
INFO:root:current mean train loss 3371.216114222839
INFO:root:current train perplexity3.7804908752441406
INFO:root:current mean train loss 3376.6184619878845
INFO:root:current train perplexity3.784956693649292
INFO:root:current mean train loss 3376.944026316885
INFO:root:current train perplexity3.7877330780029297
INFO:root:current mean train loss 3384.232666383861
INFO:root:current train perplexity3.794764518737793
INFO:root:current mean train loss 3386.1107051344406
INFO:root:current train perplexity3.7974236011505127
INFO:root:current mean train loss 3383.4664104368844
INFO:root:current train perplexity3.796286106109619
INFO:root:current mean train loss 3384.304088937159
INFO:root:current train perplexity3.79850697517395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.30s/it]
INFO:root:final mean train loss: 3383.249236322218
INFO:root:final train perplexity: 3.7991974353790283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4025.991756358045
INFO:root:eval perplexity: 5.093640327453613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 5006.763704773382
INFO:root:eval perplexity: 7.747222900390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [7:49:38<6:35:09, 260.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3326.0861369388203
INFO:root:current train perplexity3.7674808502197266
INFO:root:current mean train loss 3353.6417343407347
INFO:root:current train perplexity3.7817494869232178
INFO:root:current mean train loss 3353.894477196725
INFO:root:current train perplexity3.773252487182617
INFO:root:current mean train loss 3367.6010189416274
INFO:root:current train perplexity3.7742836475372314
INFO:root:current mean train loss 3374.476882319035
INFO:root:current train perplexity3.7819631099700928
INFO:root:current mean train loss 3375.0633226384634
INFO:root:current train perplexity3.78625226020813
INFO:root:current mean train loss 3376.6068237122763
INFO:root:current train perplexity3.786325693130493
INFO:root:current mean train loss 3379.8934207426437
INFO:root:current train perplexity3.786864757537842
INFO:root:current mean train loss 3380.5148424045638
INFO:root:current train perplexity3.7914187908172607
INFO:root:current mean train loss 3380.389391473835
INFO:root:current train perplexity3.7911109924316406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.32s/it]
INFO:root:final mean train loss: 3378.244946202924
INFO:root:final train perplexity: 3.791703462600708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 4027.7454600232713
INFO:root:eval perplexity: 5.097254276275635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.47s/it]
INFO:root:eval mean loss: 5008.506619500776
INFO:root:eval perplexity: 7.752745628356934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [7:53:58<6:30:29, 260.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.7717594195014
INFO:root:current train perplexity3.8058388233184814
INFO:root:current mean train loss 3381.425373439682
INFO:root:current train perplexity3.7881104946136475
INFO:root:current mean train loss 3378.2157389322915
INFO:root:current train perplexity3.788800001144409
INFO:root:current mean train loss 3375.6030015769293
INFO:root:current train perplexity3.7834973335266113
INFO:root:current mean train loss 3374.1967437043318
INFO:root:current train perplexity3.784860610961914
INFO:root:current mean train loss 3374.596500904037
INFO:root:current train perplexity3.7860708236694336
INFO:root:current mean train loss 3376.0686419884482
INFO:root:current train perplexity3.7842235565185547
INFO:root:current mean train loss 3377.331664568959
INFO:root:current train perplexity3.7832019329071045
INFO:root:current mean train loss 3378.172736574765
INFO:root:current train perplexity3.786245822906494
INFO:root:current mean train loss 3376.9664868987006
INFO:root:current train perplexity3.786501407623291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.83s/it]
INFO:root:final mean train loss: 3375.119947802636
INFO:root:final train perplexity: 3.787031412124634
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.56s/it]
INFO:root:eval mean loss: 4028.9794211962544
INFO:root:eval perplexity: 5.099798202514648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.56s/it]
INFO:root:eval mean loss: 5007.534835923648
INFO:root:eval perplexity: 7.749666690826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [7:58:21<6:27:19, 261.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.133833961925
INFO:root:current train perplexity3.7780184745788574
INFO:root:current mean train loss 3360.083295036765
INFO:root:current train perplexity3.7699475288391113
INFO:root:current mean train loss 3364.420277452635
INFO:root:current train perplexity3.76902174949646
INFO:root:current mean train loss 3366.062558038598
INFO:root:current train perplexity3.7691650390625
INFO:root:current mean train loss 3368.152038950205
INFO:root:current train perplexity3.7696971893310547
INFO:root:current mean train loss 3367.3458291464813
INFO:root:current train perplexity3.773477792739868
INFO:root:current mean train loss 3368.8123304875135
INFO:root:current train perplexity3.7737464904785156
INFO:root:current mean train loss 3368.3145601497977
INFO:root:current train perplexity3.774016857147217
INFO:root:current mean train loss 3370.2435378426226
INFO:root:current train perplexity3.777132272720337
INFO:root:current mean train loss 3372.218232778068
INFO:root:current train perplexity3.7784252166748047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.13s/it]
INFO:root:final mean train loss: 3369.6765697848414
INFO:root:final train perplexity: 3.7789077758789062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4028.9333946282136
INFO:root:eval perplexity: 5.099703788757324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 5010.189823664672
INFO:root:eval perplexity: 7.758083820343018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [8:02:42<6:23:05, 261.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.266619551809
INFO:root:current train perplexity3.740283489227295
INFO:root:current mean train loss 3358.3773725460737
INFO:root:current train perplexity3.754948139190674
INFO:root:current mean train loss 3354.9291388042902
INFO:root:current train perplexity3.762195348739624
INFO:root:current mean train loss 3358.057266119462
INFO:root:current train perplexity3.7631583213806152
INFO:root:current mean train loss 3360.21705778488
INFO:root:current train perplexity3.7681591510772705
INFO:root:current mean train loss 3365.0031799829308
INFO:root:current train perplexity3.773911952972412
INFO:root:current mean train loss 3364.5202116822165
INFO:root:current train perplexity3.775463581085205
INFO:root:current mean train loss 3367.4399005625983
INFO:root:current train perplexity3.775651693344116
INFO:root:current mean train loss 3369.4376961308485
INFO:root:current train perplexity3.7751638889312744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.93s/it]
INFO:root:final mean train loss: 3366.588063455397
INFO:root:final train perplexity: 3.7743051052093506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 4029.2834818955007
INFO:root:eval perplexity: 5.100426197052002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 5012.193516940935
INFO:root:eval perplexity: 7.764441967010498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [8:07:05<6:19:15, 261.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3404.25048828125
INFO:root:current train perplexity3.8389503955841064
INFO:root:current mean train loss 3331.6068435224515
INFO:root:current train perplexity3.7417168617248535
INFO:root:current mean train loss 3339.353223377848
INFO:root:current train perplexity3.7541308403015137
INFO:root:current mean train loss 3349.884710834365
INFO:root:current train perplexity3.757028341293335
INFO:root:current mean train loss 3354.3748818674394
INFO:root:current train perplexity3.762220621109009
INFO:root:current mean train loss 3356.2375129108163
INFO:root:current train perplexity3.76318621635437
INFO:root:current mean train loss 3357.2072235664127
INFO:root:current train perplexity3.7619376182556152
INFO:root:current mean train loss 3358.3216175931275
INFO:root:current train perplexity3.7623708248138428
INFO:root:current mean train loss 3363.1090882943845
INFO:root:current train perplexity3.765549421310425
INFO:root:current mean train loss 3363.5751555686775
INFO:root:current train perplexity3.7654294967651367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.07s/it]
INFO:root:final mean train loss: 3362.10718277962
INFO:root:final train perplexity: 3.76763916015625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 4032.368595204455
INFO:root:eval perplexity: 5.10679292678833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 5017.3187108682405
INFO:root:eval perplexity: 7.780730724334717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [8:11:26<6:14:42, 261.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3377.404873934659
INFO:root:current train perplexity3.7843637466430664
INFO:root:current mean train loss 3349.695044165259
INFO:root:current train perplexity3.7445602416992188
INFO:root:current mean train loss 3347.8016687185277
INFO:root:current train perplexity3.746786594390869
INFO:root:current mean train loss 3346.317997481662
INFO:root:current train perplexity3.7444610595703125
INFO:root:current mean train loss 3350.948620575768
INFO:root:current train perplexity3.7489945888519287
INFO:root:current mean train loss 3355.5833174076565
INFO:root:current train perplexity3.7539939880371094
INFO:root:current mean train loss 3356.873583105309
INFO:root:current train perplexity3.7524538040161133
INFO:root:current mean train loss 3359.6346138526283
INFO:root:current train perplexity3.7562758922576904
INFO:root:current mean train loss 3358.540040567683
INFO:root:current train perplexity3.7585935592651367
INFO:root:current mean train loss 3360.6292524955406
INFO:root:current train perplexity3.761863946914673

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.50s/it]
INFO:root:final mean train loss: 3358.855454967868
INFO:root:final train perplexity: 3.7628085613250732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.42s/it]
INFO:root:eval mean loss: 4033.99263941988
INFO:root:eval perplexity: 5.110146522521973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.66s/it]
INFO:root:eval mean loss: 5020.0480472212985
INFO:root:eval perplexity: 7.789421081542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [8:15:49<6:11:15, 262.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.3884534333883
INFO:root:current train perplexity3.6973717212677
INFO:root:current mean train loss 3363.6141018907565
INFO:root:current train perplexity3.732137441635132
INFO:root:current mean train loss 3358.183390856878
INFO:root:current train perplexity3.742358684539795
INFO:root:current mean train loss 3351.4488062365303
INFO:root:current train perplexity3.7411134243011475
INFO:root:current mean train loss 3343.4732196962636
INFO:root:current train perplexity3.743591547012329
INFO:root:current mean train loss 3349.2432092214594
INFO:root:current train perplexity3.7447338104248047
INFO:root:current mean train loss 3351.6426325537664
INFO:root:current train perplexity3.7489466667175293
INFO:root:current mean train loss 3354.595163910379
INFO:root:current train perplexity3.7514233589172363
INFO:root:current mean train loss 3354.4533250224167
INFO:root:current train perplexity3.7515556812286377
INFO:root:current mean train loss 3354.4540680894656
INFO:root:current train perplexity3.75390887260437

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.58s/it]
INFO:root:final mean train loss: 3354.3875374947825
INFO:root:final train perplexity: 3.7561819553375244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4035.635388962766
INFO:root:eval perplexity: 5.1135430335998535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 5022.058370387301
INFO:root:eval perplexity: 7.795827388763428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [8:20:10<6:06:10, 261.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.126048900463
INFO:root:current train perplexity3.7376582622528076
INFO:root:current mean train loss 3365.30778443344
INFO:root:current train perplexity3.7413225173950195
INFO:root:current mean train loss 3354.6620749587005
INFO:root:current train perplexity3.746389389038086
INFO:root:current mean train loss 3351.8950337167907
INFO:root:current train perplexity3.7419393062591553
INFO:root:current mean train loss 3347.8486299537103
INFO:root:current train perplexity3.748239278793335
INFO:root:current mean train loss 3355.813371401358
INFO:root:current train perplexity3.750368118286133
INFO:root:current mean train loss 3352.737431235671
INFO:root:current train perplexity3.7504780292510986
INFO:root:current mean train loss 3353.024521188854
INFO:root:current train perplexity3.7497785091400146
INFO:root:current mean train loss 3353.9464685516173
INFO:root:current train perplexity3.7508881092071533
INFO:root:current mean train loss 3353.1724839030476
INFO:root:current train perplexity3.750781297683716

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.77s/it]
INFO:root:final mean train loss: 3350.1161063409622
INFO:root:final train perplexity: 3.749857187271118
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4037.8724598986037
INFO:root:eval perplexity: 5.118171691894531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 5024.60275376773
INFO:root:eval perplexity: 7.803942680358887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [8:24:33<6:02:46, 262.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.7197893415178
INFO:root:current train perplexity3.7063148021698
INFO:root:current mean train loss 3346.502734375
INFO:root:current train perplexity3.7208971977233887
INFO:root:current mean train loss 3338.1461477726066
INFO:root:current train perplexity3.7199463844299316
INFO:root:current mean train loss 3341.9396666569496
INFO:root:current train perplexity3.7254278659820557
INFO:root:current mean train loss 3341.788758306394
INFO:root:current train perplexity3.731334686279297
INFO:root:current mean train loss 3339.82353515625
INFO:root:current train perplexity3.7315163612365723
INFO:root:current mean train loss 3338.5954132320376
INFO:root:current train perplexity3.7343077659606934
INFO:root:current mean train loss 3342.8854199883076
INFO:root:current train perplexity3.7374956607818604
INFO:root:current mean train loss 3347.6206981544724
INFO:root:current train perplexity3.7409541606903076
INFO:root:current mean train loss 3349.21175922251
INFO:root:current train perplexity3.7439236640930176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.75s/it]
INFO:root:final mean train loss: 3346.912052154541
INFO:root:final train perplexity: 3.745119571685791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4038.2859163757757
INFO:root:eval perplexity: 5.119026184082031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 5024.907420489805
INFO:root:eval perplexity: 7.8049139976501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [8:28:56<5:58:19, 262.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.3093602380086
INFO:root:current train perplexity3.7642927169799805
INFO:root:current mean train loss 3326.534510899257
INFO:root:current train perplexity3.7367119789123535
INFO:root:current mean train loss 3334.4521735548483
INFO:root:current train perplexity3.736372947692871
INFO:root:current mean train loss 3336.336020066509
INFO:root:current train perplexity3.732166290283203
INFO:root:current mean train loss 3336.8344754117875
INFO:root:current train perplexity3.7345566749572754
INFO:root:current mean train loss 3338.1707860338975
INFO:root:current train perplexity3.736621618270874
INFO:root:current mean train loss 3339.6098108840397
INFO:root:current train perplexity3.7380475997924805
INFO:root:current mean train loss 3344.27439730453
INFO:root:current train perplexity3.738729953765869
INFO:root:current mean train loss 3345.815645156806
INFO:root:current train perplexity3.7407352924346924
INFO:root:current mean train loss 3344.299793037099
INFO:root:current train perplexity3.7380895614624023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.53s/it]
INFO:root:final mean train loss: 3342.8734188695107
INFO:root:final train perplexity: 3.7391574382781982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 4039.874516913231
INFO:root:eval perplexity: 5.122315883636475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.70s/it]
INFO:root:eval mean loss: 5028.626047553746
INFO:root:eval perplexity: 7.816793441772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [8:33:16<5:53:06, 261.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3329.408136106005
INFO:root:current train perplexity3.728485584259033
INFO:root:current mean train loss 3338.245962787148
INFO:root:current train perplexity3.7169783115386963
INFO:root:current mean train loss 3330.850358332296
INFO:root:current train perplexity3.7229909896850586
INFO:root:current mean train loss 3333.746652978098
INFO:root:current train perplexity3.724355936050415
INFO:root:current mean train loss 3334.416335552072
INFO:root:current train perplexity3.727257251739502
INFO:root:current mean train loss 3333.400434490557
INFO:root:current train perplexity3.7281699180603027
INFO:root:current mean train loss 3336.3116805725567
INFO:root:current train perplexity3.728306770324707
INFO:root:current mean train loss 3339.724671141603
INFO:root:current train perplexity3.7292611598968506
INFO:root:current mean train loss 3340.9543497195396
INFO:root:current train perplexity3.7307872772216797
INFO:root:current mean train loss 3342.1701056864486
INFO:root:current train perplexity3.7319722175598145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.66s/it]
INFO:root:final mean train loss: 3338.067014386577
INFO:root:final train perplexity: 3.7320737838745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.17s/it]
INFO:root:eval mean loss: 4041.3269441212324
INFO:root:eval perplexity: 5.125324726104736
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 5033.884502437943
INFO:root:eval perplexity: 7.833620071411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [8:37:39<5:49:28, 262.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3316.7263969809323
INFO:root:current train perplexity3.690279006958008
INFO:root:current mean train loss 3312.496867629717
INFO:root:current train perplexity3.7078068256378174
INFO:root:current mean train loss 3324.358082657155
INFO:root:current train perplexity3.718656063079834
INFO:root:current mean train loss 3334.581319909906
INFO:root:current train perplexity3.7189860343933105
INFO:root:current mean train loss 3334.8266495183143
INFO:root:current train perplexity3.7185423374176025
INFO:root:current mean train loss 3336.0322532039636
INFO:root:current train perplexity3.720590829849243
INFO:root:current mean train loss 3333.63366087941
INFO:root:current train perplexity3.7221717834472656
INFO:root:current mean train loss 3334.115540596179
INFO:root:current train perplexity3.7237837314605713
INFO:root:current mean train loss 3334.0340762332653
INFO:root:current train perplexity3.7244577407836914
INFO:root:current mean train loss 3336.046897657472
INFO:root:current train perplexity3.7259414196014404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.29s/it]
INFO:root:final mean train loss: 3334.1102555797947
INFO:root:final train perplexity: 3.726252317428589
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]
INFO:root:eval mean loss: 4042.201803870235
INFO:root:eval perplexity: 5.127139091491699
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.55s/it]
INFO:root:eval mean loss: 5033.508167456228
INFO:root:eval perplexity: 7.832413673400879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [8:42:00<5:44:42, 261.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3347.5962242012592
INFO:root:current train perplexity3.7318882942199707
INFO:root:current mean train loss 3326.444252608065
INFO:root:current train perplexity3.7243311405181885
INFO:root:current mean train loss 3326.4490962224954
INFO:root:current train perplexity3.715139389038086
INFO:root:current mean train loss 3329.363087667107
INFO:root:current train perplexity3.717423677444458
INFO:root:current mean train loss 3333.9864624807615
INFO:root:current train perplexity3.719831943511963
INFO:root:current mean train loss 3334.0528467571926
INFO:root:current train perplexity3.7202115058898926
INFO:root:current mean train loss 3332.6797424041883
INFO:root:current train perplexity3.720828056335449
INFO:root:current mean train loss 3330.9946744239937
INFO:root:current train perplexity3.721688747406006
INFO:root:current mean train loss 3331.240544689843
INFO:root:current train perplexity3.7219784259796143
INFO:root:current mean train loss 3332.766021128894
INFO:root:current train perplexity3.721432685852051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.16s/it]
INFO:root:final mean train loss: 3330.625918542185
INFO:root:final train perplexity: 3.7211337089538574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4042.3468528368794
INFO:root:eval perplexity: 5.127439022064209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 5033.5447850869905
INFO:root:eval perplexity: 7.832529067993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [8:46:25<5:41:24, 262.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.2668880208334
INFO:root:current train perplexity3.6985068321228027
INFO:root:current mean train loss 3306.6001018415177
INFO:root:current train perplexity3.6954240798950195
INFO:root:current mean train loss 3313.9174156605113
INFO:root:current train perplexity3.6995491981506348
INFO:root:current mean train loss 3319.0887239583335
INFO:root:current train perplexity3.703615427017212
INFO:root:current mean train loss 3320.0909318462172
INFO:root:current train perplexity3.704411029815674
INFO:root:current mean train loss 3323.201492017663
INFO:root:current train perplexity3.704787015914917
INFO:root:current mean train loss 3324.799406828704
INFO:root:current train perplexity3.7076480388641357
INFO:root:current mean train loss 3327.013868762601
INFO:root:current train perplexity3.7087721824645996
INFO:root:current mean train loss 3328.658349888393
INFO:root:current train perplexity3.714219093322754
INFO:root:current mean train loss 3330.0639650941507
INFO:root:current train perplexity3.717047691345215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.82s/it]
INFO:root:final mean train loss: 3327.933960883848
INFO:root:final train perplexity: 3.7171828746795654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4043.911091256649
INFO:root:eval perplexity: 5.130683898925781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.62s/it]
INFO:root:eval mean loss: 5036.990232643506
INFO:root:eval perplexity: 7.843571662902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [8:51:48<6:00:29, 280.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.0809105562876
INFO:root:current train perplexity3.6847684383392334
INFO:root:current mean train loss 3320.7612704918033
INFO:root:current train perplexity3.690833806991577
INFO:root:current mean train loss 3324.552913814046
INFO:root:current train perplexity3.703721761703491
INFO:root:current mean train loss 3327.8001399824575
INFO:root:current train perplexity3.7081308364868164
INFO:root:current mean train loss 3328.7900865764104
INFO:root:current train perplexity3.714120388031006
INFO:root:current mean train loss 3325.24180391027
INFO:root:current train perplexity3.710584878921509
INFO:root:current mean train loss 3325.407340947566
INFO:root:current train perplexity3.7102651596069336
INFO:root:current mean train loss 3325.833142510776
INFO:root:current train perplexity3.7111902236938477
INFO:root:current mean train loss 3327.3422597191748
INFO:root:current train perplexity3.7132461071014404
INFO:root:current mean train loss 3326.56072296422
INFO:root:current train perplexity3.711430788040161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.62s/it]
INFO:root:final mean train loss: 3324.0470972984067
INFO:root:final train perplexity: 3.7114875316619873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 4045.037303302305
INFO:root:eval perplexity: 5.133020401000977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 5041.996550864362
INFO:root:eval perplexity: 7.859646320343018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [8:57:25<6:17:12, 297.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.0518704927886
INFO:root:current train perplexity3.7065274715423584
INFO:root:current mean train loss 3309.3332097717603
INFO:root:current train perplexity3.695404529571533
INFO:root:current mean train loss 3320.707176392021
INFO:root:current train perplexity3.70257306098938
INFO:root:current mean train loss 3325.3590521849023
INFO:root:current train perplexity3.703026056289673
INFO:root:current mean train loss 3323.348295192369
INFO:root:current train perplexity3.7050607204437256
INFO:root:current mean train loss 3321.9088058342586
INFO:root:current train perplexity3.705127000808716
INFO:root:current mean train loss 3323.5423313698443
INFO:root:current train perplexity3.706561326980591
INFO:root:current mean train loss 3322.6478501427187
INFO:root:current train perplexity3.706915855407715
INFO:root:current mean train loss 3321.987118910459
INFO:root:current train perplexity3.7051198482513428
INFO:root:current mean train loss 3323.3873513969475
INFO:root:current train perplexity3.706713914871216

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.13s/it]
INFO:root:final mean train loss: 3320.8113618666125
INFO:root:final train perplexity: 3.7067527770996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4046.373465896498
INFO:root:eval perplexity: 5.135794162750244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5040.86735199191
INFO:root:eval perplexity: 7.856019020080566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [9:02:57<6:25:03, 308.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3311.093380089962
INFO:root:current train perplexity3.685781955718994
INFO:root:current mean train loss 3321.068398633794
INFO:root:current train perplexity3.6874141693115234
INFO:root:current mean train loss 3316.0815756297034
INFO:root:current train perplexity3.6799471378326416
INFO:root:current mean train loss 3315.56630957276
INFO:root:current train perplexity3.686492919921875
INFO:root:current mean train loss 3317.4877352360973
INFO:root:current train perplexity3.693420886993408
INFO:root:current mean train loss 3317.8351463865556
INFO:root:current train perplexity3.6941308975219727
INFO:root:current mean train loss 3315.5571844403835
INFO:root:current train perplexity3.6963162422180176
INFO:root:current mean train loss 3318.0690508521393
INFO:root:current train perplexity3.6977572441101074
INFO:root:current mean train loss 3320.5546961902114
INFO:root:current train perplexity3.7005388736724854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.83s/it]
INFO:root:final mean train loss: 3316.758528186429
INFO:root:final train perplexity: 3.7008302211761475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.40s/it]
INFO:root:eval mean loss: 4048.266930546321
INFO:root:eval perplexity: 5.139729022979736
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.75s/it]
INFO:root:eval mean loss: 5044.678837336547
INFO:root:eval perplexity: 7.86827278137207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [9:08:28<6:28:12, 314.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.618826729911
INFO:root:current train perplexity3.6504170894622803
INFO:root:current mean train loss 3320.504577066297
INFO:root:current train perplexity3.6844921112060547
INFO:root:current mean train loss 3311.542685688406
INFO:root:current train perplexity3.693685531616211
INFO:root:current mean train loss 3313.148207673809
INFO:root:current train perplexity3.692413806915283
INFO:root:current mean train loss 3313.600747898111
INFO:root:current train perplexity3.6912240982055664
INFO:root:current mean train loss 3310.5948580228364
INFO:root:current train perplexity3.690955638885498
INFO:root:current mean train loss 3313.097376312809
INFO:root:current train perplexity3.688981056213379
INFO:root:current mean train loss 3315.5492577019977
INFO:root:current train perplexity3.6929445266723633
INFO:root:current mean train loss 3317.8801756602384
INFO:root:current train perplexity3.695469856262207
INFO:root:current mean train loss 3318.005449154148
INFO:root:current train perplexity3.6968462467193604

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.72s/it]
INFO:root:final mean train loss: 3313.6548219496203
INFO:root:final train perplexity: 3.6963016986846924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4047.53448096742
INFO:root:eval perplexity: 5.138206958770752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 5043.062867076685
INFO:root:eval perplexity: 7.86307430267334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [9:13:52<6:26:28, 317.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3319.8119140625
INFO:root:current train perplexity3.675476312637329
INFO:root:current mean train loss 3302.560986328125
INFO:root:current train perplexity3.6900930404663086
INFO:root:current mean train loss 3301.2409156976746
INFO:root:current train perplexity3.685828447341919
INFO:root:current mean train loss 3305.327330574157
INFO:root:current train perplexity3.6863062381744385
INFO:root:current mean train loss 3307.4100891848643
INFO:root:current train perplexity3.6801626682281494
INFO:root:current mean train loss 3309.400668423847
INFO:root:current train perplexity3.685997247695923
INFO:root:current mean train loss 3311.8632915713924
INFO:root:current train perplexity3.6904335021972656
INFO:root:current mean train loss 3315.802057268903
INFO:root:current train perplexity3.692371368408203
INFO:root:current mean train loss 3311.9823382980253
INFO:root:current train perplexity3.6894116401672363
INFO:root:current mean train loss 3312.762778827271
INFO:root:current train perplexity3.6893985271453857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.14s/it]
INFO:root:final mean train loss: 3310.0931758880615
INFO:root:final train perplexity: 3.6911110877990723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 4050.5518236092644
INFO:root:eval perplexity: 5.144480228424072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.29s/it]
INFO:root:eval mean loss: 5046.614654324579
INFO:root:eval perplexity: 7.8745012283325195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [9:18:18<6:02:34, 302.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.468612007473
INFO:root:current train perplexity3.6680967807769775
INFO:root:current mean train loss 3298.851320344258
INFO:root:current train perplexity3.6739819049835205
INFO:root:current mean train loss 3303.9594934574693
INFO:root:current train perplexity3.679034948348999
INFO:root:current mean train loss 3306.5907137371805
INFO:root:current train perplexity3.6794497966766357
INFO:root:current mean train loss 3305.094081869644
INFO:root:current train perplexity3.675741672515869
INFO:root:current mean train loss 3304.861165675789
INFO:root:current train perplexity3.677586555480957
INFO:root:current mean train loss 3304.306032428772
INFO:root:current train perplexity3.682037353515625
INFO:root:current mean train loss 3306.568768302105
INFO:root:current train perplexity3.685178279876709
INFO:root:current mean train loss 3308.1444446290247
INFO:root:current train perplexity3.6875157356262207
INFO:root:current mean train loss 3309.8554727176156
INFO:root:current train perplexity3.685976505279541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.83s/it]
INFO:root:final mean train loss: 3307.0570585804603
INFO:root:final train perplexity: 3.686692476272583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4052.057102933843
INFO:root:eval perplexity: 5.147612571716309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5047.897334538453
INFO:root:eval perplexity: 7.87863302230835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [9:22:35<5:41:19, 288.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.4398075226813
INFO:root:current train perplexity3.6810050010681152
INFO:root:current mean train loss 3288.808524794251
INFO:root:current train perplexity3.6706457138061523
INFO:root:current mean train loss 3298.7262253534227
INFO:root:current train perplexity3.6726064682006836
INFO:root:current mean train loss 3298.3225968006514
INFO:root:current train perplexity3.672940254211426
INFO:root:current mean train loss 3300.467546290422
INFO:root:current train perplexity3.6736667156219482
INFO:root:current mean train loss 3302.091481928996
INFO:root:current train perplexity3.6766586303710938
INFO:root:current mean train loss 3300.6679172908825
INFO:root:current train perplexity3.6763176918029785
INFO:root:current mean train loss 3301.8817521080923
INFO:root:current train perplexity3.6777725219726562
INFO:root:current mean train loss 3304.684882612722
INFO:root:current train perplexity3.6785967350006104
INFO:root:current mean train loss 3305.3705813431457
INFO:root:current train perplexity3.679433584213257

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it]
INFO:root:final mean train loss: 3302.6392755200786
INFO:root:final train perplexity: 3.680272340774536
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 4050.8523832280584
INFO:root:eval perplexity: 5.145104885101318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.34s/it]
INFO:root:eval mean loss: 5049.887529089096
INFO:root:eval perplexity: 7.885050296783447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [9:28:01<5:49:48, 299.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.392371544471
INFO:root:current train perplexity3.640397548675537
INFO:root:current mean train loss 3273.4978554265963
INFO:root:current train perplexity3.6380810737609863
INFO:root:current mean train loss 3276.5515279729993
INFO:root:current train perplexity3.638441324234009
INFO:root:current mean train loss 3281.8341032045078
INFO:root:current train perplexity3.6524746417999268
INFO:root:current mean train loss 3283.9565157184297
INFO:root:current train perplexity3.655797004699707
INFO:root:current mean train loss 3288.0687416657
INFO:root:current train perplexity3.662858486175537
INFO:root:current mean train loss 3292.810172067562
INFO:root:current train perplexity3.6695172786712646
INFO:root:current mean train loss 3298.2693445930945
INFO:root:current train perplexity3.67229962348938
INFO:root:current mean train loss 3298.39306757021
INFO:root:current train perplexity3.6724512577056885
INFO:root:current mean train loss 3300.266457782132
INFO:root:current train perplexity3.6749260425567627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.53s/it]
INFO:root:final mean train loss: 3299.417945738762
INFO:root:final train perplexity: 3.67559814453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 4053.7184435255986
INFO:root:eval perplexity: 5.151071548461914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.37s/it]
INFO:root:eval mean loss: 5052.382175310284
INFO:root:eval perplexity: 7.893095016479492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [9:32:17<5:29:41, 286.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.2464158078456
INFO:root:current train perplexity3.690906047821045
INFO:root:current mean train loss 3284.421720543686
INFO:root:current train perplexity3.6573030948638916
INFO:root:current mean train loss 3299.8027798424846
INFO:root:current train perplexity3.6646292209625244
INFO:root:current mean train loss 3302.8177092714336
INFO:root:current train perplexity3.6732966899871826
INFO:root:current mean train loss 3295.397086260836
INFO:root:current train perplexity3.667633295059204
INFO:root:current mean train loss 3296.2776753706294
INFO:root:current train perplexity3.670322895050049
INFO:root:current mean train loss 3297.263299815253
INFO:root:current train perplexity3.672105312347412
INFO:root:current mean train loss 3297.8790598592286
INFO:root:current train perplexity3.673027276992798
INFO:root:current mean train loss 3296.4011060406215
INFO:root:current train perplexity3.672710418701172
INFO:root:current mean train loss 3298.901142639998
INFO:root:current train perplexity3.6720077991485596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:43<00:00, 223.91s/it]
INFO:root:final mean train loss: 3296.435249943887
INFO:root:final train perplexity: 3.6712753772735596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 4055.9402478806514
INFO:root:eval perplexity: 5.155701160430908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 5055.41857130984
INFO:root:eval perplexity: 7.902901649475098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [9:36:34<5:14:38, 277.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.1792436079545
INFO:root:current train perplexity3.6285383701324463
INFO:root:current mean train loss 3294.3625693044355
INFO:root:current train perplexity3.6549336910247803
INFO:root:current mean train loss 3290.242887369792
INFO:root:current train perplexity3.6488351821899414
INFO:root:current mean train loss 3291.6633135728434
INFO:root:current train perplexity3.651319742202759
INFO:root:current mean train loss 3290.649362551511
INFO:root:current train perplexity3.654792547225952
INFO:root:current mean train loss 3294.836326805321
INFO:root:current train perplexity3.6597776412963867
INFO:root:current mean train loss 3292.1734404818703
INFO:root:current train perplexity3.661630630493164
INFO:root:current mean train loss 3293.6987366126864
INFO:root:current train perplexity3.664581060409546
INFO:root:current mean train loss 3295.9829004477338
INFO:root:current train perplexity3.667118787765503
INFO:root:current mean train loss 3297.97428828534
INFO:root:current train perplexity3.6704208850860596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:45<00:00, 225.09s/it]
INFO:root:final mean train loss: 3294.9963272463892
INFO:root:final train perplexity: 3.669191837310791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4055.392940007203
INFO:root:eval perplexity: 5.154560089111328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 5055.682830161237
INFO:root:eval perplexity: 7.903757095336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [9:41:00<5:06:18, 274.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.0550362723216
INFO:root:current train perplexity3.6569700241088867
INFO:root:current mean train loss 3283.4836276001724
INFO:root:current train perplexity3.668257713317871
INFO:root:current mean train loss 3283.989621702709
INFO:root:current train perplexity3.6626157760620117
INFO:root:current mean train loss 3282.3211989389633
INFO:root:current train perplexity3.655952215194702
INFO:root:current mean train loss 3290.3791424811016
INFO:root:current train perplexity3.657803535461426
INFO:root:current mean train loss 3289.5083679958093
INFO:root:current train perplexity3.658140182495117
INFO:root:current mean train loss 3292.4929887820513
INFO:root:current train perplexity3.6607751846313477
INFO:root:current mean train loss 3292.367918002027
INFO:root:current train perplexity3.6606228351593018
INFO:root:current mean train loss 3292.100190729559
INFO:root:current train perplexity3.6603212356567383
INFO:root:current mean train loss 3292.9612974996753
INFO:root:current train perplexity3.6613545417785645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.95s/it]
INFO:root:final mean train loss: 3290.1115484545307
INFO:root:final train perplexity: 3.6621272563934326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4055.7468538757757
INFO:root:eval perplexity: 5.155299186706543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]
INFO:root:eval mean loss: 5056.564427152593
INFO:root:eval perplexity: 7.906608581542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [9:45:20<4:57:01, 270.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.55312637544
INFO:root:current train perplexity3.655158042907715
INFO:root:current mean train loss 3273.2495302791485
INFO:root:current train perplexity3.649777889251709
INFO:root:current mean train loss 3279.973378762108
INFO:root:current train perplexity3.646190643310547
INFO:root:current mean train loss 3285.3191885318397
INFO:root:current train perplexity3.650768280029297
INFO:root:current mean train loss 3281.669450699144
INFO:root:current train perplexity3.650479793548584
INFO:root:current mean train loss 3284.9474965110553
INFO:root:current train perplexity3.651416778564453
INFO:root:current mean train loss 3284.661269982419
INFO:root:current train perplexity3.65317964553833
INFO:root:current mean train loss 3283.9472273098045
INFO:root:current train perplexity3.6532201766967773
INFO:root:current mean train loss 3286.8429107841202
INFO:root:current train perplexity3.6553215980529785
INFO:root:current mean train loss 3288.5867061281056
INFO:root:current train perplexity3.6567928791046143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.03s/it]
INFO:root:final mean train loss: 3287.557932515298
INFO:root:final train perplexity: 3.658439874649048
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.30s/it]
INFO:root:eval mean loss: 4059.761365525266
INFO:root:eval perplexity: 5.163672924041748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.63s/it]
INFO:root:eval mean loss: 5062.557300324135
INFO:root:eval perplexity: 7.9260053634643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [9:49:45<4:50:57, 268.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.7902770223495
INFO:root:current train perplexity3.631335496902466
INFO:root:current mean train loss 3277.1961240288933
INFO:root:current train perplexity3.6446738243103027
INFO:root:current mean train loss 3277.2705611909164
INFO:root:current train perplexity3.6447572708129883
INFO:root:current mean train loss 3279.5562766686594
INFO:root:current train perplexity3.64460825920105
INFO:root:current mean train loss 3278.452278917667
INFO:root:current train perplexity3.646937370300293
INFO:root:current mean train loss 3280.0174701802675
INFO:root:current train perplexity3.6474242210388184
INFO:root:current mean train loss 3284.2187251904224
INFO:root:current train perplexity3.6492035388946533
INFO:root:current mean train loss 3284.518809797216
INFO:root:current train perplexity3.65153431892395
INFO:root:current mean train loss 3286.6966170830665
INFO:root:current train perplexity3.6529579162597656
INFO:root:current mean train loss 3287.515194324965
INFO:root:current train perplexity3.654407024383545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.10s/it]
INFO:root:final mean train loss: 3284.9740610430317
INFO:root:final train perplexity: 3.654711961746216
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 4059.270400459885
INFO:root:eval perplexity: 5.162649154663086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.59s/it]
INFO:root:eval mean loss: 5063.078303343861
INFO:root:eval perplexity: 7.9276933670043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [9:54:05<4:43:40, 265.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.1960336970187
INFO:root:current train perplexity3.6425256729125977
INFO:root:current mean train loss 3273.82377355239
INFO:root:current train perplexity3.6459357738494873
INFO:root:current mean train loss 3276.4721654167574
INFO:root:current train perplexity3.642472505569458
INFO:root:current mean train loss 3273.8963966862484
INFO:root:current train perplexity3.6397221088409424
INFO:root:current mean train loss 3276.749105653234
INFO:root:current train perplexity3.6455085277557373
INFO:root:current mean train loss 3281.177670324478
INFO:root:current train perplexity3.646023988723755
INFO:root:current mean train loss 3279.7893482191594
INFO:root:current train perplexity3.647789239883423
INFO:root:current mean train loss 3281.0902473420624
INFO:root:current train perplexity3.647918701171875
INFO:root:current mean train loss 3283.324262238409
INFO:root:current train perplexity3.6490421295166016
INFO:root:current mean train loss 3283.7202264694943
INFO:root:current train perplexity3.6494710445404053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.42s/it]
INFO:root:final mean train loss: 3281.4061023342992
INFO:root:final train perplexity: 3.649571180343628
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.78s/it]
INFO:root:eval mean loss: 4058.4626066600176
INFO:root:eval perplexity: 5.160962104797363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 5064.678658992686
INFO:root:eval perplexity: 7.93288516998291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [9:58:29<4:38:43, 265.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3266.1968570106906
INFO:root:current train perplexity3.63987398147583
INFO:root:current mean train loss 3271.1156199919874
INFO:root:current train perplexity3.6244142055511475
INFO:root:current mean train loss 3268.1952065677965
INFO:root:current train perplexity3.629385471343994
INFO:root:current mean train loss 3272.9042350672466
INFO:root:current train perplexity3.6340277194976807
INFO:root:current mean train loss 3276.998495205966
INFO:root:current train perplexity3.639408826828003
INFO:root:current mean train loss 3277.387570575105
INFO:root:current train perplexity3.6385338306427
INFO:root:current mean train loss 3277.650946703575
INFO:root:current train perplexity3.6399731636047363
INFO:root:current mean train loss 3280.871794541077
INFO:root:current train perplexity3.642730474472046
INFO:root:current mean train loss 3282.2423473507333
INFO:root:current train perplexity3.6440021991729736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.86s/it]
INFO:root:final mean train loss: 3277.534846890357
INFO:root:final train perplexity: 3.6440014839172363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4061.832367159796
INFO:root:eval perplexity: 5.1680006980896
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 5068.414240843861
INFO:root:eval perplexity: 7.945010185241699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [10:02:51<4:33:04, 264.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.4595540364585
INFO:root:current train perplexity3.6842355728149414
INFO:root:current mean train loss 3266.8271768810678
INFO:root:current train perplexity3.6250946521759033
INFO:root:current mean train loss 3274.84922332012
INFO:root:current train perplexity3.621406078338623
INFO:root:current mean train loss 3275.0966168394184
INFO:root:current train perplexity3.6293296813964844
INFO:root:current mean train loss 3271.4208445205877
INFO:root:current train perplexity3.6285102367401123
INFO:root:current mean train loss 3275.51703451168
INFO:root:current train perplexity3.632169008255005
INFO:root:current mean train loss 3275.4353768268033
INFO:root:current train perplexity3.6319775581359863
INFO:root:current mean train loss 3277.308223892581
INFO:root:current train perplexity3.6373116970062256
INFO:root:current mean train loss 3276.407938309951
INFO:root:current train perplexity3.6374804973602295
INFO:root:current mean train loss 3279.8474778083473
INFO:root:current train perplexity3.6405751705169678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.57s/it]
INFO:root:final mean train loss: 3275.339639786751
INFO:root:final train perplexity: 3.6408467292785645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4061.6638737671765
INFO:root:eval perplexity: 5.1676483154296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 5067.942600980718
INFO:root:eval perplexity: 7.943481922149658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [10:07:12<4:27:32, 263.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.073397549716
INFO:root:current train perplexity3.621025323867798
INFO:root:current mean train loss 3272.227952561937
INFO:root:current train perplexity3.6307373046875
INFO:root:current mean train loss 3276.821085419135
INFO:root:current train perplexity3.6278650760650635
INFO:root:current mean train loss 3273.16095225834
INFO:root:current train perplexity3.6270134449005127
INFO:root:current mean train loss 3269.1868691548816
INFO:root:current train perplexity3.6267571449279785
INFO:root:current mean train loss 3266.802717175269
INFO:root:current train perplexity3.6248960494995117
INFO:root:current mean train loss 3269.156749868939
INFO:root:current train perplexity3.628702402114868
INFO:root:current mean train loss 3270.3500447762835
INFO:root:current train perplexity3.6301167011260986
INFO:root:current mean train loss 3272.061455102208
INFO:root:current train perplexity3.631166696548462
INFO:root:current mean train loss 3274.6392928122427
INFO:root:current train perplexity3.635136127471924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.92s/it]
INFO:root:final mean train loss: 3272.6487676558954
INFO:root:final train perplexity: 3.6369833946228027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.39s/it]
INFO:root:eval mean loss: 4060.7601984984485
INFO:root:eval perplexity: 5.165759563446045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 5067.96508096465
INFO:root:eval perplexity: 7.943552017211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [10:11:35<4:23:22, 263.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.3215717516446
INFO:root:current train perplexity3.6399524211883545
INFO:root:current mean train loss 3263.5488527442226
INFO:root:current train perplexity3.626884698867798
INFO:root:current mean train loss 3256.2719325235444
INFO:root:current train perplexity3.6221365928649902
INFO:root:current mean train loss 3264.819939783748
INFO:root:current train perplexity3.6300721168518066
INFO:root:current mean train loss 3261.5542190296837
INFO:root:current train perplexity3.623311758041382
INFO:root:current mean train loss 3270.7769090950146
INFO:root:current train perplexity3.627700090408325
INFO:root:current mean train loss 3271.54341325159
INFO:root:current train perplexity3.6274495124816895
INFO:root:current mean train loss 3272.552356788943
INFO:root:current train perplexity3.6293785572052
INFO:root:current mean train loss 3275.121540595906
INFO:root:current train perplexity3.632066249847412
INFO:root:current mean train loss 3272.9244691601775
INFO:root:current train perplexity3.632277250289917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.75s/it]
INFO:root:final mean train loss: 3269.667022151332
INFO:root:final train perplexity: 3.6327075958251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 4065.1441728307846
INFO:root:eval perplexity: 5.174926280975342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.46s/it]
INFO:root:eval mean loss: 5074.057154878657
INFO:root:eval perplexity: 7.963364124298096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [10:16:02<4:19:47, 264.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.4658836082176
INFO:root:current train perplexity3.6091582775115967
INFO:root:current mean train loss 3260.9961879459893
INFO:root:current train perplexity3.6139185428619385
INFO:root:current mean train loss 3256.1286567318284
INFO:root:current train perplexity3.6114749908447266
INFO:root:current mean train loss 3265.488697856938
INFO:root:current train perplexity3.6221067905426025
INFO:root:current mean train loss 3261.477706587566
INFO:root:current train perplexity3.6206769943237305
INFO:root:current mean train loss 3262.677218761118
INFO:root:current train perplexity3.6241397857666016
INFO:root:current mean train loss 3261.7092230643193
INFO:root:current train perplexity3.6255874633789062
INFO:root:current mean train loss 3264.7779740828105
INFO:root:current train perplexity3.623485803604126
INFO:root:current mean train loss 3266.185846515549
INFO:root:current train perplexity3.625439167022705
INFO:root:current mean train loss 3270.2984457170305
INFO:root:current train perplexity3.629206657409668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.37s/it]
INFO:root:final mean train loss: 3267.0127667457828
INFO:root:final train perplexity: 3.628905773162842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 4065.815810616135
INFO:root:eval perplexity: 5.176331520080566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it]
INFO:root:eval mean loss: 5074.110159366689
INFO:root:eval perplexity: 7.963538646697998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [10:20:23<4:14:40, 263.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.663071986607
INFO:root:current train perplexity3.6113178730010986
INFO:root:current mean train loss 3248.9314597800926
INFO:root:current train perplexity3.6082923412323
INFO:root:current mean train loss 3265.2932783410906
INFO:root:current train perplexity3.617204189300537
INFO:root:current mean train loss 3256.4715499650188
INFO:root:current train perplexity3.6179842948913574
INFO:root:current mean train loss 3261.0226293103447
INFO:root:current train perplexity3.622333526611328
INFO:root:current mean train loss 3267.0699510806076
INFO:root:current train perplexity3.622769594192505
INFO:root:current mean train loss 3265.7350382166583
INFO:root:current train perplexity3.623664617538452
INFO:root:current mean train loss 3267.1967670466624
INFO:root:current train perplexity3.6220757961273193
INFO:root:current mean train loss 3265.755878964727
INFO:root:current train perplexity3.6238818168640137
INFO:root:current mean train loss 3266.832828689004
INFO:root:current train perplexity3.625129222869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.83s/it]
INFO:root:final mean train loss: 3264.6157974735384
INFO:root:final train perplexity: 3.6254754066467285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.22s/it]
INFO:root:eval mean loss: 4065.545098487367
INFO:root:eval perplexity: 5.175764083862305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 5074.696408535572
INFO:root:eval perplexity: 7.965446949005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [10:24:43<4:09:11, 262.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.1941712845205
INFO:root:current train perplexity3.581634759902954
INFO:root:current mean train loss 3245.7302348530375
INFO:root:current train perplexity3.6011781692504883
INFO:root:current mean train loss 3250.3452761300796
INFO:root:current train perplexity3.610621452331543
INFO:root:current mean train loss 3250.6894253655705
INFO:root:current train perplexity3.609889268875122
INFO:root:current mean train loss 3255.5223165473335
INFO:root:current train perplexity3.6121578216552734
INFO:root:current mean train loss 3260.2679013977613
INFO:root:current train perplexity3.615032434463501
INFO:root:current mean train loss 3261.6604038078344
INFO:root:current train perplexity3.6163578033447266
INFO:root:current mean train loss 3260.6530656570703
INFO:root:current train perplexity3.616027593612671
INFO:root:current mean train loss 3261.0325237016236
INFO:root:current train perplexity3.6170406341552734
INFO:root:current mean train loss 3263.4660740323434
INFO:root:current train perplexity3.6201491355895996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.02s/it]
INFO:root:final mean train loss: 3261.7392959594727
INFO:root:final train perplexity: 3.621363401412964
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4067.1078322390294
INFO:root:eval perplexity: 5.1790361404418945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 5076.3661624556735
INFO:root:eval perplexity: 7.970887660980225
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [10:29:15<4:07:35, 265.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.335319967831
INFO:root:current train perplexity3.6163504123687744
INFO:root:current mean train loss 3249.3152566871895
INFO:root:current train perplexity3.60436749458313
INFO:root:current mean train loss 3251.0814933624874
INFO:root:current train perplexity3.6074612140655518
INFO:root:current mean train loss 3255.063685925258
INFO:root:current train perplexity3.6100800037384033
INFO:root:current mean train loss 3257.767088219755
INFO:root:current train perplexity3.611002206802368
INFO:root:current mean train loss 3256.71072127382
INFO:root:current train perplexity3.609851360321045
INFO:root:current mean train loss 3257.809539560532
INFO:root:current train perplexity3.6147453784942627
INFO:root:current mean train loss 3257.934295938748
INFO:root:current train perplexity3.6154892444610596
INFO:root:current mean train loss 3257.196004470843
INFO:root:current train perplexity3.6136653423309326
INFO:root:current mean train loss 3258.8637151066314
INFO:root:current train perplexity3.6144752502441406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.74s/it]
INFO:root:final mean train loss: 3258.6618210577194
INFO:root:final train perplexity: 3.616969108581543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.72s/it]
INFO:root:eval mean loss: 4067.695101257757
INFO:root:eval perplexity: 5.180267333984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 5077.55040724734
INFO:root:eval perplexity: 7.974748611450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [10:33:38<4:02:34, 264.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.6940711069915
INFO:root:current train perplexity3.610680341720581
INFO:root:current mean train loss 3246.9935387185533
INFO:root:current train perplexity3.5931341648101807
INFO:root:current mean train loss 3248.1346977557914
INFO:root:current train perplexity3.5966169834136963
INFO:root:current mean train loss 3253.157712803578
INFO:root:current train perplexity3.604487895965576
INFO:root:current mean train loss 3255.315412134906
INFO:root:current train perplexity3.608818769454956
INFO:root:current mean train loss 3252.643048936438
INFO:root:current train perplexity3.6088600158691406
INFO:root:current mean train loss 3257.703588459669
INFO:root:current train perplexity3.6141960620880127
INFO:root:current mean train loss 3257.291273275383
INFO:root:current train perplexity3.611671209335327
INFO:root:current mean train loss 3256.9676782254983
INFO:root:current train perplexity3.612574338912964
INFO:root:current mean train loss 3258.6777465947603
INFO:root:current train perplexity3.6145339012145996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.73s/it]
INFO:root:final mean train loss: 3256.2952110536635
INFO:root:final train perplexity: 3.613593339920044
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4068.4614067348184
INFO:root:eval perplexity: 5.1818718910217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.45s/it]
INFO:root:eval mean loss: 5081.097720315271
INFO:root:eval perplexity: 7.986326694488525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [10:37:59<3:57:00, 263.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.4910396746736
INFO:root:current train perplexity3.626939535140991
INFO:root:current mean train loss 3243.5534580253557
INFO:root:current train perplexity3.6010236740112305
INFO:root:current mean train loss 3251.302128138167
INFO:root:current train perplexity3.5942273139953613
INFO:root:current mean train loss 3257.170241186989
INFO:root:current train perplexity3.602755069732666
INFO:root:current mean train loss 3259.260685203928
INFO:root:current train perplexity3.6059699058532715
INFO:root:current mean train loss 3256.417163990162
INFO:root:current train perplexity3.6050679683685303
INFO:root:current mean train loss 3252.175182062289
INFO:root:current train perplexity3.6032681465148926
INFO:root:current mean train loss 3253.5833261184
INFO:root:current train perplexity3.6041007041931152
INFO:root:current mean train loss 3254.021455370981
INFO:root:current train perplexity3.606321096420288
INFO:root:current mean train loss 3255.4510501833956
INFO:root:current train perplexity3.608285427093506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.68s/it]
INFO:root:final mean train loss: 3253.340504492483
INFO:root:final train perplexity: 3.6093833446502686
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4072.2160419437055
INFO:root:eval perplexity: 5.18974494934082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 5083.931758366578
INFO:root:eval perplexity: 7.995585918426514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [10:42:22<3:52:47, 263.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3258.315963541667
INFO:root:current train perplexity3.593940258026123
INFO:root:current mean train loss 3248.0627371651785
INFO:root:current train perplexity3.603228807449341
INFO:root:current mean train loss 3254.854224964489
INFO:root:current train perplexity3.6022868156433105
INFO:root:current mean train loss 3254.880139322917
INFO:root:current train perplexity3.603114366531372
INFO:root:current mean train loss 3255.883056640625
INFO:root:current train perplexity3.6044609546661377
INFO:root:current mean train loss 3255.6917280910325
INFO:root:current train perplexity3.6055378913879395
INFO:root:current mean train loss 3254.355130570023
INFO:root:current train perplexity3.6051337718963623
INFO:root:current mean train loss 3254.737326738911
INFO:root:current train perplexity3.6078312397003174
INFO:root:current mean train loss 3253.4113342633927
INFO:root:current train perplexity3.606699228286743
INFO:root:current mean train loss 3254.8712224559295
INFO:root:current train perplexity3.607910394668579

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it]
INFO:root:final mean train loss: 3251.5738695821456
INFO:root:final train perplexity: 3.6068687438964844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 4070.701854083555
INFO:root:eval perplexity: 5.186568260192871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it]
INFO:root:eval mean loss: 5081.968668619792
INFO:root:eval perplexity: 7.989169597625732
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [10:46:43<3:47:34, 262.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.266563323607
INFO:root:current train perplexity3.594614267349243
INFO:root:current mean train loss 3253.8577100409834
INFO:root:current train perplexity3.5999486446380615
INFO:root:current mean train loss 3256.1263181868376
INFO:root:current train perplexity3.599175214767456
INFO:root:current mean train loss 3254.3894144959613
INFO:root:current train perplexity3.5987796783447266
INFO:root:current mean train loss 3252.2116254407674
INFO:root:current train perplexity3.6000266075134277
INFO:root:current mean train loss 3254.081506117335
INFO:root:current train perplexity3.601871967315674
INFO:root:current mean train loss 3252.162495067144
INFO:root:current train perplexity3.6022207736968994
INFO:root:current mean train loss 3251.42080676784
INFO:root:current train perplexity3.6019458770751953
INFO:root:current mean train loss 3251.2070276556306
INFO:root:current train perplexity3.601977586746216
INFO:root:current mean train loss 3250.9376887557223
INFO:root:current train perplexity3.602250814437866

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.24s/it]
INFO:root:final mean train loss: 3248.118878272272
INFO:root:final train perplexity: 3.6019554138183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4071.444543716755
INFO:root:eval perplexity: 5.188126564025879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 5084.1250554078015
INFO:root:eval perplexity: 7.996216773986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [10:51:04<3:42:46, 262.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.220182649382
INFO:root:current train perplexity3.601137161254883
INFO:root:current mean train loss 3260.949462890625
INFO:root:current train perplexity3.5925002098083496
INFO:root:current mean train loss 3250.727565909579
INFO:root:current train perplexity3.5887978076934814
INFO:root:current mean train loss 3242.5455725003994
INFO:root:current train perplexity3.589099407196045
INFO:root:current mean train loss 3243.187888834967
INFO:root:current train perplexity3.5933265686035156
INFO:root:current mean train loss 3242.2999480323338
INFO:root:current train perplexity3.5921006202697754
INFO:root:current mean train loss 3241.4475860816524
INFO:root:current train perplexity3.595903158187866
INFO:root:current mean train loss 3244.88856940384
INFO:root:current train perplexity3.5981574058532715
INFO:root:current mean train loss 3246.2206738062046
INFO:root:current train perplexity3.596316337585449
INFO:root:current mean train loss 3247.2914583300485
INFO:root:current train perplexity3.5970935821533203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.62s/it]
INFO:root:final mean train loss: 3244.7376116475752
INFO:root:final train perplexity: 3.5971531867980957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 4072.1352885361257
INFO:root:eval perplexity: 5.189576148986816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 5085.932625844969
INFO:root:eval perplexity: 8.002128601074219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [10:55:24<3:38:02, 261.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.4076334635415
INFO:root:current train perplexity3.596539258956909
INFO:root:current mean train loss 3229.1454771415674
INFO:root:current train perplexity3.5856075286865234
INFO:root:current mean train loss 3237.633367736204
INFO:root:current train perplexity3.586848735809326
INFO:root:current mean train loss 3244.9981649680844
INFO:root:current train perplexity3.589402675628662
INFO:root:current mean train loss 3241.8056058405873
INFO:root:current train perplexity3.5891690254211426
INFO:root:current mean train loss 3242.420014395738
INFO:root:current train perplexity3.5897881984710693
INFO:root:current mean train loss 3247.3430874323813
INFO:root:current train perplexity3.5937891006469727
INFO:root:current mean train loss 3249.0168625088
INFO:root:current train perplexity3.595637321472168
INFO:root:current mean train loss 3248.271302966838
INFO:root:current train perplexity3.595125198364258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.72s/it]
INFO:root:final mean train loss: 3243.753508475519
INFO:root:final train perplexity: 3.5957577228546143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.38s/it]
INFO:root:eval mean loss: 4072.4819526401816
INFO:root:eval perplexity: 5.190302848815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.31s/it]
INFO:root:eval mean loss: 5086.928404463099
INFO:root:eval perplexity: 8.005390167236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [10:59:44<3:33:07, 260.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.2031598772323
INFO:root:current train perplexity3.538787603378296
INFO:root:current mean train loss 3239.4626921181366
INFO:root:current train perplexity3.5666494369506836
INFO:root:current mean train loss 3241.823722212787
INFO:root:current train perplexity3.578533172607422
INFO:root:current mean train loss 3244.0714457260283
INFO:root:current train perplexity3.5879878997802734
INFO:root:current mean train loss 3242.3437110094824
INFO:root:current train perplexity3.586681842803955
INFO:root:current mean train loss 3246.292402940859
INFO:root:current train perplexity3.5886433124542236
INFO:root:current mean train loss 3243.300293773167
INFO:root:current train perplexity3.5888307094573975
INFO:root:current mean train loss 3242.808290559804
INFO:root:current train perplexity3.5894887447357178
INFO:root:current mean train loss 3241.666299396879
INFO:root:current train perplexity3.590731143951416
INFO:root:current mean train loss 3244.770893269363
INFO:root:current train perplexity3.5916340351104736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:44<00:00, 224.26s/it]
INFO:root:final mean train loss: 3241.4241013680735
INFO:root:final train perplexity: 3.592454433441162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4075.001137591423
INFO:root:eval perplexity: 5.195592880249023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]
INFO:root:eval mean loss: 5090.871183787677
INFO:root:eval perplexity: 8.018306732177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [11:04:01<3:27:51, 259.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.1608072916665
INFO:root:current train perplexity3.606815814971924
INFO:root:current mean train loss 3227.114266304348
INFO:root:current train perplexity3.584939479827881
INFO:root:current mean train loss 3232.5354083393895
INFO:root:current train perplexity3.5779335498809814
INFO:root:current mean train loss 3234.085880921379
INFO:root:current train perplexity3.5830507278442383
INFO:root:current mean train loss 3235.0395778426205
INFO:root:current train perplexity3.581306219100952
INFO:root:current mean train loss 3234.4005518052186
INFO:root:current train perplexity3.5814950466156006
INFO:root:current mean train loss 3235.344563405107
INFO:root:current train perplexity3.584038734436035
INFO:root:current mean train loss 3234.6336159446023
INFO:root:current train perplexity3.5855746269226074
INFO:root:current mean train loss 3239.4218609207246
INFO:root:current train perplexity3.5888819694519043
INFO:root:current mean train loss 3241.196704501793
INFO:root:current train perplexity3.590041160583496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.72s/it]
INFO:root:final mean train loss: 3239.857616547615
INFO:root:final train perplexity: 3.5902349948883057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.43s/it]
INFO:root:eval mean loss: 4075.0970034768397
INFO:root:eval perplexity: 5.195795059204102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 5089.804200950244
INFO:root:eval perplexity: 8.014806747436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [11:08:25<3:24:34, 261.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.989162279212
INFO:root:current train perplexity3.5329198837280273
INFO:root:current mean train loss 3233.4440620236282
INFO:root:current train perplexity3.565906524658203
INFO:root:current mean train loss 3238.504471167321
INFO:root:current train perplexity3.5795700550079346
INFO:root:current mean train loss 3237.0847984290344
INFO:root:current train perplexity3.581132650375366
INFO:root:current mean train loss 3231.7234279190675
INFO:root:current train perplexity3.5773603916168213
INFO:root:current mean train loss 3231.343672976667
INFO:root:current train perplexity3.582712411880493
INFO:root:current mean train loss 3234.2349784936796
INFO:root:current train perplexity3.5837371349334717
INFO:root:current mean train loss 3233.1296018650587
INFO:root:current train perplexity3.583529472351074
INFO:root:current mean train loss 3234.003122804811
INFO:root:current train perplexity3.5847105979919434
INFO:root:current mean train loss 3237.0005671045506
INFO:root:current train perplexity3.5839662551879883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.94s/it]
INFO:root:final mean train loss: 3237.2474995274697
INFO:root:final train perplexity: 3.5865390300750732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4075.069590467088
INFO:root:eval perplexity: 5.195736885070801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.92s/it]
INFO:root:eval mean loss: 5091.604653216423
INFO:root:eval perplexity: 8.020711898803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [11:12:46<3:20:12, 261.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.7034085181454
INFO:root:current train perplexity3.5581159591674805
INFO:root:current mean train loss 3227.676860314289
INFO:root:current train perplexity3.5607519149780273
INFO:root:current mean train loss 3225.0786397033958
INFO:root:current train perplexity3.5665442943573
INFO:root:current mean train loss 3223.2684942055325
INFO:root:current train perplexity3.5678858757019043
INFO:root:current mean train loss 3225.6831626803582
INFO:root:current train perplexity3.5748417377471924
INFO:root:current mean train loss 3227.4513539459745
INFO:root:current train perplexity3.575502395629883
INFO:root:current mean train loss 3229.228635567304
INFO:root:current train perplexity3.578514814376831
INFO:root:current mean train loss 3232.641708770627
INFO:root:current train perplexity3.579195022583008
INFO:root:current mean train loss 3236.8803311381243
INFO:root:current train perplexity3.5811026096343994
INFO:root:current mean train loss 3236.103129615333
INFO:root:current train perplexity3.5813450813293457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.20s/it]
INFO:root:final mean train loss: 3234.9077873845254
INFO:root:final train perplexity: 3.5832302570343018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 4075.4487702931074
INFO:root:eval perplexity: 5.196534156799316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it]
INFO:root:eval mean loss: 5092.844752534907
INFO:root:eval perplexity: 8.0247802734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [11:17:06<3:15:31, 260.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.0526655148237
INFO:root:current train perplexity3.5772335529327393
INFO:root:current mean train loss 3230.9480243929856
INFO:root:current train perplexity3.5728673934936523
INFO:root:current mean train loss 3234.16984832636
INFO:root:current train perplexity3.5763425827026367
INFO:root:current mean train loss 3228.6318589832226
INFO:root:current train perplexity3.569136142730713
INFO:root:current mean train loss 3227.2837381210848
INFO:root:current train perplexity3.5701417922973633
INFO:root:current mean train loss 3227.223483791599
INFO:root:current train perplexity3.5713565349578857
INFO:root:current mean train loss 3230.463401448186
INFO:root:current train perplexity3.5751752853393555
INFO:root:current mean train loss 3234.8883672773595
INFO:root:current train perplexity3.577071189880371
INFO:root:current mean train loss 3234.1728585462606
INFO:root:current train perplexity3.577474594116211
INFO:root:current mean train loss 3234.453166860107
INFO:root:current train perplexity3.579007625579834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.90s/it]
INFO:root:final mean train loss: 3232.7370006192114
INFO:root:final train perplexity: 3.5801632404327393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4076.3300123282356
INFO:root:eval perplexity: 5.1983866691589355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]
INFO:root:eval mean loss: 5093.482717960439
INFO:root:eval perplexity: 8.026873588562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [11:21:30<3:11:50, 261.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.5094747340427
INFO:root:current train perplexity3.569046974182129
INFO:root:current mean train loss 3231.692112098746
INFO:root:current train perplexity3.576524496078491
INFO:root:current mean train loss 3229.0816971628287
INFO:root:current train perplexity3.575331687927246
INFO:root:current mean train loss 3231.110864468885
INFO:root:current train perplexity3.579500913619995
INFO:root:current mean train loss 3233.7672881055996
INFO:root:current train perplexity3.575653076171875
INFO:root:current mean train loss 3229.3285945355346
INFO:root:current train perplexity3.572547197341919
INFO:root:current mean train loss 3229.374230221213
INFO:root:current train perplexity3.5760228633880615
INFO:root:current mean train loss 3229.1728662697665
INFO:root:current train perplexity3.576172351837158
INFO:root:current mean train loss 3231.83345977531
INFO:root:current train perplexity3.5762648582458496
INFO:root:current mean train loss 3230.8410381570916
INFO:root:current train perplexity3.5757393836975098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.97s/it]
INFO:root:final mean train loss: 3229.8491331531154
INFO:root:final train perplexity: 3.5760858058929443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 4079.919263907358
INFO:root:eval perplexity: 5.205935955047607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.90s/it]
INFO:root:eval mean loss: 5098.571316766401
INFO:root:eval perplexity: 8.04359245300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [11:25:50<3:07:07, 261.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3228.0916370738637
INFO:root:current train perplexity3.541363477706909
INFO:root:current mean train loss 3233.520786605343
INFO:root:current train perplexity3.5686240196228027
INFO:root:current mean train loss 3228.948127297794
INFO:root:current train perplexity3.569922685623169
INFO:root:current mean train loss 3221.6343763754403
INFO:root:current train perplexity3.5677273273468018
INFO:root:current mean train loss 3219.8666954627406
INFO:root:current train perplexity3.564649820327759
INFO:root:current mean train loss 3223.1153681024775
INFO:root:current train perplexity3.5670783519744873
INFO:root:current mean train loss 3225.809563603292
INFO:root:current train perplexity3.5680718421936035
INFO:root:current mean train loss 3229.6178183852444
INFO:root:current train perplexity3.5719356536865234
INFO:root:current mean train loss 3231.5568936175073
INFO:root:current train perplexity3.5727996826171875
INFO:root:current mean train loss 3232.371954505481
INFO:root:current train perplexity3.5744731426239014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.71s/it]
INFO:root:final mean train loss: 3228.3855879383705
INFO:root:final train perplexity: 3.574021816253662
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4080.852142550421
INFO:root:eval perplexity: 5.2079010009765625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.80s/it]
INFO:root:eval mean loss: 5098.152013034685
INFO:root:eval perplexity: 8.042213439941406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [11:30:26<3:06:03, 265.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.6483793712796
INFO:root:current train perplexity3.5453813076019287
INFO:root:current mean train loss 3213.749035419862
INFO:root:current train perplexity3.550642490386963
INFO:root:current mean train loss 3219.0329023586028
INFO:root:current train perplexity3.551708459854126
INFO:root:current mean train loss 3224.8506962379474
INFO:root:current train perplexity3.558086395263672
INFO:root:current mean train loss 3225.7124724748583
INFO:root:current train perplexity3.563150644302368
INFO:root:current mean train loss 3226.3966149013377
INFO:root:current train perplexity3.566328763961792
INFO:root:current mean train loss 3230.0090821785443
INFO:root:current train perplexity3.568655490875244
INFO:root:current mean train loss 3229.8111439476165
INFO:root:current train perplexity3.568967342376709
INFO:root:current mean train loss 3231.224985628802
INFO:root:current train perplexity3.5709829330444336
INFO:root:current mean train loss 3230.305947498864
INFO:root:current train perplexity3.571620464324951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.98s/it]
INFO:root:final mean train loss: 3226.5658741612588
INFO:root:final train perplexity: 3.5714566707611084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it]
INFO:root:eval mean loss: 4078.864822279477
INFO:root:eval perplexity: 5.20371675491333
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]
INFO:root:eval mean loss: 5096.844184604943
INFO:root:eval perplexity: 8.037914276123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [11:34:46<3:00:27, 264.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.07099678147
INFO:root:current train perplexity3.564744710922241
INFO:root:current mean train loss 3218.615227236385
INFO:root:current train perplexity3.56109881401062
INFO:root:current mean train loss 3227.201721416628
INFO:root:current train perplexity3.562272310256958
INFO:root:current mean train loss 3217.476490771353
INFO:root:current train perplexity3.560758590698242
INFO:root:current mean train loss 3218.372532158141
INFO:root:current train perplexity3.5605359077453613
INFO:root:current mean train loss 3216.8586955964042
INFO:root:current train perplexity3.561227798461914
INFO:root:current mean train loss 3218.3890295355577
INFO:root:current train perplexity3.562234401702881
INFO:root:current mean train loss 3219.687700442303
INFO:root:current train perplexity3.5651679039001465
INFO:root:current mean train loss 3223.1461457735363
INFO:root:current train perplexity3.5654263496398926
INFO:root:current mean train loss 3226.4935427193295
INFO:root:current train perplexity3.568056583404541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.19s/it]
INFO:root:final mean train loss: 3224.502283034786
INFO:root:final train perplexity: 3.5685508251190186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 4081.0204541361923
INFO:root:eval perplexity: 5.208256244659424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.29s/it]
INFO:root:eval mean loss: 5100.72781263852
INFO:root:eval perplexity: 8.050689697265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [11:39:06<2:55:07, 262.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.5099943136865
INFO:root:current train perplexity3.542722702026367
INFO:root:current mean train loss 3214.983270229574
INFO:root:current train perplexity3.5442705154418945
INFO:root:current mean train loss 3213.1449136494734
INFO:root:current train perplexity3.5554163455963135
INFO:root:current mean train loss 3218.048600088638
INFO:root:current train perplexity3.5581228733062744
INFO:root:current mean train loss 3223.141103087487
INFO:root:current train perplexity3.560856819152832
INFO:root:current mean train loss 3221.6280844363937
INFO:root:current train perplexity3.5603842735290527
INFO:root:current mean train loss 3222.7830977741855
INFO:root:current train perplexity3.563563346862793
INFO:root:current mean train loss 3222.9267270990454
INFO:root:current train perplexity3.56353497505188
INFO:root:current mean train loss 3224.7780814490898
INFO:root:current train perplexity3.5658841133117676
INFO:root:current mean train loss 3225.2439074569875
INFO:root:current train perplexity3.5656707286834717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:52<00:00, 232.42s/it]
INFO:root:final mean train loss: 3222.4696097835417
INFO:root:final train perplexity: 3.5656893253326416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 4081.9742769281916
INFO:root:eval perplexity: 5.210264205932617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.69s/it]
INFO:root:eval mean loss: 5102.862386067708
INFO:root:eval perplexity: 8.057717323303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [11:43:31<2:51:14, 263.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.0595703125
INFO:root:current train perplexity3.5296711921691895
INFO:root:current mean train loss 3225.144109552557
INFO:root:current train perplexity3.5535147190093994
INFO:root:current mean train loss 3225.956787960039
INFO:root:current train perplexity3.5589025020599365
INFO:root:current mean train loss 3222.204663022852
INFO:root:current train perplexity3.5622923374176025
INFO:root:current mean train loss 3221.897652941318
INFO:root:current train perplexity3.5620012283325195
INFO:root:current mean train loss 3219.778345683161
INFO:root:current train perplexity3.55954909324646
INFO:root:current mean train loss 3218.4494163368813
INFO:root:current train perplexity3.559803009033203
INFO:root:current mean train loss 3221.424041864378
INFO:root:current train perplexity3.560560941696167
INFO:root:current mean train loss 3222.424778539406
INFO:root:current train perplexity3.561652421951294
INFO:root:current mean train loss 3222.112001676086
INFO:root:current train perplexity3.561589002609253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.38s/it]
INFO:root:final mean train loss: 3219.7313073065975
INFO:root:final train perplexity: 3.5618395805358887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.05s/it]
INFO:root:eval mean loss: 4081.5193078873003
INFO:root:eval perplexity: 5.209305286407471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]
INFO:root:eval mean loss: 5102.443357643506
INFO:root:eval perplexity: 8.0563383102417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [11:47:52<2:46:16, 262.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3197.33871042352
INFO:root:current train perplexity3.5387942790985107
INFO:root:current mean train loss 3204.6352564102563
INFO:root:current train perplexity3.5450098514556885
INFO:root:current mean train loss 3213.695263671875
INFO:root:current train perplexity3.5554728507995605
INFO:root:current mean train loss 3219.7742737589
INFO:root:current train perplexity3.5577619075775146
INFO:root:current mean train loss 3218.753064827967
INFO:root:current train perplexity3.558454990386963
INFO:root:current mean train loss 3220.137664948792
INFO:root:current train perplexity3.556438446044922
INFO:root:current mean train loss 3223.933037671425
INFO:root:current train perplexity3.557446002960205
INFO:root:current mean train loss 3221.864872924037
INFO:root:current train perplexity3.5590097904205322
INFO:root:current mean train loss 3220.7950001636696
INFO:root:current train perplexity3.5587613582611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.58s/it]
INFO:root:final mean train loss: 3219.1177386622276
INFO:root:final train perplexity: 3.5609776973724365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]
INFO:root:eval mean loss: 4082.935690588985
INFO:root:eval perplexity: 5.212290287017822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.50s/it]
INFO:root:eval mean loss: 5102.81278742797
INFO:root:eval perplexity: 8.05755615234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [11:52:11<2:41:16, 261.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3178.3301595052085
INFO:root:current train perplexity3.4840617179870605
INFO:root:current mean train loss 3201.412372478004
INFO:root:current train perplexity3.5218570232391357
INFO:root:current mean train loss 3206.491509197968
INFO:root:current train perplexity3.5316648483276367
INFO:root:current mean train loss 3209.6292986476383
INFO:root:current train perplexity3.5362813472747803
INFO:root:current mean train loss 3215.389646014268
INFO:root:current train perplexity3.546555757522583
INFO:root:current mean train loss 3210.338758950205
INFO:root:current train perplexity3.5469462871551514
INFO:root:current mean train loss 3213.285813769693
INFO:root:current train perplexity3.5476670265197754
INFO:root:current mean train loss 3213.770491837438
INFO:root:current train perplexity3.5477118492126465
INFO:root:current mean train loss 3214.8959963977854
INFO:root:current train perplexity3.5497326850891113
INFO:root:current mean train loss 3216.7496444685253
INFO:root:current train perplexity3.5535032749176025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.16s/it]
INFO:root:final mean train loss: 3215.9908555553807
INFO:root:final train perplexity: 3.5565872192382812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.27s/it]
INFO:root:eval mean loss: 4084.0114503684617
INFO:root:eval perplexity: 5.214558124542236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]
INFO:root:eval mean loss: 5106.709936696587
INFO:root:eval perplexity: 8.070406913757324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [11:56:34<2:37:13, 262.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3246.0334028764205
INFO:root:current train perplexity3.5383968353271484
INFO:root:current mean train loss 3203.2588484480575
INFO:root:current train perplexity3.5440094470977783
INFO:root:current mean train loss 3201.7269478025028
INFO:root:current train perplexity3.5360107421875
INFO:root:current mean train loss 3205.1904500979704
INFO:root:current train perplexity3.540543794631958
INFO:root:current mean train loss 3207.79914651764
INFO:root:current train perplexity3.543999195098877
INFO:root:current mean train loss 3209.9943436773788
INFO:root:current train perplexity3.548292875289917
INFO:root:current mean train loss 3213.189381201412
INFO:root:current train perplexity3.5523135662078857
INFO:root:current mean train loss 3215.1751827449234
INFO:root:current train perplexity3.5530357360839844
INFO:root:current mean train loss 3217.457928639893
INFO:root:current train perplexity3.5528769493103027
INFO:root:current mean train loss 3218.365043296772
INFO:root:current train perplexity3.554478645324707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.23s/it]
INFO:root:final mean train loss: 3215.3758984842607
INFO:root:final train perplexity: 3.555724620819092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4083.6900401013963
INFO:root:eval perplexity: 5.21388053894043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it]
INFO:root:eval mean loss: 5106.14587315769
INFO:root:eval perplexity: 8.068544387817383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [12:00:54<2:32:26, 261.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.8426834909537
INFO:root:current train perplexity3.5521652698516846
INFO:root:current mean train loss 3211.434668789391
INFO:root:current train perplexity3.538890838623047
INFO:root:current mean train loss 3211.5183005136987
INFO:root:current train perplexity3.535593032836914
INFO:root:current mean train loss 3208.350083114959
INFO:root:current train perplexity3.5404539108276367
INFO:root:current mean train loss 3208.5955242439213
INFO:root:current train perplexity3.546187400817871
INFO:root:current mean train loss 3209.623658872983
INFO:root:current train perplexity3.5439975261688232
INFO:root:current mean train loss 3206.935847416448
INFO:root:current train perplexity3.5447723865509033
INFO:root:current mean train loss 3209.76758865123
INFO:root:current train perplexity3.54799222946167
INFO:root:current mean train loss 3211.3378101390795
INFO:root:current train perplexity3.550215005874634
INFO:root:current mean train loss 3215.611513023667
INFO:root:current train perplexity3.552262306213379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.64s/it]
INFO:root:final mean train loss: 3211.7994565040835
INFO:root:final train perplexity: 3.550710678100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.02s/it]
INFO:root:eval mean loss: 4085.0772471326463
INFO:root:eval perplexity: 5.216805458068848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it]
INFO:root:eval mean loss: 5107.633659200465
INFO:root:eval perplexity: 8.073455810546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [12:05:12<2:27:40, 260.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3198.80749963831
INFO:root:current train perplexity3.5747628211975098
INFO:root:current mean train loss 3197.7897526297984
INFO:root:current train perplexity3.5423803329467773
INFO:root:current mean train loss 3201.6702251686397
INFO:root:current train perplexity3.5423202514648438
INFO:root:current mean train loss 3205.4756949421826
INFO:root:current train perplexity3.5482797622680664
INFO:root:current mean train loss 3208.6756285906395
INFO:root:current train perplexity3.5465879440307617
INFO:root:current mean train loss 3214.6506088227884
INFO:root:current train perplexity3.5511953830718994
INFO:root:current mean train loss 3214.089356247508
INFO:root:current train perplexity3.5504086017608643
INFO:root:current mean train loss 3216.187152091214
INFO:root:current train perplexity3.5511136054992676
INFO:root:current mean train loss 3215.743664447457
INFO:root:current train perplexity3.5521585941314697
INFO:root:current mean train loss 3215.610254116943
INFO:root:current train perplexity3.551281690597534

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.85s/it]
INFO:root:final mean train loss: 3212.842557353358
INFO:root:final train perplexity: 3.5521721839904785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.23s/it]
INFO:root:eval mean loss: 4083.692742963209
INFO:root:eval perplexity: 5.213886260986328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.18s/it]
INFO:root:eval mean loss: 5106.832690949135
INFO:root:eval perplexity: 8.07081127166748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [12:09:36<2:23:45, 261.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.0602120535714
INFO:root:current train perplexity3.5537569522857666
INFO:root:current mean train loss 3200.918507667824
INFO:root:current train perplexity3.550367832183838
INFO:root:current mean train loss 3202.398890458777
INFO:root:current train perplexity3.5390310287475586
INFO:root:current mean train loss 3205.4157984491603
INFO:root:current train perplexity3.538801431655884
INFO:root:current mean train loss 3210.921818314476
INFO:root:current train perplexity3.5443191528320312
INFO:root:current mean train loss 3212.41164984302
INFO:root:current train perplexity3.5457406044006348
INFO:root:current mean train loss 3209.070735805241
INFO:root:current train perplexity3.54376482963562
INFO:root:current mean train loss 3210.2134157764667
INFO:root:current train perplexity3.5436017513275146
INFO:root:current mean train loss 3212.349859363305
INFO:root:current train perplexity3.5460128784179688
INFO:root:current mean train loss 3212.149267839238
INFO:root:current train perplexity3.5474212169647217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.18s/it]
INFO:root:final mean train loss: 3210.685724073841
INFO:root:final train perplexity: 3.5491509437561035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4086.252820603391
INFO:root:eval perplexity: 5.2192864418029785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.44s/it]
INFO:root:eval mean loss: 5108.987126343639
INFO:root:eval perplexity: 8.077925682067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [12:13:56<2:19:09, 260.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.8512331940406
INFO:root:current train perplexity3.5277163982391357
INFO:root:current mean train loss 3218.58626700448
INFO:root:current train perplexity3.5432674884796143
INFO:root:current mean train loss 3210.124750835905
INFO:root:current train perplexity3.538778781890869
INFO:root:current mean train loss 3207.2525374965835
INFO:root:current train perplexity3.5352888107299805
INFO:root:current mean train loss 3210.892664097771
INFO:root:current train perplexity3.5388145446777344
INFO:root:current mean train loss 3210.9821795328326
INFO:root:current train perplexity3.539902687072754
INFO:root:current mean train loss 3206.876513064371
INFO:root:current train perplexity3.5393710136413574
INFO:root:current mean train loss 3207.02195589828
INFO:root:current train perplexity3.5416133403778076
INFO:root:current mean train loss 3209.561288274763
INFO:root:current train perplexity3.5446207523345947
INFO:root:current mean train loss 3210.079961879888
INFO:root:current train perplexity3.5452330112457275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.65s/it]
INFO:root:final mean train loss: 3207.454236799671
INFO:root:final train perplexity: 3.544628858566284
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.20s/it]
INFO:root:eval mean loss: 4086.2762355939717
INFO:root:eval perplexity: 5.219336986541748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 5109.756939827128
INFO:root:eval perplexity: 8.080467224121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [12:18:15<2:14:35, 260.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.1133051853553
INFO:root:current train perplexity3.5456371307373047
INFO:root:current mean train loss 3218.330435443398
INFO:root:current train perplexity3.552039623260498
INFO:root:current mean train loss 3223.6662879731075
INFO:root:current train perplexity3.547701120376587
INFO:root:current mean train loss 3215.7351275930378
INFO:root:current train perplexity3.540493965148926
INFO:root:current mean train loss 3211.8892554306403
INFO:root:current train perplexity3.5435678958892822
INFO:root:current mean train loss 3210.9289985005953
INFO:root:current train perplexity3.542670726776123
INFO:root:current mean train loss 3209.128169327837
INFO:root:current train perplexity3.542664051055908
INFO:root:current mean train loss 3211.7547241698567
INFO:root:current train perplexity3.545466661453247
INFO:root:current mean train loss 3210.0550441002315
INFO:root:current train perplexity3.5423388481140137
INFO:root:current mean train loss 3209.1259103287657
INFO:root:current train perplexity3.543398380279541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.74s/it]
INFO:root:final mean train loss: 3206.692741578625
INFO:root:final train perplexity: 3.5435640811920166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 4087.257881759752
INFO:root:eval perplexity: 5.221407413482666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]
INFO:root:eval mean loss: 5111.574075036015
INFO:root:eval perplexity: 8.086474418640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [12:22:38<2:10:33, 261.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3197.3092020325744
INFO:root:current train perplexity3.5220518112182617
INFO:root:current mean train loss 3201.0777303827635
INFO:root:current train perplexity3.534585475921631
INFO:root:current mean train loss 3197.4544654168676
INFO:root:current train perplexity3.5290863513946533
INFO:root:current mean train loss 3205.355678887752
INFO:root:current train perplexity3.533343553543091
INFO:root:current mean train loss 3206.3607850583808
INFO:root:current train perplexity3.5326223373413086
INFO:root:current mean train loss 3208.11244138878
INFO:root:current train perplexity3.535123586654663
INFO:root:current mean train loss 3204.713837920263
INFO:root:current train perplexity3.5356853008270264
INFO:root:current mean train loss 3205.757954352458
INFO:root:current train perplexity3.5389137268066406
INFO:root:current mean train loss 3207.8528619306608
INFO:root:current train perplexity3.5401406288146973
INFO:root:current mean train loss 3207.944644995601
INFO:root:current train perplexity3.5408105850219727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:51<00:00, 231.75s/it]
INFO:root:final mean train loss: 3204.845076099519
INFO:root:final train perplexity: 3.5409820079803467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4087.826203041888
INFO:root:eval perplexity: 5.2226080894470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.40s/it]
INFO:root:eval mean loss: 5112.286408120013
INFO:root:eval perplexity: 8.08882999420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [12:27:02<2:06:41, 262.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3167.4531468633395
INFO:root:current train perplexity3.5046162605285645
INFO:root:current mean train loss 3194.024807318956
INFO:root:current train perplexity3.529520034790039
INFO:root:current mean train loss 3205.7943064943233
INFO:root:current train perplexity3.539064645767212
INFO:root:current mean train loss 3211.295350285252
INFO:root:current train perplexity3.5395348072052
INFO:root:current mean train loss 3205.009512074244
INFO:root:current train perplexity3.5345025062561035
INFO:root:current mean train loss 3208.3839436418375
INFO:root:current train perplexity3.5353763103485107
INFO:root:current mean train loss 3209.4148673954037
INFO:root:current train perplexity3.5372965335845947
INFO:root:current mean train loss 3207.114711080101
INFO:root:current train perplexity3.5364887714385986
INFO:root:current mean train loss 3204.1664413927338
INFO:root:current train perplexity3.5372865200042725
INFO:root:current mean train loss 3205.0162703189635
INFO:root:current train perplexity3.538963794708252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.47s/it]
INFO:root:final mean train loss: 3203.9543236147974
INFO:root:final train perplexity: 3.539738178253174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]
INFO:root:eval mean loss: 4088.046681072695
INFO:root:eval perplexity: 5.223074436187744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 5113.814733626995
INFO:root:eval perplexity: 8.093884468078613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [12:31:26<2:02:34, 262.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3206.6140885416667
INFO:root:current train perplexity3.5139706134796143
INFO:root:current mean train loss 3193.9224483816965
INFO:root:current train perplexity3.519439935684204
INFO:root:current mean train loss 3200.4844664417615
INFO:root:current train perplexity3.5305721759796143
INFO:root:current mean train loss 3199.414854817708
INFO:root:current train perplexity3.525070905685425
INFO:root:current mean train loss 3201.3561415501645
INFO:root:current train perplexity3.527386426925659
INFO:root:current mean train loss 3202.6746382472825
INFO:root:current train perplexity3.530189275741577
INFO:root:current mean train loss 3199.0547591145832
INFO:root:current train perplexity3.5300073623657227
INFO:root:current mean train loss 3199.3581961945565
INFO:root:current train perplexity3.5314531326293945
INFO:root:current mean train loss 3202.3288604910713
INFO:root:current train perplexity3.533339738845825
INFO:root:current mean train loss 3202.379761368189
INFO:root:current train perplexity3.5351319313049316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 228.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 228.00s/it]
INFO:root:final mean train loss: 3200.680362024615
INFO:root:final train perplexity: 3.5351686477661133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4089.7733994071364
INFO:root:eval perplexity: 5.226722240447998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.93s/it]
INFO:root:eval mean loss: 5115.174397786458
INFO:root:eval perplexity: 8.098389625549316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [12:35:47<1:57:58, 262.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.0033209007906
INFO:root:current train perplexity3.5382068157196045
INFO:root:current mean train loss 3219.4321622587945
INFO:root:current train perplexity3.5313453674316406
INFO:root:current mean train loss 3210.7673874710135
INFO:root:current train perplexity3.531994104385376
INFO:root:current mean train loss 3210.7415685429587
INFO:root:current train perplexity3.535111665725708
INFO:root:current mean train loss 3207.9552666642403
INFO:root:current train perplexity3.5312864780426025
INFO:root:current mean train loss 3208.915745102112
INFO:root:current train perplexity3.5313735008239746
INFO:root:current mean train loss 3206.8869353667187
INFO:root:current train perplexity3.5327091217041016
INFO:root:current mean train loss 3205.046546361151
INFO:root:current train perplexity3.5346288681030273
INFO:root:current mean train loss 3204.86165244771
INFO:root:current train perplexity3.5323684215545654
INFO:root:current mean train loss 3204.375985006835
INFO:root:current train perplexity3.535740852355957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.83s/it]
INFO:root:final mean train loss: 3200.978369497484
INFO:root:final train perplexity: 3.535583734512329
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 4090.0406087239585
INFO:root:eval perplexity: 5.2272868156433105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.68s/it]
INFO:root:eval mean loss: 5114.441982837434
INFO:root:eval perplexity: 8.095961570739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [12:40:08<1:53:23, 261.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3206.86176274897
INFO:root:current train perplexity3.5403027534484863
INFO:root:current mean train loss 3211.843995418848
INFO:root:current train perplexity3.5393123626708984
INFO:root:current mean train loss 3194.123337159042
INFO:root:current train perplexity3.5268821716308594
INFO:root:current mean train loss 3198.528108640705
INFO:root:current train perplexity3.5300352573394775
INFO:root:current mean train loss 3200.4965273357943
INFO:root:current train perplexity3.5345041751861572
INFO:root:current mean train loss 3198.8354463270675
INFO:root:current train perplexity3.5348238945007324
INFO:root:current mean train loss 3198.5078898759725
INFO:root:current train perplexity3.5323941707611084
INFO:root:current mean train loss 3202.293513205199
INFO:root:current train perplexity3.5320193767547607
INFO:root:current mean train loss 3201.6399377893517
INFO:root:current train perplexity3.532597064971924
INFO:root:current mean train loss 3201.879122798546
INFO:root:current train perplexity3.5333380699157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.27s/it]
INFO:root:final mean train loss: 3199.3681007508308
INFO:root:final train perplexity: 3.533338785171509
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.35s/it]
INFO:root:eval mean loss: 4090.451665350731
INFO:root:eval perplexity: 5.228155612945557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.64s/it]
INFO:root:eval mean loss: 5116.104549326795
INFO:root:eval perplexity: 8.101469993591309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [12:44:31<1:49:14, 262.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.7023531210543
INFO:root:current train perplexity3.5354926586151123
INFO:root:current mean train loss 3197.594368326005
INFO:root:current train perplexity3.5246024131774902
INFO:root:current mean train loss 3203.6445108369044
INFO:root:current train perplexity3.5310890674591064
INFO:root:current mean train loss 3202.6120666656875
INFO:root:current train perplexity3.5310726165771484
INFO:root:current mean train loss 3206.147825436028
INFO:root:current train perplexity3.534108877182007
INFO:root:current mean train loss 3208.020075369757
INFO:root:current train perplexity3.5356671810150146
INFO:root:current mean train loss 3205.3725177290103
INFO:root:current train perplexity3.5325963497161865
INFO:root:current mean train loss 3201.980708307259
INFO:root:current train perplexity3.5317113399505615
INFO:root:current mean train loss 3201.2612375295466
INFO:root:current train perplexity3.531066417694092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.80s/it]
INFO:root:final mean train loss: 3198.478967851208
INFO:root:final train perplexity: 3.532099485397339
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4090.8329298952794
INFO:root:eval perplexity: 5.2289628982543945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.51s/it]
INFO:root:eval mean loss: 5116.6866827349295
INFO:root:eval perplexity: 8.103398323059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [12:48:51<1:44:40, 261.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.8037458147323
INFO:root:current train perplexity3.5312392711639404
INFO:root:current mean train loss 3201.8182156286507
INFO:root:current train perplexity3.526981830596924
INFO:root:current mean train loss 3195.740539845637
INFO:root:current train perplexity3.523118257522583
INFO:root:current mean train loss 3193.9370991958467
INFO:root:current train perplexity3.526542901992798
INFO:root:current mean train loss 3194.323310570869
INFO:root:current train perplexity3.526244878768921
INFO:root:current mean train loss 3192.282335390471
INFO:root:current train perplexity3.5274863243103027
INFO:root:current mean train loss 3197.1545241228637
INFO:root:current train perplexity3.53222918510437
INFO:root:current mean train loss 3196.40460248243
INFO:root:current train perplexity3.527059555053711
INFO:root:current mean train loss 3198.6671253001086
INFO:root:current train perplexity3.5268490314483643
INFO:root:current mean train loss 3199.4801861175233
INFO:root:current train perplexity3.529754161834717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.96s/it]
INFO:root:final mean train loss: 3197.3572507673694
INFO:root:final train perplexity: 3.5305368900299072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 4090.58060276762
INFO:root:eval perplexity: 5.228428840637207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.00s/it]
INFO:root:eval mean loss: 5116.45204801086
INFO:root:eval perplexity: 8.102621078491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [12:53:11<1:40:07, 261.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.307080078125
INFO:root:current train perplexity3.5535507202148438
INFO:root:current mean train loss 3196.5505073879076
INFO:root:current train perplexity3.5290446281433105
INFO:root:current mean train loss 3192.729721566134
INFO:root:current train perplexity3.5285003185272217
INFO:root:current mean train loss 3198.0410970052085
INFO:root:current train perplexity3.5261120796203613
INFO:root:current mean train loss 3200.1956990069652
INFO:root:current train perplexity3.5252685546875
INFO:root:current mean train loss 3197.840214938562
INFO:root:current train perplexity3.5254104137420654
INFO:root:current mean train loss 3196.2966947726118
INFO:root:current train perplexity3.5281896591186523
INFO:root:current mean train loss 3197.8452097219188
INFO:root:current train perplexity3.528988838195801
INFO:root:current mean train loss 3197.662267841737
INFO:root:current train perplexity3.528184175491333
INFO:root:current mean train loss 3199.654678428108
INFO:root:current train perplexity3.5299227237701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.84s/it]
INFO:root:final mean train loss: 3196.121427905175
INFO:root:final train perplexity: 3.5288162231445312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.31s/it]
INFO:root:eval mean loss: 4091.449447307181
INFO:root:eval perplexity: 5.2302656173706055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.87s/it]
INFO:root:eval mean loss: 5117.073813580452
INFO:root:eval perplexity: 8.104681015014648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [12:57:32<1:35:44, 261.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.5013056216035
INFO:root:current train perplexity3.501298427581787
INFO:root:current mean train loss 3198.4878624396597
INFO:root:current train perplexity3.520470142364502
INFO:root:current mean train loss 3192.566049344871
INFO:root:current train perplexity3.529740571975708
INFO:root:current mean train loss 3192.9295627842007
INFO:root:current train perplexity3.526322603225708
INFO:root:current mean train loss 3193.731419917258
INFO:root:current train perplexity3.522120475769043
INFO:root:current mean train loss 3194.6810183698317
INFO:root:current train perplexity3.5227584838867188
INFO:root:current mean train loss 3195.4634235804574
INFO:root:current train perplexity3.52366304397583
INFO:root:current mean train loss 3195.7877445458375
INFO:root:current train perplexity3.5250179767608643
INFO:root:current mean train loss 3195.2154942972547
INFO:root:current train perplexity3.5273866653442383
INFO:root:current mean train loss 3195.530298830241
INFO:root:current train perplexity3.5267231464385986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.12s/it]
INFO:root:final mean train loss: 3194.35386091663
INFO:root:final train perplexity: 3.5263562202453613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.14s/it]
INFO:root:eval mean loss: 4093.3216197778147
INFO:root:eval perplexity: 5.234227180480957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.85s/it]
INFO:root:eval mean loss: 5120.030759987256
INFO:root:eval perplexity: 8.114485740661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [13:01:53<1:31:17, 260.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.5739509828627
INFO:root:current train perplexity3.514127731323242
INFO:root:current mean train loss 3195.038941361522
INFO:root:current train perplexity3.531018018722534
INFO:root:current mean train loss 3194.260267645766
INFO:root:current train perplexity3.5329699516296387
INFO:root:current mean train loss 3197.0304770109515
INFO:root:current train perplexity3.5333189964294434
INFO:root:current mean train loss 3197.3551832584108
INFO:root:current train perplexity3.53011417388916
INFO:root:current mean train loss 3199.942075222899
INFO:root:current train perplexity3.535429000854492
INFO:root:current mean train loss 3195.345030287366
INFO:root:current train perplexity3.5314574241638184
INFO:root:current mean train loss 3197.218303466463
INFO:root:current train perplexity3.529905080795288
INFO:root:current mean train loss 3196.6465989536327
INFO:root:current train perplexity3.528095006942749
INFO:root:current mean train loss 3196.110681453914
INFO:root:current train perplexity3.526052713394165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.42s/it]
INFO:root:final mean train loss: 3193.6541000489265
INFO:root:final train perplexity: 3.5253827571868896
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.04s/it]
INFO:root:eval mean loss: 4093.1158629072474
INFO:root:eval perplexity: 5.233791828155518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.57s/it]
INFO:root:eval mean loss: 5119.259668661348
INFO:root:eval perplexity: 8.111926078796387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [13:06:13<1:26:51, 260.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.5443897736377
INFO:root:current train perplexity3.5336568355560303
INFO:root:current mean train loss 3184.6083352068345
INFO:root:current train perplexity3.514188528060913
INFO:root:current mean train loss 3188.225418410042
INFO:root:current train perplexity3.515036106109619
INFO:root:current mean train loss 3189.787610619469
INFO:root:current train perplexity3.5190224647521973
INFO:root:current mean train loss 3189.9713337752705
INFO:root:current train perplexity3.5186264514923096
INFO:root:current mean train loss 3190.6332690746754
INFO:root:current train perplexity3.519089937210083
INFO:root:current mean train loss 3191.7661606575216
INFO:root:current train perplexity3.5199530124664307
INFO:root:current mean train loss 3191.960209372886
INFO:root:current train perplexity3.518899917602539
INFO:root:current mean train loss 3191.531264258511
INFO:root:current train perplexity3.5179624557495117
INFO:root:current mean train loss 3191.2295246875833
INFO:root:current train perplexity3.5192973613739014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.91s/it]
INFO:root:final mean train loss: 3190.0843040712416
INFO:root:final train perplexity: 3.520421028137207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.29s/it]
INFO:root:eval mean loss: 4093.1131773603724
INFO:root:eval perplexity: 5.233786106109619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 5119.415193165448
INFO:root:eval perplexity: 8.112442970275879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [13:10:35<1:22:43, 261.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3174.4326951047206
INFO:root:current train perplexity3.504404067993164
INFO:root:current mean train loss 3193.318557012649
INFO:root:current train perplexity3.517157793045044
INFO:root:current mean train loss 3188.6352885010756
INFO:root:current train perplexity3.514068603515625
INFO:root:current mean train loss 3193.472270690742
INFO:root:current train perplexity3.515377998352051
INFO:root:current mean train loss 3193.38152461724
INFO:root:current train perplexity3.517801523208618
INFO:root:current mean train loss 3194.7631010233376
INFO:root:current train perplexity3.5185110569000244
INFO:root:current mean train loss 3193.9430563689384
INFO:root:current train perplexity3.518700361251831
INFO:root:current mean train loss 3193.3098915845676
INFO:root:current train perplexity3.5195858478546143
INFO:root:current mean train loss 3194.624614620997
INFO:root:current train perplexity3.5204226970672607
INFO:root:current mean train loss 3193.5622385864904
INFO:root:current train perplexity3.521219253540039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 227.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 227.00s/it]
INFO:root:final mean train loss: 3190.8775049640285
INFO:root:final train perplexity: 3.5215227603912354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4093.830194135084
INFO:root:eval perplexity: 5.235304355621338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it]
INFO:root:eval mean loss: 5120.221759336215
INFO:root:eval perplexity: 8.115119934082031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [13:14:55<1:18:15, 260.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.1991255326707
INFO:root:current train perplexity3.5175135135650635
INFO:root:current mean train loss 3193.051983051915
INFO:root:current train perplexity3.509033203125
INFO:root:current mean train loss 3190.5896484375
INFO:root:current train perplexity3.514019250869751
INFO:root:current mean train loss 3186.343115234375
INFO:root:current train perplexity3.5158634185791016
INFO:root:current mean train loss 3187.337917990213
INFO:root:current train perplexity3.5166585445404053
INFO:root:current mean train loss 3185.105986504082
INFO:root:current train perplexity3.5133156776428223
INFO:root:current mean train loss 3185.6100895306536
INFO:root:current train perplexity3.5152413845062256
INFO:root:current mean train loss 3187.687577607616
INFO:root:current train perplexity3.518505573272705
INFO:root:current mean train loss 3190.219078661824
INFO:root:current train perplexity3.5199508666992188
INFO:root:current mean train loss 3191.4570064524705
INFO:root:current train perplexity3.5193819999694824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.41s/it]
INFO:root:final mean train loss: 3190.0730919376497
INFO:root:final train perplexity: 3.5204052925109863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4094.0992769281916
INFO:root:eval perplexity: 5.235872745513916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]
INFO:root:eval mean loss: 5122.689356161348
INFO:root:eval perplexity: 8.123313903808594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [13:19:15<1:13:49, 260.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3183.5078783792164
INFO:root:current train perplexity3.512737989425659
INFO:root:current mean train loss 3198.330768608608
INFO:root:current train perplexity3.5187103748321533
INFO:root:current mean train loss 3195.7820901036716
INFO:root:current train perplexity3.520085096359253
INFO:root:current mean train loss 3189.207398469783
INFO:root:current train perplexity3.5160958766937256
INFO:root:current mean train loss 3191.3642989420223
INFO:root:current train perplexity3.5168681144714355
INFO:root:current mean train loss 3194.2234983833814
INFO:root:current train perplexity3.519183874130249
INFO:root:current mean train loss 3193.613269834677
INFO:root:current train perplexity3.517703056335449
INFO:root:current mean train loss 3194.88231589941
INFO:root:current train perplexity3.5172009468078613
INFO:root:current mean train loss 3193.3198344030634
INFO:root:current train perplexity3.5174665451049805
INFO:root:current mean train loss 3191.3847384982637
INFO:root:current train perplexity3.520193576812744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.52s/it]
INFO:root:final mean train loss: 3189.0439316534225
INFO:root:final train perplexity: 3.5189762115478516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.25s/it]
INFO:root:eval mean loss: 4094.071990317487
INFO:root:eval perplexity: 5.235814571380615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]
INFO:root:eval mean loss: 5121.802637411348
INFO:root:eval perplexity: 8.120368957519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [13:23:39<1:09:44, 261.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.5051613391283
INFO:root:current train perplexity3.499765396118164
INFO:root:current mean train loss 3189.476997955501
INFO:root:current train perplexity3.519253969192505
INFO:root:current mean train loss 3188.4686608120965
INFO:root:current train perplexity3.512295961380005
INFO:root:current mean train loss 3188.841178297675
INFO:root:current train perplexity3.5155444145202637
INFO:root:current mean train loss 3188.4786213674365
INFO:root:current train perplexity3.514226198196411
INFO:root:current mean train loss 3188.8733619917084
INFO:root:current train perplexity3.5155575275421143
INFO:root:current mean train loss 3190.532317160139
INFO:root:current train perplexity3.518001079559326
INFO:root:current mean train loss 3191.3163483022254
INFO:root:current train perplexity3.5184097290039062
INFO:root:current mean train loss 3188.9927565074267
INFO:root:current train perplexity3.515956401824951
INFO:root:current mean train loss 3190.075986066636
INFO:root:current train perplexity3.5175483226776123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.74s/it]
INFO:root:final mean train loss: 3187.1499558725664
INFO:root:final train perplexity: 3.5163474082946777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.19s/it]
INFO:root:eval mean loss: 4094.1481916278813
INFO:root:eval perplexity: 5.235976219177246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.46s/it]
INFO:root:eval mean loss: 5121.986319467531
INFO:root:eval perplexity: 8.120979309082031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [13:27:59<1:05:17, 261.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.5618571993673
INFO:root:current train perplexity3.5236189365386963
INFO:root:current mean train loss 3211.6355566951815
INFO:root:current train perplexity3.524702787399292
INFO:root:current mean train loss 3201.493346949205
INFO:root:current train perplexity3.5201313495635986
INFO:root:current mean train loss 3197.208920602119
INFO:root:current train perplexity3.520111560821533
INFO:root:current mean train loss 3192.542834702016
INFO:root:current train perplexity3.519392490386963
INFO:root:current mean train loss 3191.7807798500917
INFO:root:current train perplexity3.5157108306884766
INFO:root:current mean train loss 3190.718227201077
INFO:root:current train perplexity3.515028476715088
INFO:root:current mean train loss 3189.3375035727895
INFO:root:current train perplexity3.5147035121917725
INFO:root:current mean train loss 3190.0490369916097
INFO:root:current train perplexity3.517817974090576
INFO:root:current mean train loss 3189.42473436303
INFO:root:current train perplexity3.516296863555908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.26s/it]
INFO:root:final mean train loss: 3187.1531067509804
INFO:root:final train perplexity: 3.5163521766662598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 16.00s/it]
INFO:root:eval mean loss: 4094.5792643229165
INFO:root:eval perplexity: 5.236889839172363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.33s/it]
INFO:root:eval mean loss: 5123.193612173094
INFO:root:eval perplexity: 8.124987602233887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [13:32:19<1:00:49, 260.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3184.0823988640445
INFO:root:current train perplexity3.5133984088897705
INFO:root:current mean train loss 3185.336192085144
INFO:root:current train perplexity3.5183303356170654
INFO:root:current mean train loss 3185.7834983054768
INFO:root:current train perplexity3.512261152267456
INFO:root:current mean train loss 3184.287610904191
INFO:root:current train perplexity3.5117976665496826
INFO:root:current mean train loss 3181.6159432350487
INFO:root:current train perplexity3.508091449737549
INFO:root:current mean train loss 3183.3013560410454
INFO:root:current train perplexity3.5086445808410645
INFO:root:current mean train loss 3181.379847275291
INFO:root:current train perplexity3.507371187210083
INFO:root:current mean train loss 3184.9349757658633
INFO:root:current train perplexity3.510136842727661
INFO:root:current mean train loss 3186.2811052221323
INFO:root:current train perplexity3.512848138809204
INFO:root:current mean train loss 3187.827955808321
INFO:root:current train perplexity3.514029026031494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.89s/it]
INFO:root:final mean train loss: 3185.500721470002
INFO:root:final train perplexity: 3.5140602588653564
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 4094.430033798759
INFO:root:eval perplexity: 5.236573219299316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.21s/it]
INFO:root:eval mean loss: 5122.760731798538
INFO:root:eval perplexity: 8.12354850769043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [13:36:43<56:41, 261.63s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3205.9233655427633
INFO:root:current train perplexity3.5114619731903076
INFO:root:current mean train loss 3198.438843399439
INFO:root:current train perplexity3.5159199237823486
INFO:root:current mean train loss 3188.526276979608
INFO:root:current train perplexity3.5094027519226074
INFO:root:current mean train loss 3190.2579664013056
INFO:root:current train perplexity3.510366678237915
INFO:root:current mean train loss 3189.087335759943
INFO:root:current train perplexity3.5101611614227295
INFO:root:current mean train loss 3190.163562319459
INFO:root:current train perplexity3.5102152824401855
INFO:root:current mean train loss 3189.338063104204
INFO:root:current train perplexity3.5115654468536377
INFO:root:current mean train loss 3187.329269236439
INFO:root:current train perplexity3.513444662094116
INFO:root:current mean train loss 3186.7971311430692
INFO:root:current train perplexity3.5140788555145264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.50s/it]
INFO:root:final mean train loss: 3184.0889450196296
INFO:root:final train perplexity: 3.5121042728424072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 4095.3782275044327
INFO:root:eval perplexity: 5.23858118057251
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.65s/it]
INFO:root:eval mean loss: 5124.078812403036
INFO:root:eval perplexity: 8.127928733825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [13:41:03<52:14, 261.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3111.501953125
INFO:root:current train perplexity3.4953794479370117
INFO:root:current mean train loss 3190.6234687879246
INFO:root:current train perplexity3.5025858879089355
INFO:root:current mean train loss 3186.107718932805
INFO:root:current train perplexity3.5170304775238037
INFO:root:current mean train loss 3180.887416524856
INFO:root:current train perplexity3.511950969696045
INFO:root:current mean train loss 3182.7085803010623
INFO:root:current train perplexity3.5082783699035645
INFO:root:current mean train loss 3183.4948803274106
INFO:root:current train perplexity3.50883412361145
INFO:root:current mean train loss 3185.552145279462
INFO:root:current train perplexity3.5097813606262207
INFO:root:current mean train loss 3184.5161111975463
INFO:root:current train perplexity3.510730266571045
INFO:root:current mean train loss 3186.2797717786816
INFO:root:current train perplexity3.5123274326324463
INFO:root:current mean train loss 3186.1886869073574
INFO:root:current train perplexity3.511223793029785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.84s/it]
INFO:root:final mean train loss: 3183.6013905925133
INFO:root:final train perplexity: 3.511428117752075
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.32s/it]
INFO:root:eval mean loss: 4095.0983609679743
INFO:root:eval perplexity: 5.237988471984863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it]
INFO:root:eval mean loss: 5123.778230274823
INFO:root:eval perplexity: 8.12692928314209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [13:45:26<48:00, 261.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3132.095148259943
INFO:root:current train perplexity3.4563403129577637
INFO:root:current mean train loss 3175.0402128202422
INFO:root:current train perplexity3.5032103061676025
INFO:root:current mean train loss 3179.4242122704386
INFO:root:current train perplexity3.5090956687927246
INFO:root:current mean train loss 3184.868572271905
INFO:root:current train perplexity3.5137546062469482
INFO:root:current mean train loss 3184.3458355905946
INFO:root:current train perplexity3.511399984359741
INFO:root:current mean train loss 3187.1026914712265
INFO:root:current train perplexity3.512387990951538
INFO:root:current mean train loss 3189.483428405662
INFO:root:current train perplexity3.5133278369903564
INFO:root:current mean train loss 3186.5273361957193
INFO:root:current train perplexity3.511202096939087
INFO:root:current mean train loss 3186.960560301229
INFO:root:current train perplexity3.5109333992004395
INFO:root:current mean train loss 3186.879709153746
INFO:root:current train perplexity3.510223865509033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.99s/it]
INFO:root:final mean train loss: 3182.779541692426
INFO:root:final train perplexity: 3.5102901458740234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.07s/it]
INFO:root:eval mean loss: 4095.6145417774824
INFO:root:eval perplexity: 5.2390828132629395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it]
INFO:root:eval mean loss: 5123.742906069925
INFO:root:eval perplexity: 8.126812934875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [13:49:47<43:34, 261.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3164.902896278783
INFO:root:current train perplexity3.5229785442352295
INFO:root:current mean train loss 3209.240517496061
INFO:root:current train perplexity3.5347437858581543
INFO:root:current mean train loss 3185.362638011915
INFO:root:current train perplexity3.5175838470458984
INFO:root:current mean train loss 3175.1512600411443
INFO:root:current train perplexity3.5186285972595215
INFO:root:current mean train loss 3175.4854080819287
INFO:root:current train perplexity3.5147368907928467
INFO:root:current mean train loss 3178.47462630961
INFO:root:current train perplexity3.5157246589660645
INFO:root:current mean train loss 3179.9818562891255
INFO:root:current train perplexity3.5122694969177246
INFO:root:current mean train loss 3181.0419616274776
INFO:root:current train perplexity3.5098440647125244
INFO:root:current mean train loss 3182.3596468635533
INFO:root:current train perplexity3.5096285343170166
INFO:root:current mean train loss 3184.709650647783
INFO:root:current train perplexity3.510590076446533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.31s/it]
INFO:root:final mean train loss: 3182.9252838626985
INFO:root:final train perplexity: 3.5104918479919434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 4095.3497998393173
INFO:root:eval perplexity: 5.238521575927734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.67s/it]
INFO:root:eval mean loss: 5124.78416583555
INFO:root:eval perplexity: 8.13027572631836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [13:54:10<39:18, 262.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3162.9798448350693
INFO:root:current train perplexity3.4787304401397705
INFO:root:current mean train loss 3170.923751230315
INFO:root:current train perplexity3.5068140029907227
INFO:root:current mean train loss 3169.5932724738436
INFO:root:current train perplexity3.5000126361846924
INFO:root:current mean train loss 3172.35062924073
INFO:root:current train perplexity3.4961907863616943
INFO:root:current mean train loss 3173.2586301138026
INFO:root:current train perplexity3.496580123901367
INFO:root:current mean train loss 3176.2706921919475
INFO:root:current train perplexity3.4996402263641357
INFO:root:current mean train loss 3178.1504377398574
INFO:root:current train perplexity3.5041420459747314
INFO:root:current mean train loss 3181.7916462936296
INFO:root:current train perplexity3.5062906742095947
INFO:root:current mean train loss 3182.175962215179
INFO:root:current train perplexity3.507495880126953
INFO:root:current mean train loss 3183.1113318121293
INFO:root:current train perplexity3.5088999271392822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:46<00:00, 226.09s/it]
INFO:root:final mean train loss: 3181.78774439904
INFO:root:final train perplexity: 3.5089168548583984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it]
INFO:root:eval mean loss: 4095.8999733349956
INFO:root:eval perplexity: 5.239687442779541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 5125.110748074579
INFO:root:eval perplexity: 8.131360054016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [13:58:30<34:50, 261.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.8256766183035
INFO:root:current train perplexity3.5199592113494873
INFO:root:current mean train loss 3186.7663013599536
INFO:root:current train perplexity3.503652811050415
INFO:root:current mean train loss 3179.861954579455
INFO:root:current train perplexity3.5033531188964844
INFO:root:current mean train loss 3190.998178783815
INFO:root:current train perplexity3.5137977600097656
INFO:root:current mean train loss 3191.335339215158
INFO:root:current train perplexity3.514652729034424
INFO:root:current mean train loss 3188.8554792457653
INFO:root:current train perplexity3.5132133960723877
INFO:root:current mean train loss 3186.7177565206694
INFO:root:current train perplexity3.511061429977417
INFO:root:current mean train loss 3186.287357501594
INFO:root:current train perplexity3.5111610889434814
INFO:root:current mean train loss 3185.6657931207897
INFO:root:current train perplexity3.510082483291626
INFO:root:current mean train loss 3185.494570678058
INFO:root:current train perplexity3.5091190338134766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:49<00:00, 229.75s/it]
INFO:root:final mean train loss: 3182.2000624133693
INFO:root:final train perplexity: 3.5094876289367676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.45s/it]
INFO:root:eval mean loss: 4096.025472005208
INFO:root:eval perplexity: 5.239953517913818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.86s/it]
INFO:root:eval mean loss: 5124.727118309508
INFO:root:eval perplexity: 8.130085945129395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [14:02:53<30:32, 261.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3173.3646552507266
INFO:root:current train perplexity3.516075849533081
INFO:root:current mean train loss 3177.4273246284965
INFO:root:current train perplexity3.507066011428833
INFO:root:current mean train loss 3169.261757933063
INFO:root:current train perplexity3.5018961429595947
INFO:root:current mean train loss 3175.8375204992712
INFO:root:current train perplexity3.5021238327026367
INFO:root:current mean train loss 3181.685229437077
INFO:root:current train perplexity3.504795789718628
INFO:root:current mean train loss 3182.8235492741424
INFO:root:current train perplexity3.50510835647583
INFO:root:current mean train loss 3184.089342559292
INFO:root:current train perplexity3.5058400630950928
INFO:root:current mean train loss 3181.9905337183504
INFO:root:current train perplexity3.504824161529541
INFO:root:current mean train loss 3180.767708159568
INFO:root:current train perplexity3.5053110122680664
INFO:root:current mean train loss 3181.826363977167
INFO:root:current train perplexity3.506582736968994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.19s/it]
INFO:root:final mean train loss: 3180.378971715127
INFO:root:final train perplexity: 3.506967067718506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.15s/it]
INFO:root:eval mean loss: 4096.45371370789
INFO:root:eval perplexity: 5.240860462188721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.88s/it]
INFO:root:eval mean loss: 5126.044843957779
INFO:root:eval perplexity: 8.134468078613281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [14:07:14<26:09, 261.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3179.501900467218
INFO:root:current train perplexity3.5253567695617676
INFO:root:current mean train loss 3171.3304322097474
INFO:root:current train perplexity3.507566213607788
INFO:root:current mean train loss 3174.8992205008094
INFO:root:current train perplexity3.4992401599884033
INFO:root:current mean train loss 3182.575635600294
INFO:root:current train perplexity3.507946252822876
INFO:root:current mean train loss 3183.3147394895027
INFO:root:current train perplexity3.509479284286499
INFO:root:current mean train loss 3179.9938255905454
INFO:root:current train perplexity3.505018472671509
INFO:root:current mean train loss 3180.650459629416
INFO:root:current train perplexity3.50386643409729
INFO:root:current mean train loss 3181.3419145566327
INFO:root:current train perplexity3.503950357437134
INFO:root:current mean train loss 3179.9988005264945
INFO:root:current train perplexity3.5047528743743896
INFO:root:current mean train loss 3182.986762495071
INFO:root:current train perplexity3.507180690765381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.62s/it]
INFO:root:final mean train loss: 3180.380234502977
INFO:root:final train perplexity: 3.5069682598114014
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.13s/it]
INFO:root:eval mean loss: 4095.977358987145
INFO:root:eval perplexity: 5.239850997924805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.54s/it]
INFO:root:eval mean loss: 5125.069128158245
INFO:root:eval perplexity: 8.131221771240234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [14:11:35<21:47, 261.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.155790684587
INFO:root:current train perplexity3.5055603981018066
INFO:root:current mean train loss 3190.868449660967
INFO:root:current train perplexity3.5052649974823
INFO:root:current mean train loss 3196.22300125181
INFO:root:current train perplexity3.506357192993164
INFO:root:current mean train loss 3189.403383557843
INFO:root:current train perplexity3.5066287517547607
INFO:root:current mean train loss 3186.557761863426
INFO:root:current train perplexity3.5064122676849365
INFO:root:current mean train loss 3185.4483076992956
INFO:root:current train perplexity3.507063150405884
INFO:root:current mean train loss 3184.7205141846075
INFO:root:current train perplexity3.5086848735809326
INFO:root:current mean train loss 3182.1514955302
INFO:root:current train perplexity3.508129835128784
INFO:root:current mean train loss 3183.7840156954853
INFO:root:current train perplexity3.5068705081939697
INFO:root:current mean train loss 3181.554641166743
INFO:root:current train perplexity3.5061285495758057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.54s/it]
INFO:root:final mean train loss: 3179.943118003107
INFO:root:final train perplexity: 3.506364107131958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 4096.310371994126
INFO:root:eval perplexity: 5.2405571937561035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.58s/it]
INFO:root:eval mean loss: 5125.689624542885
INFO:root:eval perplexity: 8.133285522460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [14:15:55<17:24, 261.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.151713357043
INFO:root:current train perplexity3.508115530014038
INFO:root:current mean train loss 3181.604926377713
INFO:root:current train perplexity3.5129942893981934
INFO:root:current mean train loss 3181.452976869733
INFO:root:current train perplexity3.511146306991577
INFO:root:current mean train loss 3188.835037439331
INFO:root:current train perplexity3.5120794773101807
INFO:root:current mean train loss 3184.07214486165
INFO:root:current train perplexity3.5090208053588867
INFO:root:current mean train loss 3182.8345626481205
INFO:root:current train perplexity3.5092837810516357
INFO:root:current mean train loss 3182.8072478653253
INFO:root:current train perplexity3.5085480213165283
INFO:root:current mean train loss 3181.3540860291723
INFO:root:current train perplexity3.508063793182373
INFO:root:current mean train loss 3180.4985855612927
INFO:root:current train perplexity3.5069453716278076
INFO:root:current mean train loss 3181.386615236395
INFO:root:current train perplexity3.5067403316497803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:50<00:00, 230.19s/it]
INFO:root:final mean train loss: 3178.9031092120754
INFO:root:final train perplexity: 3.5049257278442383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.34s/it]
INFO:root:eval mean loss: 4096.598452737146
INFO:root:eval perplexity: 5.241166591644287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.09s/it]
INFO:root:eval mean loss: 5126.101768547762
INFO:root:eval perplexity: 8.134655952453613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [14:20:19<13:05, 261.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.775673828125
INFO:root:current train perplexity3.505831241607666
INFO:root:current mean train loss 3173.641898716518
INFO:root:current train perplexity3.501335620880127
INFO:root:current mean train loss 3180.8720365767044
INFO:root:current train perplexity3.509290933609009
INFO:root:current mean train loss 3183.3312415364585
INFO:root:current train perplexity3.5079755783081055
INFO:root:current mean train loss 3183.666173930921
INFO:root:current train perplexity3.51161527633667
INFO:root:current mean train loss 3182.6325275985055
INFO:root:current train perplexity3.509539842605591
INFO:root:current mean train loss 3181.4610771122684
INFO:root:current train perplexity3.5071141719818115
INFO:root:current mean train loss 3182.8261961315525
INFO:root:current train perplexity3.5054197311401367
INFO:root:current mean train loss 3181.299736049107
INFO:root:current train perplexity3.5041375160217285
INFO:root:current mean train loss 3181.1148580228364
INFO:root:current train perplexity3.505073308944702

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.57s/it]
INFO:root:final mean train loss: 3179.034179502918
INFO:root:final train perplexity: 3.5051066875457764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.99s/it]
INFO:root:eval mean loss: 4096.494850537456
INFO:root:eval perplexity: 5.240947246551514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it]
INFO:root:eval mean loss: 5125.825958901263
INFO:root:eval perplexity: 8.13373851776123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [14:24:39<08:42, 261.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3180.0552816735694
INFO:root:current train perplexity3.4812135696411133
INFO:root:current mean train loss 3185.303424105618
INFO:root:current train perplexity3.4980785846710205
INFO:root:current mean train loss 3178.515955409397
INFO:root:current train perplexity3.499980926513672
INFO:root:current mean train loss 3179.2221137861047
INFO:root:current train perplexity3.5034432411193848
INFO:root:current mean train loss 3180.9557756696427
INFO:root:current train perplexity3.5034170150756836
INFO:root:current mean train loss 3176.742239426994
INFO:root:current train perplexity3.501786470413208
INFO:root:current mean train loss 3179.776927674323
INFO:root:current train perplexity3.5030994415283203
INFO:root:current mean train loss 3179.041043375339
INFO:root:current train perplexity3.50089693069458
INFO:root:current mean train loss 3177.45252888767
INFO:root:current train perplexity3.5008890628814697
INFO:root:current mean train loss 3180.3768840801436
INFO:root:current train perplexity3.5032339096069336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:47<00:00, 227.09s/it]
INFO:root:final mean train loss: 3177.615167125579
INFO:root:final train perplexity: 3.5031449794769287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.11s/it]
INFO:root:eval mean loss: 4096.5197199828235
INFO:root:eval perplexity: 5.240999698638916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]
INFO:root:eval mean loss: 5125.922915627771
INFO:root:eval perplexity: 8.134060859680176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [14:29:00<04:21, 261.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3176.1631932520604
INFO:root:current train perplexity3.5153801441192627
INFO:root:current mean train loss 3197.50226373323
INFO:root:current train perplexity3.5217947959899902
INFO:root:current mean train loss 3183.984867476106
INFO:root:current train perplexity3.5093274116516113
INFO:root:current mean train loss 3181.25656494765
INFO:root:current train perplexity3.5048234462738037
INFO:root:current mean train loss 3178.869723380219
INFO:root:current train perplexity3.505455255508423
INFO:root:current mean train loss 3178.340687708201
INFO:root:current train perplexity3.5061113834381104
INFO:root:current mean train loss 3174.846246523381
INFO:root:current train perplexity3.5043742656707764
INFO:root:current mean train loss 3176.6311868506045
INFO:root:current train perplexity3.504626989364624
INFO:root:current mean train loss 3178.6131061592487
INFO:root:current train perplexity3.5038111209869385
INFO:root:current mean train loss 3180.5211416912366
INFO:root:current train perplexity3.503711700439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [03:48<00:00, 228.05s/it]
INFO:root:final mean train loss: 3177.988713479811
INFO:root:final train perplexity: 3.503661632537842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.03s/it]
INFO:root:eval mean loss: 4096.573146955341
INFO:root:eval perplexity: 5.241113185882568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it]
INFO:root:eval mean loss: 5125.903363599845
INFO:root:eval perplexity: 8.133996963500977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_final/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:33:20<00:00, 260.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [14:33:20<00:00, 262.00s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:20<00:00, 20.97s/it]
INFO:root:eval mean loss: 4096.573146955341
INFO:root:eval perplexity: 5.241113185882568
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it]
INFO:root:eval mean loss: 5125.903363599845
INFO:root:eval perplexity: 8.133996963500977
INFO:root:evalaution complete
INFO:root:save model final: small_multiqa_minilm_final/final
