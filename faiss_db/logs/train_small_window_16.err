INFO:root:Output: small_window_16
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97827.82078598485
INFO:root:current train perplexity15170.7392578125
INFO:root:current mean train loss 81423.63811243718
INFO:root:current train perplexity3044.948486328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.51s/it]
INFO:root:final mean train loss: 75054.54585118448
INFO:root:final train perplexity: 1640.56787109375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.24s/it]
INFO:root:eval mean loss: 44180.67131696428
INFO:root:eval perplexity: 96.78667449951172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/1

  0%|          | 1/200 [05:28<18:10:56, 328.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42895.21622242647
INFO:root:current train perplexity69.46813201904297
INFO:root:current mean train loss 39104.20268522351
INFO:root:current train perplexity47.216156005859375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it]
INFO:root:final mean train loss: 36512.720183341735
INFO:root:final train perplexity: 36.64698028564453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.65s/it]
INFO:root:eval mean loss: 31759.526925223214
INFO:root:eval perplexity: 26.76177215576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/2

  1%|          | 2/200 [11:01<18:12:33, 331.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31228.807942708332
INFO:root:current train perplexity22.092321395874023
INFO:root:current mean train loss 29689.10480506675
INFO:root:current train perplexity18.650373458862305
INFO:root:current mean train loss 28785.897552339902
INFO:root:current train perplexity17.062414169311523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.61s/it]
INFO:root:final mean train loss: 28400.556703629034
INFO:root:final train perplexity: 16.464563369750977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it]
INFO:root:eval mean loss: 28525.134905133928
INFO:root:eval perplexity: 19.148574829101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/3

  2%|â–         | 3/200 [16:32<18:06:56, 331.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26363.959339488636
INFO:root:current train perplexity13.394020080566406
INFO:root:current mean train loss 25883.508316532258
INFO:root:current train perplexity12.814005851745605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.11s/it]
INFO:root:final mean train loss: 25518.83654391381
INFO:root:final train perplexity: 12.391115188598633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:eval mean loss: 27113.254371279763
INFO:root:eval perplexity: 16.545351028442383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/4

  2%|â–         | 4/200 [22:11<18:12:13, 334.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24889.93973214286
INFO:root:current train perplexity11.328702926635742
INFO:root:current mean train loss 24371.49229702103
INFO:root:current train perplexity11.010900497436523
INFO:root:current mean train loss 24088.05535741244
INFO:root:current train perplexity10.752025604248047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.96s/it]
INFO:root:final mean train loss: 23974.13820722026
INFO:root:final train perplexity: 10.640022277832031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 26302.154808407737
INFO:root:eval perplexity: 15.213141441345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/5

  2%|â–Ž         | 5/200 [27:49<18:10:46, 335.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23340.98622881356
INFO:root:current train perplexity9.989494323730469
INFO:root:current mean train loss 23108.888082252357
INFO:root:current train perplexity9.754647254943848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.98s/it]
INFO:root:final mean train loss: 22958.857807774697
INFO:root:final train perplexity: 9.626151084899902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.92s/it]
INFO:root:eval mean loss: 25742.881789434523
INFO:root:eval perplexity: 14.357573509216309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/6

  3%|â–Ž         | 6/200 [33:30<18:11:06, 337.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22336.533735795456
INFO:root:current train perplexity9.106181144714355
INFO:root:current mean train loss 22386.976650478602
INFO:root:current train perplexity9.090213775634766
INFO:root:current mean train loss 22263.80398400474
INFO:root:current train perplexity8.977461814880371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.19s/it]
INFO:root:final mean train loss: 22214.579266948083
INFO:root:final train perplexity: 8.944809913635254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.29s/it]
INFO:root:eval mean loss: 25302.057082403273
INFO:root:eval perplexity: 13.717245101928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/7

  4%|â–Ž         | 7/200 [39:24<18:22:22, 342.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21859.054718501986
INFO:root:current train perplexity8.622977256774902
INFO:root:current mean train loss 21764.291123466257
INFO:root:current train perplexity8.527356147766113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.74s/it]
INFO:root:final mean train loss: 21644.50257528982
INFO:root:final train perplexity: 8.455741882324219
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.74s/it]
INFO:root:eval mean loss: 25002.69275483631
INFO:root:eval perplexity: 13.298763275146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/8

  4%|â–         | 8/200 [45:03<18:13:18, 341.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21408.907942708334
INFO:root:current train perplexity8.18536376953125
INFO:root:current mean train loss 21324.825747282608
INFO:root:current train perplexity8.161797523498535
INFO:root:current mean train loss 21214.472165697673
INFO:root:current train perplexity8.091804504394531


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.59s/it]
INFO:root:final mean train loss: 21179.657801474295
INFO:root:final train perplexity: 8.07680892944336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.64s/it]
INFO:root:eval mean loss: 24710.469075520832
INFO:root:eval perplexity: 12.902578353881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/9

  4%|â–         | 9/200 [50:43<18:05:43, 341.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20952.486036613805
INFO:root:current train perplexity7.858829021453857
INFO:root:current mean train loss 20886.236597118263
INFO:root:current train perplexity7.8249921798706055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.64s/it]
INFO:root:final mean train loss: 20791.836256457915
INFO:root:final train perplexity: 7.773694038391113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.60s/it]
INFO:root:eval mean loss: 24493.534086681546
INFO:root:eval perplexity: 12.616119384765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/10

  5%|â–Œ         | 10/200 [56:36<18:11:12, 344.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20777.43359375
INFO:root:current train perplexity7.630221843719482
INFO:root:current mean train loss 20582.61254267332
INFO:root:current train perplexity7.567751407623291
INFO:root:current mean train loss 20496.876810430935
INFO:root:current train perplexity7.5388264656066895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.28s/it]
INFO:root:final mean train loss: 20469.34025327621
INFO:root:final train perplexity: 7.530314922332764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.77s/it]
INFO:root:eval mean loss: 24274.190336681546
INFO:root:eval perplexity: 12.3329439163208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/11

  6%|â–Œ         | 11/200 [1:02:25<18:09:51, 345.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20283.70392275528
INFO:root:current train perplexity7.345994472503662
INFO:root:current mean train loss 20227.241387975148
INFO:root:current train perplexity7.338315486907959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.69s/it]
INFO:root:final mean train loss: 20176.45414094002
INFO:root:final train perplexity: 7.315889835357666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:eval mean loss: 24106.73025948661
INFO:root:eval perplexity: 12.121038436889648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/12

  6%|â–Œ         | 12/200 [1:07:57<17:50:56, 341.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20051.086447010868
INFO:root:current train perplexity7.196717739105225
INFO:root:current mean train loss 19955.819169207316
INFO:root:current train perplexity7.16335391998291
INFO:root:current mean train loss 19927.604032371077
INFO:root:current train perplexity7.135242938995361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.92s/it]
INFO:root:final mean train loss: 19923.22937405494
INFO:root:final train perplexity: 7.135430812835693
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.44s/it]
INFO:root:eval mean loss: 23956.921037946428
INFO:root:eval perplexity: 11.934556007385254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/13

  6%|â–‹         | 13/200 [1:13:38<17:44:53, 341.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19806.95125
INFO:root:current train perplexity7.009648323059082
INFO:root:current mean train loss 19736.735
INFO:root:current train perplexity6.9958600997924805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.57s/it]
INFO:root:final mean train loss: 19702.113990045364
INFO:root:final train perplexity: 6.981497287750244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.86s/it]
INFO:root:eval mean loss: 23836.892136346727
INFO:root:eval perplexity: 11.78721809387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/14

  7%|â–‹         | 14/200 [1:19:08<17:27:54, 338.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19500.513599537036
INFO:root:current train perplexity6.871819019317627
INFO:root:current mean train loss 19467.41739972933
INFO:root:current train perplexity6.850691318511963
INFO:root:current mean train loss 19510.65098430617
INFO:root:current train perplexity6.843414306640625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.62s/it]
INFO:root:final mean train loss: 19488.674599924394
INFO:root:final train perplexity: 6.836059093475342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it]
INFO:root:eval mean loss: 23721.72388857887
INFO:root:eval perplexity: 11.647551536560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/15

  8%|â–Š         | 15/200 [1:24:40<17:16:26, 336.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19317.937030261077
INFO:root:current train perplexity6.729494094848633
INFO:root:current mean train loss 19319.799570094274
INFO:root:current train perplexity6.720712184906006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.12s/it]
INFO:root:final mean train loss: 19302.514325541833
INFO:root:final train perplexity: 6.711687088012695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it]
INFO:root:eval mean loss: 23615.163736979168
INFO:root:eval perplexity: 11.519804954528809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/16

  8%|â–Š         | 16/200 [1:30:10<17:05:46, 334.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19097.941280241936
INFO:root:current train perplexity6.640592098236084
INFO:root:current mean train loss 19139.087965171755
INFO:root:current train perplexity6.601207256317139
INFO:root:current mean train loss 19136.00944433171
INFO:root:current train perplexity6.598189353942871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.26s/it]
INFO:root:final mean train loss: 19133.409077305947
INFO:root:final train perplexity: 6.6006693840026855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:eval mean loss: 23501.435988653273
INFO:root:eval perplexity: 11.385005950927734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/17

  8%|â–Š         | 17/200 [1:36:16<17:29:02, 343.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18975.198371611445
INFO:root:current train perplexity6.496008396148682
INFO:root:current mean train loss 18986.060909750682
INFO:root:current train perplexity6.488701820373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.29s/it]
INFO:root:final mean train loss: 18968.557254914314
INFO:root:final train perplexity: 6.494210720062256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it]
INFO:root:eval mean loss: 23442.74402436756
INFO:root:eval perplexity: 11.316058158874512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/18

  9%|â–‰         | 18/200 [1:41:52<17:15:38, 341.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18895.973493303572
INFO:root:current train perplexity6.437996864318848
INFO:root:current mean train loss 18899.62282986111
INFO:root:current train perplexity6.432579040527344
INFO:root:current mean train loss 18825.64924368351
INFO:root:current train perplexity6.399217128753662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.05s/it]
INFO:root:final mean train loss: 18824.58327951739
INFO:root:final train perplexity: 6.402641773223877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 23360.90164620536
INFO:root:eval perplexity: 11.22061538696289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/19

 10%|â–‰         | 19/200 [1:47:27<17:04:46, 339.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18692.934154992818
INFO:root:current train perplexity6.305184841156006
INFO:root:current mean train loss 18726.084746824865
INFO:root:current train perplexity6.321172714233398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.07s/it]
INFO:root:final mean train loss: 18694.671721427672
INFO:root:final train perplexity: 6.321125030517578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it]
INFO:root:eval mean loss: 23263.23023623512
INFO:root:eval perplexity: 11.107763290405273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/20

 10%|â–ˆ         | 20/200 [1:52:58<16:50:34, 336.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18703.664212740383
INFO:root:current train perplexity6.260093688964844
INFO:root:current mean train loss 18594.691434352517
INFO:root:current train perplexity6.244783401489258
INFO:root:current mean train loss 18584.580707374476
INFO:root:current train perplexity6.242055416107178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.88s/it]
INFO:root:final mean train loss: 18562.98519011467
INFO:root:final train perplexity: 6.239554405212402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.44s/it]
INFO:root:eval mean loss: 23214.59788876488
INFO:root:eval perplexity: 11.051993370056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/21

 10%|â–ˆ         | 21/200 [1:58:39<16:49:20, 338.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18442.159898695056
INFO:root:current train perplexity6.1683759689331055
INFO:root:current mean train loss 18455.5867044339
INFO:root:current train perplexity6.15999174118042


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.46s/it]
INFO:root:final mean train loss: 18441.79578424269
INFO:root:final train perplexity: 6.1654157638549805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.90s/it]
INFO:root:eval mean loss: 23142.711123511905
INFO:root:eval perplexity: 10.970072746276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/22

 11%|â–ˆ         | 22/200 [2:04:12<16:38:25, 336.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18386.563499273256
INFO:root:current train perplexity6.123971462249756
INFO:root:current mean train loss 18356.26264750874
INFO:root:current train perplexity6.107132911682129
INFO:root:current mean train loss 18360.545267489713
INFO:root:current train perplexity6.104326248168945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it]
INFO:root:final mean train loss: 18337.88767168599
INFO:root:final train perplexity: 6.1025519371032715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.62s/it]
INFO:root:eval mean loss: 23112.426920572918
INFO:root:eval perplexity: 10.935741424560547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/23

 12%|â–ˆâ–        | 23/200 [2:09:44<16:29:13, 335.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18278.235587993422
INFO:root:current train perplexity6.036656856536865
INFO:root:current mean train loss 18244.931670673075
INFO:root:current train perplexity6.031864643096924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.54s/it]
INFO:root:final mean train loss: 18223.05303364415
INFO:root:final train perplexity: 6.0338215827941895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it]
INFO:root:eval mean loss: 23030.142903645832
INFO:root:eval perplexity: 10.843009948730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/24

 12%|â–ˆâ–        | 24/200 [2:15:14<16:18:45, 333.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18072.601146941488
INFO:root:current train perplexity5.9636335372924805
INFO:root:current mean train loss 18133.264442495747
INFO:root:current train perplexity5.980112075805664
INFO:root:current mean train loss 18141.04238360324
INFO:root:current train perplexity5.977984428405762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.46s/it]
INFO:root:final mean train loss: 18127.78699124244
INFO:root:final train perplexity: 5.977389812469482
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it]
INFO:root:eval mean loss: 23034.133277529763
INFO:root:eval perplexity: 10.847488403320312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/25

 12%|â–ˆâ–Ž        | 25/200 [2:20:57<16:21:37, 336.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18080.59315814394
INFO:root:current train perplexity5.9378557205200195
INFO:root:current mean train loss 18066.289268608667
INFO:root:current train perplexity5.923068523406982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.84s/it]
INFO:root:final mean train loss: 18035.360717773438
INFO:root:final train perplexity: 5.923145771026611
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it]
INFO:root:eval mean loss: 22961.92892020089
INFO:root:eval perplexity: 10.766732215881348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/26

 13%|â–ˆâ–Ž        | 26/200 [2:26:30<16:12:22, 335.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17956.313112745098
INFO:root:current train perplexity5.886993885040283
INFO:root:current mean train loss 17978.793175703642
INFO:root:current train perplexity5.882619857788086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it]
INFO:root:final mean train loss: 17947.67730516003
INFO:root:final train perplexity: 5.872142314910889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it]
INFO:root:eval mean loss: 22920.825148809523
INFO:root:eval perplexity: 10.72102165222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/27

 14%|â–ˆâ–Ž        | 27/200 [2:32:03<16:05:15, 334.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18031.650390625
INFO:root:current train perplexity5.8220295906066895
INFO:root:current mean train loss 17885.46984981796
INFO:root:current train perplexity5.8322954177856445
INFO:root:current mean train loss 17884.681034482757
INFO:root:current train perplexity5.82141637802124


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.09s/it]
INFO:root:final mean train loss: 17858.577530399445
INFO:root:final train perplexity: 5.820763111114502
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.56s/it]
INFO:root:eval mean loss: 22867.804129464286
INFO:root:eval perplexity: 10.662351608276367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/28

 14%|â–ˆâ–        | 28/200 [2:37:35<15:57:04, 333.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17854.029154829546
INFO:root:current train perplexity5.802051067352295
INFO:root:current mean train loss 17822.214755544355
INFO:root:current train perplexity5.7858076095581055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.28s/it]
INFO:root:final mean train loss: 17784.169193390877
INFO:root:final train perplexity: 5.778200626373291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.41s/it]
INFO:root:eval mean loss: 22842.669828869046
INFO:root:eval perplexity: 10.634653091430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/29

 14%|â–ˆâ–        | 29/200 [2:43:19<15:59:59, 336.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17816.946149553572
INFO:root:current train perplexity5.7383713722229
INFO:root:current mean train loss 17810.655519859814
INFO:root:current train perplexity5.740549087524414
INFO:root:current mean train loss 17747.74982072766
INFO:root:current train perplexity5.733203411102295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it]
INFO:root:final mean train loss: 17701.356783959174
INFO:root:final train perplexity: 5.731197834014893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.92s/it]
INFO:root:eval mean loss: 22798.38709077381
INFO:root:eval perplexity: 10.586027145385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/30

 15%|â–ˆâ–Œ        | 30/200 [2:48:52<15:50:50, 335.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17648.922470868645
INFO:root:current train perplexity5.693313121795654
INFO:root:current mean train loss 17645.36882124607
INFO:root:current train perplexity5.691089153289795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it]
INFO:root:final mean train loss: 17626.962784305695
INFO:root:final train perplexity: 5.689297676086426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.79s/it]
INFO:root:eval mean loss: 22770.467308407737
INFO:root:eval perplexity: 10.555479049682617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/31

 16%|â–ˆâ–Œ        | 31/200 [2:54:23<15:42:06, 334.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17492.577414772728
INFO:root:current train perplexity5.623294830322266
INFO:root:current mean train loss 17569.49389428491
INFO:root:current train perplexity5.636772155761719
INFO:root:current mean train loss 17569.20591121149
INFO:root:current train perplexity5.652557373046875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.41s/it]
INFO:root:final mean train loss: 17555.46417433216
INFO:root:final train perplexity: 5.649316787719727
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22753.90701729911
INFO:root:eval perplexity: 10.537405967712402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/32

 16%|â–ˆâ–Œ        | 32/200 [2:59:55<15:34:13, 333.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17496.37072172619
INFO:root:current train perplexity5.598435878753662
INFO:root:current mean train loss 17510.229594037577
INFO:root:current train perplexity5.61496114730835


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.05s/it]
INFO:root:final mean train loss: 17488.97314453125
INFO:root:final train perplexity: 5.61238956451416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it]
INFO:root:eval mean loss: 22735.726515997023
INFO:root:eval perplexity: 10.517597198486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/33

 16%|â–ˆâ–‹        | 33/200 [3:05:28<15:28:22, 333.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17263.163932291667
INFO:root:current train perplexity5.525483131408691
INFO:root:current mean train loss 17416.16875
INFO:root:current train perplexity5.572350025177002
INFO:root:current mean train loss 17399.96354469477
INFO:root:current train perplexity5.561058521270752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it]
INFO:root:final mean train loss: 17416.073179183466
INFO:root:final train perplexity: 5.572178840637207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.80s/it]
INFO:root:eval mean loss: 22675.072777157737
INFO:root:eval perplexity: 10.45177936553955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/34

 17%|â–ˆâ–‹        | 34/200 [3:11:00<15:21:11, 332.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17353.373236357274
INFO:root:current train perplexity5.536098003387451
INFO:root:current mean train loss 17372.600796453968
INFO:root:current train perplexity5.537207126617432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.40s/it]
INFO:root:final mean train loss: 17356.136380103326
INFO:root:final train perplexity: 5.53933572769165
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it]
INFO:root:eval mean loss: 22659.718447730655
INFO:root:eval perplexity: 10.43518352508545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/35

 18%|â–ˆâ–Š        | 35/200 [3:16:30<15:13:20, 332.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17502.263157894737
INFO:root:current train perplexity5.569812774658203
INFO:root:current mean train loss 17346.05275899422
INFO:root:current train perplexity5.522015571594238
INFO:root:current mean train loss 17319.177350884704
INFO:root:current train perplexity5.508930206298828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.92s/it]
INFO:root:final mean train loss: 17301.341686617943
INFO:root:final train perplexity: 5.5094780921936035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it]
INFO:root:eval mean loss: 22662.663550967263
INFO:root:eval perplexity: 10.438365936279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/36

 18%|â–ˆâ–Š        | 36/200 [3:21:59<15:04:42, 330.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17207.31973481514
INFO:root:current train perplexity5.45774507522583
INFO:root:current mean train loss 17231.395759091738
INFO:root:current train perplexity5.474740028381348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.42s/it]
INFO:root:final mean train loss: 17237.869853358116
INFO:root:final train perplexity: 5.475094318389893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:eval mean loss: 22617.47435360863
INFO:root:eval perplexity: 10.38965892791748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/37

 18%|â–ˆâ–Š        | 37/200 [3:27:28<14:58:14, 330.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17126.656504755436
INFO:root:current train perplexity5.416718482971191
INFO:root:current mean train loss 17130.98194550305
INFO:root:current train perplexity5.433891773223877
INFO:root:current mean train loss 17196.306342839125
INFO:root:current train perplexity5.445715427398682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.49s/it]
INFO:root:final mean train loss: 17180.668878370714
INFO:root:final train perplexity: 5.444291114807129
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.56s/it]
INFO:root:eval mean loss: 22603.737769717263
INFO:root:eval perplexity: 10.374898910522461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/38

 19%|â–ˆâ–‰        | 38/200 [3:33:23<15:11:45, 337.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17151.10825520833
INFO:root:current train perplexity5.410482406616211
INFO:root:current mean train loss 17134.66529575893
INFO:root:current train perplexity5.412015914916992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.45s/it]
INFO:root:final mean train loss: 17130.83027107485
INFO:root:final train perplexity: 5.4175944328308105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it]
INFO:root:eval mean loss: 22582.819893973214
INFO:root:eval perplexity: 10.352462768554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/39

 20%|â–ˆâ–‰        | 39/200 [3:39:03<15:08:15, 338.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16995.13111255787
INFO:root:current train perplexity5.350783348083496
INFO:root:current mean train loss 17084.19125246063
INFO:root:current train perplexity5.389955520629883
INFO:root:current mean train loss 17086.70918226872
INFO:root:current train perplexity5.387762069702148


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.78s/it]
INFO:root:final mean train loss: 17077.43527517011
INFO:root:final train perplexity: 5.389139175415039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it]
INFO:root:eval mean loss: 22567.162016369046
INFO:root:eval perplexity: 10.335702896118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/40

 20%|â–ˆâ–ˆ        | 40/200 [3:44:42<15:03:32, 338.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17069.674137163765
INFO:root:current train perplexity5.371291160583496
INFO:root:current mean train loss 17079.44322298359
INFO:root:current train perplexity5.374985694885254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.04s/it]
INFO:root:final mean train loss: 17024.480831023186
INFO:root:final train perplexity: 5.361064434051514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.77s/it]
INFO:root:eval mean loss: 22555.504906063987
INFO:root:eval perplexity: 10.32323932647705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/41

 20%|â–ˆâ–ˆ        | 41/200 [3:50:27<15:02:47, 340.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16900.417023689515
INFO:root:current train perplexity5.304441928863525
INFO:root:current mean train loss 16952.471769143605
INFO:root:current train perplexity5.3197021484375
INFO:root:current mean train loss 16995.762906689666
INFO:root:current train perplexity5.335063934326172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.34s/it]
INFO:root:final mean train loss: 16976.165381646926
INFO:root:final train perplexity: 5.335577487945557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.55s/it]
INFO:root:eval mean loss: 22519.26146298363
INFO:root:eval perplexity: 10.284588813781738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/42

 21%|â–ˆâ–ˆ        | 42/200 [3:56:21<15:07:32, 344.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16920.40234375
INFO:root:current train perplexity5.308553695678711
INFO:root:current mean train loss 16951.942115992144
INFO:root:current train perplexity5.311298370361328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.84s/it]
INFO:root:final mean train loss: 16927.255871188256
INFO:root:final train perplexity: 5.309900283813477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.40s/it]
INFO:root:eval mean loss: 22549.206612723214
INFO:root:eval perplexity: 10.316512107849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/43

 22%|â–ˆâ–ˆâ–       | 43/200 [4:02:16<15:09:32, 347.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17007.093582589285
INFO:root:current train perplexity5.320047378540039
INFO:root:current mean train loss 16923.865212673612
INFO:root:current train perplexity5.286117076873779
INFO:root:current mean train loss 16896.37674119016
INFO:root:current train perplexity5.286462783813477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.50s/it]
INFO:root:final mean train loss: 16881.471616683466
INFO:root:final train perplexity: 5.285975933074951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it]
INFO:root:eval mean loss: 22520.888671875
INFO:root:eval perplexity: 10.286322593688965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:07:55<14:56:50, 344.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16824.375628591955
INFO:root:current train perplexity5.250104904174805
INFO:root:current mean train loss 16845.144797585228
INFO:root:current train perplexity5.257717609405518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.17s/it]
INFO:root:final mean train loss: 16835.984599451866
INFO:root:final train perplexity: 5.262313365936279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.89s/it]
INFO:root:eval mean loss: 22499.15555245536
INFO:root:eval perplexity: 10.263209342956543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:13:40<14:51:10, 344.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16829.15740184295
INFO:root:current train perplexity5.250513553619385
INFO:root:current mean train loss 16793.852862241456
INFO:root:current train perplexity5.238992214202881
INFO:root:current mean train loss 16807.999930537397
INFO:root:current train perplexity5.240469932556152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.09s/it]
INFO:root:final mean train loss: 16792.25520964592
INFO:root:final train perplexity: 5.239665508270264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.86s/it]
INFO:root:eval mean loss: 22494.036458333332
INFO:root:eval perplexity: 10.257773399353027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:19:17<14:39:18, 342.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16788.999495621567
INFO:root:current train perplexity5.215146541595459
INFO:root:current mean train loss 16782.163290453205
INFO:root:current train perplexity5.222410202026367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.56s/it]
INFO:root:final mean train loss: 16750.036124936996
INFO:root:final train perplexity: 5.217891693115234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22483.121256510418
INFO:root:eval perplexity: 10.246190071105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:24:45<14:22:25, 338.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16718.05843477471
INFO:root:current train perplexity5.1969194412231445
INFO:root:current mean train loss 16723.0059413243
INFO:root:current train perplexity5.196400165557861
INFO:root:current mean train loss 16717.024815940073
INFO:root:current train perplexity5.195859432220459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.28s/it]
INFO:root:final mean train loss: 16706.432215536795
INFO:root:final train perplexity: 5.195498943328857
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 54.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 54.00s/it]
INFO:root:eval mean loss: 22472.076683407737
INFO:root:eval perplexity: 10.234485626220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:30:39<14:28:59, 343.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16652.955592105263
INFO:root:current train perplexity5.160037517547607
INFO:root:current mean train loss 16668.75625
INFO:root:current train perplexity5.167778015136719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.03s/it]
INFO:root:final mean train loss: 16670.5627953314
INFO:root:final train perplexity: 5.177151203155518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it]
INFO:root:eval mean loss: 22451.446196056546
INFO:root:eval perplexity: 10.212657928466797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:36:11<14:15:02, 339.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16649.117769281915
INFO:root:current train perplexity5.131990909576416
INFO:root:current mean train loss 16635.97389190051
INFO:root:current train perplexity5.1523895263671875
INFO:root:current mean train loss 16639.48548598811
INFO:root:current train perplexity5.155492782592773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.56s/it]
INFO:root:final mean train loss: 16628.78060420867
INFO:root:final train perplexity: 5.155859470367432
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it]
INFO:root:eval mean loss: 22449.64134579613
INFO:root:eval perplexity: 10.2107515335083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:41:42<14:02:35, 337.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16604.618805239897
INFO:root:current train perplexity5.122655868530273
INFO:root:current mean train loss 16581.973662256594
INFO:root:current train perplexity5.135912895202637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.83s/it]
INFO:root:final mean train loss: 16594.86857752646
INFO:root:final train perplexity: 5.138641834259033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.94s/it]
INFO:root:eval mean loss: 22434.421409970237
INFO:root:eval perplexity: 10.194680213928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:47:30<14:05:25, 340.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16567.082816329657
INFO:root:current train perplexity5.114001274108887
INFO:root:current mean train loss 16578.73004190811
INFO:root:current train perplexity5.118655204772949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.68s/it]
INFO:root:final mean train loss: 16556.752992691534
INFO:root:final train perplexity: 5.11936092376709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.83s/it]
INFO:root:eval mean loss: 22431.32152157738
INFO:root:eval perplexity: 10.19140911102295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:53:05<13:55:30, 338.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16637.907877604168
INFO:root:current train perplexity5.224867343902588
INFO:root:current mean train loss 16484.51004057949
INFO:root:current train perplexity5.0820183753967285
INFO:root:current mean train loss 16525.699117726293
INFO:root:current train perplexity5.09803581237793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.70s/it]
INFO:root:final mean train loss: 16520.37653966104
INFO:root:final train perplexity: 5.1010260581970215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it]
INFO:root:eval mean loss: 22420.12820870536
INFO:root:eval perplexity: 10.179612159729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:58:37<13:45:05, 336.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16472.542151988637
INFO:root:current train perplexity5.088004112243652
INFO:root:current mean train loss 16528.420381804437
INFO:root:current train perplexity5.097014427185059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.02s/it]
INFO:root:final mean train loss: 16485.088701801917
INFO:root:final train perplexity: 5.0833024978637695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it]
INFO:root:eval mean loss: 22393.281691778273
INFO:root:eval perplexity: 10.15136432647705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:04:08<13:35:17, 335.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16354.1396484375
INFO:root:current train perplexity5.082241058349609
INFO:root:current mean train loss 16447.360022999415
INFO:root:current train perplexity5.067391872406006
INFO:root:current mean train loss 16450.292671535328
INFO:root:current train perplexity5.06874418258667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.90s/it]
INFO:root:final mean train loss: 16449.66947297127
INFO:root:final train perplexity: 5.065575122833252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it]
INFO:root:eval mean loss: 22402.33386811756
INFO:root:eval perplexity: 10.16087818145752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:09:36<13:24:31, 332.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16438.133755958686
INFO:root:current train perplexity5.039006233215332
INFO:root:current mean train loss 16393.941387824292
INFO:root:current train perplexity5.040128707885742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it]
INFO:root:final mean train loss: 16415.484154485886
INFO:root:final train perplexity: 5.048523426055908
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.97s/it]
INFO:root:eval mean loss: 22403.69494047619
INFO:root:eval perplexity: 10.162309646606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:15:11<13:20:43, 333.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16509.779651988636
INFO:root:current train perplexity5.065791130065918
INFO:root:current mean train loss 16370.562904701577
INFO:root:current train perplexity5.024710655212402
INFO:root:current mean train loss 16405.3512292654
INFO:root:current train perplexity5.033279895782471


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.82s/it]
INFO:root:final mean train loss: 16377.00687531502
INFO:root:final train perplexity: 5.029400825500488
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it]
INFO:root:eval mean loss: 22396.803571428572
INFO:root:eval perplexity: 10.155065536499023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:20:41<13:12:29, 332.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16312.175223214286
INFO:root:current train perplexity4.987400054931641
INFO:root:current mean train loss 16343.532759777607
INFO:root:current train perplexity5.008859157562256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.10s/it]
INFO:root:final mean train loss: 16343.69708842616
INFO:root:final train perplexity: 5.012903690338135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it]
INFO:root:eval mean loss: 22390.184430803572
INFO:root:eval perplexity: 10.148112297058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:26:33<13:20:26, 338.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16308.806705729166
INFO:root:current train perplexity5.002037048339844
INFO:root:current mean train loss 16262.912831182066
INFO:root:current train perplexity4.974094390869141
INFO:root:current mean train loss 16296.709034338663
INFO:root:current train perplexity4.991413593292236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.90s/it]
INFO:root:final mean train loss: 16312.243833480343
INFO:root:final train perplexity: 4.997376441955566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22368.151181175595
INFO:root:eval perplexity: 10.124996185302734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:32:07<13:11:57, 337.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16284.410068796642
INFO:root:current train perplexity4.962765216827393
INFO:root:current mean train loss 16285.48990105726
INFO:root:current train perplexity4.9829559326171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.37s/it]
INFO:root:final mean train loss: 16281.939736643146
INFO:root:final train perplexity: 4.982461452484131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it]
INFO:root:eval mean loss: 22377.339425223214
INFO:root:eval perplexity: 10.13463020324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:37:46<13:07:32, 337.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16244.612510279605
INFO:root:current train perplexity4.972416400909424
INFO:root:current mean train loss 16230.565946691177
INFO:root:current train perplexity4.963287353515625
INFO:root:current mean train loss 16250.984419591896
INFO:root:current train perplexity4.96452522277832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.03s/it]
INFO:root:final mean train loss: 16250.995034494708
INFO:root:final train perplexity: 4.967277526855469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it]
INFO:root:eval mean loss: 22357.777483258928
INFO:root:eval perplexity: 10.114131927490234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:43:18<12:58:24, 336.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16251.166125660211
INFO:root:current train perplexity4.957250595092773
INFO:root:current mean train loss 16253.48711622807
INFO:root:current train perplexity4.957335948944092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.49s/it]
INFO:root:final mean train loss: 16224.567430065525
INFO:root:final train perplexity: 4.954346656799316
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it]
INFO:root:eval mean loss: 22369.19945126488
INFO:root:eval perplexity: 10.126093864440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:48:54<12:52:50, 336.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16119.784943953804
INFO:root:current train perplexity4.906569480895996
INFO:root:current mean train loss 16205.54573964685
INFO:root:current train perplexity4.931487083435059
INFO:root:current mean train loss 16209.836375420404
INFO:root:current train perplexity4.94169282913208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.97s/it]
INFO:root:final mean train loss: 16195.563232421875
INFO:root:final train perplexity: 4.940194129943848
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it]
INFO:root:eval mean loss: 22358.38548642113
INFO:root:eval perplexity: 10.114770889282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:54:22<12:41:28, 333.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16155.494140625
INFO:root:current train perplexity4.927499294281006
INFO:root:current mean train loss 16192.442393973215
INFO:root:current train perplexity4.9244489669799805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.06s/it]
INFO:root:final mean train loss: 16167.724573935231
INFO:root:final train perplexity: 4.926648139953613
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it]
INFO:root:eval mean loss: 22348.313313802082
INFO:root:eval perplexity: 10.104228019714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:00:06<12:43:22, 336.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16251.515335648148
INFO:root:current train perplexity4.9262166023254395
INFO:root:current mean train loss 16127.228577140748
INFO:root:current train perplexity4.903861999511719
INFO:root:current mean train loss 16150.141790852147
INFO:root:current train perplexity4.91310453414917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.88s/it]
INFO:root:final mean train loss: 16142.681802072833
INFO:root:final train perplexity: 4.914494037628174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:eval mean loss: 22361.84256417411
INFO:root:eval perplexity: 10.118386268615723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:05:55<12:45:34, 340.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16133.565553303006
INFO:root:current train perplexity4.895834922790527
INFO:root:current mean train loss 16125.891121464734
INFO:root:current train perplexity4.898684501647949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.83s/it]
INFO:root:final mean train loss: 16113.186495873237
INFO:root:final train perplexity: 4.900217056274414
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22352.195172991072
INFO:root:eval perplexity: 10.108287811279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:11:34<12:39:01, 339.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16039.978736139114
INFO:root:current train perplexity4.856380462646484
INFO:root:current mean train loss 16096.69576723521
INFO:root:current train perplexity4.879439353942871
INFO:root:current mean train loss 16090.814546130952
INFO:root:current train perplexity4.88388204574585


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.58s/it]
INFO:root:final mean train loss: 16081.289054624496
INFO:root:final train perplexity: 4.884824275970459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:eval mean loss: 22347.981863839286
INFO:root:eval perplexity: 10.103883743286133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:17:18<12:36:32, 341.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16071.385483339609
INFO:root:current train perplexity4.870406627655029
INFO:root:current mean train loss 16076.445253799522
INFO:root:current train perplexity4.871011257171631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.92s/it]
INFO:root:final mean train loss: 16060.27209078881
INFO:root:final train perplexity: 4.874709129333496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22343.508138020832
INFO:root:eval perplexity: 10.09920597076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:22:53<12:26:42, 339.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16120.789313616071
INFO:root:current train perplexity4.8832831382751465
INFO:root:current mean train loss 16047.91794704861
INFO:root:current train perplexity4.857338905334473
INFO:root:current mean train loss 16047.278960272606
INFO:root:current train perplexity4.859755516052246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it]
INFO:root:final mean train loss: 16031.011143838206
INFO:root:final train perplexity: 4.860661029815674
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it]
INFO:root:eval mean loss: 22340.437848772322
INFO:root:eval perplexity: 10.09599494934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:28:39<12:25:20, 341.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16007.442584859913
INFO:root:current train perplexity4.853612422943115
INFO:root:current mean train loss 15990.398082386364
INFO:root:current train perplexity4.847351551055908


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.53s/it]
INFO:root:final mean train loss: 16012.477550875756
INFO:root:final train perplexity: 4.851783275604248
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it]
INFO:root:eval mean loss: 22353.95972842262
INFO:root:eval perplexity: 10.11013412475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:34:15<12:15:49, 339.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15895.63714443109
INFO:root:current train perplexity4.833512783050537
INFO:root:current mean train loss 15947.854386803057
INFO:root:current train perplexity4.823399543762207
INFO:root:current mean train loss 15990.013622842573
INFO:root:current train perplexity4.834750175476074


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.24s/it]
INFO:root:final mean train loss: 15983.490065051663
INFO:root:final train perplexity: 4.837932109832764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.45s/it]
INFO:root:eval mean loss: 22319.96749441964
INFO:root:eval perplexity: 10.074627876281738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:40:03<12:16:02, 342.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15931.254861349587
INFO:root:current train perplexity4.809002876281738
INFO:root:current mean train loss 15950.090032927028
INFO:root:current train perplexity4.818441390991211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.44s/it]
INFO:root:final mean train loss: 15957.851609753025
INFO:root:final train perplexity: 4.825713634490967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it]
INFO:root:eval mean loss: 22323.420014880954
INFO:root:eval perplexity: 10.078231811523438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:45:35<12:03:36, 339.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15944.651662427326
INFO:root:current train perplexity4.79464864730835
INFO:root:current mean train loss 15939.078855714597
INFO:root:current train perplexity4.810086727142334
INFO:root:current mean train loss 15950.371238425925
INFO:root:current train perplexity4.815601348876953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.28s/it]
INFO:root:final mean train loss: 15936.448076801915
INFO:root:final train perplexity: 4.815536975860596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.87s/it]
INFO:root:eval mean loss: 22325.11170014881
INFO:root:eval perplexity: 10.079996109008789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [6:51:16<11:59:04, 339.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15909.242793996711
INFO:root:current train perplexity4.799035549163818
INFO:root:current mean train loss 15918.749003405448
INFO:root:current train perplexity4.804380416870117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.45s/it]
INFO:root:final mean train loss: 15914.34486438382
INFO:root:final train perplexity: 4.805049419403076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.34s/it]
INFO:root:eval mean loss: 22326.839890252977
INFO:root:eval perplexity: 10.081798553466797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [6:56:51<11:50:05, 338.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15880.092066988032
INFO:root:current train perplexity4.777832508087158
INFO:root:current mean train loss 15877.547207164116
INFO:root:current train perplexity4.7762274742126465
INFO:root:current mean train loss 15900.992729156123
INFO:root:current train perplexity4.792362689971924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.62s/it]
INFO:root:final mean train loss: 15888.22670032132
INFO:root:final train perplexity: 4.79268741607666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.98s/it]
INFO:root:eval mean loss: 22331.84412202381
INFO:root:eval perplexity: 10.087020874023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:02:27<11:43:25, 337.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15866.336302477905
INFO:root:current train perplexity4.776057243347168
INFO:root:current mean train loss 15872.806390350188
INFO:root:current train perplexity4.779511451721191


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.31s/it]
INFO:root:final mean train loss: 15863.041688980595
INFO:root:final train perplexity: 4.780796527862549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.82s/it]
INFO:root:eval mean loss: 22326.388811383928
INFO:root:eval perplexity: 10.081327438354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:08:02<11:36:12, 336.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15834.847560508579
INFO:root:current train perplexity4.770392894744873
INFO:root:current mean train loss 15859.820377173013
INFO:root:current train perplexity4.77015495300293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.63s/it]
INFO:root:final mean train loss: 15840.263900264617
INFO:root:final train perplexity: 4.7700676918029785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it]
INFO:root:eval mean loss: 22324.393949962796
INFO:root:eval perplexity: 10.079248428344727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:13:43<11:32:45, 337.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15390.1845703125
INFO:root:current train perplexity4.622826099395752
INFO:root:current mean train loss 15829.989618097694
INFO:root:current train perplexity4.754537105560303
INFO:root:current mean train loss 15823.339944773707
INFO:root:current train perplexity4.757307052612305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.85s/it]
INFO:root:final mean train loss: 15821.672469600555
INFO:root:final train perplexity: 4.761329174041748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22319.554268973214
INFO:root:eval perplexity: 10.074200630187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:19:17<11:25:14, 337.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15771.65713778409
INFO:root:current train perplexity4.753606796264648
INFO:root:current mean train loss 15798.445942540322
INFO:root:current train perplexity4.750119686126709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.73s/it]
INFO:root:final mean train loss: 15802.051734185989
INFO:root:final train perplexity: 4.752124309539795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.89s/it]
INFO:root:eval mean loss: 22328.705961681546
INFO:root:eval perplexity: 10.083747863769531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:24:54<11:19:20, 336.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15712.357840401786
INFO:root:current train perplexity4.706334590911865
INFO:root:current mean train loss 15808.052907783294
INFO:root:current train perplexity4.742558002471924
INFO:root:current mean train loss 15808.10710107186
INFO:root:current train perplexity4.747217655181885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.86s/it]
INFO:root:final mean train loss: 15779.89898484753
INFO:root:final train perplexity: 4.741751670837402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.20s/it]
INFO:root:eval mean loss: 22313.741117931546
INFO:root:eval perplexity: 10.068138122558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:30:28<11:12:19, 336.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15707.91303628178
INFO:root:current train perplexity4.709092140197754
INFO:root:current mean train loss 15744.581668877752
INFO:root:current train perplexity4.721529960632324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.13s/it]
INFO:root:final mean train loss: 15755.894251669606
INFO:root:final train perplexity: 4.730538368225098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it]
INFO:root:eval mean loss: 22321.497140066964
INFO:root:eval perplexity: 10.076225280761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:36:08<11:08:49, 337.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15841.590997869318
INFO:root:current train perplexity4.800675868988037
INFO:root:current mean train loss 15758.849310247748
INFO:root:current train perplexity4.716516971588135
INFO:root:current mean train loss 15761.655986189277
INFO:root:current train perplexity4.719477653503418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it]
INFO:root:final mean train loss: 15732.516786636845
INFO:root:final train perplexity: 4.719644069671631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it]
INFO:root:eval mean loss: 22320.41920107887
INFO:root:eval perplexity: 10.075101852416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:41:42<11:01:25, 336.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15712.944816468254
INFO:root:current train perplexity4.710088729858398
INFO:root:current mean train loss 15713.242816574004
INFO:root:current train perplexity4.715534687042236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it]
INFO:root:final mean train loss: 15716.371609595513
INFO:root:final train perplexity: 4.712133884429932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.57s/it]
INFO:root:eval mean loss: 22314.39718191964
INFO:root:eval perplexity: 10.068826675415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [7:47:18<10:55:31, 336.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15713.1244140625
INFO:root:current train perplexity4.678290843963623
INFO:root:current mean train loss 15681.625127377718
INFO:root:current train perplexity4.698346138000488
INFO:root:current mean train loss 15706.642718931686
INFO:root:current train perplexity4.702727794647217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it]
INFO:root:final mean train loss: 15692.944788778981
INFO:root:final train perplexity: 4.701258659362793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it]
INFO:root:eval mean loss: 22326.07784598214
INFO:root:eval perplexity: 10.081005096435547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [7:52:51<10:48:01, 335.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15638.09813724347
INFO:root:current train perplexity4.68250036239624
INFO:root:current mean train loss 15684.754958832335
INFO:root:current train perplexity4.692696571350098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.37s/it]
INFO:root:final mean train loss: 15680.879989131805
INFO:root:final train perplexity: 4.695667743682861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.77s/it]
INFO:root:eval mean loss: 22319.031063988095
INFO:root:eval perplexity: 10.073653221130371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [7:58:19<10:38:14, 333.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15454.446905838815
INFO:root:current train perplexity4.678530693054199
INFO:root:current mean train loss 15670.99040670956
INFO:root:current train perplexity4.6805338859558105
INFO:root:current mean train loss 15665.57660887557
INFO:root:current train perplexity4.681581020355225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.57s/it]
INFO:root:final mean train loss: 15652.595990580898
INFO:root:final train perplexity: 4.682585716247559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 22324.134719122023
INFO:root:eval perplexity: 10.07897663116455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:03:47<10:30:00, 331.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15585.939439370599
INFO:root:current train perplexity4.676124095916748
INFO:root:current mean train loss 15633.493278280337
INFO:root:current train perplexity4.673165321350098


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.36s/it]
INFO:root:final mean train loss: 15639.587567729335
INFO:root:final train perplexity: 4.676581859588623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.24s/it]
INFO:root:eval mean loss: 22322.97667875744
INFO:root:eval perplexity: 10.077770233154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:09:15<10:22:11, 330.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15659.239852241848
INFO:root:current train perplexity4.661850452423096
INFO:root:current mean train loss 15626.966876270326
INFO:root:current train perplexity4.6653032302856445
INFO:root:current mean train loss 15631.29553934277
INFO:root:current train perplexity4.667654514312744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.46s/it]
INFO:root:final mean train loss: 15620.73699360509
INFO:root:final train perplexity: 4.66789436340332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.28s/it]
INFO:root:eval mean loss: 22332.705008370536
INFO:root:eval perplexity: 10.087920188903809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:14:45<10:16:47, 330.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15604.324830729167
INFO:root:current train perplexity4.647505283355713
INFO:root:current mean train loss 15596.684425223215
INFO:root:current train perplexity4.654581546783447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.46s/it]
INFO:root:final mean train loss: 15600.977511498237
INFO:root:final train perplexity: 4.658806324005127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it]
INFO:root:eval mean loss: 22308.212379092263
INFO:root:eval perplexity: 10.06238079071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:20:11<10:08:54, 329.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15564.195240162036
INFO:root:current train perplexity4.644413948059082
INFO:root:current mean train loss 15540.982760211615
INFO:root:current train perplexity4.632000923156738
INFO:root:current mean train loss 15581.510174318557
INFO:root:current train perplexity4.646186828613281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.34s/it]
INFO:root:final mean train loss: 15582.848963583669
INFO:root:final train perplexity: 4.650484085083008
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it]
INFO:root:eval mean loss: 22318.355794270832
INFO:root:eval perplexity: 10.072949409484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:25:41<10:03:30, 329.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15628.466735067246
INFO:root:current train perplexity4.647060871124268
INFO:root:current mean train loss 15570.463692606494
INFO:root:current train perplexity4.6415205001831055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.03s/it]
INFO:root:final mean train loss: 15568.870818107358
INFO:root:final train perplexity: 4.644076347351074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.99s/it]
INFO:root:eval mean loss: 22301.285667782737
INFO:root:eval perplexity: 10.055169105529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/91
#################best###############
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:31:16<10:01:07, 330.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15561.138451360886
INFO:root:current train perplexity4.6404876708984375
INFO:root:current mean train loss 15548.546584267653
INFO:root:current train perplexity4.638311386108398
INFO:root:current mean train loss 15559.924610220509
INFO:root:current train perplexity4.636685371398926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.71s/it]
INFO:root:final mean train loss: 15550.723565870716
INFO:root:final train perplexity: 4.63577127456665
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it]
INFO:root:eval mean loss: 22325.028715587796
INFO:root:eval perplexity: 10.079909324645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:36:43<9:53:52, 329.93s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15567.239187217621
INFO:root:current train perplexity4.636333465576172
INFO:root:current mean train loss 15543.858884050547
INFO:root:current train perplexity4.627191066741943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.64s/it]
INFO:root:final mean train loss: 15533.967934885333
INFO:root:final train perplexity: 4.628115653991699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.52s/it]
INFO:root:eval mean loss: 22321.381533668155
INFO:root:eval perplexity: 10.076105117797852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:42:29<9:56:58, 334.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15510.200697544642
INFO:root:current train perplexity4.5924248695373535
INFO:root:current mean train loss 15497.551859085648
INFO:root:current train perplexity4.611990451812744
INFO:root:current mean train loss 15522.317698636967
INFO:root:current train perplexity4.6172661781311035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.30s/it]
INFO:root:final mean train loss: 15511.659561649445
INFO:root:final train perplexity: 4.61794376373291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.57s/it]
INFO:root:eval mean loss: 22328.161295572918
INFO:root:eval perplexity: 10.083178520202637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [8:48:20<9:59:54, 339.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15529.881981860632
INFO:root:current train perplexity4.6059699058532715
INFO:root:current mean train loss 15517.364048922125
INFO:root:current train perplexity4.613300800323486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it]
INFO:root:final mean train loss: 15497.411144625756
INFO:root:final train perplexity: 4.6114583015441895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.84s/it]
INFO:root:eval mean loss: 22324.913016183036
INFO:root:eval perplexity: 10.079789161682129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [8:54:02<9:55:34, 340.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15421.056139823719
INFO:root:current train perplexity4.557034969329834
INFO:root:current mean train loss 15485.857969874101
INFO:root:current train perplexity4.5893378257751465
INFO:root:current mean train loss 15505.12051353295
INFO:root:current train perplexity4.604928970336914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.12s/it]
INFO:root:final mean train loss: 15482.027292559223
INFO:root:final train perplexity: 4.604467391967773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:eval mean loss: 22328.439546130954
INFO:root:eval perplexity: 10.08346939086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [8:59:40<9:48:44, 339.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15508.17084478022
INFO:root:current train perplexity4.602363109588623
INFO:root:current mean train loss 15463.982779777487
INFO:root:current train perplexity4.595963478088379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.87s/it]
INFO:root:final mean train loss: 15462.991864604335
INFO:root:final train perplexity: 4.59583044052124
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it]
INFO:root:eval mean loss: 22336.077776227678
INFO:root:eval perplexity: 10.09144401550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:05:25<9:45:53, 341.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15458.461664244185
INFO:root:current train perplexity4.601744651794434
INFO:root:current mean train loss 15470.304755791083
INFO:root:current train perplexity4.596989631652832
INFO:root:current mean train loss 15461.83895158179
INFO:root:current train perplexity4.591564178466797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.75s/it]
INFO:root:final mean train loss: 15453.028052545364
INFO:root:final train perplexity: 4.5913166999816895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.89s/it]
INFO:root:eval mean loss: 22323.306547619046
INFO:root:eval perplexity: 10.07811164855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:11:05<9:39:20, 340.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15474.416827713816
INFO:root:current train perplexity4.580146312713623
INFO:root:current mean train loss 15450.147546073718
INFO:root:current train perplexity4.583249092102051


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.58s/it]
INFO:root:final mean train loss: 15435.945513325352
INFO:root:final train perplexity: 4.583586692810059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.74s/it]
INFO:root:eval mean loss: 22319.99537295387
INFO:root:eval perplexity: 10.074657440185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:16:42<9:31:53, 339.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15347.843583776596
INFO:root:current train perplexity4.529514312744141
INFO:root:current mean train loss 15407.251381802722
INFO:root:current train perplexity4.561974048614502
INFO:root:current mean train loss 15420.931379681175
INFO:root:current train perplexity4.571316719055176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it]
INFO:root:final mean train loss: 15410.201246692288
INFO:root:final train perplexity: 4.571963310241699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it]
INFO:root:eval mean loss: 22328.51892671131
INFO:root:eval perplexity: 10.083553314208984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:22:29<9:29:33, 341.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15356.2926333649
INFO:root:current train perplexity4.55210542678833
INFO:root:current mean train loss 15423.53697687657
INFO:root:current train perplexity4.569023132324219


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it]
INFO:root:final mean train loss: 15403.970939390121
INFO:root:final train perplexity: 4.569153785705566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.55s/it]
INFO:root:eval mean loss: 22320.254417782737
INFO:root:eval perplexity: 10.074928283691406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:28:05<9:21:19, 340.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15430.29270067402
INFO:root:current train perplexity4.552947998046875
INFO:root:current mean train loss 15411.85669106995
INFO:root:current train perplexity4.562789440155029


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.30s/it]
INFO:root:final mean train loss: 15388.564527942288
INFO:root:final train perplexity: 4.562215805053711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it]
INFO:root:eval mean loss: 22316.784319196428
INFO:root:eval perplexity: 10.071311950683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:33:36<9:10:45, 337.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15441.705729166666
INFO:root:current train perplexity4.494007587432861
INFO:root:current mean train loss 15399.032017976335
INFO:root:current train perplexity4.545560359954834
INFO:root:current mean train loss 15367.40884294181
INFO:root:current train perplexity4.547766208648682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.74s/it]
INFO:root:final mean train loss: 15368.665106004284
INFO:root:final train perplexity: 4.55327033996582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it]
INFO:root:eval mean loss: 22317.44703311012
INFO:root:eval perplexity: 10.072003364562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:39:01<8:59:12, 333.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15335.872425426136
INFO:root:current train perplexity4.523386478424072
INFO:root:current mean train loss 15354.946150453628
INFO:root:current train perplexity4.546365737915039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.83s/it]
INFO:root:final mean train loss: 15357.005540417087
INFO:root:final train perplexity: 4.548037052154541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it]
INFO:root:eval mean loss: 22323.99279203869
INFO:root:eval perplexity: 10.078827857971191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:44:25<8:49:30, 330.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15173.267020089286
INFO:root:current train perplexity4.490307807922363
INFO:root:current mean train loss 15268.049549138435
INFO:root:current train perplexity4.525511741638184
INFO:root:current mean train loss 15354.35369017965
INFO:root:current train perplexity4.544347286224365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.35s/it]
INFO:root:final mean train loss: 15346.689669701362
INFO:root:final train perplexity: 4.543412208557129
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.59s/it]
INFO:root:eval mean loss: 22326.587983630954
INFO:root:eval perplexity: 10.081536293029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [9:49:50<8:41:03, 329.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15331.593667240466
INFO:root:current train perplexity4.53418493270874
INFO:root:current mean train loss 15364.738588345126
INFO:root:current train perplexity4.537566184997559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it]
INFO:root:final mean train loss: 15326.486615580898
INFO:root:final train perplexity: 4.53436803817749
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it]
INFO:root:eval mean loss: 22334.34216889881
INFO:root:eval perplexity: 10.089632987976074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [9:55:20<8:35:56, 329.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15044.269353693182
INFO:root:current train perplexity4.485449314117432
INFO:root:current mean train loss 15278.457902238175
INFO:root:current train perplexity4.511933326721191
INFO:root:current mean train loss 15321.667163433056
INFO:root:current train perplexity4.5261969566345215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.92s/it]
INFO:root:final mean train loss: 15312.025339434223
INFO:root:final train perplexity: 4.527904987335205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.18s/it]
INFO:root:eval mean loss: 22335.205636160714
INFO:root:eval perplexity: 10.090532302856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [10:01:00<8:35:32, 332.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15265.281467013889
INFO:root:current train perplexity4.5124969482421875
INFO:root:current mean train loss 15305.0789757477
INFO:root:current train perplexity4.520789623260498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.87s/it]
INFO:root:final mean train loss: 15304.304986769153
INFO:root:final train perplexity: 4.524457931518555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:eval mean loss: 22339.500651041668
INFO:root:eval perplexity: 10.095020294189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [10:06:39<8:32:47, 334.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15033.046028645833
INFO:root:current train perplexity4.493462085723877
INFO:root:current mean train loss 15263.639317255434
INFO:root:current train perplexity4.505924701690674
INFO:root:current mean train loss 15290.747706213662
INFO:root:current train perplexity4.512680530548096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.50s/it]
INFO:root:final mean train loss: 15285.6544937626
INFO:root:final train perplexity: 4.516143321990967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it]
INFO:root:eval mean loss: 22354.39969308036
INFO:root:eval perplexity: 10.110599517822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:12:21<8:30:32, 336.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15206.942018423508
INFO:root:current train perplexity4.494194030761719
INFO:root:current mean train loss 15260.401285319986
INFO:root:current train perplexity4.507014274597168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.50s/it]
INFO:root:final mean train loss: 15270.16029407132
INFO:root:final train perplexity: 4.509246349334717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it]
INFO:root:eval mean loss: 22350.765811011905
INFO:root:eval perplexity: 10.106796264648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:18:01<8:26:45, 337.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15260.149928042763
INFO:root:current train perplexity4.488910675048828
INFO:root:current mean train loss 15309.713793329833
INFO:root:current train perplexity4.506280422210693
INFO:root:current mean train loss 15270.364636843608
INFO:root:current train perplexity4.504432201385498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.19s/it]
INFO:root:final mean train loss: 15264.501890120968
INFO:root:final train perplexity: 4.506730556488037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it]
INFO:root:eval mean loss: 22358.107282366072
INFO:root:eval perplexity: 10.114476203918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:23:35<8:19:13, 336.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15282.860241527289
INFO:root:current train perplexity4.505982875823975
INFO:root:current mean train loss 15267.402663559942
INFO:root:current train perplexity4.503961086273193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.55s/it]
INFO:root:final mean train loss: 15248.399796024445
INFO:root:final train perplexity: 4.49957799911499
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.94s/it]
INFO:root:eval mean loss: 22354.01232328869
INFO:root:eval perplexity: 10.11019229888916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:29:16<8:15:40, 337.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15174.179008152174
INFO:root:current train perplexity4.475970268249512
INFO:root:current mean train loss 15225.637703252032
INFO:root:current train perplexity4.494391441345215
INFO:root:current mean train loss 15242.289360285875
INFO:root:current train perplexity4.4957709312438965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.96s/it]
INFO:root:final mean train loss: 15236.700620589718
INFO:root:final train perplexity: 4.494388580322266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.11s/it]
INFO:root:eval mean loss: 22354.881742931546
INFO:root:eval perplexity: 10.111103057861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:34:55<8:10:30, 338.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15220.8419921875
INFO:root:current train perplexity4.489017486572266
INFO:root:current mean train loss 15243.753370535715
INFO:root:current train perplexity4.494747638702393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it]
INFO:root:final mean train loss: 15229.833114131805
INFO:root:final train perplexity: 4.4913458824157715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.57s/it]
INFO:root:eval mean loss: 22346.809616815477
INFO:root:eval perplexity: 10.102655410766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:40:28<8:02:17, 336.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15189.931640625
INFO:root:current train perplexity4.504661560058594
INFO:root:current mean train loss 15209.609382689468
INFO:root:current train perplexity4.486538887023926
INFO:root:current mean train loss 15221.430242462831
INFO:root:current train perplexity4.482059001922607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.72s/it]
INFO:root:final mean train loss: 15215.97316422001
INFO:root:final train perplexity: 4.48521089553833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.35s/it]
INFO:root:eval mean loss: 22339.420386904763
INFO:root:eval perplexity: 10.094935417175293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [10:46:03<7:56:26, 336.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15181.205473694621
INFO:root:current train perplexity4.471362113952637
INFO:root:current mean train loss 15211.05867012919
INFO:root:current train perplexity4.472568035125732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.15s/it]
INFO:root:final mean train loss: 15197.229850522934
INFO:root:final train perplexity: 4.476926326751709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it]
INFO:root:eval mean loss: 22345.89229910714
INFO:root:eval perplexity: 10.101698875427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [10:52:05<8:01:20, 343.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15248.593088457661
INFO:root:current train perplexity4.483067512512207
INFO:root:current mean train loss 15221.100802123092
INFO:root:current train perplexity4.4748406410217285
INFO:root:current mean train loss 15203.025792241613
INFO:root:current train perplexity4.473903656005859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.77s/it]
INFO:root:final mean train loss: 15185.83720545615
INFO:root:final train perplexity: 4.471898078918457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:eval mean loss: 22355.174502418155
INFO:root:eval perplexity: 10.111404418945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [10:57:55<7:58:24, 345.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15187.165321442018
INFO:root:current train perplexity4.4614410400390625
INFO:root:current mean train loss 15203.401543288934
INFO:root:current train perplexity4.468422889709473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.59s/it]
INFO:root:final mean train loss: 15176.412837859123
INFO:root:final train perplexity: 4.467742919921875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it]
INFO:root:eval mean loss: 22367.782877604168
INFO:root:eval perplexity: 10.124611854553223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [11:03:37<7:50:47, 344.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15122.472712053572
INFO:root:current train perplexity4.437689304351807
INFO:root:current mean train loss 15179.976916956019
INFO:root:current train perplexity4.454465389251709
INFO:root:current mean train loss 15175.372643783245
INFO:root:current train perplexity4.462786674499512


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.22s/it]
INFO:root:final mean train loss: 15164.96851767263
INFO:root:final train perplexity: 4.462703227996826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it]
INFO:root:eval mean loss: 22351.900855654763
INFO:root:eval perplexity: 10.10798168182373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [11:09:14<7:42:05, 342.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15114.81759608477
INFO:root:current train perplexity4.456286907196045
INFO:root:current mean train loss 15157.396014371658
INFO:root:current train perplexity4.456068515777588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.03s/it]
INFO:root:final mean train loss: 15154.223176033267
INFO:root:final train perplexity: 4.457976341247559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.44s/it]
INFO:root:eval mean loss: 22361.274065290178
INFO:root:eval perplexity: 10.117793083190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:14:44<7:31:34, 338.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15095.368189102564
INFO:root:current train perplexity4.430726051330566
INFO:root:current mean train loss 15115.158364714478
INFO:root:current train perplexity4.445128917694092
INFO:root:current mean train loss 15145.154366337605
INFO:root:current train perplexity4.44948148727417


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.20s/it]
INFO:root:final mean train loss: 15135.872944493447
INFO:root:final train perplexity: 4.449914932250977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.38s/it]
INFO:root:eval mean loss: 22360.22093563988
INFO:root:eval perplexity: 10.116687774658203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:20:21<7:25:07, 338.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15108.291799021292
INFO:root:current train perplexity4.439233779907227
INFO:root:current mean train loss 15121.767562786323
INFO:root:current train perplexity4.436535835266113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.84s/it]
INFO:root:final mean train loss: 15129.15146169355
INFO:root:final train perplexity: 4.44696569442749
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it]
INFO:root:eval mean loss: 22357.998511904763
INFO:root:eval perplexity: 10.114362716674805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:25:54<7:17:36, 336.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15102.539902797966
INFO:root:current train perplexity4.456062316894531
INFO:root:current mean train loss 15146.673438865822
INFO:root:current train perplexity4.448065280914307
INFO:root:current mean train loss 15133.428493923611
INFO:root:current train perplexity4.443791389465332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.82s/it]
INFO:root:final mean train loss: 15121.700088993195
INFO:root:final train perplexity: 4.443698883056641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it]
INFO:root:eval mean loss: 22365.42601376488
INFO:root:eval perplexity: 10.122142791748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:31:19<7:07:26, 333.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15087.286430921053
INFO:root:current train perplexity4.4337310791015625
INFO:root:current mean train loss 15127.215830328525
INFO:root:current train perplexity4.436421871185303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.60s/it]
INFO:root:final mean train loss: 15110.682904643398
INFO:root:final train perplexity: 4.438872337341309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.33s/it]
INFO:root:eval mean loss: 22368.110305059523
INFO:root:eval perplexity: 10.124950408935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:36:43<6:58:23, 330.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15092.337184175532
INFO:root:current train perplexity4.420352935791016
INFO:root:current mean train loss 15111.8381164966
INFO:root:current train perplexity4.430002689361572
INFO:root:current mean train loss 15113.057431363866
INFO:root:current train perplexity4.434228897094727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.31s/it]
INFO:root:final mean train loss: 15099.300950573337
INFO:root:final train perplexity: 4.433892726898193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22365.264136904763
INFO:root:eval perplexity: 10.12197208404541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:42:19<6:55:07, 332.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15075.849589646465
INFO:root:current train perplexity4.423154354095459
INFO:root:current mean train loss 15093.74237888662
INFO:root:current train perplexity4.425008296966553


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.79s/it]
INFO:root:final mean train loss: 15085.759478169102
INFO:root:final train perplexity: 4.42797327041626
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.19s/it]
INFO:root:eval mean loss: 22356.043550037204
INFO:root:eval perplexity: 10.112313270568848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [11:47:45<6:47:13, 330.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15082.179630055147
INFO:root:current train perplexity4.419436931610107
INFO:root:current mean train loss 15068.231535854718
INFO:root:current train perplexity4.419513702392578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.66s/it]
INFO:root:final mean train loss: 15080.913767168598
INFO:root:final train perplexity: 4.425858020782471
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.70s/it]
INFO:root:eval mean loss: 22367.02222842262
INFO:root:eval perplexity: 10.123810768127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [11:53:12<6:40:39, 329.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14902.296875
INFO:root:current train perplexity4.428658485412598
INFO:root:current mean train loss 15063.153633191747
INFO:root:current train perplexity4.420498371124268
INFO:root:current mean train loss 15062.899491032944
INFO:root:current train perplexity4.414562225341797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.28s/it]
INFO:root:final mean train loss: 15065.057699880292
INFO:root:final train perplexity: 4.418942451477051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it]
INFO:root:eval mean loss: 22365.452101934523
INFO:root:eval perplexity: 10.122166633605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [11:58:49<6:38:02, 331.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15081.544176136364
INFO:root:current train perplexity4.418898582458496
INFO:root:current mean train loss 15067.33601310484
INFO:root:current train perplexity4.418649673461914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.98s/it]
INFO:root:final mean train loss: 15060.930419921875
INFO:root:final train perplexity: 4.41714334487915
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.14s/it]
INFO:root:eval mean loss: 22367.087588355655
INFO:root:eval perplexity: 10.123883247375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [12:04:17<6:31:11, 330.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15088.85463169643
INFO:root:current train perplexity4.373028755187988
INFO:root:current mean train loss 15078.318368501752
INFO:root:current train perplexity4.422906875610352
INFO:root:current mean train loss 15061.394672780798
INFO:root:current train perplexity4.413448810577393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.80s/it]
INFO:root:final mean train loss: 15049.547418409778
INFO:root:final train perplexity: 4.412187576293945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.95s/it]
INFO:root:eval mean loss: 22397.396949404763
INFO:root:eval perplexity: 10.155688285827637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [12:09:50<6:26:22, 331.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15082.120034427966
INFO:root:current train perplexity4.418889999389648
INFO:root:current mean train loss 15034.373384679639
INFO:root:current train perplexity4.408995628356934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it]
INFO:root:final mean train loss: 15042.338949880292
INFO:root:final train perplexity: 4.409050941467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it]
INFO:root:eval mean loss: 22372.16041201637
INFO:root:eval perplexity: 10.129197120666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:15:22<6:21:05, 331.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14950.386541193182
INFO:root:current train perplexity4.425509452819824
INFO:root:current mean train loss 15036.811435458896
INFO:root:current train perplexity4.400315761566162
INFO:root:current mean train loss 15030.201394031397
INFO:root:current train perplexity4.401068210601807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it]
INFO:root:final mean train loss: 15028.492053616432
INFO:root:final train perplexity: 4.403033256530762
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.20s/it]
INFO:root:eval mean loss: 22377.150204613095
INFO:root:eval perplexity: 10.134428977966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:21:11<6:21:36, 336.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14919.04408482143
INFO:root:current train perplexity4.385868549346924
INFO:root:current mean train loss 14984.92987921779
INFO:root:current train perplexity4.389290809631348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it]
INFO:root:final mean train loss: 15016.32338000882
INFO:root:final train perplexity: 4.397752285003662
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.37s/it]
INFO:root:eval mean loss: 22373.830543154763
INFO:root:eval perplexity: 10.130950927734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:26:53<6:17:53, 338.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14992.096223958333
INFO:root:current train perplexity4.41082763671875
INFO:root:current mean train loss 15026.042306385869
INFO:root:current train perplexity4.401904582977295
INFO:root:current mean train loss 15014.402007630813
INFO:root:current train perplexity4.391379356384277


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.08s/it]
INFO:root:final mean train loss: 15005.92511576991
INFO:root:final train perplexity: 4.39324426651001
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.50s/it]
INFO:root:eval mean loss: 22390.245419456845
INFO:root:eval perplexity: 10.148177146911621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:32:29<6:11:16, 337.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14957.693461403918
INFO:root:current train perplexity4.3734588623046875
INFO:root:current mean train loss 15039.50978316804
INFO:root:current train perplexity4.399050235748291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.04s/it]
INFO:root:final mean train loss: 15005.171516664566
INFO:root:final train perplexity: 4.392918109893799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.80s/it]
INFO:root:eval mean loss: 22387.495093936013
INFO:root:eval perplexity: 10.145286560058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:38:12<6:07:36, 339.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15052.322265625
INFO:root:current train perplexity4.39369535446167
INFO:root:current mean train loss 15022.900751706933
INFO:root:current train perplexity4.395749568939209
INFO:root:current mean train loss 15023.176334189498
INFO:root:current train perplexity4.389381408691406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.77s/it]
INFO:root:final mean train loss: 14990.264943768902
INFO:root:final train perplexity: 4.386463642120361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it]
INFO:root:eval mean loss: 22395.93468656994
INFO:root:eval perplexity: 10.154152870178223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [12:43:42<5:59:04, 336.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14977.141821632922
INFO:root:current train perplexity4.377131938934326
INFO:root:current mean train loss 15015.429459064328
INFO:root:current train perplexity4.386088848114014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.07s/it]
INFO:root:final mean train loss: 14988.075904107864
INFO:root:final train perplexity: 4.385516166687012
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it]
INFO:root:eval mean loss: 22393.980166480655
INFO:root:eval perplexity: 10.152097702026367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [12:49:23<5:54:46, 337.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14882.469132133152
INFO:root:current train perplexity4.352229118347168
INFO:root:current mean train loss 14962.267125571647
INFO:root:current train perplexity4.376338958740234
INFO:root:current mean train loss 14975.736993764014
INFO:root:current train perplexity4.378089427947998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.42s/it]
INFO:root:final mean train loss: 14968.685216103831
INFO:root:final train perplexity: 4.377137184143066
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it]
INFO:root:eval mean loss: 22395.73851376488
INFO:root:eval perplexity: 10.153942108154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [12:55:09<5:51:31, 340.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14913.7253125
INFO:root:current train perplexity4.356883525848389
INFO:root:current mean train loss 14962.408191964285
INFO:root:current train perplexity4.365509510040283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.97s/it]
INFO:root:final mean train loss: 14965.398429624496
INFO:root:final train perplexity: 4.375717639923096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.05s/it]
INFO:root:eval mean loss: 22386.102725074405
INFO:root:eval perplexity: 10.14382553100586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [13:00:58<5:48:31, 342.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14972.084309895834
INFO:root:current train perplexity4.375941753387451
INFO:root:current mean train loss 14935.813745693898
INFO:root:current train perplexity4.365813732147217
INFO:root:current mean train loss 14972.362080981553
INFO:root:current train perplexity4.372368335723877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it]
INFO:root:final mean train loss: 14960.460177513862
INFO:root:final train perplexity: 4.373587131500244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it]
INFO:root:eval mean loss: 22394.13318452381
INFO:root:eval perplexity: 10.152259826660156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [13:06:32<5:40:10, 340.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14906.381168413765
INFO:root:current train perplexity4.363947868347168
INFO:root:current mean train loss 14935.053918252444
INFO:root:current train perplexity4.3631815910339355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.71s/it]
INFO:root:final mean train loss: 14943.643775201614
INFO:root:final train perplexity: 4.366339206695557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it]
INFO:root:eval mean loss: 22394.79854910714
INFO:root:eval perplexity: 10.15295696258545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [13:12:05<5:32:34, 338.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14920.04482736895
INFO:root:current train perplexity4.365591526031494
INFO:root:current mean train loss 14952.262598401718
INFO:root:current train perplexity4.369142055511475
INFO:root:current mean train loss 14948.33853321158
INFO:root:current train perplexity4.365763187408447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.67s/it]
INFO:root:final mean train loss: 14937.299123456402
INFO:root:final train perplexity: 4.363607406616211
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it]
INFO:root:eval mean loss: 22417.646809895832
INFO:root:eval perplexity: 10.176993370056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:17:34<5:24:09, 335.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14998.582254800453
INFO:root:current train perplexity4.354949474334717
INFO:root:current mean train loss 14949.525129141051
INFO:root:current train perplexity4.3553786277771


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.65s/it]
INFO:root:final mean train loss: 14934.333598475303
INFO:root:final train perplexity: 4.362331867218018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it]
INFO:root:eval mean loss: 22393.950148809523
INFO:root:eval perplexity: 10.152066230773926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:23:02<5:16:31, 333.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14882.831780133929
INFO:root:current train perplexity4.33217716217041
INFO:root:current mean train loss 14919.092975983796
INFO:root:current train perplexity4.3483428955078125
INFO:root:current mean train loss 14930.779774767287
INFO:root:current train perplexity4.359887599945068


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.96s/it]
INFO:root:final mean train loss: 14928.414613785282
INFO:root:final train perplexity: 4.359786033630371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it]
INFO:root:eval mean loss: 22405.02599516369
INFO:root:eval perplexity: 10.163710594177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:28:28<5:08:54, 330.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14898.321390086207
INFO:root:current train perplexity4.344336032867432
INFO:root:current mean train loss 14940.98787391377
INFO:root:current train perplexity4.358316421508789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.47s/it]
INFO:root:final mean train loss: 14920.226223853326
INFO:root:final train perplexity: 4.356265544891357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.01s/it]
INFO:root:eval mean loss: 22408.180152529763
INFO:root:eval perplexity: 10.167028427124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:34:06<5:05:24, 333.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14926.017077323719
INFO:root:current train perplexity4.346530437469482
INFO:root:current mean train loss 14913.621416928956
INFO:root:current train perplexity4.350661277770996
INFO:root:current mean train loss 14919.067652490847
INFO:root:current train perplexity4.35109281539917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.21s/it]
INFO:root:final mean train loss: 14909.439634261593
INFO:root:final train perplexity: 4.351634502410889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.55s/it]
INFO:root:eval mean loss: 22402.22667875744
INFO:root:eval perplexity: 10.1607666015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [13:39:35<4:58:39, 331.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14957.440719436812
INFO:root:current train perplexity4.345295429229736
INFO:root:current mean train loss 14911.662007117147
INFO:root:current train perplexity4.341597557067871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.71s/it]
INFO:root:final mean train loss: 14905.504071635585
INFO:root:final train perplexity: 4.349944591522217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:eval mean loss: 22407.478608630954
INFO:root:eval perplexity: 10.166291236877441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [13:45:04<4:52:17, 330.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14903.196788699128
INFO:root:current train perplexity4.3489837646484375
INFO:root:current mean train loss 14893.497923951049
INFO:root:current train perplexity4.339285850524902
INFO:root:current mean train loss 14912.651134098509
INFO:root:current train perplexity4.346385478973389


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.69s/it]
INFO:root:final mean train loss: 14897.591792937248
INFO:root:final train perplexity: 4.346550941467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.08s/it]
INFO:root:eval mean loss: 22408.93043154762
INFO:root:eval perplexity: 10.167819023132324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [13:50:29<4:45:23, 329.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14909.7037109375
INFO:root:current train perplexity4.343414306640625
INFO:root:current mean train loss 14892.276893028846
INFO:root:current train perplexity4.341036796569824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.04s/it]
INFO:root:final mean train loss: 14893.034675844254
INFO:root:final train perplexity: 4.344597816467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.95s/it]
INFO:root:eval mean loss: 22404.892066592263
INFO:root:eval perplexity: 10.163567543029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [13:55:54<4:38:46, 327.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14875.075901761968
INFO:root:current train perplexity4.3309454917907715
INFO:root:current mean train loss 14865.676591730442
INFO:root:current train perplexity4.331633567810059
INFO:root:current mean train loss 14896.380495635121
INFO:root:current train perplexity4.341477394104004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.58s/it]
INFO:root:final mean train loss: 14885.51363249748
INFO:root:final train perplexity: 4.341376781463623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.37s/it]
INFO:root:eval mean loss: 22412.27955264137
INFO:root:eval perplexity: 10.171343803405762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [14:01:43<4:38:31, 334.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14864.769975142046
INFO:root:current train perplexity4.328304290771484
INFO:root:current mean train loss 14858.755815208857
INFO:root:current train perplexity4.334229469299316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.78s/it]
INFO:root:final mean train loss: 14875.998858051915
INFO:root:final train perplexity: 4.33730411529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it]
INFO:root:eval mean loss: 22422.03055245536
INFO:root:eval perplexity: 10.181612014770508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [14:07:13<4:31:58, 333.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14861.091164981617
INFO:root:current train perplexity4.334278106689453
INFO:root:current mean train loss 14854.533856322434
INFO:root:current train perplexity4.328581809997559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it]
INFO:root:final mean train loss: 14868.2013687626
INFO:root:final train perplexity: 4.333970069885254
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it]
INFO:root:eval mean loss: 22416.259440104168
INFO:root:eval perplexity: 10.175535202026367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [14:12:43<4:25:42, 332.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14890.2451171875
INFO:root:current train perplexity4.322760581970215
INFO:root:current mean train loss 14849.435584799758
INFO:root:current train perplexity4.322648525238037
INFO:root:current mean train loss 14873.29777940271
INFO:root:current train perplexity4.33112907409668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.83s/it]
INFO:root:final mean train loss: 14861.985083795364
INFO:root:final train perplexity: 4.331313610076904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.52s/it]
INFO:root:eval mean loss: 22423.627255394345
INFO:root:eval perplexity: 10.183297157287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:18:25<4:22:20, 334.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14820.459623579545
INFO:root:current train perplexity4.308618545532227
INFO:root:current mean train loss 14842.672662550403
INFO:root:current train perplexity4.320380687713623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it]
INFO:root:final mean train loss: 14855.886045394405
INFO:root:final train perplexity: 4.328709125518799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.45s/it]
INFO:root:eval mean loss: 22419.523390997023
INFO:root:eval perplexity: 10.178971290588379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:24:09<4:18:52, 337.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14928.411830357143
INFO:root:current train perplexity4.3664631843566895
INFO:root:current mean train loss 14819.112551109813
INFO:root:current train perplexity4.320839881896973
INFO:root:current mean train loss 14861.74695237017
INFO:root:current train perplexity4.325723648071289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.50s/it]
INFO:root:final mean train loss: 14845.856957220261
INFO:root:final train perplexity: 4.324428558349609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.56s/it]
INFO:root:eval mean loss: 22424.34093656994
INFO:root:eval perplexity: 10.184046745300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:29:44<4:12:36, 336.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14865.768058130298
INFO:root:current train perplexity4.318507194519043
INFO:root:current mean train loss 14829.596335740958
INFO:root:current train perplexity4.316887378692627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.79s/it]
INFO:root:final mean train loss: 14836.374621975807
INFO:root:final train perplexity: 4.3203864097595215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it]
INFO:root:eval mean loss: 22417.52711123512
INFO:root:eval perplexity: 10.17686939239502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [14:35:18<4:06:23, 335.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14816.195134943182
INFO:root:current train perplexity4.273910999298096
INFO:root:current mean train loss 14841.998442778717
INFO:root:current train perplexity4.313141345977783
INFO:root:current mean train loss 14847.476784656397
INFO:root:current train perplexity4.318254470825195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.93s/it]
INFO:root:final mean train loss: 14837.861521074848
INFO:root:final train perplexity: 4.321019172668457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it]
INFO:root:eval mean loss: 22425.574358258928
INFO:root:eval perplexity: 10.185348510742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [14:40:49<3:59:48, 334.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14768.459170386905
INFO:root:current train perplexity4.307984352111816
INFO:root:current mean train loss 14844.789433953221
INFO:root:current train perplexity4.321166515350342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.82s/it]
INFO:root:final mean train loss: 14835.193075856854
INFO:root:final train perplexity: 4.319882392883301
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it]
INFO:root:eval mean loss: 22425.549665178572
INFO:root:eval perplexity: 10.185318946838379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [14:46:25<3:54:27, 334.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14898.270052083333
INFO:root:current train perplexity4.314788341522217
INFO:root:current mean train loss 14845.402819293478
INFO:root:current train perplexity4.323667526245117
INFO:root:current mean train loss 14839.069008902616
INFO:root:current train perplexity4.317009925842285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.50s/it]
INFO:root:final mean train loss: 14824.9943375126
INFO:root:final train perplexity: 4.3155388832092285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.70s/it]
INFO:root:eval mean loss: 22427.78536551339
INFO:root:eval perplexity: 10.1876802444458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [14:51:54<3:47:40, 333.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14804.371807952426
INFO:root:current train perplexity4.300182342529297
INFO:root:current mean train loss 14814.709165653068
INFO:root:current train perplexity4.308180332183838


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it]
INFO:root:final mean train loss: 14822.718442855343
INFO:root:final train perplexity: 4.314570426940918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.82s/it]
INFO:root:eval mean loss: 22420.63123139881
INFO:root:eval perplexity: 10.18014144897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [14:57:24<3:41:30, 332.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14804.835834703947
INFO:root:current train perplexity4.2945637702941895
INFO:root:current mean train loss 14837.142651982667
INFO:root:current train perplexity4.313083171844482
INFO:root:current mean train loss 14818.5760024258
INFO:root:current train perplexity4.3126983642578125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.49s/it]
INFO:root:final mean train loss: 14818.382288778981
INFO:root:final train perplexity: 4.312725067138672
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.84s/it]
INFO:root:eval mean loss: 22434.60914248512
INFO:root:eval perplexity: 10.194876670837402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [15:02:49<3:34:37, 330.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14818.828152508802
INFO:root:current train perplexity4.297383785247803
INFO:root:current mean train loss 14817.363458287646
INFO:root:current train perplexity4.303198337554932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.11s/it]
INFO:root:final mean train loss: 14811.790385584678
INFO:root:final train perplexity: 4.309922695159912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it]
INFO:root:eval mean loss: 22428.38455636161
INFO:root:eval perplexity: 10.188311576843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [15:08:13<3:27:51, 328.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14808.58054517663
INFO:root:current train perplexity4.321137428283691
INFO:root:current mean train loss 14851.030503683944
INFO:root:current train perplexity4.311145305633545
INFO:root:current mean train loss 14813.386258933577
INFO:root:current train perplexity4.303512096405029


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.76s/it]
INFO:root:final mean train loss: 14801.338386781754
INFO:root:final train perplexity: 4.305481910705566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.18s/it]
INFO:root:eval mean loss: 22423.091820126487
INFO:root:eval perplexity: 10.182730674743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [15:13:45<3:23:01, 329.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14781.873229166667
INFO:root:current train perplexity4.311903953552246
INFO:root:current mean train loss 14791.845652901786
INFO:root:current train perplexity4.302938461303711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it]
INFO:root:final mean train loss: 14799.248054750504
INFO:root:final train perplexity: 4.304594039916992
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it]
INFO:root:eval mean loss: 22432.90294828869
INFO:root:eval perplexity: 10.193076133728027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [15:19:09<3:16:39, 327.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14841.621780960648
INFO:root:current train perplexity4.297718048095703
INFO:root:current mean train loss 14839.178572527067
INFO:root:current train perplexity4.31923246383667
INFO:root:current mean train loss 14817.436497625275
INFO:root:current train perplexity4.307805061340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.23s/it]
INFO:root:final mean train loss: 14799.014979208669
INFO:root:final train perplexity: 4.304494857788086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.60s/it]
INFO:root:eval mean loss: 22429.629975818454
INFO:root:eval perplexity: 10.18962574005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:24:43<3:12:13, 329.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14825.36229232595
INFO:root:current train perplexity4.3086748123168945
INFO:root:current mean train loss 14817.286034610685
INFO:root:current train perplexity4.304776191711426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.72s/it]
INFO:root:final mean train loss: 14791.476952337449
INFO:root:final train perplexity: 4.301296234130859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it]
INFO:root:eval mean loss: 22440.099283854168
INFO:root:eval perplexity: 10.200671195983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:30:05<3:05:36, 327.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14807.915984122983
INFO:root:current train perplexity4.2957634925842285
INFO:root:current mean train loss 14811.158650405534
INFO:root:current train perplexity4.2961015701293945
INFO:root:current mean train loss 14799.451958198051
INFO:root:current train perplexity4.299578666687012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.55s/it]
INFO:root:final mean train loss: 14785.41831920993
INFO:root:final train perplexity: 4.298727035522461
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 22435.971493675595
INFO:root:eval perplexity: 10.196313858032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [15:35:31<2:59:50, 326.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14773.05128717997
INFO:root:current train perplexity4.289186000823975
INFO:root:current mean train loss 14800.853990565232
INFO:root:current train perplexity4.295382022857666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.68s/it]
INFO:root:final mean train loss: 14779.00679655998
INFO:root:final train perplexity: 4.296009063720703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it]
INFO:root:eval mean loss: 22432.955915178572
INFO:root:eval perplexity: 10.193134307861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [15:40:57<2:54:10, 326.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14926.660630580358
INFO:root:current train perplexity4.330739974975586
INFO:root:current mean train loss 14773.91665943287
INFO:root:current train perplexity4.289231777191162
INFO:root:current mean train loss 14793.78513962766
INFO:root:current train perplexity4.296280860900879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.72s/it]
INFO:root:final mean train loss: 14775.838390719506
INFO:root:final train perplexity: 4.294666767120361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.21s/it]
INFO:root:eval mean loss: 22438.730515252977
INFO:root:eval perplexity: 10.19922924041748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [15:46:22<2:48:35, 326.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14785.934626436781
INFO:root:current train perplexity4.300073623657227
INFO:root:current mean train loss 14781.696069727606
INFO:root:current train perplexity4.296242713928223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.59s/it]
INFO:root:final mean train loss: 14781.070084110383
INFO:root:final train perplexity: 4.2968831062316895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.66s/it]
INFO:root:eval mean loss: 22445.424711681546
INFO:root:eval perplexity: 10.206295013427734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [15:51:57<2:44:19, 328.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14696.120693108975
INFO:root:current train perplexity4.261848449707031
INFO:root:current mean train loss 14750.926645402427
INFO:root:current train perplexity4.291175842285156
INFO:root:current mean train loss 14781.211644384153
INFO:root:current train perplexity4.294813632965088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.21s/it]
INFO:root:final mean train loss: 14771.9148421749
INFO:root:final train perplexity: 4.293004989624023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.75s/it]
INFO:root:eval mean loss: 22443.68289620536
INFO:root:eval perplexity: 10.204456329345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [15:57:43<2:41:29, 334.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14810.445033482143
INFO:root:current train perplexity4.308513641357422
INFO:root:current mean train loss 14760.447981429974
INFO:root:current train perplexity4.288717746734619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.51s/it]
INFO:root:final mean train loss: 14763.40935688634
INFO:root:final train perplexity: 4.28940486907959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it]
INFO:root:eval mean loss: 22438.670014880954
INFO:root:eval perplexity: 10.199163436889648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [16:03:15<2:35:37, 333.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14726.314271438954
INFO:root:current train perplexity4.280658721923828
INFO:root:current mean train loss 14775.58444875437
INFO:root:current train perplexity4.288384437561035
INFO:root:current mean train loss 14769.924290284207
INFO:root:current train perplexity4.286045074462891


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.70s/it]
INFO:root:final mean train loss: 14756.458862304688
INFO:root:final train perplexity: 4.286465644836426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it]
INFO:root:eval mean loss: 22444.931710379464
INFO:root:eval perplexity: 10.205774307250977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [16:08:44<2:29:27, 332.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14790.59591899671
INFO:root:current train perplexity4.288334369659424
INFO:root:current mean train loss 14778.342678285257
INFO:root:current train perplexity4.2873334884643555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.87s/it]
INFO:root:final mean train loss: 14759.544973065777
INFO:root:final train perplexity: 4.287770748138428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it]
INFO:root:eval mean loss: 22446.060128348214
INFO:root:eval perplexity: 10.2069673538208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [16:14:11<2:23:09, 330.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14688.42341256649
INFO:root:current train perplexity4.2659149169921875
INFO:root:current mean train loss 14744.372482196004
INFO:root:current train perplexity4.275478363037109
INFO:root:current mean train loss 14766.771911373988
INFO:root:current train perplexity4.286156177520752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.96s/it]
INFO:root:final mean train loss: 14754.883036951866
INFO:root:final train perplexity: 4.285799503326416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it]
INFO:root:eval mean loss: 22441.789155505954
INFO:root:eval perplexity: 10.20245361328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [16:19:42<2:17:49, 330.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14746.515171243687
INFO:root:current train perplexity4.278293609619141
INFO:root:current mean train loss 14751.901524222676
INFO:root:current train perplexity4.279885768890381


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.05s/it]
INFO:root:final mean train loss: 14748.443914598034
INFO:root:final train perplexity: 4.283078193664551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 22440.319963727678
INFO:root:eval perplexity: 10.200904846191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [16:25:12<2:12:08, 330.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14762.40975413603
INFO:root:current train perplexity4.269967079162598
INFO:root:current mean train loss 14745.243396885347
INFO:root:current train perplexity4.274604797363281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.42s/it]
INFO:root:final mean train loss: 14746.381808373237
INFO:root:final train perplexity: 4.282207012176514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it]
INFO:root:eval mean loss: 22448.15457589286
INFO:root:eval perplexity: 10.209178924560547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:30:53<2:07:51, 333.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14784.965169270834
INFO:root:current train perplexity4.269913673400879
INFO:root:current mean train loss 14742.067202669903
INFO:root:current train perplexity4.279666423797607
INFO:root:current mean train loss 14769.071572891009
INFO:root:current train perplexity4.282689094543457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.34s/it]
INFO:root:final mean train loss: 14746.153918850807
INFO:root:final train perplexity: 4.282110691070557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it]
INFO:root:eval mean loss: 22450.462309337796
INFO:root:eval perplexity: 10.211618423461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [16:36:23<2:01:59, 332.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14806.655823863637
INFO:root:current train perplexity4.274662017822266
INFO:root:current mean train loss 14776.385509072581
INFO:root:current train perplexity4.281375885009766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.34s/it]
INFO:root:final mean train loss: 14742.232043850807
INFO:root:final train perplexity: 4.280454635620117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it]
INFO:root:eval mean loss: 22454.251139322918
INFO:root:eval perplexity: 10.21562385559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [16:41:57<1:56:33, 333.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14664.82407924107
INFO:root:current train perplexity4.261692523956299
INFO:root:current mean train loss 14720.568934360397
INFO:root:current train perplexity4.2775492668151855
INFO:root:current mean train loss 14746.876033174818
INFO:root:current train perplexity4.277665615081787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it]
INFO:root:final mean train loss: 14738.35388577369
INFO:root:final train perplexity: 4.278818130493164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.38s/it]
INFO:root:eval mean loss: 22448.420875186013
INFO:root:eval perplexity: 10.20945930480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [16:47:22<1:50:10, 330.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14708.505859375
INFO:root:current train perplexity4.274377822875977
INFO:root:current mean train loss 14719.849111880896
INFO:root:current train perplexity4.268847942352295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.31s/it]
INFO:root:final mean train loss: 14736.60451187626
INFO:root:final train perplexity: 4.278079509735107
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.46s/it]
INFO:root:eval mean loss: 22452.665225074405
INFO:root:eval perplexity: 10.213946342468262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [16:52:53<1:44:40, 330.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14829.025745738636
INFO:root:current train perplexity4.261579513549805
INFO:root:current mean train loss 14763.141891891892
INFO:root:current train perplexity4.280675888061523
INFO:root:current mean train loss 14748.68774529769
INFO:root:current train perplexity4.278044700622559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.65s/it]
INFO:root:final mean train loss: 14731.84226546749
INFO:root:final train perplexity: 4.2760701179504395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it]
INFO:root:eval mean loss: 22452.682756696428
INFO:root:eval perplexity: 10.213963508605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [16:58:18<1:38:40, 328.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14684.891369047618
INFO:root:current train perplexity4.266617774963379
INFO:root:current mean train loss 14723.159503211273
INFO:root:current train perplexity4.267763614654541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.59s/it]
INFO:root:final mean train loss: 14730.46078392767
INFO:root:final train perplexity: 4.275487899780273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it]
INFO:root:eval mean loss: 22449.37841796875
INFO:root:eval perplexity: 10.210472106933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [17:03:45<1:33:04, 328.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14696.934505208334
INFO:root:current train perplexity4.284269332885742
INFO:root:current mean train loss 14736.539979619565
INFO:root:current train perplexity4.276566982269287
INFO:root:current mean train loss 14732.733144077034
INFO:root:current train perplexity4.271824359893799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.68s/it]
INFO:root:final mean train loss: 14721.375921433972
INFO:root:final train perplexity: 4.271658897399902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it]
INFO:root:eval mean loss: 22446.173432849704
INFO:root:eval perplexity: 10.207086563110352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [17:09:10<1:27:18, 327.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14752.9443359375
INFO:root:current train perplexity4.264699935913086
INFO:root:current mean train loss 14729.531168132486
INFO:root:current train perplexity4.267805576324463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.82s/it]
INFO:root:final mean train loss: 14723.611225743447
INFO:root:final train perplexity: 4.272600173950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it]
INFO:root:eval mean loss: 22452.260928199405
INFO:root:eval perplexity: 10.213518142700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [17:14:33<1:21:33, 326.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14667.370476973685
INFO:root:current train perplexity4.252151966094971
INFO:root:current mean train loss 14719.472106420693
INFO:root:current train perplexity4.272939205169678
INFO:root:current mean train loss 14744.409942208904
INFO:root:current train perplexity4.275021553039551


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.34s/it]
INFO:root:final mean train loss: 14721.36785298009
INFO:root:final train perplexity: 4.271655559539795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.93s/it]
INFO:root:eval mean loss: 22449.014973958332
INFO:root:eval perplexity: 10.210086822509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [17:20:19<1:17:26, 331.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14750.829761773768
INFO:root:current train perplexity4.272200584411621
INFO:root:current mean train loss 14759.08367027595
INFO:root:current train perplexity4.275930881500244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.95s/it]
INFO:root:final mean train loss: 14726.019846270161
INFO:root:final train perplexity: 4.273615837097168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.81s/it]
INFO:root:eval mean loss: 22452.63843936012
INFO:root:eval perplexity: 10.213916778564453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [17:26:04<1:12:48, 336.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14768.210300611414
INFO:root:current train perplexity4.25632905960083
INFO:root:current mean train loss 14712.735804115853
INFO:root:current train perplexity4.264803886413574
INFO:root:current mean train loss 14732.380719240471
INFO:root:current train perplexity4.2715301513671875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.87s/it]
INFO:root:final mean train loss: 14719.584015877017
INFO:root:final train perplexity: 4.270903587341309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.36s/it]
INFO:root:eval mean loss: 22456.636183965773
INFO:root:eval perplexity: 10.218145370483398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [17:31:50<1:07:48, 339.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14739.844596354167
INFO:root:current train perplexity4.273553848266602
INFO:root:current mean train loss 14708.323962053571
INFO:root:current train perplexity4.265151500701904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.64s/it]
INFO:root:final mean train loss: 14713.714973695816
INFO:root:final train perplexity: 4.268432140350342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.95s/it]
INFO:root:eval mean loss: 22453.40538969494
INFO:root:eval perplexity: 10.214728355407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [17:37:36<1:02:29, 340.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14673.505823206018
INFO:root:current train perplexity4.258116722106934
INFO:root:current mean train loss 14700.361904835137
INFO:root:current train perplexity4.2667622566223145
INFO:root:current mean train loss 14718.036347914373
INFO:root:current train perplexity4.267205238342285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.61s/it]
INFO:root:final mean train loss: 14716.049418787803
INFO:root:final train perplexity: 4.26941442489624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it]
INFO:root:eval mean loss: 22455.23279389881
INFO:root:eval perplexity: 10.216659545898438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [17:43:03<56:08, 336.89s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14784.55174545095
INFO:root:current train perplexity4.275775909423828
INFO:root:current mean train loss 14724.863788626048
INFO:root:current train perplexity4.268130779266357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.93s/it]
INFO:root:final mean train loss: 14714.579873361896
INFO:root:final train perplexity: 4.268796443939209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it]
INFO:root:eval mean loss: 22454.224097842263
INFO:root:eval perplexity: 10.215595245361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [17:48:27<49:56, 332.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14827.979366179436
INFO:root:current train perplexity4.274832725524902
INFO:root:current mean train loss 14763.545152969942
INFO:root:current train perplexity4.272029876708984
INFO:root:current mean train loss 14718.862182088744
INFO:root:current train perplexity4.266960144042969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.53s/it]
INFO:root:final mean train loss: 14713.014018397178
INFO:root:final train perplexity: 4.268136501312256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.03s/it]
INFO:root:eval mean loss: 22455.369466145832
INFO:root:eval perplexity: 10.216805458068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [17:53:51<44:01, 330.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14711.541286238706
INFO:root:current train perplexity4.2686944007873535
INFO:root:current mean train loss 14709.95903773907
INFO:root:current train perplexity4.265427589416504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.32s/it]
INFO:root:final mean train loss: 14711.002157888104
INFO:root:final train perplexity: 4.2672905921936035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it]
INFO:root:eval mean loss: 22455.802269345237
INFO:root:eval perplexity: 10.217263221740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [17:59:15<38:19, 328.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14715.506668526787
INFO:root:current train perplexity4.2865142822265625
INFO:root:current mean train loss 14722.637029803242
INFO:root:current train perplexity4.266632080078125
INFO:root:current mean train loss 14722.865757978723
INFO:root:current train perplexity4.264891624450684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.49s/it]
INFO:root:final mean train loss: 14706.695178616432
INFO:root:final train perplexity: 4.265477657318115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it]
INFO:root:eval mean loss: 22451.666085379464
INFO:root:eval perplexity: 10.212891578674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [18:04:39<32:42, 327.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14678.800814924569
INFO:root:current train perplexity4.260239124298096
INFO:root:current mean train loss 14704.263227982954
INFO:root:current train perplexity4.2635674476623535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.23s/it]
INFO:root:final mean train loss: 14704.439279863911
INFO:root:final train perplexity: 4.264528274536133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it]
INFO:root:eval mean loss: 22454.64039248512
INFO:root:eval perplexity: 10.216035842895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [18:10:24<27:42, 332.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14781.26800380609
INFO:root:current train perplexity4.282705307006836
INFO:root:current mean train loss 14714.024919907824
INFO:root:current train perplexity4.265578746795654
INFO:root:current mean train loss 14717.890179622123
INFO:root:current train perplexity4.265463352203369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.99s/it]
INFO:root:final mean train loss: 14706.201026178176
INFO:root:final train perplexity: 4.265270233154297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.18s/it]
INFO:root:eval mean loss: 22457.303757440477
INFO:root:eval perplexity: 10.218853950500488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [18:15:55<22:07, 331.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14741.599899124312
INFO:root:current train perplexity4.26912784576416
INFO:root:current mean train loss 14729.928726276177
INFO:root:current train perplexity4.269776344299316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.80s/it]
INFO:root:final mean train loss: 14705.717056766633
INFO:root:final train perplexity: 4.265066623687744
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it]
INFO:root:eval mean loss: 22454.554664248513
INFO:root:eval perplexity: 10.215943336486816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [18:21:40<16:47, 335.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14712.669694767443
INFO:root:current train perplexity4.25807523727417
INFO:root:current mean train loss 14707.797209626311
INFO:root:current train perplexity4.256134986877441
INFO:root:current mean train loss 14712.066779996141
INFO:root:current train perplexity4.262884616851807


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.48s/it]
INFO:root:final mean train loss: 14699.43996109501
INFO:root:final train perplexity: 4.262426376342773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it]
INFO:root:eval mean loss: 22454.404599144345
INFO:root:eval perplexity: 10.215785026550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [18:27:11<11:08, 334.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14726.153525904605
INFO:root:current train perplexity4.26996374130249
INFO:root:current mean train loss 14714.465985576922
INFO:root:current train perplexity4.26362419128418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.01s/it]
INFO:root:final mean train loss: 14696.27406360257
INFO:root:final train perplexity: 4.2610955238342285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.48s/it]
INFO:root:eval mean loss: 22455.325613839286
INFO:root:eval perplexity: 10.21675968170166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [18:32:51<05:36, 336.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14692.543841422872
INFO:root:current train perplexity4.254931449890137
INFO:root:current mean train loss 14703.711561968537
INFO:root:current train perplexity4.263675212860107
INFO:root:current mean train loss 14714.198941991397
INFO:root:current train perplexity4.263877868652344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.04s/it]
INFO:root:final mean train loss: 14702.446474136845
INFO:root:final train perplexity: 4.26369047164917
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it]
INFO:root:eval mean loss: 22455.36937313988
INFO:root:eval perplexity: 10.216805458068848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_16/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:38:19<00:00, 333.63s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:38:19<00:00, 335.50s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.87s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.87s/it]
INFO:root:eval mean loss: 22455.36937313988
INFO:root:eval perplexity: 10.216805458068848
INFO:root:evalaution complete
INFO:root:save model final: small_window_16/final
