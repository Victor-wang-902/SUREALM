INFO:root:Output: allminil16_minilml12
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11417.847917653093
INFO:root:current train perplexity8518.8076171875
INFO:root:current mean train loss 9454.48603123037
INFO:root:current train perplexity1786.42431640625
INFO:root:current mean train loss 8300.878253030936
INFO:root:current train perplexity716.394287109375
INFO:root:current mean train loss 7520.269258350955
INFO:root:current train perplexity380.4151611328125
INFO:root:current mean train loss 6937.014799618769
INFO:root:current train perplexity239.94737243652344
INFO:root:current mean train loss 6487.86792644316
INFO:root:current train perplexity168.34054565429688
INFO:root:current mean train loss 6133.597019528456
INFO:root:current train perplexity126.95933532714844
INFO:root:current mean train loss 5852.727136337414
INFO:root:current train perplexity101.17066955566406
INFO:root:current mean train loss 5614.660117958756
INFO:root:current train perplexity83.90611267089844
INFO:root:current mean train loss 5411.02465600366
INFO:root:current train perplexity71.53602600097656
INFO:root:current mean train loss 5237.636423737488
INFO:root:current train perplexity62.273651123046875
INFO:root:current mean train loss 5086.971376700636
INFO:root:current train perplexity55.297237396240234
INFO:root:current mean train loss 4953.301214463349
INFO:root:current train perplexity49.743385314941406
INFO:root:current mean train loss 4835.056142745655
INFO:root:current train perplexity45.32184600830078
INFO:root:current mean train loss 4728.122457777841
INFO:root:current train perplexity41.683860778808594
INFO:root:current mean train loss 4632.646954486935
INFO:root:current train perplexity38.62320327758789
INFO:root:current mean train loss 4544.993118654355
INFO:root:current train perplexity36.03691864013672
INFO:root:current mean train loss 4466.732015562031
INFO:root:current train perplexity33.86896514892578
INFO:root:current mean train loss 4394.323141522882
INFO:root:current train perplexity31.979042053222656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.90s/it]
INFO:root:final mean train loss: 4335.893130242313
INFO:root:final train perplexity: 30.555543899536133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.42s/it]
INFO:root:eval mean loss: 2831.531123600953
INFO:root:eval perplexity: 9.874701499938965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 3125.963783210051
INFO:root:eval perplexity: 12.890607833862305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/1
  0%|          | 1/200 [10:39<35:21:03, 639.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2989.839645385742
INFO:root:current train perplexity10.570151329040527
INFO:root:current mean train loss 3026.117532664332
INFO:root:current train perplexity10.732891082763672
INFO:root:current mean train loss 3005.0965881347656
INFO:root:current train perplexity10.592018127441406
INFO:root:current mean train loss 2988.678920311264
INFO:root:current train perplexity10.46011734008789
INFO:root:current mean train loss 2967.668347285344
INFO:root:current train perplexity10.29694938659668
INFO:root:current mean train loss 2952.586364272953
INFO:root:current train perplexity10.20634937286377
INFO:root:current mean train loss 2940.795922217431
INFO:root:current train perplexity10.125478744506836
INFO:root:current mean train loss 2926.546385354836
INFO:root:current train perplexity10.025254249572754
INFO:root:current mean train loss 2912.415688309015
INFO:root:current train perplexity9.926803588867188
INFO:root:current mean train loss 2905.804832225283
INFO:root:current train perplexity9.861547470092773
INFO:root:current mean train loss 2892.71780443567
INFO:root:current train perplexity9.764464378356934
INFO:root:current mean train loss 2881.602711448533
INFO:root:current train perplexity9.685224533081055
INFO:root:current mean train loss 2871.6304835269325
INFO:root:current train perplexity9.618078231811523
INFO:root:current mean train loss 2863.071604441727
INFO:root:current train perplexity9.54896068572998
INFO:root:current mean train loss 2856.665023717503
INFO:root:current train perplexity9.490201950073242
INFO:root:current mean train loss 2846.623530808099
INFO:root:current train perplexity9.426218032836914
INFO:root:current mean train loss 2837.5309532845376
INFO:root:current train perplexity9.364847183227539
INFO:root:current mean train loss 2829.6664395988128
INFO:root:current train perplexity9.299527168273926
INFO:root:current mean train loss 2819.9241548109685
INFO:root:current train perplexity9.23137378692627
INFO:root:current mean train loss 2812.612916950393
INFO:root:current train perplexity9.182624816894531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:34<00:00, 574.61s/it]
INFO:root:final mean train loss: 2806.63626863496
INFO:root:final train perplexity: 9.147516250610352
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.40s/it]
INFO:root:eval mean loss: 2504.4488170434397
INFO:root:eval perplexity: 7.579529762268066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.02s/it]
INFO:root:eval mean loss: 2841.894153784353
INFO:root:eval perplexity: 10.218289375305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/2
  1%|          | 2/200 [21:48<36:06:50, 656.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2616.064667672822
INFO:root:current train perplexity7.922219276428223
INFO:root:current mean train loss 2631.363106863839
INFO:root:current train perplexity7.96776819229126
INFO:root:current mean train loss 2621.659976026019
INFO:root:current train perplexity7.940980434417725
INFO:root:current mean train loss 2624.8023282071135
INFO:root:current train perplexity7.913835525512695
INFO:root:current mean train loss 2622.9115675294097
INFO:root:current train perplexity7.9103288650512695
INFO:root:current mean train loss 2619.4599302481533
INFO:root:current train perplexity7.879773139953613
INFO:root:current mean train loss 2613.2479296257898
INFO:root:current train perplexity7.8516693115234375
INFO:root:current mean train loss 2611.216312257525
INFO:root:current train perplexity7.828311920166016
INFO:root:current mean train loss 2607.556225908332
INFO:root:current train perplexity7.80534029006958
INFO:root:current mean train loss 2601.492963882888
INFO:root:current train perplexity7.773306846618652
INFO:root:current mean train loss 2594.6948532887372
INFO:root:current train perplexity7.739336013793945
INFO:root:current mean train loss 2588.6079373069283
INFO:root:current train perplexity7.704277515411377
INFO:root:current mean train loss 2584.908924458574
INFO:root:current train perplexity7.684410095214844
INFO:root:current mean train loss 2580.8372743210216
INFO:root:current train perplexity7.656229496002197
INFO:root:current mean train loss 2577.213061847141
INFO:root:current train perplexity7.631413459777832
INFO:root:current mean train loss 2572.016351210861
INFO:root:current train perplexity7.601380348205566
INFO:root:current mean train loss 2568.6655028250343
INFO:root:current train perplexity7.576387882232666
INFO:root:current mean train loss 2565.5249492559415
INFO:root:current train perplexity7.556952953338623
INFO:root:current mean train loss 2563.0055608921084
INFO:root:current train perplexity7.542808532714844
INFO:root:current mean train loss 2560.132699081334
INFO:root:current train perplexity7.524566650390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.85s/it]
INFO:root:final mean train loss: 2557.8484531235226
INFO:root:final train perplexity: 7.517795562744141
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2362.9328539692765
INFO:root:eval perplexity: 6.759853363037109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2720.8120229734595
INFO:root:eval perplexity: 9.254914283752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/3
  2%|â–         | 3/200 [32:21<35:20:54, 645.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2438.5625341796876
INFO:root:current train perplexity6.9263739585876465
INFO:root:current mean train loss 2453.184413248698
INFO:root:current train perplexity6.995257377624512
INFO:root:current mean train loss 2464.769441894531
INFO:root:current train perplexity6.989701747894287
INFO:root:current mean train loss 2468.554485560826
INFO:root:current train perplexity6.969827175140381
INFO:root:current mean train loss 2467.5987901475696
INFO:root:current train perplexity6.967257022857666
INFO:root:current mean train loss 2461.2279256924717
INFO:root:current train perplexity6.948663234710693
INFO:root:current mean train loss 2456.8548482572114
INFO:root:current train perplexity6.939357280731201
INFO:root:current mean train loss 2451.7176591796874
INFO:root:current train perplexity6.9277143478393555
INFO:root:current mean train loss 2450.34730669807
INFO:root:current train perplexity6.9070329666137695
INFO:root:current mean train loss 2446.725796412418
INFO:root:current train perplexity6.886904239654541
INFO:root:current mean train loss 2441.0350825427827
INFO:root:current train perplexity6.873121738433838
INFO:root:current mean train loss 2440.806207753057
INFO:root:current train perplexity6.868977069854736
INFO:root:current mean train loss 2440.7272302734377
INFO:root:current train perplexity6.862682342529297
INFO:root:current mean train loss 2438.672238679109
INFO:root:current train perplexity6.848940372467041
INFO:root:current mean train loss 2437.4341943359377
INFO:root:current train perplexity6.833850860595703
INFO:root:current mean train loss 2435.4978487273183
INFO:root:current train perplexity6.827792644500732
INFO:root:current mean train loss 2433.930295632102
INFO:root:current train perplexity6.8152337074279785
INFO:root:current mean train loss 2432.1855771484375
INFO:root:current train perplexity6.803752422332764
INFO:root:current mean train loss 2429.4934609243032
INFO:root:current train perplexity6.794096946716309
INFO:root:current mean train loss 2427.4832384940905
INFO:root:current train perplexity6.7803778648376465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.75s/it]
INFO:root:final mean train loss: 2426.0844999574015
INFO:root:final train perplexity: 6.775792121887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 2273.082207429494
INFO:root:eval perplexity: 6.286065578460693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2639.7234782766786
INFO:root:eval perplexity: 8.661069869995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/4
  2%|â–         | 4/200 [42:59<34:59:55, 642.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2379.843556873834
INFO:root:current train perplexity6.465912342071533
INFO:root:current mean train loss 2360.214223164998
INFO:root:current train perplexity6.390019416809082
INFO:root:current mean train loss 2358.706968157479
INFO:root:current train perplexity6.411500930786133
INFO:root:current mean train loss 2353.779442893712
INFO:root:current train perplexity6.394356727600098
INFO:root:current mean train loss 2355.623757601295
INFO:root:current train perplexity6.413629055023193
INFO:root:current mean train loss 2357.520685428034
INFO:root:current train perplexity6.409133434295654
INFO:root:current mean train loss 2354.462990733637
INFO:root:current train perplexity6.403841018676758
INFO:root:current mean train loss 2357.4379935332972
INFO:root:current train perplexity6.407107353210449
INFO:root:current mean train loss 2355.1820303489044
INFO:root:current train perplexity6.403773784637451
INFO:root:current mean train loss 2353.8382300738836
INFO:root:current train perplexity6.393576145172119
INFO:root:current mean train loss 2353.415404129386
INFO:root:current train perplexity6.3901190757751465
INFO:root:current mean train loss 2350.9678988550704
INFO:root:current train perplexity6.3764777183532715
INFO:root:current mean train loss 2351.369441031657
INFO:root:current train perplexity6.372774600982666
INFO:root:current mean train loss 2348.664286369988
INFO:root:current train perplexity6.366466999053955
INFO:root:current mean train loss 2346.4319209623436
INFO:root:current train perplexity6.353799819946289
INFO:root:current mean train loss 2345.884817273128
INFO:root:current train perplexity6.348400115966797
INFO:root:current mean train loss 2342.7340254117144
INFO:root:current train perplexity6.340619087219238
INFO:root:current mean train loss 2343.1320546554452
INFO:root:current train perplexity6.336361885070801
INFO:root:current mean train loss 2341.668011379804
INFO:root:current train perplexity6.333515644073486
INFO:root:current mean train loss 2340.143975696651
INFO:root:current train perplexity6.327557563781738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.15s/it]
INFO:root:final mean train loss: 2338.9648364861087
INFO:root:final train perplexity: 6.325875759124756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2218.8896025529143
INFO:root:eval perplexity: 6.016510963439941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2596.378583759281
INFO:root:eval perplexity: 8.35942554473877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/5
  2%|â–Ž         | 5/200 [53:24<34:28:38, 636.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2287.4893798828125
INFO:root:current train perplexity6.128498554229736
INFO:root:current mean train loss 2305.1137708581014
INFO:root:current train perplexity6.126919269561768
INFO:root:current mean train loss 2295.5660116706094
INFO:root:current train perplexity6.102086067199707
INFO:root:current mean train loss 2294.616495768229
INFO:root:current train perplexity6.108645915985107
INFO:root:current mean train loss 2289.211925664224
INFO:root:current train perplexity6.097896099090576
INFO:root:current mean train loss 2293.35806086292
INFO:root:current train perplexity6.098194122314453
INFO:root:current mean train loss 2288.785315441109
INFO:root:current train perplexity6.088857173919678
INFO:root:current mean train loss 2286.083782118194
INFO:root:current train perplexity6.07659387588501
INFO:root:current mean train loss 2285.7432147410123
INFO:root:current train perplexity6.069650173187256
INFO:root:current mean train loss 2283.134529299852
INFO:root:current train perplexity6.063199520111084
INFO:root:current mean train loss 2282.6184236308304
INFO:root:current train perplexity6.057345390319824
INFO:root:current mean train loss 2282.2480703817832
INFO:root:current train perplexity6.050990104675293
INFO:root:current mean train loss 2281.785245235835
INFO:root:current train perplexity6.043288230895996
INFO:root:current mean train loss 2280.8168067711626
INFO:root:current train perplexity6.039010524749756
INFO:root:current mean train loss 2278.2797778353215
INFO:root:current train perplexity6.035722732543945
INFO:root:current mean train loss 2276.6334869693023
INFO:root:current train perplexity6.029507160186768
INFO:root:current mean train loss 2276.421230288979
INFO:root:current train perplexity6.025136470794678
INFO:root:current mean train loss 2276.282021150461
INFO:root:current train perplexity6.020753860473633
INFO:root:current mean train loss 2275.3148497239295
INFO:root:current train perplexity6.01723051071167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.63s/it]
INFO:root:final mean train loss: 2275.372066372762
INFO:root:final train perplexity: 6.016437530517578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2174.4547101825688
INFO:root:eval perplexity: 5.80413818359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2556.265181304715
INFO:root:eval perplexity: 8.08963680267334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/6
  3%|â–Ž         | 6/200 [1:03:49<34:05:11, 632.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2297.72705078125
INFO:root:current train perplexity6.088423728942871
INFO:root:current mean train loss 2215.1077602877476
INFO:root:current train perplexity5.769402503967285
INFO:root:current mean train loss 2221.858828416511
INFO:root:current train perplexity5.800705909729004
INFO:root:current mean train loss 2224.526479930181
INFO:root:current train perplexity5.790785789489746
INFO:root:current mean train loss 2226.891895931558
INFO:root:current train perplexity5.80117130279541
INFO:root:current mean train loss 2232.440516184428
INFO:root:current train perplexity5.804167747497559
INFO:root:current mean train loss 2233.617907735155
INFO:root:current train perplexity5.805882930755615
INFO:root:current mean train loss 2235.278653089058
INFO:root:current train perplexity5.812281608581543
INFO:root:current mean train loss 2233.9991392595193
INFO:root:current train perplexity5.806482315063477
INFO:root:current mean train loss 2234.2762482332996
INFO:root:current train perplexity5.807872295379639
INFO:root:current mean train loss 2231.761140348909
INFO:root:current train perplexity5.8063764572143555
INFO:root:current mean train loss 2232.2234755956943
INFO:root:current train perplexity5.805012226104736
INFO:root:current mean train loss 2231.252834247014
INFO:root:current train perplexity5.8040690422058105
INFO:root:current mean train loss 2229.675157011884
INFO:root:current train perplexity5.797883987426758
INFO:root:current mean train loss 2230.027627709421
INFO:root:current train perplexity5.79828405380249
INFO:root:current mean train loss 2229.316441057524
INFO:root:current train perplexity5.7983574867248535
INFO:root:current mean train loss 2228.5998300317674
INFO:root:current train perplexity5.796141624450684
INFO:root:current mean train loss 2226.2318362819665
INFO:root:current train perplexity5.790165901184082
INFO:root:current mean train loss 2225.869179665811
INFO:root:current train perplexity5.787524223327637
INFO:root:current mean train loss 2226.6676892276064
INFO:root:current train perplexity5.785543918609619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.75s/it]
INFO:root:final mean train loss: 2225.080716116285
INFO:root:final train perplexity: 5.782479286193848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2143.9336123635585
INFO:root:eval perplexity: 5.662624835968018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2531.531472929826
INFO:root:eval perplexity: 7.927645683288574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/7
  4%|â–Ž         | 7/200 [1:14:18<33:50:39, 631.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2282.767184787326
INFO:root:current train perplexity5.680534839630127
INFO:root:current mean train loss 2200.8101092839647
INFO:root:current train perplexity5.645732879638672
INFO:root:current mean train loss 2197.114057348409
INFO:root:current train perplexity5.6112060546875
INFO:root:current mean train loss 2185.3803357778106
INFO:root:current train perplexity5.590031623840332
INFO:root:current mean train loss 2195.4262639825993
INFO:root:current train perplexity5.623684883117676
INFO:root:current mean train loss 2193.5426553262246
INFO:root:current train perplexity5.612398147583008
INFO:root:current mean train loss 2194.5158977817177
INFO:root:current train perplexity5.614840030670166
INFO:root:current mean train loss 2195.504791514787
INFO:root:current train perplexity5.619333267211914
INFO:root:current mean train loss 2190.351249116557
INFO:root:current train perplexity5.614721298217773
INFO:root:current mean train loss 2191.7552897135415
INFO:root:current train perplexity5.615311145782471
INFO:root:current mean train loss 2190.5916666506782
INFO:root:current train perplexity5.613977909088135
INFO:root:current mean train loss 2189.3125781774093
INFO:root:current train perplexity5.61449670791626
INFO:root:current mean train loss 2187.322666312282
INFO:root:current train perplexity5.611023426055908
INFO:root:current mean train loss 2188.7006024605225
INFO:root:current train perplexity5.612793922424316
INFO:root:current mean train loss 2188.860976032209
INFO:root:current train perplexity5.614307880401611
INFO:root:current mean train loss 2188.1473082289867
INFO:root:current train perplexity5.612776279449463
INFO:root:current mean train loss 2186.6759772565956
INFO:root:current train perplexity5.606403827667236
INFO:root:current mean train loss 2187.3220555901667
INFO:root:current train perplexity5.607339859008789
INFO:root:current mean train loss 2186.2472822233394
INFO:root:current train perplexity5.605263710021973
INFO:root:current mean train loss 2185.0506131010084
INFO:root:current train perplexity5.60196590423584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.24s/it]
INFO:root:final mean train loss: 2184.159104617028
INFO:root:final train perplexity: 5.598838806152344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2121.0432973009474
INFO:root:eval perplexity: 5.558762073516846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2512.2937509523217
INFO:root:eval perplexity: 7.803894519805908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/8
  4%|â–         | 8/200 [1:24:46<33:36:32, 630.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2100.8451799665177
INFO:root:current train perplexity5.273331165313721
INFO:root:current mean train loss 2137.598971896701
INFO:root:current train perplexity5.415833473205566
INFO:root:current mean train loss 2133.1975227518283
INFO:root:current train perplexity5.422016143798828
INFO:root:current mean train loss 2145.3945596723415
INFO:root:current train perplexity5.434806823730469
INFO:root:current mean train loss 2152.168731478987
INFO:root:current train perplexity5.459205627441406
INFO:root:current mean train loss 2150.059347847912
INFO:root:current train perplexity5.446390628814697
INFO:root:current mean train loss 2149.8235118956077
INFO:root:current train perplexity5.439424991607666
INFO:root:current mean train loss 2148.921914859694
INFO:root:current train perplexity5.44155216217041
INFO:root:current mean train loss 2147.4208931745884
INFO:root:current train perplexity5.441328048706055
INFO:root:current mean train loss 2150.4918603254514
INFO:root:current train perplexity5.442497730255127
INFO:root:current mean train loss 2151.2815871971243
INFO:root:current train perplexity5.444372177124023
INFO:root:current mean train loss 2151.694850783831
INFO:root:current train perplexity5.448577404022217
INFO:root:current mean train loss 2149.181694494085
INFO:root:current train perplexity5.44641637802124
INFO:root:current mean train loss 2147.6240025895363
INFO:root:current train perplexity5.443604469299316
INFO:root:current mean train loss 2148.120622056702
INFO:root:current train perplexity5.4426751136779785
INFO:root:current mean train loss 2149.090546270613
INFO:root:current train perplexity5.4458327293396
INFO:root:current mean train loss 2149.912948412414
INFO:root:current train perplexity5.4471564292907715
INFO:root:current mean train loss 2149.8463767983385
INFO:root:current train perplexity5.447893142700195
INFO:root:current mean train loss 2149.201774908996
INFO:root:current train perplexity5.446162700653076
INFO:root:current mean train loss 2149.87818398488
INFO:root:current train perplexity5.446461200714111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.03s/it]
INFO:root:final mean train loss: 2148.8659559933753
INFO:root:final train perplexity: 5.44514799118042
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2097.9088108793217
INFO:root:eval perplexity: 5.455725193023682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2494.74047158965
INFO:root:eval perplexity: 7.692664623260498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/9
  4%|â–         | 9/200 [1:35:11<33:21:42, 628.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2086.5962688739482
INFO:root:current train perplexity5.309556484222412
INFO:root:current mean train loss 2122.16468007941
INFO:root:current train perplexity5.370131492614746
INFO:root:current mean train loss 2133.094988626147
INFO:root:current train perplexity5.365592002868652
INFO:root:current mean train loss 2126.0507049560547
INFO:root:current train perplexity5.352542877197266
INFO:root:current mean train loss 2123.9470503815505
INFO:root:current train perplexity5.348624229431152
INFO:root:current mean train loss 2120.7997171153193
INFO:root:current train perplexity5.336585521697998
INFO:root:current mean train loss 2120.6284039269194
INFO:root:current train perplexity5.335293769836426
INFO:root:current mean train loss 2120.104605979108
INFO:root:current train perplexity5.331187725067139
INFO:root:current mean train loss 2122.9690000149008
INFO:root:current train perplexity5.332719802856445
INFO:root:current mean train loss 2121.0450186849644
INFO:root:current train perplexity5.328457355499268
INFO:root:current mean train loss 2121.1599607286344
INFO:root:current train perplexity5.326289176940918
INFO:root:current mean train loss 2122.4603078630234
INFO:root:current train perplexity5.329060077667236
INFO:root:current mean train loss 2120.478912841017
INFO:root:current train perplexity5.32763147354126
INFO:root:current mean train loss 2121.3262681227466
INFO:root:current train perplexity5.324259281158447
INFO:root:current mean train loss 2121.686247013817
INFO:root:current train perplexity5.324174880981445
INFO:root:current mean train loss 2121.038486126772
INFO:root:current train perplexity5.323069095611572
INFO:root:current mean train loss 2121.989576806168
INFO:root:current train perplexity5.324578285217285
INFO:root:current mean train loss 2122.0720714412323
INFO:root:current train perplexity5.324426174163818
INFO:root:current mean train loss 2120.865105317942
INFO:root:current train perplexity5.3214311599731445
INFO:root:current mean train loss 2121.078272897689
INFO:root:current train perplexity5.321401119232178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.21s/it]
INFO:root:final mean train loss: 2119.1961895533423
INFO:root:final train perplexity: 5.319212913513184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 2082.7680343736147
INFO:root:eval perplexity: 5.389327526092529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.41s/it]
INFO:root:eval mean loss: 2482.636023122368
INFO:root:eval perplexity: 7.61688756942749
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/10
  5%|â–Œ         | 10/200 [1:45:50<33:20:56, 631.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.254288383152
INFO:root:current train perplexity5.232472896575928
INFO:root:current mean train loss 2111.3125043338573
INFO:root:current train perplexity5.240413188934326
INFO:root:current mean train loss 2108.200193951121
INFO:root:current train perplexity5.229320049285889
INFO:root:current mean train loss 2103.0106168090488
INFO:root:current train perplexity5.2176103591918945
INFO:root:current mean train loss 2100.9657513388693
INFO:root:current train perplexity5.216488361358643
INFO:root:current mean train loss 2096.5928193479513
INFO:root:current train perplexity5.214427947998047
INFO:root:current mean train loss 2094.067219322216
INFO:root:current train perplexity5.205260753631592
INFO:root:current mean train loss 2096.076364107963
INFO:root:current train perplexity5.214860916137695
INFO:root:current mean train loss 2094.832170738861
INFO:root:current train perplexity5.214335918426514
INFO:root:current mean train loss 2094.4885815757225
INFO:root:current train perplexity5.213862895965576
INFO:root:current mean train loss 2093.353082269681
INFO:root:current train perplexity5.21063756942749
INFO:root:current mean train loss 2094.9767706147413
INFO:root:current train perplexity5.21060848236084
INFO:root:current mean train loss 2094.6732794338554
INFO:root:current train perplexity5.2131428718566895
INFO:root:current mean train loss 2094.6117417730493
INFO:root:current train perplexity5.209699630737305
INFO:root:current mean train loss 2095.1879100033507
INFO:root:current train perplexity5.21363639831543
INFO:root:current mean train loss 2094.324702752176
INFO:root:current train perplexity5.211238861083984
INFO:root:current mean train loss 2093.294044051219
INFO:root:current train perplexity5.208399295806885
INFO:root:current mean train loss 2093.3369260694158
INFO:root:current train perplexity5.206715106964111
INFO:root:current mean train loss 2092.7509960911375
INFO:root:current train perplexity5.204224586486816
INFO:root:current mean train loss 2093.303021168939
INFO:root:current train perplexity5.209819793701172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.12s/it]
INFO:root:final mean train loss: 2092.6703018750195
INFO:root:final train perplexity: 5.20909309387207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2067.7560268970246
INFO:root:eval perplexity: 5.324291229248047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2470.3720642522717
INFO:root:eval perplexity: 7.5408735275268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/11
  6%|â–Œ         | 11/200 [1:56:27<33:14:50, 633.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2073.785335097202
INFO:root:current train perplexity5.070321083068848
INFO:root:current mean train loss 2059.3221757129954
INFO:root:current train perplexity5.071573734283447
INFO:root:current mean train loss 2059.827389163571
INFO:root:current train perplexity5.075543403625488
INFO:root:current mean train loss 2062.8057083367066
INFO:root:current train perplexity5.087847709655762
INFO:root:current mean train loss 2058.4075277195057
INFO:root:current train perplexity5.095280647277832
INFO:root:current mean train loss 2062.993549646371
INFO:root:current train perplexity5.0997185707092285
INFO:root:current mean train loss 2064.8285752010065
INFO:root:current train perplexity5.092895984649658
INFO:root:current mean train loss 2065.2379961086594
INFO:root:current train perplexity5.091000556945801
INFO:root:current mean train loss 2065.66931097233
INFO:root:current train perplexity5.092859268188477
INFO:root:current mean train loss 2067.509311637337
INFO:root:current train perplexity5.096681594848633
INFO:root:current mean train loss 2068.807779835513
INFO:root:current train perplexity5.103217124938965
INFO:root:current mean train loss 2069.563483149768
INFO:root:current train perplexity5.105188369750977
INFO:root:current mean train loss 2069.598864423357
INFO:root:current train perplexity5.105350494384766
INFO:root:current mean train loss 2069.3449926335056
INFO:root:current train perplexity5.1074090003967285
INFO:root:current mean train loss 2068.0381856638523
INFO:root:current train perplexity5.108911991119385
INFO:root:current mean train loss 2069.724552111247
INFO:root:current train perplexity5.111632347106934
INFO:root:current mean train loss 2068.902294516422
INFO:root:current train perplexity5.1124091148376465
INFO:root:current mean train loss 2069.336959650909
INFO:root:current train perplexity5.113662242889404
INFO:root:current mean train loss 2069.103514524684
INFO:root:current train perplexity5.114735126495361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.90s/it]
INFO:root:final mean train loss: 2069.380988986217
INFO:root:final train perplexity: 5.114288330078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2056.3698146089596
INFO:root:eval perplexity: 5.275487422943115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it]
INFO:root:eval mean loss: 2461.3437417754044
INFO:root:eval perplexity: 7.4854021072387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/12
  6%|â–Œ         | 12/200 [2:06:50<32:54:37, 630.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2093.784952799479
INFO:root:current train perplexity4.848292350769043
INFO:root:current mean train loss 2049.8375279695083
INFO:root:current train perplexity5.038514137268066
INFO:root:current mean train loss 2041.0519839131773
INFO:root:current train perplexity5.002718448638916
INFO:root:current mean train loss 2045.2011879898928
INFO:root:current train perplexity5.0063371658325195
INFO:root:current mean train loss 2044.3404668235305
INFO:root:current train perplexity5.0065131187438965
INFO:root:current mean train loss 2044.7555392741208
INFO:root:current train perplexity5.010848522186279
INFO:root:current mean train loss 2048.398387700171
INFO:root:current train perplexity5.027494430541992
INFO:root:current mean train loss 2045.9547324038163
INFO:root:current train perplexity5.016702175140381
INFO:root:current mean train loss 2045.9695795612645
INFO:root:current train perplexity5.016939163208008
INFO:root:current mean train loss 2046.679237610742
INFO:root:current train perplexity5.021717548370361
INFO:root:current mean train loss 2045.5062393386247
INFO:root:current train perplexity5.0164690017700195
INFO:root:current mean train loss 2045.6268287305927
INFO:root:current train perplexity5.022385120391846
INFO:root:current mean train loss 2044.3200398458607
INFO:root:current train perplexity5.0209503173828125
INFO:root:current mean train loss 2044.9184223681527
INFO:root:current train perplexity5.022622108459473
INFO:root:current mean train loss 2046.0505335421028
INFO:root:current train perplexity5.021286487579346
INFO:root:current mean train loss 2045.8278916613388
INFO:root:current train perplexity5.019692897796631
INFO:root:current mean train loss 2047.0402476405325
INFO:root:current train perplexity5.025064468383789
INFO:root:current mean train loss 2047.6582657729466
INFO:root:current train perplexity5.026716709136963
INFO:root:current mean train loss 2047.710201083589
INFO:root:current train perplexity5.025780200958252
INFO:root:current mean train loss 2048.668083251055
INFO:root:current train perplexity5.027740478515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it]
INFO:root:final mean train loss: 2047.487022473003
INFO:root:final train perplexity: 5.026739120483398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2046.259037964733
INFO:root:eval perplexity: 5.2325263023376465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2455.432691641733
INFO:root:eval perplexity: 7.449301719665527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/13
  6%|â–‹         | 13/200 [2:17:13<32:37:16, 628.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1986.9501037597656
INFO:root:current train perplexity4.859922885894775
INFO:root:current mean train loss 2012.1194610595703
INFO:root:current train perplexity4.876912593841553
INFO:root:current mean train loss 2014.194785378196
INFO:root:current train perplexity4.915829658508301
INFO:root:current mean train loss 2017.6063892364502
INFO:root:current train perplexity4.912487030029297
INFO:root:current mean train loss 2019.0401602608817
INFO:root:current train perplexity4.915584087371826
INFO:root:current mean train loss 2024.364850792518
INFO:root:current train perplexity4.924627780914307
INFO:root:current mean train loss 2021.282547095514
INFO:root:current train perplexity4.917026519775391
INFO:root:current mean train loss 2020.2710695054795
INFO:root:current train perplexity4.919313907623291
INFO:root:current mean train loss 2019.5877819526486
INFO:root:current train perplexity4.925011157989502
INFO:root:current mean train loss 2019.6171401314114
INFO:root:current train perplexity4.929370403289795
INFO:root:current mean train loss 2021.393391568053
INFO:root:current train perplexity4.932656288146973
INFO:root:current mean train loss 2022.2844457353865
INFO:root:current train perplexity4.936557769775391
INFO:root:current mean train loss 2022.7029748134926
INFO:root:current train perplexity4.9338579177856445
INFO:root:current mean train loss 2024.8642162900983
INFO:root:current train perplexity4.935615539550781
INFO:root:current mean train loss 2025.37373046875
INFO:root:current train perplexity4.9413371086120605
INFO:root:current mean train loss 2024.4505864996659
INFO:root:current train perplexity4.9426445960998535
INFO:root:current mean train loss 2025.0783075780043
INFO:root:current train perplexity4.944013595581055
INFO:root:current mean train loss 2026.877046381041
INFO:root:current train perplexity4.945037364959717
INFO:root:current mean train loss 2026.2384536910843
INFO:root:current train perplexity4.9449262619018555
INFO:root:current mean train loss 2026.9135417938232
INFO:root:current train perplexity4.9482293128967285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.50s/it]
INFO:root:final mean train loss: 2027.804620524458
INFO:root:final train perplexity: 4.949313163757324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 2039.4571386026153
INFO:root:eval perplexity: 5.203821659088135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2452.4486075326904
INFO:root:eval perplexity: 7.4311442375183105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/14
  7%|â–‹         | 14/200 [2:27:53<32:37:54, 631.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.4434484533363
INFO:root:current train perplexity4.79623556137085
INFO:root:current mean train loss 2018.455880046761
INFO:root:current train perplexity4.84930944442749
INFO:root:current mean train loss 2007.869685563357
INFO:root:current train perplexity4.843461036682129
INFO:root:current mean train loss 2005.938565670206
INFO:root:current train perplexity4.836371421813965
INFO:root:current mean train loss 2007.385399720216
INFO:root:current train perplexity4.844017028808594
INFO:root:current mean train loss 2010.1386941522637
INFO:root:current train perplexity4.85575008392334
INFO:root:current mean train loss 2007.4758013331534
INFO:root:current train perplexity4.8548712730407715
INFO:root:current mean train loss 2006.6108247712962
INFO:root:current train perplexity4.856579303741455
INFO:root:current mean train loss 2007.0288638681209
INFO:root:current train perplexity4.855664253234863
INFO:root:current mean train loss 2004.8238762496248
INFO:root:current train perplexity4.853386878967285
INFO:root:current mean train loss 2004.0904619884584
INFO:root:current train perplexity4.855329513549805
INFO:root:current mean train loss 2004.8617048573892
INFO:root:current train perplexity4.8592352867126465
INFO:root:current mean train loss 2005.4344338345354
INFO:root:current train perplexity4.861343860626221
INFO:root:current mean train loss 2006.7717543539934
INFO:root:current train perplexity4.865421772003174
INFO:root:current mean train loss 2005.8047471335137
INFO:root:current train perplexity4.862392902374268
INFO:root:current mean train loss 2007.7160191036464
INFO:root:current train perplexity4.867105484008789
INFO:root:current mean train loss 2008.0915097823286
INFO:root:current train perplexity4.868780136108398
INFO:root:current mean train loss 2008.5367416882557
INFO:root:current train perplexity4.871164321899414
INFO:root:current mean train loss 2008.5851123791126
INFO:root:current train perplexity4.872488975524902
INFO:root:current mean train loss 2009.121876903213
INFO:root:current train perplexity4.875809192657471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.67s/it]
INFO:root:final mean train loss: 2009.6390259589323
INFO:root:final train perplexity: 4.878911972045898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2029.663542186115
INFO:root:eval perplexity: 5.162766933441162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2443.852039093667
INFO:root:eval perplexity: 7.379082202911377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/15
  8%|â–Š         | 15/200 [2:38:17<32:20:30, 629.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1963.104320384838
INFO:root:current train perplexity4.759433746337891
INFO:root:current mean train loss 1980.7057820109578
INFO:root:current train perplexity4.80462121963501
INFO:root:current mean train loss 1989.3986383873646
INFO:root:current train perplexity4.815547466278076
INFO:root:current mean train loss 1986.2234721210716
INFO:root:current train perplexity4.8057403564453125
INFO:root:current mean train loss 1987.3244077707702
INFO:root:current train perplexity4.796790599822998
INFO:root:current mean train loss 1992.0812999298425
INFO:root:current train perplexity4.811874866485596
INFO:root:current mean train loss 1995.8455308453388
INFO:root:current train perplexity4.818887233734131
INFO:root:current mean train loss 1992.9407939556738
INFO:root:current train perplexity4.808134078979492
INFO:root:current mean train loss 1993.170226336084
INFO:root:current train perplexity4.811861038208008
INFO:root:current mean train loss 1992.9703317958104
INFO:root:current train perplexity4.8136515617370605
INFO:root:current mean train loss 1995.9839668635852
INFO:root:current train perplexity4.816714286804199
INFO:root:current mean train loss 1993.380091410989
INFO:root:current train perplexity4.812785625457764
INFO:root:current mean train loss 1994.479652514298
INFO:root:current train perplexity4.816277027130127
INFO:root:current mean train loss 1995.8568616497992
INFO:root:current train perplexity4.815288543701172
INFO:root:current mean train loss 1995.922376965886
INFO:root:current train perplexity4.8156561851501465
INFO:root:current mean train loss 1995.044351585123
INFO:root:current train perplexity4.815750598907471
INFO:root:current mean train loss 1993.6864105187708
INFO:root:current train perplexity4.813197612762451
INFO:root:current mean train loss 1993.8581708605775
INFO:root:current train perplexity4.815145969390869
INFO:root:current mean train loss 1994.4136661994548
INFO:root:current train perplexity4.816532611846924
INFO:root:current mean train loss 1993.1765056129855
INFO:root:current train perplexity4.814167499542236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.54s/it]
INFO:root:final mean train loss: 1992.750209729478
INFO:root:final train perplexity: 4.814357280731201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 2027.7954317999224
INFO:root:eval perplexity: 5.154973030090332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2443.6344007126827
INFO:root:eval perplexity: 7.3777689933776855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/16
  8%|â–Š         | 16/200 [2:48:54<32:17:05, 631.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1998.6036411339128
INFO:root:current train perplexity4.754344940185547
INFO:root:current mean train loss 1980.9514952542488
INFO:root:current train perplexity4.745793342590332
INFO:root:current mean train loss 1979.0208821314288
INFO:root:current train perplexity4.7535905838012695
INFO:root:current mean train loss 1978.4730461511328
INFO:root:current train perplexity4.748739242553711
INFO:root:current mean train loss 1976.8767022458865
INFO:root:current train perplexity4.7544074058532715
INFO:root:current mean train loss 1975.9213969803525
INFO:root:current train perplexity4.750368595123291
INFO:root:current mean train loss 1975.7215110449074
INFO:root:current train perplexity4.743812084197998
INFO:root:current mean train loss 1976.5173716662614
INFO:root:current train perplexity4.748009204864502
INFO:root:current mean train loss 1976.1392223826779
INFO:root:current train perplexity4.748253345489502
INFO:root:current mean train loss 1975.6510132967383
INFO:root:current train perplexity4.749450206756592
INFO:root:current mean train loss 1975.2163139507104
INFO:root:current train perplexity4.751139163970947
INFO:root:current mean train loss 1974.821758892473
INFO:root:current train perplexity4.749049663543701
INFO:root:current mean train loss 1974.681091068487
INFO:root:current train perplexity4.746210098266602
INFO:root:current mean train loss 1976.0535688337663
INFO:root:current train perplexity4.749807834625244
INFO:root:current mean train loss 1976.8866368442227
INFO:root:current train perplexity4.752597332000732
INFO:root:current mean train loss 1976.546184848176
INFO:root:current train perplexity4.754281520843506
INFO:root:current mean train loss 1976.5126191920538
INFO:root:current train perplexity4.754758358001709
INFO:root:current mean train loss 1975.7720823885693
INFO:root:current train perplexity4.751533031463623
INFO:root:current mean train loss 1976.0453112473276
INFO:root:current train perplexity4.7527055740356445
INFO:root:current mean train loss 1977.1599043057934
INFO:root:current train perplexity4.753266334533691

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it]
INFO:root:final mean train loss: 1976.9241085850826
INFO:root:final train perplexity: 4.754641056060791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2019.2592903299535
INFO:root:eval perplexity: 5.119508266448975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 2438.493648447889
INFO:root:eval perplexity: 7.346817493438721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/17
  8%|â–Š         | 17/200 [2:59:16<31:58:11, 628.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.0600419477983
INFO:root:current train perplexity4.708219051361084
INFO:root:current mean train loss 1946.7324627815408
INFO:root:current train perplexity4.661210060119629
INFO:root:current mean train loss 1950.806863149007
INFO:root:current train perplexity4.674444675445557
INFO:root:current mean train loss 1959.5808001646062
INFO:root:current train perplexity4.6841301918029785
INFO:root:current mean train loss 1954.936818857662
INFO:root:current train perplexity4.671658992767334
INFO:root:current mean train loss 1959.5931786777212
INFO:root:current train perplexity4.68369197845459
INFO:root:current mean train loss 1956.3213577270508
INFO:root:current train perplexity4.679661273956299
INFO:root:current mean train loss 1956.1360166907916
INFO:root:current train perplexity4.682191848754883
INFO:root:current mean train loss 1957.7382508698884
INFO:root:current train perplexity4.6880059242248535
INFO:root:current mean train loss 1957.551914601191
INFO:root:current train perplexity4.687633991241455
INFO:root:current mean train loss 1957.67714657503
INFO:root:current train perplexity4.687751770019531
INFO:root:current mean train loss 1959.0119046297941
INFO:root:current train perplexity4.69139289855957
INFO:root:current mean train loss 1960.2025441234896
INFO:root:current train perplexity4.6947712898254395
INFO:root:current mean train loss 1959.9372694031993
INFO:root:current train perplexity4.6960673332214355
INFO:root:current mean train loss 1959.7543403871598
INFO:root:current train perplexity4.696099758148193
INFO:root:current mean train loss 1959.2425768489502
INFO:root:current train perplexity4.694591999053955
INFO:root:current mean train loss 1959.3463989547079
INFO:root:current train perplexity4.695394515991211
INFO:root:current mean train loss 1960.2964762915967
INFO:root:current train perplexity4.694792747497559
INFO:root:current mean train loss 1962.4768279124114
INFO:root:current train perplexity4.69807243347168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.17s/it]
INFO:root:final mean train loss: 1961.6030016431168
INFO:root:final train perplexity: 4.697536468505859
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 2016.2730847081393
INFO:root:eval perplexity: 5.107158660888672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2439.669785952737
INFO:root:eval perplexity: 7.35388708114624
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/18
  9%|â–‰         | 18/200 [3:09:52<31:54:03, 631.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.867138671875
INFO:root:current train perplexity4.434020519256592
INFO:root:current mean train loss 1918.5836042131696
INFO:root:current train perplexity4.614022254943848
INFO:root:current mean train loss 1927.6208192406632
INFO:root:current train perplexity4.603213787078857
INFO:root:current mean train loss 1937.2834140464909
INFO:root:current train perplexity4.615443706512451
INFO:root:current mean train loss 1933.2083670910495
INFO:root:current train perplexity4.614502429962158
INFO:root:current mean train loss 1935.5280623936417
INFO:root:current train perplexity4.612729072570801
INFO:root:current mean train loss 1934.3748995189824
INFO:root:current train perplexity4.60998010635376
INFO:root:current mean train loss 1936.754245795933
INFO:root:current train perplexity4.61509895324707
INFO:root:current mean train loss 1939.2456650633249
INFO:root:current train perplexity4.623745918273926
INFO:root:current mean train loss 1943.5493406854282
INFO:root:current train perplexity4.631928443908691
INFO:root:current mean train loss 1943.5007525847325
INFO:root:current train perplexity4.631767749786377
INFO:root:current mean train loss 1944.0468574351314
INFO:root:current train perplexity4.633001804351807
INFO:root:current mean train loss 1944.1179688513032
INFO:root:current train perplexity4.634732723236084
INFO:root:current mean train loss 1943.8540071801665
INFO:root:current train perplexity4.634119510650635
INFO:root:current mean train loss 1944.6937924856818
INFO:root:current train perplexity4.633645534515381
INFO:root:current mean train loss 1945.9241860627335
INFO:root:current train perplexity4.635639190673828
INFO:root:current mean train loss 1946.7712013696214
INFO:root:current train perplexity4.637720584869385
INFO:root:current mean train loss 1947.599052576865
INFO:root:current train perplexity4.641140937805176
INFO:root:current mean train loss 1947.8036341786055
INFO:root:current train perplexity4.643700122833252
INFO:root:current mean train loss 1948.7294752065905
INFO:root:current train perplexity4.647273063659668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.09s/it]
INFO:root:final mean train loss: 1948.0212346633396
INFO:root:final train perplexity: 4.647488117218018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 2013.8039555109985
INFO:root:eval perplexity: 5.096971035003662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.02s/it]
INFO:root:eval mean loss: 2437.3128644794438
INFO:root:eval perplexity: 7.339724063873291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/19
 10%|â–‰         | 19/200 [3:20:37<31:55:52, 635.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.723299893466
INFO:root:current train perplexity4.602908134460449
INFO:root:current mean train loss 1918.6626026591316
INFO:root:current train perplexity4.580497741699219
INFO:root:current mean train loss 1937.2273840002113
INFO:root:current train perplexity4.615261077880859
INFO:root:current mean train loss 1927.3231963163578
INFO:root:current train perplexity4.589134693145752
INFO:root:current mean train loss 1924.525989695183
INFO:root:current train perplexity4.579315662384033
INFO:root:current mean train loss 1930.472591473225
INFO:root:current train perplexity4.591798305511475
INFO:root:current mean train loss 1929.2468285269292
INFO:root:current train perplexity4.586441516876221
INFO:root:current mean train loss 1931.8230727769
INFO:root:current train perplexity4.5955610275268555
INFO:root:current mean train loss 1930.0917659861618
INFO:root:current train perplexity4.595076560974121
INFO:root:current mean train loss 1931.351538403691
INFO:root:current train perplexity4.594183921813965
INFO:root:current mean train loss 1932.403282329761
INFO:root:current train perplexity4.59340763092041
INFO:root:current mean train loss 1934.0756875104446
INFO:root:current train perplexity4.59490966796875
INFO:root:current mean train loss 1934.1097480037208
INFO:root:current train perplexity4.5926737785339355
INFO:root:current mean train loss 1933.580130111071
INFO:root:current train perplexity4.591343402862549
INFO:root:current mean train loss 1932.8254989430875
INFO:root:current train perplexity4.588690757751465
INFO:root:current mean train loss 1932.8299109801044
INFO:root:current train perplexity4.589196681976318
INFO:root:current mean train loss 1934.1725614385452
INFO:root:current train perplexity4.592548370361328
INFO:root:current mean train loss 1933.8813319189624
INFO:root:current train perplexity4.592730522155762
INFO:root:current mean train loss 1934.4917841721838
INFO:root:current train perplexity4.594333171844482
INFO:root:current mean train loss 1934.66038711659
INFO:root:current train perplexity4.596668243408203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.59s/it]
INFO:root:final mean train loss: 1934.1291627330847
INFO:root:final train perplexity: 4.596846103668213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2008.346145088791
INFO:root:eval perplexity: 5.074522972106934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2433.8326351084606
INFO:root:eval perplexity: 7.318865776062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/20
 10%|â–ˆ         | 20/200 [3:31:04<31:38:21, 632.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1881.7168187850561
INFO:root:current train perplexity4.4616827964782715
INFO:root:current mean train loss 1907.6561454937612
INFO:root:current train perplexity4.509502410888672
INFO:root:current mean train loss 1917.4657743445998
INFO:root:current train perplexity4.5157470703125
INFO:root:current mean train loss 1916.443845135624
INFO:root:current train perplexity4.508546352386475
INFO:root:current mean train loss 1918.8476651480637
INFO:root:current train perplexity4.5311431884765625
INFO:root:current mean train loss 1914.0446288156597
INFO:root:current train perplexity4.5255818367004395
INFO:root:current mean train loss 1917.343365067794
INFO:root:current train perplexity4.5309906005859375
INFO:root:current mean train loss 1916.6738603357048
INFO:root:current train perplexity4.524901390075684
INFO:root:current mean train loss 1918.4028116619488
INFO:root:current train perplexity4.530617713928223
INFO:root:current mean train loss 1919.7315022526457
INFO:root:current train perplexity4.534351825714111
INFO:root:current mean train loss 1921.0037746631376
INFO:root:current train perplexity4.537829875946045
INFO:root:current mean train loss 1921.3218675836122
INFO:root:current train perplexity4.542176246643066
INFO:root:current mean train loss 1919.9413992548489
INFO:root:current train perplexity4.541574478149414
INFO:root:current mean train loss 1921.198645138046
INFO:root:current train perplexity4.541028022766113
INFO:root:current mean train loss 1922.5526916207002
INFO:root:current train perplexity4.5430216789245605
INFO:root:current mean train loss 1922.2937132282023
INFO:root:current train perplexity4.545922756195068
INFO:root:current mean train loss 1923.060242555722
INFO:root:current train perplexity4.546654224395752
INFO:root:current mean train loss 1924.0852742910797
INFO:root:current train perplexity4.549753189086914
INFO:root:current mean train loss 1922.7675782577574
INFO:root:current train perplexity4.547645092010498
INFO:root:current mean train loss 1921.4407670019582
INFO:root:current train perplexity4.549335479736328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.26s/it]
INFO:root:final mean train loss: 1921.440935851466
INFO:root:final train perplexity: 4.551076889038086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2004.2658375408632
INFO:root:eval perplexity: 5.057805061340332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.86s/it]
INFO:root:eval mean loss: 2433.6521143270725
INFO:root:eval perplexity: 7.317784309387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/21
 10%|â–ˆ         | 21/200 [3:41:43<31:33:30, 634.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1911.749252319336
INFO:root:current train perplexity4.508910179138184
INFO:root:current mean train loss 1913.7549696702224
INFO:root:current train perplexity4.485391616821289
INFO:root:current mean train loss 1906.896469116211
INFO:root:current train perplexity4.4806084632873535
INFO:root:current mean train loss 1906.868353340063
INFO:root:current train perplexity4.483300685882568
INFO:root:current mean train loss 1902.141606648763
INFO:root:current train perplexity4.489763259887695
INFO:root:current mean train loss 1901.5838443015118
INFO:root:current train perplexity4.485610485076904
INFO:root:current mean train loss 1902.3814185537942
INFO:root:current train perplexity4.486752510070801
INFO:root:current mean train loss 1906.0569600100239
INFO:root:current train perplexity4.490230083465576
INFO:root:current mean train loss 1901.9709414187994
INFO:root:current train perplexity4.481524467468262
INFO:root:current mean train loss 1904.2087282316456
INFO:root:current train perplexity4.486084938049316
INFO:root:current mean train loss 1903.885703462543
INFO:root:current train perplexity4.486905574798584
INFO:root:current mean train loss 1904.2728150047647
INFO:root:current train perplexity4.490208625793457
INFO:root:current mean train loss 1905.300382772069
INFO:root:current train perplexity4.492237567901611
INFO:root:current mean train loss 1905.4457920490815
INFO:root:current train perplexity4.491106033325195
INFO:root:current mean train loss 1905.8363935030425
INFO:root:current train perplexity4.491159915924072
INFO:root:current mean train loss 1907.2478782830324
INFO:root:current train perplexity4.494873046875
INFO:root:current mean train loss 1909.2825077075313
INFO:root:current train perplexity4.499100685119629
INFO:root:current mean train loss 1908.7307926951346
INFO:root:current train perplexity4.50016975402832
INFO:root:current mean train loss 1909.3782934649237
INFO:root:current train perplexity4.503121852874756
INFO:root:current mean train loss 1909.6067724559448
INFO:root:current train perplexity4.506264686584473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.70s/it]
INFO:root:final mean train loss: 1908.7547884434687
INFO:root:final train perplexity: 4.505770206451416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 2003.5380257680906
INFO:root:eval perplexity: 5.054829120635986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2431.5589097476177
INFO:root:eval perplexity: 7.305266857147217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/22
 11%|â–ˆ         | 22/200 [3:52:16<31:21:14, 634.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1899.1158179714255
INFO:root:current train perplexity4.430634498596191
INFO:root:current mean train loss 1897.0956022229498
INFO:root:current train perplexity4.433431625366211
INFO:root:current mean train loss 1903.0111101870134
INFO:root:current train perplexity4.436763763427734
INFO:root:current mean train loss 1898.9785346064427
INFO:root:current train perplexity4.43320369720459
INFO:root:current mean train loss 1895.4274701043869
INFO:root:current train perplexity4.428554534912109
INFO:root:current mean train loss 1892.6154904457078
INFO:root:current train perplexity4.428633213043213
INFO:root:current mean train loss 1890.372805999257
INFO:root:current train perplexity4.42263650894165
INFO:root:current mean train loss 1892.180932522437
INFO:root:current train perplexity4.429937839508057
INFO:root:current mean train loss 1890.2948365795926
INFO:root:current train perplexity4.433219909667969
INFO:root:current mean train loss 1892.068103817727
INFO:root:current train perplexity4.44099760055542
INFO:root:current mean train loss 1893.9757939007166
INFO:root:current train perplexity4.444223403930664
INFO:root:current mean train loss 1893.8969539242328
INFO:root:current train perplexity4.445170879364014
INFO:root:current mean train loss 1895.038697152089
INFO:root:current train perplexity4.448981761932373
INFO:root:current mean train loss 1895.2783997071024
INFO:root:current train perplexity4.44797420501709
INFO:root:current mean train loss 1895.2879470441912
INFO:root:current train perplexity4.448732376098633
INFO:root:current mean train loss 1895.9128625170106
INFO:root:current train perplexity4.449304103851318
INFO:root:current mean train loss 1896.4620906376083
INFO:root:current train perplexity4.452763080596924
INFO:root:current mean train loss 1897.1137500468178
INFO:root:current train perplexity4.458818435668945
INFO:root:current mean train loss 1897.5787575106156
INFO:root:current train perplexity4.463381290435791
INFO:root:current mean train loss 1897.5409494236649
INFO:root:current train perplexity4.464034557342529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.93s/it]
INFO:root:final mean train loss: 1896.8748907338352
INFO:root:final train perplexity: 4.463752269744873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it]
INFO:root:eval mean loss: 2003.1465203034963
INFO:root:eval perplexity: 5.053226947784424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2433.654640576518
INFO:root:eval perplexity: 7.317800045013428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/23
 12%|â–ˆâ–        | 23/200 [4:02:50<31:10:32, 634.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.3501980251735
INFO:root:current train perplexity4.335249900817871
INFO:root:current mean train loss 1869.933570620888
INFO:root:current train perplexity4.372529983520508
INFO:root:current mean train loss 1870.4040283203126
INFO:root:current train perplexity4.381239891052246
INFO:root:current mean train loss 1875.9992469200722
INFO:root:current train perplexity4.389636516571045
INFO:root:current mean train loss 1876.2558317223375
INFO:root:current train perplexity4.392012119293213
INFO:root:current mean train loss 1879.7301215737552
INFO:root:current train perplexity4.395419597625732
INFO:root:current mean train loss 1880.0696948949842
INFO:root:current train perplexity4.39984130859375
INFO:root:current mean train loss 1880.3062360932556
INFO:root:current train perplexity4.406428813934326
INFO:root:current mean train loss 1880.7668211519049
INFO:root:current train perplexity4.4069013595581055
INFO:root:current mean train loss 1878.8285385594224
INFO:root:current train perplexity4.404064655303955
INFO:root:current mean train loss 1879.072636315582
INFO:root:current train perplexity4.40030574798584
INFO:root:current mean train loss 1880.1220946239823
INFO:root:current train perplexity4.405800819396973
INFO:root:current mean train loss 1880.9537900466328
INFO:root:current train perplexity4.411076068878174
INFO:root:current mean train loss 1881.4569796994435
INFO:root:current train perplexity4.413641452789307
INFO:root:current mean train loss 1882.5345463080694
INFO:root:current train perplexity4.417142868041992
INFO:root:current mean train loss 1882.1527779057342
INFO:root:current train perplexity4.417271137237549
INFO:root:current mean train loss 1882.23020229001
INFO:root:current train perplexity4.418429374694824
INFO:root:current mean train loss 1883.6747857290939
INFO:root:current train perplexity4.4185566902160645
INFO:root:current mean train loss 1884.5343799086475
INFO:root:current train perplexity4.420734405517578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.57s/it]
INFO:root:final mean train loss: 1885.1929457640924
INFO:root:final train perplexity: 4.422815322875977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.65s/it]
INFO:root:eval mean loss: 1998.855725443955
INFO:root:eval perplexity: 5.035722255706787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2433.353076691323
INFO:root:eval perplexity: 7.3159942626953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/24
 12%|â–ˆâ–        | 24/200 [4:13:38<31:11:54, 638.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.5211704799108
INFO:root:current train perplexity4.310853481292725
INFO:root:current mean train loss 1860.5389495564398
INFO:root:current train perplexity4.330260276794434
INFO:root:current mean train loss 1863.0645616319443
INFO:root:current train perplexity4.329718589782715
INFO:root:current mean train loss 1860.741393446534
INFO:root:current train perplexity4.334288120269775
INFO:root:current mean train loss 1854.8710583586071
INFO:root:current train perplexity4.322681903839111
INFO:root:current mean train loss 1856.3053021854198
INFO:root:current train perplexity4.330388069152832
INFO:root:current mean train loss 1862.3444983091151
INFO:root:current train perplexity4.345489025115967
INFO:root:current mean train loss 1863.4866869115763
INFO:root:current train perplexity4.352207660675049
INFO:root:current mean train loss 1865.5591629576654
INFO:root:current train perplexity4.35756778717041
INFO:root:current mean train loss 1867.6256335005082
INFO:root:current train perplexity4.364756107330322
INFO:root:current mean train loss 1869.192007267487
INFO:root:current train perplexity4.369785308837891
INFO:root:current mean train loss 1869.736543595091
INFO:root:current train perplexity4.3702921867370605
INFO:root:current mean train loss 1870.3131292638645
INFO:root:current train perplexity4.370580196380615
INFO:root:current mean train loss 1869.441531589219
INFO:root:current train perplexity4.369741439819336
INFO:root:current mean train loss 1870.5930342359075
INFO:root:current train perplexity4.374270439147949
INFO:root:current mean train loss 1872.1260709300607
INFO:root:current train perplexity4.377331733703613
INFO:root:current mean train loss 1873.0273032624602
INFO:root:current train perplexity4.380784511566162
INFO:root:current mean train loss 1873.1891201669596
INFO:root:current train perplexity4.381954193115234
INFO:root:current mean train loss 1873.650523841744
INFO:root:current train perplexity4.383824825286865
INFO:root:current mean train loss 1874.0743319226863
INFO:root:current train perplexity4.383994102478027

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it]
INFO:root:final mean train loss: 1874.5362637164433
INFO:root:final train perplexity: 4.385800361633301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 1997.452051906721
INFO:root:eval perplexity: 5.030010223388672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2434.012554628629
INFO:root:eval perplexity: 7.319941997528076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/25
 12%|â–ˆâ–Ž        | 25/200 [4:24:07<30:53:44, 635.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1853.7676595052083
INFO:root:current train perplexity4.342824459075928
INFO:root:current mean train loss 1869.1870648784022
INFO:root:current train perplexity4.341584205627441
INFO:root:current mean train loss 1862.1626772199359
INFO:root:current train perplexity4.316656112670898
INFO:root:current mean train loss 1858.9687741126543
INFO:root:current train perplexity4.312023639678955
INFO:root:current mean train loss 1865.2156602391656
INFO:root:current train perplexity4.337132453918457
INFO:root:current mean train loss 1861.3281590119573
INFO:root:current train perplexity4.331760883331299
INFO:root:current mean train loss 1861.4352759336814
INFO:root:current train perplexity4.331666946411133
INFO:root:current mean train loss 1857.7181069389892
INFO:root:current train perplexity4.334381580352783
INFO:root:current mean train loss 1859.2664223087645
INFO:root:current train perplexity4.335319519042969
INFO:root:current mean train loss 1858.7487006909919
INFO:root:current train perplexity4.335628986358643
INFO:root:current mean train loss 1861.4409304857254
INFO:root:current train perplexity4.339092254638672
INFO:root:current mean train loss 1861.2613082288424
INFO:root:current train perplexity4.335951805114746
INFO:root:current mean train loss 1863.3177804385914
INFO:root:current train perplexity4.340701580047607
INFO:root:current mean train loss 1864.181512008621
INFO:root:current train perplexity4.341428756713867
INFO:root:current mean train loss 1864.0881151349356
INFO:root:current train perplexity4.345412254333496
INFO:root:current mean train loss 1863.8068562505127
INFO:root:current train perplexity4.343276500701904
INFO:root:current mean train loss 1864.6783898264316
INFO:root:current train perplexity4.345560073852539
INFO:root:current mean train loss 1865.3946026228973
INFO:root:current train perplexity4.347387313842773
INFO:root:current mean train loss 1864.3096084594727
INFO:root:current train perplexity4.347400188446045
INFO:root:current mean train loss 1864.2926387033442
INFO:root:current train perplexity4.347360134124756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.24s/it]
INFO:root:final mean train loss: 1863.5530851347785
INFO:root:final train perplexity: 4.347973823547363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 1995.356221516927
INFO:root:eval perplexity: 5.021492004394531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 2432.132500398244
INFO:root:eval perplexity: 7.308694839477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/26
 13%|â–ˆâ–Ž        | 26/200 [4:34:32<30:33:44, 632.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1821.5689250666921
INFO:root:current train perplexity4.279684543609619
INFO:root:current mean train loss 1830.7068693553301
INFO:root:current train perplexity4.251881122589111
INFO:root:current mean train loss 1835.1514553212526
INFO:root:current train perplexity4.26335334777832
INFO:root:current mean train loss 1835.2387799125963
INFO:root:current train perplexity4.273897171020508
INFO:root:current mean train loss 1839.236917439502
INFO:root:current train perplexity4.2825775146484375
INFO:root:current mean train loss 1840.8854944366624
INFO:root:current train perplexity4.279794692993164
INFO:root:current mean train loss 1845.7904751639285
INFO:root:current train perplexity4.296241283416748
INFO:root:current mean train loss 1847.2872625806554
INFO:root:current train perplexity4.29575252532959
INFO:root:current mean train loss 1849.238874183682
INFO:root:current train perplexity4.297976493835449
INFO:root:current mean train loss 1850.117225768589
INFO:root:current train perplexity4.299474239349365
INFO:root:current mean train loss 1850.2681056892036
INFO:root:current train perplexity4.301731109619141
INFO:root:current mean train loss 1850.2669255142146
INFO:root:current train perplexity4.303609848022461
INFO:root:current mean train loss 1848.8927058020874
INFO:root:current train perplexity4.300403118133545
INFO:root:current mean train loss 1850.8762314445842
INFO:root:current train perplexity4.304397106170654
INFO:root:current mean train loss 1850.5401679097904
INFO:root:current train perplexity4.30426549911499
INFO:root:current mean train loss 1851.951276518013
INFO:root:current train perplexity4.307473182678223
INFO:root:current mean train loss 1852.087327360889
INFO:root:current train perplexity4.306368350982666
INFO:root:current mean train loss 1852.8910674260035
INFO:root:current train perplexity4.308445930480957
INFO:root:current mean train loss 1852.8118659107015
INFO:root:current train perplexity4.308933734893799
INFO:root:current mean train loss 1853.3350260290886
INFO:root:current train perplexity4.310678482055664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.97s/it]
INFO:root:final mean train loss: 1852.8558776824689
INFO:root:final train perplexity: 4.311447620391846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 1994.6343171681074
INFO:root:eval perplexity: 5.018560409545898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2433.342004654255
INFO:root:eval perplexity: 7.315927982330322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/27
 14%|â–ˆâ–Ž        | 27/200 [4:45:02<30:21:11, 631.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1830.4281426791488
INFO:root:current train perplexity4.197484016418457
INFO:root:current mean train loss 1828.8890535378757
INFO:root:current train perplexity4.2270612716674805
INFO:root:current mean train loss 1829.9929331698158
INFO:root:current train perplexity4.243076801300049
INFO:root:current mean train loss 1827.4563417914194
INFO:root:current train perplexity4.240660190582275
INFO:root:current mean train loss 1829.5107269953432
INFO:root:current train perplexity4.2450642585754395
INFO:root:current mean train loss 1831.3589685364864
INFO:root:current train perplexity4.247886657714844
INFO:root:current mean train loss 1832.4274956143736
INFO:root:current train perplexity4.251369953155518
INFO:root:current mean train loss 1834.8030087916393
INFO:root:current train perplexity4.252301216125488
INFO:root:current mean train loss 1835.3870755709136
INFO:root:current train perplexity4.256244659423828
INFO:root:current mean train loss 1837.9864164284725
INFO:root:current train perplexity4.258120536804199
INFO:root:current mean train loss 1837.1635604887242
INFO:root:current train perplexity4.256724834442139
INFO:root:current mean train loss 1836.3411048269847
INFO:root:current train perplexity4.255161762237549
INFO:root:current mean train loss 1836.6964337420197
INFO:root:current train perplexity4.25834321975708
INFO:root:current mean train loss 1837.2648142841322
INFO:root:current train perplexity4.262078285217285
INFO:root:current mean train loss 1838.5284370244449
INFO:root:current train perplexity4.267547607421875
INFO:root:current mean train loss 1839.8729749491033
INFO:root:current train perplexity4.269255638122559
INFO:root:current mean train loss 1840.3640191201278
INFO:root:current train perplexity4.272119998931885
INFO:root:current mean train loss 1841.5233929908588
INFO:root:current train perplexity4.275211811065674
INFO:root:current mean train loss 1842.0669355936534
INFO:root:current train perplexity4.2771315574646
INFO:root:current mean train loss 1843.6766880491293
INFO:root:current train perplexity4.277932167053223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it]
INFO:root:final mean train loss: 1842.8680811433317
INFO:root:final train perplexity: 4.277619361877441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 1997.109188864417
INFO:root:eval perplexity: 5.028615474700928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.12s/it]
INFO:root:eval mean loss: 2438.1207288376827
INFO:root:eval perplexity: 7.344575881958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/28
 14%|â–ˆâ–        | 28/200 [4:55:29<30:07:02, 630.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.364345703125
INFO:root:current train perplexity4.230379581451416
INFO:root:current mean train loss 1825.7924755859376
INFO:root:current train perplexity4.211147785186768
INFO:root:current mean train loss 1824.5504860617898
INFO:root:current train perplexity4.20721960067749
INFO:root:current mean train loss 1826.1451484375
INFO:root:current train perplexity4.2098612785339355
INFO:root:current mean train loss 1829.331828227796
INFO:root:current train perplexity4.22404670715332
INFO:root:current mean train loss 1830.292380689538
INFO:root:current train perplexity4.224374771118164
INFO:root:current mean train loss 1828.174256004051
INFO:root:current train perplexity4.224868297576904
INFO:root:current mean train loss 1831.1961537613408
INFO:root:current train perplexity4.232815742492676
INFO:root:current mean train loss 1832.9847527901786
INFO:root:current train perplexity4.233987808227539
INFO:root:current mean train loss 1834.1049782151442
INFO:root:current train perplexity4.240697860717773
INFO:root:current mean train loss 1834.5409562363736
INFO:root:current train perplexity4.2371063232421875
INFO:root:current mean train loss 1831.6540974069148
INFO:root:current train perplexity4.233994483947754
INFO:root:current mean train loss 1831.8332520488664
INFO:root:current train perplexity4.236757278442383
INFO:root:current mean train loss 1831.6427770774148
INFO:root:current train perplexity4.237948417663574
INFO:root:current mean train loss 1832.8443308891685
INFO:root:current train perplexity4.241139888763428
INFO:root:current mean train loss 1833.1942420014882
INFO:root:current train perplexity4.240932464599609
INFO:root:current mean train loss 1833.890780521222
INFO:root:current train perplexity4.242094993591309
INFO:root:current mean train loss 1833.916365055568
INFO:root:current train perplexity4.243089199066162
INFO:root:current mean train loss 1833.6387852864584
INFO:root:current train perplexity4.2433624267578125
INFO:root:current mean train loss 1834.083562413469
INFO:root:current train perplexity4.246106147766113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.68s/it]
INFO:root:final mean train loss: 1833.492862580223
INFO:root:final train perplexity: 4.246108055114746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.29s/it]
INFO:root:eval mean loss: 1994.1908075860206
INFO:root:eval perplexity: 5.016759872436523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2437.229622482408
INFO:root:eval perplexity: 7.3392252922058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/29
 14%|â–ˆâ–        | 29/200 [5:06:07<30:02:44, 632.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.7015924868376
INFO:root:current train perplexity4.164581298828125
INFO:root:current mean train loss 1816.8639812469482
INFO:root:current train perplexity4.175262928009033
INFO:root:current mean train loss 1814.8561886304046
INFO:root:current train perplexity4.182137489318848
INFO:root:current mean train loss 1814.6864773497289
INFO:root:current train perplexity4.189840316772461
INFO:root:current mean train loss 1815.660385752112
INFO:root:current train perplexity4.192275047302246
INFO:root:current mean train loss 1817.853902043523
INFO:root:current train perplexity4.187352180480957
INFO:root:current mean train loss 1815.6109033485368
INFO:root:current train perplexity4.18701171875
INFO:root:current mean train loss 1816.906240752249
INFO:root:current train perplexity4.190547466278076
INFO:root:current mean train loss 1818.3813123489174
INFO:root:current train perplexity4.19327449798584
INFO:root:current mean train loss 1820.1150417943154
INFO:root:current train perplexity4.201034069061279
INFO:root:current mean train loss 1820.5980090466173
INFO:root:current train perplexity4.200183391571045
INFO:root:current mean train loss 1821.7411804199219
INFO:root:current train perplexity4.2020087242126465
INFO:root:current mean train loss 1822.4869194857476
INFO:root:current train perplexity4.205613613128662
INFO:root:current mean train loss 1822.951683219822
INFO:root:current train perplexity4.206644058227539
INFO:root:current mean train loss 1822.2149841472226
INFO:root:current train perplexity4.206777572631836
INFO:root:current mean train loss 1822.4640911619867
INFO:root:current train perplexity4.210476875305176
INFO:root:current mean train loss 1823.2874154165281
INFO:root:current train perplexity4.211950302124023
INFO:root:current mean train loss 1824.0438492638725
INFO:root:current train perplexity4.21187686920166
INFO:root:current mean train loss 1824.0549685456033
INFO:root:current train perplexity4.212080478668213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.67s/it]
INFO:root:final mean train loss: 1823.6560395626004
INFO:root:final train perplexity: 4.213294506072998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.41s/it]
INFO:root:eval mean loss: 1996.728411302499
INFO:root:eval perplexity: 5.0270676612854
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2440.0421207509144
INFO:root:eval perplexity: 7.356126308441162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/30
 15%|â–ˆâ–Œ        | 30/200 [5:16:36<29:49:22, 631.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1834.0366346571182
INFO:root:current train perplexity4.13822078704834
INFO:root:current mean train loss 1793.3017779709003
INFO:root:current train perplexity4.114811897277832
INFO:root:current mean train loss 1791.0325740832461
INFO:root:current train perplexity4.112795829772949
INFO:root:current mean train loss 1800.499389253388
INFO:root:current train perplexity4.133313179016113
INFO:root:current mean train loss 1801.191995112412
INFO:root:current train perplexity4.133309364318848
INFO:root:current mean train loss 1802.3397394266485
INFO:root:current train perplexity4.133259296417236
INFO:root:current mean train loss 1803.0524986530172
INFO:root:current train perplexity4.144261360168457
INFO:root:current mean train loss 1804.6343448353755
INFO:root:current train perplexity4.144590854644775
INFO:root:current mean train loss 1804.9660780332586
INFO:root:current train perplexity4.151124000549316
INFO:root:current mean train loss 1808.1898792296222
INFO:root:current train perplexity4.158118724822998
INFO:root:current mean train loss 1808.710005579666
INFO:root:current train perplexity4.1602678298950195
INFO:root:current mean train loss 1808.2685401579406
INFO:root:current train perplexity4.166070938110352
INFO:root:current mean train loss 1809.4550584362398
INFO:root:current train perplexity4.169851303100586
INFO:root:current mean train loss 1810.1529469209559
INFO:root:current train perplexity4.173978328704834
INFO:root:current mean train loss 1811.1275732664456
INFO:root:current train perplexity4.175379276275635
INFO:root:current mean train loss 1811.1576851553439
INFO:root:current train perplexity4.175698757171631
INFO:root:current mean train loss 1812.5377354310713
INFO:root:current train perplexity4.178810119628906
INFO:root:current mean train loss 1813.1531148143788
INFO:root:current train perplexity4.177444934844971
INFO:root:current mean train loss 1813.6789957682292
INFO:root:current train perplexity4.178712844848633
INFO:root:current mean train loss 1814.5687168255222
INFO:root:current train perplexity4.18082857131958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.83s/it]
INFO:root:final mean train loss: 1814.538053496222
INFO:root:final train perplexity: 4.18310546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 1996.518975440492
INFO:root:eval perplexity: 5.026214599609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2440.717783826463
INFO:root:eval perplexity: 7.360192775726318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/31
 16%|â–ˆâ–Œ        | 31/200 [5:27:25<29:53:35, 636.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1791.4745671198918
INFO:root:current train perplexity4.102311134338379
INFO:root:current mean train loss 1813.3529508076017
INFO:root:current train perplexity4.1367974281311035
INFO:root:current mean train loss 1804.730782027793
INFO:root:current train perplexity4.1257004737854
INFO:root:current mean train loss 1800.2433243265912
INFO:root:current train perplexity4.127655982971191
INFO:root:current mean train loss 1803.7520084291557
INFO:root:current train perplexity4.12702751159668
INFO:root:current mean train loss 1803.7886259709928
INFO:root:current train perplexity4.128709316253662
INFO:root:current mean train loss 1800.889790982865
INFO:root:current train perplexity4.128031253814697
INFO:root:current mean train loss 1799.4800569728716
INFO:root:current train perplexity4.127459526062012
INFO:root:current mean train loss 1801.630722821769
INFO:root:current train perplexity4.129283428192139
INFO:root:current mean train loss 1801.5741347772257
INFO:root:current train perplexity4.135756969451904
INFO:root:current mean train loss 1801.4325260511848
INFO:root:current train perplexity4.135971546173096
INFO:root:current mean train loss 1801.09748973135
INFO:root:current train perplexity4.139653205871582
INFO:root:current mean train loss 1801.3351077006653
INFO:root:current train perplexity4.141247749328613
INFO:root:current mean train loss 1802.24308185376
INFO:root:current train perplexity4.1430535316467285
INFO:root:current mean train loss 1801.7300603366332
INFO:root:current train perplexity4.1430559158325195
INFO:root:current mean train loss 1802.5799190976204
INFO:root:current train perplexity4.146181106567383
INFO:root:current mean train loss 1803.7441185532462
INFO:root:current train perplexity4.1479315757751465
INFO:root:current mean train loss 1803.8520113170355
INFO:root:current train perplexity4.145977973937988
INFO:root:current mean train loss 1804.8138740598044
INFO:root:current train perplexity4.150607109069824
INFO:root:current mean train loss 1804.5051786713882
INFO:root:current train perplexity4.150315284729004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.10s/it]
INFO:root:final mean train loss: 1804.9022461491525
INFO:root:final train perplexity: 4.151436805725098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 1993.832838991855
INFO:root:eval perplexity: 5.015308380126953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.57s/it]
INFO:root:eval mean loss: 2441.254664644282
INFO:root:eval perplexity: 7.3634257316589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/32
 16%|â–ˆâ–Œ        | 32/200 [5:37:54<29:35:53, 634.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.5983177007631
INFO:root:current train perplexity4.078676223754883
INFO:root:current mean train loss 1795.3174511035838
INFO:root:current train perplexity4.1073899269104
INFO:root:current mean train loss 1797.8558183834878
INFO:root:current train perplexity4.089430332183838
INFO:root:current mean train loss 1790.0468023984147
INFO:root:current train perplexity4.0810227394104
INFO:root:current mean train loss 1787.841278558391
INFO:root:current train perplexity4.093477725982666
INFO:root:current mean train loss 1788.8086800759668
INFO:root:current train perplexity4.099149703979492
INFO:root:current mean train loss 1790.8136571050618
INFO:root:current train perplexity4.107250213623047
INFO:root:current mean train loss 1791.6355872584224
INFO:root:current train perplexity4.112280368804932
INFO:root:current mean train loss 1792.9316762469418
INFO:root:current train perplexity4.116423606872559
INFO:root:current mean train loss 1793.287431055516
INFO:root:current train perplexity4.113455295562744
INFO:root:current mean train loss 1792.8605644540612
INFO:root:current train perplexity4.114495277404785
INFO:root:current mean train loss 1791.815210751244
INFO:root:current train perplexity4.112452507019043
INFO:root:current mean train loss 1792.8729230369759
INFO:root:current train perplexity4.113765239715576
INFO:root:current mean train loss 1793.6021969384076
INFO:root:current train perplexity4.114053726196289
INFO:root:current mean train loss 1794.5520151499156
INFO:root:current train perplexity4.1173095703125
INFO:root:current mean train loss 1794.3759508509954
INFO:root:current train perplexity4.1181721687316895
INFO:root:current mean train loss 1795.3396262077754
INFO:root:current train perplexity4.1200385093688965
INFO:root:current mean train loss 1795.3397805787883
INFO:root:current train perplexity4.118791103363037
INFO:root:current mean train loss 1796.6479506759106
INFO:root:current train perplexity4.121677398681641
INFO:root:current mean train loss 1796.1263341663182
INFO:root:current train perplexity4.1199493408203125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.82s/it]
INFO:root:final mean train loss: 1795.736897571004
INFO:root:final train perplexity: 4.121537208557129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 1996.2057283009199
INFO:root:eval perplexity: 5.024942398071289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 2444.5984756794383
INFO:root:eval perplexity: 7.3835883140563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/33
 16%|â–ˆâ–‹        | 33/200 [5:48:38<29:33:31, 637.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.2310180664062
INFO:root:current train perplexity4.053408145904541
INFO:root:current mean train loss 1777.6783538818358
INFO:root:current train perplexity4.085406303405762
INFO:root:current mean train loss 1779.9396517240084
INFO:root:current train perplexity4.081759452819824
INFO:root:current mean train loss 1776.3184919569228
INFO:root:current train perplexity4.07536506652832
INFO:root:current mean train loss 1778.1752130923064
INFO:root:current train perplexity4.081797122955322
INFO:root:current mean train loss 1775.4622892107282
INFO:root:current train perplexity4.071829795837402
INFO:root:current mean train loss 1774.493634033203
INFO:root:current train perplexity4.072911262512207
INFO:root:current mean train loss 1778.1340152138157
INFO:root:current train perplexity4.073150157928467
INFO:root:current mean train loss 1777.1750344919603
INFO:root:current train perplexity4.070634365081787
INFO:root:current mean train loss 1778.9732165018718
INFO:root:current train perplexity4.074392318725586
INFO:root:current mean train loss 1780.4335813126474
INFO:root:current train perplexity4.07583475112915
INFO:root:current mean train loss 1781.3675017258217
INFO:root:current train perplexity4.076425075531006
INFO:root:current mean train loss 1782.1360678052145
INFO:root:current train perplexity4.0793776512146
INFO:root:current mean train loss 1784.0525311638328
INFO:root:current train perplexity4.082597732543945
INFO:root:current mean train loss 1785.9888250481592
INFO:root:current train perplexity4.085348606109619
INFO:root:current mean train loss 1787.1895534417567
INFO:root:current train perplexity4.087613582611084
INFO:root:current mean train loss 1788.0275325913028
INFO:root:current train perplexity4.090788841247559
INFO:root:current mean train loss 1788.0722599376331
INFO:root:current train perplexity4.0916547775268555
INFO:root:current mean train loss 1787.8298551826067
INFO:root:current train perplexity4.093268871307373
INFO:root:current mean train loss 1787.7752159274355
INFO:root:current train perplexity4.094441890716553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.28s/it]
INFO:root:final mean train loss: 1787.4625647655955
INFO:root:final train perplexity: 4.094729423522949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 1994.902142030973
INFO:root:eval perplexity: 5.01964807510376
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2443.7719237415504
INFO:root:eval perplexity: 7.378598213195801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/34
 17%|â–ˆâ–‹        | 34/200 [5:59:04<29:13:41, 633.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.8054040685877
INFO:root:current train perplexity4.016157627105713
INFO:root:current mean train loss 1769.3482948777366
INFO:root:current train perplexity4.045360565185547
INFO:root:current mean train loss 1769.524738848855
INFO:root:current train perplexity4.044259548187256
INFO:root:current mean train loss 1770.337206124627
INFO:root:current train perplexity4.046464920043945
INFO:root:current mean train loss 1771.5311786003833
INFO:root:current train perplexity4.045483589172363
INFO:root:current mean train loss 1771.4138384576067
INFO:root:current train perplexity4.0495991706848145
INFO:root:current mean train loss 1770.312868554976
INFO:root:current train perplexity4.047364711761475
INFO:root:current mean train loss 1771.2203969280386
INFO:root:current train perplexity4.045435428619385
INFO:root:current mean train loss 1774.0475486833666
INFO:root:current train perplexity4.051974296569824
INFO:root:current mean train loss 1775.49170946416
INFO:root:current train perplexity4.054396152496338
INFO:root:current mean train loss 1774.4768932346071
INFO:root:current train perplexity4.0530829429626465
INFO:root:current mean train loss 1774.544857365455
INFO:root:current train perplexity4.058309078216553
INFO:root:current mean train loss 1774.9471435546875
INFO:root:current train perplexity4.058536052703857
INFO:root:current mean train loss 1774.7864713648046
INFO:root:current train perplexity4.058126926422119
INFO:root:current mean train loss 1775.8595302945953
INFO:root:current train perplexity4.059106826782227
INFO:root:current mean train loss 1776.9347387494056
INFO:root:current train perplexity4.059937477111816
INFO:root:current mean train loss 1777.0463165483377
INFO:root:current train perplexity4.059854507446289
INFO:root:current mean train loss 1777.7238588177493
INFO:root:current train perplexity4.0618896484375
INFO:root:current mean train loss 1778.5675321323922
INFO:root:current train perplexity4.063185214996338
INFO:root:current mean train loss 1778.6354457486682
INFO:root:current train perplexity4.064807415008545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.31s/it]
INFO:root:final mean train loss: 1778.0950240742602
INFO:root:final train perplexity: 4.064589500427246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 1996.1623764579178
INFO:root:eval perplexity: 5.024765491485596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2449.6600263879654
INFO:root:eval perplexity: 7.414216995239258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/35
 18%|â–ˆâ–Š        | 35/200 [6:09:30<28:56:48, 631.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1775.4214854138963
INFO:root:current train perplexity4.001124858856201
INFO:root:current mean train loss 1768.8291185516673
INFO:root:current train perplexity4.004429340362549
INFO:root:current mean train loss 1768.2557547433037
INFO:root:current train perplexity4.020158290863037
INFO:root:current mean train loss 1764.2843516393361
INFO:root:current train perplexity4.017129898071289
INFO:root:current mean train loss 1765.6590030067846
INFO:root:current train perplexity4.024237155914307
INFO:root:current mean train loss 1764.878771849353
INFO:root:current train perplexity4.023106575012207
INFO:root:current mean train loss 1768.4284602888035
INFO:root:current train perplexity4.032707691192627
INFO:root:current mean train loss 1771.647696468632
INFO:root:current train perplexity4.034905910491943
INFO:root:current mean train loss 1770.995039357435
INFO:root:current train perplexity4.029810905456543
INFO:root:current mean train loss 1768.6407975440534
INFO:root:current train perplexity4.023654460906982
INFO:root:current mean train loss 1767.8716651595707
INFO:root:current train perplexity4.026785373687744
INFO:root:current mean train loss 1767.6473130013676
INFO:root:current train perplexity4.02858829498291
INFO:root:current mean train loss 1768.4301206892387
INFO:root:current train perplexity4.03115701675415
INFO:root:current mean train loss 1769.0724822691557
INFO:root:current train perplexity4.03171443939209
INFO:root:current mean train loss 1769.8521960563608
INFO:root:current train perplexity4.032922267913818
INFO:root:current mean train loss 1770.5839913438824
INFO:root:current train perplexity4.034214973449707
INFO:root:current mean train loss 1771.5836266671893
INFO:root:current train perplexity4.035451889038086
INFO:root:current mean train loss 1771.9908128821332
INFO:root:current train perplexity4.0369672775268555
INFO:root:current mean train loss 1771.3886557622343
INFO:root:current train perplexity4.0392608642578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.10s/it]
INFO:root:final mean train loss: 1770.1577062563529
INFO:root:final train perplexity: 4.039224624633789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 2000.8094088507037
INFO:root:eval perplexity: 5.0436859130859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.26s/it]
INFO:root:eval mean loss: 2453.3851946025875
INFO:root:eval perplexity: 7.4368391036987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/36
 18%|â–ˆâ–Š        | 36/200 [6:20:07<28:50:38, 633.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1784.3350719105113
INFO:root:current train perplexity3.9911649227142334
INFO:root:current mean train loss 1744.7677067937077
INFO:root:current train perplexity3.958761692047119
INFO:root:current mean train loss 1751.9018381127814
INFO:root:current train perplexity3.9837563037872314
INFO:root:current mean train loss 1754.0407769795015
INFO:root:current train perplexity3.9863860607147217
INFO:root:current mean train loss 1758.3429341188603
INFO:root:current train perplexity3.9898486137390137
INFO:root:current mean train loss 1758.5982582405823
INFO:root:current train perplexity3.9920504093170166
INFO:root:current mean train loss 1758.8243683910214
INFO:root:current train perplexity3.992271661758423
INFO:root:current mean train loss 1756.5511847172777
INFO:root:current train perplexity3.9910354614257812
INFO:root:current mean train loss 1756.973011322586
INFO:root:current train perplexity3.9923934936523438
INFO:root:current mean train loss 1759.2462135423814
INFO:root:current train perplexity3.9953267574310303
INFO:root:current mean train loss 1759.9367695099993
INFO:root:current train perplexity3.998884916305542
INFO:root:current mean train loss 1759.133613593293
INFO:root:current train perplexity4.000608921051025
INFO:root:current mean train loss 1759.351143066003
INFO:root:current train perplexity4.001376628875732
INFO:root:current mean train loss 1759.6800974737498
INFO:root:current train perplexity4.002266883850098
INFO:root:current mean train loss 1759.9860706613217
INFO:root:current train perplexity4.004927158355713
INFO:root:current mean train loss 1760.622821234773
INFO:root:current train perplexity4.0070037841796875
INFO:root:current mean train loss 1760.091923643239
INFO:root:current train perplexity4.0064287185668945
INFO:root:current mean train loss 1760.7852489264092
INFO:root:current train perplexity4.007339954376221
INFO:root:current mean train loss 1762.1003889803198
INFO:root:current train perplexity4.010328769683838
INFO:root:current mean train loss 1762.200368101718
INFO:root:current train perplexity4.011749267578125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.32s/it]
INFO:root:final mean train loss: 1761.7919009887264
INFO:root:final train perplexity: 4.0126633644104
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2003.1089771893007
INFO:root:eval perplexity: 5.053075313568115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2457.894494455757
INFO:root:eval perplexity: 7.464315414428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/37
 18%|â–ˆâ–Š        | 37/200 [6:30:45<28:43:58, 634.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.1627894810267
INFO:root:current train perplexity3.9650144577026367
INFO:root:current mean train loss 1758.6091899871826
INFO:root:current train perplexity3.9751157760620117
INFO:root:current mean train loss 1752.431750381202
INFO:root:current train perplexity3.9770288467407227
INFO:root:current mean train loss 1746.512262856088
INFO:root:current train perplexity3.974149703979492
INFO:root:current mean train loss 1744.2244918680638
INFO:root:current train perplexity3.97090482711792
INFO:root:current mean train loss 1746.1883424701114
INFO:root:current train perplexity3.9670052528381348
INFO:root:current mean train loss 1747.8338302320735
INFO:root:current train perplexity3.9696075916290283
INFO:root:current mean train loss 1747.8518587887943
INFO:root:current train perplexity3.971503257751465
INFO:root:current mean train loss 1749.7651958373433
INFO:root:current train perplexity3.9734504222869873
INFO:root:current mean train loss 1751.4721283748231
INFO:root:current train perplexity3.9732890129089355
INFO:root:current mean train loss 1753.2473523329204
INFO:root:current train perplexity3.9747262001037598
INFO:root:current mean train loss 1753.6407144965856
INFO:root:current train perplexity3.979475975036621
INFO:root:current mean train loss 1753.0820052056824
INFO:root:current train perplexity3.982715368270874
INFO:root:current mean train loss 1753.1450716501258
INFO:root:current train perplexity3.980527877807617
INFO:root:current mean train loss 1753.9753781273253
INFO:root:current train perplexity3.982241630554199
INFO:root:current mean train loss 1754.1403712727013
INFO:root:current train perplexity3.9815196990966797
INFO:root:current mean train loss 1753.590408437668
INFO:root:current train perplexity3.981414794921875
INFO:root:current mean train loss 1754.4117303777623
INFO:root:current train perplexity3.9817991256713867
INFO:root:current mean train loss 1753.81698554976
INFO:root:current train perplexity3.984067916870117
INFO:root:current mean train loss 1753.756475108293
INFO:root:current train perplexity3.9853312969207764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.53s/it]
INFO:root:final mean train loss: 1753.5202141173609
INFO:root:final train perplexity: 3.9865710735321045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2000.1336890687335
INFO:root:eval perplexity: 5.040930271148682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2459.9575740733044
INFO:root:eval perplexity: 7.476918697357178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/38
 19%|â–ˆâ–‰        | 38/200 [6:41:21<28:35:01, 635.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.0629421657986
INFO:root:current train perplexity3.9332683086395264
INFO:root:current mean train loss 1737.2325809873385
INFO:root:current train perplexity3.9368667602539062
INFO:root:current mean train loss 1741.106092055963
INFO:root:current train perplexity3.940443992614746
INFO:root:current mean train loss 1745.2550367272418
INFO:root:current train perplexity3.9454729557037354
INFO:root:current mean train loss 1742.5541915379213
INFO:root:current train perplexity3.9494926929473877
INFO:root:current mean train loss 1740.676794769567
INFO:root:current train perplexity3.949882984161377
INFO:root:current mean train loss 1741.296115892987
INFO:root:current train perplexity3.945803642272949
INFO:root:current mean train loss 1741.2393800466652
INFO:root:current train perplexity3.9482667446136475
INFO:root:current mean train loss 1741.4054660052238
INFO:root:current train perplexity3.948068141937256
INFO:root:current mean train loss 1739.9517662088706
INFO:root:current train perplexity3.944697380065918
INFO:root:current mean train loss 1739.7362243944378
INFO:root:current train perplexity3.9456591606140137
INFO:root:current mean train loss 1740.076543096684
INFO:root:current train perplexity3.946535587310791
INFO:root:current mean train loss 1739.3769892068274
INFO:root:current train perplexity3.9472014904022217
INFO:root:current mean train loss 1741.0568018122676
INFO:root:current train perplexity3.949486017227173
INFO:root:current mean train loss 1741.8261377459992
INFO:root:current train perplexity3.9509849548339844
INFO:root:current mean train loss 1742.9663313486044
INFO:root:current train perplexity3.9542808532714844
INFO:root:current mean train loss 1744.2035509474733
INFO:root:current train perplexity3.95581316947937
INFO:root:current mean train loss 1745.191657525967
INFO:root:current train perplexity3.9580793380737305
INFO:root:current mean train loss 1745.713940562013
INFO:root:current train perplexity3.959676742553711
INFO:root:current mean train loss 1745.9692369632671
INFO:root:current train perplexity3.9606192111968994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.14s/it]
INFO:root:final mean train loss: 1745.8245227869509
INFO:root:final train perplexity: 3.962449073791504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2001.3036797706118
INFO:root:eval perplexity: 5.04570198059082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it]
INFO:root:eval mean loss: 2458.728706522191
INFO:root:eval perplexity: 7.469408988952637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/39
 20%|â–ˆâ–‰        | 39/200 [6:51:46<28:15:43, 631.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.7610572076612
INFO:root:current train perplexity3.8863725662231445
INFO:root:current mean train loss 1732.291315526138
INFO:root:current train perplexity3.890233278274536
INFO:root:current mean train loss 1725.6137723267534
INFO:root:current train perplexity3.890536069869995
INFO:root:current mean train loss 1725.7859328464908
INFO:root:current train perplexity3.893422842025757
INFO:root:current mean train loss 1727.1923991942303
INFO:root:current train perplexity3.893580198287964
INFO:root:current mean train loss 1727.3189818901524
INFO:root:current train perplexity3.901913642883301
INFO:root:current mean train loss 1730.6582036781888
INFO:root:current train perplexity3.9118404388427734
INFO:root:current mean train loss 1733.8904936382464
INFO:root:current train perplexity3.9156792163848877
INFO:root:current mean train loss 1734.9743867595346
INFO:root:current train perplexity3.9168777465820312
INFO:root:current mean train loss 1736.8696333474775
INFO:root:current train perplexity3.9203035831451416
INFO:root:current mean train loss 1739.9096179681983
INFO:root:current train perplexity3.9297702312469482
INFO:root:current mean train loss 1738.9176049552564
INFO:root:current train perplexity3.9276373386383057
INFO:root:current mean train loss 1738.1362112199447
INFO:root:current train perplexity3.9267613887786865
INFO:root:current mean train loss 1739.029698398495
INFO:root:current train perplexity3.9287030696868896
INFO:root:current mean train loss 1740.0988166694276
INFO:root:current train perplexity3.9332449436187744
INFO:root:current mean train loss 1740.8110039743967
INFO:root:current train perplexity3.9356536865234375
INFO:root:current mean train loss 1739.8824401928916
INFO:root:current train perplexity3.935227394104004
INFO:root:current mean train loss 1739.8897525644466
INFO:root:current train perplexity3.9360437393188477
INFO:root:current mean train loss 1739.3054917086592
INFO:root:current train perplexity3.9370276927948
INFO:root:current mean train loss 1738.7972017029617
INFO:root:current train perplexity3.9379026889801025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.11s/it]
INFO:root:final mean train loss: 1738.0960818938515
INFO:root:final train perplexity: 3.938370704650879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2003.246535713791
INFO:root:eval perplexity: 5.053637504577637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 2461.751049718113
INFO:root:eval perplexity: 7.487895488739014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/40
 20%|â–ˆâ–ˆ        | 40/200 [7:02:21<28:07:40, 632.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1719.6968391515031
INFO:root:current train perplexity3.8935515880584717
INFO:root:current mean train loss 1716.8042442279154
INFO:root:current train perplexity3.8947105407714844
INFO:root:current mean train loss 1718.9561080659162
INFO:root:current train perplexity3.8934571743011475
INFO:root:current mean train loss 1721.542594164846
INFO:root:current train perplexity3.8973584175109863
INFO:root:current mean train loss 1720.5941157012494
INFO:root:current train perplexity3.896371364593506
INFO:root:current mean train loss 1721.2518590950183
INFO:root:current train perplexity3.896465539932251
INFO:root:current mean train loss 1719.9237051557898
INFO:root:current train perplexity3.8926315307617188
INFO:root:current mean train loss 1722.6524125418705
INFO:root:current train perplexity3.895141839981079
INFO:root:current mean train loss 1726.6239190041952
INFO:root:current train perplexity3.901304006576538
INFO:root:current mean train loss 1727.4478770987614
INFO:root:current train perplexity3.906275510787964
INFO:root:current mean train loss 1728.1936632497539
INFO:root:current train perplexity3.9097676277160645
INFO:root:current mean train loss 1730.6120667591047
INFO:root:current train perplexity3.9112751483917236
INFO:root:current mean train loss 1729.8450456250916
INFO:root:current train perplexity3.908761501312256
INFO:root:current mean train loss 1730.2635457327265
INFO:root:current train perplexity3.910130262374878
INFO:root:current mean train loss 1730.240150353649
INFO:root:current train perplexity3.9099395275115967
INFO:root:current mean train loss 1731.0150447987996
INFO:root:current train perplexity3.9123282432556152
INFO:root:current mean train loss 1730.3302366928092
INFO:root:current train perplexity3.9120240211486816
INFO:root:current mean train loss 1731.2193435403053
INFO:root:current train perplexity3.9141852855682373
INFO:root:current mean train loss 1731.2620285058542
INFO:root:current train perplexity3.91565203666687
INFO:root:current mean train loss 1731.28622034043
INFO:root:current train perplexity3.916006088256836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.03s/it]
INFO:root:final mean train loss: 1730.915540640365
INFO:root:final train perplexity: 3.916130542755127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2004.1778365331338
INFO:root:eval perplexity: 5.0574445724487305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2463.1262839026485
INFO:root:eval perplexity: 7.496321201324463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/41
 20%|â–ˆâ–ˆ        | 41/200 [7:12:48<27:52:43, 631.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.8895581563313
INFO:root:current train perplexity3.852459669113159
INFO:root:current mean train loss 1722.9876403808594
INFO:root:current train perplexity3.880373477935791
INFO:root:current mean train loss 1729.8797611545872
INFO:root:current train perplexity3.8819479942321777
INFO:root:current mean train loss 1726.9485498293482
INFO:root:current train perplexity3.8752973079681396
INFO:root:current mean train loss 1721.7377484229303
INFO:root:current train perplexity3.876936197280884
INFO:root:current mean train loss 1723.2334166661205
INFO:root:current train perplexity3.8757171630859375
INFO:root:current mean train loss 1724.6976967296382
INFO:root:current train perplexity3.878525972366333
INFO:root:current mean train loss 1723.3539536059202
INFO:root:current train perplexity3.8741064071655273
INFO:root:current mean train loss 1722.8116461890083
INFO:root:current train perplexity3.876849412918091
INFO:root:current mean train loss 1722.5696400102363
INFO:root:current train perplexity3.878537893295288
INFO:root:current mean train loss 1723.2982296908858
INFO:root:current train perplexity3.8819899559020996
INFO:root:current mean train loss 1723.5468120255996
INFO:root:current train perplexity3.882681369781494
INFO:root:current mean train loss 1724.3966450632354
INFO:root:current train perplexity3.884267568588257
INFO:root:current mean train loss 1725.1556300297166
INFO:root:current train perplexity3.886890172958374
INFO:root:current mean train loss 1724.4006479028712
INFO:root:current train perplexity3.8880722522735596
INFO:root:current mean train loss 1724.377314670343
INFO:root:current train perplexity3.8884029388427734
INFO:root:current mean train loss 1723.3147236806042
INFO:root:current train perplexity3.8879499435424805
INFO:root:current mean train loss 1722.8188535014876
INFO:root:current train perplexity3.8897347450256348
INFO:root:current mean train loss 1723.0823695830654
INFO:root:current train perplexity3.88964581489563

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.28s/it]
INFO:root:final mean train loss: 1722.9852166264814
INFO:root:final train perplexity: 3.8917148113250732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2007.0945101257757
INFO:root:eval perplexity: 5.069387912750244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 2471.018231331034
INFO:root:eval perplexity: 7.54486083984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/42
 21%|â–ˆâ–ˆ        | 42/200 [7:23:12<27:36:22, 629.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1686.9839618389424
INFO:root:current train perplexity3.831054210662842
INFO:root:current mean train loss 1707.81709222034
INFO:root:current train perplexity3.806530237197876
INFO:root:current mean train loss 1697.2383861273108
INFO:root:current train perplexity3.8229541778564453
INFO:root:current mean train loss 1698.5875189540486
INFO:root:current train perplexity3.8259544372558594
INFO:root:current mean train loss 1703.3810027263355
INFO:root:current train perplexity3.8320164680480957
INFO:root:current mean train loss 1704.2206179375305
INFO:root:current train perplexity3.8384666442871094
INFO:root:current mean train loss 1707.5904252268556
INFO:root:current train perplexity3.8468806743621826
INFO:root:current mean train loss 1709.4771377542077
INFO:root:current train perplexity3.8512208461761475
INFO:root:current mean train loss 1708.097571566536
INFO:root:current train perplexity3.8475215435028076
INFO:root:current mean train loss 1707.4764647635286
INFO:root:current train perplexity3.8480966091156006
INFO:root:current mean train loss 1708.2583233154537
INFO:root:current train perplexity3.848531484603882
INFO:root:current mean train loss 1709.712910147476
INFO:root:current train perplexity3.851022481918335
INFO:root:current mean train loss 1711.039894349302
INFO:root:current train perplexity3.8512935638427734
INFO:root:current mean train loss 1710.0134573919756
INFO:root:current train perplexity3.8502321243286133
INFO:root:current mean train loss 1710.393110033644
INFO:root:current train perplexity3.852739095687866
INFO:root:current mean train loss 1710.306091994382
INFO:root:current train perplexity3.8519110679626465
INFO:root:current mean train loss 1711.848280223792
INFO:root:current train perplexity3.8564670085906982
INFO:root:current mean train loss 1713.4410661918964
INFO:root:current train perplexity3.860464096069336
INFO:root:current mean train loss 1714.5767242549468
INFO:root:current train perplexity3.86417555809021
INFO:root:current mean train loss 1716.2029845521392
INFO:root:current train perplexity3.8682944774627686

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.81s/it]
INFO:root:final mean train loss: 1715.3359913943816
INFO:root:final train perplexity: 3.8683078289031982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2009.0189265257923
INFO:root:eval perplexity: 5.07728385925293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2472.558650889295
INFO:root:eval perplexity: 7.554369926452637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:33:44<27:28:27, 629.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.6858235677084
INFO:root:current train perplexity3.7933290004730225
INFO:root:current mean train loss 1695.1246553861179
INFO:root:current train perplexity3.803575038909912
INFO:root:current mean train loss 1697.128853175951
INFO:root:current train perplexity3.8005378246307373
INFO:root:current mean train loss 1701.0457697088068
INFO:root:current train perplexity3.815105438232422
INFO:root:current mean train loss 1700.3738829146985
INFO:root:current train perplexity3.812168836593628
INFO:root:current mean train loss 1701.7305869048496
INFO:root:current train perplexity3.8158726692199707
INFO:root:current mean train loss 1700.9127555726066
INFO:root:current train perplexity3.81496524810791
INFO:root:current mean train loss 1702.4703598231486
INFO:root:current train perplexity3.8239240646362305
INFO:root:current mean train loss 1703.0914853750942
INFO:root:current train perplexity3.8260838985443115
INFO:root:current mean train loss 1701.9127678983955
INFO:root:current train perplexity3.8245649337768555
INFO:root:current mean train loss 1700.6481895668992
INFO:root:current train perplexity3.8263134956359863
INFO:root:current mean train loss 1700.4804950005184
INFO:root:current train perplexity3.8252525329589844
INFO:root:current mean train loss 1700.8549090129573
INFO:root:current train perplexity3.8252170085906982
INFO:root:current mean train loss 1701.7451942845394
INFO:root:current train perplexity3.8310446739196777
INFO:root:current mean train loss 1703.3316127963833
INFO:root:current train perplexity3.833831787109375
INFO:root:current mean train loss 1705.4407851275275
INFO:root:current train perplexity3.8357596397399902
INFO:root:current mean train loss 1705.7243431418951
INFO:root:current train perplexity3.8377411365509033
INFO:root:current mean train loss 1707.9190678767386
INFO:root:current train perplexity3.8411083221435547
INFO:root:current mean train loss 1708.6627488099812
INFO:root:current train perplexity3.8428092002868652
INFO:root:current mean train loss 1708.1921732057563
INFO:root:current train perplexity3.843907117843628

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.66s/it]
INFO:root:final mean train loss: 1707.789335696191
INFO:root:final train perplexity: 3.845353126525879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2009.7694909927693
INFO:root:eval perplexity: 5.080367565155029
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 2474.0062545884584
INFO:root:eval perplexity: 7.563319683074951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:44:10<27:14:44, 628.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1668.6779187790892
INFO:root:current train perplexity3.757211446762085
INFO:root:current mean train loss 1688.9157158468856
INFO:root:current train perplexity3.783540964126587
INFO:root:current mean train loss 1690.9341022939334
INFO:root:current train perplexity3.793903112411499
INFO:root:current mean train loss 1690.377048811239
INFO:root:current train perplexity3.79854679107666
INFO:root:current mean train loss 1691.1161008830572
INFO:root:current train perplexity3.799663543701172
INFO:root:current mean train loss 1689.175499171618
INFO:root:current train perplexity3.8016538619995117
INFO:root:current mean train loss 1692.5663454978508
INFO:root:current train perplexity3.8043899536132812
INFO:root:current mean train loss 1693.4210893051372
INFO:root:current train perplexity3.8072926998138428
INFO:root:current mean train loss 1694.4229458174993
INFO:root:current train perplexity3.8095314502716064
INFO:root:current mean train loss 1694.7913479346787
INFO:root:current train perplexity3.812779426574707
INFO:root:current mean train loss 1695.4900376867315
INFO:root:current train perplexity3.813943862915039
INFO:root:current mean train loss 1696.6158138631008
INFO:root:current train perplexity3.81461501121521
INFO:root:current mean train loss 1696.3057284749023
INFO:root:current train perplexity3.813429355621338
INFO:root:current mean train loss 1697.4488014272167
INFO:root:current train perplexity3.815251350402832
INFO:root:current mean train loss 1698.3452021052447
INFO:root:current train perplexity3.815310001373291
INFO:root:current mean train loss 1699.5338641353476
INFO:root:current train perplexity3.818589210510254
INFO:root:current mean train loss 1700.0055251083884
INFO:root:current train perplexity3.820509433746338
INFO:root:current mean train loss 1700.8888766065488
INFO:root:current train perplexity3.820930242538452
INFO:root:current mean train loss 1700.6845545167205
INFO:root:current train perplexity3.8214786052703857
INFO:root:current mean train loss 1701.2865773942083
INFO:root:current train perplexity3.823611259460449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.95s/it]
INFO:root:final mean train loss: 1700.771035829699
INFO:root:final train perplexity: 3.824127435684204
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2013.001693400931
INFO:root:eval perplexity: 5.09366512298584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2480.3958112567875
INFO:root:eval perplexity: 7.6029462814331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:54:35<27:01:25, 627.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1705.243459701538
INFO:root:current train perplexity3.8046889305114746
INFO:root:current mean train loss 1690.0452992509051
INFO:root:current train perplexity3.7618510723114014
INFO:root:current mean train loss 1684.792241414388
INFO:root:current train perplexity3.7644577026367188
INFO:root:current mean train loss 1681.3492257254463
INFO:root:current train perplexity3.7566826343536377
INFO:root:current mean train loss 1679.0121417867726
INFO:root:current train perplexity3.760821580886841
INFO:root:current mean train loss 1682.6811153330702
INFO:root:current train perplexity3.7694525718688965
INFO:root:current mean train loss 1685.6235825871847
INFO:root:current train perplexity3.7712175846099854
INFO:root:current mean train loss 1684.493606167938
INFO:root:current train perplexity3.7766315937042236
INFO:root:current mean train loss 1687.7531818813748
INFO:root:current train perplexity3.7811124324798584
INFO:root:current mean train loss 1689.3116490534233
INFO:root:current train perplexity3.7827417850494385
INFO:root:current mean train loss 1689.6300656885132
INFO:root:current train perplexity3.7864999771118164
INFO:root:current mean train loss 1690.6551308123926
INFO:root:current train perplexity3.788808584213257
INFO:root:current mean train loss 1690.1118260637115
INFO:root:current train perplexity3.789109468460083
INFO:root:current mean train loss 1690.1193389445107
INFO:root:current train perplexity3.7922205924987793
INFO:root:current mean train loss 1689.9998736772382
INFO:root:current train perplexity3.793670415878296
INFO:root:current mean train loss 1689.9875635795886
INFO:root:current train perplexity3.7949531078338623
INFO:root:current mean train loss 1691.3067272626436
INFO:root:current train perplexity3.797553062438965
INFO:root:current mean train loss 1692.2059140713577
INFO:root:current train perplexity3.7983462810516357
INFO:root:current mean train loss 1693.0911637989748
INFO:root:current train perplexity3.799839735031128
INFO:root:current mean train loss 1693.823314472517
INFO:root:current train perplexity3.801957607269287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.88s/it]
INFO:root:final mean train loss: 1693.544124478231
INFO:root:final train perplexity: 3.802393674850464
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.18s/it]
INFO:root:eval mean loss: 2012.7312241141678
INFO:root:eval perplexity: 5.092550277709961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2480.2110777509974
INFO:root:eval perplexity: 7.601797103881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [8:05:02<26:50:23, 627.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1667.7593994140625
INFO:root:current train perplexity3.7309579849243164
INFO:root:current mean train loss 1672.6790677065349
INFO:root:current train perplexity3.740532398223877
INFO:root:current mean train loss 1667.2683157598422
INFO:root:current train perplexity3.7376279830932617
INFO:root:current mean train loss 1671.1486793978634
INFO:root:current train perplexity3.7394347190856934
INFO:root:current mean train loss 1672.0466136020336
INFO:root:current train perplexity3.7549381256103516
INFO:root:current mean train loss 1674.7947495898773
INFO:root:current train perplexity3.7544713020324707
INFO:root:current mean train loss 1675.4445228968773
INFO:root:current train perplexity3.753995180130005
INFO:root:current mean train loss 1676.6627405144645
INFO:root:current train perplexity3.7581863403320312
INFO:root:current mean train loss 1676.9555343991647
INFO:root:current train perplexity3.7635414600372314
INFO:root:current mean train loss 1678.8630614985507
INFO:root:current train perplexity3.7671027183532715
INFO:root:current mean train loss 1679.9696617444063
INFO:root:current train perplexity3.7699546813964844
INFO:root:current mean train loss 1681.4858412908154
INFO:root:current train perplexity3.7727162837982178
INFO:root:current mean train loss 1682.3119736968495
INFO:root:current train perplexity3.77268123626709
INFO:root:current mean train loss 1683.6542870634107
INFO:root:current train perplexity3.773644208908081
INFO:root:current mean train loss 1684.407377646148
INFO:root:current train perplexity3.772742986679077
INFO:root:current mean train loss 1685.6287708994257
INFO:root:current train perplexity3.7745683193206787
INFO:root:current mean train loss 1686.8689253135922
INFO:root:current train perplexity3.7770111560821533
INFO:root:current mean train loss 1687.247783748706
INFO:root:current train perplexity3.7779080867767334
INFO:root:current mean train loss 1686.563889109537
INFO:root:current train perplexity3.7797813415527344
INFO:root:current mean train loss 1687.1913638550607
INFO:root:current train perplexity3.782174587249756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.56s/it]
INFO:root:final mean train loss: 1686.8400951545166
INFO:root:final train perplexity: 3.7823429107666016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2014.470075025626
INFO:root:eval perplexity: 5.099717140197754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2484.1646845391456
INFO:root:eval perplexity: 7.6264166831970215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [8:15:23<26:34:50, 625.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.7787699796716
INFO:root:current train perplexity3.728654384613037
INFO:root:current mean train loss 1667.084835784604
INFO:root:current train perplexity3.718569278717041
INFO:root:current mean train loss 1664.2682937519662
INFO:root:current train perplexity3.7142655849456787
INFO:root:current mean train loss 1665.6010570430276
INFO:root:current train perplexity3.7292215824127197
INFO:root:current mean train loss 1666.2761176542106
INFO:root:current train perplexity3.7337963581085205
INFO:root:current mean train loss 1668.8259189567439
INFO:root:current train perplexity3.7386293411254883
INFO:root:current mean train loss 1670.9032860348764
INFO:root:current train perplexity3.7419426441192627
INFO:root:current mean train loss 1671.7407075121887
INFO:root:current train perplexity3.7436037063598633
INFO:root:current mean train loss 1674.896277616709
INFO:root:current train perplexity3.7496140003204346
INFO:root:current mean train loss 1675.459419571565
INFO:root:current train perplexity3.7466542720794678
INFO:root:current mean train loss 1676.132212376551
INFO:root:current train perplexity3.747681140899658
INFO:root:current mean train loss 1678.813778987114
INFO:root:current train perplexity3.751579523086548
INFO:root:current mean train loss 1679.333081919901
INFO:root:current train perplexity3.7513248920440674
INFO:root:current mean train loss 1679.3443978109074
INFO:root:current train perplexity3.754042625427246
INFO:root:current mean train loss 1679.7205921371724
INFO:root:current train perplexity3.7569468021392822
INFO:root:current mean train loss 1680.364457570865
INFO:root:current train perplexity3.759099006652832
INFO:root:current mean train loss 1680.1925652709529
INFO:root:current train perplexity3.760962724685669
INFO:root:current mean train loss 1681.0339116487937
INFO:root:current train perplexity3.7610697746276855
INFO:root:current mean train loss 1680.956829300168
INFO:root:current train perplexity3.762910842895508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.25s/it]
INFO:root:final mean train loss: 1680.4821393527109
INFO:root:final train perplexity: 3.7634243965148926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2017.8272016809342
INFO:root:eval perplexity: 5.113581657409668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2489.733055168855
INFO:root:eval perplexity: 7.661226749420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/48
 24%|â–ˆâ–ˆâ–       | 48/200 [8:25:56<26:30:27, 627.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1644.7877278645833
INFO:root:current train perplexity3.667869806289673
INFO:root:current mean train loss 1667.437198539402
INFO:root:current train perplexity3.707935333251953
INFO:root:current mean train loss 1657.8517430505087
INFO:root:current train perplexity3.7051777839660645
INFO:root:current mean train loss 1664.1497512090773
INFO:root:current train perplexity3.7158896923065186
INFO:root:current mean train loss 1665.3096770872553
INFO:root:current train perplexity3.7160723209381104
INFO:root:current mean train loss 1664.4196232175364
INFO:root:current train perplexity3.7151119709014893
INFO:root:current mean train loss 1664.017128548971
INFO:root:current train perplexity3.714712381362915
INFO:root:current mean train loss 1664.679988151497
INFO:root:current train perplexity3.7157692909240723
INFO:root:current mean train loss 1662.784721889379
INFO:root:current train perplexity3.715167760848999
INFO:root:current mean train loss 1662.9196593237705
INFO:root:current train perplexity3.7163026332855225
INFO:root:current mean train loss 1663.2845704327663
INFO:root:current train perplexity3.719540596008301
INFO:root:current mean train loss 1664.8005398463774
INFO:root:current train perplexity3.7215960025787354
INFO:root:current mean train loss 1665.7245504999357
INFO:root:current train perplexity3.7222211360931396
INFO:root:current mean train loss 1666.3493525167835
INFO:root:current train perplexity3.7245113849639893
INFO:root:current mean train loss 1668.801509530974
INFO:root:current train perplexity3.7292375564575195
INFO:root:current mean train loss 1669.4578332076371
INFO:root:current train perplexity3.7321746349334717
INFO:root:current mean train loss 1669.6565595975233
INFO:root:current train perplexity3.7324740886688232
INFO:root:current mean train loss 1670.233967221096
INFO:root:current train perplexity3.7340197563171387
INFO:root:current mean train loss 1670.7124757877066
INFO:root:current train perplexity3.7360994815826416
INFO:root:current mean train loss 1671.9609283845668
INFO:root:current train perplexity3.7371864318847656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.05s/it]
INFO:root:final mean train loss: 1672.2086884945375
INFO:root:final train perplexity: 3.738948345184326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2020.570479589151
INFO:root:eval perplexity: 5.124939918518066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2493.66986040697
INFO:root:eval perplexity: 7.685932636260986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:36:20<26:17:04, 626.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1650.7753639221191
INFO:root:current train perplexity3.7141761779785156
INFO:root:current mean train loss 1654.8256345806699
INFO:root:current train perplexity3.6811673641204834
INFO:root:current mean train loss 1659.1911636878704
INFO:root:current train perplexity3.682823896408081
INFO:root:current mean train loss 1657.8041348744587
INFO:root:current train perplexity3.682671546936035
INFO:root:current mean train loss 1660.7168533890335
INFO:root:current train perplexity3.689866542816162
INFO:root:current mean train loss 1661.1382951091107
INFO:root:current train perplexity3.6850290298461914
INFO:root:current mean train loss 1664.0775443934187
INFO:root:current train perplexity3.694831132888794
INFO:root:current mean train loss 1665.0141404782487
INFO:root:current train perplexity3.6996877193450928
INFO:root:current mean train loss 1664.9177488180308
INFO:root:current train perplexity3.701266050338745
INFO:root:current mean train loss 1665.580911529934
INFO:root:current train perplexity3.7042009830474854
INFO:root:current mean train loss 1665.4113878353621
INFO:root:current train perplexity3.7074880599975586
INFO:root:current mean train loss 1664.762368138182
INFO:root:current train perplexity3.7078757286071777
INFO:root:current mean train loss 1665.056517762023
INFO:root:current train perplexity3.7090158462524414
INFO:root:current mean train loss 1664.8622333881733
INFO:root:current train perplexity3.71071720123291
INFO:root:current mean train loss 1665.1360596385082
INFO:root:current train perplexity3.712527275085449
INFO:root:current mean train loss 1665.3652299925802
INFO:root:current train perplexity3.7138309478759766
INFO:root:current mean train loss 1664.6172268437404
INFO:root:current train perplexity3.7162680625915527
INFO:root:current mean train loss 1664.8600243971475
INFO:root:current train perplexity3.716125249862671
INFO:root:current mean train loss 1665.760676687982
INFO:root:current train perplexity3.7180674076080322
INFO:root:current mean train loss 1666.243854530603
INFO:root:current train perplexity3.7195420265197754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.68s/it]
INFO:root:final mean train loss: 1665.8787554319135
INFO:root:final train perplexity: 3.720329523086548
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 2023.3199346014794
INFO:root:eval perplexity: 5.136348247528076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2500.560839497451
INFO:root:eval perplexity: 7.729369163513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:47:00<26:16:13, 630.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1633.5379638671875
INFO:root:current train perplexity3.652491569519043
INFO:root:current mean train loss 1648.0084621762269
INFO:root:current train perplexity3.65690279006958
INFO:root:current mean train loss 1647.9222858229793
INFO:root:current train perplexity3.661452054977417
INFO:root:current mean train loss 1647.4197392941887
INFO:root:current train perplexity3.6687772274017334
INFO:root:current mean train loss 1648.79400077429
INFO:root:current train perplexity3.672466516494751
INFO:root:current mean train loss 1648.7264035195383
INFO:root:current train perplexity3.6753921508789062
INFO:root:current mean train loss 1651.0330417439088
INFO:root:current train perplexity3.6767728328704834
INFO:root:current mean train loss 1652.0675286775597
INFO:root:current train perplexity3.6773571968078613
INFO:root:current mean train loss 1651.7878274187462
INFO:root:current train perplexity3.675191879272461
INFO:root:current mean train loss 1651.993232493908
INFO:root:current train perplexity3.6777100563049316
INFO:root:current mean train loss 1652.7503201291036
INFO:root:current train perplexity3.6828489303588867
INFO:root:current mean train loss 1652.6777270444068
INFO:root:current train perplexity3.6832480430603027
INFO:root:current mean train loss 1655.048352353758
INFO:root:current train perplexity3.688479423522949
INFO:root:current mean train loss 1655.5274924242206
INFO:root:current train perplexity3.691826105117798
INFO:root:current mean train loss 1655.5351496789274
INFO:root:current train perplexity3.6923723220825195
INFO:root:current mean train loss 1656.493030250111
INFO:root:current train perplexity3.6957900524139404
INFO:root:current mean train loss 1657.2491503195592
INFO:root:current train perplexity3.6976985931396484
INFO:root:current mean train loss 1658.067513258134
INFO:root:current train perplexity3.699207067489624
INFO:root:current mean train loss 1658.718872334391
INFO:root:current train perplexity3.6996192932128906
INFO:root:current mean train loss 1660.1372979733196
INFO:root:current train perplexity3.7028191089630127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.72s/it]
INFO:root:final mean train loss: 1659.852260356832
INFO:root:final train perplexity: 3.7026891708374023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2023.5725218860816
INFO:root:eval perplexity: 5.137397289276123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2499.7196841409022
INFO:root:eval perplexity: 7.724052429199219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [8:57:27<26:03:17, 629.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.6143928296638
INFO:root:current train perplexity3.6125588417053223
INFO:root:current mean train loss 1633.9791215643825
INFO:root:current train perplexity3.6176223754882812
INFO:root:current mean train loss 1637.1852577611019
INFO:root:current train perplexity3.6353869438171387
INFO:root:current mean train loss 1634.4619594219603
INFO:root:current train perplexity3.633504867553711
INFO:root:current mean train loss 1641.5748998289969
INFO:root:current train perplexity3.6407430171966553
INFO:root:current mean train loss 1642.6060674552782
INFO:root:current train perplexity3.6451449394226074
INFO:root:current mean train loss 1642.9639892578125
INFO:root:current train perplexity3.6503407955169678
INFO:root:current mean train loss 1644.9426398613434
INFO:root:current train perplexity3.6533308029174805
INFO:root:current mean train loss 1645.086581117837
INFO:root:current train perplexity3.653714418411255
INFO:root:current mean train loss 1647.0915898862092
INFO:root:current train perplexity3.6597087383270264
INFO:root:current mean train loss 1650.2640535451235
INFO:root:current train perplexity3.664003610610962
INFO:root:current mean train loss 1651.0829293985514
INFO:root:current train perplexity3.6680517196655273
INFO:root:current mean train loss 1651.9190022979303
INFO:root:current train perplexity3.6719021797180176
INFO:root:current mean train loss 1652.6709920009093
INFO:root:current train perplexity3.6739320755004883
INFO:root:current mean train loss 1653.5187621071102
INFO:root:current train perplexity3.6765196323394775
INFO:root:current mean train loss 1653.869422259763
INFO:root:current train perplexity3.6773409843444824
INFO:root:current mean train loss 1652.5210735417213
INFO:root:current train perplexity3.677281379699707
INFO:root:current mean train loss 1653.672857230544
INFO:root:current train perplexity3.679158926010132
INFO:root:current mean train loss 1653.4863358443445
INFO:root:current train perplexity3.6794919967651367
INFO:root:current mean train loss 1653.3104198995225
INFO:root:current train perplexity3.682387590408325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.65s/it]
INFO:root:final mean train loss: 1652.8495604052907
INFO:root:final train perplexity: 3.6822967529296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2029.6816795836103
INFO:root:eval perplexity: 5.162843227386475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2507.221112190409
INFO:root:eval perplexity: 7.771586894989014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [9:07:52<25:49:53, 628.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.3118558217243
INFO:root:current train perplexity3.598766803741455
INFO:root:current mean train loss 1623.0514016073257
INFO:root:current train perplexity3.6278860569000244
INFO:root:current mean train loss 1625.4427265935567
INFO:root:current train perplexity3.626955270767212
INFO:root:current mean train loss 1630.1327726598197
INFO:root:current train perplexity3.627453327178955
INFO:root:current mean train loss 1630.8138073907382
INFO:root:current train perplexity3.629551649093628
INFO:root:current mean train loss 1634.015936143198
INFO:root:current train perplexity3.633096933364868
INFO:root:current mean train loss 1634.4927476293694
INFO:root:current train perplexity3.635009527206421
INFO:root:current mean train loss 1636.987417715567
INFO:root:current train perplexity3.6352617740631104
INFO:root:current mean train loss 1638.945995983154
INFO:root:current train perplexity3.6403555870056152
INFO:root:current mean train loss 1640.84639506374
INFO:root:current train perplexity3.6459667682647705
INFO:root:current mean train loss 1641.6681080657029
INFO:root:current train perplexity3.6464955806732178
INFO:root:current mean train loss 1642.691543901561
INFO:root:current train perplexity3.6495754718780518
INFO:root:current mean train loss 1643.5789440033125
INFO:root:current train perplexity3.6502699851989746
INFO:root:current mean train loss 1643.6343630489368
INFO:root:current train perplexity3.652768135070801
INFO:root:current mean train loss 1644.8134671788077
INFO:root:current train perplexity3.655834436416626
INFO:root:current mean train loss 1645.632780112425
INFO:root:current train perplexity3.657822370529175
INFO:root:current mean train loss 1645.5954642066345
INFO:root:current train perplexity3.6588850021362305
INFO:root:current mean train loss 1646.79364852349
INFO:root:current train perplexity3.6617469787597656
INFO:root:current mean train loss 1647.199994347036
INFO:root:current train perplexity3.6613054275512695
INFO:root:current mean train loss 1646.3553991274466
INFO:root:current train perplexity3.663485288619995

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.02s/it]
INFO:root:final mean train loss: 1646.3553991274466
INFO:root:final train perplexity: 3.663485288619995
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 2026.5749065859097
INFO:root:eval perplexity: 5.149886608123779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 2506.38590408217
INFO:root:eval perplexity: 7.766280174255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [9:18:27<25:44:16, 630.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.209423828125
INFO:root:current train perplexity3.58642315864563
INFO:root:current mean train loss 1612.9576159667968
INFO:root:current train perplexity3.5919277667999268
INFO:root:current mean train loss 1620.6335904947916
INFO:root:current train perplexity3.6001343727111816
INFO:root:current mean train loss 1621.3299569702149
INFO:root:current train perplexity3.6096348762512207
INFO:root:current mean train loss 1624.7268125
INFO:root:current train perplexity3.613393545150757
INFO:root:current mean train loss 1627.181034749349
INFO:root:current train perplexity3.6115851402282715
INFO:root:current mean train loss 1628.3182320731028
INFO:root:current train perplexity3.6140220165252686
INFO:root:current mean train loss 1628.413224182129
INFO:root:current train perplexity3.614806652069092
INFO:root:current mean train loss 1629.9410141330295
INFO:root:current train perplexity3.618142604827881
INFO:root:current mean train loss 1631.6411828613282
INFO:root:current train perplexity3.6212925910949707
INFO:root:current mean train loss 1631.7733617054332
INFO:root:current train perplexity3.6233558654785156
INFO:root:current mean train loss 1633.9873406982422
INFO:root:current train perplexity3.6284496784210205
INFO:root:current mean train loss 1634.501892559345
INFO:root:current train perplexity3.629849672317505
INFO:root:current mean train loss 1635.9385858154296
INFO:root:current train perplexity3.633143186569214
INFO:root:current mean train loss 1636.633782796224
INFO:root:current train perplexity3.635688543319702
INFO:root:current mean train loss 1637.9423918914795
INFO:root:current train perplexity3.6393051147460938
INFO:root:current mean train loss 1639.2398865464154
INFO:root:current train perplexity3.640533447265625
INFO:root:current mean train loss 1639.6047285970053
INFO:root:current train perplexity3.6410233974456787
INFO:root:current mean train loss 1640.2756523052014
INFO:root:current train perplexity3.642956018447876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it]
INFO:root:final mean train loss: 1639.7930142724388
INFO:root:final train perplexity: 3.644573450088501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2031.875748871066
INFO:root:eval perplexity: 5.172011852264404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2511.8411034117353
INFO:root:eval perplexity: 7.8010053634643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [9:28:58<25:34:18, 630.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.443359375
INFO:root:current train perplexity3.592785596847534
INFO:root:current mean train loss 1622.8834197215544
INFO:root:current train perplexity3.5823960304260254
INFO:root:current mean train loss 1623.8090623424898
INFO:root:current train perplexity3.588192939758301
INFO:root:current mean train loss 1621.994184139023
INFO:root:current train perplexity3.5897574424743652
INFO:root:current mean train loss 1620.4885054846748
INFO:root:current train perplexity3.5916926860809326
INFO:root:current mean train loss 1625.354299755576
INFO:root:current train perplexity3.5992631912231445
INFO:root:current mean train loss 1627.5926343525248
INFO:root:current train perplexity3.601327657699585
INFO:root:current mean train loss 1628.1656172365324
INFO:root:current train perplexity3.6030757427215576
INFO:root:current mean train loss 1629.3161077230914
INFO:root:current train perplexity3.604839324951172
INFO:root:current mean train loss 1630.4631744351486
INFO:root:current train perplexity3.6074135303497314
INFO:root:current mean train loss 1629.7662936860481
INFO:root:current train perplexity3.609135866165161
INFO:root:current mean train loss 1630.8845441061787
INFO:root:current train perplexity3.612342596054077
INFO:root:current mean train loss 1630.7524451175084
INFO:root:current train perplexity3.6136574745178223
INFO:root:current mean train loss 1631.2557309092042
INFO:root:current train perplexity3.6158008575439453
INFO:root:current mean train loss 1631.401367101353
INFO:root:current train perplexity3.6169652938842773
INFO:root:current mean train loss 1631.7461743791714
INFO:root:current train perplexity3.619102716445923
INFO:root:current mean train loss 1631.213222185181
INFO:root:current train perplexity3.6198043823242188
INFO:root:current mean train loss 1631.296119045642
INFO:root:current train perplexity3.620988130569458
INFO:root:current mean train loss 1631.9825506635466
INFO:root:current train perplexity3.6230883598327637
INFO:root:current mean train loss 1633.6330588056696
INFO:root:current train perplexity3.6257917881011963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.74s/it]
INFO:root:final mean train loss: 1633.4437567960476
INFO:root:final train perplexity: 3.6263692378997803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2037.6825306128103
INFO:root:eval perplexity: 5.1963582038879395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2520.2429220862423
INFO:root:eval perplexity: 7.854790687561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:39:33<25:26:34, 631.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1601.89503030216
INFO:root:current train perplexity3.577974796295166
INFO:root:current mean train loss 1612.2900809672342
INFO:root:current train perplexity3.5855722427368164
INFO:root:current mean train loss 1616.059594830896
INFO:root:current train perplexity3.577816963195801
INFO:root:current mean train loss 1617.2575482579762
INFO:root:current train perplexity3.573563814163208
INFO:root:current mean train loss 1616.3555885701685
INFO:root:current train perplexity3.5777297019958496
INFO:root:current mean train loss 1617.4213613445838
INFO:root:current train perplexity3.5761852264404297
INFO:root:current mean train loss 1617.8858621398733
INFO:root:current train perplexity3.581731081008911
INFO:root:current mean train loss 1618.2203374129874
INFO:root:current train perplexity3.5852959156036377
INFO:root:current mean train loss 1620.3453525753616
INFO:root:current train perplexity3.590705394744873
INFO:root:current mean train loss 1622.8689326872407
INFO:root:current train perplexity3.596216917037964
INFO:root:current mean train loss 1624.0203888116537
INFO:root:current train perplexity3.5996923446655273
INFO:root:current mean train loss 1624.6247576893531
INFO:root:current train perplexity3.6003129482269287
INFO:root:current mean train loss 1625.0831849826213
INFO:root:current train perplexity3.602407455444336
INFO:root:current mean train loss 1625.8122969460094
INFO:root:current train perplexity3.6044869422912598
INFO:root:current mean train loss 1626.213460371584
INFO:root:current train perplexity3.6055073738098145
INFO:root:current mean train loss 1627.270078179112
INFO:root:current train perplexity3.607506513595581
INFO:root:current mean train loss 1627.2064318802832
INFO:root:current train perplexity3.608025074005127
INFO:root:current mean train loss 1627.8312896059733
INFO:root:current train perplexity3.608804225921631
INFO:root:current mean train loss 1627.071378318928
INFO:root:current train perplexity3.608839750289917
INFO:root:current mean train loss 1627.4070702190852
INFO:root:current train perplexity3.609671115875244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.86s/it]
INFO:root:final mean train loss: 1627.6205307984076
INFO:root:final train perplexity: 3.6097538471221924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2038.485861920296
INFO:root:eval perplexity: 5.199734687805176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 2524.214384471271
INFO:root:eval perplexity: 7.880346298217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:49:57<25:10:17, 629.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1596.5043514476104
INFO:root:current train perplexity3.5349693298339844
INFO:root:current mean train loss 1591.033077012624
INFO:root:current train perplexity3.5291638374328613
INFO:root:current mean train loss 1604.8241885971738
INFO:root:current train perplexity3.549095869064331
INFO:root:current mean train loss 1611.9542980574474
INFO:root:current train perplexity3.557816982269287
INFO:root:current mean train loss 1613.4820721746812
INFO:root:current train perplexity3.5617423057556152
INFO:root:current mean train loss 1611.9138954564144
INFO:root:current train perplexity3.55916690826416
INFO:root:current mean train loss 1613.9239183182724
INFO:root:current train perplexity3.563959836959839
INFO:root:current mean train loss 1614.960518299819
INFO:root:current train perplexity3.565678834915161
INFO:root:current mean train loss 1615.114283775751
INFO:root:current train perplexity3.5695745944976807
INFO:root:current mean train loss 1614.7186299834466
INFO:root:current train perplexity3.5691123008728027
INFO:root:current mean train loss 1615.4857790989608
INFO:root:current train perplexity3.5721893310546875
INFO:root:current mean train loss 1616.6915125179871
INFO:root:current train perplexity3.5725135803222656
INFO:root:current mean train loss 1617.0472152551397
INFO:root:current train perplexity3.5747292041778564
INFO:root:current mean train loss 1618.2840807482016
INFO:root:current train perplexity3.5781466960906982
INFO:root:current mean train loss 1619.6246794707852
INFO:root:current train perplexity3.58084774017334
INFO:root:current mean train loss 1620.3434875999858
INFO:root:current train perplexity3.5820322036743164
INFO:root:current mean train loss 1620.8721683532235
INFO:root:current train perplexity3.584293842315674
INFO:root:current mean train loss 1622.0219369623608
INFO:root:current train perplexity3.588070869445801
INFO:root:current mean train loss 1621.4832661452003
INFO:root:current train perplexity3.588677406311035
INFO:root:current mean train loss 1621.2116459583026
INFO:root:current train perplexity3.5902628898620605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.94s/it]
INFO:root:final mean train loss: 1620.8100545001162
INFO:root:final train perplexity: 3.590416431427002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2038.4670847358434
INFO:root:eval perplexity: 5.1996564865112305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2522.9680682243184
INFO:root:eval perplexity: 7.872318267822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [10:00:20<24:55:56, 627.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1595.5200428682215
INFO:root:current train perplexity3.526423931121826
INFO:root:current mean train loss 1603.4012211390905
INFO:root:current train perplexity3.5343191623687744
INFO:root:current mean train loss 1602.6649147147564
INFO:root:current train perplexity3.5426294803619385
INFO:root:current mean train loss 1607.35907944389
INFO:root:current train perplexity3.5571236610412598
INFO:root:current mean train loss 1606.8978185409155
INFO:root:current train perplexity3.5523643493652344
INFO:root:current mean train loss 1608.6213383204501
INFO:root:current train perplexity3.5514214038848877
INFO:root:current mean train loss 1608.6712359582593
INFO:root:current train perplexity3.551232099533081
INFO:root:current mean train loss 1606.4116837183635
INFO:root:current train perplexity3.551569938659668
INFO:root:current mean train loss 1606.5301039735293
INFO:root:current train perplexity3.552788734436035
INFO:root:current mean train loss 1608.8274649627938
INFO:root:current train perplexity3.559370994567871
INFO:root:current mean train loss 1611.0252182635475
INFO:root:current train perplexity3.5625271797180176
INFO:root:current mean train loss 1611.3751589631381
INFO:root:current train perplexity3.5659632682800293
INFO:root:current mean train loss 1611.6841807079616
INFO:root:current train perplexity3.5665693283081055
INFO:root:current mean train loss 1611.530814009103
INFO:root:current train perplexity3.5671956539154053
INFO:root:current mean train loss 1612.459047821627
INFO:root:current train perplexity3.5686442852020264
INFO:root:current mean train loss 1613.2205712454659
INFO:root:current train perplexity3.5697150230407715
INFO:root:current mean train loss 1613.6641284384602
INFO:root:current train perplexity3.570392370223999
INFO:root:current mean train loss 1614.3295112022986
INFO:root:current train perplexity3.570457935333252
INFO:root:current mean train loss 1614.8971606628288
INFO:root:current train perplexity3.5717198848724365
INFO:root:current mean train loss 1615.4302843915739
INFO:root:current train perplexity3.57338285446167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it]
INFO:root:final mean train loss: 1614.9953790877241
INFO:root:final train perplexity: 3.5739898681640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.11s/it]
INFO:root:eval mean loss: 2039.2155805006096
INFO:root:eval perplexity: 5.202804088592529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2524.466035450604
INFO:root:eval perplexity: 7.881967544555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [10:11:02<24:55:05, 631.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1586.6255227481618
INFO:root:current train perplexity3.4921042919158936
INFO:root:current mean train loss 1591.5466064453126
INFO:root:current train perplexity3.5193233489990234
INFO:root:current mean train loss 1597.16108055784
INFO:root:current train perplexity3.532195806503296
INFO:root:current mean train loss 1599.2153199827517
INFO:root:current train perplexity3.540983200073242
INFO:root:current mean train loss 1600.4306285740174
INFO:root:current train perplexity3.540362596511841
INFO:root:current mean train loss 1601.0616108690572
INFO:root:current train perplexity3.539470672607422
INFO:root:current mean train loss 1600.892330776688
INFO:root:current train perplexity3.5396246910095215
INFO:root:current mean train loss 1601.324791936206
INFO:root:current train perplexity3.543071985244751
INFO:root:current mean train loss 1603.2538248697917
INFO:root:current train perplexity3.542341709136963
INFO:root:current mean train loss 1603.5459238429964
INFO:root:current train perplexity3.5424139499664307
INFO:root:current mean train loss 1602.6873638662873
INFO:root:current train perplexity3.5418050289154053
INFO:root:current mean train loss 1603.7615672179918
INFO:root:current train perplexity3.543381690979004
INFO:root:current mean train loss 1605.597023384302
INFO:root:current train perplexity3.5452046394348145
INFO:root:current mean train loss 1605.6771717057761
INFO:root:current train perplexity3.546854257583618
INFO:root:current mean train loss 1606.365231497922
INFO:root:current train perplexity3.5493323802948
INFO:root:current mean train loss 1607.5290515791355
INFO:root:current train perplexity3.551088809967041
INFO:root:current mean train loss 1608.3922476295902
INFO:root:current train perplexity3.554795026779175
INFO:root:current mean train loss 1609.1114014355742
INFO:root:current train perplexity3.5557055473327637
INFO:root:current mean train loss 1609.3196989104981
INFO:root:current train perplexity3.5577380657196045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.60s/it]
INFO:root:final mean train loss: 1609.3650609034212
INFO:root:final train perplexity: 3.558155059814453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2045.855543204233
INFO:root:eval perplexity: 5.230818748474121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2535.2139524635695
INFO:root:eval perplexity: 7.9515557289123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [10:21:28<24:40:27, 629.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1615.5049438476562
INFO:root:current train perplexity3.476586103439331
INFO:root:current mean train loss 1573.8495232077205
INFO:root:current train perplexity3.4663748741149902
INFO:root:current mean train loss 1582.9207123104889
INFO:root:current train perplexity3.4912471771240234
INFO:root:current mean train loss 1585.8744692770852
INFO:root:current train perplexity3.4933784008026123
INFO:root:current mean train loss 1588.0780539441464
INFO:root:current train perplexity3.4987142086029053
INFO:root:current mean train loss 1589.901382263913
INFO:root:current train perplexity3.5065691471099854
INFO:root:current mean train loss 1593.4991406412219
INFO:root:current train perplexity3.5161378383636475
INFO:root:current mean train loss 1594.5220629048144
INFO:root:current train perplexity3.5181188583374023
INFO:root:current mean train loss 1595.96302152334
INFO:root:current train perplexity3.519239664077759
INFO:root:current mean train loss 1597.8371460231604
INFO:root:current train perplexity3.522873878479004
INFO:root:current mean train loss 1598.769897339111
INFO:root:current train perplexity3.528036117553711
INFO:root:current mean train loss 1601.4011460873696
INFO:root:current train perplexity3.5319082736968994
INFO:root:current mean train loss 1601.6702346674813
INFO:root:current train perplexity3.5315334796905518
INFO:root:current mean train loss 1601.7628991380448
INFO:root:current train perplexity3.535284996032715
INFO:root:current mean train loss 1601.8686506894448
INFO:root:current train perplexity3.537719964981079
INFO:root:current mean train loss 1602.3413008729246
INFO:root:current train perplexity3.539008617401123
INFO:root:current mean train loss 1602.2892235840454
INFO:root:current train perplexity3.5408682823181152
INFO:root:current mean train loss 1602.172501990994
INFO:root:current train perplexity3.539517402648926
INFO:root:current mean train loss 1602.6369563196924
INFO:root:current train perplexity3.539522171020508
INFO:root:current mean train loss 1602.8674557722957
INFO:root:current train perplexity3.5403075218200684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.34s/it]
INFO:root:final mean train loss: 1603.3731304097523
INFO:root:final train perplexity: 3.5413804054260254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2046.6813536299037
INFO:root:eval perplexity: 5.234313011169434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2536.8022872167276
INFO:root:eval perplexity: 7.961892604827881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [10:31:54<24:27:37, 628.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1583.6939311780427
INFO:root:current train perplexity3.5095365047454834
INFO:root:current mean train loss 1586.517613002232
INFO:root:current train perplexity3.500272750854492
INFO:root:current mean train loss 1590.9773774168807
INFO:root:current train perplexity3.4965906143188477
INFO:root:current mean train loss 1588.0639307865156
INFO:root:current train perplexity3.494925022125244
INFO:root:current mean train loss 1584.4402656646218
INFO:root:current train perplexity3.4901161193847656
INFO:root:current mean train loss 1588.4262043800427
INFO:root:current train perplexity3.4969120025634766
INFO:root:current mean train loss 1587.3986633004972
INFO:root:current train perplexity3.50107479095459
INFO:root:current mean train loss 1589.383186860277
INFO:root:current train perplexity3.506542682647705
INFO:root:current mean train loss 1589.2794037424164
INFO:root:current train perplexity3.506007194519043
INFO:root:current mean train loss 1589.589873636638
INFO:root:current train perplexity3.5074729919433594
INFO:root:current mean train loss 1590.4217144757422
INFO:root:current train perplexity3.509542465209961
INFO:root:current mean train loss 1591.0612651153374
INFO:root:current train perplexity3.5111989974975586
INFO:root:current mean train loss 1591.8200425233285
INFO:root:current train perplexity3.511993646621704
INFO:root:current mean train loss 1592.6137151132486
INFO:root:current train perplexity3.5142786502838135
INFO:root:current mean train loss 1593.5516303225754
INFO:root:current train perplexity3.5154035091400146
INFO:root:current mean train loss 1594.255107344727
INFO:root:current train perplexity3.5164124965667725
INFO:root:current mean train loss 1595.228325922155
INFO:root:current train perplexity3.5187325477600098
INFO:root:current mean train loss 1595.9096910477795
INFO:root:current train perplexity3.5203890800476074
INFO:root:current mean train loss 1596.3600044774773
INFO:root:current train perplexity3.522726535797119
INFO:root:current mean train loss 1596.7254265272848
INFO:root:current train perplexity3.52250599861145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.48s/it]
INFO:root:final mean train loss: 1596.938781368931
INFO:root:final train perplexity: 3.5234551429748535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 2048.9185137376717
INFO:root:eval perplexity: 5.2437920570373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2538.9908745948305
INFO:root:eval perplexity: 7.976155757904053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:42:19<24:14:10, 627.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1565.6332499186199
INFO:root:current train perplexity3.447144031524658
INFO:root:current mean train loss 1566.1076319077436
INFO:root:current train perplexity3.449556350708008
INFO:root:current mean train loss 1573.4976108357057
INFO:root:current train perplexity3.4717960357666016
INFO:root:current mean train loss 1580.3129356020972
INFO:root:current train perplexity3.480560779571533
INFO:root:current mean train loss 1579.1129967925744
INFO:root:current train perplexity3.481293201446533
INFO:root:current mean train loss 1579.3376890723384
INFO:root:current train perplexity3.4800045490264893
INFO:root:current mean train loss 1579.8575905853847
INFO:root:current train perplexity3.480503559112549
INFO:root:current mean train loss 1582.8052104452381
INFO:root:current train perplexity3.484292507171631
INFO:root:current mean train loss 1583.8163963208358
INFO:root:current train perplexity3.4892616271972656
INFO:root:current mean train loss 1584.1539304032285
INFO:root:current train perplexity3.488675594329834
INFO:root:current mean train loss 1583.8939349200275
INFO:root:current train perplexity3.487508535385132
INFO:root:current mean train loss 1583.8257594578702
INFO:root:current train perplexity3.4879109859466553
INFO:root:current mean train loss 1584.6545177077012
INFO:root:current train perplexity3.4927265644073486
INFO:root:current mean train loss 1586.593441352159
INFO:root:current train perplexity3.496617317199707
INFO:root:current mean train loss 1586.7532726064699
INFO:root:current train perplexity3.4993343353271484
INFO:root:current mean train loss 1588.2803650697072
INFO:root:current train perplexity3.503208637237549
INFO:root:current mean train loss 1589.3251002528557
INFO:root:current train perplexity3.504795789718628
INFO:root:current mean train loss 1590.1873854536066
INFO:root:current train perplexity3.506535291671753
INFO:root:current mean train loss 1591.1541187560636
INFO:root:current train perplexity3.5069310665130615
INFO:root:current mean train loss 1591.8077325742106
INFO:root:current train perplexity3.5075886249542236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.77s/it]
INFO:root:final mean train loss: 1591.0894517768709
INFO:root:final train perplexity: 3.5072379112243652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2054.246994126773
INFO:root:eval perplexity: 5.2664384841918945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 2547.0307457024323
INFO:root:eval perplexity: 8.028772354125977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:52:43<24:01:08, 626.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1568.2776615934552
INFO:root:current train perplexity3.4279844760894775
INFO:root:current mean train loss 1572.288743361928
INFO:root:current train perplexity3.452946901321411
INFO:root:current mean train loss 1583.120379180305
INFO:root:current train perplexity3.4759409427642822
INFO:root:current mean train loss 1582.6239404435198
INFO:root:current train perplexity3.4780023097991943
INFO:root:current mean train loss 1583.954167043926
INFO:root:current train perplexity3.4820611476898193
INFO:root:current mean train loss 1583.3701787745113
INFO:root:current train perplexity3.48149037361145
INFO:root:current mean train loss 1583.5540068598655
INFO:root:current train perplexity3.4789135456085205
INFO:root:current mean train loss 1583.5925633403886
INFO:root:current train perplexity3.4748568534851074
INFO:root:current mean train loss 1582.8555530400517
INFO:root:current train perplexity3.4742491245269775
INFO:root:current mean train loss 1581.2852454010363
INFO:root:current train perplexity3.472808599472046
INFO:root:current mean train loss 1582.2597425556817
INFO:root:current train perplexity3.476977825164795
INFO:root:current mean train loss 1581.8223581570496
INFO:root:current train perplexity3.4776501655578613
INFO:root:current mean train loss 1582.063225699727
INFO:root:current train perplexity3.4786038398742676
INFO:root:current mean train loss 1582.84579009897
INFO:root:current train perplexity3.4823360443115234
INFO:root:current mean train loss 1582.9072671405875
INFO:root:current train perplexity3.4832987785339355
INFO:root:current mean train loss 1582.6834724657165
INFO:root:current train perplexity3.4855568408966064
INFO:root:current mean train loss 1583.572965480022
INFO:root:current train perplexity3.486017942428589
INFO:root:current mean train loss 1583.8422464391401
INFO:root:current train perplexity3.4870617389678955
INFO:root:current mean train loss 1584.5428630172146
INFO:root:current train perplexity3.489300012588501
INFO:root:current mean train loss 1585.095948015673
INFO:root:current train perplexity3.490365743637085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.99s/it]
INFO:root:final mean train loss: 1585.2250238785043
INFO:root:final train perplexity: 3.491054058074951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2056.1472518596242
INFO:root:eval perplexity: 5.274538516998291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2550.7084618967474
INFO:root:eval perplexity: 8.052956581115723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [11:03:20<23:57:57, 629.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1577.7120413643972
INFO:root:current train perplexity3.446331262588501
INFO:root:current mean train loss 1575.263276941636
INFO:root:current train perplexity3.4379055500030518
INFO:root:current mean train loss 1569.398083948206
INFO:root:current train perplexity3.434365749359131
INFO:root:current mean train loss 1566.1330500422298
INFO:root:current train perplexity3.4390292167663574
INFO:root:current mean train loss 1570.0680191364695
INFO:root:current train perplexity3.4473836421966553
INFO:root:current mean train loss 1571.768628572163
INFO:root:current train perplexity3.454383134841919
INFO:root:current mean train loss 1571.517578489389
INFO:root:current train perplexity3.453064441680908
INFO:root:current mean train loss 1572.113003341873
INFO:root:current train perplexity3.454045295715332
INFO:root:current mean train loss 1572.475802156295
INFO:root:current train perplexity3.458176612854004
INFO:root:current mean train loss 1572.3513652998147
INFO:root:current train perplexity3.4572291374206543
INFO:root:current mean train loss 1571.9785083235981
INFO:root:current train perplexity3.459268569946289
INFO:root:current mean train loss 1572.9885994674812
INFO:root:current train perplexity3.463123083114624
INFO:root:current mean train loss 1573.1983399398684
INFO:root:current train perplexity3.4647066593170166
INFO:root:current mean train loss 1574.773052221145
INFO:root:current train perplexity3.4667530059814453
INFO:root:current mean train loss 1575.6835054773862
INFO:root:current train perplexity3.4678099155426025
INFO:root:current mean train loss 1576.0320065249302
INFO:root:current train perplexity3.469271659851074
INFO:root:current mean train loss 1576.8426344089166
INFO:root:current train perplexity3.469956159591675
INFO:root:current mean train loss 1577.564790232168
INFO:root:current train perplexity3.4700918197631836
INFO:root:current mean train loss 1578.6711652949532
INFO:root:current train perplexity3.4718117713928223
INFO:root:current mean train loss 1579.9693818532876
INFO:root:current train perplexity3.475008726119995

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.52s/it]
INFO:root:final mean train loss: 1579.4664811111734
INFO:root:final train perplexity: 3.4752357006073
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2056.250509492049
INFO:root:eval perplexity: 5.2749786376953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2551.973982141373
INFO:root:eval perplexity: 8.061295509338379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [11:13:43<23:42:45, 627.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1565.0230320020653
INFO:root:current train perplexity3.4083213806152344
INFO:root:current mean train loss 1562.8581471162684
INFO:root:current train perplexity3.426487445831299
INFO:root:current mean train loss 1566.6273622944796
INFO:root:current train perplexity3.4416415691375732
INFO:root:current mean train loss 1565.138433412064
INFO:root:current train perplexity3.4366509914398193
INFO:root:current mean train loss 1565.3627385760235
INFO:root:current train perplexity3.4414610862731934
INFO:root:current mean train loss 1568.049655166964
INFO:root:current train perplexity3.4402642250061035
INFO:root:current mean train loss 1566.0962784724118
INFO:root:current train perplexity3.4403183460235596
INFO:root:current mean train loss 1566.741957629348
INFO:root:current train perplexity3.4432897567749023
INFO:root:current mean train loss 1567.5173250389744
INFO:root:current train perplexity3.444814443588257
INFO:root:current mean train loss 1567.8453025315428
INFO:root:current train perplexity3.448030948638916
INFO:root:current mean train loss 1568.5451255875546
INFO:root:current train perplexity3.451319694519043
INFO:root:current mean train loss 1569.602270754627
INFO:root:current train perplexity3.4531641006469727
INFO:root:current mean train loss 1570.6198675456487
INFO:root:current train perplexity3.4556987285614014
INFO:root:current mean train loss 1570.246865336467
INFO:root:current train perplexity3.455915927886963
INFO:root:current mean train loss 1571.281306643252
INFO:root:current train perplexity3.456465005874634
INFO:root:current mean train loss 1571.9589198400333
INFO:root:current train perplexity3.457399368286133
INFO:root:current mean train loss 1572.7654719598631
INFO:root:current train perplexity3.4579343795776367
INFO:root:current mean train loss 1572.427558339636
INFO:root:current train perplexity3.4586541652679443
INFO:root:current mean train loss 1573.6055878445657
INFO:root:current train perplexity3.459756374359131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.65s/it]
INFO:root:final mean train loss: 1574.0623338230919
INFO:root:final train perplexity: 3.4604556560516357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.88s/it]
INFO:root:eval mean loss: 2062.0079315401986
INFO:root:eval perplexity: 5.299598217010498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2557.3163430504765
INFO:root:eval perplexity: 8.096596717834473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [11:24:18<23:37:00, 629.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1503.1884765625
INFO:root:current train perplexity3.358572483062744
INFO:root:current mean train loss 1546.3584571251502
INFO:root:current train perplexity3.4005398750305176
INFO:root:current mean train loss 1548.1670274921491
INFO:root:current train perplexity3.40643572807312
INFO:root:current mean train loss 1549.5629645899724
INFO:root:current train perplexity3.4143192768096924
INFO:root:current mean train loss 1553.1815046555926
INFO:root:current train perplexity3.417799711227417
INFO:root:current mean train loss 1556.6954343281095
INFO:root:current train perplexity3.423212766647339
INFO:root:current mean train loss 1559.252531140056
INFO:root:current train perplexity3.4241933822631836
INFO:root:current mean train loss 1561.0927326895974
INFO:root:current train perplexity3.4285237789154053
INFO:root:current mean train loss 1562.7746758152596
INFO:root:current train perplexity3.4318017959594727
INFO:root:current mean train loss 1564.109103177501
INFO:root:current train perplexity3.4357759952545166
INFO:root:current mean train loss 1565.1286638115507
INFO:root:current train perplexity3.438304901123047
INFO:root:current mean train loss 1566.3685177789218
INFO:root:current train perplexity3.4392895698547363
INFO:root:current mean train loss 1566.6065835033937
INFO:root:current train perplexity3.4385671615600586
INFO:root:current mean train loss 1567.087141072092
INFO:root:current train perplexity3.439769983291626
INFO:root:current mean train loss 1567.586060787538
INFO:root:current train perplexity3.4412453174591064
INFO:root:current mean train loss 1568.818799363806
INFO:root:current train perplexity3.443476438522339
INFO:root:current mean train loss 1568.6062267427135
INFO:root:current train perplexity3.4430994987487793
INFO:root:current mean train loss 1568.5710218545976
INFO:root:current train perplexity3.443840503692627
INFO:root:current mean train loss 1568.2137254939112
INFO:root:current train perplexity3.4433705806732178
INFO:root:current mean train loss 1568.8626440993878
INFO:root:current train perplexity3.4453158378601074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.55s/it]
INFO:root:final mean train loss: 1568.731898874811
INFO:root:final train perplexity: 3.4459385871887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 2068.4012161146666
INFO:root:eval perplexity: 5.327071189880371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 2566.0082375817265
INFO:root:eval perplexity: 8.154354095458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [11:34:42<23:22:51, 628.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1568.523670014881
INFO:root:current train perplexity3.4325406551361084
INFO:root:current mean train loss 1557.4013248159865
INFO:root:current train perplexity3.4122724533081055
INFO:root:current mean train loss 1564.689188547264
INFO:root:current train perplexity3.419482946395874
INFO:root:current mean train loss 1558.106758284049
INFO:root:current train perplexity3.412708282470703
INFO:root:current mean train loss 1555.0755484755418
INFO:root:current train perplexity3.408231258392334
INFO:root:current mean train loss 1555.1847078466142
INFO:root:current train perplexity3.409926176071167
INFO:root:current mean train loss 1555.2493064990942
INFO:root:current train perplexity3.411529302597046
INFO:root:current mean train loss 1555.511690645046
INFO:root:current train perplexity3.4093539714813232
INFO:root:current mean train loss 1556.3628323702517
INFO:root:current train perplexity3.4118916988372803
INFO:root:current mean train loss 1556.1126852128716
INFO:root:current train perplexity3.4143993854522705
INFO:root:current mean train loss 1555.8446733584951
INFO:root:current train perplexity3.416090250015259
INFO:root:current mean train loss 1557.1870647501883
INFO:root:current train perplexity3.4163622856140137
INFO:root:current mean train loss 1556.6994976821636
INFO:root:current train perplexity3.4172110557556152
INFO:root:current mean train loss 1556.808255908166
INFO:root:current train perplexity3.418724775314331
INFO:root:current mean train loss 1557.9725687133016
INFO:root:current train perplexity3.420020580291748
INFO:root:current mean train loss 1560.2219231058154
INFO:root:current train perplexity3.421994924545288
INFO:root:current mean train loss 1561.3544742647769
INFO:root:current train perplexity3.423664093017578
INFO:root:current mean train loss 1562.037432673364
INFO:root:current train perplexity3.4268105030059814
INFO:root:current mean train loss 1562.5809035240982
INFO:root:current train perplexity3.428595781326294
INFO:root:current mean train loss 1562.7132135616623
INFO:root:current train perplexity3.428623914718628

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.89s/it]
INFO:root:final mean train loss: 1562.761851469916
INFO:root:final train perplexity: 3.4297523498535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 2065.4712117513022
INFO:root:eval perplexity: 5.314463138580322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2564.7822914935173
INFO:root:eval perplexity: 8.146183013916016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:45:17<23:16:44, 630.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1521.4516730057567
INFO:root:current train perplexity3.3608198165893555
INFO:root:current mean train loss 1532.3591264365375
INFO:root:current train perplexity3.3526241779327393
INFO:root:current mean train loss 1539.0479977391346
INFO:root:current train perplexity3.365752696990967
INFO:root:current mean train loss 1543.1001157139885
INFO:root:current train perplexity3.3750243186950684
INFO:root:current mean train loss 1543.5433711918522
INFO:root:current train perplexity3.3791990280151367
INFO:root:current mean train loss 1545.158297740837
INFO:root:current train perplexity3.3814117908477783
INFO:root:current mean train loss 1547.539148025752
INFO:root:current train perplexity3.388136863708496
INFO:root:current mean train loss 1548.1452357181042
INFO:root:current train perplexity3.39456844329834
INFO:root:current mean train loss 1550.2041014168315
INFO:root:current train perplexity3.3995110988616943
INFO:root:current mean train loss 1550.9992664068748
INFO:root:current train perplexity3.4007375240325928
INFO:root:current mean train loss 1549.7460424757646
INFO:root:current train perplexity3.3982365131378174
INFO:root:current mean train loss 1550.4024313874738
INFO:root:current train perplexity3.3987553119659424
INFO:root:current mean train loss 1552.336854111975
INFO:root:current train perplexity3.401705741882324
INFO:root:current mean train loss 1554.0259419485415
INFO:root:current train perplexity3.4058475494384766
INFO:root:current mean train loss 1555.1629883152057
INFO:root:current train perplexity3.4073362350463867
INFO:root:current mean train loss 1555.9833315289998
INFO:root:current train perplexity3.4092373847961426
INFO:root:current mean train loss 1556.611576811589
INFO:root:current train perplexity3.4108450412750244
INFO:root:current mean train loss 1556.802535887829
INFO:root:current train perplexity3.4131507873535156
INFO:root:current mean train loss 1556.6242523027322
INFO:root:current train perplexity3.413722515106201
INFO:root:current mean train loss 1557.6010738408233
INFO:root:current train perplexity3.4146556854248047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.68s/it]
INFO:root:final mean train loss: 1557.6722149254995
INFO:root:final train perplexity: 3.4160122871398926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2070.931868316434
INFO:root:eval perplexity: 5.337984561920166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2568.221705659907
INFO:root:eval perplexity: 8.169129371643066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [11:55:41<23:02:16, 628.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1543.4802712180397
INFO:root:current train perplexity3.3594086170196533
INFO:root:current mean train loss 1545.1564366494456
INFO:root:current train perplexity3.3697690963745117
INFO:root:current mean train loss 1542.1904430912991
INFO:root:current train perplexity3.364457607269287
INFO:root:current mean train loss 1540.3949944294675
INFO:root:current train perplexity3.363518238067627
INFO:root:current mean train loss 1543.695568713513
INFO:root:current train perplexity3.3662331104278564
INFO:root:current mean train loss 1543.2973285297016
INFO:root:current train perplexity3.3631062507629395
INFO:root:current mean train loss 1543.1283013030773
INFO:root:current train perplexity3.3681654930114746
INFO:root:current mean train loss 1545.2617287743171
INFO:root:current train perplexity3.37449049949646
INFO:root:current mean train loss 1546.2950131064968
INFO:root:current train perplexity3.3784773349761963
INFO:root:current mean train loss 1546.6703063645289
INFO:root:current train perplexity3.3796608448028564
INFO:root:current mean train loss 1548.0278765782361
INFO:root:current train perplexity3.3819119930267334
INFO:root:current mean train loss 1546.852176550663
INFO:root:current train perplexity3.380531072616577
INFO:root:current mean train loss 1548.0905927072959
INFO:root:current train perplexity3.3857433795928955
INFO:root:current mean train loss 1548.2295874113527
INFO:root:current train perplexity3.387904167175293
INFO:root:current mean train loss 1548.5207483455488
INFO:root:current train perplexity3.3877124786376953
INFO:root:current mean train loss 1549.8588971594907
INFO:root:current train perplexity3.390679121017456
INFO:root:current mean train loss 1550.0719060523272
INFO:root:current train perplexity3.392382860183716
INFO:root:current mean train loss 1551.1586823640046
INFO:root:current train perplexity3.394251823425293
INFO:root:current mean train loss 1550.6753146189565
INFO:root:current train perplexity3.39582896232605
INFO:root:current mean train loss 1551.9896001713355
INFO:root:current train perplexity3.3999125957489014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.01s/it]
INFO:root:final mean train loss: 1551.8575845430792
INFO:root:final train perplexity: 3.400383710861206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2073.843856919742
INFO:root:eval perplexity: 5.350569725036621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2575.689589047263
INFO:root:eval perplexity: 8.219173431396484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [12:06:08<22:50:54, 627.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1556.2358907063801
INFO:root:current train perplexity3.3861279487609863
INFO:root:current mean train loss 1547.9367477062137
INFO:root:current train perplexity3.37109375
INFO:root:current mean train loss 1545.9420179479262
INFO:root:current train perplexity3.3742101192474365
INFO:root:current mean train loss 1545.5171351278982
INFO:root:current train perplexity3.3748135566711426
INFO:root:current mean train loss 1540.8910444873875
INFO:root:current train perplexity3.369297504425049
INFO:root:current mean train loss 1538.850734257198
INFO:root:current train perplexity3.365988254547119
INFO:root:current mean train loss 1539.6808873131163
INFO:root:current train perplexity3.3674633502960205
INFO:root:current mean train loss 1541.114856463022
INFO:root:current train perplexity3.3700196743011475
INFO:root:current mean train loss 1541.3413762083842
INFO:root:current train perplexity3.372171401977539
INFO:root:current mean train loss 1543.0643404736932
INFO:root:current train perplexity3.3744888305664062
INFO:root:current mean train loss 1542.0558429547211
INFO:root:current train perplexity3.376638889312744
INFO:root:current mean train loss 1542.3161197180634
INFO:root:current train perplexity3.376328229904175
INFO:root:current mean train loss 1541.7860800305252
INFO:root:current train perplexity3.3773481845855713
INFO:root:current mean train loss 1543.2826088774657
INFO:root:current train perplexity3.380338191986084
INFO:root:current mean train loss 1544.2212110602338
INFO:root:current train perplexity3.3822572231292725
INFO:root:current mean train loss 1544.3368440972636
INFO:root:current train perplexity3.3822216987609863
INFO:root:current mean train loss 1544.8283698707105
INFO:root:current train perplexity3.3821165561676025
INFO:root:current mean train loss 1546.3981802705716
INFO:root:current train perplexity3.384629249572754
INFO:root:current mean train loss 1547.32834110097
INFO:root:current train perplexity3.386622905731201
INFO:root:current mean train loss 1548.0530691398326
INFO:root:current train perplexity3.3891026973724365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.64s/it]
INFO:root:final mean train loss: 1547.6564817058277
INFO:root:final train perplexity: 3.3891358375549316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2080.151915638159
INFO:root:eval perplexity: 5.377935886383057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2584.4086134890294
INFO:root:eval perplexity: 8.277992248535156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [12:16:40<22:43:13, 629.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1511.657057858585
INFO:root:current train perplexity3.3291962146759033
INFO:root:current mean train loss 1518.3059069113756
INFO:root:current train perplexity3.332998514175415
INFO:root:current mean train loss 1527.87920107726
INFO:root:current train perplexity3.333498239517212
INFO:root:current mean train loss 1527.4918693012935
INFO:root:current train perplexity3.339169502258301
INFO:root:current mean train loss 1529.315319349917
INFO:root:current train perplexity3.3440568447113037
INFO:root:current mean train loss 1531.0273431282496
INFO:root:current train perplexity3.3491129875183105
INFO:root:current mean train loss 1532.5215871337537
INFO:root:current train perplexity3.35194993019104
INFO:root:current mean train loss 1534.354536745485
INFO:root:current train perplexity3.352842330932617
INFO:root:current mean train loss 1535.9265142211227
INFO:root:current train perplexity3.3575243949890137
INFO:root:current mean train loss 1537.8863822852154
INFO:root:current train perplexity3.362565040588379
INFO:root:current mean train loss 1536.39385599604
INFO:root:current train perplexity3.3602499961853027
INFO:root:current mean train loss 1536.8304137413595
INFO:root:current train perplexity3.3611443042755127
INFO:root:current mean train loss 1536.2033900696701
INFO:root:current train perplexity3.3597309589385986
INFO:root:current mean train loss 1537.1897322432956
INFO:root:current train perplexity3.363145351409912
INFO:root:current mean train loss 1538.1278463943922
INFO:root:current train perplexity3.364640474319458
INFO:root:current mean train loss 1539.0635719755448
INFO:root:current train perplexity3.3672754764556885
INFO:root:current mean train loss 1539.486622568134
INFO:root:current train perplexity3.368199586868286
INFO:root:current mean train loss 1540.4830954110842
INFO:root:current train perplexity3.368833303451538
INFO:root:current mean train loss 1541.6176801109011
INFO:root:current train perplexity3.3720641136169434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.26s/it]
INFO:root:final mean train loss: 1541.6585147951928
INFO:root:final train perplexity: 3.3731420040130615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.38s/it]
INFO:root:eval mean loss: 2077.672109617409
INFO:root:eval perplexity: 5.367162227630615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2582.237891231023
INFO:root:eval perplexity: 8.263307571411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [12:27:10<22:33:30, 629.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1551.5790608723958
INFO:root:current train perplexity3.3001952171325684
INFO:root:current mean train loss 1513.7764362839032
INFO:root:current train perplexity3.3111488819122314
INFO:root:current mean train loss 1524.7996707657007
INFO:root:current train perplexity3.315002679824829
INFO:root:current mean train loss 1526.8111687953176
INFO:root:current train perplexity3.3214364051818848
INFO:root:current mean train loss 1528.9829769040564
INFO:root:current train perplexity3.3247687816619873
INFO:root:current mean train loss 1526.9051518496788
INFO:root:current train perplexity3.327988386154175
INFO:root:current mean train loss 1526.9987885629382
INFO:root:current train perplexity3.3272485733032227
INFO:root:current mean train loss 1526.6596575945025
INFO:root:current train perplexity3.329559803009033
INFO:root:current mean train loss 1526.9804034741878
INFO:root:current train perplexity3.336416721343994
INFO:root:current mean train loss 1527.9723807160165
INFO:root:current train perplexity3.341367721557617
INFO:root:current mean train loss 1529.717753780054
INFO:root:current train perplexity3.3428282737731934
INFO:root:current mean train loss 1531.5185305162536
INFO:root:current train perplexity3.3460421562194824
INFO:root:current mean train loss 1532.2672511870983
INFO:root:current train perplexity3.3473727703094482
INFO:root:current mean train loss 1532.9440636627523
INFO:root:current train perplexity3.3500924110412598
INFO:root:current mean train loss 1533.5579450235598
INFO:root:current train perplexity3.351259708404541
INFO:root:current mean train loss 1534.3579585466728
INFO:root:current train perplexity3.3527324199676514
INFO:root:current mean train loss 1534.6858086496925
INFO:root:current train perplexity3.3535099029541016
INFO:root:current mean train loss 1535.5646141204297
INFO:root:current train perplexity3.353987216949463
INFO:root:current mean train loss 1535.9625091383755
INFO:root:current train perplexity3.355379819869995
INFO:root:current mean train loss 1536.6235379101972
INFO:root:current train perplexity3.3572163581848145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.88s/it]
INFO:root:final mean train loss: 1536.6072577602986
INFO:root:final train perplexity: 3.3597309589385986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2085.411513741135
INFO:root:eval perplexity: 5.400861740112305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2590.436524303247
INFO:root:eval perplexity: 8.318900108337402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [12:37:38<22:22:06, 629.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1551.6483472741168
INFO:root:current train perplexity3.3387327194213867
INFO:root:current mean train loss 1534.5343513798907
INFO:root:current train perplexity3.3331477642059326
INFO:root:current mean train loss 1525.3426573885931
INFO:root:current train perplexity3.317176103591919
INFO:root:current mean train loss 1524.5656035337654
INFO:root:current train perplexity3.317045211791992
INFO:root:current mean train loss 1525.751874919197
INFO:root:current train perplexity3.3182260990142822
INFO:root:current mean train loss 1525.3609838540422
INFO:root:current train perplexity3.3209214210510254
INFO:root:current mean train loss 1525.28559299916
INFO:root:current train perplexity3.3225109577178955
INFO:root:current mean train loss 1525.6032432883278
INFO:root:current train perplexity3.3275163173675537
INFO:root:current mean train loss 1525.1317580676166
INFO:root:current train perplexity3.328019618988037
INFO:root:current mean train loss 1526.4231468853686
INFO:root:current train perplexity3.3317692279815674
INFO:root:current mean train loss 1525.9567677785924
INFO:root:current train perplexity3.3339357376098633
INFO:root:current mean train loss 1527.059141816354
INFO:root:current train perplexity3.3358981609344482
INFO:root:current mean train loss 1527.546621576841
INFO:root:current train perplexity3.3369476795196533
INFO:root:current mean train loss 1527.8947066511066
INFO:root:current train perplexity3.3375937938690186
INFO:root:current mean train loss 1528.4395869476898
INFO:root:current train perplexity3.339118480682373
INFO:root:current mean train loss 1530.2390923002247
INFO:root:current train perplexity3.341670274734497
INFO:root:current mean train loss 1530.2283099180963
INFO:root:current train perplexity3.3432819843292236
INFO:root:current mean train loss 1530.3799155440638
INFO:root:current train perplexity3.343461275100708
INFO:root:current mean train loss 1531.000523502854
INFO:root:current train perplexity3.345733165740967
INFO:root:current mean train loss 1532.038525593758
INFO:root:current train perplexity3.3475136756896973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.40s/it]
INFO:root:final mean train loss: 1531.9469249300205
INFO:root:final train perplexity: 3.347405433654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2088.7153965293937
INFO:root:eval perplexity: 5.415311813354492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2594.9481724948746
INFO:root:eval perplexity: 8.349651336669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:48:06<22:10:38, 628.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1515.3683654785157
INFO:root:current train perplexity3.3015847206115723
INFO:root:current mean train loss 1510.8839817592077
INFO:root:current train perplexity3.284510374069214
INFO:root:current mean train loss 1520.214300028483
INFO:root:current train perplexity3.2960422039031982
INFO:root:current mean train loss 1518.0642018037684
INFO:root:current train perplexity3.303218126296997
INFO:root:current mean train loss 1518.231343494762
INFO:root:current train perplexity3.303621768951416
INFO:root:current mean train loss 1520.6273225007233
INFO:root:current train perplexity3.30637264251709
INFO:root:current mean train loss 1520.5158266067506
INFO:root:current train perplexity3.3093101978302
INFO:root:current mean train loss 1520.0996293351457
INFO:root:current train perplexity3.309830665588379
INFO:root:current mean train loss 1521.1049888974144
INFO:root:current train perplexity3.312121868133545
INFO:root:current mean train loss 1521.925529707239
INFO:root:current train perplexity3.3143022060394287
INFO:root:current mean train loss 1521.681295658992
INFO:root:current train perplexity3.316110134124756
INFO:root:current mean train loss 1521.8289702833745
INFO:root:current train perplexity3.3168513774871826
INFO:root:current mean train loss 1523.3361276934224
INFO:root:current train perplexity3.320929765701294
INFO:root:current mean train loss 1524.0208222802005
INFO:root:current train perplexity3.323319435119629
INFO:root:current mean train loss 1524.2610835605196
INFO:root:current train perplexity3.3241145610809326
INFO:root:current mean train loss 1524.261995944729
INFO:root:current train perplexity3.3245513439178467
INFO:root:current mean train loss 1523.804630409799
INFO:root:current train perplexity3.325030565261841
INFO:root:current mean train loss 1524.7508394087868
INFO:root:current train perplexity3.325575828552246
INFO:root:current mean train loss 1525.8996329266092
INFO:root:current train perplexity3.3285298347473145
INFO:root:current mean train loss 1526.261186422761
INFO:root:current train perplexity3.3301773071289062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.26s/it]
INFO:root:final mean train loss: 1525.8538941168388
INFO:root:final train perplexity: 3.3313586711883545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 2090.3808684653422
INFO:root:eval perplexity: 5.422610282897949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 2595.5869763962764
INFO:root:eval perplexity: 8.35401439666748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [12:58:44<22:06:02, 631.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.084108586897
INFO:root:current train perplexity3.2664601802825928
INFO:root:current mean train loss 1506.9175784360073
INFO:root:current train perplexity3.285759925842285
INFO:root:current mean train loss 1512.288794610287
INFO:root:current train perplexity3.2908661365509033
INFO:root:current mean train loss 1508.1031531753326
INFO:root:current train perplexity3.2893478870391846
INFO:root:current mean train loss 1511.1239027027489
INFO:root:current train perplexity3.2907493114471436
INFO:root:current mean train loss 1508.588317104045
INFO:root:current train perplexity3.2932050228118896
INFO:root:current mean train loss 1510.8411042142313
INFO:root:current train perplexity3.295804500579834
INFO:root:current mean train loss 1512.3856673650098
INFO:root:current train perplexity3.2993500232696533
INFO:root:current mean train loss 1513.2304560729197
INFO:root:current train perplexity3.3035082817077637
INFO:root:current mean train loss 1515.0795033613342
INFO:root:current train perplexity3.305281400680542
INFO:root:current mean train loss 1515.6948113996348
INFO:root:current train perplexity3.305734872817993
INFO:root:current mean train loss 1516.4041359785208
INFO:root:current train perplexity3.3084254264831543
INFO:root:current mean train loss 1517.2947982508888
INFO:root:current train perplexity3.3097901344299316
INFO:root:current mean train loss 1517.5328272887689
INFO:root:current train perplexity3.3097426891326904
INFO:root:current mean train loss 1518.1038541041094
INFO:root:current train perplexity3.310610771179199
INFO:root:current mean train loss 1518.9440638077283
INFO:root:current train perplexity3.313650608062744
INFO:root:current mean train loss 1519.3645821055088
INFO:root:current train perplexity3.314857244491577
INFO:root:current mean train loss 1520.053092040321
INFO:root:current train perplexity3.3157105445861816
INFO:root:current mean train loss 1521.4272978273718
INFO:root:current train perplexity3.3183376789093018
INFO:root:current mean train loss 1521.5119558421093
INFO:root:current train perplexity3.3189282417297363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.22s/it]
INFO:root:final mean train loss: 1521.1089018928963
INFO:root:final train perplexity: 3.3189148902893066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2089.8346631205673
INFO:root:eval perplexity: 5.420215606689453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2599.383936672346
INFO:root:eval perplexity: 8.379997253417969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [13:09:15<21:55:28, 631.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1505.0001583614865
INFO:root:current train perplexity3.270156145095825
INFO:root:current mean train loss 1503.218418165185
INFO:root:current train perplexity3.274604320526123
INFO:root:current mean train loss 1501.9630674932996
INFO:root:current train perplexity3.2797420024871826
INFO:root:current mean train loss 1503.3458532649565
INFO:root:current train perplexity3.2809629440307617
INFO:root:current mean train loss 1504.2485312932654
INFO:root:current train perplexity3.2799489498138428
INFO:root:current mean train loss 1508.057476189909
INFO:root:current train perplexity3.2838478088378906
INFO:root:current mean train loss 1509.2041403207297
INFO:root:current train perplexity3.286957263946533
INFO:root:current mean train loss 1509.4440009538519
INFO:root:current train perplexity3.2849583625793457
INFO:root:current mean train loss 1509.3766116353959
INFO:root:current train perplexity3.288067102432251
INFO:root:current mean train loss 1510.5967840864428
INFO:root:current train perplexity3.288231372833252
INFO:root:current mean train loss 1512.095472396197
INFO:root:current train perplexity3.289936065673828
INFO:root:current mean train loss 1511.7583196012897
INFO:root:current train perplexity3.291745662689209
INFO:root:current mean train loss 1512.2381898409906
INFO:root:current train perplexity3.295168876647949
INFO:root:current mean train loss 1513.9850777483057
INFO:root:current train perplexity3.297563314437866
INFO:root:current mean train loss 1514.4856289122126
INFO:root:current train perplexity3.299464464187622
INFO:root:current mean train loss 1515.1860234455655
INFO:root:current train perplexity3.3023409843444824
INFO:root:current mean train loss 1516.1188733683123
INFO:root:current train perplexity3.303583860397339
INFO:root:current mean train loss 1516.6768163704685
INFO:root:current train perplexity3.304327964782715
INFO:root:current mean train loss 1516.8294630834362
INFO:root:current train perplexity3.305579662322998
INFO:root:current mean train loss 1516.6700563131253
INFO:root:current train perplexity3.306361198425293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it]
INFO:root:final mean train loss: 1516.3640967757185
INFO:root:final train perplexity: 3.306518793106079
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2095.294907590176
INFO:root:eval perplexity: 5.444204330444336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2605.380080635666
INFO:root:eval perplexity: 8.421192169189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [13:19:40<21:40:53, 629.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1481.0164848579154
INFO:root:current train perplexity3.2750930786132812
INFO:root:current mean train loss 1496.743251620787
INFO:root:current train perplexity3.2751972675323486
INFO:root:current mean train loss 1494.502298361657
INFO:root:current train perplexity3.2783069610595703
INFO:root:current mean train loss 1495.0533456631633
INFO:root:current train perplexity3.2684853076934814
INFO:root:current mean train loss 1495.2630734569914
INFO:root:current train perplexity3.27038836479187
INFO:root:current mean train loss 1494.7828883447019
INFO:root:current train perplexity3.2665936946868896
INFO:root:current mean train loss 1497.7992252509948
INFO:root:current train perplexity3.267160415649414
INFO:root:current mean train loss 1498.5374575300252
INFO:root:current train perplexity3.270615339279175
INFO:root:current mean train loss 1501.2936978837859
INFO:root:current train perplexity3.276078701019287
INFO:root:current mean train loss 1502.6380065856379
INFO:root:current train perplexity3.2769722938537598
INFO:root:current mean train loss 1503.2467621716744
INFO:root:current train perplexity3.2791872024536133
INFO:root:current mean train loss 1505.0660211801728
INFO:root:current train perplexity3.2815022468566895
INFO:root:current mean train loss 1505.79600310972
INFO:root:current train perplexity3.2833175659179688
INFO:root:current mean train loss 1507.374740063073
INFO:root:current train perplexity3.2845587730407715
INFO:root:current mean train loss 1508.1269333939838
INFO:root:current train perplexity3.2857391834259033
INFO:root:current mean train loss 1509.2636451745168
INFO:root:current train perplexity3.2888145446777344
INFO:root:current mean train loss 1509.8733183749678
INFO:root:current train perplexity3.290951728820801
INFO:root:current mean train loss 1511.2199538681907
INFO:root:current train perplexity3.2922091484069824
INFO:root:current mean train loss 1511.1437525434005
INFO:root:current train perplexity3.293039083480835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.32s/it]
INFO:root:final mean train loss: 1511.2956010180774
INFO:root:final train perplexity: 3.293328046798706
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2097.243045455175
INFO:root:eval perplexity: 5.452787399291992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.67s/it]
INFO:root:eval mean loss: 2609.6489573810118
INFO:root:eval perplexity: 8.450645446777344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [13:30:18<21:35:41, 632.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.9561920166016
INFO:root:current train perplexity3.2161033153533936
INFO:root:current mean train loss 1495.5525162308304
INFO:root:current train perplexity3.241039991378784
INFO:root:current mean train loss 1495.5309800368088
INFO:root:current train perplexity3.2554965019226074
INFO:root:current mean train loss 1494.1985441926238
INFO:root:current train perplexity3.260119915008545
INFO:root:current mean train loss 1494.4963199391084
INFO:root:current train perplexity3.2561893463134766
INFO:root:current mean train loss 1496.1023941640779
INFO:root:current train perplexity3.259786605834961
INFO:root:current mean train loss 1495.488149341784
INFO:root:current train perplexity3.2606077194213867
INFO:root:current mean train loss 1495.6378197966321
INFO:root:current train perplexity3.2615532875061035
INFO:root:current mean train loss 1499.0234232987507
INFO:root:current train perplexity3.2640914916992188
INFO:root:current mean train loss 1500.1879023749398
INFO:root:current train perplexity3.2654521465301514
INFO:root:current mean train loss 1501.1848828754728
INFO:root:current train perplexity3.268080472946167
INFO:root:current mean train loss 1502.0468687202097
INFO:root:current train perplexity3.2693257331848145
INFO:root:current mean train loss 1502.538117263491
INFO:root:current train perplexity3.2703030109405518
INFO:root:current mean train loss 1504.0060940897063
INFO:root:current train perplexity3.2727432250976562
INFO:root:current mean train loss 1504.1482403495095
INFO:root:current train perplexity3.27376389503479
INFO:root:current mean train loss 1505.0104914900478
INFO:root:current train perplexity3.2756831645965576
INFO:root:current mean train loss 1506.141582887564
INFO:root:current train perplexity3.276754856109619
INFO:root:current mean train loss 1506.198155709117
INFO:root:current train perplexity3.277597427368164
INFO:root:current mean train loss 1506.2164966279427
INFO:root:current train perplexity3.2789559364318848
INFO:root:current mean train loss 1506.510951715945
INFO:root:current train perplexity3.280350923538208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.75s/it]
INFO:root:final mean train loss: 1506.3948805015975
INFO:root:final train perplexity: 3.2806236743927
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2103.861677453873
INFO:root:eval perplexity: 5.482053756713867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2617.1854806453625
INFO:root:eval perplexity: 8.502890586853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [13:40:44<21:21:19, 630.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1489.2993115234376
INFO:root:current train perplexity3.242017984390259
INFO:root:current mean train loss 1485.479431640625
INFO:root:current train perplexity3.2617692947387695
INFO:root:current mean train loss 1485.451115451389
INFO:root:current train perplexity3.2431304454803467
INFO:root:current mean train loss 1489.3895624248798
INFO:root:current train perplexity3.248511552810669
INFO:root:current mean train loss 1490.8084274471507
INFO:root:current train perplexity3.2521212100982666
INFO:root:current mean train loss 1492.5426806640626
INFO:root:current train perplexity3.2523112297058105
INFO:root:current mean train loss 1490.1192490234375
INFO:root:current train perplexity3.254398822784424
INFO:root:current mean train loss 1490.3908627424569
INFO:root:current train perplexity3.2521088123321533
INFO:root:current mean train loss 1492.8613031190814
INFO:root:current train perplexity3.252300262451172
INFO:root:current mean train loss 1494.2123653927365
INFO:root:current train perplexity3.2555277347564697
INFO:root:current mean train loss 1494.056874047256
INFO:root:current train perplexity3.2582733631134033
INFO:root:current mean train loss 1495.8577639973958
INFO:root:current train perplexity3.2591702938079834
INFO:root:current mean train loss 1497.5017556202167
INFO:root:current train perplexity3.260711908340454
INFO:root:current mean train loss 1498.0036829304245
INFO:root:current train perplexity3.2610809803009033
INFO:root:current mean train loss 1499.1434455523574
INFO:root:current train perplexity3.2628190517425537
INFO:root:current mean train loss 1499.4091142097848
INFO:root:current train perplexity3.2624919414520264
INFO:root:current mean train loss 1499.4857916917067
INFO:root:current train perplexity3.2638278007507324
INFO:root:current mean train loss 1500.013884595788
INFO:root:current train perplexity3.2632343769073486
INFO:root:current mean train loss 1501.3264069188783
INFO:root:current train perplexity3.265310049057007
INFO:root:current mean train loss 1501.8472862976867
INFO:root:current train perplexity3.2673404216766357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.48s/it]
INFO:root:final mean train loss: 1501.5789591779146
INFO:root:final train perplexity: 3.2681872844696045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2102.121388969692
INFO:root:eval perplexity: 5.474343776702881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it]
INFO:root:eval mean loss: 2617.778442815686
INFO:root:eval perplexity: 8.507017135620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:51:06<21:05:45, 627.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1494.4612426757812
INFO:root:current train perplexity3.236722230911255
INFO:root:current mean train loss 1501.3580141739108
INFO:root:current train perplexity3.244865655899048
INFO:root:current mean train loss 1498.050153748063
INFO:root:current train perplexity3.2434399127960205
INFO:root:current mean train loss 1494.7067399945176
INFO:root:current train perplexity3.2418220043182373
INFO:root:current mean train loss 1492.5356395600609
INFO:root:current train perplexity3.244274377822876
INFO:root:current mean train loss 1490.284581933954
INFO:root:current train perplexity3.23823881149292
INFO:root:current mean train loss 1492.3823618666033
INFO:root:current train perplexity3.240662097930908
INFO:root:current mean train loss 1493.0094255719866
INFO:root:current train perplexity3.2425637245178223
INFO:root:current mean train loss 1492.2407851411724
INFO:root:current train perplexity3.24345064163208
INFO:root:current mean train loss 1492.7097445283473
INFO:root:current train perplexity3.246407985687256
INFO:root:current mean train loss 1494.315593931817
INFO:root:current train perplexity3.247628688812256
INFO:root:current mean train loss 1492.6907537831107
INFO:root:current train perplexity3.246964931488037
INFO:root:current mean train loss 1493.3780928410579
INFO:root:current train perplexity3.2490499019622803
INFO:root:current mean train loss 1493.1101540851166
INFO:root:current train perplexity3.248896837234497
INFO:root:current mean train loss 1494.0078563505006
INFO:root:current train perplexity3.251175880432129
INFO:root:current mean train loss 1495.1344670989633
INFO:root:current train perplexity3.2522480487823486
INFO:root:current mean train loss 1495.7825420718825
INFO:root:current train perplexity3.2529683113098145
INFO:root:current mean train loss 1495.7766940163963
INFO:root:current train perplexity3.2536494731903076
INFO:root:current mean train loss 1496.813430239401
INFO:root:current train perplexity3.2547805309295654
INFO:root:current mean train loss 1496.9273700498036
INFO:root:current train perplexity3.255711078643799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.57s/it]
INFO:root:final mean train loss: 1496.9317480444126
INFO:root:final train perplexity: 3.2562308311462402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2106.5504081130875
INFO:root:eval perplexity: 5.4939866065979
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2621.1902214753713
INFO:root:eval perplexity: 8.530784606933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [14:01:30<20:53:19, 626.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1477.3344085176113
INFO:root:current train perplexity3.195030689239502
INFO:root:current mean train loss 1472.8342146963444
INFO:root:current train perplexity3.1912145614624023
INFO:root:current mean train loss 1475.4637375761642
INFO:root:current train perplexity3.206498384475708
INFO:root:current mean train loss 1481.1453850621301
INFO:root:current train perplexity3.2140324115753174
INFO:root:current mean train loss 1480.60557965048
INFO:root:current train perplexity3.2149264812469482
INFO:root:current mean train loss 1482.3554923342465
INFO:root:current train perplexity3.2134199142456055
INFO:root:current mean train loss 1484.089867460167
INFO:root:current train perplexity3.217107057571411
INFO:root:current mean train loss 1484.2561836091897
INFO:root:current train perplexity3.220062732696533
INFO:root:current mean train loss 1483.7448333988923
INFO:root:current train perplexity3.2221784591674805
INFO:root:current mean train loss 1485.2785978028871
INFO:root:current train perplexity3.2256107330322266
INFO:root:current mean train loss 1486.0765786607722
INFO:root:current train perplexity3.2272276878356934
INFO:root:current mean train loss 1486.5848562456185
INFO:root:current train perplexity3.228724956512451
INFO:root:current mean train loss 1488.3512948955024
INFO:root:current train perplexity3.231520414352417
INFO:root:current mean train loss 1489.2595151068972
INFO:root:current train perplexity3.2336699962615967
INFO:root:current mean train loss 1489.9253845005676
INFO:root:current train perplexity3.2347822189331055
INFO:root:current mean train loss 1489.8401892113334
INFO:root:current train perplexity3.2361536026000977
INFO:root:current mean train loss 1490.9208687844946
INFO:root:current train perplexity3.237511396408081
INFO:root:current mean train loss 1491.363567445548
INFO:root:current train perplexity3.240334987640381
INFO:root:current mean train loss 1491.2047939290278
INFO:root:current train perplexity3.2408978939056396
INFO:root:current mean train loss 1491.781756975019
INFO:root:current train perplexity3.2428231239318848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.21s/it]
INFO:root:final mean train loss: 1491.9068958707608
INFO:root:final train perplexity: 3.2433528900146484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2110.8988634474736
INFO:root:eval perplexity: 5.513342380523682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2627.184016667359
INFO:root:eval perplexity: 8.57270336151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [14:12:03<20:46:52, 628.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.9490822239925
INFO:root:current train perplexity3.2005863189697266
INFO:root:current mean train loss 1479.7028538097036
INFO:root:current train perplexity3.2094383239746094
INFO:root:current mean train loss 1477.5620541779892
INFO:root:current train perplexity3.207150459289551
INFO:root:current mean train loss 1478.1376255116563
INFO:root:current train perplexity3.20991587638855
INFO:root:current mean train loss 1478.8749851258863
INFO:root:current train perplexity3.2057695388793945
INFO:root:current mean train loss 1481.6140778859456
INFO:root:current train perplexity3.207900285720825
INFO:root:current mean train loss 1481.8022004076715
INFO:root:current train perplexity3.2103614807128906
INFO:root:current mean train loss 1482.4701284821501
INFO:root:current train perplexity3.2119297981262207
INFO:root:current mean train loss 1483.277763192512
INFO:root:current train perplexity3.2143447399139404
INFO:root:current mean train loss 1484.263141694616
INFO:root:current train perplexity3.2160019874572754
INFO:root:current mean train loss 1484.3157805829244
INFO:root:current train perplexity3.2184274196624756
INFO:root:current mean train loss 1484.8652828502006
INFO:root:current train perplexity3.2203896045684814
INFO:root:current mean train loss 1486.4969320745677
INFO:root:current train perplexity3.224255323410034
INFO:root:current mean train loss 1486.3473216212074
INFO:root:current train perplexity3.2245726585388184
INFO:root:current mean train loss 1485.3146774167938
INFO:root:current train perplexity3.224797487258911
INFO:root:current mean train loss 1485.8853545213108
INFO:root:current train perplexity3.2262933254241943
INFO:root:current mean train loss 1486.011376428718
INFO:root:current train perplexity3.2275567054748535
INFO:root:current mean train loss 1485.9705669643643
INFO:root:current train perplexity3.2283740043640137
INFO:root:current mean train loss 1486.834679707281
INFO:root:current train perplexity3.2299563884735107
INFO:root:current mean train loss 1487.6255397410528
INFO:root:current train perplexity3.2315802574157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.80s/it]
INFO:root:final mean train loss: 1487.3397334989008
INFO:root:final train perplexity: 3.231691598892212
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2114.146354080092
INFO:root:eval perplexity: 5.527841091156006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2630.485102227394
INFO:root:eval perplexity: 8.595877647399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [14:22:28<20:34:06, 627.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1464.5568375126009
INFO:root:current train perplexity3.1739723682403564
INFO:root:current mean train loss 1469.7598427886173
INFO:root:current train perplexity3.1911392211914062
INFO:root:current mean train loss 1471.9873571819005
INFO:root:current train perplexity3.1956770420074463
INFO:root:current mean train loss 1474.2622051675812
INFO:root:current train perplexity3.1958892345428467
INFO:root:current mean train loss 1474.5439331797509
INFO:root:current train perplexity3.195343255996704
INFO:root:current mean train loss 1478.808936699647
INFO:root:current train perplexity3.20400333404541
INFO:root:current mean train loss 1477.7519066220239
INFO:root:current train perplexity3.207672119140625
INFO:root:current mean train loss 1478.5674597799102
INFO:root:current train perplexity3.2105343341827393
INFO:root:current mean train loss 1478.6380972013228
INFO:root:current train perplexity3.2093021869659424
INFO:root:current mean train loss 1480.0929491056536
INFO:root:current train perplexity3.210861921310425
INFO:root:current mean train loss 1480.8106901652204
INFO:root:current train perplexity3.211559772491455
INFO:root:current mean train loss 1481.0863097479437
INFO:root:current train perplexity3.2139711380004883
INFO:root:current mean train loss 1480.4750528121676
INFO:root:current train perplexity3.2140145301818848
INFO:root:current mean train loss 1480.7094242838075
INFO:root:current train perplexity3.2150402069091797
INFO:root:current mean train loss 1480.9551486854016
INFO:root:current train perplexity3.215090751647949
INFO:root:current mean train loss 1482.047745967465
INFO:root:current train perplexity3.2150521278381348
INFO:root:current mean train loss 1482.203751070008
INFO:root:current train perplexity3.2174553871154785
INFO:root:current mean train loss 1482.5128710991964
INFO:root:current train perplexity3.218744993209839
INFO:root:current mean train loss 1482.7954892794794
INFO:root:current train perplexity3.2187063694000244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.17s/it]
INFO:root:final mean train loss: 1482.557108284185
INFO:root:final train perplexity: 3.219524621963501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2115.895428596659
INFO:root:eval perplexity: 5.535665988922119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2636.3004687153702
INFO:root:eval perplexity: 8.636858940124512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [14:33:05<20:28:47, 630.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1430.1684692382812
INFO:root:current train perplexity3.116680383682251
INFO:root:current mean train loss 1458.290049050071
INFO:root:current train perplexity3.1617815494537354
INFO:root:current mean train loss 1462.5773286365327
INFO:root:current train perplexity3.1658103466033936
INFO:root:current mean train loss 1463.9497314453124
INFO:root:current train perplexity3.1668200492858887
INFO:root:current mean train loss 1461.9646240234374
INFO:root:current train perplexity3.1658990383148193
INFO:root:current mean train loss 1464.565789196538
INFO:root:current train perplexity3.171980857849121
INFO:root:current mean train loss 1464.8874207543545
INFO:root:current train perplexity3.177504062652588
INFO:root:current mean train loss 1465.3048319212148
INFO:root:current train perplexity3.180844783782959
INFO:root:current mean train loss 1466.1614557713638
INFO:root:current train perplexity3.18385910987854
INFO:root:current mean train loss 1466.9097373207846
INFO:root:current train perplexity3.186450958251953
INFO:root:current mean train loss 1469.4497964689047
INFO:root:current train perplexity3.1881988048553467
INFO:root:current mean train loss 1470.382670304582
INFO:root:current train perplexity3.190704345703125
INFO:root:current mean train loss 1471.8267910035188
INFO:root:current train perplexity3.1932802200317383
INFO:root:current mean train loss 1471.94369968094
INFO:root:current train perplexity3.1949729919433594
INFO:root:current mean train loss 1472.8306195631094
INFO:root:current train perplexity3.197899103164673
INFO:root:current mean train loss 1473.755930919521
INFO:root:current train perplexity3.1989636421203613
INFO:root:current mean train loss 1474.3825735151397
INFO:root:current train perplexity3.2003014087677
INFO:root:current mean train loss 1474.1934774476883
INFO:root:current train perplexity3.2011075019836426
INFO:root:current mean train loss 1476.4409611317335
INFO:root:current train perplexity3.205150842666626
INFO:root:current mean train loss 1477.558183312541
INFO:root:current train perplexity3.206179618835449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.48s/it]
INFO:root:final mean train loss: 1478.2094626837888
INFO:root:final train perplexity: 3.2085046768188477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2119.0979423793497
INFO:root:eval perplexity: 5.550022602081299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2638.096601337406
INFO:root:eval perplexity: 8.649555206298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [14:43:28<20:14:28, 628.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1447.5444833260995
INFO:root:current train perplexity3.1605279445648193
INFO:root:current mean train loss 1462.7063632274237
INFO:root:current train perplexity3.170163631439209
INFO:root:current mean train loss 1468.1896978033797
INFO:root:current train perplexity3.174802541732788
INFO:root:current mean train loss 1464.7380960913608
INFO:root:current train perplexity3.1770336627960205
INFO:root:current mean train loss 1465.8903585608168
INFO:root:current train perplexity3.1771206855773926
INFO:root:current mean train loss 1465.7597904096745
INFO:root:current train perplexity3.17421293258667
INFO:root:current mean train loss 1467.3122032932117
INFO:root:current train perplexity3.177267551422119
INFO:root:current mean train loss 1469.6633948912483
INFO:root:current train perplexity3.1811580657958984
INFO:root:current mean train loss 1470.128829051967
INFO:root:current train perplexity3.1826460361480713
INFO:root:current mean train loss 1468.5653490973907
INFO:root:current train perplexity3.179809331893921
INFO:root:current mean train loss 1468.3747530067094
INFO:root:current train perplexity3.179347276687622
INFO:root:current mean train loss 1470.6510941269341
INFO:root:current train perplexity3.1819775104522705
INFO:root:current mean train loss 1470.8202147044685
INFO:root:current train perplexity3.1839120388031006
INFO:root:current mean train loss 1471.8316402938372
INFO:root:current train perplexity3.1870620250701904
INFO:root:current mean train loss 1472.381030803806
INFO:root:current train perplexity3.187872886657715
INFO:root:current mean train loss 1472.513466266065
INFO:root:current train perplexity3.1900675296783447
INFO:root:current mean train loss 1472.2110095267362
INFO:root:current train perplexity3.1900551319122314
INFO:root:current mean train loss 1472.691698808786
INFO:root:current train perplexity3.1924679279327393
INFO:root:current mean train loss 1473.4802584843878
INFO:root:current train perplexity3.195042848587036
INFO:root:current mean train loss 1474.4219729349782
INFO:root:current train perplexity3.1971969604492188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.54s/it]
INFO:root:final mean train loss: 1474.0028363649615
INFO:root:final train perplexity: 3.1978776454925537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2121.306554483184
INFO:root:eval perplexity: 5.559945106506348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2643.2608248663287
INFO:root:eval perplexity: 8.686164855957031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [14:53:52<20:01:40, 626.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1450.9115073464134
INFO:root:current train perplexity3.1451261043548584
INFO:root:current mean train loss 1457.2031071980794
INFO:root:current train perplexity3.165645122528076
INFO:root:current mean train loss 1461.0891303390754
INFO:root:current train perplexity3.174427032470703
INFO:root:current mean train loss 1461.5458139818768
INFO:root:current train perplexity3.16865611076355
INFO:root:current mean train loss 1462.561499243384
INFO:root:current train perplexity3.169275999069214
INFO:root:current mean train loss 1462.5379369399127
INFO:root:current train perplexity3.168189525604248
INFO:root:current mean train loss 1464.2155102084141
INFO:root:current train perplexity3.1697611808776855
INFO:root:current mean train loss 1466.6247282951108
INFO:root:current train perplexity3.1726925373077393
INFO:root:current mean train loss 1467.7407920801245
INFO:root:current train perplexity3.174307107925415
INFO:root:current mean train loss 1466.9942245483398
INFO:root:current train perplexity3.172088861465454
INFO:root:current mean train loss 1466.5376613806948
INFO:root:current train perplexity3.1730713844299316
INFO:root:current mean train loss 1466.4336338710118
INFO:root:current train perplexity3.174262046813965
INFO:root:current mean train loss 1467.512938373725
INFO:root:current train perplexity3.1756715774536133
INFO:root:current mean train loss 1468.0716292063396
INFO:root:current train perplexity3.177093029022217
INFO:root:current mean train loss 1469.1542333037569
INFO:root:current train perplexity3.1794543266296387
INFO:root:current mean train loss 1469.389179209971
INFO:root:current train perplexity3.180593490600586
INFO:root:current mean train loss 1469.3321841348986
INFO:root:current train perplexity3.181856870651245
INFO:root:current mean train loss 1469.2469815595434
INFO:root:current train perplexity3.183419704437256
INFO:root:current mean train loss 1469.028769536546
INFO:root:current train perplexity3.184227466583252
INFO:root:current mean train loss 1469.3014046625835
INFO:root:current train perplexity3.1856651306152344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.86s/it]
INFO:root:final mean train loss: 1469.1817256063748
INFO:root:final train perplexity: 3.185741662979126
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2126.3249438130265
INFO:root:eval perplexity: 5.582555770874023
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2648.3672195326353
INFO:root:eval perplexity: 8.722515106201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [15:04:31<19:57:58, 630.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1445.0994152631915
INFO:root:current train perplexity3.121823310852051
INFO:root:current mean train loss 1448.4148032620826
INFO:root:current train perplexity3.1431403160095215
INFO:root:current mean train loss 1451.9314306266463
INFO:root:current train perplexity3.151207685470581
INFO:root:current mean train loss 1453.9790671393482
INFO:root:current train perplexity3.1544907093048096
INFO:root:current mean train loss 1455.0101652000576
INFO:root:current train perplexity3.1568069458007812
INFO:root:current mean train loss 1454.7788858396698
INFO:root:current train perplexity3.159939765930176
INFO:root:current mean train loss 1455.8439019876962
INFO:root:current train perplexity3.158478260040283
INFO:root:current mean train loss 1457.9571465831862
INFO:root:current train perplexity3.1629281044006348
INFO:root:current mean train loss 1458.6335710089104
INFO:root:current train perplexity3.1641197204589844
INFO:root:current mean train loss 1458.4715143019152
INFO:root:current train perplexity3.1645750999450684
INFO:root:current mean train loss 1458.945098733138
INFO:root:current train perplexity3.1647369861602783
INFO:root:current mean train loss 1460.3721066917662
INFO:root:current train perplexity3.166278839111328
INFO:root:current mean train loss 1460.8804820315597
INFO:root:current train perplexity3.1678082942962646
INFO:root:current mean train loss 1462.1121253939257
INFO:root:current train perplexity3.168294906616211
INFO:root:current mean train loss 1463.1608474804555
INFO:root:current train perplexity3.1700479984283447
INFO:root:current mean train loss 1463.0787395743664
INFO:root:current train perplexity3.1689937114715576
INFO:root:current mean train loss 1462.909966566992
INFO:root:current train perplexity3.169661045074463
INFO:root:current mean train loss 1463.4974025572517
INFO:root:current train perplexity3.171185255050659
INFO:root:current mean train loss 1464.646168015453
INFO:root:current train perplexity3.1752469539642334
INFO:root:current mean train loss 1465.946392146864
INFO:root:current train perplexity3.176262855529785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.95s/it]
INFO:root:final mean train loss: 1465.375989120414
INFO:root:final train perplexity: 3.176194429397583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2128.348319412123
INFO:root:eval perplexity: 5.591699123382568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2651.145366695756
INFO:root:eval perplexity: 8.742354393005371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [15:14:56<19:44:27, 628.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1439.804912860577
INFO:root:current train perplexity3.1062216758728027
INFO:root:current mean train loss 1456.416252221954
INFO:root:current train perplexity3.1377837657928467
INFO:root:current mean train loss 1451.5881975571886
INFO:root:current train perplexity3.133269786834717
INFO:root:current mean train loss 1452.7029328522858
INFO:root:current train perplexity3.1340041160583496
INFO:root:current mean train loss 1453.9973415231107
INFO:root:current train perplexity3.1399974822998047
INFO:root:current mean train loss 1453.6923697184527
INFO:root:current train perplexity3.1388628482818604
INFO:root:current mean train loss 1454.6100044363016
INFO:root:current train perplexity3.1414577960968018
INFO:root:current mean train loss 1455.1429493568244
INFO:root:current train perplexity3.143627166748047
INFO:root:current mean train loss 1455.2209946756211
INFO:root:current train perplexity3.1484391689300537
INFO:root:current mean train loss 1456.565968768972
INFO:root:current train perplexity3.1524412631988525
INFO:root:current mean train loss 1455.8695784022061
INFO:root:current train perplexity3.153453826904297
INFO:root:current mean train loss 1457.4078694523291
INFO:root:current train perplexity3.1544079780578613
INFO:root:current mean train loss 1457.8114275387568
INFO:root:current train perplexity3.156280517578125
INFO:root:current mean train loss 1458.5536878167804
INFO:root:current train perplexity3.157444953918457
INFO:root:current mean train loss 1459.6037924718792
INFO:root:current train perplexity3.1585750579833984
INFO:root:current mean train loss 1459.2284566784992
INFO:root:current train perplexity3.158501148223877
INFO:root:current mean train loss 1460.102395313431
INFO:root:current train perplexity3.1603994369506836
INFO:root:current mean train loss 1460.183131763986
INFO:root:current train perplexity3.1608681678771973
INFO:root:current mean train loss 1460.485875398841
INFO:root:current train perplexity3.1625638008117676
INFO:root:current mean train loss 1460.9818997127584
INFO:root:current train perplexity3.16428804397583

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.03s/it]
INFO:root:final mean train loss: 1460.6523486131139
INFO:root:final train perplexity: 3.1643834114074707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2132.3488583395665
INFO:root:eval perplexity: 5.609819412231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2653.607749993074
INFO:root:eval perplexity: 8.759976387023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [15:25:34<19:38:54, 631.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1447.0738217002468
INFO:root:current train perplexity3.1298608779907227
INFO:root:current mean train loss 1443.8680845602964
INFO:root:current train perplexity3.1241366863250732
INFO:root:current mean train loss 1447.1744744769599
INFO:root:current train perplexity3.12732195854187
INFO:root:current mean train loss 1443.8383813785601
INFO:root:current train perplexity3.128204107284546
INFO:root:current mean train loss 1446.9037392972696
INFO:root:current train perplexity3.1310536861419678
INFO:root:current mean train loss 1447.6482263901655
INFO:root:current train perplexity3.1312813758850098
INFO:root:current mean train loss 1448.4123549207509
INFO:root:current train perplexity3.1344897747039795
INFO:root:current mean train loss 1449.6270719708136
INFO:root:current train perplexity3.136183261871338
INFO:root:current mean train loss 1451.7495973725559
INFO:root:current train perplexity3.1358482837677
INFO:root:current mean train loss 1451.6371923092022
INFO:root:current train perplexity3.139909505844116
INFO:root:current mean train loss 1453.132093232734
INFO:root:current train perplexity3.141247272491455
INFO:root:current mean train loss 1453.2350057817403
INFO:root:current train perplexity3.143906354904175
INFO:root:current mean train loss 1453.4369092550978
INFO:root:current train perplexity3.1439032554626465
INFO:root:current mean train loss 1454.1430268537185
INFO:root:current train perplexity3.1442387104034424
INFO:root:current mean train loss 1454.3220285881323
INFO:root:current train perplexity3.145841121673584
INFO:root:current mean train loss 1454.5394083531298
INFO:root:current train perplexity3.1487369537353516
INFO:root:current mean train loss 1455.014369008112
INFO:root:current train perplexity3.1489977836608887
INFO:root:current mean train loss 1455.4948699866165
INFO:root:current train perplexity3.1505980491638184
INFO:root:current mean train loss 1455.9096346007173
INFO:root:current train perplexity3.152001142501831

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.46s/it]
INFO:root:final mean train loss: 1456.2453216845138
INFO:root:final train perplexity: 3.1534042358398438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2137.7936665419993
INFO:root:eval perplexity: 5.634576797485352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2661.840022526734
INFO:root:eval perplexity: 8.8191556930542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [15:35:58<19:24:17, 629.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1473.1764628092449
INFO:root:current train perplexity3.1029138565063477
INFO:root:current mean train loss 1437.1235580444336
INFO:root:current train perplexity3.093829870223999
INFO:root:current mean train loss 1438.608481353184
INFO:root:current train perplexity3.0975794792175293
INFO:root:current mean train loss 1439.3978834885818
INFO:root:current train perplexity3.1077511310577393
INFO:root:current mean train loss 1440.971834645688
INFO:root:current train perplexity3.1140084266662598
INFO:root:current mean train loss 1443.6167330741882
INFO:root:current train perplexity3.1209020614624023
INFO:root:current mean train loss 1447.1034591774535
INFO:root:current train perplexity3.1255898475646973
INFO:root:current mean train loss 1446.877625368954
INFO:root:current train perplexity3.127845287322998
INFO:root:current mean train loss 1446.733417379445
INFO:root:current train perplexity3.131948947906494
INFO:root:current mean train loss 1447.6994931405052
INFO:root:current train perplexity3.1345245838165283
INFO:root:current mean train loss 1448.8636457722178
INFO:root:current train perplexity3.135437488555908
INFO:root:current mean train loss 1449.6828609987986
INFO:root:current train perplexity3.1356394290924072
INFO:root:current mean train loss 1450.4764216961246
INFO:root:current train perplexity3.1366195678710938
INFO:root:current mean train loss 1450.6861985369426
INFO:root:current train perplexity3.137331247329712
INFO:root:current mean train loss 1451.0074764608323
INFO:root:current train perplexity3.138127565383911
INFO:root:current mean train loss 1451.2169419545976
INFO:root:current train perplexity3.1388943195343018
INFO:root:current mean train loss 1451.6401755661882
INFO:root:current train perplexity3.141339063644409
INFO:root:current mean train loss 1452.1458045745565
INFO:root:current train perplexity3.1428017616271973
INFO:root:current mean train loss 1452.269094639793
INFO:root:current train perplexity3.142427921295166
INFO:root:current mean train loss 1452.453567121817
INFO:root:current train perplexity3.1433539390563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.40s/it]
INFO:root:final mean train loss: 1452.1087660642809
INFO:root:final train perplexity: 3.143134117126465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2139.6846296161625
INFO:root:eval perplexity: 5.643200397491455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 2665.654917182652
INFO:root:eval perplexity: 8.846712112426758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [15:46:23<19:11:24, 628.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.7846553407867
INFO:root:current train perplexity3.1136457920074463
INFO:root:current mean train loss 1436.177918899891
INFO:root:current train perplexity3.111558437347412
INFO:root:current mean train loss 1436.5251571455376
INFO:root:current train perplexity3.1172738075256348
INFO:root:current mean train loss 1435.050866216874
INFO:root:current train perplexity3.1141152381896973
INFO:root:current mean train loss 1440.2203915469297
INFO:root:current train perplexity3.116936683654785
INFO:root:current mean train loss 1440.5639246920782
INFO:root:current train perplexity3.1110475063323975
INFO:root:current mean train loss 1441.9054785699648
INFO:root:current train perplexity3.1139984130859375
INFO:root:current mean train loss 1441.9542611413858
INFO:root:current train perplexity3.1155967712402344
INFO:root:current mean train loss 1442.1216750932977
INFO:root:current train perplexity3.1158950328826904
INFO:root:current mean train loss 1442.714439958751
INFO:root:current train perplexity3.116412878036499
INFO:root:current mean train loss 1443.678265956215
INFO:root:current train perplexity3.119753122329712
INFO:root:current mean train loss 1444.06939583737
INFO:root:current train perplexity3.1223113536834717
INFO:root:current mean train loss 1445.254659232131
INFO:root:current train perplexity3.12520432472229
INFO:root:current mean train loss 1445.1351753734305
INFO:root:current train perplexity3.125969648361206
INFO:root:current mean train loss 1446.224519594805
INFO:root:current train perplexity3.1284055709838867
INFO:root:current mean train loss 1447.1396455633787
INFO:root:current train perplexity3.129589796066284
INFO:root:current mean train loss 1448.1411108833065
INFO:root:current train perplexity3.130707025527954
INFO:root:current mean train loss 1448.0742104896028
INFO:root:current train perplexity3.13055419921875
INFO:root:current mean train loss 1447.9988433687722
INFO:root:current train perplexity3.1316471099853516
INFO:root:current mean train loss 1448.4598071630783
INFO:root:current train perplexity3.133082628250122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it]
INFO:root:final mean train loss: 1448.2254553105695
INFO:root:final train perplexity: 3.1335225105285645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2140.0566739562555
INFO:root:eval perplexity: 5.644898414611816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 2666.311963669797
INFO:root:eval perplexity: 8.85146713256836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [15:56:47<18:58:54, 626.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1409.8290378736413
INFO:root:current train perplexity3.046844244003296
INFO:root:current mean train loss 1421.8846226522367
INFO:root:current train perplexity3.082435369491577
INFO:root:current mean train loss 1424.7334520293446
INFO:root:current train perplexity3.081850290298462
INFO:root:current mean train loss 1425.350075782379
INFO:root:current train perplexity3.0869827270507812
INFO:root:current mean train loss 1429.3451157642587
INFO:root:current train perplexity3.09143328666687
INFO:root:current mean train loss 1432.9251411633613
INFO:root:current train perplexity3.102320909500122
INFO:root:current mean train loss 1434.2050373089203
INFO:root:current train perplexity3.1026127338409424
INFO:root:current mean train loss 1436.7977915091426
INFO:root:current train perplexity3.106416940689087
INFO:root:current mean train loss 1436.4067746426197
INFO:root:current train perplexity3.1078274250030518
INFO:root:current mean train loss 1436.902141417812
INFO:root:current train perplexity3.109595537185669
INFO:root:current mean train loss 1439.238799640371
INFO:root:current train perplexity3.111442804336548
INFO:root:current mean train loss 1439.2801572257104
INFO:root:current train perplexity3.1130878925323486
INFO:root:current mean train loss 1439.7541529378386
INFO:root:current train perplexity3.1129720211029053
INFO:root:current mean train loss 1440.706747840099
INFO:root:current train perplexity3.1144635677337646
INFO:root:current mean train loss 1441.8686165499655
INFO:root:current train perplexity3.115988254547119
INFO:root:current mean train loss 1442.1747401781563
INFO:root:current train perplexity3.1172332763671875
INFO:root:current mean train loss 1443.0560343523362
INFO:root:current train perplexity3.119504690170288
INFO:root:current mean train loss 1442.9180811721435
INFO:root:current train perplexity3.11991286277771
INFO:root:current mean train loss 1443.1269791128834
INFO:root:current train perplexity3.1208178997039795
INFO:root:current mean train loss 1443.9909809108628
INFO:root:current train perplexity3.122635841369629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.68s/it]
INFO:root:final mean train loss: 1444.033171453202
INFO:root:final train perplexity: 3.123178720474243
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 2141.375358852089
INFO:root:eval perplexity: 5.6509222984313965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2668.9002568671044
INFO:root:eval perplexity: 8.870221138000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [16:07:15<18:48:46, 627.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1422.5245555090526
INFO:root:current train perplexity3.093580722808838
INFO:root:current mean train loss 1424.3665269722967
INFO:root:current train perplexity3.097372531890869
INFO:root:current mean train loss 1429.541327066748
INFO:root:current train perplexity3.099524974822998
INFO:root:current mean train loss 1430.8814851955278
INFO:root:current train perplexity3.099940538406372
INFO:root:current mean train loss 1430.5360980105966
INFO:root:current train perplexity3.0963728427886963
INFO:root:current mean train loss 1430.5635040987872
INFO:root:current train perplexity3.097468137741089
INFO:root:current mean train loss 1431.9418840365172
INFO:root:current train perplexity3.0998241901397705
INFO:root:current mean train loss 1432.9225411871314
INFO:root:current train perplexity3.0996251106262207
INFO:root:current mean train loss 1433.7702921030834
INFO:root:current train perplexity3.0998666286468506
INFO:root:current mean train loss 1434.4216418875342
INFO:root:current train perplexity3.099841833114624
INFO:root:current mean train loss 1435.808740395145
INFO:root:current train perplexity3.100527763366699
INFO:root:current mean train loss 1436.3207563825035
INFO:root:current train perplexity3.1015055179595947
INFO:root:current mean train loss 1437.6079523927715
INFO:root:current train perplexity3.1047017574310303
INFO:root:current mean train loss 1438.2236123032546
INFO:root:current train perplexity3.1054704189300537
INFO:root:current mean train loss 1438.1278332327622
INFO:root:current train perplexity3.1068286895751953
INFO:root:current mean train loss 1438.3900426082403
INFO:root:current train perplexity3.106868028640747
INFO:root:current mean train loss 1438.5525489573154
INFO:root:current train perplexity3.10907244682312
INFO:root:current mean train loss 1438.849157306327
INFO:root:current train perplexity3.10972261428833
INFO:root:current mean train loss 1439.5023991435814
INFO:root:current train perplexity3.11091685295105
INFO:root:current mean train loss 1439.7892346297122
INFO:root:current train perplexity3.1114513874053955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.51s/it]
INFO:root:final mean train loss: 1439.4177809660926
INFO:root:final train perplexity: 3.1118314266204834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2148.78564582987
INFO:root:eval perplexity: 5.684889316558838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2678.21014923745
INFO:root:eval perplexity: 8.938019752502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [16:17:42<18:38:25, 627.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1416.1785018920898
INFO:root:current train perplexity3.0584123134613037
INFO:root:current mean train loss 1427.4782755533854
INFO:root:current train perplexity3.071971893310547
INFO:root:current mean train loss 1429.2659022739956
INFO:root:current train perplexity3.0790133476257324
INFO:root:current mean train loss 1430.0777112458882
INFO:root:current train perplexity3.079467535018921
INFO:root:current mean train loss 1428.570012919108
INFO:root:current train perplexity3.082209825515747
INFO:root:current mean train loss 1428.2556884765625
INFO:root:current train perplexity3.0824601650238037
INFO:root:current mean train loss 1429.8609188304229
INFO:root:current train perplexity3.0852699279785156
INFO:root:current mean train loss 1430.1374240973057
INFO:root:current train perplexity3.085404396057129
INFO:root:current mean train loss 1430.3390518188476
INFO:root:current train perplexity3.088613748550415
INFO:root:current mean train loss 1431.8654101313377
INFO:root:current train perplexity3.091057300567627
INFO:root:current mean train loss 1431.8563722963686
INFO:root:current train perplexity3.091779947280884
INFO:root:current mean train loss 1433.0726862503311
INFO:root:current train perplexity3.094177722930908
INFO:root:current mean train loss 1433.200410270691
INFO:root:current train perplexity3.095435380935669
INFO:root:current mean train loss 1433.6910782523778
INFO:root:current train perplexity3.095365285873413
INFO:root:current mean train loss 1433.9276694632865
INFO:root:current train perplexity3.0973634719848633
INFO:root:current mean train loss 1435.2081331277195
INFO:root:current train perplexity3.0998342037200928
INFO:root:current mean train loss 1435.6008546375092
INFO:root:current train perplexity3.100843906402588
INFO:root:current mean train loss 1436.0455020518784
INFO:root:current train perplexity3.1020121574401855
INFO:root:current mean train loss 1436.0708675303358
INFO:root:current train perplexity3.1023166179656982
INFO:root:current mean train loss 1436.1441231775766
INFO:root:current train perplexity3.102883815765381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.23s/it]
INFO:root:final mean train loss: 1435.8139572412872
INFO:root:final train perplexity: 3.102999687194824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 2148.9597046764184
INFO:root:eval perplexity: 5.6856889724731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2679.359026536874
INFO:root:eval perplexity: 8.946419715881348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [16:28:20<18:33:41, 630.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1418.1521650491302
INFO:root:current train perplexity3.0727667808532715
INFO:root:current mean train loss 1421.7640473806314
INFO:root:current train perplexity3.0754899978637695
INFO:root:current mean train loss 1419.8558945575546
INFO:root:current train perplexity3.0732128620147705
INFO:root:current mean train loss 1417.7767389331116
INFO:root:current train perplexity3.0656416416168213
INFO:root:current mean train loss 1417.7127422739563
INFO:root:current train perplexity3.0698037147521973
INFO:root:current mean train loss 1419.4148650560746
INFO:root:current train perplexity3.0741114616394043
INFO:root:current mean train loss 1420.4410139436873
INFO:root:current train perplexity3.075227737426758
INFO:root:current mean train loss 1424.2186703556306
INFO:root:current train perplexity3.08029842376709
INFO:root:current mean train loss 1426.1886315659403
INFO:root:current train perplexity3.0825254917144775
INFO:root:current mean train loss 1426.6200107892037
INFO:root:current train perplexity3.0835416316986084
INFO:root:current mean train loss 1427.2970714030096
INFO:root:current train perplexity3.0835111141204834
INFO:root:current mean train loss 1428.3891002938662
INFO:root:current train perplexity3.0848388671875
INFO:root:current mean train loss 1428.946255274341
INFO:root:current train perplexity3.086106061935425
INFO:root:current mean train loss 1429.0917773891877
INFO:root:current train perplexity3.084925889968872
INFO:root:current mean train loss 1429.3568354971662
INFO:root:current train perplexity3.0848398208618164
INFO:root:current mean train loss 1430.1105986077412
INFO:root:current train perplexity3.0860812664031982
INFO:root:current mean train loss 1429.794697587885
INFO:root:current train perplexity3.087541341781616
INFO:root:current mean train loss 1430.6406980248114
INFO:root:current train perplexity3.08963680267334
INFO:root:current mean train loss 1430.806194170689
INFO:root:current train perplexity3.0896475315093994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.00s/it]
INFO:root:final mean train loss: 1430.6240139882852
INFO:root:final train perplexity: 3.090324640274048
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 2153.054932939245
INFO:root:eval perplexity: 5.704552173614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2684.098347116024
INFO:root:eval perplexity: 8.981163024902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [16:38:48<18:21:57, 629.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1440.1331089564733
INFO:root:current train perplexity3.0592739582061768
INFO:root:current mean train loss 1415.1039567913926
INFO:root:current train perplexity3.0712201595306396
INFO:root:current mean train loss 1420.382053838712
INFO:root:current train perplexity3.0590691566467285
INFO:root:current mean train loss 1420.6156215789213
INFO:root:current train perplexity3.065110445022583
INFO:root:current mean train loss 1421.2426560259096
INFO:root:current train perplexity3.061527967453003
INFO:root:current mean train loss 1421.6451670130866
INFO:root:current train perplexity3.0628387928009033
INFO:root:current mean train loss 1420.4590454101562
INFO:root:current train perplexity3.0639286041259766
INFO:root:current mean train loss 1420.7027945211287
INFO:root:current train perplexity3.064107894897461
INFO:root:current mean train loss 1422.342578334949
INFO:root:current train perplexity3.067324638366699
INFO:root:current mean train loss 1422.884662118991
INFO:root:current train perplexity3.068835973739624
INFO:root:current mean train loss 1422.896276349852
INFO:root:current train perplexity3.070612668991089
INFO:root:current mean train loss 1423.707819118534
INFO:root:current train perplexity3.0702340602874756
INFO:root:current mean train loss 1423.9590494322424
INFO:root:current train perplexity3.0721709728240967
INFO:root:current mean train loss 1424.8114820041976
INFO:root:current train perplexity3.074575424194336
INFO:root:current mean train loss 1425.893150491458
INFO:root:current train perplexity3.0748093128204346
INFO:root:current mean train loss 1426.1500940763808
INFO:root:current train perplexity3.0768747329711914
INFO:root:current mean train loss 1426.4590094848784
INFO:root:current train perplexity3.0784122943878174
INFO:root:current mean train loss 1426.5594111368007
INFO:root:current train perplexity3.0798044204711914
INFO:root:current mean train loss 1427.1065500883967
INFO:root:current train perplexity3.08095383644104
INFO:root:current mean train loss 1427.7219504233813
INFO:root:current train perplexity3.0823657512664795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.84s/it]
INFO:root:final mean train loss: 1427.4941041516465
INFO:root:final train perplexity: 3.0827059745788574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2158.6099697681184
INFO:root:eval perplexity: 5.730238437652588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2692.764358845163
INFO:root:eval perplexity: 9.04504108428955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [16:49:14<18:09:23, 628.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1411.0637994581652
INFO:root:current train perplexity3.008274555206299
INFO:root:current mean train loss 1411.5332860582657
INFO:root:current train perplexity3.032426357269287
INFO:root:current mean train loss 1416.4104157154695
INFO:root:current train perplexity3.045124053955078
INFO:root:current mean train loss 1415.9931434101209
INFO:root:current train perplexity3.046902894973755
INFO:root:current mean train loss 1415.773956936086
INFO:root:current train perplexity3.0415470600128174
INFO:root:current mean train loss 1414.846573709319
INFO:root:current train perplexity3.046081066131592
INFO:root:current mean train loss 1416.9101123356404
INFO:root:current train perplexity3.0506532192230225
INFO:root:current mean train loss 1419.026123046875
INFO:root:current train perplexity3.0526726245880127
INFO:root:current mean train loss 1418.9059385811522
INFO:root:current train perplexity3.0529932975769043
INFO:root:current mean train loss 1419.0263093647204
INFO:root:current train perplexity3.0567467212677
INFO:root:current mean train loss 1420.0123026983815
INFO:root:current train perplexity3.0586118698120117
INFO:root:current mean train loss 1420.527664305993
INFO:root:current train perplexity3.061514377593994
INFO:root:current mean train loss 1420.5078837985823
INFO:root:current train perplexity3.063523530960083
INFO:root:current mean train loss 1420.4176621526638
INFO:root:current train perplexity3.0648891925811768
INFO:root:current mean train loss 1420.877084664079
INFO:root:current train perplexity3.065681219100952
INFO:root:current mean train loss 1421.0313238322074
INFO:root:current train perplexity3.0664567947387695
INFO:root:current mean train loss 1422.0369614835606
INFO:root:current train perplexity3.067904233932495
INFO:root:current mean train loss 1422.9357645705834
INFO:root:current train perplexity3.0691425800323486
INFO:root:current mean train loss 1423.098723015194
INFO:root:current train perplexity3.0704774856567383
INFO:root:current mean train loss 1423.302596184579
INFO:root:current train perplexity3.0720481872558594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.12s/it]
INFO:root:final mean train loss: 1423.4106168299688
INFO:root:final train perplexity: 3.072793483734131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.43s/it]
INFO:root:eval mean loss: 2162.67719588043
INFO:root:eval perplexity: 5.749117851257324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 2697.332510873781
INFO:root:eval perplexity: 9.078898429870605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [16:59:55<18:05:08, 632.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1421.3646545410156
INFO:root:current train perplexity3.0406463146209717
INFO:root:current mean train loss 1417.610617972709
INFO:root:current train perplexity3.0362801551818848
INFO:root:current mean train loss 1418.6942192815966
INFO:root:current train perplexity3.0511116981506348
INFO:root:current mean train loss 1415.4911990110902
INFO:root:current train perplexity3.0545177459716797
INFO:root:current mean train loss 1414.40150478908
INFO:root:current train perplexity3.054062604904175
INFO:root:current mean train loss 1415.1617480646955
INFO:root:current train perplexity3.052037000656128
INFO:root:current mean train loss 1413.8438843150197
INFO:root:current train perplexity3.0529162883758545
INFO:root:current mean train loss 1414.400914809283
INFO:root:current train perplexity3.05440092086792
INFO:root:current mean train loss 1415.9884093662479
INFO:root:current train perplexity3.0544543266296387
INFO:root:current mean train loss 1415.8099161783855
INFO:root:current train perplexity3.052874803543091
INFO:root:current mean train loss 1415.8350515584
INFO:root:current train perplexity3.053666830062866
INFO:root:current mean train loss 1416.938643611682
INFO:root:current train perplexity3.0563032627105713
INFO:root:current mean train loss 1417.5322746863733
INFO:root:current train perplexity3.056553602218628
INFO:root:current mean train loss 1418.100990544441
INFO:root:current train perplexity3.0567007064819336
INFO:root:current mean train loss 1417.701625929353
INFO:root:current train perplexity3.058189630508423
INFO:root:current mean train loss 1417.4209382601794
INFO:root:current train perplexity3.059131145477295
INFO:root:current mean train loss 1417.7656381107072
INFO:root:current train perplexity3.060573101043701
INFO:root:current mean train loss 1418.485582504447
INFO:root:current train perplexity3.0608232021331787
INFO:root:current mean train loss 1419.1637307699625
INFO:root:current train perplexity3.0617990493774414
INFO:root:current mean train loss 1419.844899829653
INFO:root:current train perplexity3.062363386154175

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.50s/it]
INFO:root:final mean train loss: 1419.2866023799957
INFO:root:final train perplexity: 3.0628161430358887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2162.2142009329286
INFO:root:eval perplexity: 5.7469658851623535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2693.920304968002
INFO:root:eval perplexity: 9.053595542907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [17:10:31<17:56:43, 633.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1382.8336651141826
INFO:root:current train perplexity2.996304750442505
INFO:root:current mean train loss 1398.5062255859375
INFO:root:current train perplexity3.0064830780029297
INFO:root:current mean train loss 1400.8929489423645
INFO:root:current train perplexity3.0131518840789795
INFO:root:current mean train loss 1402.1139638404325
INFO:root:current train perplexity3.013618230819702
INFO:root:current mean train loss 1404.957257014449
INFO:root:current train perplexity3.0226969718933105
INFO:root:current mean train loss 1404.6692858130532
INFO:root:current train perplexity3.0296173095703125
INFO:root:current mean train loss 1405.2859125352443
INFO:root:current train perplexity3.0324738025665283
INFO:root:current mean train loss 1406.096297200521
INFO:root:current train perplexity3.0343635082244873
INFO:root:current mean train loss 1407.8589499412933
INFO:root:current train perplexity3.037944793701172
INFO:root:current mean train loss 1409.19640569341
INFO:root:current train perplexity3.040778160095215
INFO:root:current mean train loss 1410.0652491609815
INFO:root:current train perplexity3.040959119796753
INFO:root:current mean train loss 1410.736928207987
INFO:root:current train perplexity3.042877674102783
INFO:root:current mean train loss 1411.4727046921319
INFO:root:current train perplexity3.0449512004852295
INFO:root:current mean train loss 1411.5472837790464
INFO:root:current train perplexity3.046736001968384
INFO:root:current mean train loss 1412.812094043302
INFO:root:current train perplexity3.048006534576416
INFO:root:current mean train loss 1413.3628244028305
INFO:root:current train perplexity3.0503456592559814
INFO:root:current mean train loss 1414.8055239565738
INFO:root:current train perplexity3.0522100925445557
INFO:root:current mean train loss 1415.6114154070024
INFO:root:current train perplexity3.0543904304504395
INFO:root:current mean train loss 1415.7043708371732
INFO:root:current train perplexity3.054161310195923
INFO:root:current mean train loss 1415.8081303176687
INFO:root:current train perplexity3.053621530532837

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.97s/it]
INFO:root:final mean train loss: 1415.4700606091722
INFO:root:final train perplexity: 3.0536108016967773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2167.341114666445
INFO:root:eval perplexity: 5.770843505859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2701.1745947438776
INFO:root:eval perplexity: 9.107468605041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [17:21:05<17:46:28, 633.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1395.8961777105565
INFO:root:current train perplexity3.0233826637268066
INFO:root:current mean train loss 1397.2452359042325
INFO:root:current train perplexity3.0253522396087646
INFO:root:current mean train loss 1401.271551903258
INFO:root:current train perplexity3.020807981491089
INFO:root:current mean train loss 1403.8465742340886
INFO:root:current train perplexity3.0203983783721924
INFO:root:current mean train loss 1404.537376055579
INFO:root:current train perplexity3.0256526470184326
INFO:root:current mean train loss 1403.7119895699097
INFO:root:current train perplexity3.025064468383789
INFO:root:current mean train loss 1403.3147164174188
INFO:root:current train perplexity3.027205228805542
INFO:root:current mean train loss 1402.833935515655
INFO:root:current train perplexity3.026648998260498
INFO:root:current mean train loss 1405.0088592321695
INFO:root:current train perplexity3.0295610427856445
INFO:root:current mean train loss 1406.3820262528243
INFO:root:current train perplexity3.0294878482818604
INFO:root:current mean train loss 1406.6388958209984
INFO:root:current train perplexity3.030961513519287
INFO:root:current mean train loss 1406.9655695623148
INFO:root:current train perplexity3.0300981998443604
INFO:root:current mean train loss 1407.9469233139444
INFO:root:current train perplexity3.031750440597534
INFO:root:current mean train loss 1408.7462766788112
INFO:root:current train perplexity3.0337953567504883
INFO:root:current mean train loss 1409.839358598758
INFO:root:current train perplexity3.037083864212036
INFO:root:current mean train loss 1410.2651272278217
INFO:root:current train perplexity3.039113759994507
INFO:root:current mean train loss 1411.1753868075812
INFO:root:current train perplexity3.0406622886657715
INFO:root:current mean train loss 1411.3842099379208
INFO:root:current train perplexity3.0412755012512207
INFO:root:current mean train loss 1411.533743101276
INFO:root:current train perplexity3.043393135070801
INFO:root:current mean train loss 1412.0642788884136
INFO:root:current train perplexity3.0443639755249023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.48s/it]
INFO:root:final mean train loss: 1411.6179322951139
INFO:root:final train perplexity: 3.0443482398986816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2172.8803407926084
INFO:root:eval perplexity: 5.796753406524658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2709.2849636213155
INFO:root:eval perplexity: 9.168079376220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [17:31:44<17:38:49, 635.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1394.179151130445
INFO:root:current train perplexity3.015314817428589
INFO:root:current mean train loss 1404.962384554609
INFO:root:current train perplexity3.0226237773895264
INFO:root:current mean train loss 1402.8451568705582
INFO:root:current train perplexity3.018357992172241
INFO:root:current mean train loss 1402.1583349854127
INFO:root:current train perplexity3.020573854446411
INFO:root:current mean train loss 1403.2801303290173
INFO:root:current train perplexity3.017338752746582
INFO:root:current mean train loss 1402.1310197578646
INFO:root:current train perplexity3.01948881149292
INFO:root:current mean train loss 1402.0287457249194
INFO:root:current train perplexity3.0225634574890137
INFO:root:current mean train loss 1402.338421837111
INFO:root:current train perplexity3.022369623184204
INFO:root:current mean train loss 1403.0846020589283
INFO:root:current train perplexity3.0258677005767822
INFO:root:current mean train loss 1403.3241878352962
INFO:root:current train perplexity3.0262279510498047
INFO:root:current mean train loss 1404.4870027884015
INFO:root:current train perplexity3.0298473834991455
INFO:root:current mean train loss 1406.2955938216744
INFO:root:current train perplexity3.0319457054138184
INFO:root:current mean train loss 1405.575713195096
INFO:root:current train perplexity3.031376361846924
INFO:root:current mean train loss 1405.5854312441365
INFO:root:current train perplexity3.0320510864257812
INFO:root:current mean train loss 1406.731196937281
INFO:root:current train perplexity3.033271551132202
INFO:root:current mean train loss 1407.684964159118
INFO:root:current train perplexity3.0337326526641846
INFO:root:current mean train loss 1408.0913067256934
INFO:root:current train perplexity3.0348334312438965
INFO:root:current mean train loss 1408.4195551890807
INFO:root:current train perplexity3.035201072692871
INFO:root:current mean train loss 1408.9354186979579
INFO:root:current train perplexity3.0359456539154053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.24s/it]
INFO:root:final mean train loss: 1408.817358343035
INFO:root:final train perplexity: 3.0376317501068115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2172.016457848515
INFO:root:eval perplexity: 5.7927045822143555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2707.5587292393893
INFO:root:eval perplexity: 9.155143737792969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [17:42:15<17:26:13, 634.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1384.0297470092773
INFO:root:current train perplexity3.0182676315307617
INFO:root:current mean train loss 1397.3430302060883
INFO:root:current train perplexity2.999560594558716
INFO:root:current mean train loss 1402.0870395236545
INFO:root:current train perplexity3.0038528442382812
INFO:root:current mean train loss 1399.53556186338
INFO:root:current train perplexity3.006242513656616
INFO:root:current mean train loss 1397.1878509521484
INFO:root:current train perplexity3.0097217559814453
INFO:root:current mean train loss 1397.291528036428
INFO:root:current train perplexity3.0113935470581055
INFO:root:current mean train loss 1396.967788299957
INFO:root:current train perplexity3.00823712348938
INFO:root:current mean train loss 1395.3691718245352
INFO:root:current train perplexity3.0086159706115723
INFO:root:current mean train loss 1396.3048614801146
INFO:root:current train perplexity3.0102715492248535
INFO:root:current mean train loss 1397.35349563532
INFO:root:current train perplexity3.0124146938323975
INFO:root:current mean train loss 1397.6289020448219
INFO:root:current train perplexity3.0139946937561035
INFO:root:current mean train loss 1399.664075735222
INFO:root:current train perplexity3.017098903656006
INFO:root:current mean train loss 1399.9190748114336
INFO:root:current train perplexity3.018075942993164
INFO:root:current mean train loss 1400.6923593445752
INFO:root:current train perplexity3.019014358520508
INFO:root:current mean train loss 1401.7347117278534
INFO:root:current train perplexity3.021273612976074
INFO:root:current mean train loss 1402.5128723788703
INFO:root:current train perplexity3.023956775665283
INFO:root:current mean train loss 1402.9171046644153
INFO:root:current train perplexity3.024813175201416
INFO:root:current mean train loss 1403.9431272564511
INFO:root:current train perplexity3.0269076824188232
INFO:root:current mean train loss 1404.5515372658617
INFO:root:current train perplexity3.0278382301330566
INFO:root:current mean train loss 1404.6938386729962
INFO:root:current train perplexity3.0277581214904785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.79s/it]
INFO:root:final mean train loss: 1404.8541790706847
INFO:root:final train perplexity: 3.0281522274017334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 2177.142680283134
INFO:root:eval perplexity: 5.816770076751709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 2714.104742821227
INFO:root:eval perplexity: 9.204289436340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [17:52:53<17:17:34, 635.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.3077096650095
INFO:root:current train perplexity2.999307870864868
INFO:root:current mean train loss 1396.573405559798
INFO:root:current train perplexity3.019787073135376
INFO:root:current mean train loss 1392.7397481893777
INFO:root:current train perplexity3.005686044692993
INFO:root:current mean train loss 1394.2730448954815
INFO:root:current train perplexity3.0047338008880615
INFO:root:current mean train loss 1396.1725067772986
INFO:root:current train perplexity3.004365921020508
INFO:root:current mean train loss 1394.7974045057458
INFO:root:current train perplexity3.0029430389404297
INFO:root:current mean train loss 1393.590586392612
INFO:root:current train perplexity3.0035481452941895
INFO:root:current mean train loss 1395.483640912773
INFO:root:current train perplexity3.0050387382507324
INFO:root:current mean train loss 1395.7468118106617
INFO:root:current train perplexity3.0067672729492188
INFO:root:current mean train loss 1397.6487539931254
INFO:root:current train perplexity3.007514238357544
INFO:root:current mean train loss 1397.79634677706
INFO:root:current train perplexity3.007781744003296
INFO:root:current mean train loss 1397.9583323277527
INFO:root:current train perplexity3.009596586227417
INFO:root:current mean train loss 1398.1882626176944
INFO:root:current train perplexity3.0099332332611084
INFO:root:current mean train loss 1398.8989290779725
INFO:root:current train perplexity3.011220932006836
INFO:root:current mean train loss 1399.4015907985051
INFO:root:current train perplexity3.012746572494507
INFO:root:current mean train loss 1400.0093990159205
INFO:root:current train perplexity3.0150818824768066
INFO:root:current mean train loss 1400.0830295653848
INFO:root:current train perplexity3.0154614448547363
INFO:root:current mean train loss 1399.9237865661516
INFO:root:current train perplexity3.0153286457061768
INFO:root:current mean train loss 1400.9480142962782
INFO:root:current train perplexity3.017256021499634
INFO:root:current mean train loss 1400.94241596662
INFO:root:current train perplexity3.017770528793335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.37s/it]
INFO:root:final mean train loss: 1400.652167169722
INFO:root:final train perplexity: 3.0181334018707275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it]
INFO:root:eval mean loss: 2178.7012099678636
INFO:root:eval perplexity: 5.8241071701049805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2716.37640337572
INFO:root:eval perplexity: 9.221402168273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [18:03:24<17:04:51, 633.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1398.9623193359375
INFO:root:current train perplexity2.981553077697754
INFO:root:current mean train loss 1387.0327848307293
INFO:root:current train perplexity2.986661911010742
INFO:root:current mean train loss 1391.3947099609375
INFO:root:current train perplexity2.989049196243286
INFO:root:current mean train loss 1390.6413201032367
INFO:root:current train perplexity2.98818302154541
INFO:root:current mean train loss 1389.5358729383681
INFO:root:current train perplexity2.9900665283203125
INFO:root:current mean train loss 1391.9236348100142
INFO:root:current train perplexity2.9953558444976807
INFO:root:current mean train loss 1392.3493340594953
INFO:root:current train perplexity2.9985692501068115
INFO:root:current mean train loss 1394.1231481119792
INFO:root:current train perplexity2.9991941452026367
INFO:root:current mean train loss 1394.8270915670955
INFO:root:current train perplexity2.9993300437927246
INFO:root:current mean train loss 1396.3295383172285
INFO:root:current train perplexity3.0024983882904053
INFO:root:current mean train loss 1396.7821973818825
INFO:root:current train perplexity3.005542755126953
INFO:root:current mean train loss 1396.3911303710938
INFO:root:current train perplexity3.004884958267212
INFO:root:current mean train loss 1396.6678514648438
INFO:root:current train perplexity3.0049335956573486
INFO:root:current mean train loss 1396.7475294777198
INFO:root:current train perplexity3.006376266479492
INFO:root:current mean train loss 1396.7741651232488
INFO:root:current train perplexity3.006747245788574
INFO:root:current mean train loss 1397.1153869235131
INFO:root:current train perplexity3.0087037086486816
INFO:root:current mean train loss 1397.8155325224905
INFO:root:current train perplexity3.0093421936035156
INFO:root:current mean train loss 1398.1703539341518
INFO:root:current train perplexity3.009833812713623
INFO:root:current mean train loss 1397.9715221838048
INFO:root:current train perplexity3.0102789402008057
INFO:root:current mean train loss 1397.9685557517028
INFO:root:current train perplexity3.0105292797088623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.96s/it]
INFO:root:final mean train loss: 1397.669201672468
INFO:root:final train perplexity: 3.0110414028167725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2183.8975617970136
INFO:root:eval perplexity: 5.848634243011475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 2724.381999996537
INFO:root:eval perplexity: 9.281974792480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [18:14:11<17:00:19, 637.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.6019013817631
INFO:root:current train perplexity2.9546709060668945
INFO:root:current mean train loss 1387.253955224317
INFO:root:current train perplexity2.969944953918457
INFO:root:current mean train loss 1385.8401272091526
INFO:root:current train perplexity2.969369649887085
INFO:root:current mean train loss 1386.093676824336
INFO:root:current train perplexity2.9749131202697754
INFO:root:current mean train loss 1385.2869771103788
INFO:root:current train perplexity2.9733777046203613
INFO:root:current mean train loss 1385.480284245136
INFO:root:current train perplexity2.975421667098999
INFO:root:current mean train loss 1385.9562204981494
INFO:root:current train perplexity2.977219820022583
INFO:root:current mean train loss 1387.4520605850716
INFO:root:current train perplexity2.9801411628723145
INFO:root:current mean train loss 1387.5876691525646
INFO:root:current train perplexity2.983543634414673
INFO:root:current mean train loss 1387.7927810369135
INFO:root:current train perplexity2.9853858947753906
INFO:root:current mean train loss 1388.0110855174041
INFO:root:current train perplexity2.9894378185272217
INFO:root:current mean train loss 1389.7384831314937
INFO:root:current train perplexity2.9927165508270264
INFO:root:current mean train loss 1389.8052978515625
INFO:root:current train perplexity2.993544340133667
INFO:root:current mean train loss 1390.7338125121446
INFO:root:current train perplexity2.9948549270629883
INFO:root:current mean train loss 1390.3019269801518
INFO:root:current train perplexity2.9961955547332764
INFO:root:current mean train loss 1390.683382405547
INFO:root:current train perplexity2.9972376823425293
INFO:root:current mean train loss 1391.391052355935
INFO:root:current train perplexity2.9981534481048584
INFO:root:current mean train loss 1392.5816292538775
INFO:root:current train perplexity3.0002901554107666
INFO:root:current mean train loss 1393.279031419473
INFO:root:current train perplexity3.0011637210845947
INFO:root:current mean train loss 1394.010025776881
INFO:root:current train perplexity3.0013184547424316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.93s/it]
INFO:root:final mean train loss: 1393.7586305803923
INFO:root:final train perplexity: 3.0017690658569336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2187.764100419714
INFO:root:eval perplexity: 5.866951942443848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.23s/it]
INFO:root:eval mean loss: 2729.3153539346463
INFO:root:eval perplexity: 9.319500923156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [18:24:42<16:46:27, 635.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1372.2825985863096
INFO:root:current train perplexity2.9451589584350586
INFO:root:current mean train loss 1374.7637594471807
INFO:root:current train perplexity2.955352544784546
INFO:root:current mean train loss 1376.7605229767275
INFO:root:current train perplexity2.9636237621307373
INFO:root:current mean train loss 1377.1083017985027
INFO:root:current train perplexity2.964010000228882
INFO:root:current mean train loss 1379.1273337119867
INFO:root:current train perplexity2.967819929122925
INFO:root:current mean train loss 1383.378190341061
INFO:root:current train perplexity2.9734745025634766
INFO:root:current mean train loss 1384.4931710226494
INFO:root:current train perplexity2.9741108417510986
INFO:root:current mean train loss 1384.7422751601862
INFO:root:current train perplexity2.975306749343872
INFO:root:current mean train loss 1384.0969430224388
INFO:root:current train perplexity2.977544069290161
INFO:root:current mean train loss 1384.052381686079
INFO:root:current train perplexity2.9789559841156006
INFO:root:current mean train loss 1384.8222486207405
INFO:root:current train perplexity2.9799306392669678
INFO:root:current mean train loss 1386.1551874521617
INFO:root:current train perplexity2.9810614585876465
INFO:root:current mean train loss 1386.2930061126424
INFO:root:current train perplexity2.982969045639038
INFO:root:current mean train loss 1387.1389003158304
INFO:root:current train perplexity2.9852492809295654
INFO:root:current mean train loss 1387.8884960904597
INFO:root:current train perplexity2.9867048263549805
INFO:root:current mean train loss 1388.141172466856
INFO:root:current train perplexity2.9871373176574707
INFO:root:current mean train loss 1388.167853348612
INFO:root:current train perplexity2.9880893230438232
INFO:root:current mean train loss 1389.0590177116908
INFO:root:current train perplexity2.9910647869110107
INFO:root:current mean train loss 1389.7582975415921
INFO:root:current train perplexity2.992177963256836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 560.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 560.00s/it]
INFO:root:final mean train loss: 1389.929760108136
INFO:root:final train perplexity: 2.99271821975708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.34s/it]
INFO:root:eval mean loss: 2189.529934064716
INFO:root:eval perplexity: 5.875336170196533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it]
INFO:root:eval mean loss: 2731.372306661403
INFO:root:eval perplexity: 9.33519172668457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [18:35:23<16:38:18, 637.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1345.5765380859375
INFO:root:current train perplexity2.9834370613098145
INFO:root:current mean train loss 1375.229490978883
INFO:root:current train perplexity2.9648401737213135
INFO:root:current mean train loss 1380.033354953747
INFO:root:current train perplexity2.9711856842041016
INFO:root:current mean train loss 1381.497402862853
INFO:root:current train perplexity2.9709317684173584
INFO:root:current mean train loss 1379.5818212038264
INFO:root:current train perplexity2.970258951187134
INFO:root:current mean train loss 1378.5040887463354
INFO:root:current train perplexity2.967409372329712
INFO:root:current mean train loss 1379.9252178173097
INFO:root:current train perplexity2.9676640033721924
INFO:root:current mean train loss 1381.1964059086906
INFO:root:current train perplexity2.9726150035858154
INFO:root:current mean train loss 1382.1232067398662
INFO:root:current train perplexity2.9734456539154053
INFO:root:current mean train loss 1381.8222535670002
INFO:root:current train perplexity2.974097967147827
INFO:root:current mean train loss 1381.6511071935877
INFO:root:current train perplexity2.9745330810546875
INFO:root:current mean train loss 1381.5453838795343
INFO:root:current train perplexity2.976491689682007
INFO:root:current mean train loss 1382.3556850411117
INFO:root:current train perplexity2.9789772033691406
INFO:root:current mean train loss 1383.253504853538
INFO:root:current train perplexity2.9798693656921387
INFO:root:current mean train loss 1383.150992873394
INFO:root:current train perplexity2.980668783187866
INFO:root:current mean train loss 1383.7796255133296
INFO:root:current train perplexity2.981779098510742
INFO:root:current mean train loss 1384.6841684182982
INFO:root:current train perplexity2.982393741607666
INFO:root:current mean train loss 1385.2835038155406
INFO:root:current train perplexity2.982722282409668
INFO:root:current mean train loss 1386.627452454257
INFO:root:current train perplexity2.9847025871276855
INFO:root:current mean train loss 1386.8758562901721
INFO:root:current train perplexity2.9852542877197266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.45s/it]
INFO:root:final mean train loss: 1386.9894892105356
INFO:root:final train perplexity: 2.9857869148254395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it]
INFO:root:eval mean loss: 2189.5170149566434
INFO:root:eval perplexity: 5.875275135040283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 2731.9587956421765
INFO:root:eval perplexity: 9.33967113494873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [18:45:55<16:25:16, 635.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.323248969184
INFO:root:current train perplexity2.962082862854004
INFO:root:current mean train loss 1376.657518289857
INFO:root:current train perplexity2.959620475769043
INFO:root:current mean train loss 1377.4850004703626
INFO:root:current train perplexity2.9601659774780273
INFO:root:current mean train loss 1376.6043524592178
INFO:root:current train perplexity2.957369327545166
INFO:root:current mean train loss 1378.0810733776914
INFO:root:current train perplexity2.9586567878723145
INFO:root:current mean train loss 1376.6869504479369
INFO:root:current train perplexity2.962639808654785
INFO:root:current mean train loss 1376.9206390874672
INFO:root:current train perplexity2.963474988937378
INFO:root:current mean train loss 1377.2953547315676
INFO:root:current train perplexity2.9655661582946777
INFO:root:current mean train loss 1377.7734665998912
INFO:root:current train perplexity2.9664649963378906
INFO:root:current mean train loss 1379.4659591375612
INFO:root:current train perplexity2.9672677516937256
INFO:root:current mean train loss 1380.235915268334
INFO:root:current train perplexity2.9689693450927734
INFO:root:current mean train loss 1379.971407376803
INFO:root:current train perplexity2.969714879989624
INFO:root:current mean train loss 1379.5780043327945
INFO:root:current train perplexity2.969080924987793
INFO:root:current mean train loss 1380.6065644190417
INFO:root:current train perplexity2.971355438232422
INFO:root:current mean train loss 1381.5399519432078
INFO:root:current train perplexity2.973173141479492
INFO:root:current mean train loss 1382.0539742169487
INFO:root:current train perplexity2.973912239074707
INFO:root:current mean train loss 1382.9286702725442
INFO:root:current train perplexity2.9742069244384766
INFO:root:current mean train loss 1383.2463598462284
INFO:root:current train perplexity2.9756369590759277
INFO:root:current mean train loss 1383.868731575306
INFO:root:current train perplexity2.975961923599243
INFO:root:current mean train loss 1383.6890841773454
INFO:root:current train perplexity2.9762141704559326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.65s/it]
INFO:root:final mean train loss: 1383.5935025352212
INFO:root:final train perplexity: 2.9778006076812744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 2192.799996883311
INFO:root:eval perplexity: 5.890894889831543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2737.057221541168
INFO:root:eval perplexity: 9.378693580627441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [18:56:33<16:15:59, 636.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1370.3930908203124
INFO:root:current train perplexity2.9674038887023926
INFO:root:current mean train loss 1359.8255570023148
INFO:root:current train perplexity2.9621548652648926
INFO:root:current mean train loss 1365.0001288231383
INFO:root:current train perplexity2.94803524017334
INFO:root:current mean train loss 1366.0780852816
INFO:root:current train perplexity2.943758010864258
INFO:root:current mean train loss 1366.949086016074
INFO:root:current train perplexity2.947240114212036
INFO:root:current mean train loss 1369.8436518874123
INFO:root:current train perplexity2.9495458602905273
INFO:root:current mean train loss 1371.5410880982406
INFO:root:current train perplexity2.950835943222046
INFO:root:current mean train loss 1372.8151989995217
INFO:root:current train perplexity2.9533586502075195
INFO:root:current mean train loss 1372.2970413664857
INFO:root:current train perplexity2.957551956176758
INFO:root:current mean train loss 1373.5460620247743
INFO:root:current train perplexity2.956895589828491
INFO:root:current mean train loss 1374.6055253623188
INFO:root:current train perplexity2.9599995613098145
INFO:root:current mean train loss 1375.5694836049354
INFO:root:current train perplexity2.96130633354187
INFO:root:current mean train loss 1375.96963058657
INFO:root:current train perplexity2.962946891784668
INFO:root:current mean train loss 1377.0657117750761
INFO:root:current train perplexity2.963843584060669
INFO:root:current mean train loss 1377.3902911993684
INFO:root:current train perplexity2.96504545211792
INFO:root:current mean train loss 1377.5419135376374
INFO:root:current train perplexity2.964637517929077
INFO:root:current mean train loss 1377.7017668464498
INFO:root:current train perplexity2.9650580883026123
INFO:root:current mean train loss 1378.1297317548856
INFO:root:current train perplexity2.965932846069336
INFO:root:current mean train loss 1378.8450254518264
INFO:root:current train perplexity2.9668848514556885
INFO:root:current mean train loss 1380.207953622113
INFO:root:current train perplexity2.9688467979431152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.08s/it]
INFO:root:final mean train loss: 1379.9421102011138
INFO:root:final train perplexity: 2.96923828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2199.3830977636026
INFO:root:eval perplexity: 5.9223408699035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 2745.1813605558787
INFO:root:eval perplexity: 9.441215515136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [19:07:04<16:02:54, 634.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1367.1143657977764
INFO:root:current train perplexity2.956146240234375
INFO:root:current mean train loss 1375.1166558516652
INFO:root:current train perplexity2.9542202949523926
INFO:root:current mean train loss 1376.25490218874
INFO:root:current train perplexity2.949097156524658
INFO:root:current mean train loss 1373.5645883733575
INFO:root:current train perplexity2.9534926414489746
INFO:root:current mean train loss 1373.3967709161539
INFO:root:current train perplexity2.956481456756592
INFO:root:current mean train loss 1375.5157439743264
INFO:root:current train perplexity2.954261541366577
INFO:root:current mean train loss 1375.9163883887918
INFO:root:current train perplexity2.954136610031128
INFO:root:current mean train loss 1378.1912455457323
INFO:root:current train perplexity2.955153465270996
INFO:root:current mean train loss 1377.957509788549
INFO:root:current train perplexity2.955982208251953
INFO:root:current mean train loss 1377.308299601579
INFO:root:current train perplexity2.956796646118164
INFO:root:current mean train loss 1376.4758682541067
INFO:root:current train perplexity2.9569907188415527
INFO:root:current mean train loss 1376.3651464250352
INFO:root:current train perplexity2.955711841583252
INFO:root:current mean train loss 1376.5945881121456
INFO:root:current train perplexity2.956045627593994
INFO:root:current mean train loss 1376.355850400304
INFO:root:current train perplexity2.957261800765991
INFO:root:current mean train loss 1377.4197849242155
INFO:root:current train perplexity2.9592695236206055
INFO:root:current mean train loss 1377.4299800125593
INFO:root:current train perplexity2.9602017402648926
INFO:root:current mean train loss 1377.2386818209225
INFO:root:current train perplexity2.9610660076141357
INFO:root:current mean train loss 1377.2814738652478
INFO:root:current train perplexity2.9625260829925537
INFO:root:current mean train loss 1377.3994628378948
INFO:root:current train perplexity2.963172674179077
INFO:root:current mean train loss 1377.8901375942544
INFO:root:current train perplexity2.9637234210968018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.34s/it]
INFO:root:final mean train loss: 1377.4700658416364
INFO:root:final train perplexity: 2.9634549617767334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2201.0957749819927
INFO:root:eval perplexity: 5.930549144744873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2743.885218410627
INFO:root:eval perplexity: 9.431215286254883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [19:17:42<15:53:34, 635.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1362.0124777088995
INFO:root:current train perplexity2.9227118492126465
INFO:root:current mean train loss 1358.6704058223927
INFO:root:current train perplexity2.9233293533325195
INFO:root:current mean train loss 1360.369658856587
INFO:root:current train perplexity2.9287610054016113
INFO:root:current mean train loss 1365.1899126254445
INFO:root:current train perplexity2.929853916168213
INFO:root:current mean train loss 1365.9415283203125
INFO:root:current train perplexity2.9305357933044434
INFO:root:current mean train loss 1367.0977032331255
INFO:root:current train perplexity2.9323110580444336
INFO:root:current mean train loss 1368.803640322835
INFO:root:current train perplexity2.935054302215576
INFO:root:current mean train loss 1369.3110480141113
INFO:root:current train perplexity2.938368320465088
INFO:root:current mean train loss 1369.3045282045634
INFO:root:current train perplexity2.942085027694702
INFO:root:current mean train loss 1370.7819722178551
INFO:root:current train perplexity2.943390369415283
INFO:root:current mean train loss 1370.1757755404437
INFO:root:current train perplexity2.9448866844177246
INFO:root:current mean train loss 1370.1879061004665
INFO:root:current train perplexity2.9472482204437256
INFO:root:current mean train loss 1370.7332840627155
INFO:root:current train perplexity2.9462320804595947
INFO:root:current mean train loss 1370.2706760715794
INFO:root:current train perplexity2.9474916458129883
INFO:root:current mean train loss 1371.7006438731173
INFO:root:current train perplexity2.948725700378418
INFO:root:current mean train loss 1372.0037316637786
INFO:root:current train perplexity2.949146032333374
INFO:root:current mean train loss 1372.550570826819
INFO:root:current train perplexity2.9504122734069824
INFO:root:current mean train loss 1373.4028117437024
INFO:root:current train perplexity2.9519646167755127
INFO:root:current mean train loss 1373.311892914096
INFO:root:current train perplexity2.9527876377105713
INFO:root:current mean train loss 1373.463999363176
INFO:root:current train perplexity2.9532437324523926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.07s/it]
INFO:root:final mean train loss: 1373.3278690401617
INFO:root:final train perplexity: 2.953789710998535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it]
INFO:root:eval mean loss: 2203.309566416639
INFO:root:eval perplexity: 5.941177845001221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 2748.960790755901
INFO:root:eval perplexity: 9.470442771911621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [19:28:18<15:43:16, 635.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1360.7397134470384
INFO:root:current train perplexity2.9297666549682617
INFO:root:current mean train loss 1360.1180295226395
INFO:root:current train perplexity2.925013303756714
INFO:root:current mean train loss 1362.0245698515353
INFO:root:current train perplexity2.930331230163574
INFO:root:current mean train loss 1360.9256933340755
INFO:root:current train perplexity2.926828145980835
INFO:root:current mean train loss 1362.8879560305747
INFO:root:current train perplexity2.9239540100097656
INFO:root:current mean train loss 1363.4769045468483
INFO:root:current train perplexity2.926381826400757
INFO:root:current mean train loss 1365.0302995954241
INFO:root:current train perplexity2.928417205810547
INFO:root:current mean train loss 1363.610730663814
INFO:root:current train perplexity2.9303321838378906
INFO:root:current mean train loss 1364.1099194942155
INFO:root:current train perplexity2.9300806522369385
INFO:root:current mean train loss 1364.9213754526259
INFO:root:current train perplexity2.931936502456665
INFO:root:current mean train loss 1365.9960856569405
INFO:root:current train perplexity2.9341342449188232
INFO:root:current mean train loss 1366.170585748116
INFO:root:current train perplexity2.935483932495117
INFO:root:current mean train loss 1367.1152836397684
INFO:root:current train perplexity2.9377593994140625
INFO:root:current mean train loss 1366.939333344607
INFO:root:current train perplexity2.939281940460205
INFO:root:current mean train loss 1368.4542951006267
INFO:root:current train perplexity2.9411332607269287
INFO:root:current mean train loss 1368.3535958250413
INFO:root:current train perplexity2.9427988529205322
INFO:root:current mean train loss 1369.006303418432
INFO:root:current train perplexity2.9447505474090576
INFO:root:current mean train loss 1369.7113162870503
INFO:root:current train perplexity2.9453842639923096
INFO:root:current mean train loss 1369.980301890368
INFO:root:current train perplexity2.9461052417755127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:33<00:00, 573.91s/it]
INFO:root:final mean train loss: 1370.1956999485865
INFO:root:final train perplexity: 2.946502447128296
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 2203.950299635001
INFO:root:eval perplexity: 5.944257736206055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2751.453115476784
INFO:root:eval perplexity: 9.489765167236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [19:39:08<15:38:54, 640.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1332.8126220703125
INFO:root:current train perplexity2.848269462585449
INFO:root:current mean train loss 1360.285400390625
INFO:root:current train perplexity2.919135570526123
INFO:root:current mean train loss 1358.3076298154633
INFO:root:current train perplexity2.9273438453674316
INFO:root:current mean train loss 1353.8770933245669
INFO:root:current train perplexity2.924842596054077
INFO:root:current mean train loss 1355.707047606816
INFO:root:current train perplexity2.9287757873535156
INFO:root:current mean train loss 1357.0220961826697
INFO:root:current train perplexity2.9287145137786865
INFO:root:current mean train loss 1359.569184716068
INFO:root:current train perplexity2.930800676345825
INFO:root:current mean train loss 1358.6975722767381
INFO:root:current train perplexity2.9303793907165527
INFO:root:current mean train loss 1359.4207082632024
INFO:root:current train perplexity2.9308485984802246
INFO:root:current mean train loss 1360.4465934947743
INFO:root:current train perplexity2.933350086212158
INFO:root:current mean train loss 1361.8911231393708
INFO:root:current train perplexity2.935802459716797
INFO:root:current mean train loss 1362.3367994071566
INFO:root:current train perplexity2.9339821338653564
INFO:root:current mean train loss 1363.0085629838165
INFO:root:current train perplexity2.9332103729248047
INFO:root:current mean train loss 1363.2079080389906
INFO:root:current train perplexity2.933138608932495
INFO:root:current mean train loss 1363.533115509316
INFO:root:current train perplexity2.932076930999756
INFO:root:current mean train loss 1363.7607068577688
INFO:root:current train perplexity2.932572841644287
INFO:root:current mean train loss 1364.765659801081
INFO:root:current train perplexity2.933809995651245
INFO:root:current mean train loss 1365.882453600379
INFO:root:current train perplexity2.9334089756011963
INFO:root:current mean train loss 1366.4510777664395
INFO:root:current train perplexity2.9352264404296875
INFO:root:current mean train loss 1367.1049243407817
INFO:root:current train perplexity2.936739444732666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.80s/it]
INFO:root:final mean train loss: 1366.7338208820383
INFO:root:final train perplexity: 2.9384684562683105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2209.450429064162
INFO:root:eval perplexity: 5.970758438110352
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2758.5623874529033
INFO:root:eval perplexity: 9.5451021194458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [19:49:38<15:23:53, 637.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1320.9191467285157
INFO:root:current train perplexity2.8847768306732178
INFO:root:current mean train loss 1356.5929728190104
INFO:root:current train perplexity2.9185678958892822
INFO:root:current mean train loss 1352.7486921830612
INFO:root:current train perplexity2.9098458290100098
INFO:root:current mean train loss 1355.210531616211
INFO:root:current train perplexity2.910508394241333
INFO:root:current mean train loss 1353.7275332496279
INFO:root:current train perplexity2.9142160415649414
INFO:root:current mean train loss 1354.194273024339
INFO:root:current train perplexity2.9149107933044434
INFO:root:current mean train loss 1355.599441232989
INFO:root:current train perplexity2.914198637008667
INFO:root:current mean train loss 1354.7806560940212
INFO:root:current train perplexity2.9154140949249268
INFO:root:current mean train loss 1354.1024872570504
INFO:root:current train perplexity2.915215253829956
INFO:root:current mean train loss 1355.032653012483
INFO:root:current train perplexity2.9161393642425537
INFO:root:current mean train loss 1357.3345701928233
INFO:root:current train perplexity2.917471170425415
INFO:root:current mean train loss 1358.3218008858817
INFO:root:current train perplexity2.919344902038574
INFO:root:current mean train loss 1359.748733470479
INFO:root:current train perplexity2.921431064605713
INFO:root:current mean train loss 1360.5912944446911
INFO:root:current train perplexity2.9239580631256104
INFO:root:current mean train loss 1361.5364527742627
INFO:root:current train perplexity2.924720525741577
INFO:root:current mean train loss 1361.8248405054997
INFO:root:current train perplexity2.926708936691284
INFO:root:current mean train loss 1362.3538216296538
INFO:root:current train perplexity2.9284043312072754
INFO:root:current mean train loss 1362.6500656482785
INFO:root:current train perplexity2.928034543991089
INFO:root:current mean train loss 1363.1500601632254
INFO:root:current train perplexity2.9299612045288086
INFO:root:current mean train loss 1364.2552520116171
INFO:root:current train perplexity2.9311044216156006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.18s/it]
INFO:root:final mean train loss: 1363.8283842532128
INFO:root:final train perplexity: 2.9317426681518555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it]
INFO:root:eval mean loss: 2213.067130014406
INFO:root:eval perplexity: 5.988246917724609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2762.6714655017176
INFO:root:eval perplexity: 9.577230453491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [20:00:20<15:15:01, 638.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1342.6886646167652
INFO:root:current train perplexity2.8687989711761475
INFO:root:current mean train loss 1343.6372934605954
INFO:root:current train perplexity2.9061524868011475
INFO:root:current mean train loss 1344.516976529536
INFO:root:current train perplexity2.896402359008789
INFO:root:current mean train loss 1351.7931335630333
INFO:root:current train perplexity2.9081780910491943
INFO:root:current mean train loss 1352.5929186927917
INFO:root:current train perplexity2.9157755374908447
INFO:root:current mean train loss 1355.092041924901
INFO:root:current train perplexity2.9201605319976807
INFO:root:current mean train loss 1356.300789106959
INFO:root:current train perplexity2.922741174697876
INFO:root:current mean train loss 1355.8609435289816
INFO:root:current train perplexity2.919187068939209
INFO:root:current mean train loss 1355.754966088663
INFO:root:current train perplexity2.9170215129852295
INFO:root:current mean train loss 1355.5712596197138
INFO:root:current train perplexity2.9168386459350586
INFO:root:current mean train loss 1356.4572696225966
INFO:root:current train perplexity2.916919708251953
INFO:root:current mean train loss 1356.1974197964764
INFO:root:current train perplexity2.9166512489318848
INFO:root:current mean train loss 1356.9545418840314
INFO:root:current train perplexity2.9181151390075684
INFO:root:current mean train loss 1357.3793721623447
INFO:root:current train perplexity2.9184277057647705
INFO:root:current mean train loss 1358.3661619224893
INFO:root:current train perplexity2.9195687770843506
INFO:root:current mean train loss 1358.2402551833422
INFO:root:current train perplexity2.9200994968414307
INFO:root:current mean train loss 1359.0680598292179
INFO:root:current train perplexity2.921863317489624
INFO:root:current mean train loss 1359.2147155656303
INFO:root:current train perplexity2.9232048988342285
INFO:root:current mean train loss 1360.2838659063266
INFO:root:current train perplexity2.9238998889923096
INFO:root:current mean train loss 1360.7101354406984
INFO:root:current train perplexity2.9239084720611572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.25s/it]
INFO:root:final mean train loss: 1360.5083855471705
INFO:root:final train perplexity: 2.924076557159424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2214.1670748663287
INFO:root:eval perplexity: 5.993575572967529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.36s/it]
INFO:root:eval mean loss: 2764.1462462946033
INFO:root:eval perplexity: 9.588788986206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [20:11:05<15:07:11, 640.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1359.0748471860531
INFO:root:current train perplexity2.896135091781616
INFO:root:current mean train loss 1361.6574429598722
INFO:root:current train perplexity2.898503065109253
INFO:root:current mean train loss 1356.840180644839
INFO:root:current train perplexity2.902474880218506
INFO:root:current mean train loss 1350.6226479050804
INFO:root:current train perplexity2.8989851474761963
INFO:root:current mean train loss 1350.6771611285105
INFO:root:current train perplexity2.902592897415161
INFO:root:current mean train loss 1352.2360595262437
INFO:root:current train perplexity2.904670476913452
INFO:root:current mean train loss 1353.576639624546
INFO:root:current train perplexity2.9080398082733154
INFO:root:current mean train loss 1354.4079996205135
INFO:root:current train perplexity2.9096877574920654
INFO:root:current mean train loss 1354.0945174420467
INFO:root:current train perplexity2.910032033920288
INFO:root:current mean train loss 1354.117699837035
INFO:root:current train perplexity2.912590980529785
INFO:root:current mean train loss 1354.7230449292872
INFO:root:current train perplexity2.912442445755005
INFO:root:current mean train loss 1355.5018774921807
INFO:root:current train perplexity2.912364959716797
INFO:root:current mean train loss 1355.3362964100816
INFO:root:current train perplexity2.9137637615203857
INFO:root:current mean train loss 1355.3650393690282
INFO:root:current train perplexity2.912853717803955
INFO:root:current mean train loss 1355.3660360596039
INFO:root:current train perplexity2.913064956665039
INFO:root:current mean train loss 1355.8361956229387
INFO:root:current train perplexity2.913909673690796
INFO:root:current mean train loss 1356.6927960360065
INFO:root:current train perplexity2.9143850803375244
INFO:root:current mean train loss 1357.5217271237173
INFO:root:current train perplexity2.9156534671783447
INFO:root:current mean train loss 1357.6078323314878
INFO:root:current train perplexity2.9168341159820557
INFO:root:current mean train loss 1357.7548325225298
INFO:root:current train perplexity2.9177281856536865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.18s/it]
INFO:root:final mean train loss: 1357.7020789380633
INFO:root:final train perplexity: 2.917612075805664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 2218.2065213250776
INFO:root:eval perplexity: 6.01318883895874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.21s/it]
INFO:root:eval mean loss: 2770.4291754107103
INFO:root:eval perplexity: 9.638189315795898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [20:21:56<15:00:55, 643.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1365.088543959067
INFO:root:current train perplexity2.902296304702759
INFO:root:current mean train loss 1350.1845096342745
INFO:root:current train perplexity2.8935294151306152
INFO:root:current mean train loss 1353.0101818352168
INFO:root:current train perplexity2.9001219272613525
INFO:root:current mean train loss 1351.5523974477762
INFO:root:current train perplexity2.9001007080078125
INFO:root:current mean train loss 1351.089728418176
INFO:root:current train perplexity2.896573305130005
INFO:root:current mean train loss 1350.5256020567672
INFO:root:current train perplexity2.8970813751220703
INFO:root:current mean train loss 1350.5102560893256
INFO:root:current train perplexity2.9000799655914307
INFO:root:current mean train loss 1351.523125278656
INFO:root:current train perplexity2.9006478786468506
INFO:root:current mean train loss 1353.1291390385063
INFO:root:current train perplexity2.902970552444458
INFO:root:current mean train loss 1351.9791689714614
INFO:root:current train perplexity2.9020140171051025
INFO:root:current mean train loss 1351.9003910809115
INFO:root:current train perplexity2.901318073272705
INFO:root:current mean train loss 1351.473955761969
INFO:root:current train perplexity2.9029033184051514
INFO:root:current mean train loss 1351.2276474947446
INFO:root:current train perplexity2.9031994342803955
INFO:root:current mean train loss 1351.8668869986836
INFO:root:current train perplexity2.904003381729126
INFO:root:current mean train loss 1352.2899837117873
INFO:root:current train perplexity2.905651569366455
INFO:root:current mean train loss 1352.5116877467824
INFO:root:current train perplexity2.907437324523926
INFO:root:current mean train loss 1352.5372319566782
INFO:root:current train perplexity2.907463788986206
INFO:root:current mean train loss 1353.1359242935223
INFO:root:current train perplexity2.908109426498413
INFO:root:current mean train loss 1353.4830869657353
INFO:root:current train perplexity2.907703161239624
INFO:root:current mean train loss 1354.1960309249746
INFO:root:current train perplexity2.908810615539551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.57s/it]
INFO:root:final mean train loss: 1353.8871505514155
INFO:root:final train perplexity: 2.908846855163574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 2221.9623430400875
INFO:root:eval perplexity: 6.0314812660217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2773.442141701989
INFO:root:eval perplexity: 9.661967277526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [20:32:28<14:45:31, 640.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1341.2548731023614
INFO:root:current train perplexity2.863726854324341
INFO:root:current mean train loss 1346.610524279006
INFO:root:current train perplexity2.870924234390259
INFO:root:current mean train loss 1345.506259918213
INFO:root:current train perplexity2.874652624130249
INFO:root:current mean train loss 1347.9421572341132
INFO:root:current train perplexity2.8740248680114746
INFO:root:current mean train loss 1346.5731288722304
INFO:root:current train perplexity2.8795969486236572
INFO:root:current mean train loss 1346.7190535149607
INFO:root:current train perplexity2.8792693614959717
INFO:root:current mean train loss 1348.2748570996662
INFO:root:current train perplexity2.8826568126678467
INFO:root:current mean train loss 1347.3593709722993
INFO:root:current train perplexity2.8844752311706543
INFO:root:current mean train loss 1347.7754215549778
INFO:root:current train perplexity2.886934518814087
INFO:root:current mean train loss 1347.0854835664695
INFO:root:current train perplexity2.8878862857818604
INFO:root:current mean train loss 1348.914847430061
INFO:root:current train perplexity2.8900649547576904
INFO:root:current mean train loss 1348.7076086179175
INFO:root:current train perplexity2.89094614982605
INFO:root:current mean train loss 1349.494571282997
INFO:root:current train perplexity2.893864631652832
INFO:root:current mean train loss 1349.9173659618718
INFO:root:current train perplexity2.8939929008483887
INFO:root:current mean train loss 1350.3569259643555
INFO:root:current train perplexity2.8944239616394043
INFO:root:current mean train loss 1350.3190921812275
INFO:root:current train perplexity2.8971245288848877
INFO:root:current mean train loss 1351.5429501646504
INFO:root:current train perplexity2.899427890777588
INFO:root:current mean train loss 1351.8767053659597
INFO:root:current train perplexity2.9005584716796875
INFO:root:current mean train loss 1351.8544976832502
INFO:root:current train perplexity2.9015958309173584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.00s/it]
INFO:root:final mean train loss: 1351.6071577278942
INFO:root:final train perplexity: 2.9036214351654053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2223.2446457883143
INFO:root:eval perplexity: 6.037740230560303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2775.1008547519114
INFO:root:eval perplexity: 9.675081253051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [20:43:06<14:34:14, 639.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1298.6303955078124
INFO:root:current train perplexity2.803830146789551
INFO:root:current mean train loss 1338.2989653087798
INFO:root:current train perplexity2.8699214458465576
INFO:root:current mean train loss 1334.7725359660824
INFO:root:current train perplexity2.8686792850494385
INFO:root:current mean train loss 1340.0525110463627
INFO:root:current train perplexity2.8709006309509277
INFO:root:current mean train loss 1341.1385621624229
INFO:root:current train perplexity2.8728621006011963
INFO:root:current mean train loss 1343.0423127127167
INFO:root:current train perplexity2.8737869262695312
INFO:root:current mean train loss 1343.4170674473787
INFO:root:current train perplexity2.8796088695526123
INFO:root:current mean train loss 1343.5377507203013
INFO:root:current train perplexity2.884842872619629
INFO:root:current mean train loss 1344.0204215292604
INFO:root:current train perplexity2.887216091156006
INFO:root:current mean train loss 1345.1961888434478
INFO:root:current train perplexity2.8890249729156494
INFO:root:current mean train loss 1344.7384001622745
INFO:root:current train perplexity2.8896262645721436
INFO:root:current mean train loss 1346.1547000936794
INFO:root:current train perplexity2.891906261444092
INFO:root:current mean train loss 1346.3746164662214
INFO:root:current train perplexity2.8925094604492188
INFO:root:current mean train loss 1347.3282524956596
INFO:root:current train perplexity2.8938839435577393
INFO:root:current mean train loss 1347.7246644586855
INFO:root:current train perplexity2.894648313522339
INFO:root:current mean train loss 1348.5635847630294
INFO:root:current train perplexity2.8959221839904785
INFO:root:current mean train loss 1348.4002490082262
INFO:root:current train perplexity2.896122455596924
INFO:root:current mean train loss 1348.3143982828537
INFO:root:current train perplexity2.8957481384277344
INFO:root:current mean train loss 1348.9843174477364
INFO:root:current train perplexity2.8959577083587646
INFO:root:current mean train loss 1349.118794022207
INFO:root:current train perplexity2.8968288898468018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.33s/it]
INFO:root:final mean train loss: 1348.7778209815167
INFO:root:final train perplexity: 2.8971495628356934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 2226.3377075195312
INFO:root:eval perplexity: 6.052862167358398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2778.648124099623
INFO:root:eval perplexity: 9.703190803527832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [20:53:50<14:25:01, 640.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1335.1287619850852
INFO:root:current train perplexity2.8502912521362305
INFO:root:current mean train loss 1329.8595991290983
INFO:root:current train perplexity2.862830638885498
INFO:root:current mean train loss 1332.064511960691
INFO:root:current train perplexity2.8569324016571045
INFO:root:current mean train loss 1334.1642801036005
INFO:root:current train perplexity2.8626928329467773
INFO:root:current mean train loss 1335.1774118432502
INFO:root:current train perplexity2.863434076309204
INFO:root:current mean train loss 1336.6414832338062
INFO:root:current train perplexity2.8683691024780273
INFO:root:current mean train loss 1336.1578033545393
INFO:root:current train perplexity2.868884325027466
INFO:root:current mean train loss 1336.5598379541962
INFO:root:current train perplexity2.869858503341675
INFO:root:current mean train loss 1338.4695185083542
INFO:root:current train perplexity2.8704376220703125
INFO:root:current mean train loss 1339.780774826083
INFO:root:current train perplexity2.8737144470214844
INFO:root:current mean train loss 1340.1554129464287
INFO:root:current train perplexity2.8745195865631104
INFO:root:current mean train loss 1341.068191501121
INFO:root:current train perplexity2.876466989517212
INFO:root:current mean train loss 1341.376258363115
INFO:root:current train perplexity2.87908935546875
INFO:root:current mean train loss 1341.3738665559108
INFO:root:current train perplexity2.8809666633605957
INFO:root:current mean train loss 1341.848403694593
INFO:root:current train perplexity2.8832662105560303
INFO:root:current mean train loss 1343.3873347960382
INFO:root:current train perplexity2.885404348373413
INFO:root:current mean train loss 1344.165105591573
INFO:root:current train perplexity2.886773109436035
INFO:root:current mean train loss 1344.249378589803
INFO:root:current train perplexity2.8877787590026855
INFO:root:current mean train loss 1345.1017929730378
INFO:root:current train perplexity2.888371229171753
INFO:root:current mean train loss 1345.1539444461946
INFO:root:current train perplexity2.888594150543213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.93s/it]
INFO:root:final mean train loss: 1345.22869251307
INFO:root:final train perplexity: 2.889051675796509
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.48s/it]
INFO:root:eval mean loss: 2227.664574156416
INFO:root:eval perplexity: 6.059360504150391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2781.3165179313496
INFO:root:eval perplexity: 9.724388122558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [21:04:32<14:15:06, 641.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1330.7820825821314
INFO:root:current train perplexity2.8386569023132324
INFO:root:current mean train loss 1333.2217701424797
INFO:root:current train perplexity2.8503031730651855
INFO:root:current mean train loss 1333.240886608427
INFO:root:current train perplexity2.860562324523926
INFO:root:current mean train loss 1329.91104639104
INFO:root:current train perplexity2.866547107696533
INFO:root:current mean train loss 1330.3093901267084
INFO:root:current train perplexity2.8616135120391846
INFO:root:current mean train loss 1332.893927466228
INFO:root:current train perplexity2.864206552505493
INFO:root:current mean train loss 1333.7576529871503
INFO:root:current train perplexity2.8634753227233887
INFO:root:current mean train loss 1334.140261266809
INFO:root:current train perplexity2.8674638271331787
INFO:root:current mean train loss 1335.768945196104
INFO:root:current train perplexity2.866577625274658
INFO:root:current mean train loss 1336.4482389374916
INFO:root:current train perplexity2.8678531646728516
INFO:root:current mean train loss 1337.4066532197426
INFO:root:current train perplexity2.87020206451416
INFO:root:current mean train loss 1338.419038231693
INFO:root:current train perplexity2.8718059062957764
INFO:root:current mean train loss 1338.4874035063244
INFO:root:current train perplexity2.8723700046539307
INFO:root:current mean train loss 1339.2991441950323
INFO:root:current train perplexity2.8738465309143066
INFO:root:current mean train loss 1339.5327372388595
INFO:root:current train perplexity2.875507354736328
INFO:root:current mean train loss 1341.0070518409377
INFO:root:current train perplexity2.8776817321777344
INFO:root:current mean train loss 1341.950418152265
INFO:root:current train perplexity2.880096435546875
INFO:root:current mean train loss 1342.4571298749506
INFO:root:current train perplexity2.8809714317321777
INFO:root:current mean train loss 1342.6615582331813
INFO:root:current train perplexity2.8824055194854736
INFO:root:current mean train loss 1343.2116250347513
INFO:root:current train perplexity2.8835973739624023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.71s/it]
INFO:root:final mean train loss: 1342.9868217926103
INFO:root:final train perplexity: 2.8839480876922607
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2231.0012003580728
INFO:root:eval perplexity: 6.075732707977295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2785.836197224069
INFO:root:eval perplexity: 9.760397911071777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [21:15:12<14:03:37, 640.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1329.143290928432
INFO:root:current train perplexity2.8502564430236816
INFO:root:current mean train loss 1331.1399723933293
INFO:root:current train perplexity2.856458902359009
INFO:root:current mean train loss 1332.1784977912903
INFO:root:current train perplexity2.8569014072418213
INFO:root:current mean train loss 1331.6603129526202
INFO:root:current train perplexity2.859595537185669
INFO:root:current mean train loss 1334.7333668491297
INFO:root:current train perplexity2.85825514793396
INFO:root:current mean train loss 1336.773350118733
INFO:root:current train perplexity2.859243392944336
INFO:root:current mean train loss 1337.7998314834222
INFO:root:current train perplexity2.860139846801758
INFO:root:current mean train loss 1336.167251829117
INFO:root:current train perplexity2.8619658946990967
INFO:root:current mean train loss 1336.2657848607714
INFO:root:current train perplexity2.8648602962493896
INFO:root:current mean train loss 1336.7564512117137
INFO:root:current train perplexity2.868788003921509
INFO:root:current mean train loss 1336.6127127445106
INFO:root:current train perplexity2.8688108921051025
INFO:root:current mean train loss 1335.8656588755678
INFO:root:current train perplexity2.869110584259033
INFO:root:current mean train loss 1335.5885842681691
INFO:root:current train perplexity2.869391918182373
INFO:root:current mean train loss 1336.6823472104593
INFO:root:current train perplexity2.870419979095459
INFO:root:current mean train loss 1336.767946934962
INFO:root:current train perplexity2.8713438510894775
INFO:root:current mean train loss 1337.8143611800087
INFO:root:current train perplexity2.872313976287842
INFO:root:current mean train loss 1338.0000229987545
INFO:root:current train perplexity2.8725697994232178
INFO:root:current mean train loss 1338.5428707322662
INFO:root:current train perplexity2.8741252422332764
INFO:root:current mean train loss 1339.37894821167
INFO:root:current train perplexity2.87480092048645
INFO:root:current mean train loss 1339.846016913104
INFO:root:current train perplexity2.8761022090911865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.42s/it]
INFO:root:final mean train loss: 1339.6849878323662
INFO:root:final train perplexity: 2.8764476776123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2234.0578617609985
INFO:root:eval perplexity: 6.0907721519470215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it]
INFO:root:eval mean loss: 2791.2858098889074
INFO:root:eval perplexity: 9.803999900817871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [21:25:48<13:51:14, 639.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1327.6782627889554
INFO:root:current train perplexity2.8667378425598145
INFO:root:current mean train loss 1328.2715161273934
INFO:root:current train perplexity2.8582072257995605
INFO:root:current mean train loss 1331.4531773158483
INFO:root:current train perplexity2.856757164001465
INFO:root:current mean train loss 1331.605915795702
INFO:root:current train perplexity2.8551180362701416
INFO:root:current mean train loss 1329.4939940373943
INFO:root:current train perplexity2.8567419052124023
INFO:root:current mean train loss 1330.0766546172829
INFO:root:current train perplexity2.858825206756592
INFO:root:current mean train loss 1330.525842811165
INFO:root:current train perplexity2.8602254390716553
INFO:root:current mean train loss 1332.0981607967638
INFO:root:current train perplexity2.861133337020874
INFO:root:current mean train loss 1333.876745199966
INFO:root:current train perplexity2.861900806427002
INFO:root:current mean train loss 1334.8891934025323
INFO:root:current train perplexity2.861706256866455
INFO:root:current mean train loss 1335.7345760235248
INFO:root:current train perplexity2.8630967140197754
INFO:root:current mean train loss 1336.7682839057838
INFO:root:current train perplexity2.865846633911133
INFO:root:current mean train loss 1337.7096251242758
INFO:root:current train perplexity2.8664162158966064
INFO:root:current mean train loss 1337.2499195385049
INFO:root:current train perplexity2.867213249206543
INFO:root:current mean train loss 1336.8963179682196
INFO:root:current train perplexity2.8664040565490723
INFO:root:current mean train loss 1337.0035026341734
INFO:root:current train perplexity2.866870641708374
INFO:root:current mean train loss 1337.7867641049947
INFO:root:current train perplexity2.867786407470703
INFO:root:current mean train loss 1338.2114036805335
INFO:root:current train perplexity2.8688912391662598
INFO:root:current mean train loss 1337.6025184024418
INFO:root:current train perplexity2.869540214538574
INFO:root:current mean train loss 1337.7257612782328
INFO:root:current train perplexity2.8708860874176025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.11s/it]
INFO:root:final mean train loss: 1337.3197911003294
INFO:root:final train perplexity: 2.8710873126983643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.88s/it]
INFO:root:eval mean loss: 2235.606109835577
INFO:root:eval perplexity: 6.098404407501221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2791.4971568871897
INFO:root:eval perplexity: 9.805691719055176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [21:36:19<13:37:21, 636.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1322.7948215060765
INFO:root:current train perplexity2.853489398956299
INFO:root:current mean train loss 1321.1393888774671
INFO:root:current train perplexity2.8433139324188232
INFO:root:current mean train loss 1327.3766668911637
INFO:root:current train perplexity2.850733518600464
INFO:root:current mean train loss 1329.8597753280249
INFO:root:current train perplexity2.853480339050293
INFO:root:current mean train loss 1330.135966398278
INFO:root:current train perplexity2.854914665222168
INFO:root:current mean train loss 1330.2312015856726
INFO:root:current train perplexity2.854654312133789
INFO:root:current mean train loss 1329.5418096127717
INFO:root:current train perplexity2.855455160140991
INFO:root:current mean train loss 1330.436171596865
INFO:root:current train perplexity2.856518268585205
INFO:root:current mean train loss 1330.9397971163976
INFO:root:current train perplexity2.857379913330078
INFO:root:current mean train loss 1330.773771775371
INFO:root:current train perplexity2.858757734298706
INFO:root:current mean train loss 1331.2818088356507
INFO:root:current train perplexity2.8588309288024902
INFO:root:current mean train loss 1331.363978999803
INFO:root:current train perplexity2.8605692386627197
INFO:root:current mean train loss 1330.8181043521379
INFO:root:current train perplexity2.8601152896881104
INFO:root:current mean train loss 1331.3206447244547
INFO:root:current train perplexity2.8601160049438477
INFO:root:current mean train loss 1332.373236862285
INFO:root:current train perplexity2.860513210296631
INFO:root:current mean train loss 1332.4099560239779
INFO:root:current train perplexity2.860400676727295
INFO:root:current mean train loss 1332.4449688973511
INFO:root:current train perplexity2.8607590198516846
INFO:root:current mean train loss 1333.4213932655377
INFO:root:current train perplexity2.8616907596588135
INFO:root:current mean train loss 1334.2204097041376
INFO:root:current train perplexity2.8638908863067627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.57s/it]
INFO:root:final mean train loss: 1334.6298471086263
INFO:root:final train perplexity: 2.8650026321411133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2236.9471937680073
INFO:root:eval perplexity: 6.1050214767456055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 2792.530372998393
INFO:root:eval perplexity: 9.813982963562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [21:46:45<13:22:45, 633.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1332.9846888950892
INFO:root:current train perplexity2.7806248664855957
INFO:root:current mean train loss 1327.3333922769423
INFO:root:current train perplexity2.829953908920288
INFO:root:current mean train loss 1330.9960277022947
INFO:root:current train perplexity2.842034101486206
INFO:root:current mean train loss 1328.0386799865125
INFO:root:current train perplexity2.842561721801758
INFO:root:current mean train loss 1323.9498509962377
INFO:root:current train perplexity2.8437132835388184
INFO:root:current mean train loss 1326.3274433805627
INFO:root:current train perplexity2.847437620162964
INFO:root:current mean train loss 1326.5741093492586
INFO:root:current train perplexity2.846196174621582
INFO:root:current mean train loss 1327.1595025608867
INFO:root:current train perplexity2.8447341918945312
INFO:root:current mean train loss 1326.5639315655978
INFO:root:current train perplexity2.8432693481445312
INFO:root:current mean train loss 1327.2392684448646
INFO:root:current train perplexity2.8455352783203125
INFO:root:current mean train loss 1326.4913040358117
INFO:root:current train perplexity2.8462135791778564
INFO:root:current mean train loss 1326.9818150521187
INFO:root:current train perplexity2.8481504917144775
INFO:root:current mean train loss 1327.350680296739
INFO:root:current train perplexity2.848088026046753
INFO:root:current mean train loss 1327.8979957306212
INFO:root:current train perplexity2.849317789077759
INFO:root:current mean train loss 1328.2112217234142
INFO:root:current train perplexity2.8504550457000732
INFO:root:current mean train loss 1329.433730400708
INFO:root:current train perplexity2.8517684936523438
INFO:root:current mean train loss 1329.2860446970287
INFO:root:current train perplexity2.85266375541687
INFO:root:current mean train loss 1330.020853356583
INFO:root:current train perplexity2.854224920272827
INFO:root:current mean train loss 1330.6660397418243
INFO:root:current train perplexity2.856015682220459
INFO:root:current mean train loss 1331.2026262848428
INFO:root:current train perplexity2.857231378555298

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.25s/it]
INFO:root:final mean train loss: 1331.2984869991117
INFO:root:final train perplexity: 2.857485771179199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2242.2261703166555
INFO:root:eval perplexity: 6.13114070892334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2800.7002766927085
INFO:root:eval perplexity: 9.87977409362793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [21:57:20<13:12:19, 633.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1311.6544494628906
INFO:root:current train perplexity2.8255252838134766
INFO:root:current mean train loss 1319.7662786668348
INFO:root:current train perplexity2.8362877368927
INFO:root:current mean train loss 1320.1535715375628
INFO:root:current train perplexity2.8249399662017822
INFO:root:current mean train loss 1321.6768373089071
INFO:root:current train perplexity2.8320233821868896
INFO:root:current mean train loss 1324.5994729096035
INFO:root:current train perplexity2.8347415924072266
INFO:root:current mean train loss 1323.176974929926
INFO:root:current train perplexity2.833519458770752
INFO:root:current mean train loss 1323.6710784129607
INFO:root:current train perplexity2.837128162384033
INFO:root:current mean train loss 1323.9741662799984
INFO:root:current train perplexity2.8381481170654297
INFO:root:current mean train loss 1323.4076351425024
INFO:root:current train perplexity2.8412880897521973
INFO:root:current mean train loss 1322.8077670010653
INFO:root:current train perplexity2.8420166969299316
INFO:root:current mean train loss 1323.8412932157516
INFO:root:current train perplexity2.8441107273101807
INFO:root:current mean train loss 1324.0331726074219
INFO:root:current train perplexity2.8442344665527344
INFO:root:current mean train loss 1325.6953064164304
INFO:root:current train perplexity2.8456785678863525
INFO:root:current mean train loss 1325.8499612030305
INFO:root:current train perplexity2.845308303833008
INFO:root:current mean train loss 1326.1654727378589
INFO:root:current train perplexity2.846569061279297
INFO:root:current mean train loss 1326.8455891446492
INFO:root:current train perplexity2.847684621810913
INFO:root:current mean train loss 1327.452334775126
INFO:root:current train perplexity2.8480660915374756
INFO:root:current mean train loss 1328.1291531520765
INFO:root:current train perplexity2.849684238433838
INFO:root:current mean train loss 1328.5287184464305
INFO:root:current train perplexity2.8505213260650635
INFO:root:current mean train loss 1328.918322398608
INFO:root:current train perplexity2.8509774208068848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.45s/it]
INFO:root:final mean train loss: 1328.8145517107819
INFO:root:final train perplexity: 2.851893186569214
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2244.8408016989415
INFO:root:eval perplexity: 6.144119739532471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2802.716777395695
INFO:root:eval perplexity: 9.896079063415527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [22:07:47<12:59:25, 631.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1314.1790116472941
INFO:root:current train perplexity2.8246266841888428
INFO:root:current mean train loss 1319.4183124515182
INFO:root:current train perplexity2.824944257736206
INFO:root:current mean train loss 1318.6163927766793
INFO:root:current train perplexity2.824260711669922
INFO:root:current mean train loss 1319.160225339649
INFO:root:current train perplexity2.824671745300293
INFO:root:current mean train loss 1321.3986492546237
INFO:root:current train perplexity2.8252854347229004
INFO:root:current mean train loss 1321.4414538596782
INFO:root:current train perplexity2.8234498500823975
INFO:root:current mean train loss 1321.6705802167633
INFO:root:current train perplexity2.823744297027588
INFO:root:current mean train loss 1320.8314993133752
INFO:root:current train perplexity2.8239829540252686
INFO:root:current mean train loss 1320.979246595385
INFO:root:current train perplexity2.8250584602355957
INFO:root:current mean train loss 1321.691457490992
INFO:root:current train perplexity2.8278586864471436
INFO:root:current mean train loss 1321.9338312066598
INFO:root:current train perplexity2.829859733581543
INFO:root:current mean train loss 1322.529749423135
INFO:root:current train perplexity2.8319826126098633
INFO:root:current mean train loss 1322.827009841956
INFO:root:current train perplexity2.8343544006347656
INFO:root:current mean train loss 1323.671441518398
INFO:root:current train perplexity2.8363516330718994
INFO:root:current mean train loss 1324.2171591891752
INFO:root:current train perplexity2.8373749256134033
INFO:root:current mean train loss 1324.944242305372
INFO:root:current train perplexity2.83937406539917
INFO:root:current mean train loss 1325.2340839950868
INFO:root:current train perplexity2.8418235778808594
INFO:root:current mean train loss 1325.8882743927475
INFO:root:current train perplexity2.8430068492889404
INFO:root:current mean train loss 1326.012454089362
INFO:root:current train perplexity2.8438045978546143
INFO:root:current mean train loss 1326.4364058324077
INFO:root:current train perplexity2.8450779914855957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.84s/it]
INFO:root:final mean train loss: 1325.985049649314
INFO:root:final train perplexity: 2.845536708831787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2246.5835467399434
INFO:root:eval perplexity: 6.152785301208496
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.25s/it]
INFO:root:eval mean loss: 2805.4040756766676
INFO:root:eval perplexity: 9.917856216430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [22:18:20<12:49:19, 632.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1299.7942546976024
INFO:root:current train perplexity2.805304765701294
INFO:root:current mean train loss 1305.4164104220233
INFO:root:current train perplexity2.820192575454712
INFO:root:current mean train loss 1310.5377604166667
INFO:root:current train perplexity2.826751232147217
INFO:root:current mean train loss 1312.247790459148
INFO:root:current train perplexity2.8267650604248047
INFO:root:current mean train loss 1313.536577382983
INFO:root:current train perplexity2.824707269668579
INFO:root:current mean train loss 1315.8214588233648
INFO:root:current train perplexity2.825119733810425
INFO:root:current mean train loss 1316.965269140922
INFO:root:current train perplexity2.827043294906616
INFO:root:current mean train loss 1318.1392951099729
INFO:root:current train perplexity2.829347848892212
INFO:root:current mean train loss 1319.0427149348047
INFO:root:current train perplexity2.8287036418914795
INFO:root:current mean train loss 1319.3146819749804
INFO:root:current train perplexity2.8294756412506104
INFO:root:current mean train loss 1320.2475456713728
INFO:root:current train perplexity2.829979658126831
INFO:root:current mean train loss 1320.2489320428879
INFO:root:current train perplexity2.8310546875
INFO:root:current mean train loss 1320.6953822683265
INFO:root:current train perplexity2.832477569580078
INFO:root:current mean train loss 1320.9857221780364
INFO:root:current train perplexity2.8331782817840576
INFO:root:current mean train loss 1321.1592470019932
INFO:root:current train perplexity2.8334531784057617
INFO:root:current mean train loss 1321.8685909951912
INFO:root:current train perplexity2.833635091781616
INFO:root:current mean train loss 1322.2919703208638
INFO:root:current train perplexity2.834944725036621
INFO:root:current mean train loss 1322.8173049735806
INFO:root:current train perplexity2.835808038711548
INFO:root:current mean train loss 1323.2847359680898
INFO:root:current train perplexity2.836963415145874
INFO:root:current mean train loss 1323.4477418114386
INFO:root:current train perplexity2.838495969772339

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.60s/it]
INFO:root:final mean train loss: 1323.202256503276
INFO:root:final train perplexity: 2.8392982482910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2248.676421902704
INFO:root:eval perplexity: 6.1632080078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2808.1226979790003
INFO:root:eval perplexity: 9.93993091583252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [22:28:45<12:36:13, 630.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1313.1877262369792
INFO:root:current train perplexity2.8269217014312744
INFO:root:current mean train loss 1314.22869140625
INFO:root:current train perplexity2.81197190284729
INFO:root:current mean train loss 1314.8714821555398
INFO:root:current train perplexity2.8201396465301514
INFO:root:current mean train loss 1315.83588671875
INFO:root:current train perplexity2.822154998779297
INFO:root:current mean train loss 1314.012503854852
INFO:root:current train perplexity2.8215208053588867
INFO:root:current mean train loss 1314.9708481233017
INFO:root:current train perplexity2.8230977058410645
INFO:root:current mean train loss 1314.6459572120948
INFO:root:current train perplexity2.82139253616333
INFO:root:current mean train loss 1315.9167784463207
INFO:root:current train perplexity2.8228440284729004
INFO:root:current mean train loss 1317.3455562220981
INFO:root:current train perplexity2.8246052265167236
INFO:root:current mean train loss 1317.131036283053
INFO:root:current train perplexity2.8257381916046143
INFO:root:current mean train loss 1317.9880984284157
INFO:root:current train perplexity2.8265435695648193
INFO:root:current mean train loss 1318.1115781873339
INFO:root:current train perplexity2.82627272605896
INFO:root:current mean train loss 1317.8332927389706
INFO:root:current train perplexity2.8265795707702637
INFO:root:current mean train loss 1318.2463290127841
INFO:root:current train perplexity2.8285839557647705
INFO:root:current mean train loss 1319.1459138307732
INFO:root:current train perplexity2.8293237686157227
INFO:root:current mean train loss 1319.1374150545635
INFO:root:current train perplexity2.8309051990509033
INFO:root:current mean train loss 1319.4234541161381
INFO:root:current train perplexity2.831641912460327
INFO:root:current mean train loss 1320.2601675973813
INFO:root:current train perplexity2.8324787616729736
INFO:root:current mean train loss 1320.963000065104
INFO:root:current train perplexity2.833341360092163
INFO:root:current mean train loss 1320.753806059632
INFO:root:current train perplexity2.833437919616699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.10s/it]
INFO:root:final mean train loss: 1320.5717413320845
INFO:root:final train perplexity: 2.833413600921631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2252.030246166473
INFO:root:eval perplexity: 6.179947853088379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 2815.724161350981
INFO:root:eval perplexity: 10.001914978027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [22:39:21<12:27:40, 631.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1309.6472274116848
INFO:root:current train perplexity2.791158437728882
INFO:root:current mean train loss 1307.8325017293294
INFO:root:current train perplexity2.807551145553589
INFO:root:current mean train loss 1305.2030259223834
INFO:root:current train perplexity2.8116092681884766
INFO:root:current mean train loss 1308.7624197200853
INFO:root:current train perplexity2.816840887069702
INFO:root:current mean train loss 1308.7300464661141
INFO:root:current train perplexity2.8136370182037354
INFO:root:current mean train loss 1310.665859531712
INFO:root:current train perplexity2.8163063526153564
INFO:root:current mean train loss 1311.8392356916659
INFO:root:current train perplexity2.81955623626709
INFO:root:current mean train loss 1311.8010765615136
INFO:root:current train perplexity2.820920467376709
INFO:root:current mean train loss 1311.8110103863771
INFO:root:current train perplexity2.8213906288146973
INFO:root:current mean train loss 1312.5653143851987
INFO:root:current train perplexity2.8217756748199463
INFO:root:current mean train loss 1313.4974644699375
INFO:root:current train perplexity2.82387113571167
INFO:root:current mean train loss 1313.5454961789535
INFO:root:current train perplexity2.823704242706299
INFO:root:current mean train loss 1314.2961671433582
INFO:root:current train perplexity2.8237617015838623
INFO:root:current mean train loss 1314.848161193146
INFO:root:current train perplexity2.823164939880371
INFO:root:current mean train loss 1315.629805086765
INFO:root:current train perplexity2.8234951496124268
INFO:root:current mean train loss 1316.6624024357627
INFO:root:current train perplexity2.8249189853668213
INFO:root:current mean train loss 1317.5389796768802
INFO:root:current train perplexity2.824723720550537
INFO:root:current mean train loss 1317.835673740932
INFO:root:current train perplexity2.8258705139160156
INFO:root:current mean train loss 1318.120680762648
INFO:root:current train perplexity2.8271636962890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.20s/it]
INFO:root:final mean train loss: 1317.9256012532305
INFO:root:final train perplexity: 2.8275070190429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2253.610028206034
INFO:root:eval perplexity: 6.187849521636963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2815.53769678427
INFO:root:eval perplexity: 10.000389099121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [22:49:50<12:15:59, 630.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1298.055636935764
INFO:root:current train perplexity2.7576260566711426
INFO:root:current mean train loss 1309.3119669223051
INFO:root:current train perplexity2.806647300720215
INFO:root:current mean train loss 1308.493801865281
INFO:root:current train perplexity2.8154726028442383
INFO:root:current mean train loss 1308.3839229842993
INFO:root:current train perplexity2.815150737762451
INFO:root:current mean train loss 1309.791660896432
INFO:root:current train perplexity2.8132848739624023
INFO:root:current mean train loss 1311.5634307561547
INFO:root:current train perplexity2.8166539669036865
INFO:root:current mean train loss 1311.385963076637
INFO:root:current train perplexity2.8157942295074463
INFO:root:current mean train loss 1311.3953903908455
INFO:root:current train perplexity2.817286968231201
INFO:root:current mean train loss 1311.6628953629577
INFO:root:current train perplexity2.8187549114227295
INFO:root:current mean train loss 1311.2957846932154
INFO:root:current train perplexity2.818859815597534
INFO:root:current mean train loss 1311.5251474522267
INFO:root:current train perplexity2.8194315433502197
INFO:root:current mean train loss 1312.1887969833112
INFO:root:current train perplexity2.818739891052246
INFO:root:current mean train loss 1312.363806182634
INFO:root:current train perplexity2.8195695877075195
INFO:root:current mean train loss 1313.6332735508977
INFO:root:current train perplexity2.8207273483276367
INFO:root:current mean train loss 1313.7653641386012
INFO:root:current train perplexity2.821598768234253
INFO:root:current mean train loss 1314.7014614785246
INFO:root:current train perplexity2.82169771194458
INFO:root:current mean train loss 1314.295533212836
INFO:root:current train perplexity2.8215718269348145
INFO:root:current mean train loss 1314.752191194252
INFO:root:current train perplexity2.8217859268188477
INFO:root:current mean train loss 1314.93074524027
INFO:root:current train perplexity2.821512460708618
INFO:root:current mean train loss 1315.562269799306
INFO:root:current train perplexity2.8215770721435547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.53s/it]
INFO:root:final mean train loss: 1315.554815295244
INFO:root:final train perplexity: 2.8222250938415527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2257.7719981957835
INFO:root:eval perplexity: 6.208713054656982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2822.3919586830953
INFO:root:eval perplexity: 10.056605339050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [23:00:12<12:02:36, 628.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.8506845327524
INFO:root:current train perplexity2.828230619430542
INFO:root:current mean train loss 1302.6424008324034
INFO:root:current train perplexity2.798017740249634
INFO:root:current mean train loss 1303.3808275070865
INFO:root:current train perplexity2.797396183013916
INFO:root:current mean train loss 1305.931730118266
INFO:root:current train perplexity2.80230712890625
INFO:root:current mean train loss 1307.1203790942268
INFO:root:current train perplexity2.802602767944336
INFO:root:current mean train loss 1309.0949495844968
INFO:root:current train perplexity2.804633617401123
INFO:root:current mean train loss 1309.3278740343576
INFO:root:current train perplexity2.8063857555389404
INFO:root:current mean train loss 1309.1407946541947
INFO:root:current train perplexity2.8067219257354736
INFO:root:current mean train loss 1310.0136545841688
INFO:root:current train perplexity2.8073222637176514
INFO:root:current mean train loss 1310.948118271632
INFO:root:current train perplexity2.8095479011535645
INFO:root:current mean train loss 1311.5074021486278
INFO:root:current train perplexity2.80989670753479
INFO:root:current mean train loss 1312.1094862292546
INFO:root:current train perplexity2.811845541000366
INFO:root:current mean train loss 1312.1095716467105
INFO:root:current train perplexity2.811573028564453
INFO:root:current mean train loss 1312.352803548177
INFO:root:current train perplexity2.812215566635132
INFO:root:current mean train loss 1311.8022493466756
INFO:root:current train perplexity2.81213641166687
INFO:root:current mean train loss 1312.0830354103098
INFO:root:current train perplexity2.8129522800445557
INFO:root:current mean train loss 1312.836276909522
INFO:root:current train perplexity2.8147711753845215
INFO:root:current mean train loss 1313.197181250792
INFO:root:current train perplexity2.8167529106140137
INFO:root:current mean train loss 1313.8848003207788
INFO:root:current train perplexity2.8171634674072266
INFO:root:current mean train loss 1314.1000212830795
INFO:root:current train perplexity2.818164587020874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.38s/it]
INFO:root:final mean train loss: 1314.1454964241955
INFO:root:final train perplexity: 2.8190901279449463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.58s/it]
INFO:root:eval mean loss: 2258.426504148659
INFO:root:eval perplexity: 6.211999893188477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 2821.2088900085882
INFO:root:eval perplexity: 10.046880722045898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [23:10:37<11:51:01, 627.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1299.5520700853924
INFO:root:current train perplexity2.795929193496704
INFO:root:current mean train loss 1304.2302493648929
INFO:root:current train perplexity2.7972137928009033
INFO:root:current mean train loss 1303.8461693029835
INFO:root:current train perplexity2.7908177375793457
INFO:root:current mean train loss 1307.3209712526193
INFO:root:current train perplexity2.795743227005005
INFO:root:current mean train loss 1307.50341135546
INFO:root:current train perplexity2.7996015548706055
INFO:root:current mean train loss 1307.0510847397272
INFO:root:current train perplexity2.7978386878967285
INFO:root:current mean train loss 1307.696706911268
INFO:root:current train perplexity2.7992658615112305
INFO:root:current mean train loss 1307.2957716026665
INFO:root:current train perplexity2.7990453243255615
INFO:root:current mean train loss 1307.725014103972
INFO:root:current train perplexity2.799135446548462
INFO:root:current mean train loss 1306.9887749681038
INFO:root:current train perplexity2.800990343093872
INFO:root:current mean train loss 1307.3001573220652
INFO:root:current train perplexity2.802582025527954
INFO:root:current mean train loss 1307.916049373223
INFO:root:current train perplexity2.8040342330932617
INFO:root:current mean train loss 1308.8356941450247
INFO:root:current train perplexity2.804806709289551
INFO:root:current mean train loss 1308.5947318343378
INFO:root:current train perplexity2.805567502975464
INFO:root:current mean train loss 1309.1136121849013
INFO:root:current train perplexity2.8071305751800537
INFO:root:current mean train loss 1309.612877065148
INFO:root:current train perplexity2.808664321899414
INFO:root:current mean train loss 1310.0258416090517
INFO:root:current train perplexity2.8086230754852295
INFO:root:current mean train loss 1310.0542155368125
INFO:root:current train perplexity2.8097846508026123
INFO:root:current mean train loss 1310.546562770237
INFO:root:current train perplexity2.80983829498291
INFO:root:current mean train loss 1310.931499895458
INFO:root:current train perplexity2.811361074447632

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.16s/it]
INFO:root:final mean train loss: 1310.8084501958049
INFO:root:final train perplexity: 2.811680793762207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 2260.623456806156
INFO:root:eval perplexity: 6.223045825958252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2826.614669908023
INFO:root:eval perplexity: 10.09139633178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [23:21:05<11:40:37, 627.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1297.8257100423177
INFO:root:current train perplexity2.804985523223877
INFO:root:current mean train loss 1306.0360313415526
INFO:root:current train perplexity2.784926652908325
INFO:root:current mean train loss 1304.3721219576323
INFO:root:current train perplexity2.783365488052368
INFO:root:current mean train loss 1305.7056698269314
INFO:root:current train perplexity2.7892239093780518
INFO:root:current mean train loss 1306.6623362665591
INFO:root:current train perplexity2.792163848876953
INFO:root:current mean train loss 1306.9704659598215
INFO:root:current train perplexity2.7894632816314697
INFO:root:current mean train loss 1307.0950265595407
INFO:root:current train perplexity2.7912888526916504
INFO:root:current mean train loss 1306.392940962942
INFO:root:current train perplexity2.794722318649292
INFO:root:current mean train loss 1307.165745508948
INFO:root:current train perplexity2.7962191104888916
INFO:root:current mean train loss 1307.0446004231771
INFO:root:current train perplexity2.799053430557251
INFO:root:current mean train loss 1306.7857831846993
INFO:root:current train perplexity2.7988359928131104
INFO:root:current mean train loss 1307.1288595265355
INFO:root:current train perplexity2.8001656532287598
INFO:root:current mean train loss 1308.0848377046132
INFO:root:current train perplexity2.800952911376953
INFO:root:current mean train loss 1308.0593727560604
INFO:root:current train perplexity2.801457405090332
INFO:root:current mean train loss 1308.1885552393246
INFO:root:current train perplexity2.800773859024048
INFO:root:current mean train loss 1307.7425416604067
INFO:root:current train perplexity2.8014862537384033
INFO:root:current mean train loss 1308.1289724326996
INFO:root:current train perplexity2.8036909103393555
INFO:root:current mean train loss 1308.6414189425382
INFO:root:current train perplexity2.804598808288574
INFO:root:current mean train loss 1308.576484204364
INFO:root:current train perplexity2.8055145740509033
INFO:root:current mean train loss 1308.7655459657008
INFO:root:current train perplexity2.8059351444244385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.67s/it]
INFO:root:final mean train loss: 1308.4392431492886
INFO:root:final train perplexity: 2.806431770324707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 2263.1301498954176
INFO:root:eval perplexity: 6.2356743812561035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2827.285379179826
INFO:root:eval perplexity: 10.096933364868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [23:31:39<11:32:25, 629.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1290.433420949168
INFO:root:current train perplexity2.768446922302246
INFO:root:current mean train loss 1295.9881729729432
INFO:root:current train perplexity2.78417706489563
INFO:root:current mean train loss 1295.359121604947
INFO:root:current train perplexity2.777885675430298
INFO:root:current mean train loss 1295.890275950141
INFO:root:current train perplexity2.779869318008423
INFO:root:current mean train loss 1296.2460177439564
INFO:root:current train perplexity2.7812490463256836
INFO:root:current mean train loss 1297.0811357151078
INFO:root:current train perplexity2.7839736938476562
INFO:root:current mean train loss 1298.2524666497416
INFO:root:current train perplexity2.7857136726379395
INFO:root:current mean train loss 1299.3350715391732
INFO:root:current train perplexity2.788785934448242
INFO:root:current mean train loss 1300.5682675090864
INFO:root:current train perplexity2.7894883155822754
INFO:root:current mean train loss 1301.0214565124825
INFO:root:current train perplexity2.7885582447052
INFO:root:current mean train loss 1301.6425202067737
INFO:root:current train perplexity2.7927815914154053
INFO:root:current mean train loss 1301.4990639893201
INFO:root:current train perplexity2.793445587158203
INFO:root:current mean train loss 1301.5385935282277
INFO:root:current train perplexity2.7930383682250977
INFO:root:current mean train loss 1302.119414374546
INFO:root:current train perplexity2.7942495346069336
INFO:root:current mean train loss 1302.8951970580144
INFO:root:current train perplexity2.7958476543426514
INFO:root:current mean train loss 1303.3606655239378
INFO:root:current train perplexity2.7959654331207275
INFO:root:current mean train loss 1303.9839968513575
INFO:root:current train perplexity2.7975845336914062
INFO:root:current mean train loss 1304.8421134197383
INFO:root:current train perplexity2.7983686923980713
INFO:root:current mean train loss 1305.2929070319783
INFO:root:current train perplexity2.8002495765686035
INFO:root:current mean train loss 1305.711299512262
INFO:root:current train perplexity2.7998037338256836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.01s/it]
INFO:root:final mean train loss: 1305.4239611527082
INFO:root:final train perplexity: 2.7997660636901855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2269.2967412421044
INFO:root:eval perplexity: 6.266849994659424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2833.2894274123173
INFO:root:eval perplexity: 10.146636009216309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [23:42:06<11:21:14, 628.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1287.4316938684342
INFO:root:current train perplexity2.763958215713501
INFO:root:current mean train loss 1291.6915069265465
INFO:root:current train perplexity2.772109270095825
INFO:root:current mean train loss 1293.1850577633397
INFO:root:current train perplexity2.773988962173462
INFO:root:current mean train loss 1295.284213768044
INFO:root:current train perplexity2.7708358764648438
INFO:root:current mean train loss 1295.5208666102606
INFO:root:current train perplexity2.774564266204834
INFO:root:current mean train loss 1297.6638193869028
INFO:root:current train perplexity2.778221607208252
INFO:root:current mean train loss 1298.5705918193894
INFO:root:current train perplexity2.780526876449585
INFO:root:current mean train loss 1298.4788309476837
INFO:root:current train perplexity2.7822771072387695
INFO:root:current mean train loss 1300.1991702768894
INFO:root:current train perplexity2.785553216934204
INFO:root:current mean train loss 1300.6459529884385
INFO:root:current train perplexity2.7866275310516357
INFO:root:current mean train loss 1300.9274924660078
INFO:root:current train perplexity2.787367582321167
INFO:root:current mean train loss 1301.029307712063
INFO:root:current train perplexity2.788569688796997
INFO:root:current mean train loss 1301.1356285130591
INFO:root:current train perplexity2.788382053375244
INFO:root:current mean train loss 1301.8535300737817
INFO:root:current train perplexity2.789769172668457
INFO:root:current mean train loss 1302.067250855636
INFO:root:current train perplexity2.7901175022125244
INFO:root:current mean train loss 1302.1569345586722
INFO:root:current train perplexity2.7914350032806396
INFO:root:current mean train loss 1303.066171188985
INFO:root:current train perplexity2.792778253555298
INFO:root:current mean train loss 1303.312467475134
INFO:root:current train perplexity2.7939794063568115
INFO:root:current mean train loss 1303.4645840766689
INFO:root:current train perplexity2.794499635696411

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.81s/it]
INFO:root:final mean train loss: 1303.390868371145
INFO:root:final train perplexity: 2.7952799797058105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2267.959715931128
INFO:root:eval perplexity: 6.260077953338623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 2833.457472348044
INFO:root:eval perplexity: 10.148024559020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [23:52:34<11:10:15, 628.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1304.1501797762785
INFO:root:current train perplexity2.8008205890655518
INFO:root:current mean train loss 1294.962131809544
INFO:root:current train perplexity2.7692558765411377
INFO:root:current mean train loss 1290.582828467491
INFO:root:current train perplexity2.7741546630859375
INFO:root:current mean train loss 1292.9883314911576
INFO:root:current train perplexity2.7716658115386963
INFO:root:current mean train loss 1293.5337531839264
INFO:root:current train perplexity2.7708911895751953
INFO:root:current mean train loss 1293.6109702750427
INFO:root:current train perplexity2.7724647521972656
INFO:root:current mean train loss 1294.2195667323035
INFO:root:current train perplexity2.7752766609191895
INFO:root:current mean train loss 1295.2825419537294
INFO:root:current train perplexity2.778325319290161
INFO:root:current mean train loss 1296.098064305015
INFO:root:current train perplexity2.7809009552001953
INFO:root:current mean train loss 1297.1031041234307
INFO:root:current train perplexity2.782275676727295
INFO:root:current mean train loss 1297.2226598722646
INFO:root:current train perplexity2.7824528217315674
INFO:root:current mean train loss 1298.390137927367
INFO:root:current train perplexity2.783867835998535
INFO:root:current mean train loss 1298.421215457428
INFO:root:current train perplexity2.7836365699768066
INFO:root:current mean train loss 1299.0242161056087
INFO:root:current train perplexity2.784651517868042
INFO:root:current mean train loss 1299.9997125161954
INFO:root:current train perplexity2.787358283996582
INFO:root:current mean train loss 1299.941219145537
INFO:root:current train perplexity2.7880897521972656
INFO:root:current mean train loss 1300.249100347101
INFO:root:current train perplexity2.789060115814209
INFO:root:current mean train loss 1300.4605341186166
INFO:root:current train perplexity2.7889628410339355
INFO:root:current mean train loss 1301.7365918130522
INFO:root:current train perplexity2.7907159328460693
INFO:root:current mean train loss 1302.1260181468922
INFO:root:current train perplexity2.791445255279541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.97s/it]
INFO:root:final mean train loss: 1301.8433991171048
INFO:root:final train perplexity: 2.7918715476989746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2273.555659300892
INFO:root:eval perplexity: 6.288473129272461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2840.8483466831503
INFO:root:eval perplexity: 10.209553718566895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [24:03:00<10:59:08, 627.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1281.6145804268974
INFO:root:current train perplexity2.7400689125061035
INFO:root:current mean train loss 1284.5615968704224
INFO:root:current train perplexity2.7515292167663574
INFO:root:current mean train loss 1290.608054713199
INFO:root:current train perplexity2.7603588104248047
INFO:root:current mean train loss 1293.3991658280536
INFO:root:current train perplexity2.7656259536743164
INFO:root:current mean train loss 1291.6526095666618
INFO:root:current train perplexity2.7694008350372314
INFO:root:current mean train loss 1292.1306441335967
INFO:root:current train perplexity2.770153045654297
INFO:root:current mean train loss 1292.432842278936
INFO:root:current train perplexity2.7720513343811035
INFO:root:current mean train loss 1292.332500751202
INFO:root:current train perplexity2.7728195190429688
INFO:root:current mean train loss 1293.4959833264927
INFO:root:current train perplexity2.7750134468078613
INFO:root:current mean train loss 1294.2320902594204
INFO:root:current train perplexity2.7750978469848633
INFO:root:current mean train loss 1294.556939269782
INFO:root:current train perplexity2.7759833335876465
INFO:root:current mean train loss 1295.1990447348737
INFO:root:current train perplexity2.779527187347412
INFO:root:current mean train loss 1296.2001856701381
INFO:root:current train perplexity2.780872344970703
INFO:root:current mean train loss 1296.5468911779933
INFO:root:current train perplexity2.7826294898986816
INFO:root:current mean train loss 1296.4360996107428
INFO:root:current train perplexity2.7837371826171875
INFO:root:current mean train loss 1296.8625317318902
INFO:root:current train perplexity2.784264087677002
INFO:root:current mean train loss 1296.8835734149454
INFO:root:current train perplexity2.7841250896453857
INFO:root:current mean train loss 1297.6468317950214
INFO:root:current train perplexity2.7843267917633057
INFO:root:current mean train loss 1299.0640965968828
INFO:root:current train perplexity2.785374641418457
INFO:root:current mean train loss 1299.1952851481458
INFO:root:current train perplexity2.785560131072998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.28s/it]
INFO:root:final mean train loss: 1299.1619048779862
INFO:root:final train perplexity: 2.785973072052002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2270.9532665496176
INFO:root:eval perplexity: 6.275251865386963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2838.732293744459
INFO:root:eval perplexity: 10.191900253295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [24:13:39<10:52:02, 631.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1286.9744194878472
INFO:root:current train perplexity2.7774031162261963
INFO:root:current mean train loss 1290.6223456021014
INFO:root:current train perplexity2.7669224739074707
INFO:root:current mean train loss 1288.4282934072066
INFO:root:current train perplexity2.76135516166687
INFO:root:current mean train loss 1287.9665902400363
INFO:root:current train perplexity2.7609496116638184
INFO:root:current mean train loss 1286.6611446080583
INFO:root:current train perplexity2.7612452507019043
INFO:root:current mean train loss 1288.937508959289
INFO:root:current train perplexity2.764120578765869
INFO:root:current mean train loss 1290.3003537200218
INFO:root:current train perplexity2.765613079071045
INFO:root:current mean train loss 1290.4326260355494
INFO:root:current train perplexity2.7672019004821777
INFO:root:current mean train loss 1291.7114451391458
INFO:root:current train perplexity2.7698495388031006
INFO:root:current mean train loss 1292.039216734871
INFO:root:current train perplexity2.7702038288116455
INFO:root:current mean train loss 1292.6451866916493
INFO:root:current train perplexity2.7714056968688965
INFO:root:current mean train loss 1293.7650939674877
INFO:root:current train perplexity2.77177357673645
INFO:root:current mean train loss 1294.1398239442144
INFO:root:current train perplexity2.773954153060913
INFO:root:current mean train loss 1294.7194464814706
INFO:root:current train perplexity2.774845838546753
INFO:root:current mean train loss 1295.581314794415
INFO:root:current train perplexity2.776153802871704
INFO:root:current mean train loss 1296.1493908335863
INFO:root:current train perplexity2.7768630981445312
INFO:root:current mean train loss 1296.5163010988554
INFO:root:current train perplexity2.7785305976867676
INFO:root:current mean train loss 1296.8067128178725
INFO:root:current train perplexity2.778547763824463
INFO:root:current mean train loss 1297.2320286034892
INFO:root:current train perplexity2.7795751094818115
INFO:root:current mean train loss 1297.1354277544585
INFO:root:current train perplexity2.7809014320373535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.61s/it]
INFO:root:final mean train loss: 1296.9215030333519
INFO:root:final train perplexity: 2.781054735183716
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 2277.3709651865856
INFO:root:eval perplexity: 6.3079071044921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 2842.3040862387797
INFO:root:eval perplexity: 10.221714973449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [24:24:13<10:42:37, 632.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.1409203314013
INFO:root:current train perplexity2.7626943588256836
INFO:root:current mean train loss 1287.9653749819156
INFO:root:current train perplexity2.759443521499634
INFO:root:current mean train loss 1289.443332351801
INFO:root:current train perplexity2.757871389389038
INFO:root:current mean train loss 1291.1766431608253
INFO:root:current train perplexity2.7576284408569336
INFO:root:current mean train loss 1292.8673473539807
INFO:root:current train perplexity2.7628707885742188
INFO:root:current mean train loss 1292.3605689866688
INFO:root:current train perplexity2.7603037357330322
INFO:root:current mean train loss 1291.1439140757766
INFO:root:current train perplexity2.761733293533325
INFO:root:current mean train loss 1291.471931837988
INFO:root:current train perplexity2.7642650604248047
INFO:root:current mean train loss 1292.8349093904076
INFO:root:current train perplexity2.7653934955596924
INFO:root:current mean train loss 1293.7898498662048
INFO:root:current train perplexity2.7646737098693848
INFO:root:current mean train loss 1295.0680248885506
INFO:root:current train perplexity2.766810655593872
INFO:root:current mean train loss 1295.0036670468146
INFO:root:current train perplexity2.7688000202178955
INFO:root:current mean train loss 1294.1394776164445
INFO:root:current train perplexity2.7676503658294678
INFO:root:current mean train loss 1293.6100354523735
INFO:root:current train perplexity2.7678062915802
INFO:root:current mean train loss 1293.4244439037652
INFO:root:current train perplexity2.7681798934936523
INFO:root:current mean train loss 1293.4373518275847
INFO:root:current train perplexity2.7693262100219727
INFO:root:current mean train loss 1294.2937218107184
INFO:root:current train perplexity2.7705914974212646
INFO:root:current mean train loss 1294.607176210228
INFO:root:current train perplexity2.772211790084839
INFO:root:current mean train loss 1294.539349581578
INFO:root:current train perplexity2.7741360664367676
INFO:root:current mean train loss 1294.7706214212617
INFO:root:current train perplexity2.77516770362854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.92s/it]
INFO:root:final mean train loss: 1294.3930483388588
INFO:root:final train perplexity: 2.775514841079712
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2280.744468310201
INFO:root:eval perplexity: 6.325140476226807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2849.2679387085827
INFO:root:eval perplexity: 10.280097007751465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [24:34:41<10:30:43, 630.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.776809112935
INFO:root:current train perplexity2.7676455974578857
INFO:root:current mean train loss 1287.5372962312326
INFO:root:current train perplexity2.763371229171753
INFO:root:current mean train loss 1284.2806650250616
INFO:root:current train perplexity2.7596731185913086
INFO:root:current mean train loss 1285.1271553945417
INFO:root:current train perplexity2.75815749168396
INFO:root:current mean train loss 1287.1632587217837
INFO:root:current train perplexity2.7625436782836914
INFO:root:current mean train loss 1286.5007813343318
INFO:root:current train perplexity2.7611124515533447
INFO:root:current mean train loss 1288.165657504142
INFO:root:current train perplexity2.762620449066162
INFO:root:current mean train loss 1288.9164584628732
INFO:root:current train perplexity2.7626097202301025
INFO:root:current mean train loss 1288.93076321859
INFO:root:current train perplexity2.764798164367676
INFO:root:current mean train loss 1290.138286960746
INFO:root:current train perplexity2.7673325538635254
INFO:root:current mean train loss 1291.065272093482
INFO:root:current train perplexity2.7676022052764893
INFO:root:current mean train loss 1291.1162621883946
INFO:root:current train perplexity2.7675416469573975
INFO:root:current mean train loss 1291.3466494323873
INFO:root:current train perplexity2.7679991722106934
INFO:root:current mean train loss 1291.6096479099156
INFO:root:current train perplexity2.768008232116699
INFO:root:current mean train loss 1293.119104969574
INFO:root:current train perplexity2.769409418106079
INFO:root:current mean train loss 1293.3789871921263
INFO:root:current train perplexity2.7711870670318604
INFO:root:current mean train loss 1293.4562525155645
INFO:root:current train perplexity2.771740198135376
INFO:root:current mean train loss 1293.1192282493896
INFO:root:current train perplexity2.771566152572632
INFO:root:current mean train loss 1293.2973361906058
INFO:root:current train perplexity2.7722837924957275
INFO:root:current mean train loss 1293.4037899038537
INFO:root:current train perplexity2.772517681121826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.18s/it]
INFO:root:final mean train loss: 1293.0950731978655
INFO:root:final train perplexity: 2.7726755142211914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2279.562203914561
INFO:root:eval perplexity: 6.319096088409424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 2849.0063615082004
INFO:root:eval perplexity: 10.277896881103516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [24:45:17<10:21:57, 632.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.7130482991536
INFO:root:current train perplexity2.7519474029541016
INFO:root:current mean train loss 1282.371507294324
INFO:root:current train perplexity2.7565667629241943
INFO:root:current mean train loss 1281.4204390242294
INFO:root:current train perplexity2.749663829803467
INFO:root:current mean train loss 1283.4163818359375
INFO:root:current train perplexity2.753403425216675
INFO:root:current mean train loss 1284.9407565209174
INFO:root:current train perplexity2.7554550170898438
INFO:root:current mean train loss 1286.5887500327706
INFO:root:current train perplexity2.7561721801757812
INFO:root:current mean train loss 1285.5525684575925
INFO:root:current train perplexity2.7541158199310303
INFO:root:current mean train loss 1285.5193256013956
INFO:root:current train perplexity2.755784273147583
INFO:root:current mean train loss 1286.2905248914446
INFO:root:current train perplexity2.757481098175049
INFO:root:current mean train loss 1287.1788555589546
INFO:root:current train perplexity2.758545398712158
INFO:root:current mean train loss 1288.1658289554346
INFO:root:current train perplexity2.7596981525421143
INFO:root:current mean train loss 1287.788138603287
INFO:root:current train perplexity2.7600173950195312
INFO:root:current mean train loss 1287.8829509593822
INFO:root:current train perplexity2.7604384422302246
INFO:root:current mean train loss 1288.3861539561974
INFO:root:current train perplexity2.760305881500244
INFO:root:current mean train loss 1288.5730910683699
INFO:root:current train perplexity2.760195732116699
INFO:root:current mean train loss 1289.9165533921473
INFO:root:current train perplexity2.762641191482544
INFO:root:current mean train loss 1290.2255198640644
INFO:root:current train perplexity2.764650583267212
INFO:root:current mean train loss 1291.1167897519663
INFO:root:current train perplexity2.765423536300659
INFO:root:current mean train loss 1291.1431763081612
INFO:root:current train perplexity2.766798496246338

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.82s/it]
INFO:root:final mean train loss: 1290.559186311184
INFO:root:final train perplexity: 2.7671353816986084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2283.944881358045
INFO:root:eval perplexity: 6.341533660888672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.14s/it]
INFO:root:eval mean loss: 2854.4726913127492
INFO:root:eval perplexity: 10.32394790649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [24:55:51<10:11:35, 632.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1301.857431265024
INFO:root:current train perplexity2.726696252822876
INFO:root:current mean train loss 1296.3651900840016
INFO:root:current train perplexity2.7517950534820557
INFO:root:current mean train loss 1290.3072016899575
INFO:root:current train perplexity2.7412424087524414
INFO:root:current mean train loss 1287.7844534682008
INFO:root:current train perplexity2.742982864379883
INFO:root:current mean train loss 1287.4664566742017
INFO:root:current train perplexity2.744469404220581
INFO:root:current mean train loss 1286.463838633041
INFO:root:current train perplexity2.7458291053771973
INFO:root:current mean train loss 1286.760246936493
INFO:root:current train perplexity2.748457431793213
INFO:root:current mean train loss 1285.7247555854444
INFO:root:current train perplexity2.7511484622955322
INFO:root:current mean train loss 1286.0103468478533
INFO:root:current train perplexity2.752213954925537
INFO:root:current mean train loss 1285.7332017612353
INFO:root:current train perplexity2.752368450164795
INFO:root:current mean train loss 1285.6862055485717
INFO:root:current train perplexity2.753485918045044
INFO:root:current mean train loss 1286.0817880964664
INFO:root:current train perplexity2.754427671432495
INFO:root:current mean train loss 1286.172732712509
INFO:root:current train perplexity2.755324363708496
INFO:root:current mean train loss 1287.0080127585325
INFO:root:current train perplexity2.75653076171875
INFO:root:current mean train loss 1287.570357596039
INFO:root:current train perplexity2.757081985473633
INFO:root:current mean train loss 1288.2091635674415
INFO:root:current train perplexity2.7573726177215576
INFO:root:current mean train loss 1288.1420757674462
INFO:root:current train perplexity2.758674383163452
INFO:root:current mean train loss 1288.2911294290216
INFO:root:current train perplexity2.75950288772583
INFO:root:current mean train loss 1288.5953671454856
INFO:root:current train perplexity2.760267734527588
INFO:root:current mean train loss 1288.8130624295527
INFO:root:current train perplexity2.7615573406219482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.37s/it]
INFO:root:final mean train loss: 1288.5210378919055
INFO:root:final train perplexity: 2.762690544128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.99s/it]
INFO:root:eval mean loss: 2283.503402385306
INFO:root:eval perplexity: 6.339270114898682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2853.7034847178356
INFO:root:eval perplexity: 10.31745433807373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [25:06:26<10:01:54, 633.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1277.431974283854
INFO:root:current train perplexity2.715092897415161
INFO:root:current mean train loss 1281.1117149939903
INFO:root:current train perplexity2.7322375774383545
INFO:root:current mean train loss 1285.2997983186142
INFO:root:current train perplexity2.7320961952209473
INFO:root:current mean train loss 1283.943671209162
INFO:root:current train perplexity2.7350873947143555
INFO:root:current mean train loss 1286.1551658452943
INFO:root:current train perplexity2.7394232749938965
INFO:root:current mean train loss 1285.4846958376327
INFO:root:current train perplexity2.7443654537200928
INFO:root:current mean train loss 1285.793252999442
INFO:root:current train perplexity2.747908115386963
INFO:root:current mean train loss 1285.2205206884096
INFO:root:current train perplexity2.7495222091674805
INFO:root:current mean train loss 1285.593829125094
INFO:root:current train perplexity2.750316858291626
INFO:root:current mean train loss 1285.0596485425067
INFO:root:current train perplexity2.749856948852539
INFO:root:current mean train loss 1285.6442873464048
INFO:root:current train perplexity2.7524380683898926
INFO:root:current mean train loss 1286.9150245869055
INFO:root:current train perplexity2.754164695739746
INFO:root:current mean train loss 1286.6945249976181
INFO:root:current train perplexity2.7545199394226074
INFO:root:current mean train loss 1287.226435748796
INFO:root:current train perplexity2.755549907684326
INFO:root:current mean train loss 1287.196110737407
INFO:root:current train perplexity2.756715774536133
INFO:root:current mean train loss 1286.4283436095793
INFO:root:current train perplexity2.7566308975219727
INFO:root:current mean train loss 1286.7299453454516
INFO:root:current train perplexity2.7578184604644775
INFO:root:current mean train loss 1286.9340470330565
INFO:root:current train perplexity2.7586328983306885
INFO:root:current mean train loss 1287.071065933978
INFO:root:current train perplexity2.7586140632629395
INFO:root:current mean train loss 1287.418319148721
INFO:root:current train perplexity2.7587814331054688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.73s/it]
INFO:root:final mean train loss: 1286.8811195208098
INFO:root:final train perplexity: 2.759119987487793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.78s/it]
INFO:root:eval mean loss: 2284.168383875637
INFO:root:eval perplexity: 6.342678546905518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 2854.45628064744
INFO:root:eval perplexity: 10.323807716369629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [25:17:09<9:53:51, 636.28s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1264.2434705369017
INFO:root:current train perplexity2.7326886653900146
INFO:root:current mean train loss 1273.0824057650404
INFO:root:current train perplexity2.730449676513672
INFO:root:current mean train loss 1274.570395033369
INFO:root:current train perplexity2.7311508655548096
INFO:root:current mean train loss 1276.0250462248964
INFO:root:current train perplexity2.7330095767974854
INFO:root:current mean train loss 1278.2386613884228
INFO:root:current train perplexity2.7378571033477783
INFO:root:current mean train loss 1277.9403895181101
INFO:root:current train perplexity2.7356276512145996
INFO:root:current mean train loss 1279.1557337954018
INFO:root:current train perplexity2.7408266067504883
INFO:root:current mean train loss 1280.953158499885
INFO:root:current train perplexity2.7424073219299316
INFO:root:current mean train loss 1282.045512914376
INFO:root:current train perplexity2.743717670440674
INFO:root:current mean train loss 1283.070377466671
INFO:root:current train perplexity2.7462127208709717
INFO:root:current mean train loss 1283.325556393453
INFO:root:current train perplexity2.7478036880493164
INFO:root:current mean train loss 1283.2060998120096
INFO:root:current train perplexity2.748325824737549
INFO:root:current mean train loss 1283.756072973574
INFO:root:current train perplexity2.7489891052246094
INFO:root:current mean train loss 1284.780186801109
INFO:root:current train perplexity2.7500007152557373
INFO:root:current mean train loss 1284.9427728975897
INFO:root:current train perplexity2.750912666320801
INFO:root:current mean train loss 1284.9781074351315
INFO:root:current train perplexity2.750955581665039
INFO:root:current mean train loss 1285.3087776336947
INFO:root:current train perplexity2.7519009113311768
INFO:root:current mean train loss 1284.9001533320513
INFO:root:current train perplexity2.752568006515503
INFO:root:current mean train loss 1285.0146073288188
INFO:root:current train perplexity2.753148317337036
INFO:root:current mean train loss 1285.0324854368298
INFO:root:current train perplexity2.753551483154297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:45<00:00, 585.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:45<00:00, 585.87s/it]
INFO:root:final mean train loss: 1284.4837541219506
INFO:root:final train perplexity: 2.753908634185791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2290.1646477449026
INFO:root:eval perplexity: 6.373512268066406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.14s/it]
INFO:root:eval mean loss: 2860.922810872396
INFO:root:eval perplexity: 10.37855339050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [25:28:13<9:51:02, 644.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1278.182481765747
INFO:root:current train perplexity2.7308855056762695
INFO:root:current mean train loss 1275.4555872475228
INFO:root:current train perplexity2.7295498847961426
INFO:root:current mean train loss 1269.2594382546165
INFO:root:current train perplexity2.728679895401001
INFO:root:current mean train loss 1272.0771105420458
INFO:root:current train perplexity2.7309746742248535
INFO:root:current mean train loss 1272.9261016845703
INFO:root:current train perplexity2.7355830669403076
INFO:root:current mean train loss 1274.849928835605
INFO:root:current train perplexity2.738969326019287
INFO:root:current mean train loss 1274.965266216232
INFO:root:current train perplexity2.739405393600464
INFO:root:current mean train loss 1276.4156104282558
INFO:root:current train perplexity2.7384464740753174
INFO:root:current mean train loss 1276.2315381368
INFO:root:current train perplexity2.739607572555542
INFO:root:current mean train loss 1277.0281272033437
INFO:root:current train perplexity2.7418174743652344
INFO:root:current mean train loss 1278.3400821542382
INFO:root:current train perplexity2.7450387477874756
INFO:root:current mean train loss 1278.346503608415
INFO:root:current train perplexity2.7451751232147217
INFO:root:current mean train loss 1279.0169337791733
INFO:root:current train perplexity2.745468854904175
INFO:root:current mean train loss 1279.2341113496036
INFO:root:current train perplexity2.7457475662231445
INFO:root:current mean train loss 1280.0938755723296
INFO:root:current train perplexity2.7464284896850586
INFO:root:current mean train loss 1280.7760360990949
INFO:root:current train perplexity2.7473387718200684
INFO:root:current mean train loss 1281.0777334800134
INFO:root:current train perplexity2.747689962387085
INFO:root:current mean train loss 1281.4202550771286
INFO:root:current train perplexity2.7486813068389893
INFO:root:current mean train loss 1282.5334288633944
INFO:root:current train perplexity2.750335454940796
INFO:root:current mean train loss 1282.9514302488742
INFO:root:current train perplexity2.7501461505889893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.73s/it]
INFO:root:final mean train loss: 1282.7390119174606
INFO:root:final train perplexity: 2.7501220703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2288.8550674763133
INFO:root:eval perplexity: 6.366766452789307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 2859.5512894434287
INFO:root:eval perplexity: 10.366917610168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [25:38:42<9:36:00, 640.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1287.755099826389
INFO:root:current train perplexity2.742422103881836
INFO:root:current mean train loss 1282.4301663393474
INFO:root:current train perplexity2.7363409996032715
INFO:root:current mean train loss 1280.5927816913645
INFO:root:current train perplexity2.735689640045166
INFO:root:current mean train loss 1278.8358964895012
INFO:root:current train perplexity2.7388222217559814
INFO:root:current mean train loss 1278.7287800683796
INFO:root:current train perplexity2.7376155853271484
INFO:root:current mean train loss 1278.5668590237065
INFO:root:current train perplexity2.738597869873047
INFO:root:current mean train loss 1278.3144206804675
INFO:root:current train perplexity2.7397608757019043
INFO:root:current mean train loss 1278.13876956251
INFO:root:current train perplexity2.740011692047119
INFO:root:current mean train loss 1279.5972220066863
INFO:root:current train perplexity2.741314172744751
INFO:root:current mean train loss 1279.0457671590293
INFO:root:current train perplexity2.7424073219299316
INFO:root:current mean train loss 1279.2972254016463
INFO:root:current train perplexity2.7428853511810303
INFO:root:current mean train loss 1279.5031981181533
INFO:root:current train perplexity2.743079900741577
INFO:root:current mean train loss 1278.9773705845043
INFO:root:current train perplexity2.7438955307006836
INFO:root:current mean train loss 1278.872960603729
INFO:root:current train perplexity2.7435009479522705
INFO:root:current mean train loss 1279.2463420942618
INFO:root:current train perplexity2.743178129196167
INFO:root:current mean train loss 1279.1615282863397
INFO:root:current train perplexity2.742915391921997
INFO:root:current mean train loss 1279.7243982027996
INFO:root:current train perplexity2.743454694747925
INFO:root:current mean train loss 1280.2664633166717
INFO:root:current train perplexity2.7438337802886963
INFO:root:current mean train loss 1280.071470383315
INFO:root:current train perplexity2.743661403656006
INFO:root:current mean train loss 1280.3688304887644
INFO:root:current train perplexity2.74410343170166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.38s/it]
INFO:root:final mean train loss: 1280.012770967777
INFO:root:final train perplexity: 2.7442150115966797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it]
INFO:root:eval mean loss: 2292.5131411721522
INFO:root:eval perplexity: 6.385628700256348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2864.6379662912786
INFO:root:eval perplexity: 10.41013240814209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [25:49:30<9:27:16, 642.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.0897777323821
INFO:root:current train perplexity2.730264663696289
INFO:root:current mean train loss 1270.4310641818577
INFO:root:current train perplexity2.7233896255493164
INFO:root:current mean train loss 1269.2875067179634
INFO:root:current train perplexity2.7297568321228027
INFO:root:current mean train loss 1268.97306693379
INFO:root:current train perplexity2.7276859283447266
INFO:root:current mean train loss 1273.188250560837
INFO:root:current train perplexity2.729978084564209
INFO:root:current mean train loss 1274.0819736850701
INFO:root:current train perplexity2.730363607406616
INFO:root:current mean train loss 1274.3146635126589
INFO:root:current train perplexity2.730377435684204
INFO:root:current mean train loss 1274.4028182639215
INFO:root:current train perplexity2.7309255599975586
INFO:root:current mean train loss 1274.3312584552043
INFO:root:current train perplexity2.731555938720703
INFO:root:current mean train loss 1274.6932249508784
INFO:root:current train perplexity2.7323837280273438
INFO:root:current mean train loss 1275.9083339781491
INFO:root:current train perplexity2.734102725982666
INFO:root:current mean train loss 1276.203014240042
INFO:root:current train perplexity2.7351832389831543
INFO:root:current mean train loss 1276.5731613088647
INFO:root:current train perplexity2.736595630645752
INFO:root:current mean train loss 1276.3834008474719
INFO:root:current train perplexity2.7366690635681152
INFO:root:current mean train loss 1276.7910496058546
INFO:root:current train perplexity2.736193895339966
INFO:root:current mean train loss 1277.3516209379156
INFO:root:current train perplexity2.7370052337646484
INFO:root:current mean train loss 1277.642513423421
INFO:root:current train perplexity2.7376842498779297
INFO:root:current mean train loss 1277.9945349433399
INFO:root:current train perplexity2.739046335220337
INFO:root:current mean train loss 1278.326370802016
INFO:root:current train perplexity2.739539623260498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.28s/it]
INFO:root:final mean train loss: 1278.4858886903426
INFO:root:final train perplexity: 2.7409121990203857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.26s/it]
INFO:root:eval mean loss: 2294.7436731216753
INFO:root:eval perplexity: 6.397159099578857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2868.650043027621
INFO:root:eval perplexity: 10.444345474243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [26:00:12<9:16:43, 642.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.238614908854
INFO:root:current train perplexity2.7318806648254395
INFO:root:current mean train loss 1280.3198358950408
INFO:root:current train perplexity2.733018636703491
INFO:root:current mean train loss 1267.828971543423
INFO:root:current train perplexity2.731189489364624
INFO:root:current mean train loss 1269.9450989738343
INFO:root:current train perplexity2.7334156036376953
INFO:root:current mean train loss 1270.6738375376506
INFO:root:current train perplexity2.729994535446167
INFO:root:current mean train loss 1271.6493258874393
INFO:root:current train perplexity2.7310574054718018
INFO:root:current mean train loss 1272.3695745204523
INFO:root:current train perplexity2.7298970222473145
INFO:root:current mean train loss 1273.7847307965471
INFO:root:current train perplexity2.7300333976745605
INFO:root:current mean train loss 1274.4556128379027
INFO:root:current train perplexity2.7286369800567627
INFO:root:current mean train loss 1275.1824645662568
INFO:root:current train perplexity2.7306478023529053
INFO:root:current mean train loss 1275.4849388084976
INFO:root:current train perplexity2.7313578128814697
INFO:root:current mean train loss 1275.684174213495
INFO:root:current train perplexity2.733750820159912
INFO:root:current mean train loss 1276.0109028380593
INFO:root:current train perplexity2.73323917388916
INFO:root:current mean train loss 1276.6471013174312
INFO:root:current train perplexity2.733686923980713
INFO:root:current mean train loss 1276.1422902461075
INFO:root:current train perplexity2.734513759613037
INFO:root:current mean train loss 1275.772076919606
INFO:root:current train perplexity2.734510660171509
INFO:root:current mean train loss 1275.948686629257
INFO:root:current train perplexity2.7354440689086914
INFO:root:current mean train loss 1276.5217989818696
INFO:root:current train perplexity2.7363827228546143
INFO:root:current mean train loss 1276.5991007150697
INFO:root:current train perplexity2.7367069721221924
INFO:root:current mean train loss 1277.0588333010362
INFO:root:current train perplexity2.737919807434082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.51s/it]
INFO:root:final mean train loss: 1277.2606444019773
INFO:root:final train perplexity: 2.7382655143737793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2297.4695170517507
INFO:root:eval perplexity: 6.411276340484619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.77s/it]
INFO:root:eval mean loss: 2872.7533937278367
INFO:root:eval perplexity: 10.479453086853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [26:10:52<9:05:24, 641.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1261.481616973877
INFO:root:current train perplexity2.7267661094665527
INFO:root:current mean train loss 1269.07216759884
INFO:root:current train perplexity2.7163615226745605
INFO:root:current mean train loss 1269.1373375202047
INFO:root:current train perplexity2.7254080772399902
INFO:root:current mean train loss 1266.6190755453454
INFO:root:current train perplexity2.7243824005126953
INFO:root:current mean train loss 1268.882319415057
INFO:root:current train perplexity2.7219696044921875
INFO:root:current mean train loss 1268.9971827456825
INFO:root:current train perplexity2.720496892929077
INFO:root:current mean train loss 1270.5220468255538
INFO:root:current train perplexity2.7231523990631104
INFO:root:current mean train loss 1270.4421978726414
INFO:root:current train perplexity2.7243080139160156
INFO:root:current mean train loss 1271.1457240764912
INFO:root:current train perplexity2.7245473861694336
INFO:root:current mean train loss 1271.9277563790906
INFO:root:current train perplexity2.726729154586792
INFO:root:current mean train loss 1272.4913399866384
INFO:root:current train perplexity2.725658416748047
INFO:root:current mean train loss 1272.7702133124792
INFO:root:current train perplexity2.7272520065307617
INFO:root:current mean train loss 1272.539730418812
INFO:root:current train perplexity2.727022409439087
INFO:root:current mean train loss 1272.5917483034793
INFO:root:current train perplexity2.7269105911254883
INFO:root:current mean train loss 1273.1131137442987
INFO:root:current train perplexity2.727382183074951
INFO:root:current mean train loss 1273.5605134092486
INFO:root:current train perplexity2.7297372817993164
INFO:root:current mean train loss 1273.8597982818005
INFO:root:current train perplexity2.7300314903259277
INFO:root:current mean train loss 1274.3911896809143
INFO:root:current train perplexity2.7308828830718994
INFO:root:current mean train loss 1274.5204992169377
INFO:root:current train perplexity2.7303829193115234
INFO:root:current mean train loss 1274.6543596161077
INFO:root:current train perplexity2.731626272201538

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.47s/it]
INFO:root:final mean train loss: 1274.461956568577
INFO:root:final train perplexity: 2.7322278022766113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 41.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 41.00s/it]
INFO:root:eval mean loss: 2297.2041452827184
INFO:root:eval perplexity: 6.409902095794678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2872.648109381926
INFO:root:eval perplexity: 10.478553771972656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [26:21:26<8:52:37, 639.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1269.5124586455677
INFO:root:current train perplexity2.7073843479156494
INFO:root:current mean train loss 1264.5601847603816
INFO:root:current train perplexity2.7102882862091064
INFO:root:current mean train loss 1263.4918644303777
INFO:root:current train perplexity2.7100889682769775
INFO:root:current mean train loss 1265.3495761466913
INFO:root:current train perplexity2.713567018508911
INFO:root:current mean train loss 1266.9264193324575
INFO:root:current train perplexity2.712090492248535
INFO:root:current mean train loss 1266.033544210354
INFO:root:current train perplexity2.7129838466644287
INFO:root:current mean train loss 1268.394544980559
INFO:root:current train perplexity2.718252420425415
INFO:root:current mean train loss 1268.7898265395527
INFO:root:current train perplexity2.7188127040863037
INFO:root:current mean train loss 1270.4013171516121
INFO:root:current train perplexity2.7187728881835938
INFO:root:current mean train loss 1270.2483038786715
INFO:root:current train perplexity2.7212040424346924
INFO:root:current mean train loss 1270.9429404492373
INFO:root:current train perplexity2.721996307373047
INFO:root:current mean train loss 1271.6709022621574
INFO:root:current train perplexity2.723266363143921
INFO:root:current mean train loss 1271.511300642076
INFO:root:current train perplexity2.7237370014190674
INFO:root:current mean train loss 1271.7162381929322
INFO:root:current train perplexity2.7243502140045166
INFO:root:current mean train loss 1271.8258689316986
INFO:root:current train perplexity2.7248775959014893
INFO:root:current mean train loss 1272.4948940880456
INFO:root:current train perplexity2.726135730743408
INFO:root:current mean train loss 1272.518707849099
INFO:root:current train perplexity2.7264373302459717
INFO:root:current mean train loss 1273.0703230389463
INFO:root:current train perplexity2.7276718616485596
INFO:root:current mean train loss 1273.1253297680967
INFO:root:current train perplexity2.7282192707061768
INFO:root:current mean train loss 1273.5433199918227
INFO:root:current train perplexity2.7289540767669678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:32<00:00, 572.13s/it]
INFO:root:final mean train loss: 1273.1490079001592
INFO:root:final train perplexity: 2.729400157928467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.41s/it]
INFO:root:eval mean loss: 2297.593816662511
INFO:root:eval perplexity: 6.411921977996826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2873.2340771830673
INFO:root:eval perplexity: 10.483573913574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [26:32:13<8:44:00, 641.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1268.2641583066998
INFO:root:current train perplexity2.7241930961608887
INFO:root:current mean train loss 1263.6371945300734
INFO:root:current train perplexity2.7109737396240234
INFO:root:current mean train loss 1263.464065895941
INFO:root:current train perplexity2.7062816619873047
INFO:root:current mean train loss 1265.1269998185621
INFO:root:current train perplexity2.7101552486419678
INFO:root:current mean train loss 1264.0211095195982
INFO:root:current train perplexity2.711453676223755
INFO:root:current mean train loss 1264.504005243416
INFO:root:current train perplexity2.7144548892974854
INFO:root:current mean train loss 1265.4638477588917
INFO:root:current train perplexity2.7162485122680664
INFO:root:current mean train loss 1265.228219373419
INFO:root:current train perplexity2.713974952697754
INFO:root:current mean train loss 1265.4316428803406
INFO:root:current train perplexity2.7154977321624756
INFO:root:current mean train loss 1265.968741280692
INFO:root:current train perplexity2.7159149646759033
INFO:root:current mean train loss 1266.8029895088239
INFO:root:current train perplexity2.7174346446990967
INFO:root:current mean train loss 1267.4213574051244
INFO:root:current train perplexity2.719302177429199
INFO:root:current mean train loss 1268.6784588902672
INFO:root:current train perplexity2.722080707550049
INFO:root:current mean train loss 1268.4595896328526
INFO:root:current train perplexity2.7220547199249268
INFO:root:current mean train loss 1270.068728666839
INFO:root:current train perplexity2.7236523628234863
INFO:root:current mean train loss 1270.4026203179876
INFO:root:current train perplexity2.723850965499878
INFO:root:current mean train loss 1270.2460977066607
INFO:root:current train perplexity2.7239253520965576
INFO:root:current mean train loss 1270.580010177595
INFO:root:current train perplexity2.7243807315826416
INFO:root:current mean train loss 1270.915795558263
INFO:root:current train perplexity2.7247636318206787
INFO:root:current mean train loss 1271.1522856951972
INFO:root:current train perplexity2.7241246700286865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.69s/it]
INFO:root:final mean train loss: 1270.8278910472907
INFO:root:final train perplexity: 2.7244086265563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2301.401095775848
INFO:root:eval perplexity: 6.431694507598877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2875.4409067140405
INFO:root:eval perplexity: 10.502514839172363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [26:42:45<8:30:51, 638.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1259.6630491693336
INFO:root:current train perplexity2.7054269313812256
INFO:root:current mean train loss 1263.7797171170594
INFO:root:current train perplexity2.711066722869873
INFO:root:current mean train loss 1262.0742907844246
INFO:root:current train perplexity2.7061636447906494
INFO:root:current mean train loss 1264.6910766920284
INFO:root:current train perplexity2.7088510990142822
INFO:root:current mean train loss 1265.8270536624127
INFO:root:current train perplexity2.70729398727417
INFO:root:current mean train loss 1266.2382065002546
INFO:root:current train perplexity2.709428548812866
INFO:root:current mean train loss 1265.8997611496843
INFO:root:current train perplexity2.7098591327667236
INFO:root:current mean train loss 1267.2438740346624
INFO:root:current train perplexity2.714047908782959
INFO:root:current mean train loss 1267.048784577833
INFO:root:current train perplexity2.7127811908721924
INFO:root:current mean train loss 1267.689563770624
INFO:root:current train perplexity2.7145566940307617
INFO:root:current mean train loss 1267.3136362796124
INFO:root:current train perplexity2.7153091430664062
INFO:root:current mean train loss 1267.925134473399
INFO:root:current train perplexity2.7160849571228027
INFO:root:current mean train loss 1268.1791530736982
INFO:root:current train perplexity2.717461585998535
INFO:root:current mean train loss 1268.3879959426406
INFO:root:current train perplexity2.717766761779785
INFO:root:current mean train loss 1268.126354214957
INFO:root:current train perplexity2.7171902656555176
INFO:root:current mean train loss 1268.118626125237
INFO:root:current train perplexity2.717426300048828
INFO:root:current mean train loss 1268.1581645383058
INFO:root:current train perplexity2.7174649238586426
INFO:root:current mean train loss 1268.2515980736032
INFO:root:current train perplexity2.718723773956299
INFO:root:current mean train loss 1268.6852034185392
INFO:root:current train perplexity2.719326972961426
INFO:root:current mean train loss 1268.813004347993
INFO:root:current train perplexity2.7200827598571777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.22s/it]
INFO:root:final mean train loss: 1268.813004347993
INFO:root:final train perplexity: 2.7200827598571777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2304.180003930491
INFO:root:eval perplexity: 6.446165561676025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2879.314730164007
INFO:root:eval perplexity: 10.53583812713623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [26:53:13<8:17:52, 635.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.6769104003906
INFO:root:current train perplexity2.7263522148132324
INFO:root:current mean train loss 1265.2520263671875
INFO:root:current train perplexity2.7202539443969727
INFO:root:current mean train loss 1267.9171826171876
INFO:root:current train perplexity2.716198682785034
INFO:root:current mean train loss 1267.2919589233397
INFO:root:current train perplexity2.7137022018432617
INFO:root:current mean train loss 1266.9178979492187
INFO:root:current train perplexity2.7130188941955566
INFO:root:current mean train loss 1265.975156656901
INFO:root:current train perplexity2.710496425628662
INFO:root:current mean train loss 1266.3172420828682
INFO:root:current train perplexity2.711207628250122
INFO:root:current mean train loss 1265.7266778564453
INFO:root:current train perplexity2.7093634605407715
INFO:root:current mean train loss 1265.7527799479167
INFO:root:current train perplexity2.710953712463379
INFO:root:current mean train loss 1266.3630700683593
INFO:root:current train perplexity2.7121424674987793
INFO:root:current mean train loss 1267.6564093572442
INFO:root:current train perplexity2.713059186935425
INFO:root:current mean train loss 1266.4231071980794
INFO:root:current train perplexity2.7126305103302
INFO:root:current mean train loss 1266.4542022235578
INFO:root:current train perplexity2.7123992443084717
INFO:root:current mean train loss 1266.7953813825334
INFO:root:current train perplexity2.713761568069458
INFO:root:current mean train loss 1267.0761974283855
INFO:root:current train perplexity2.71282958984375
INFO:root:current mean train loss 1267.6408700561524
INFO:root:current train perplexity2.7135798931121826
INFO:root:current mean train loss 1266.8381674373852
INFO:root:current train perplexity2.7143495082855225
INFO:root:current mean train loss 1266.9584728325738
INFO:root:current train perplexity2.714595317840576
INFO:root:current mean train loss 1266.9720914499383
INFO:root:current train perplexity2.715090751647949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.94s/it]
INFO:root:final mean train loss: 1266.5825697013481
INFO:root:final train perplexity: 2.715301990509033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2307.1218569058897
INFO:root:eval perplexity: 6.461521148681641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2884.3244308579897
INFO:root:eval perplexity: 10.579093933105469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [27:03:37<8:04:29, 631.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.293722713695
INFO:root:current train perplexity2.6503536701202393
INFO:root:current mean train loss 1253.3746901292068
INFO:root:current train perplexity2.6958167552948
INFO:root:current mean train loss 1255.554222845262
INFO:root:current train perplexity2.7000226974487305
INFO:root:current mean train loss 1258.9013356109522
INFO:root:current train perplexity2.703578472137451
INFO:root:current mean train loss 1261.687939394578
INFO:root:current train perplexity2.705308437347412
INFO:root:current mean train loss 1261.6532183117747
INFO:root:current train perplexity2.7019431591033936
INFO:root:current mean train loss 1261.7621328394068
INFO:root:current train perplexity2.702509641647339
INFO:root:current mean train loss 1262.9656645323942
INFO:root:current train perplexity2.7041473388671875
INFO:root:current mean train loss 1263.1430233753442
INFO:root:current train perplexity2.7060766220092773
INFO:root:current mean train loss 1263.4400839769203
INFO:root:current train perplexity2.7065093517303467
INFO:root:current mean train loss 1263.4883967186731
INFO:root:current train perplexity2.7059669494628906
INFO:root:current mean train loss 1264.3771591254826
INFO:root:current train perplexity2.7076516151428223
INFO:root:current mean train loss 1264.4046250706142
INFO:root:current train perplexity2.7069525718688965
INFO:root:current mean train loss 1264.2965816419596
INFO:root:current train perplexity2.708181619644165
INFO:root:current mean train loss 1265.5055493319128
INFO:root:current train perplexity2.7090628147125244
INFO:root:current mean train loss 1266.0184345484251
INFO:root:current train perplexity2.710373640060425
INFO:root:current mean train loss 1266.1437792002455
INFO:root:current train perplexity2.7114202976226807
INFO:root:current mean train loss 1265.8800614745242
INFO:root:current train perplexity2.7119333744049072
INFO:root:current mean train loss 1266.3809838638767
INFO:root:current train perplexity2.713453531265259
INFO:root:current mean train loss 1266.6366785056402
INFO:root:current train perplexity2.7137372493743896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.60s/it]
INFO:root:final mean train loss: 1265.978256494904
INFO:root:final train perplexity: 2.714008092880249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2310.4721021719856
INFO:root:eval perplexity: 6.479053020477295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 2886.0365955542165
INFO:root:eval perplexity: 10.593917846679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [27:14:15<7:55:30, 634.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.8521836224725
INFO:root:current train perplexity2.6853983402252197
INFO:root:current mean train loss 1262.2958310255365
INFO:root:current train perplexity2.709496259689331
INFO:root:current mean train loss 1259.0943008814102
INFO:root:current train perplexity2.705120801925659
INFO:root:current mean train loss 1259.5216217954714
INFO:root:current train perplexity2.70174503326416
INFO:root:current mean train loss 1259.9784394013716
INFO:root:current train perplexity2.7030978202819824
INFO:root:current mean train loss 1260.8589306091994
INFO:root:current train perplexity2.703822135925293
INFO:root:current mean train loss 1261.6484176683878
INFO:root:current train perplexity2.703836441040039
INFO:root:current mean train loss 1262.8984850641816
INFO:root:current train perplexity2.704070568084717
INFO:root:current mean train loss 1263.6070045818815
INFO:root:current train perplexity2.703538417816162
INFO:root:current mean train loss 1263.2612841849154
INFO:root:current train perplexity2.7028613090515137
INFO:root:current mean train loss 1262.2862783760352
INFO:root:current train perplexity2.70393443107605
INFO:root:current mean train loss 1261.9721041348034
INFO:root:current train perplexity2.7041287422180176
INFO:root:current mean train loss 1261.931546549743
INFO:root:current train perplexity2.7039952278137207
INFO:root:current mean train loss 1262.5949201912715
INFO:root:current train perplexity2.7056524753570557
INFO:root:current mean train loss 1262.7717609485323
INFO:root:current train perplexity2.7068581581115723
INFO:root:current mean train loss 1263.0266620183395
INFO:root:current train perplexity2.7069149017333984
INFO:root:current mean train loss 1263.5298774186956
INFO:root:current train perplexity2.7074203491210938
INFO:root:current mean train loss 1264.069302850391
INFO:root:current train perplexity2.7088232040405273
INFO:root:current mean train loss 1264.504739176876
INFO:root:current train perplexity2.7093493938446045
INFO:root:current mean train loss 1264.778717451283
INFO:root:current train perplexity2.710509777069092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.09s/it]
INFO:root:final mean train loss: 1264.4377126842812
INFO:root:final train perplexity: 2.7107131481170654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2307.7317652059787
INFO:root:eval perplexity: 6.464709281921387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2884.687361047623
INFO:root:eval perplexity: 10.582234382629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [27:24:42<7:43:19, 631.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1255.9320642807904
INFO:root:current train perplexity2.7150001525878906
INFO:root:current mean train loss 1258.5854241579573
INFO:root:current train perplexity2.7059991359710693
INFO:root:current mean train loss 1258.5657424014878
INFO:root:current train perplexity2.7017834186553955
INFO:root:current mean train loss 1259.0968942669383
INFO:root:current train perplexity2.697770357131958
INFO:root:current mean train loss 1261.93053197755
INFO:root:current train perplexity2.7010085582733154
INFO:root:current mean train loss 1261.8245597050109
INFO:root:current train perplexity2.7028050422668457
INFO:root:current mean train loss 1262.5785418391777
INFO:root:current train perplexity2.7029342651367188
INFO:root:current mean train loss 1261.5342916801037
INFO:root:current train perplexity2.7027766704559326
INFO:root:current mean train loss 1261.0357174004848
INFO:root:current train perplexity2.7028424739837646
INFO:root:current mean train loss 1261.5590065555994
INFO:root:current train perplexity2.701995372772217
INFO:root:current mean train loss 1261.8926776628286
INFO:root:current train perplexity2.702100992202759
INFO:root:current mean train loss 1262.2090051619516
INFO:root:current train perplexity2.7029976844787598
INFO:root:current mean train loss 1262.3259502749363
INFO:root:current train perplexity2.7032203674316406
INFO:root:current mean train loss 1262.463027965396
INFO:root:current train perplexity2.7043418884277344
INFO:root:current mean train loss 1263.307311212499
INFO:root:current train perplexity2.7053909301757812
INFO:root:current mean train loss 1263.2060722385506
INFO:root:current train perplexity2.705016613006592
INFO:root:current mean train loss 1263.2036781241718
INFO:root:current train perplexity2.7052884101867676
INFO:root:current mean train loss 1263.4255481940008
INFO:root:current train perplexity2.7063915729522705
INFO:root:current mean train loss 1263.1546080850512
INFO:root:current train perplexity2.706904411315918
INFO:root:current mean train loss 1263.1586622495274
INFO:root:current train perplexity2.7064216136932373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.50s/it]
INFO:root:final mean train loss: 1262.6153102457313
INFO:root:final train perplexity: 2.706819534301758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2310.6239065616687
INFO:root:eval perplexity: 6.479848861694336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2889.3377772121567
INFO:root:eval perplexity: 10.62255859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [27:35:07<7:31:12, 629.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1252.9328020881203
INFO:root:current train perplexity2.6812610626220703
INFO:root:current mean train loss 1252.2313464936756
INFO:root:current train perplexity2.688703775405884
INFO:root:current mean train loss 1252.5866384933245
INFO:root:current train perplexity2.691887378692627
INFO:root:current mean train loss 1254.990712373153
INFO:root:current train perplexity2.6968064308166504
INFO:root:current mean train loss 1256.33739843124
INFO:root:current train perplexity2.697938919067383
INFO:root:current mean train loss 1255.8355197100573
INFO:root:current train perplexity2.696793556213379
INFO:root:current mean train loss 1255.6177532630052
INFO:root:current train perplexity2.699648141860962
INFO:root:current mean train loss 1256.7823454538982
INFO:root:current train perplexity2.701263427734375
INFO:root:current mean train loss 1257.8197979201918
INFO:root:current train perplexity2.702634334564209
INFO:root:current mean train loss 1258.1021290928863
INFO:root:current train perplexity2.7036490440368652
INFO:root:current mean train loss 1258.883509946673
INFO:root:current train perplexity2.7032551765441895
INFO:root:current mean train loss 1259.3401174675928
INFO:root:current train perplexity2.703632354736328
INFO:root:current mean train loss 1260.0637267681327
INFO:root:current train perplexity2.7023873329162598
INFO:root:current mean train loss 1260.207481875057
INFO:root:current train perplexity2.7028017044067383
INFO:root:current mean train loss 1259.8009604472231
INFO:root:current train perplexity2.7021164894104004
INFO:root:current mean train loss 1260.3275123907595
INFO:root:current train perplexity2.7025983333587646
INFO:root:current mean train loss 1260.382439482984
INFO:root:current train perplexity2.703331232070923
INFO:root:current mean train loss 1260.4097605571487
INFO:root:current train perplexity2.702765941619873
INFO:root:current mean train loss 1260.5636315029235
INFO:root:current train perplexity2.7029640674591064
INFO:root:current mean train loss 1261.3825662504366
INFO:root:current train perplexity2.703519344329834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.99s/it]
INFO:root:final mean train loss: 1261.06937139514
INFO:root:final train perplexity: 2.703521251678467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 2313.08327013381
INFO:root:eval perplexity: 6.492747783660889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2891.6212902745456
INFO:root:eval perplexity: 10.642415046691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [27:45:31<7:19:43, 628.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1245.6201229319854
INFO:root:current train perplexity2.6808369159698486
INFO:root:current mean train loss 1247.9259429106842
INFO:root:current train perplexity2.6876118183135986
INFO:root:current mean train loss 1250.7742388808936
INFO:root:current train perplexity2.6888651847839355
INFO:root:current mean train loss 1251.9970671418425
INFO:root:current train perplexity2.6900572776794434
INFO:root:current mean train loss 1253.3751306278189
INFO:root:current train perplexity2.691769599914551
INFO:root:current mean train loss 1251.653650632679
INFO:root:current train perplexity2.692241907119751
INFO:root:current mean train loss 1252.9132906948562
INFO:root:current train perplexity2.6921591758728027
INFO:root:current mean train loss 1253.724031990197
INFO:root:current train perplexity2.693291187286377
INFO:root:current mean train loss 1254.0046520513329
INFO:root:current train perplexity2.691952705383301
INFO:root:current mean train loss 1255.24125728704
INFO:root:current train perplexity2.6920273303985596
INFO:root:current mean train loss 1254.8876865369384
INFO:root:current train perplexity2.6925277709960938
INFO:root:current mean train loss 1255.079708514636
INFO:root:current train perplexity2.6932060718536377
INFO:root:current mean train loss 1255.5402602140077
INFO:root:current train perplexity2.6942296028137207
INFO:root:current mean train loss 1256.4942990960628
INFO:root:current train perplexity2.694488286972046
INFO:root:current mean train loss 1256.7796250263048
INFO:root:current train perplexity2.6943087577819824
INFO:root:current mean train loss 1257.1764662300375
INFO:root:current train perplexity2.695740222930908
INFO:root:current mean train loss 1257.939266071263
INFO:root:current train perplexity2.696089506149292
INFO:root:current mean train loss 1258.7798315908394
INFO:root:current train perplexity2.697082281112671
INFO:root:current mean train loss 1259.2398407710957
INFO:root:current train perplexity2.6980597972869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.36s/it]
INFO:root:final mean train loss: 1258.850436258244
INFO:root:final train perplexity: 2.698794364929199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 2312.760926591589
INFO:root:eval perplexity: 6.4910569190979
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2892.3106624522106
INFO:root:eval perplexity: 10.648414611816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [27:56:07<7:10:40, 630.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1164.7728271484375
INFO:root:current train perplexity2.6439247131347656
INFO:root:current mean train loss 1245.1455042221967
INFO:root:current train perplexity2.689361572265625
INFO:root:current mean train loss 1246.2375977771117
INFO:root:current train perplexity2.682298421859741
INFO:root:current mean train loss 1251.1096826010194
INFO:root:current train perplexity2.682983875274658
INFO:root:current mean train loss 1251.1349283854167
INFO:root:current train perplexity2.6826627254486084
INFO:root:current mean train loss 1251.8160456319254
INFO:root:current train perplexity2.682830333709717
INFO:root:current mean train loss 1253.3637091044175
INFO:root:current train perplexity2.684948205947876
INFO:root:current mean train loss 1253.7917671747018
INFO:root:current train perplexity2.685386896133423
INFO:root:current mean train loss 1254.9377153734317
INFO:root:current train perplexity2.687886953353882
INFO:root:current mean train loss 1254.5622737233232
INFO:root:current train perplexity2.6897151470184326
INFO:root:current mean train loss 1254.3968370631783
INFO:root:current train perplexity2.690908670425415
INFO:root:current mean train loss 1255.888523330273
INFO:root:current train perplexity2.6930506229400635
INFO:root:current mean train loss 1255.7280649194702
INFO:root:current train perplexity2.692221164703369
INFO:root:current mean train loss 1255.8768566500755
INFO:root:current train perplexity2.691575527191162
INFO:root:current mean train loss 1256.8422993484476
INFO:root:current train perplexity2.691642999649048
INFO:root:current mean train loss 1257.170992712841
INFO:root:current train perplexity2.693359375
INFO:root:current mean train loss 1257.4938554132773
INFO:root:current train perplexity2.6941745281219482
INFO:root:current mean train loss 1257.3988746436867
INFO:root:current train perplexity2.694843053817749
INFO:root:current mean train loss 1257.5492690548913
INFO:root:current train perplexity2.695498466491699
INFO:root:current mean train loss 1257.6481567767892
INFO:root:current train perplexity2.695725917816162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.06s/it]
INFO:root:final mean train loss: 1257.4996503482728
INFO:root:final train perplexity: 2.6959211826324463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 2316.2799816807956
INFO:root:eval perplexity: 6.509555816650391
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 2894.52720696199
INFO:root:eval perplexity: 10.667737007141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [28:06:36<6:59:57, 629.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.9317434210527
INFO:root:current train perplexity2.707982063293457
INFO:root:current mean train loss 1254.120173606552
INFO:root:current train perplexity2.6762635707855225
INFO:root:current mean train loss 1255.3025521056293
INFO:root:current train perplexity2.678253650665283
INFO:root:current mean train loss 1251.8618562034678
INFO:root:current train perplexity2.683138847351074
INFO:root:current mean train loss 1252.655530979639
INFO:root:current train perplexity2.6846816539764404
INFO:root:current mean train loss 1251.4083797623887
INFO:root:current train perplexity2.6852335929870605
INFO:root:current mean train loss 1251.5495635049601
INFO:root:current train perplexity2.6851859092712402
INFO:root:current mean train loss 1252.513659650991
INFO:root:current train perplexity2.6854071617126465
INFO:root:current mean train loss 1252.6328640706083
INFO:root:current train perplexity2.6865673065185547
INFO:root:current mean train loss 1253.1654103209585
INFO:root:current train perplexity2.6881046295166016
INFO:root:current mean train loss 1253.845939119618
INFO:root:current train perplexity2.688871145248413
INFO:root:current mean train loss 1254.0651616564385
INFO:root:current train perplexity2.6901986598968506
INFO:root:current mean train loss 1255.0632975126898
INFO:root:current train perplexity2.6908071041107178
INFO:root:current mean train loss 1256.2981952843654
INFO:root:current train perplexity2.6918511390686035
INFO:root:current mean train loss 1256.3392117199887
INFO:root:current train perplexity2.6911869049072266
INFO:root:current mean train loss 1256.0671769243231
INFO:root:current train perplexity2.6930906772613525
INFO:root:current mean train loss 1255.7331139586308
INFO:root:current train perplexity2.6934280395507812
INFO:root:current mean train loss 1256.0846150361083
INFO:root:current train perplexity2.6937320232391357
INFO:root:current mean train loss 1256.425192238932
INFO:root:current train perplexity2.6930503845214844
INFO:root:current mean train loss 1256.7978853401632
INFO:root:current train perplexity2.6934945583343506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.20s/it]
INFO:root:final mean train loss: 1256.3316410005064
INFO:root:final train perplexity: 2.693438768386841
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2318.778969189799
INFO:root:eval perplexity: 6.522725582122803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.64s/it]
INFO:root:eval mean loss: 2898.466441485899
INFO:root:eval perplexity: 10.70215892791748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [28:17:00<6:48:15, 628.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1254.8587307400173
INFO:root:current train perplexity2.675391435623169
INFO:root:current mean train loss 1252.5976508645451
INFO:root:current train perplexity2.668172597885132
INFO:root:current mean train loss 1252.7023879229012
INFO:root:current train perplexity2.6819329261779785
INFO:root:current mean train loss 1253.4270052228655
INFO:root:current train perplexity2.68353009223938
INFO:root:current mean train loss 1254.2415376715703
INFO:root:current train perplexity2.684023857116699
INFO:root:current mean train loss 1253.4859068002274
INFO:root:current train perplexity2.6857235431671143
INFO:root:current mean train loss 1254.8825006065128
INFO:root:current train perplexity2.6853904724121094
INFO:root:current mean train loss 1254.5527998882792
INFO:root:current train perplexity2.688546657562256
INFO:root:current mean train loss 1254.8293094908793
INFO:root:current train perplexity2.688061237335205
INFO:root:current mean train loss 1254.4287051991519
INFO:root:current train perplexity2.6879255771636963
INFO:root:current mean train loss 1254.373163996516
INFO:root:current train perplexity2.6884565353393555
INFO:root:current mean train loss 1255.0500720386774
INFO:root:current train perplexity2.6893646717071533
INFO:root:current mean train loss 1254.7976177919259
INFO:root:current train perplexity2.688978433609009
INFO:root:current mean train loss 1254.8584877059845
INFO:root:current train perplexity2.68975567817688
INFO:root:current mean train loss 1255.0037893651256
INFO:root:current train perplexity2.6898105144500732
INFO:root:current mean train loss 1255.648783604304
INFO:root:current train perplexity2.6898748874664307
INFO:root:current mean train loss 1255.6341013267163
INFO:root:current train perplexity2.6907453536987305
INFO:root:current mean train loss 1255.3294499832364
INFO:root:current train perplexity2.6912953853607178
INFO:root:current mean train loss 1255.3755629462614
INFO:root:current train perplexity2.691234588623047
INFO:root:current mean train loss 1255.4243189914168
INFO:root:current train perplexity2.690824270248413

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.93s/it]
INFO:root:final mean train loss: 1254.9925064956426
INFO:root:final train perplexity: 2.6905956268310547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 2318.076755388409
INFO:root:eval perplexity: 6.5190229415893555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2899.8501833651926
INFO:root:eval perplexity: 10.714278221130371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [28:27:33<6:38:51, 629.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1249.7009162183078
INFO:root:current train perplexity2.6711995601654053
INFO:root:current mean train loss 1251.0185562831903
INFO:root:current train perplexity2.6664116382598877
INFO:root:current mean train loss 1251.9521706321023
INFO:root:current train perplexity2.666470766067505
INFO:root:current mean train loss 1250.5634416358666
INFO:root:current train perplexity2.6681742668151855
INFO:root:current mean train loss 1250.2006914084059
INFO:root:current train perplexity2.67311954498291
INFO:root:current mean train loss 1249.9140883268112
INFO:root:current train perplexity2.67507004737854
INFO:root:current mean train loss 1250.293793145219
INFO:root:current train perplexity2.6764605045318604
INFO:root:current mean train loss 1250.6442185360122
INFO:root:current train perplexity2.678248643875122
INFO:root:current mean train loss 1250.9594211377125
INFO:root:current train perplexity2.678447961807251
INFO:root:current mean train loss 1250.9080330207241
INFO:root:current train perplexity2.678528308868408
INFO:root:current mean train loss 1251.2866974891308
INFO:root:current train perplexity2.678762674331665
INFO:root:current mean train loss 1251.8215690937025
INFO:root:current train perplexity2.6786837577819824
INFO:root:current mean train loss 1251.7090938778183
INFO:root:current train perplexity2.6788604259490967
INFO:root:current mean train loss 1252.853070560069
INFO:root:current train perplexity2.681839942932129
INFO:root:current mean train loss 1252.1431158056607
INFO:root:current train perplexity2.682288885116577
INFO:root:current mean train loss 1252.3885445382928
INFO:root:current train perplexity2.683105707168579
INFO:root:current mean train loss 1252.3812727007949
INFO:root:current train perplexity2.6835215091705322
INFO:root:current mean train loss 1252.5012860904744
INFO:root:current train perplexity2.683779001235962
INFO:root:current mean train loss 1252.8067675702198
INFO:root:current train perplexity2.6847171783447266
INFO:root:current mean train loss 1253.161394579253
INFO:root:current train perplexity2.6859889030456543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.13s/it]
INFO:root:final mean train loss: 1252.823552072499
INFO:root:final train perplexity: 2.6859970092773438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2321.047290991384
INFO:root:eval perplexity: 6.534701824188232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2902.9721619085217
INFO:root:eval perplexity: 10.741666793823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [28:37:55<6:26:55, 627.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1246.6146850585938
INFO:root:current train perplexity2.6889545917510986
INFO:root:current mean train loss 1247.7113080193014
INFO:root:current train perplexity2.68149471282959
INFO:root:current mean train loss 1247.4578079788773
INFO:root:current train perplexity2.6821866035461426
INFO:root:current mean train loss 1248.5987730283996
INFO:root:current train perplexity2.6771247386932373
INFO:root:current mean train loss 1249.3467202044549
INFO:root:current train perplexity2.6756246089935303
INFO:root:current mean train loss 1250.5178835149397
INFO:root:current train perplexity2.6746535301208496
INFO:root:current mean train loss 1250.436132448111
INFO:root:current train perplexity2.676353693008423
INFO:root:current mean train loss 1250.6926951222606
INFO:root:current train perplexity2.6772828102111816
INFO:root:current mean train loss 1250.490280817843
INFO:root:current train perplexity2.6767210960388184
INFO:root:current mean train loss 1251.1505654246537
INFO:root:current train perplexity2.677320718765259
INFO:root:current mean train loss 1250.9013647917275
INFO:root:current train perplexity2.6785385608673096
INFO:root:current mean train loss 1250.3252473749667
INFO:root:current train perplexity2.679642915725708
INFO:root:current mean train loss 1250.1474627637488
INFO:root:current train perplexity2.6794352531433105
INFO:root:current mean train loss 1250.0766146249146
INFO:root:current train perplexity2.679089069366455
INFO:root:current mean train loss 1250.3291000677614
INFO:root:current train perplexity2.680452585220337
INFO:root:current mean train loss 1250.6517510480942
INFO:root:current train perplexity2.6800172328948975
INFO:root:current mean train loss 1250.8313095001404
INFO:root:current train perplexity2.6803975105285645
INFO:root:current mean train loss 1251.2814673127427
INFO:root:current train perplexity2.681140661239624
INFO:root:current mean train loss 1251.3888634666403
INFO:root:current train perplexity2.6824705600738525
INFO:root:current mean train loss 1251.9079508050445
INFO:root:current train perplexity2.6832568645477295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.03s/it]
INFO:root:final mean train loss: 1251.494818783143
INFO:root:final train perplexity: 2.6831839084625244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it]
INFO:root:eval mean loss: 2320.7638653694316
INFO:root:eval perplexity: 6.533203601837158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2901.9364069945423
INFO:root:eval perplexity: 10.732571601867676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [28:48:33<6:18:23, 630.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.9291178385417
INFO:root:current train perplexity2.663339853286743
INFO:root:current mean train loss 1245.2951222792028
INFO:root:current train perplexity2.6696653366088867
INFO:root:current mean train loss 1244.194403565304
INFO:root:current train perplexity2.665842056274414
INFO:root:current mean train loss 1247.074245561309
INFO:root:current train perplexity2.667872428894043
INFO:root:current mean train loss 1246.149900589146
INFO:root:current train perplexity2.668590784072876
INFO:root:current mean train loss 1245.706432751943
INFO:root:current train perplexity2.6711158752441406
INFO:root:current mean train loss 1245.7561470487058
INFO:root:current train perplexity2.6719465255737305
INFO:root:current mean train loss 1246.0964329100323
INFO:root:current train perplexity2.6725478172302246
INFO:root:current mean train loss 1246.5912134972607
INFO:root:current train perplexity2.6731224060058594
INFO:root:current mean train loss 1246.1962604928524
INFO:root:current train perplexity2.67431378364563
INFO:root:current mean train loss 1247.0534380480249
INFO:root:current train perplexity2.6750924587249756
INFO:root:current mean train loss 1247.6858147715157
INFO:root:current train perplexity2.675589084625244
INFO:root:current mean train loss 1248.3129996630973
INFO:root:current train perplexity2.6764636039733887
INFO:root:current mean train loss 1247.8325233156936
INFO:root:current train perplexity2.6775331497192383
INFO:root:current mean train loss 1248.3112789685083
INFO:root:current train perplexity2.6775033473968506
INFO:root:current mean train loss 1249.2279391946774
INFO:root:current train perplexity2.6791751384735107
INFO:root:current mean train loss 1249.808471752047
INFO:root:current train perplexity2.6804747581481934
INFO:root:current mean train loss 1250.3138256275795
INFO:root:current train perplexity2.6811041831970215
INFO:root:current mean train loss 1250.4319028141767
INFO:root:current train perplexity2.6807162761688232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.73s/it]
INFO:root:final mean train loss: 1250.4907895702338
INFO:root:final train perplexity: 2.6810598373413086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2322.6650152544603
INFO:root:eval perplexity: 6.543256759643555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2905.28897462669
INFO:root:eval perplexity: 10.762041091918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [28:59:00<6:07:10, 629.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.9666748046875
INFO:root:current train perplexity2.6861631870269775
INFO:root:current mean train loss 1238.4994283822866
INFO:root:current train perplexity2.6606814861297607
INFO:root:current mean train loss 1241.4975496179918
INFO:root:current train perplexity2.6666533946990967
INFO:root:current mean train loss 1242.6151990388569
INFO:root:current train perplexity2.667661666870117
INFO:root:current mean train loss 1245.308287667756
INFO:root:current train perplexity2.667973041534424
INFO:root:current mean train loss 1245.7357492598276
INFO:root:current train perplexity2.669316053390503
INFO:root:current mean train loss 1245.58153084256
INFO:root:current train perplexity2.6727397441864014
INFO:root:current mean train loss 1246.1201107718728
INFO:root:current train perplexity2.6727206707000732
INFO:root:current mean train loss 1246.1759262464532
INFO:root:current train perplexity2.6706020832061768
INFO:root:current mean train loss 1246.4983658242015
INFO:root:current train perplexity2.672165870666504
INFO:root:current mean train loss 1247.1723243743775
INFO:root:current train perplexity2.67283296585083
INFO:root:current mean train loss 1247.1801970108695
INFO:root:current train perplexity2.673095703125
INFO:root:current mean train loss 1248.040981457479
INFO:root:current train perplexity2.674095630645752
INFO:root:current mean train loss 1248.4473395786401
INFO:root:current train perplexity2.6750681400299072
INFO:root:current mean train loss 1247.9436868086161
INFO:root:current train perplexity2.67547345161438
INFO:root:current mean train loss 1248.073026454195
INFO:root:current train perplexity2.6769819259643555
INFO:root:current mean train loss 1248.1429775932484
INFO:root:current train perplexity2.677302122116089
INFO:root:current mean train loss 1248.5670956893705
INFO:root:current train perplexity2.6766788959503174
INFO:root:current mean train loss 1248.6841876586102
INFO:root:current train perplexity2.677159309387207
INFO:root:current mean train loss 1248.6311551903477
INFO:root:current train perplexity2.677424669265747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.98s/it]
INFO:root:final mean train loss: 1248.9146923347969
INFO:root:final train perplexity: 2.677729845046997
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2323.6885146553636
INFO:root:eval perplexity: 6.548674583435059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 2905.1489379017066
INFO:root:eval perplexity: 10.760807037353516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [29:09:27<5:56:15, 628.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1245.3643450055804
INFO:root:current train perplexity2.6599066257476807
INFO:root:current mean train loss 1249.1236420938792
INFO:root:current train perplexity2.672835111618042
INFO:root:current mean train loss 1248.082006394054
INFO:root:current train perplexity2.6644396781921387
INFO:root:current mean train loss 1245.826896691248
INFO:root:current train perplexity2.6628828048706055
INFO:root:current mean train loss 1245.6843273316879
INFO:root:current train perplexity2.662457227706909
INFO:root:current mean train loss 1244.4185570773602
INFO:root:current train perplexity2.665860891342163
INFO:root:current mean train loss 1245.9297106953252
INFO:root:current train perplexity2.6679043769836426
INFO:root:current mean train loss 1245.932082854759
INFO:root:current train perplexity2.6691951751708984
INFO:root:current mean train loss 1246.34593893927
INFO:root:current train perplexity2.668621778488159
INFO:root:current mean train loss 1246.958534000492
INFO:root:current train perplexity2.6687819957733154
INFO:root:current mean train loss 1246.5718401125198
INFO:root:current train perplexity2.6688809394836426
INFO:root:current mean train loss 1246.2912827422851
INFO:root:current train perplexity2.6716151237487793
INFO:root:current mean train loss 1247.0889886579585
INFO:root:current train perplexity2.6713075637817383
INFO:root:current mean train loss 1246.74816903772
INFO:root:current train perplexity2.6711061000823975
INFO:root:current mean train loss 1246.8078815156855
INFO:root:current train perplexity2.670576333999634
INFO:root:current mean train loss 1246.912610818335
INFO:root:current train perplexity2.6711814403533936
INFO:root:current mean train loss 1247.2132308555194
INFO:root:current train perplexity2.6714091300964355
INFO:root:current mean train loss 1247.0707482931434
INFO:root:current train perplexity2.671675682067871
INFO:root:current mean train loss 1247.3008084661158
INFO:root:current train perplexity2.672987222671509
INFO:root:current mean train loss 1247.6536406438095
INFO:root:current train perplexity2.6743059158325195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.99s/it]
INFO:root:final mean train loss: 1247.4710396340083
INFO:root:final train perplexity: 2.6746826171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it]
INFO:root:eval mean loss: 2325.0578630596187
INFO:root:eval perplexity: 6.555933475494385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2907.080060810062
INFO:root:eval perplexity: 10.777814865112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [29:19:49<5:44:44, 626.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.4749241879113
INFO:root:current train perplexity2.6535613536834717
INFO:root:current mean train loss 1237.9751410000565
INFO:root:current train perplexity2.64978289604187
INFO:root:current mean train loss 1243.0324840385372
INFO:root:current train perplexity2.6557064056396484
INFO:root:current mean train loss 1242.6091752814118
INFO:root:current train perplexity2.65321683883667
INFO:root:current mean train loss 1244.4528585634275
INFO:root:current train perplexity2.6586036682128906
INFO:root:current mean train loss 1243.3635408195864
INFO:root:current train perplexity2.659353733062744
INFO:root:current mean train loss 1243.972068858371
INFO:root:current train perplexity2.658874273300171
INFO:root:current mean train loss 1245.630703892488
INFO:root:current train perplexity2.6624157428741455
INFO:root:current mean train loss 1246.3642664069491
INFO:root:current train perplexity2.66300368309021
INFO:root:current mean train loss 1245.5790849047175
INFO:root:current train perplexity2.6643166542053223
INFO:root:current mean train loss 1245.2818242479152
INFO:root:current train perplexity2.665853261947632
INFO:root:current mean train loss 1245.6122358218229
INFO:root:current train perplexity2.6684298515319824
INFO:root:current mean train loss 1245.1009183276644
INFO:root:current train perplexity2.6698760986328125
INFO:root:current mean train loss 1245.4251772847767
INFO:root:current train perplexity2.6703104972839355
INFO:root:current mean train loss 1245.9434729564173
INFO:root:current train perplexity2.6707983016967773
INFO:root:current mean train loss 1245.7160158789825
INFO:root:current train perplexity2.6709086894989014
INFO:root:current mean train loss 1246.0112639300262
INFO:root:current train perplexity2.671424627304077
INFO:root:current mean train loss 1246.2238689462115
INFO:root:current train perplexity2.6717212200164795
INFO:root:current mean train loss 1246.1736084250033
INFO:root:current train perplexity2.6712968349456787
INFO:root:current mean train loss 1246.6133385688775
INFO:root:current train perplexity2.672060489654541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.34s/it]
INFO:root:final mean train loss: 1246.1728716305392
INFO:root:final train perplexity: 2.671945571899414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.92s/it]
INFO:root:eval mean loss: 2329.7775710085607
INFO:root:eval perplexity: 6.581005096435547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.39s/it]
INFO:root:eval mean loss: 2911.0877334919383
INFO:root:eval perplexity: 10.813199996948242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [29:30:37<5:37:39, 633.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1235.7121981534092
INFO:root:current train perplexity2.6540958881378174
INFO:root:current mean train loss 1239.619509986139
INFO:root:current train perplexity2.6509931087493896
INFO:root:current mean train loss 1242.2166427313114
INFO:root:current train perplexity2.6565818786621094
INFO:root:current mean train loss 1242.4575363803917
INFO:root:current train perplexity2.6569347381591797
INFO:root:current mean train loss 1241.2446243453812
INFO:root:current train perplexity2.657367467880249
INFO:root:current mean train loss 1242.2427646396397
INFO:root:current train perplexity2.659482002258301
INFO:root:current mean train loss 1242.5153769456704
INFO:root:current train perplexity2.6613919734954834
INFO:root:current mean train loss 1243.014516504553
INFO:root:current train perplexity2.6618874073028564
INFO:root:current mean train loss 1242.294811654788
INFO:root:current train perplexity2.6622183322906494
INFO:root:current mean train loss 1242.7528996492556
INFO:root:current train perplexity2.6626126766204834
INFO:root:current mean train loss 1242.6670295606857
INFO:root:current train perplexity2.6618876457214355
INFO:root:current mean train loss 1242.9908162963338
INFO:root:current train perplexity2.6623153686523438
INFO:root:current mean train loss 1244.1925804594123
INFO:root:current train perplexity2.662588596343994
INFO:root:current mean train loss 1244.1024736580373
INFO:root:current train perplexity2.66329288482666
INFO:root:current mean train loss 1244.080183415888
INFO:root:current train perplexity2.6647236347198486
INFO:root:current mean train loss 1244.3836009721665
INFO:root:current train perplexity2.666071891784668
INFO:root:current mean train loss 1244.4082332922253
INFO:root:current train perplexity2.66792631149292
INFO:root:current mean train loss 1244.2502999243234
INFO:root:current train perplexity2.668394088745117
INFO:root:current mean train loss 1244.5010772458306
INFO:root:current train perplexity2.6686182022094727
INFO:root:current mean train loss 1244.5136613226302
INFO:root:current train perplexity2.6681036949157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.44s/it]
INFO:root:final mean train loss: 1244.3551618813626
INFO:root:final train perplexity: 2.6681180000305176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2331.536207266733
INFO:root:eval perplexity: 6.590371608734131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2914.307647055768
INFO:root:eval perplexity: 10.841714859008789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [29:41:04<5:26:04, 631.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.0029432508682
INFO:root:current train perplexity2.6365609169006348
INFO:root:current mean train loss 1242.9915537279705
INFO:root:current train perplexity2.646211862564087
INFO:root:current mean train loss 1245.107328078326
INFO:root:current train perplexity2.653059720993042
INFO:root:current mean train loss 1244.752214657363
INFO:root:current train perplexity2.6574041843414307
INFO:root:current mean train loss 1243.830447956667
INFO:root:current train perplexity2.655425548553467
INFO:root:current mean train loss 1242.2726325188482
INFO:root:current train perplexity2.659122943878174
INFO:root:current mean train loss 1241.3739424205962
INFO:root:current train perplexity2.6582748889923096
INFO:root:current mean train loss 1241.9132062684687
INFO:root:current train perplexity2.6586661338806152
INFO:root:current mean train loss 1242.0920656536698
INFO:root:current train perplexity2.660170078277588
INFO:root:current mean train loss 1242.4040345242975
INFO:root:current train perplexity2.6610703468322754
INFO:root:current mean train loss 1241.299953517629
INFO:root:current train perplexity2.6602225303649902
INFO:root:current mean train loss 1241.894936623427
INFO:root:current train perplexity2.661807060241699
INFO:root:current mean train loss 1242.3746849395943
INFO:root:current train perplexity2.661271333694458
INFO:root:current mean train loss 1242.6048754811634
INFO:root:current train perplexity2.662714958190918
INFO:root:current mean train loss 1242.891799595045
INFO:root:current train perplexity2.6633048057556152
INFO:root:current mean train loss 1242.4898656791706
INFO:root:current train perplexity2.663461446762085
INFO:root:current mean train loss 1242.4503540331098
INFO:root:current train perplexity2.6639089584350586
INFO:root:current mean train loss 1242.7531601882142
INFO:root:current train perplexity2.664376974105835
INFO:root:current mean train loss 1243.2974992409731
INFO:root:current train perplexity2.6660256385803223
INFO:root:current mean train loss 1243.76542134314
INFO:root:current train perplexity2.666227102279663

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.26s/it]
INFO:root:final mean train loss: 1243.3775561203333
INFO:root:final train perplexity: 2.6660618782043457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2330.518444737644
INFO:root:eval perplexity: 6.584949016571045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2913.809575506981
INFO:root:eval perplexity: 10.837295532226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [29:51:28<5:14:34, 629.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1234.6771637991574
INFO:root:current train perplexity2.659066677093506
INFO:root:current mean train loss 1238.0425101789847
INFO:root:current train perplexity2.664820909500122
INFO:root:current mean train loss 1241.3082309181716
INFO:root:current train perplexity2.6598124504089355
INFO:root:current mean train loss 1242.0615312826358
INFO:root:current train perplexity2.658231019973755
INFO:root:current mean train loss 1242.187464552179
INFO:root:current train perplexity2.6619372367858887
INFO:root:current mean train loss 1240.7084635554834
INFO:root:current train perplexity2.660700559616089
INFO:root:current mean train loss 1241.1600253211743
INFO:root:current train perplexity2.6615359783172607
INFO:root:current mean train loss 1241.911357613722
INFO:root:current train perplexity2.661029815673828
INFO:root:current mean train loss 1242.0942763166568
INFO:root:current train perplexity2.6614558696746826
INFO:root:current mean train loss 1242.282892703528
INFO:root:current train perplexity2.660677194595337
INFO:root:current mean train loss 1241.9676088835802
INFO:root:current train perplexity2.660358190536499
INFO:root:current mean train loss 1241.501536402209
INFO:root:current train perplexity2.6602485179901123
INFO:root:current mean train loss 1241.649504502491
INFO:root:current train perplexity2.661057710647583
INFO:root:current mean train loss 1241.8456735082286
INFO:root:current train perplexity2.6618525981903076
INFO:root:current mean train loss 1241.4176637791722
INFO:root:current train perplexity2.661356210708618
INFO:root:current mean train loss 1241.7936166675681
INFO:root:current train perplexity2.662752151489258
INFO:root:current mean train loss 1241.9507014453588
INFO:root:current train perplexity2.6631274223327637
INFO:root:current mean train loss 1242.0044364950522
INFO:root:current train perplexity2.663562774658203
INFO:root:current mean train loss 1242.4505798759885
INFO:root:current train perplexity2.6633718013763428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.45s/it]
INFO:root:final mean train loss: 1242.7416580669578
INFO:root:final train perplexity: 2.6647250652313232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2329.7875006925974
INFO:root:eval perplexity: 6.581057548522949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2913.0672356355276
INFO:root:eval perplexity: 10.830718994140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [30:02:03<5:04:56, 630.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.0183919270833
INFO:root:current train perplexity2.6623270511627197
INFO:root:current mean train loss 1246.1693679521668
INFO:root:current train perplexity2.6452343463897705
INFO:root:current mean train loss 1240.2523377057419
INFO:root:current train perplexity2.6438300609588623
INFO:root:current mean train loss 1238.3628021439695
INFO:root:current train perplexity2.643726348876953
INFO:root:current mean train loss 1239.7975499947083
INFO:root:current train perplexity2.649423360824585
INFO:root:current mean train loss 1241.645177788414
INFO:root:current train perplexity2.652954339981079
INFO:root:current mean train loss 1240.471691169361
INFO:root:current train perplexity2.6520323753356934
INFO:root:current mean train loss 1239.808217164815
INFO:root:current train perplexity2.652759075164795
INFO:root:current mean train loss 1238.616184584852
INFO:root:current train perplexity2.65364408493042
INFO:root:current mean train loss 1238.687668958247
INFO:root:current train perplexity2.6543633937835693
INFO:root:current mean train loss 1238.751207112792
INFO:root:current train perplexity2.655585527420044
INFO:root:current mean train loss 1239.0198600451727
INFO:root:current train perplexity2.6560420989990234
INFO:root:current mean train loss 1239.7946754063341
INFO:root:current train perplexity2.656836748123169
INFO:root:current mean train loss 1240.340675529258
INFO:root:current train perplexity2.6571972370147705
INFO:root:current mean train loss 1241.3716338633812
INFO:root:current train perplexity2.6584980487823486
INFO:root:current mean train loss 1240.8808321401893
INFO:root:current train perplexity2.6588551998138428
INFO:root:current mean train loss 1241.5960586946899
INFO:root:current train perplexity2.659344434738159
INFO:root:current mean train loss 1241.85563990603
INFO:root:current train perplexity2.660379409790039
INFO:root:current mean train loss 1241.7777828246124
INFO:root:current train perplexity2.661311626434326
INFO:root:current mean train loss 1241.7015817007764
INFO:root:current train perplexity2.6612045764923096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.77s/it]
INFO:root:final mean train loss: 1241.4329588981932
INFO:root:final train perplexity: 2.6619763374328613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2333.8278773963875
INFO:root:eval perplexity: 6.602597236633301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 2917.429821690769
INFO:root:eval perplexity: 10.869428634643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [30:12:27<4:53:26, 628.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.7255647078805
INFO:root:current train perplexity2.6423821449279785
INFO:root:current mean train loss 1230.6934854150788
INFO:root:current train perplexity2.647789239883423
INFO:root:current mean train loss 1232.3430137463215
INFO:root:current train perplexity2.6558287143707275
INFO:root:current mean train loss 1231.6173390485924
INFO:root:current train perplexity2.6512856483459473
INFO:root:current mean train loss 1233.1915514068965
INFO:root:current train perplexity2.650768280029297
INFO:root:current mean train loss 1234.1699501168887
INFO:root:current train perplexity2.655494213104248
INFO:root:current mean train loss 1235.5313949952347
INFO:root:current train perplexity2.655611515045166
INFO:root:current mean train loss 1235.7214092080524
INFO:root:current train perplexity2.6555020809173584
INFO:root:current mean train loss 1236.9270455602598
INFO:root:current train perplexity2.6559689044952393
INFO:root:current mean train loss 1238.0708277610374
INFO:root:current train perplexity2.6560914516448975
INFO:root:current mean train loss 1238.2313903032975
INFO:root:current train perplexity2.655712604522705
INFO:root:current mean train loss 1237.7277700504021
INFO:root:current train perplexity2.6546053886413574
INFO:root:current mean train loss 1238.066988953585
INFO:root:current train perplexity2.6549594402313232
INFO:root:current mean train loss 1239.3080119091908
INFO:root:current train perplexity2.657227039337158
INFO:root:current mean train loss 1240.3610356023257
INFO:root:current train perplexity2.656864643096924
INFO:root:current mean train loss 1240.5912139351558
INFO:root:current train perplexity2.657823324203491
INFO:root:current mean train loss 1240.7227968226518
INFO:root:current train perplexity2.6586148738861084
INFO:root:current mean train loss 1240.5448968658181
INFO:root:current train perplexity2.6591076850891113
INFO:root:current mean train loss 1240.4119839566263
INFO:root:current train perplexity2.659853935241699
INFO:root:current mean train loss 1240.6666191208196
INFO:root:current train perplexity2.659996747970581

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it]
INFO:root:final mean train loss: 1240.523783766015
INFO:root:final train perplexity: 2.6600677967071533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2332.6555015618073
INFO:root:eval perplexity: 6.596339702606201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.77s/it]
INFO:root:eval mean loss: 2915.268092378657
INFO:root:eval perplexity: 10.850232124328613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [30:22:52<4:42:26, 627.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1233.1564514160157
INFO:root:current train perplexity2.655984878540039
INFO:root:current mean train loss 1236.953924560547
INFO:root:current train perplexity2.6564502716064453
INFO:root:current mean train loss 1240.0001159667968
INFO:root:current train perplexity2.6507928371429443
INFO:root:current mean train loss 1238.7570384306066
INFO:root:current train perplexity2.6496713161468506
INFO:root:current mean train loss 1237.700502985174
INFO:root:current train perplexity2.65177845954895
INFO:root:current mean train loss 1237.9522239402488
INFO:root:current train perplexity2.65214467048645
INFO:root:current mean train loss 1237.9733701705932
INFO:root:current train perplexity2.6516168117523193
INFO:root:current mean train loss 1238.436609876478
INFO:root:current train perplexity2.6505613327026367
INFO:root:current mean train loss 1237.377372233073
INFO:root:current train perplexity2.6512210369110107
INFO:root:current mean train loss 1237.6472954932678
INFO:root:current train perplexity2.652587413787842
INFO:root:current mean train loss 1237.7142742450421
INFO:root:current train perplexity2.6530873775482178
INFO:root:current mean train loss 1237.0676852042216
INFO:root:current train perplexity2.6535608768463135
INFO:root:current mean train loss 1237.4988933932398
INFO:root:current train perplexity2.6536173820495605
INFO:root:current mean train loss 1237.25211764663
INFO:root:current train perplexity2.6550960540771484
INFO:root:current mean train loss 1237.6370513068305
INFO:root:current train perplexity2.6557652950286865
INFO:root:current mean train loss 1238.052277324726
INFO:root:current train perplexity2.6564228534698486
INFO:root:current mean train loss 1238.43742765101
INFO:root:current train perplexity2.6571269035339355
INFO:root:current mean train loss 1239.0169309418777
INFO:root:current train perplexity2.657737970352173
INFO:root:current mean train loss 1238.9944795028023
INFO:root:current train perplexity2.657588481903076
INFO:root:current mean train loss 1239.2525737329856
INFO:root:current train perplexity2.6573073863983154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.04s/it]
INFO:root:final mean train loss: 1239.1605968542672
INFO:root:final train perplexity: 2.657209873199463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2335.881242468002
INFO:root:eval perplexity: 6.613569736480713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2919.30585106383
INFO:root:eval perplexity: 10.886117935180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [30:33:28<4:33:01, 630.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1236.9861246744792
INFO:root:current train perplexity2.6570889949798584
INFO:root:current mean train loss 1230.5587523636545
INFO:root:current train perplexity2.6469316482543945
INFO:root:current mean train loss 1232.7111099183792
INFO:root:current train perplexity2.646146059036255
INFO:root:current mean train loss 1234.3502156233587
INFO:root:current train perplexity2.6450979709625244
INFO:root:current mean train loss 1234.7262630671328
INFO:root:current train perplexity2.6435205936431885
INFO:root:current mean train loss 1234.3754994582446
INFO:root:current train perplexity2.646796226501465
INFO:root:current mean train loss 1234.293902021202
INFO:root:current train perplexity2.6479198932647705
INFO:root:current mean train loss 1234.2136952892793
INFO:root:current train perplexity2.647176504135132
INFO:root:current mean train loss 1234.505699700764
INFO:root:current train perplexity2.6488118171691895
INFO:root:current mean train loss 1235.6106073106469
INFO:root:current train perplexity2.649683713912964
INFO:root:current mean train loss 1235.1827710168816
INFO:root:current train perplexity2.649446725845337
INFO:root:current mean train loss 1234.9109596773376
INFO:root:current train perplexity2.649378538131714
INFO:root:current mean train loss 1236.1046001765114
INFO:root:current train perplexity2.650055408477783
INFO:root:current mean train loss 1236.4381921215802
INFO:root:current train perplexity2.650193452835083
INFO:root:current mean train loss 1236.3862969916245
INFO:root:current train perplexity2.6504552364349365
INFO:root:current mean train loss 1236.7801693994109
INFO:root:current train perplexity2.6506643295288086
INFO:root:current mean train loss 1237.096793212154
INFO:root:current train perplexity2.6514968872070312
INFO:root:current mean train loss 1237.7009034870562
INFO:root:current train perplexity2.6530113220214844
INFO:root:current mean train loss 1237.7995547621751
INFO:root:current train perplexity2.652611255645752
INFO:root:current mean train loss 1238.05309871465
INFO:root:current train perplexity2.6538705825805664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.57s/it]
INFO:root:final mean train loss: 1237.7043287745644
INFO:root:final train perplexity: 2.6541597843170166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2335.261830864223
INFO:root:eval perplexity: 6.610257625579834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2919.7915129965922
INFO:root:eval perplexity: 10.890442848205566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [30:43:54<4:22:00, 628.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1238.0174379091004
INFO:root:current train perplexity2.6456921100616455
INFO:root:current mean train loss 1233.9888228493176
INFO:root:current train perplexity2.6387622356414795
INFO:root:current mean train loss 1229.247235597485
INFO:root:current train perplexity2.644317626953125
INFO:root:current mean train loss 1229.582700025589
INFO:root:current train perplexity2.6448566913604736
INFO:root:current mean train loss 1230.7182818062697
INFO:root:current train perplexity2.6455190181732178
INFO:root:current mean train loss 1232.0613145994391
INFO:root:current train perplexity2.64654541015625
INFO:root:current mean train loss 1233.2201462018384
INFO:root:current train perplexity2.648010015487671
INFO:root:current mean train loss 1233.9129069325843
INFO:root:current train perplexity2.6475279331207275
INFO:root:current mean train loss 1234.6877899519093
INFO:root:current train perplexity2.6489880084991455
INFO:root:current mean train loss 1234.8481624532774
INFO:root:current train perplexity2.649245023727417
INFO:root:current mean train loss 1234.8506609527758
INFO:root:current train perplexity2.64983868598938
INFO:root:current mean train loss 1235.6187002776633
INFO:root:current train perplexity2.6501543521881104
INFO:root:current mean train loss 1236.3783209065627
INFO:root:current train perplexity2.6510426998138428
INFO:root:current mean train loss 1236.1068833085994
INFO:root:current train perplexity2.650327444076538
INFO:root:current mean train loss 1236.5061551097938
INFO:root:current train perplexity2.6511683464050293
INFO:root:current mean train loss 1236.5816649615083
INFO:root:current train perplexity2.65193510055542
INFO:root:current mean train loss 1237.0463623630246
INFO:root:current train perplexity2.6529831886291504
INFO:root:current mean train loss 1237.4319755958463
INFO:root:current train perplexity2.6536121368408203
INFO:root:current mean train loss 1237.632977757408
INFO:root:current train perplexity2.6537649631500244
INFO:root:current mean train loss 1237.7322088394242
INFO:root:current train perplexity2.653231382369995

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.98s/it]
INFO:root:final mean train loss: 1237.344358289356
INFO:root:final train perplexity: 2.6534063816070557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2337.8135592413287
INFO:root:eval perplexity: 6.623913764953613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 2923.2537136213155
INFO:root:eval perplexity: 10.921324729919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [30:54:16<4:10:45, 626.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.5423449841173
INFO:root:current train perplexity2.65287709236145
INFO:root:current mean train loss 1233.2981608925065
INFO:root:current train perplexity2.6512203216552734
INFO:root:current mean train loss 1233.7268817285492
INFO:root:current train perplexity2.6506478786468506
INFO:root:current mean train loss 1234.762957872942
INFO:root:current train perplexity2.6477267742156982
INFO:root:current mean train loss 1234.8762033000255
INFO:root:current train perplexity2.6491825580596924
INFO:root:current mean train loss 1236.026184804952
INFO:root:current train perplexity2.650529384613037
INFO:root:current mean train loss 1236.5791123386057
INFO:root:current train perplexity2.6507303714752197
INFO:root:current mean train loss 1236.5781533956226
INFO:root:current train perplexity2.6528091430664062
INFO:root:current mean train loss 1236.278057676373
INFO:root:current train perplexity2.6516683101654053
INFO:root:current mean train loss 1236.406950764892
INFO:root:current train perplexity2.649951696395874
INFO:root:current mean train loss 1235.5222617760369
INFO:root:current train perplexity2.6502175331115723
INFO:root:current mean train loss 1235.9697586431112
INFO:root:current train perplexity2.649826765060425
INFO:root:current mean train loss 1235.9563271945804
INFO:root:current train perplexity2.6503920555114746
INFO:root:current mean train loss 1235.9344041002987
INFO:root:current train perplexity2.6503207683563232
INFO:root:current mean train loss 1236.0090861739448
INFO:root:current train perplexity2.65065598487854
INFO:root:current mean train loss 1236.3245607923966
INFO:root:current train perplexity2.651076316833496
INFO:root:current mean train loss 1236.5259421431476
INFO:root:current train perplexity2.651404619216919
INFO:root:current mean train loss 1236.6188485014045
INFO:root:current train perplexity2.651726722717285
INFO:root:current mean train loss 1236.4061374190244
INFO:root:current train perplexity2.651583194732666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.78s/it]
INFO:root:final mean train loss: 1236.6965681990769
INFO:root:final train perplexity: 2.6520509719848633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2337.9600150466813
INFO:root:eval perplexity: 6.624698638916016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2923.660786513741
INFO:root:eval perplexity: 10.924962997436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [31:04:38<3:59:45, 625.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1220.1206665039062
INFO:root:current train perplexity2.6584908962249756
INFO:root:current mean train loss 1242.5022356951679
INFO:root:current train perplexity2.6583340167999268
INFO:root:current mean train loss 1239.0284969623272
INFO:root:current train perplexity2.656494379043579
INFO:root:current mean train loss 1234.0516246448863
INFO:root:current train perplexity2.652824878692627
INFO:root:current mean train loss 1234.4594164081648
INFO:root:current train perplexity2.6498210430145264
INFO:root:current mean train loss 1234.0065230722503
INFO:root:current train perplexity2.6503920555114746
INFO:root:current mean train loss 1234.6932985406172
INFO:root:current train perplexity2.6528308391571045
INFO:root:current mean train loss 1236.2365041614253
INFO:root:current train perplexity2.6525471210479736
INFO:root:current mean train loss 1235.359877331422
INFO:root:current train perplexity2.6499786376953125
INFO:root:current mean train loss 1235.7138880254938
INFO:root:current train perplexity2.651336193084717
INFO:root:current mean train loss 1235.9830721900576
INFO:root:current train perplexity2.6505367755889893
INFO:root:current mean train loss 1236.019332500141
INFO:root:current train perplexity2.651737928390503
INFO:root:current mean train loss 1235.636096373299
INFO:root:current train perplexity2.650987386703491
INFO:root:current mean train loss 1235.3527260876576
INFO:root:current train perplexity2.65083384513855
INFO:root:current mean train loss 1235.5216532620516
INFO:root:current train perplexity2.6500465869903564
INFO:root:current mean train loss 1235.140388225687
INFO:root:current train perplexity2.6499927043914795
INFO:root:current mean train loss 1235.1705889345994
INFO:root:current train perplexity2.650627374649048
INFO:root:current mean train loss 1235.4792615546555
INFO:root:current train perplexity2.6509549617767334
INFO:root:current mean train loss 1235.8125183645602
INFO:root:current train perplexity2.6506612300872803
INFO:root:current mean train loss 1236.3158948726375
INFO:root:current train perplexity2.6504151821136475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.74s/it]
INFO:root:final mean train loss: 1235.8083125819958
INFO:root:final train perplexity: 2.650193929672241
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 2338.418027620789
INFO:root:eval perplexity: 6.627151966094971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2923.9507441960327
INFO:root:eval perplexity: 10.927552223205566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [31:15:15<3:50:34, 628.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1224.794560546875
INFO:root:current train perplexity2.681992769241333
INFO:root:current mean train loss 1226.3605126953125
INFO:root:current train perplexity2.6433229446411133
INFO:root:current mean train loss 1232.7189561631944
INFO:root:current train perplexity2.6409382820129395
INFO:root:current mean train loss 1230.2213788311299
INFO:root:current train perplexity2.641418933868408
INFO:root:current mean train loss 1229.9578716681985
INFO:root:current train perplexity2.6412558555603027
INFO:root:current mean train loss 1231.0451690383184
INFO:root:current train perplexity2.641841173171997
INFO:root:current mean train loss 1230.96326328125
INFO:root:current train perplexity2.643071174621582
INFO:root:current mean train loss 1230.5274838362068
INFO:root:current train perplexity2.642855644226074
INFO:root:current mean train loss 1230.7040826231062
INFO:root:current train perplexity2.6445157527923584
INFO:root:current mean train loss 1231.7153882495777
INFO:root:current train perplexity2.645075798034668
INFO:root:current mean train loss 1232.6801006335747
INFO:root:current train perplexity2.645002603530884
INFO:root:current mean train loss 1232.5215006510416
INFO:root:current train perplexity2.6448311805725098
INFO:root:current mean train loss 1232.5042379823024
INFO:root:current train perplexity2.6459615230560303
INFO:root:current mean train loss 1233.7107822634139
INFO:root:current train perplexity2.6465394496917725
INFO:root:current mean train loss 1233.89944044682
INFO:root:current train perplexity2.645738124847412
INFO:root:current mean train loss 1233.7305436731558
INFO:root:current train perplexity2.6464836597442627
INFO:root:current mean train loss 1234.1925691105769
INFO:root:current train perplexity2.646083354949951
INFO:root:current mean train loss 1234.0880123414854
INFO:root:current train perplexity2.6462862491607666
INFO:root:current mean train loss 1233.981865234375
INFO:root:current train perplexity2.6470417976379395
INFO:root:current mean train loss 1234.5503027977882
INFO:root:current train perplexity2.6472949981689453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.69s/it]
INFO:root:final mean train loss: 1234.606876282877
INFO:root:final train perplexity: 2.64768385887146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2340.2037336200688
INFO:root:eval perplexity: 6.636730194091797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2926.541677488503
INFO:root:eval perplexity: 10.950730323791504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [31:25:39<3:39:37, 627.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1227.8982311430432
INFO:root:current train perplexity2.626457691192627
INFO:root:current mean train loss 1224.2161727690361
INFO:root:current train perplexity2.623098373413086
INFO:root:current mean train loss 1226.6984898590845
INFO:root:current train perplexity2.623487710952759
INFO:root:current mean train loss 1227.6228155838817
INFO:root:current train perplexity2.6307268142700195
INFO:root:current mean train loss 1227.9423695559956
INFO:root:current train perplexity2.634934663772583
INFO:root:current mean train loss 1229.3674050644315
INFO:root:current train perplexity2.6358754634857178
INFO:root:current mean train loss 1228.4708970684871
INFO:root:current train perplexity2.6356797218322754
INFO:root:current mean train loss 1228.6446725685962
INFO:root:current train perplexity2.6372828483581543
INFO:root:current mean train loss 1229.1706306656863
INFO:root:current train perplexity2.6391148567199707
INFO:root:current mean train loss 1228.6629085338293
INFO:root:current train perplexity2.638503074645996
INFO:root:current mean train loss 1229.4643094287953
INFO:root:current train perplexity2.639861583709717
INFO:root:current mean train loss 1230.77116348614
INFO:root:current train perplexity2.64070200920105
INFO:root:current mean train loss 1231.0390069688192
INFO:root:current train perplexity2.6418275833129883
INFO:root:current mean train loss 1231.6630396381042
INFO:root:current train perplexity2.6417386531829834
INFO:root:current mean train loss 1232.7076362683936
INFO:root:current train perplexity2.643028974533081
INFO:root:current mean train loss 1233.4458869904395
INFO:root:current train perplexity2.643601179122925
INFO:root:current mean train loss 1233.289496808627
INFO:root:current train perplexity2.6445059776306152
INFO:root:current mean train loss 1232.9413638547421
INFO:root:current train perplexity2.644007682800293
INFO:root:current mean train loss 1233.0582314490237
INFO:root:current train perplexity2.6438729763031006
INFO:root:current mean train loss 1233.520930721389
INFO:root:current train perplexity2.644930362701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.02s/it]
INFO:root:final mean train loss: 1233.0543694585126
INFO:root:final train perplexity: 2.644444227218628
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2342.1445905536625
INFO:root:eval perplexity: 6.647155284881592
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2928.0310742533798
INFO:root:eval perplexity: 10.964079856872559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [31:36:02<3:28:38, 625.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1226.012552552304
INFO:root:current train perplexity2.606081008911133
INFO:root:current mean train loss 1235.4249129385319
INFO:root:current train perplexity2.629305124282837
INFO:root:current mean train loss 1231.7101753853462
INFO:root:current train perplexity2.6322782039642334
INFO:root:current mean train loss 1230.3824231671092
INFO:root:current train perplexity2.6321892738342285
INFO:root:current mean train loss 1229.7536355145357
INFO:root:current train perplexity2.6312618255615234
INFO:root:current mean train loss 1228.690022422504
INFO:root:current train perplexity2.6338350772857666
INFO:root:current mean train loss 1230.4728244439966
INFO:root:current train perplexity2.6344141960144043
INFO:root:current mean train loss 1230.5521375331955
INFO:root:current train perplexity2.6332650184631348
INFO:root:current mean train loss 1229.938319817966
INFO:root:current train perplexity2.6333773136138916
INFO:root:current mean train loss 1229.3637767867326
INFO:root:current train perplexity2.6355321407318115
INFO:root:current mean train loss 1228.5852220227293
INFO:root:current train perplexity2.6358370780944824
INFO:root:current mean train loss 1228.8999381538504
INFO:root:current train perplexity2.637723684310913
INFO:root:current mean train loss 1229.8019173086589
INFO:root:current train perplexity2.6387860774993896
INFO:root:current mean train loss 1229.8253484617883
INFO:root:current train perplexity2.6385958194732666
INFO:root:current mean train loss 1230.1372257726825
INFO:root:current train perplexity2.6382272243499756
INFO:root:current mean train loss 1230.9166565920161
INFO:root:current train perplexity2.640566825866699
INFO:root:current mean train loss 1231.3732679848788
INFO:root:current train perplexity2.6403353214263916
INFO:root:current mean train loss 1231.861575110925
INFO:root:current train perplexity2.640805244445801
INFO:root:current mean train loss 1232.121929921791
INFO:root:current train perplexity2.6414453983306885
INFO:root:current mean train loss 1232.1714828047234
INFO:root:current train perplexity2.641765832901001

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.03s/it]
INFO:root:final mean train loss: 1231.8745634585875
INFO:root:final train perplexity: 2.6419849395751953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 2342.2141273444427
INFO:root:eval perplexity: 6.6475300788879395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2928.010188542359
INFO:root:eval perplexity: 10.963891983032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [31:46:37<3:19:05, 628.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.315972579153
INFO:root:current train perplexity2.6247692108154297
INFO:root:current mean train loss 1228.7159181074662
INFO:root:current train perplexity2.6322731971740723
INFO:root:current mean train loss 1229.9546601668649
INFO:root:current train perplexity2.6333467960357666
INFO:root:current mean train loss 1227.5974484707447
INFO:root:current train perplexity2.634275197982788
INFO:root:current mean train loss 1228.3054581329602
INFO:root:current train perplexity2.6374056339263916
INFO:root:current mean train loss 1229.3171730041504
INFO:root:current train perplexity2.635460376739502
INFO:root:current mean train loss 1228.444735194099
INFO:root:current train perplexity2.635050058364868
INFO:root:current mean train loss 1229.7126254052232
INFO:root:current train perplexity2.6373181343078613
INFO:root:current mean train loss 1229.9435632435698
INFO:root:current train perplexity2.639785051345825
INFO:root:current mean train loss 1229.0682953381147
INFO:root:current train perplexity2.6394143104553223
INFO:root:current mean train loss 1229.1600057041778
INFO:root:current train perplexity2.6392829418182373
INFO:root:current mean train loss 1229.7382025686252
INFO:root:current train perplexity2.639392852783203
INFO:root:current mean train loss 1230.4544896810405
INFO:root:current train perplexity2.6400153636932373
INFO:root:current mean train loss 1230.5760425301485
INFO:root:current train perplexity2.640072822570801
INFO:root:current mean train loss 1230.980912288676
INFO:root:current train perplexity2.6405882835388184
INFO:root:current mean train loss 1231.8155847539756
INFO:root:current train perplexity2.6414456367492676
INFO:root:current mean train loss 1232.321192994038
INFO:root:current train perplexity2.6426451206207275
INFO:root:current mean train loss 1232.3824772877736
INFO:root:current train perplexity2.6411783695220947
INFO:root:current mean train loss 1231.9506481308927
INFO:root:current train perplexity2.6403889656066895
INFO:root:current mean train loss 1232.0321476121662
INFO:root:current train perplexity2.641718864440918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.67s/it]
INFO:root:final mean train loss: 1231.7513122096905
INFO:root:final train perplexity: 2.6417276859283447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2343.8806658805684
INFO:root:eval perplexity: 6.656494140625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2929.3720949862864
INFO:root:eval perplexity: 10.97610855102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [31:57:03<3:08:21, 627.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1235.2954849735384
INFO:root:current train perplexity2.6365528106689453
INFO:root:current mean train loss 1231.3221713841888
INFO:root:current train perplexity2.6302711963653564
INFO:root:current mean train loss 1229.2170443486027
INFO:root:current train perplexity2.6276931762695312
INFO:root:current mean train loss 1229.114300987496
INFO:root:current train perplexity2.6322360038757324
INFO:root:current mean train loss 1230.4942092121735
INFO:root:current train perplexity2.6328394412994385
INFO:root:current mean train loss 1229.4798409010066
INFO:root:current train perplexity2.63446044921875
INFO:root:current mean train loss 1229.7067192925347
INFO:root:current train perplexity2.6380672454833984
INFO:root:current mean train loss 1230.9548064300423
INFO:root:current train perplexity2.6391587257385254
INFO:root:current mean train loss 1230.5208276831956
INFO:root:current train perplexity2.6382322311401367
INFO:root:current mean train loss 1229.9051866483353
INFO:root:current train perplexity2.638720989227295
INFO:root:current mean train loss 1230.1000190309069
INFO:root:current train perplexity2.6399049758911133
INFO:root:current mean train loss 1229.9302575366396
INFO:root:current train perplexity2.638862371444702
INFO:root:current mean train loss 1229.7424169128842
INFO:root:current train perplexity2.638897180557251
INFO:root:current mean train loss 1230.2124439685874
INFO:root:current train perplexity2.6386871337890625
INFO:root:current mean train loss 1229.879328958316
INFO:root:current train perplexity2.637969970703125
INFO:root:current mean train loss 1230.5633528063452
INFO:root:current train perplexity2.6391680240631104
INFO:root:current mean train loss 1230.6832847888134
INFO:root:current train perplexity2.639163017272949
INFO:root:current mean train loss 1230.7704371437972
INFO:root:current train perplexity2.639320135116577
INFO:root:current mean train loss 1231.0898040916577
INFO:root:current train perplexity2.6390035152435303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.15s/it]
INFO:root:final mean train loss: 1230.59405985422
INFO:root:final train perplexity: 2.639317750930786
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 2343.3383992513022
INFO:root:eval perplexity: 6.653575420379639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2928.868541095274
INFO:root:eval perplexity: 10.971592903137207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [32:07:41<2:58:48, 631.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1233.797021484375
INFO:root:current train perplexity2.5886154174804688
INFO:root:current mean train loss 1227.8139825994317
INFO:root:current train perplexity2.6181726455688477
INFO:root:current mean train loss 1229.7479858398438
INFO:root:current train perplexity2.630176305770874
INFO:root:current mean train loss 1227.756987934728
INFO:root:current train perplexity2.633164167404175
INFO:root:current mean train loss 1228.4856105897484
INFO:root:current train perplexity2.638303279876709
INFO:root:current mean train loss 1228.8966471354167
INFO:root:current train perplexity2.641030788421631
INFO:root:current mean train loss 1229.498766489498
INFO:root:current train perplexity2.6403636932373047
INFO:root:current mean train loss 1229.3666469520247
INFO:root:current train perplexity2.6391358375549316
INFO:root:current mean train loss 1228.9410079390914
INFO:root:current train perplexity2.638209104537964
INFO:root:current mean train loss 1228.897099019145
INFO:root:current train perplexity2.63745379447937
INFO:root:current mean train loss 1228.9026237865485
INFO:root:current train perplexity2.637982130050659
INFO:root:current mean train loss 1229.0994324280334
INFO:root:current train perplexity2.6385035514831543
INFO:root:current mean train loss 1229.9177973471396
INFO:root:current train perplexity2.636678695678711
INFO:root:current mean train loss 1230.047372506411
INFO:root:current train perplexity2.636629819869995
INFO:root:current mean train loss 1230.3150188905972
INFO:root:current train perplexity2.6365163326263428
INFO:root:current mean train loss 1229.8860526988049
INFO:root:current train perplexity2.6353061199188232
INFO:root:current mean train loss 1229.2231556768002
INFO:root:current train perplexity2.6345272064208984
INFO:root:current mean train loss 1229.4047457510965
INFO:root:current train perplexity2.6349995136260986
INFO:root:current mean train loss 1228.9702454624914
INFO:root:current train perplexity2.6349639892578125
INFO:root:current mean train loss 1229.0731831335897
INFO:root:current train perplexity2.6359338760375977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.35s/it]
INFO:root:final mean train loss: 1229.0262761734016
INFO:root:final train perplexity: 2.636056423187256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2344.678617436835
INFO:root:eval perplexity: 6.660792350769043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 2930.4502797228224
INFO:root:eval perplexity: 10.985793113708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [32:18:06<2:47:47, 629.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1223.123910409433
INFO:root:current train perplexity2.628133773803711
INFO:root:current mean train loss 1225.4073601670152
INFO:root:current train perplexity2.634584665298462
INFO:root:current mean train loss 1227.4919428216203
INFO:root:current train perplexity2.633479356765747
INFO:root:current mean train loss 1225.2054036458333
INFO:root:current train perplexity2.6235759258270264
INFO:root:current mean train loss 1224.8852407558181
INFO:root:current train perplexity2.6242496967315674
INFO:root:current mean train loss 1223.9865539666598
INFO:root:current train perplexity2.6261308193206787
INFO:root:current mean train loss 1225.5500122265003
INFO:root:current train perplexity2.6256182193756104
INFO:root:current mean train loss 1226.400696892194
INFO:root:current train perplexity2.6265876293182373
INFO:root:current mean train loss 1227.1797468376851
INFO:root:current train perplexity2.629333972930908
INFO:root:current mean train loss 1228.0294668779918
INFO:root:current train perplexity2.6317028999328613
INFO:root:current mean train loss 1228.1216185215965
INFO:root:current train perplexity2.6350557804107666
INFO:root:current mean train loss 1228.5825719554125
INFO:root:current train perplexity2.6347715854644775
INFO:root:current mean train loss 1228.9905737244997
INFO:root:current train perplexity2.6350386142730713
INFO:root:current mean train loss 1228.9394580004532
INFO:root:current train perplexity2.635655164718628
INFO:root:current mean train loss 1228.9023303196993
INFO:root:current train perplexity2.635852098464966
INFO:root:current mean train loss 1229.4036540672837
INFO:root:current train perplexity2.6357500553131104
INFO:root:current mean train loss 1229.659570207461
INFO:root:current train perplexity2.636094570159912
INFO:root:current mean train loss 1229.1661244068246
INFO:root:current train perplexity2.6360042095184326
INFO:root:current mean train loss 1229.2508460735453
INFO:root:current train perplexity2.636049270629883
INFO:root:current mean train loss 1229.5309508105418
INFO:root:current train perplexity2.6356799602508545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:35<00:00, 575.26s/it]
INFO:root:final mean train loss: 1228.9479832728584
INFO:root:final train perplexity: 2.6358938217163086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2346.3099962599736
INFO:root:eval perplexity: 6.66958475112915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2932.5265935803136
INFO:root:eval perplexity: 11.004462242126465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [32:28:57<2:38:56, 635.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.0257013494318
INFO:root:current train perplexity2.6410934925079346
INFO:root:current mean train loss 1226.8521931966145
INFO:root:current train perplexity2.6327285766601562
INFO:root:current mean train loss 1226.8790008044634
INFO:root:current train perplexity2.6320366859436035
INFO:root:current mean train loss 1227.4822650288427
INFO:root:current train perplexity2.63252592086792
INFO:root:current mean train loss 1227.4791655669342
INFO:root:current train perplexity2.6330554485321045
INFO:root:current mean train loss 1226.1337693158318
INFO:root:current train perplexity2.634376287460327
INFO:root:current mean train loss 1225.2535136915883
INFO:root:current train perplexity2.6323049068450928
INFO:root:current mean train loss 1225.5411444223055
INFO:root:current train perplexity2.6310486793518066
INFO:root:current mean train loss 1227.9436286817795
INFO:root:current train perplexity2.6315414905548096
INFO:root:current mean train loss 1227.2097607628773
INFO:root:current train perplexity2.6317927837371826
INFO:root:current mean train loss 1227.6511595276581
INFO:root:current train perplexity2.631331205368042
INFO:root:current mean train loss 1228.3467398690177
INFO:root:current train perplexity2.6308107376098633
INFO:root:current mean train loss 1228.3968783559524
INFO:root:current train perplexity2.63130784034729
INFO:root:current mean train loss 1227.9616797310966
INFO:root:current train perplexity2.6304965019226074
INFO:root:current mean train loss 1228.654066175635
INFO:root:current train perplexity2.632281541824341
INFO:root:current mean train loss 1228.3780242445555
INFO:root:current train perplexity2.632415771484375
INFO:root:current mean train loss 1227.9864916279369
INFO:root:current train perplexity2.632552146911621
INFO:root:current mean train loss 1228.026595929347
INFO:root:current train perplexity2.633204460144043
INFO:root:current mean train loss 1228.4067588028317
INFO:root:current train perplexity2.634169340133667
INFO:root:current mean train loss 1228.3130785153237
INFO:root:current train perplexity2.6343579292297363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.65s/it]
INFO:root:final mean train loss: 1228.238122583217
INFO:root:final train perplexity: 2.634418487548828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2344.4650294527096
INFO:root:eval perplexity: 6.659640312194824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2930.7097445007757
INFO:root:eval perplexity: 10.988121032714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [32:39:21<2:27:30, 632.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.5729920434171
INFO:root:current train perplexity2.6208508014678955
INFO:root:current mean train loss 1234.5490161587734
INFO:root:current train perplexity2.628848075866699
INFO:root:current mean train loss 1232.454310625449
INFO:root:current train perplexity2.6289572715759277
INFO:root:current mean train loss 1230.9762936747966
INFO:root:current train perplexity2.632145404815674
INFO:root:current mean train loss 1229.1012209149608
INFO:root:current train perplexity2.63019061088562
INFO:root:current mean train loss 1230.0835102373692
INFO:root:current train perplexity2.6314315795898438
INFO:root:current mean train loss 1229.1494386243028
INFO:root:current train perplexity2.632173538208008
INFO:root:current mean train loss 1227.8915685184995
INFO:root:current train perplexity2.6335601806640625
INFO:root:current mean train loss 1228.4249147067364
INFO:root:current train perplexity2.634397506713867
INFO:root:current mean train loss 1227.1421886686232
INFO:root:current train perplexity2.63275408744812
INFO:root:current mean train loss 1227.0057071610288
INFO:root:current train perplexity2.632286548614502
INFO:root:current mean train loss 1226.5483612927972
INFO:root:current train perplexity2.631847858428955
INFO:root:current mean train loss 1226.4516123348906
INFO:root:current train perplexity2.632337808609009
INFO:root:current mean train loss 1227.7550667700393
INFO:root:current train perplexity2.6331233978271484
INFO:root:current mean train loss 1228.1924229177362
INFO:root:current train perplexity2.6314315795898438
INFO:root:current mean train loss 1228.3271871465356
INFO:root:current train perplexity2.6324596405029297
INFO:root:current mean train loss 1228.1612792821766
INFO:root:current train perplexity2.6333234310150146
INFO:root:current mean train loss 1227.885011914506
INFO:root:current train perplexity2.6329128742218018
INFO:root:current mean train loss 1227.5998671591635
INFO:root:current train perplexity2.632185935974121
INFO:root:current mean train loss 1227.592342363092
INFO:root:current train perplexity2.632619619369507

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it]
INFO:root:final mean train loss: 1227.244746144228
INFO:root:final train perplexity: 2.6323556900024414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2346.214124747202
INFO:root:eval perplexity: 6.669068813323975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2933.063509028009
INFO:root:eval perplexity: 11.009293556213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [32:49:46<2:16:29, 629.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1217.4451779096555
INFO:root:current train perplexity2.6400551795959473
INFO:root:current mean train loss 1224.2658705122014
INFO:root:current train perplexity2.6347286701202393
INFO:root:current mean train loss 1224.253167680699
INFO:root:current train perplexity2.6247689723968506
INFO:root:current mean train loss 1224.4054055188699
INFO:root:current train perplexity2.6241419315338135
INFO:root:current mean train loss 1223.2568287869378
INFO:root:current train perplexity2.6241695880889893
INFO:root:current mean train loss 1223.4138912214128
INFO:root:current train perplexity2.6263604164123535
INFO:root:current mean train loss 1223.299230524924
INFO:root:current train perplexity2.626680850982666
INFO:root:current mean train loss 1223.703415426926
INFO:root:current train perplexity2.6254124641418457
INFO:root:current mean train loss 1223.8355030242294
INFO:root:current train perplexity2.6272709369659424
INFO:root:current mean train loss 1224.808806436925
INFO:root:current train perplexity2.6280276775360107
INFO:root:current mean train loss 1225.0509021879348
INFO:root:current train perplexity2.6290783882141113
INFO:root:current mean train loss 1225.2427877999323
INFO:root:current train perplexity2.6294100284576416
INFO:root:current mean train loss 1226.237913988379
INFO:root:current train perplexity2.6295347213745117
INFO:root:current mean train loss 1226.658542937568
INFO:root:current train perplexity2.628592014312744
INFO:root:current mean train loss 1226.9135073195937
INFO:root:current train perplexity2.629262685775757
INFO:root:current mean train loss 1226.8213281280944
INFO:root:current train perplexity2.6283352375030518
INFO:root:current mean train loss 1226.3926374869636
INFO:root:current train perplexity2.6278626918792725
INFO:root:current mean train loss 1226.5593140197686
INFO:root:current train perplexity2.62849497795105
INFO:root:current mean train loss 1226.9390377739367
INFO:root:current train perplexity2.629934310913086
INFO:root:current mean train loss 1226.7590593698653
INFO:root:current train perplexity2.630547046661377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.43s/it]
INFO:root:final mean train loss: 1226.4619896869976
INFO:root:final train perplexity: 2.6307308673858643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2347.3730338887967
INFO:root:eval perplexity: 6.67532205581665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.07s/it]
INFO:root:eval mean loss: 2934.2863280384254
INFO:root:eval perplexity: 11.020310401916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [33:00:10<2:05:39, 628.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1225.0453266344573
INFO:root:current train perplexity2.629786491394043
INFO:root:current mean train loss 1224.2819874298877
INFO:root:current train perplexity2.617830991744995
INFO:root:current mean train loss 1224.863917257018
INFO:root:current train perplexity2.615077018737793
INFO:root:current mean train loss 1223.620753498319
INFO:root:current train perplexity2.613755226135254
INFO:root:current mean train loss 1225.3144977608113
INFO:root:current train perplexity2.619549512863159
INFO:root:current mean train loss 1224.94644088104
INFO:root:current train perplexity2.6213297843933105
INFO:root:current mean train loss 1224.3139190015174
INFO:root:current train perplexity2.6210777759552
INFO:root:current mean train loss 1224.085945945116
INFO:root:current train perplexity2.6218960285186768
INFO:root:current mean train loss 1223.8111840956703
INFO:root:current train perplexity2.6212830543518066
INFO:root:current mean train loss 1224.7727842091315
INFO:root:current train perplexity2.6224594116210938
INFO:root:current mean train loss 1224.8146825502997
INFO:root:current train perplexity2.624453544616699
INFO:root:current mean train loss 1225.1310880908406
INFO:root:current train perplexity2.625138521194458
INFO:root:current mean train loss 1224.6160961254222
INFO:root:current train perplexity2.6255581378936768
INFO:root:current mean train loss 1224.6509379725303
INFO:root:current train perplexity2.626826524734497
INFO:root:current mean train loss 1225.332616942543
INFO:root:current train perplexity2.627652406692505
INFO:root:current mean train loss 1225.3944487473061
INFO:root:current train perplexity2.6286494731903076
INFO:root:current mean train loss 1226.0302009154914
INFO:root:current train perplexity2.6290485858917236
INFO:root:current mean train loss 1226.1973511762274
INFO:root:current train perplexity2.6300156116485596
INFO:root:current mean train loss 1226.2045312242333
INFO:root:current train perplexity2.630577325820923

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.84s/it]
INFO:root:final mean train loss: 1226.1415565325285
INFO:root:final train perplexity: 2.630066156387329
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2347.5094569862313
INFO:root:eval perplexity: 6.676058292388916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2935.04306787802
INFO:root:eval perplexity: 11.02713394165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [33:10:57<1:56:12, 633.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1222.4149271647136
INFO:root:current train perplexity2.623291492462158
INFO:root:current mean train loss 1218.8155321393695
INFO:root:current train perplexity2.6058478355407715
INFO:root:current mean train loss 1218.9381811753758
INFO:root:current train perplexity2.618177652359009
INFO:root:current mean train loss 1220.017857869466
INFO:root:current train perplexity2.6175644397735596
INFO:root:current mean train loss 1219.9206048169183
INFO:root:current train perplexity2.617753267288208
INFO:root:current mean train loss 1220.2337908744812
INFO:root:current train perplexity2.6213574409484863
INFO:root:current mean train loss 1222.5953961540672
INFO:root:current train perplexity2.6211376190185547
INFO:root:current mean train loss 1223.5478047574504
INFO:root:current train perplexity2.6228222846984863
INFO:root:current mean train loss 1224.0314585117283
INFO:root:current train perplexity2.6253809928894043
INFO:root:current mean train loss 1222.8128556368645
INFO:root:current train perplexity2.625816822052002
INFO:root:current mean train loss 1223.3548662389219
INFO:root:current train perplexity2.62552809715271
INFO:root:current mean train loss 1223.8344177685196
INFO:root:current train perplexity2.6252548694610596
INFO:root:current mean train loss 1224.3951026236657
INFO:root:current train perplexity2.6252713203430176
INFO:root:current mean train loss 1224.239137044767
INFO:root:current train perplexity2.6259703636169434
INFO:root:current mean train loss 1224.7641000720664
INFO:root:current train perplexity2.6270692348480225
INFO:root:current mean train loss 1225.1272039665746
INFO:root:current train perplexity2.6269922256469727
INFO:root:current mean train loss 1224.9536197936861
INFO:root:current train perplexity2.6276674270629883
INFO:root:current mean train loss 1224.9191135156934
INFO:root:current train perplexity2.6273274421691895
INFO:root:current mean train loss 1225.1778435107099
INFO:root:current train perplexity2.627596855163574
INFO:root:current mean train loss 1225.37943545545
INFO:root:current train perplexity2.6281702518463135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.19s/it]
INFO:root:final mean train loss: 1224.9569110572188
INFO:root:final train perplexity: 2.627609968185425
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2348.295763380984
INFO:root:eval perplexity: 6.680304527282715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2935.9021290447695
INFO:root:eval perplexity: 11.034881591796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [33:21:22<1:45:13, 631.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1230.458079370959
INFO:root:current train perplexity2.6208579540252686
INFO:root:current mean train loss 1219.6874072644137
INFO:root:current train perplexity2.6235504150390625
INFO:root:current mean train loss 1220.572702199611
INFO:root:current train perplexity2.6208081245422363
INFO:root:current mean train loss 1222.4706515512205
INFO:root:current train perplexity2.6242356300354004
INFO:root:current mean train loss 1225.734893158599
INFO:root:current train perplexity2.6273255348205566
INFO:root:current mean train loss 1224.5795711524545
INFO:root:current train perplexity2.625474691390991
INFO:root:current mean train loss 1223.1521378412535
INFO:root:current train perplexity2.6249308586120605
INFO:root:current mean train loss 1224.4006540222585
INFO:root:current train perplexity2.6247050762176514
INFO:root:current mean train loss 1223.8879802413958
INFO:root:current train perplexity2.6244895458221436
INFO:root:current mean train loss 1224.5036347782393
INFO:root:current train perplexity2.626412868499756
INFO:root:current mean train loss 1224.0311546214468
INFO:root:current train perplexity2.6267292499542236
INFO:root:current mean train loss 1223.4580818764186
INFO:root:current train perplexity2.6268813610076904
INFO:root:current mean train loss 1224.1338703102751
INFO:root:current train perplexity2.6262404918670654
INFO:root:current mean train loss 1224.7344827415172
INFO:root:current train perplexity2.6268503665924072
INFO:root:current mean train loss 1225.1143159005424
INFO:root:current train perplexity2.6280720233917236
INFO:root:current mean train loss 1225.3161162032732
INFO:root:current train perplexity2.6275691986083984
INFO:root:current mean train loss 1225.1841066851068
INFO:root:current train perplexity2.628264904022217
INFO:root:current mean train loss 1224.7648567124693
INFO:root:current train perplexity2.627967119216919
INFO:root:current mean train loss 1224.8492005162059
INFO:root:current train perplexity2.627807378768921
INFO:root:current mean train loss 1224.957294438403
INFO:root:current train perplexity2.6274752616882324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.53s/it]
INFO:root:final mean train loss: 1225.0383967458752
INFO:root:final train perplexity: 2.627779006958008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2348.3560539949026
INFO:root:eval perplexity: 6.680630683898926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2936.0644730371787
INFO:root:eval perplexity: 11.036349296569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [33:31:48<1:34:26, 629.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1217.7911483101223
INFO:root:current train perplexity2.6027846336364746
INFO:root:current mean train loss 1215.5225453834012
INFO:root:current train perplexity2.6097419261932373
INFO:root:current mean train loss 1219.4854776025788
INFO:root:current train perplexity2.620123863220215
INFO:root:current mean train loss 1220.8270337760794
INFO:root:current train perplexity2.623767375946045
INFO:root:current mean train loss 1220.7498445382566
INFO:root:current train perplexity2.6217200756073
INFO:root:current mean train loss 1220.94825448396
INFO:root:current train perplexity2.621791362762451
INFO:root:current mean train loss 1221.5039975192894
INFO:root:current train perplexity2.623164415359497
INFO:root:current mean train loss 1221.7040737448685
INFO:root:current train perplexity2.6224119663238525
INFO:root:current mean train loss 1222.3934565695183
INFO:root:current train perplexity2.620971202850342
INFO:root:current mean train loss 1222.0599820739876
INFO:root:current train perplexity2.620135545730591
INFO:root:current mean train loss 1222.9047289058765
INFO:root:current train perplexity2.620694398880005
INFO:root:current mean train loss 1223.4565635268393
INFO:root:current train perplexity2.620870590209961
INFO:root:current mean train loss 1223.69205725901
INFO:root:current train perplexity2.622987747192383
INFO:root:current mean train loss 1224.0165717251057
INFO:root:current train perplexity2.6239840984344482
INFO:root:current mean train loss 1223.8648096614854
INFO:root:current train perplexity2.624479293823242
INFO:root:current mean train loss 1223.5696737232677
INFO:root:current train perplexity2.6247482299804688
INFO:root:current mean train loss 1223.8233257678417
INFO:root:current train perplexity2.625565528869629
INFO:root:current mean train loss 1224.278609827485
INFO:root:current train perplexity2.6256887912750244
INFO:root:current mean train loss 1224.6226222078565
INFO:root:current train perplexity2.62595534324646
INFO:root:current mean train loss 1224.2462256060107
INFO:root:current train perplexity2.6252760887145996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.21s/it]
INFO:root:final mean train loss: 1223.9554717294268
INFO:root:final train perplexity: 2.625535726547241
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 2349.821386459026
INFO:root:eval perplexity: 6.6885528564453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2936.9897192555964
INFO:root:eval perplexity: 11.04470443725586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [33:42:14<1:23:48, 628.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.4064243861608
INFO:root:current train perplexity2.608090400695801
INFO:root:current mean train loss 1223.8217825860334
INFO:root:current train perplexity2.624678373336792
INFO:root:current mean train loss 1221.31355918043
INFO:root:current train perplexity2.622488260269165
INFO:root:current mean train loss 1224.4760146968622
INFO:root:current train perplexity2.6214067935943604
INFO:root:current mean train loss 1225.6439899749425
INFO:root:current train perplexity2.6216280460357666
INFO:root:current mean train loss 1225.1705562937111
INFO:root:current train perplexity2.6238369941711426
INFO:root:current mean train loss 1225.6978838936416
INFO:root:current train perplexity2.625596046447754
INFO:root:current mean train loss 1225.93800252012
INFO:root:current train perplexity2.6249048709869385
INFO:root:current mean train loss 1224.588623754119
INFO:root:current train perplexity2.6239004135131836
INFO:root:current mean train loss 1224.25889630184
INFO:root:current train perplexity2.6237754821777344
INFO:root:current mean train loss 1224.4388574724028
INFO:root:current train perplexity2.625413417816162
INFO:root:current mean train loss 1224.3926058348559
INFO:root:current train perplexity2.62546968460083
INFO:root:current mean train loss 1224.8445627389215
INFO:root:current train perplexity2.6261377334594727
INFO:root:current mean train loss 1224.3317633759686
INFO:root:current train perplexity2.625476598739624
INFO:root:current mean train loss 1224.1958915621797
INFO:root:current train perplexity2.6265993118286133
INFO:root:current mean train loss 1224.170790971889
INFO:root:current train perplexity2.626028060913086
INFO:root:current mean train loss 1224.1340351116205
INFO:root:current train perplexity2.6255335807800293
INFO:root:current mean train loss 1224.7569116861794
INFO:root:current train perplexity2.62514328956604
INFO:root:current mean train loss 1224.6122501719337
INFO:root:current train perplexity2.6256210803985596
INFO:root:current mean train loss 1223.9873641991094
INFO:root:current train perplexity2.6254210472106934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.01s/it]
INFO:root:final mean train loss: 1223.8450513138532
INFO:root:final train perplexity: 2.625307083129883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 2348.8698752112423
INFO:root:eval perplexity: 6.683407306671143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.83s/it]
INFO:root:eval mean loss: 2936.692543841423
INFO:root:eval perplexity: 11.04201889038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [33:52:57<1:13:50, 632.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1221.7066360473632
INFO:root:current train perplexity2.6208548545837402
INFO:root:current mean train loss 1222.6835801866318
INFO:root:current train perplexity2.62601375579834
INFO:root:current mean train loss 1221.7458949497768
INFO:root:current train perplexity2.6271860599517822
INFO:root:current mean train loss 1222.2525101511103
INFO:root:current train perplexity2.6274311542510986
INFO:root:current mean train loss 1222.8890179951986
INFO:root:current train perplexity2.6237990856170654
INFO:root:current mean train loss 1222.3419488314923
INFO:root:current train perplexity2.6221606731414795
INFO:root:current mean train loss 1221.120395974552
INFO:root:current train perplexity2.6190013885498047
INFO:root:current mean train loss 1221.5716907990284
INFO:root:current train perplexity2.6201629638671875
INFO:root:current mean train loss 1221.7811079545454
INFO:root:current train perplexity2.6197762489318848
INFO:root:current mean train loss 1221.8197154765226
INFO:root:current train perplexity2.619445323944092
INFO:root:current mean train loss 1221.5012109827112
INFO:root:current train perplexity2.619487762451172
INFO:root:current mean train loss 1222.3730769787805
INFO:root:current train perplexity2.620715379714966
INFO:root:current mean train loss 1222.369843006134
INFO:root:current train perplexity2.620589017868042
INFO:root:current mean train loss 1222.5417959904325
INFO:root:current train perplexity2.6203718185424805
INFO:root:current mean train loss 1222.2641665896854
INFO:root:current train perplexity2.620936870574951
INFO:root:current mean train loss 1221.8876772337321
INFO:root:current train perplexity2.6215169429779053
INFO:root:current mean train loss 1221.7767863682338
INFO:root:current train perplexity2.6214942932128906
INFO:root:current mean train loss 1222.4854858398437
INFO:root:current train perplexity2.622205972671509
INFO:root:current mean train loss 1222.6609660696477
INFO:root:current train perplexity2.6228623390197754
INFO:root:current mean train loss 1222.6778446081912
INFO:root:current train perplexity2.622272253036499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.23s/it]
INFO:root:final mean train loss: 1222.307895092909
INFO:root:final train perplexity: 2.6221261024475098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2350.7175440145725
INFO:root:eval perplexity: 6.693403244018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 2938.427705372479
INFO:root:eval perplexity: 11.057696342468262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [34:03:32<1:03:20, 633.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1211.723543462065
INFO:root:current train perplexity2.618802785873413
INFO:root:current mean train loss 1213.6574719424175
INFO:root:current train perplexity2.613295078277588
INFO:root:current mean train loss 1216.9976736768729
INFO:root:current train perplexity2.6192727088928223
INFO:root:current mean train loss 1219.4370227880981
INFO:root:current train perplexity2.615838050842285
INFO:root:current mean train loss 1219.6219325228717
INFO:root:current train perplexity2.6139209270477295
INFO:root:current mean train loss 1218.8946379848462
INFO:root:current train perplexity2.615565538406372
INFO:root:current mean train loss 1219.0413581924768
INFO:root:current train perplexity2.619056224822998
INFO:root:current mean train loss 1219.487511303374
INFO:root:current train perplexity2.6185059547424316
INFO:root:current mean train loss 1220.5296179049524
INFO:root:current train perplexity2.618238687515259
INFO:root:current mean train loss 1220.4509210003057
INFO:root:current train perplexity2.619810104370117
INFO:root:current mean train loss 1220.8545112157803
INFO:root:current train perplexity2.6206209659576416
INFO:root:current mean train loss 1221.2404290552226
INFO:root:current train perplexity2.6213223934173584
INFO:root:current mean train loss 1221.579134033015
INFO:root:current train perplexity2.620281219482422
INFO:root:current mean train loss 1221.7717137483503
INFO:root:current train perplexity2.6205313205718994
INFO:root:current mean train loss 1221.595262383491
INFO:root:current train perplexity2.621077299118042
INFO:root:current mean train loss 1222.3249072204476
INFO:root:current train perplexity2.6210453510284424
INFO:root:current mean train loss 1222.5370050002073
INFO:root:current train perplexity2.621777296066284
INFO:root:current mean train loss 1222.9108368412415
INFO:root:current train perplexity2.6222214698791504
INFO:root:current mean train loss 1222.8980497321018
INFO:root:current train perplexity2.622105121612549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.83s/it]
INFO:root:final mean train loss: 1222.3247699131584
INFO:root:final train perplexity: 2.6221611499786377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2350.4262409616026
INFO:root:eval perplexity: 6.6918253898620605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2938.187026003574
INFO:root:eval perplexity: 11.055524826049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [34:14:12<52:57, 635.49s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1205.0743844168526
INFO:root:current train perplexity2.639538526535034
INFO:root:current mean train loss 1222.9522116142407
INFO:root:current train perplexity2.627335548400879
INFO:root:current mean train loss 1224.0527149806512
INFO:root:current train perplexity2.6243674755096436
INFO:root:current mean train loss 1222.4698447452229
INFO:root:current train perplexity2.6198842525482178
INFO:root:current mean train loss 1222.301414895173
INFO:root:current train perplexity2.6203038692474365
INFO:root:current mean train loss 1222.4024249718811
INFO:root:current train perplexity2.62253999710083
INFO:root:current mean train loss 1221.60347168764
INFO:root:current train perplexity2.6222755908966064
INFO:root:current mean train loss 1222.2525800603444
INFO:root:current train perplexity2.6225368976593018
INFO:root:current mean train loss 1222.962610793055
INFO:root:current train perplexity2.6220014095306396
INFO:root:current mean train loss 1223.2771301937312
INFO:root:current train perplexity2.6229121685028076
INFO:root:current mean train loss 1222.6101313784748
INFO:root:current train perplexity2.6228435039520264
INFO:root:current mean train loss 1222.0699651365435
INFO:root:current train perplexity2.6222915649414062
INFO:root:current mean train loss 1222.3713750949212
INFO:root:current train perplexity2.622260332107544
INFO:root:current mean train loss 1222.1507729075997
INFO:root:current train perplexity2.6218042373657227
INFO:root:current mean train loss 1222.2316149505227
INFO:root:current train perplexity2.621795415878296
INFO:root:current mean train loss 1222.8313648621977
INFO:root:current train perplexity2.6209304332733154
INFO:root:current mean train loss 1223.1379017126753
INFO:root:current train perplexity2.621432304382324
INFO:root:current mean train loss 1222.9327586295308
INFO:root:current train perplexity2.621612787246704
INFO:root:current mean train loss 1223.0826041191126
INFO:root:current train perplexity2.622145175933838
INFO:root:current mean train loss 1222.9591991779323
INFO:root:current train perplexity2.6219964027404785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.43s/it]
INFO:root:final mean train loss: 1222.45574252484
INFO:root:final train perplexity: 2.622431993484497
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2350.1149521415114
INFO:root:eval perplexity: 6.690141201019287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2937.796167684785
INFO:root:eval perplexity: 11.051987648010254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [34:24:46<42:19, 634.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1210.1630741242438
INFO:root:current train perplexity2.6309804916381836
INFO:root:current mean train loss 1221.5861695267772
INFO:root:current train perplexity2.6221935749053955
INFO:root:current mean train loss 1224.3558418306955
INFO:root:current train perplexity2.618417263031006
INFO:root:current mean train loss 1222.2502740128164
INFO:root:current train perplexity2.616683006286621
INFO:root:current mean train loss 1223.046177981348
INFO:root:current train perplexity2.6201894283294678
INFO:root:current mean train loss 1224.7098607065088
INFO:root:current train perplexity2.622429609298706
INFO:root:current mean train loss 1224.5144899975858
INFO:root:current train perplexity2.6208136081695557
INFO:root:current mean train loss 1224.0880631265497
INFO:root:current train perplexity2.621319055557251
INFO:root:current mean train loss 1223.97881676115
INFO:root:current train perplexity2.621415615081787
INFO:root:current mean train loss 1223.62825013846
INFO:root:current train perplexity2.6218552589416504
INFO:root:current mean train loss 1223.1338906496271
INFO:root:current train perplexity2.6220951080322266
INFO:root:current mean train loss 1222.1977630804115
INFO:root:current train perplexity2.6220216751098633
INFO:root:current mean train loss 1222.561183207409
INFO:root:current train perplexity2.621457099914551
INFO:root:current mean train loss 1222.6547569085744
INFO:root:current train perplexity2.6219260692596436
INFO:root:current mean train loss 1222.4587348602104
INFO:root:current train perplexity2.6223526000976562
INFO:root:current mean train loss 1221.8532506742172
INFO:root:current train perplexity2.621483087539673
INFO:root:current mean train loss 1221.358394620464
INFO:root:current train perplexity2.6205544471740723
INFO:root:current mean train loss 1221.4157572393126
INFO:root:current train perplexity2.6202425956726074
INFO:root:current mean train loss 1221.6123928901343
INFO:root:current train perplexity2.6209421157836914
INFO:root:current mean train loss 1222.0772377618664
INFO:root:current train perplexity2.6212451457977295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.76s/it]
INFO:root:final mean train loss: 1221.593787427509
INFO:root:final train perplexity: 2.620650053024292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2350.5717569986978
INFO:root:eval perplexity: 6.69261360168457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2938.607345689273
INFO:root:eval perplexity: 11.059326171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [34:35:10<31:35, 631.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1221.3694661458333
INFO:root:current train perplexity2.6302273273468018
INFO:root:current mean train loss 1219.1093758247994
INFO:root:current train perplexity2.623098850250244
INFO:root:current mean train loss 1218.391088178081
INFO:root:current train perplexity2.6179568767547607
INFO:root:current mean train loss 1219.8583191619523
INFO:root:current train perplexity2.6168813705444336
INFO:root:current mean train loss 1218.8590139661517
INFO:root:current train perplexity2.6167802810668945
INFO:root:current mean train loss 1220.1501331190123
INFO:root:current train perplexity2.6137776374816895
INFO:root:current mean train loss 1219.9801528365524
INFO:root:current train perplexity2.6152496337890625
INFO:root:current mean train loss 1219.8697770878593
INFO:root:current train perplexity2.61630916595459
INFO:root:current mean train loss 1220.3925478953236
INFO:root:current train perplexity2.615992307662964
INFO:root:current mean train loss 1220.6515365149905
INFO:root:current train perplexity2.6191365718841553
INFO:root:current mean train loss 1221.3348469042596
INFO:root:current train perplexity2.6201224327087402
INFO:root:current mean train loss 1221.0574495003198
INFO:root:current train perplexity2.6204092502593994
INFO:root:current mean train loss 1221.668741568541
INFO:root:current train perplexity2.621487617492676
INFO:root:current mean train loss 1222.3662602002967
INFO:root:current train perplexity2.621983528137207
INFO:root:current mean train loss 1222.4125705950826
INFO:root:current train perplexity2.6206278800964355
INFO:root:current mean train loss 1222.400613632005
INFO:root:current train perplexity2.6206538677215576
INFO:root:current mean train loss 1222.0254304756238
INFO:root:current train perplexity2.6201696395874023
INFO:root:current mean train loss 1221.7906984377234
INFO:root:current train perplexity2.6201601028442383
INFO:root:current mean train loss 1221.9447596166042
INFO:root:current train perplexity2.620102882385254
INFO:root:current mean train loss 1221.836878343774
INFO:root:current train perplexity2.6202919483184814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it]
INFO:root:final mean train loss: 1221.2876381308997
INFO:root:final train perplexity: 2.6200172901153564
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.52s/it]
INFO:root:eval mean loss: 2350.5145332931625
INFO:root:eval perplexity: 6.69230318069458
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2938.484318726452
INFO:root:eval perplexity: 11.058213233947754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [34:45:50<21:08, 634.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1203.9612924429086
INFO:root:current train perplexity2.619396209716797
INFO:root:current mean train loss 1213.969286369555
INFO:root:current train perplexity2.615236282348633
INFO:root:current mean train loss 1218.4036759286557
INFO:root:current train perplexity2.6208643913269043
INFO:root:current mean train loss 1218.80538380244
INFO:root:current train perplexity2.6260740756988525
INFO:root:current mean train loss 1220.554667548723
INFO:root:current train perplexity2.6257221698760986
INFO:root:current mean train loss 1220.5001752195105
INFO:root:current train perplexity2.6253600120544434
INFO:root:current mean train loss 1219.9939541235901
INFO:root:current train perplexity2.6246707439422607
INFO:root:current mean train loss 1219.9049025990605
INFO:root:current train perplexity2.6243579387664795
INFO:root:current mean train loss 1220.2637118124549
INFO:root:current train perplexity2.624314546585083
INFO:root:current mean train loss 1220.4032120304405
INFO:root:current train perplexity2.6255252361297607
INFO:root:current mean train loss 1221.053309882079
INFO:root:current train perplexity2.6244537830352783
INFO:root:current mean train loss 1220.8715895755097
INFO:root:current train perplexity2.622607946395874
INFO:root:current mean train loss 1220.8705817301754
INFO:root:current train perplexity2.6225922107696533
INFO:root:current mean train loss 1221.1762474423363
INFO:root:current train perplexity2.621833086013794
INFO:root:current mean train loss 1220.756117180834
INFO:root:current train perplexity2.621718406677246
INFO:root:current mean train loss 1221.1708556933906
INFO:root:current train perplexity2.6209161281585693
INFO:root:current mean train loss 1221.0043483424831
INFO:root:current train perplexity2.6207659244537354
INFO:root:current mean train loss 1221.0511525788995
INFO:root:current train perplexity2.6195013523101807
INFO:root:current mean train loss 1221.0162462822555
INFO:root:current train perplexity2.6192078590393066
INFO:root:current mean train loss 1221.1453955575103
INFO:root:current train perplexity2.6190707683563232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.09s/it]
INFO:root:final mean train loss: 1220.7848842234187
INFO:root:final train perplexity: 2.61897873878479
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 2350.659464085356
INFO:root:eval perplexity: 6.693087100982666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.88s/it]
INFO:root:eval mean loss: 2938.6891340972684
INFO:root:eval perplexity: 11.06006145477295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [34:56:32<10:36, 636.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1205.046888397961
INFO:root:current train perplexity2.625004291534424
INFO:root:current mean train loss 1214.109158358731
INFO:root:current train perplexity2.616917610168457
INFO:root:current mean train loss 1217.557806353197
INFO:root:current train perplexity2.6193127632141113
INFO:root:current mean train loss 1215.7863600166681
INFO:root:current train perplexity2.615455150604248
INFO:root:current mean train loss 1218.4496178844659
INFO:root:current train perplexity2.6166012287139893
INFO:root:current mean train loss 1220.1675920519222
INFO:root:current train perplexity2.6187710762023926
INFO:root:current mean train loss 1220.5787135149376
INFO:root:current train perplexity2.619053840637207
INFO:root:current mean train loss 1221.2985071831042
INFO:root:current train perplexity2.618016481399536
INFO:root:current mean train loss 1220.3631590412858
INFO:root:current train perplexity2.6179397106170654
INFO:root:current mean train loss 1220.2061937879885
INFO:root:current train perplexity2.6196141242980957
INFO:root:current mean train loss 1221.2798865806594
INFO:root:current train perplexity2.6200969219207764
INFO:root:current mean train loss 1220.7469471061693
INFO:root:current train perplexity2.619316577911377
INFO:root:current mean train loss 1221.1192908800335
INFO:root:current train perplexity2.619678258895874
INFO:root:current mean train loss 1221.4511863609125
INFO:root:current train perplexity2.6202948093414307
INFO:root:current mean train loss 1221.2549912096197
INFO:root:current train perplexity2.6201584339141846
INFO:root:current mean train loss 1221.1599118007268
INFO:root:current train perplexity2.6199793815612793
INFO:root:current mean train loss 1221.5281189908312
INFO:root:current train perplexity2.619593858718872
INFO:root:current mean train loss 1221.5166261546674
INFO:root:current train perplexity2.6197402477264404
INFO:root:current mean train loss 1221.3650095632556
INFO:root:current train perplexity2.6199114322662354
INFO:root:current mean train loss 1221.4275874841346
INFO:root:current train perplexity2.619654893875122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.78s/it]
INFO:root:final mean train loss: 1221.1127155898378
INFO:root:final train perplexity: 2.6196558475494385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2350.633167889101
INFO:root:eval perplexity: 6.692946910858154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2938.663758189966
INFO:root:eval perplexity: 11.059832572937012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:06:59<00:00, 633.81s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:06:59<00:00, 632.10s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.93s/it]
INFO:root:eval mean loss: 2350.633167889101
INFO:root:eval perplexity: 6.692946910858154
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.85s/it]
INFO:root:eval mean loss: 2938.663758189966
INFO:root:eval perplexity: 11.059832572937012
INFO:root:evalaution complete
INFO:root:save model final: allminil16_minilml12/final
