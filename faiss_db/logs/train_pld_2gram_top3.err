INFO:root:Output: pld_23
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12232.261906171087
INFO:root:current train perplexity16622.390625
INFO:root:current mean train loss 10549.212004848461
INFO:root:current train perplexity4128.64892578125
INFO:root:current mean train loss 9176.276830973035
INFO:root:current train perplexity1387.006103515625
INFO:root:current mean train loss 8227.121710526315
INFO:root:current train perplexity655.4640502929688
INFO:root:current mean train loss 7535.064535320641
INFO:root:current train perplexity380.5385437011719
INFO:root:current mean train loss 7009.500241695143
INFO:root:current train perplexity251.36846923828125
INFO:root:current mean train loss 6599.146121831411
INFO:root:current train perplexity181.29615783691406
INFO:root:current mean train loss 6273.383967813771
INFO:root:current train perplexity139.76931762695312
INFO:root:current mean train loss 5996.3591151083665
INFO:root:current train perplexity112.90419006347656
INFO:root:current mean train loss 5772.304535492523
INFO:root:current train perplexity94.1277084350586
INFO:root:current mean train loss 5572.62098289816
INFO:root:current train perplexity80.60115814208984
INFO:root:current mean train loss 5402.970827536945
INFO:root:current train perplexity70.55068969726562
INFO:root:current mean train loss 5256.174830060082
INFO:root:current train perplexity62.6670036315918
INFO:root:current mean train loss 5120.045276131947
INFO:root:current train perplexity56.43314743041992
INFO:root:current mean train loss 5001.102693299439
INFO:root:current train perplexity51.454044342041016
INFO:root:current mean train loss 4894.004665238772
INFO:root:current train perplexity47.31317901611328
INFO:root:current mean train loss 4798.09172244013
INFO:root:current train perplexity43.83584213256836
INFO:root:current mean train loss 4709.132563745266
INFO:root:current train perplexity40.91302490234375
INFO:root:current mean train loss 4626.125308550553
INFO:root:current train perplexity38.37983703613281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it]
INFO:root:final mean train loss: 4561.699613462478
INFO:root:final train perplexity: 36.51161575317383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 3476.6522308441254
INFO:root:eval perplexity: 17.33706283569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/1
  1%|          | 1/100 [05:18<8:45:11, 318.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3086.4764404296875
INFO:root:current train perplexity11.32431697845459
INFO:root:current mean train loss 3075.7143912479796
INFO:root:current train perplexity11.331725120544434
INFO:root:current mean train loss 3057.3804694281685
INFO:root:current train perplexity11.2649507522583
INFO:root:current mean train loss 3055.441233960888
INFO:root:current train perplexity11.239448547363281
INFO:root:current mean train loss 3048.0700971163237
INFO:root:current train perplexity11.143041610717773
INFO:root:current mean train loss 3037.4259231922238
INFO:root:current train perplexity11.000798225402832
INFO:root:current mean train loss 3018.976227599305
INFO:root:current train perplexity10.868037223815918
INFO:root:current mean train loss 3007.51023310656
INFO:root:current train perplexity10.764493942260742
INFO:root:current mean train loss 2998.041410259172
INFO:root:current train perplexity10.683385848999023
INFO:root:current mean train loss 2991.35984329157
INFO:root:current train perplexity10.602832794189453
INFO:root:current mean train loss 2978.446317657711
INFO:root:current train perplexity10.514936447143555
INFO:root:current mean train loss 2969.313662949429
INFO:root:current train perplexity10.418813705444336
INFO:root:current mean train loss 2961.315742492676
INFO:root:current train perplexity10.338224411010742
INFO:root:current mean train loss 2951.7687133046993
INFO:root:current train perplexity10.253152847290039
INFO:root:current mean train loss 2942.079497601353
INFO:root:current train perplexity10.177556037902832
INFO:root:current mean train loss 2933.111818499804
INFO:root:current train perplexity10.09924030303955
INFO:root:current mean train loss 2923.1230586590154
INFO:root:current train perplexity10.022379875183105
INFO:root:current mean train loss 2914.5577169209373
INFO:root:current train perplexity9.952876091003418
INFO:root:current mean train loss 2903.674746475556
INFO:root:current train perplexity9.878424644470215
INFO:root:current mean train loss 2894.768945363469
INFO:root:current train perplexity9.802672386169434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.05s/it]
INFO:root:final mean train loss: 2888.534374889195
INFO:root:final train perplexity: 9.757850646972656
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it]
INFO:root:eval mean loss: 3253.364471160614
INFO:root:eval perplexity: 14.434521675109863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/2
  2%|â–         | 2/100 [10:40<8:43:59, 320.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2748.568877249053
INFO:root:current train perplexity8.714622497558594
INFO:root:current mean train loss 2696.4476309181155
INFO:root:current train perplexity8.4552640914917
INFO:root:current mean train loss 2693.3740789716335
INFO:root:current train perplexity8.415799140930176
INFO:root:current mean train loss 2680.7777315890107
INFO:root:current train perplexity8.345734596252441
INFO:root:current mean train loss 2682.2110220752743
INFO:root:current train perplexity8.306863784790039
INFO:root:current mean train loss 2676.8950062478016
INFO:root:current train perplexity8.257941246032715
INFO:root:current mean train loss 2670.9734418968455
INFO:root:current train perplexity8.210251808166504
INFO:root:current mean train loss 2663.512374565676
INFO:root:current train perplexity8.165776252746582
INFO:root:current mean train loss 2658.085639431554
INFO:root:current train perplexity8.13029956817627
INFO:root:current mean train loss 2650.8652364683817
INFO:root:current train perplexity8.092756271362305
INFO:root:current mean train loss 2645.4846120503844
INFO:root:current train perplexity8.059199333190918
INFO:root:current mean train loss 2639.6743836365017
INFO:root:current train perplexity8.030991554260254
INFO:root:current mean train loss 2633.486672654349
INFO:root:current train perplexity7.995705604553223
INFO:root:current mean train loss 2626.1751741035846
INFO:root:current train perplexity7.953347682952881
INFO:root:current mean train loss 2624.328871051498
INFO:root:current train perplexity7.931759834289551
INFO:root:current mean train loss 2622.398883737463
INFO:root:current train perplexity7.905202388763428
INFO:root:current mean train loss 2617.187462922918
INFO:root:current train perplexity7.872841835021973
INFO:root:current mean train loss 2612.7889513476903
INFO:root:current train perplexity7.840632438659668
INFO:root:current mean train loss 2607.7116576682265
INFO:root:current train perplexity7.805332660675049
INFO:root:current mean train loss 2602.034147228038
INFO:root:current train perplexity7.774974822998047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.07s/it]
INFO:root:final mean train loss: 2597.679652288594
INFO:root:final train perplexity: 7.757704734802246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it]
INFO:root:eval mean loss: 3192.9803829708617
INFO:root:eval perplexity: 13.736734390258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/3
  3%|â–Ž         | 3/100 [16:04<8:40:39, 322.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2507.30826171875
INFO:root:current train perplexity7.183632850646973
INFO:root:current mean train loss 2493.3079036458334
INFO:root:current train perplexity7.138439178466797
INFO:root:current mean train loss 2486.4584892578123
INFO:root:current train perplexity7.116581439971924
INFO:root:current mean train loss 2478.167946428571
INFO:root:current train perplexity7.05958890914917
INFO:root:current mean train loss 2481.1718804253474
INFO:root:current train perplexity7.047244071960449
INFO:root:current mean train loss 2473.238893821023
INFO:root:current train perplexity7.01077938079834
INFO:root:current mean train loss 2469.152589017428
INFO:root:current train perplexity6.994204044342041
INFO:root:current mean train loss 2465.70479296875
INFO:root:current train perplexity6.977899551391602
INFO:root:current mean train loss 2462.691731100643
INFO:root:current train perplexity6.969758987426758
INFO:root:current mean train loss 2459.320839201275
INFO:root:current train perplexity6.949231147766113
INFO:root:current mean train loss 2454.965175664993
INFO:root:current train perplexity6.926807880401611
INFO:root:current mean train loss 2453.732845936651
INFO:root:current train perplexity6.916259288787842
INFO:root:current mean train loss 2449.7437461914064
INFO:root:current train perplexity6.8987884521484375
INFO:root:current mean train loss 2446.461813241464
INFO:root:current train perplexity6.879863262176514
INFO:root:current mean train loss 2445.289711156385
INFO:root:current train perplexity6.871771335601807
INFO:root:current mean train loss 2441.6672841324344
INFO:root:current train perplexity6.854763507843018
INFO:root:current mean train loss 2439.4474055989585
INFO:root:current train perplexity6.840959548950195
INFO:root:current mean train loss 2435.7610223214288
INFO:root:current train perplexity6.820343494415283
INFO:root:current mean train loss 2433.7144667836783
INFO:root:current train perplexity6.8092756271362305
INFO:root:current mean train loss 2430.888264347957
INFO:root:current train perplexity6.7964348793029785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.09s/it]
INFO:root:final mean train loss: 2429.136281223653
INFO:root:final train perplexity: 6.792118549346924
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 3161.3655401006476
INFO:root:eval perplexity: 13.384953498840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/4
  4%|â–         | 4/100 [21:28<8:36:24, 322.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2394.3952964668842
INFO:root:current train perplexity6.479327201843262
INFO:root:current mean train loss 2356.324348129912
INFO:root:current train perplexity6.38548469543457
INFO:root:current mean train loss 2354.353145756525
INFO:root:current train perplexity6.3940629959106445
INFO:root:current mean train loss 2353.3408276300665
INFO:root:current train perplexity6.395279884338379
INFO:root:current mean train loss 2353.761364563119
INFO:root:current train perplexity6.402043342590332
INFO:root:current mean train loss 2348.137680242091
INFO:root:current train perplexity6.3686676025390625
INFO:root:current mean train loss 2348.6823516342415
INFO:root:current train perplexity6.364857196807861
INFO:root:current mean train loss 2344.9688652267355
INFO:root:current train perplexity6.348120212554932
INFO:root:current mean train loss 2344.9996830677355
INFO:root:current train perplexity6.337832927703857
INFO:root:current mean train loss 2340.528636407704
INFO:root:current train perplexity6.318995475769043
INFO:root:current mean train loss 2339.039984491236
INFO:root:current train perplexity6.310278415679932
INFO:root:current mean train loss 2337.7694131545563
INFO:root:current train perplexity6.300753116607666
INFO:root:current mean train loss 2333.9702947145383
INFO:root:current train perplexity6.286344528198242
INFO:root:current mean train loss 2333.09569830291
INFO:root:current train perplexity6.279819965362549
INFO:root:current mean train loss 2329.958217670256
INFO:root:current train perplexity6.271910667419434
INFO:root:current mean train loss 2327.037070892081
INFO:root:current train perplexity6.263932228088379
INFO:root:current mean train loss 2323.202641039175
INFO:root:current train perplexity6.248284816741943
INFO:root:current mean train loss 2321.367134858473
INFO:root:current train perplexity6.236118316650391
INFO:root:current mean train loss 2318.924102864932
INFO:root:current train perplexity6.22476053237915
INFO:root:current mean train loss 2316.5050566401287
INFO:root:current train perplexity6.211272239685059

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.16s/it]
INFO:root:final mean train loss: 2315.4191673228793
INFO:root:final train perplexity: 6.209489822387695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 3145.8616309180275
INFO:root:eval perplexity: 13.21574592590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/5
  5%|â–Œ         | 5/100 [26:54<8:32:55, 323.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2264.8545430501304
INFO:root:current train perplexity5.9168291091918945
INFO:root:current mean train loss 2259.6354496168055
INFO:root:current train perplexity5.928198337554932
INFO:root:current mean train loss 2256.612756433621
INFO:root:current train perplexity5.941720008850098
INFO:root:current mean train loss 2257.663768450419
INFO:root:current train perplexity5.943817615509033
INFO:root:current mean train loss 2263.571166739976
INFO:root:current train perplexity5.956009387969971
INFO:root:current mean train loss 2257.226235167621
INFO:root:current train perplexity5.926724910736084
INFO:root:current mean train loss 2254.927700645045
INFO:root:current train perplexity5.9070281982421875
INFO:root:current mean train loss 2254.309295031489
INFO:root:current train perplexity5.909374713897705
INFO:root:current mean train loss 2252.1893582581397
INFO:root:current train perplexity5.896901607513428
INFO:root:current mean train loss 2247.851970021318
INFO:root:current train perplexity5.880125999450684
INFO:root:current mean train loss 2246.730555122629
INFO:root:current train perplexity5.8776044845581055
INFO:root:current mean train loss 2244.588012386013
INFO:root:current train perplexity5.868636608123779
INFO:root:current mean train loss 2243.012718224451
INFO:root:current train perplexity5.862090587615967
INFO:root:current mean train loss 2242.482635498047
INFO:root:current train perplexity5.8570146560668945
INFO:root:current mean train loss 2242.3592461845624
INFO:root:current train perplexity5.8564133644104
INFO:root:current mean train loss 2241.0010784418896
INFO:root:current train perplexity5.846634387969971
INFO:root:current mean train loss 2239.8183039939317
INFO:root:current train perplexity5.84010648727417
INFO:root:current mean train loss 2236.279879445987
INFO:root:current train perplexity5.8317742347717285
INFO:root:current mean train loss 2235.4297413431154
INFO:root:current train perplexity5.824897289276123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.39s/it]
INFO:root:final mean train loss: 2232.5053336662413
INFO:root:final train perplexity: 5.816437244415283
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.40s/it]
INFO:root:eval mean loss: 3168.0947954790727
INFO:root:eval perplexity: 13.459063529968262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/6
  6%|â–Œ         | 6/100 [32:20<8:28:48, 324.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2306.19580078125
INFO:root:current train perplexity5.423597812652588
INFO:root:current mean train loss 2164.6746076829363
INFO:root:current train perplexity5.528076648712158
INFO:root:current mean train loss 2176.845895036536
INFO:root:current train perplexity5.580159664154053
INFO:root:current mean train loss 2187.1572557620434
INFO:root:current train perplexity5.599592208862305
INFO:root:current mean train loss 2183.2556170608636
INFO:root:current train perplexity5.591712474822998
INFO:root:current mean train loss 2180.814998908433
INFO:root:current train perplexity5.592611789703369
INFO:root:current mean train loss 2178.0351460944
INFO:root:current train perplexity5.583846092224121
INFO:root:current mean train loss 2179.882234189718
INFO:root:current train perplexity5.585358142852783
INFO:root:current mean train loss 2180.0811225043403
INFO:root:current train perplexity5.584525108337402
INFO:root:current mean train loss 2178.9835461141265
INFO:root:current train perplexity5.577206611633301
INFO:root:current mean train loss 2175.813138643583
INFO:root:current train perplexity5.566797733306885
INFO:root:current mean train loss 2174.172771401886
INFO:root:current train perplexity5.557391166687012
INFO:root:current mean train loss 2173.369270521636
INFO:root:current train perplexity5.55271577835083
INFO:root:current mean train loss 2172.689683097587
INFO:root:current train perplexity5.550690650939941
INFO:root:current mean train loss 2172.2303036370504
INFO:root:current train perplexity5.5492424964904785
INFO:root:current mean train loss 2172.392082280433
INFO:root:current train perplexity5.5452680587768555
INFO:root:current mean train loss 2170.719747453984
INFO:root:current train perplexity5.538064956665039
INFO:root:current mean train loss 2170.1724633200597
INFO:root:current train perplexity5.536393642425537
INFO:root:current mean train loss 2169.7375724152816
INFO:root:current train perplexity5.532009124755859
INFO:root:current mean train loss 2169.1739179600168
INFO:root:current train perplexity5.529419898986816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.37s/it]
INFO:root:final mean train loss: 2167.695882838601
INFO:root:final train perplexity: 5.526614665985107
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.83s/it]
INFO:root:eval mean loss: 3154.606657194304
INFO:root:eval perplexity: 13.310921669006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/7
  7%|â–‹         | 7/100 [37:48<8:24:55, 325.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2122.0907457139756
INFO:root:current train perplexity5.317928314208984
INFO:root:current mean train loss 2111.7720698987023
INFO:root:current train perplexity5.346056938171387
INFO:root:current mean train loss 2128.4000843293074
INFO:root:current train perplexity5.388681888580322
INFO:root:current mean train loss 2131.237965709758
INFO:root:current train perplexity5.386670112609863
INFO:root:current mean train loss 2130.2480801669035
INFO:root:current train perplexity5.365760803222656
INFO:root:current mean train loss 2130.2579069984467
INFO:root:current train perplexity5.363300323486328
INFO:root:current mean train loss 2128.839205349919
INFO:root:current train perplexity5.352980136871338
INFO:root:current mean train loss 2129.4559247965267
INFO:root:current train perplexity5.354466915130615
INFO:root:current mean train loss 2127.5872541581507
INFO:root:current train perplexity5.342970371246338
INFO:root:current mean train loss 2126.1866956390845
INFO:root:current train perplexity5.339925765991211
INFO:root:current mean train loss 2123.6340778103513
INFO:root:current train perplexity5.332784652709961
INFO:root:current mean train loss 2123.639886245318
INFO:root:current train perplexity5.3271918296813965
INFO:root:current mean train loss 2123.4351485930442
INFO:root:current train perplexity5.3241353034973145
INFO:root:current mean train loss 2123.81378136781
INFO:root:current train perplexity5.328639507293701
INFO:root:current mean train loss 2123.4927214930526
INFO:root:current train perplexity5.324615955352783
INFO:root:current mean train loss 2123.144045863698
INFO:root:current train perplexity5.319855213165283
INFO:root:current mean train loss 2121.263643583055
INFO:root:current train perplexity5.314466953277588
INFO:root:current mean train loss 2118.9239987960655
INFO:root:current train perplexity5.306326866149902
INFO:root:current mean train loss 2117.6413694408993
INFO:root:current train perplexity5.304428577423096
INFO:root:current mean train loss 2115.032912141961
INFO:root:current train perplexity5.29926872253418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.80s/it]
INFO:root:final mean train loss: 2114.403253675529
INFO:root:final train perplexity: 5.299144744873047
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it]
INFO:root:eval mean loss: 3152.9316582207207
INFO:root:eval perplexity: 13.292638778686523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/8
  8%|â–Š         | 8/100 [43:16<8:20:25, 326.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2076.7151123046874
INFO:root:current train perplexity5.120735168457031
INFO:root:current mean train loss 2084.6034035011576
INFO:root:current train perplexity5.138206481933594
INFO:root:current mean train loss 2076.0635794132313
INFO:root:current train perplexity5.13676118850708
INFO:root:current mean train loss 2078.1544043697527
INFO:root:current train perplexity5.149580001831055
INFO:root:current mean train loss 2074.645069201239
INFO:root:current train perplexity5.149430274963379
INFO:root:current mean train loss 2073.3180696006134
INFO:root:current train perplexity5.138254165649414
INFO:root:current mean train loss 2076.2827244555856
INFO:root:current train perplexity5.137094974517822
INFO:root:current mean train loss 2078.2482722483524
INFO:root:current train perplexity5.139591693878174
INFO:root:current mean train loss 2078.3460088124534
INFO:root:current train perplexity5.1415815353393555
INFO:root:current mean train loss 2079.7882050050134
INFO:root:current train perplexity5.143320560455322
INFO:root:current mean train loss 2078.2480670431387
INFO:root:current train perplexity5.141230583190918
INFO:root:current mean train loss 2075.2489330947137
INFO:root:current train perplexity5.133655548095703
INFO:root:current mean train loss 2073.163180826164
INFO:root:current train perplexity5.12927770614624
INFO:root:current mean train loss 2073.6850104971327
INFO:root:current train perplexity5.130068778991699
INFO:root:current mean train loss 2073.2059708970764
INFO:root:current train perplexity5.128479480743408
INFO:root:current mean train loss 2073.4805514556188
INFO:root:current train perplexity5.125885009765625
INFO:root:current mean train loss 2072.40898332975
INFO:root:current train perplexity5.123779296875
INFO:root:current mean train loss 2070.915294389972
INFO:root:current train perplexity5.1187052726745605
INFO:root:current mean train loss 2069.4341038509024
INFO:root:current train perplexity5.113677501678467
INFO:root:current mean train loss 2069.48209174893
INFO:root:current train perplexity5.1135101318359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.97s/it]
INFO:root:final mean train loss: 2069.8010730368287
INFO:root:final train perplexity: 5.115983009338379
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 3155.2769119216873
INFO:root:eval perplexity: 13.318245887756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/9
  9%|â–‰         | 9/100 [48:44<8:15:47, 326.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2021.8719177246094
INFO:root:current train perplexity4.9580841064453125
INFO:root:current mean train loss 2029.6991882324219
INFO:root:current train perplexity4.928202152252197
INFO:root:current mean train loss 2040.1136745876736
INFO:root:current train perplexity4.973197937011719
INFO:root:current mean train loss 2035.0346908569336
INFO:root:current train perplexity4.975566864013672
INFO:root:current mean train loss 2042.2164258028554
INFO:root:current train perplexity4.993919372558594
INFO:root:current mean train loss 2043.6201421765313
INFO:root:current train perplexity4.9976983070373535
INFO:root:current mean train loss 2046.0370543310248
INFO:root:current train perplexity5.003176212310791
INFO:root:current mean train loss 2042.3503637110932
INFO:root:current train perplexity4.993849277496338
INFO:root:current mean train loss 2041.471152578721
INFO:root:current train perplexity4.993721961975098
INFO:root:current mean train loss 2038.133541588022
INFO:root:current train perplexity4.986544609069824
INFO:root:current mean train loss 2039.235702688703
INFO:root:current train perplexity4.989477157592773
INFO:root:current mean train loss 2038.210922135247
INFO:root:current train perplexity4.9818620681762695
INFO:root:current mean train loss 2037.7223949493311
INFO:root:current train perplexity4.981106281280518
INFO:root:current mean train loss 2038.0461976542276
INFO:root:current train perplexity4.984940528869629
INFO:root:current mean train loss 2036.4997131515797
INFO:root:current train perplexity4.980072498321533
INFO:root:current mean train loss 2033.770026531416
INFO:root:current train perplexity4.972484111785889
INFO:root:current mean train loss 2033.3866464831926
INFO:root:current train perplexity4.968485355377197
INFO:root:current mean train loss 2034.8063303629558
INFO:root:current train perplexity4.9715986251831055
INFO:root:current mean train loss 2032.8319911091683
INFO:root:current train perplexity4.966314792633057
INFO:root:current mean train loss 2032.767400335093
INFO:root:current train perplexity4.9658074378967285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.27s/it]
INFO:root:final mean train loss: 2031.9489656218482
INFO:root:final train perplexity: 4.965515613555908
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 3162.0587682408973
INFO:root:eval perplexity: 13.392570495605469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/10
 10%|â–ˆ         | 10/100 [54:10<8:10:06, 326.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2019.473783188972
INFO:root:current train perplexity4.872966766357422
INFO:root:current mean train loss 2020.9971555450259
INFO:root:current train perplexity4.86191987991333
INFO:root:current mean train loss 2002.757057388476
INFO:root:current train perplexity4.826190948486328
INFO:root:current mean train loss 2002.0383902862466
INFO:root:current train perplexity4.830822944641113
INFO:root:current mean train loss 2003.3830576817363
INFO:root:current train perplexity4.833485126495361
INFO:root:current mean train loss 2007.1264097083013
INFO:root:current train perplexity4.844628810882568
INFO:root:current mean train loss 2003.3599957521722
INFO:root:current train perplexity4.838498115539551
INFO:root:current mean train loss 2004.612764554464
INFO:root:current train perplexity4.847246170043945
INFO:root:current mean train loss 2005.3336900858117
INFO:root:current train perplexity4.842165946960449
INFO:root:current mean train loss 2004.3972993108632
INFO:root:current train perplexity4.84277868270874
INFO:root:current mean train loss 2002.8732492216734
INFO:root:current train perplexity4.843402862548828
INFO:root:current mean train loss 2002.6583368906718
INFO:root:current train perplexity4.8429765701293945
INFO:root:current mean train loss 2001.690550218707
INFO:root:current train perplexity4.83898401260376
INFO:root:current mean train loss 2002.4186301053746
INFO:root:current train perplexity4.8417510986328125
INFO:root:current mean train loss 2002.990810822759
INFO:root:current train perplexity4.842373371124268
INFO:root:current mean train loss 2000.9613453346578
INFO:root:current train perplexity4.8384599685668945
INFO:root:current mean train loss 1999.8528357906353
INFO:root:current train perplexity4.836411952972412
INFO:root:current mean train loss 1998.5679521059303
INFO:root:current train perplexity4.834439277648926
INFO:root:current mean train loss 1997.7206077677736
INFO:root:current train perplexity4.833575248718262
INFO:root:current mean train loss 1999.096327425684
INFO:root:current train perplexity4.836850643157959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it]
INFO:root:final mean train loss: 1998.731141121653
INFO:root:final train perplexity: 4.83712100982666
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 3164.7506415106513
INFO:root:eval perplexity: 13.422186851501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/11
 11%|â–ˆ         | 11/100 [59:38<8:05:03, 327.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2000.844495196675
INFO:root:current train perplexity4.782984733581543
INFO:root:current mean train loss 1970.1689781271002
INFO:root:current train perplexity4.727386474609375
INFO:root:current mean train loss 1970.1281268780049
INFO:root:current train perplexity4.72263765335083
INFO:root:current mean train loss 1980.0937088882367
INFO:root:current train perplexity4.750930309295654
INFO:root:current mean train loss 1973.9873780301568
INFO:root:current train perplexity4.729323387145996
INFO:root:current mean train loss 1972.6747080311434
INFO:root:current train perplexity4.722144603729248
INFO:root:current mean train loss 1973.7848624627027
INFO:root:current train perplexity4.725604057312012
INFO:root:current mean train loss 1973.831688179618
INFO:root:current train perplexity4.731719493865967
INFO:root:current mean train loss 1971.7343711422475
INFO:root:current train perplexity4.7291951179504395
INFO:root:current mean train loss 1971.5133158159547
INFO:root:current train perplexity4.730998992919922
INFO:root:current mean train loss 1967.870379762316
INFO:root:current train perplexity4.722052574157715
INFO:root:current mean train loss 1970.7906501345449
INFO:root:current train perplexity4.726540565490723
INFO:root:current mean train loss 1969.3369553537798
INFO:root:current train perplexity4.723871231079102
INFO:root:current mean train loss 1969.5029355884458
INFO:root:current train perplexity4.7251739501953125
INFO:root:current mean train loss 1969.1241814060133
INFO:root:current train perplexity4.723817825317383
INFO:root:current mean train loss 1968.6849376779487
INFO:root:current train perplexity4.721431255340576
INFO:root:current mean train loss 1968.5918267771583
INFO:root:current train perplexity4.7209248542785645
INFO:root:current mean train loss 1968.6800591104643
INFO:root:current train perplexity4.721983909606934
INFO:root:current mean train loss 1968.6399371085465
INFO:root:current train perplexity4.72168493270874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.37s/it]
INFO:root:final mean train loss: 1968.5201163626175
INFO:root:final train perplexity: 4.723232746124268
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 3175.6453956397804
INFO:root:eval perplexity: 13.542718887329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/12
 12%|â–ˆâ–        | 12/100 [1:05:05<7:59:48, 327.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.605712890625
INFO:root:current train perplexity4.420017719268799
INFO:root:current mean train loss 1943.3275703504248
INFO:root:current train perplexity4.6223578453063965
INFO:root:current mean train loss 1947.7519014104835
INFO:root:current train perplexity4.639099597930908
INFO:root:current mean train loss 1942.4302325862468
INFO:root:current train perplexity4.629457473754883
INFO:root:current mean train loss 1938.3917148485964
INFO:root:current train perplexity4.626245021820068
INFO:root:current mean train loss 1942.0865141184145
INFO:root:current train perplexity4.636719226837158
INFO:root:current mean train loss 1940.4369971431904
INFO:root:current train perplexity4.635468006134033
INFO:root:current mean train loss 1938.7039892161383
INFO:root:current train perplexity4.630781650543213
INFO:root:current mean train loss 1938.2842183000273
INFO:root:current train perplexity4.6261420249938965
INFO:root:current mean train loss 1942.0640366259604
INFO:root:current train perplexity4.632576942443848
INFO:root:current mean train loss 1941.5462438368488
INFO:root:current train perplexity4.629787445068359
INFO:root:current mean train loss 1940.4413441634674
INFO:root:current train perplexity4.626900672912598
INFO:root:current mean train loss 1939.3799003670836
INFO:root:current train perplexity4.628130912780762
INFO:root:current mean train loss 1938.1149757133478
INFO:root:current train perplexity4.6247100830078125
INFO:root:current mean train loss 1938.4972459789012
INFO:root:current train perplexity4.624532699584961
INFO:root:current mean train loss 1938.9302861562032
INFO:root:current train perplexity4.621217250823975
INFO:root:current mean train loss 1940.8658620890274
INFO:root:current train perplexity4.622699737548828
INFO:root:current mean train loss 1939.9710420260203
INFO:root:current train perplexity4.621789455413818
INFO:root:current mean train loss 1940.980954593906
INFO:root:current train perplexity4.6240081787109375
INFO:root:current mean train loss 1941.8984178712476
INFO:root:current train perplexity4.625519275665283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.20s/it]
INFO:root:final mean train loss: 1942.0372536678958
INFO:root:final train perplexity: 4.625606536865234
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.41s/it]
INFO:root:eval mean loss: 3166.869023320195
INFO:root:eval perplexity: 13.445538520812988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/13
 13%|â–ˆâ–Ž        | 13/100 [1:10:33<7:54:50, 327.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1973.3649597167969
INFO:root:current train perplexity4.573919296264648
INFO:root:current mean train loss 1925.1258728027344
INFO:root:current train perplexity4.531791687011719
INFO:root:current mean train loss 1930.6349687056108
INFO:root:current train perplexity4.552945613861084
INFO:root:current mean train loss 1921.9014499664306
INFO:root:current train perplexity4.539313793182373
INFO:root:current mean train loss 1924.5470540364583
INFO:root:current train perplexity4.539226531982422
INFO:root:current mean train loss 1924.6704876239482
INFO:root:current train perplexity4.5489301681518555
INFO:root:current mean train loss 1924.3277774933845
INFO:root:current train perplexity4.547432899475098
INFO:root:current mean train loss 1925.3102749294706
INFO:root:current train perplexity4.549383640289307
INFO:root:current mean train loss 1925.856109916873
INFO:root:current train perplexity4.551468849182129
INFO:root:current mean train loss 1926.0817669412363
INFO:root:current train perplexity4.551153659820557
INFO:root:current mean train loss 1923.587748927696
INFO:root:current train perplexity4.548914432525635
INFO:root:current mean train loss 1924.0925309317452
INFO:root:current train perplexity4.55094575881958
INFO:root:current mean train loss 1921.3650590740267
INFO:root:current train perplexity4.549051284790039
INFO:root:current mean train loss 1920.1855977376301
INFO:root:current train perplexity4.547860622406006
INFO:root:current mean train loss 1919.379200336295
INFO:root:current train perplexity4.5421857833862305
INFO:root:current mean train loss 1918.1478220086349
INFO:root:current train perplexity4.5397443771362305
INFO:root:current mean train loss 1917.7699179566937
INFO:root:current train perplexity4.536980152130127
INFO:root:current mean train loss 1917.4384732268577
INFO:root:current train perplexity4.535501003265381
INFO:root:current mean train loss 1917.8547249930245
INFO:root:current train perplexity4.5374064445495605
INFO:root:current mean train loss 1918.7495522816976
INFO:root:current train perplexity4.538346767425537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.67s/it]
INFO:root:final mean train loss: 1917.6261358140878
INFO:root:final train perplexity: 4.537405490875244
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 3183.472551408831
INFO:root:eval perplexity: 13.629973411560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/14
 14%|â–ˆâ–        | 14/100 [1:16:01<7:49:28, 327.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.9224061708192
INFO:root:current train perplexity4.427578926086426
INFO:root:current mean train loss 1876.0950321837934
INFO:root:current train perplexity4.43571662902832
INFO:root:current mean train loss 1891.5289651733913
INFO:root:current train perplexity4.459161758422852
INFO:root:current mean train loss 1888.0974197161304
INFO:root:current train perplexity4.45388126373291
INFO:root:current mean train loss 1886.8446363366168
INFO:root:current train perplexity4.4591450691223145
INFO:root:current mean train loss 1889.6064534959846
INFO:root:current train perplexity4.460128307342529
INFO:root:current mean train loss 1889.1801886206706
INFO:root:current train perplexity4.4536638259887695
INFO:root:current mean train loss 1886.7357931357064
INFO:root:current train perplexity4.451786518096924
INFO:root:current mean train loss 1887.897371535945
INFO:root:current train perplexity4.452876567840576
INFO:root:current mean train loss 1889.1568104551595
INFO:root:current train perplexity4.456512451171875
INFO:root:current mean train loss 1889.8733711794464
INFO:root:current train perplexity4.4585795402526855
INFO:root:current mean train loss 1892.4836824093352
INFO:root:current train perplexity4.4613494873046875
INFO:root:current mean train loss 1894.0792514612913
INFO:root:current train perplexity4.464204788208008
INFO:root:current mean train loss 1894.149989354227
INFO:root:current train perplexity4.463992118835449
INFO:root:current mean train loss 1894.3107098902608
INFO:root:current train perplexity4.4602532386779785
INFO:root:current mean train loss 1895.195221324516
INFO:root:current train perplexity4.464191436767578
INFO:root:current mean train loss 1895.0823754629275
INFO:root:current train perplexity4.462789058685303
INFO:root:current mean train loss 1895.7835032760102
INFO:root:current train perplexity4.460515975952148
INFO:root:current mean train loss 1895.6739625551809
INFO:root:current train perplexity4.458606719970703
INFO:root:current mean train loss 1896.6211431579118
INFO:root:current train perplexity4.459860801696777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.17s/it]
INFO:root:final mean train loss: 1895.4884057210902
INFO:root:final train perplexity: 4.458873748779297
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it]
INFO:root:eval mean loss: 3185.909593920092
INFO:root:eval perplexity: 13.657258987426758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/15
 15%|â–ˆâ–Œ        | 15/100 [1:21:29<7:44:21, 327.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.8714667426216
INFO:root:current train perplexity4.3778181076049805
INFO:root:current mean train loss 1876.681673124239
INFO:root:current train perplexity4.351341724395752
INFO:root:current mean train loss 1873.3166153074249
INFO:root:current train perplexity4.373124599456787
INFO:root:current mean train loss 1869.5823364257812
INFO:root:current train perplexity4.37762451171875
INFO:root:current mean train loss 1870.5935590970885
INFO:root:current train perplexity4.378299236297607
INFO:root:current mean train loss 1868.5571657036185
INFO:root:current train perplexity4.374985218048096
INFO:root:current mean train loss 1870.0653412145211
INFO:root:current train perplexity4.374794960021973
INFO:root:current mean train loss 1871.46975003756
INFO:root:current train perplexity4.380555152893066
INFO:root:current mean train loss 1872.7496376484285
INFO:root:current train perplexity4.3810296058654785
INFO:root:current mean train loss 1870.6958518358147
INFO:root:current train perplexity4.3771209716796875
INFO:root:current mean train loss 1871.1589010336368
INFO:root:current train perplexity4.377047538757324
INFO:root:current mean train loss 1870.516692216103
INFO:root:current train perplexity4.378095626831055
INFO:root:current mean train loss 1872.0397697095855
INFO:root:current train perplexity4.380825042724609
INFO:root:current mean train loss 1874.0464989621319
INFO:root:current train perplexity4.38544225692749
INFO:root:current mean train loss 1873.7714526400769
INFO:root:current train perplexity4.383244037628174
INFO:root:current mean train loss 1874.2985435299279
INFO:root:current train perplexity4.385663986206055
INFO:root:current mean train loss 1873.681171901569
INFO:root:current train perplexity4.3844218254089355
INFO:root:current mean train loss 1873.5471433598204
INFO:root:current train perplexity4.3832831382751465
INFO:root:current mean train loss 1873.3253159342976
INFO:root:current train perplexity4.3831048011779785
INFO:root:current mean train loss 1874.7404518400756
INFO:root:current train perplexity4.384820938110352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.03s/it]
INFO:root:final mean train loss: 1874.549964924022
INFO:root:final train perplexity: 4.385847091674805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 3190.7727622642174
INFO:root:eval perplexity: 13.711872100830078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/16
 16%|â–ˆâ–Œ        | 16/100 [1:26:57<7:38:42, 327.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.999843543684
INFO:root:current train perplexity4.395210266113281
INFO:root:current mean train loss 1850.8517395376462
INFO:root:current train perplexity4.328658580780029
INFO:root:current mean train loss 1848.0653211305062
INFO:root:current train perplexity4.327943325042725
INFO:root:current mean train loss 1850.2849387608449
INFO:root:current train perplexity4.3259124755859375
INFO:root:current mean train loss 1851.9613410317975
INFO:root:current train perplexity4.323668956756592
INFO:root:current mean train loss 1853.2248180275833
INFO:root:current train perplexity4.3205952644348145
INFO:root:current mean train loss 1851.7811284754564
INFO:root:current train perplexity4.317752838134766
INFO:root:current mean train loss 1853.9989274911843
INFO:root:current train perplexity4.317391872406006
INFO:root:current mean train loss 1853.408899388275
INFO:root:current train perplexity4.319628715515137
INFO:root:current mean train loss 1854.2020933738575
INFO:root:current train perplexity4.318843841552734
INFO:root:current mean train loss 1853.7251391441994
INFO:root:current train perplexity4.3156046867370605
INFO:root:current mean train loss 1854.6904132168686
INFO:root:current train perplexity4.315554618835449
INFO:root:current mean train loss 1853.2516301332919
INFO:root:current train perplexity4.313892364501953
INFO:root:current mean train loss 1853.5437098085054
INFO:root:current train perplexity4.31670618057251
INFO:root:current mean train loss 1853.207456379987
INFO:root:current train perplexity4.31668758392334
INFO:root:current mean train loss 1854.1210044700579
INFO:root:current train perplexity4.3193440437316895
INFO:root:current mean train loss 1853.894736526827
INFO:root:current train perplexity4.315890789031982
INFO:root:current mean train loss 1854.7529295496454
INFO:root:current train perplexity4.318658828735352
INFO:root:current mean train loss 1854.7438981807022
INFO:root:current train perplexity4.319603443145752
INFO:root:current mean train loss 1856.1443623581977
INFO:root:current train perplexity4.321570873260498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.12s/it]
INFO:root:final mean train loss: 1855.999235629314
INFO:root:final train perplexity: 4.322148323059082
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 3196.258639498874
INFO:root:eval perplexity: 13.773733139038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/17
 17%|â–ˆâ–‹        | 17/100 [1:32:25<7:33:35, 327.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1823.0203788063743
INFO:root:current train perplexity4.224781036376953
INFO:root:current mean train loss 1828.6468388983544
INFO:root:current train perplexity4.234009742736816
INFO:root:current mean train loss 1836.7167684766982
INFO:root:current train perplexity4.247222900390625
INFO:root:current mean train loss 1829.812662340931
INFO:root:current train perplexity4.24076509475708
INFO:root:current mean train loss 1832.9209874887936
INFO:root:current train perplexity4.252640724182129
INFO:root:current mean train loss 1835.1492405067495
INFO:root:current train perplexity4.255071640014648
INFO:root:current mean train loss 1836.4634181177894
INFO:root:current train perplexity4.260571002960205
INFO:root:current mean train loss 1834.2929582160136
INFO:root:current train perplexity4.257625579833984
INFO:root:current mean train loss 1835.2441837895024
INFO:root:current train perplexity4.258510112762451
INFO:root:current mean train loss 1838.7897702112855
INFO:root:current train perplexity4.262104511260986
INFO:root:current mean train loss 1840.0704283994787
INFO:root:current train perplexity4.261733531951904
INFO:root:current mean train loss 1840.0638161604654
INFO:root:current train perplexity4.25912618637085
INFO:root:current mean train loss 1837.6098909555756
INFO:root:current train perplexity4.255739688873291
INFO:root:current mean train loss 1836.6248885712637
INFO:root:current train perplexity4.253017902374268
INFO:root:current mean train loss 1837.162730309271
INFO:root:current train perplexity4.254075050354004
INFO:root:current mean train loss 1837.407482233696
INFO:root:current train perplexity4.257161617279053
INFO:root:current mean train loss 1838.4350349462427
INFO:root:current train perplexity4.260426998138428
INFO:root:current mean train loss 1838.1863702351616
INFO:root:current train perplexity4.261402606964111
INFO:root:current mean train loss 1838.2050280813444
INFO:root:current train perplexity4.2618536949157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.97s/it]
INFO:root:final mean train loss: 1838.3416896402625
INFO:root:final train perplexity: 4.26237678527832
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it]
INFO:root:eval mean loss: 3212.59471629833
INFO:root:eval perplexity: 13.959610939025879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/18
 18%|â–ˆâ–Š        | 18/100 [1:37:53<7:28:13, 327.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.063916015625
INFO:root:current train perplexity4.318665027618408
INFO:root:current mean train loss 1822.1990769159227
INFO:root:current train perplexity4.21602201461792
INFO:root:current mean train loss 1824.6456995522103
INFO:root:current train perplexity4.212795734405518
INFO:root:current mean train loss 1827.3405349481302
INFO:root:current train perplexity4.220175743103027
INFO:root:current mean train loss 1823.7206983024691
INFO:root:current train perplexity4.216109275817871
INFO:root:current mean train loss 1821.130374236154
INFO:root:current train perplexity4.208531379699707
INFO:root:current mean train loss 1825.2104046277764
INFO:root:current train perplexity4.216238021850586
INFO:root:current mean train loss 1825.0387115262079
INFO:root:current train perplexity4.219454765319824
INFO:root:current mean train loss 1824.8807304808813
INFO:root:current train perplexity4.214540481567383
INFO:root:current mean train loss 1826.7520712836672
INFO:root:current train perplexity4.2201924324035645
INFO:root:current mean train loss 1829.508162434896
INFO:root:current train perplexity4.226102828979492
INFO:root:current mean train loss 1826.941019160068
INFO:root:current train perplexity4.218219757080078
INFO:root:current mean train loss 1825.6047264004148
INFO:root:current train perplexity4.213625431060791
INFO:root:current mean train loss 1824.6371529648586
INFO:root:current train perplexity4.212596416473389
INFO:root:current mean train loss 1824.2076162317894
INFO:root:current train perplexity4.2107367515563965
INFO:root:current mean train loss 1822.5558853301495
INFO:root:current train perplexity4.208710670471191
INFO:root:current mean train loss 1821.398551812573
INFO:root:current train perplexity4.206559658050537
INFO:root:current mean train loss 1821.95533393569
INFO:root:current train perplexity4.207363128662109
INFO:root:current mean train loss 1821.0879036097645
INFO:root:current train perplexity4.205386638641357
INFO:root:current mean train loss 1821.4926347066723
INFO:root:current train perplexity4.206782341003418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.10s/it]
INFO:root:final mean train loss: 1822.3297719642844
INFO:root:final train perplexity: 4.208889484405518
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 3198.540644648555
INFO:root:eval perplexity: 13.799552917480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/19
 19%|â–ˆâ–‰        | 19/100 [1:43:22<7:22:54, 328.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1772.4146451083097
INFO:root:current train perplexity4.092761993408203
INFO:root:current mean train loss 1796.5401131051485
INFO:root:current train perplexity4.109208106994629
INFO:root:current mean train loss 1791.0161440737613
INFO:root:current train perplexity4.106984615325928
INFO:root:current mean train loss 1791.558777234569
INFO:root:current train perplexity4.107713222503662
INFO:root:current mean train loss 1801.0054416746889
INFO:root:current train perplexity4.118348598480225
INFO:root:current mean train loss 1802.0014255567528
INFO:root:current train perplexity4.125673770904541
INFO:root:current mean train loss 1801.563619828301
INFO:root:current train perplexity4.130007743835449
INFO:root:current mean train loss 1800.2313842773438
INFO:root:current train perplexity4.132472515106201
INFO:root:current mean train loss 1802.9261070678415
INFO:root:current train perplexity4.13535213470459
INFO:root:current mean train loss 1804.1355095654403
INFO:root:current train perplexity4.1376752853393555
INFO:root:current mean train loss 1803.5599031989589
INFO:root:current train perplexity4.140899658203125
INFO:root:current mean train loss 1804.0062503916695
INFO:root:current train perplexity4.144402027130127
INFO:root:current mean train loss 1805.1358040218072
INFO:root:current train perplexity4.147341728210449
INFO:root:current mean train loss 1807.0000200372601
INFO:root:current train perplexity4.152584552764893
INFO:root:current mean train loss 1807.1221153806534
INFO:root:current train perplexity4.151939392089844
INFO:root:current mean train loss 1808.0685217076625
INFO:root:current train perplexity4.155179023742676
INFO:root:current mean train loss 1807.9052924028013
INFO:root:current train perplexity4.154995918273926
INFO:root:current mean train loss 1808.0671996361425
INFO:root:current train perplexity4.157989025115967
INFO:root:current mean train loss 1808.6452974388549
INFO:root:current train perplexity4.160099983215332
INFO:root:current mean train loss 1808.7620541575548
INFO:root:current train perplexity4.160272598266602

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.60s/it]
INFO:root:final mean train loss: 1806.9339154849915
INFO:root:final train perplexity: 4.1580939292907715
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 3210.1216216216217
INFO:root:eval perplexity: 13.931313514709473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/20
 20%|â–ˆâ–ˆ        | 20/100 [1:48:49<7:17:17, 327.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1771.4947947966746
INFO:root:current train perplexity4.070429801940918
INFO:root:current mean train loss 1802.9515995601955
INFO:root:current train perplexity4.102949142456055
INFO:root:current mean train loss 1799.3661956148667
INFO:root:current train perplexity4.100789546966553
INFO:root:current mean train loss 1798.6120479437454
INFO:root:current train perplexity4.102059841156006
INFO:root:current mean train loss 1796.3452098385892
INFO:root:current train perplexity4.1020026206970215
INFO:root:current mean train loss 1796.8257911696285
INFO:root:current train perplexity4.109027862548828
INFO:root:current mean train loss 1794.6524142413073
INFO:root:current train perplexity4.111214637756348
INFO:root:current mean train loss 1795.9664291774145
INFO:root:current train perplexity4.112634658813477
INFO:root:current mean train loss 1794.4701306021398
INFO:root:current train perplexity4.1122894287109375
INFO:root:current mean train loss 1794.285326550436
INFO:root:current train perplexity4.109623908996582
INFO:root:current mean train loss 1793.8881850036094
INFO:root:current train perplexity4.109167575836182
INFO:root:current mean train loss 1794.4609944089868
INFO:root:current train perplexity4.110407829284668
INFO:root:current mean train loss 1792.828173374918
INFO:root:current train perplexity4.106723308563232
INFO:root:current mean train loss 1793.8486526865315
INFO:root:current train perplexity4.108447074890137
INFO:root:current mean train loss 1794.5415808470239
INFO:root:current train perplexity4.112399101257324
INFO:root:current mean train loss 1795.6852346795808
INFO:root:current train perplexity4.115880489349365
INFO:root:current mean train loss 1794.2183223442744
INFO:root:current train perplexity4.113138198852539
INFO:root:current mean train loss 1794.231812085003
INFO:root:current train perplexity4.113866806030273
INFO:root:current mean train loss 1794.0579050716465
INFO:root:current train perplexity4.112696170806885
INFO:root:current mean train loss 1792.9986217827327
INFO:root:current train perplexity4.111286640167236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.23s/it]
INFO:root:final mean train loss: 1791.9492884341118
INFO:root:final train perplexity: 4.109243869781494
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it]
INFO:root:eval mean loss: 3211.3876322611673
INFO:root:eval perplexity: 13.945796012878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/21
 21%|â–ˆâ–ˆ        | 21/100 [1:54:19<7:12:26, 328.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.956279209682
INFO:root:current train perplexity4.035947799682617
INFO:root:current mean train loss 1760.6932654747595
INFO:root:current train perplexity4.041727542877197
INFO:root:current mean train loss 1768.456847667694
INFO:root:current train perplexity4.058767318725586
INFO:root:current mean train loss 1773.9245794060525
INFO:root:current train perplexity4.068298816680908
INFO:root:current mean train loss 1774.161017702337
INFO:root:current train perplexity4.065237045288086
INFO:root:current mean train loss 1774.3020814305587
INFO:root:current train perplexity4.056976795196533
INFO:root:current mean train loss 1773.1614828342344
INFO:root:current train perplexity4.0566816329956055
INFO:root:current mean train loss 1774.5458654978918
INFO:root:current train perplexity4.056626796722412
INFO:root:current mean train loss 1774.6865318512248
INFO:root:current train perplexity4.058049201965332
INFO:root:current mean train loss 1776.4840588429981
INFO:root:current train perplexity4.059421539306641
INFO:root:current mean train loss 1776.2412419174657
INFO:root:current train perplexity4.059389591217041
INFO:root:current mean train loss 1776.4215131185458
INFO:root:current train perplexity4.058678150177002
INFO:root:current mean train loss 1776.2842075809551
INFO:root:current train perplexity4.057216644287109
INFO:root:current mean train loss 1777.6303142896445
INFO:root:current train perplexity4.061257839202881
INFO:root:current mean train loss 1778.0671561943307
INFO:root:current train perplexity4.06081485748291
INFO:root:current mean train loss 1778.689333172874
INFO:root:current train perplexity4.062597274780273
INFO:root:current mean train loss 1779.1342678346496
INFO:root:current train perplexity4.061959743499756
INFO:root:current mean train loss 1779.4284975230014
INFO:root:current train perplexity4.063604831695557
INFO:root:current mean train loss 1779.703920890545
INFO:root:current train perplexity4.0647430419921875
INFO:root:current mean train loss 1779.2300574179808
INFO:root:current train perplexity4.066102981567383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.14s/it]
INFO:root:final mean train loss: 1778.8900162797352
INFO:root:final train perplexity: 4.067138671875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 3222.147100225225
INFO:root:eval perplexity: 14.069459915161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/22
 22%|â–ˆâ–ˆâ–       | 22/100 [1:59:46<7:06:29, 328.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.9108201118365
INFO:root:current train perplexity4.021233558654785
INFO:root:current mean train loss 1763.401553468208
INFO:root:current train perplexity4.011135101318359
INFO:root:current mean train loss 1762.8977976369333
INFO:root:current train perplexity4.012356758117676
INFO:root:current mean train loss 1761.1699382383126
INFO:root:current train perplexity4.015058994293213
INFO:root:current mean train loss 1759.517899946733
INFO:root:current train perplexity4.003605365753174
INFO:root:current mean train loss 1761.9187331274543
INFO:root:current train perplexity4.010952472686768
INFO:root:current mean train loss 1762.7475625841614
INFO:root:current train perplexity4.015236854553223
INFO:root:current mean train loss 1761.3266004633933
INFO:root:current train perplexity4.01481819152832
INFO:root:current mean train loss 1761.4206898133234
INFO:root:current train perplexity4.015201091766357
INFO:root:current mean train loss 1764.098532571822
INFO:root:current train perplexity4.019733428955078
INFO:root:current mean train loss 1766.08990381815
INFO:root:current train perplexity4.024254322052002
INFO:root:current mean train loss 1766.1391483967059
INFO:root:current train perplexity4.024501800537109
INFO:root:current mean train loss 1765.4532743994869
INFO:root:current train perplexity4.024085998535156
INFO:root:current mean train loss 1764.810347454963
INFO:root:current train perplexity4.0236077308654785
INFO:root:current mean train loss 1765.797625322206
INFO:root:current train perplexity4.023622035980225
INFO:root:current mean train loss 1767.2650584944174
INFO:root:current train perplexity4.028931140899658
INFO:root:current mean train loss 1767.6135094842723
INFO:root:current train perplexity4.028355598449707
INFO:root:current mean train loss 1766.6995391071146
INFO:root:current train perplexity4.026025295257568
INFO:root:current mean train loss 1766.705007085683
INFO:root:current train perplexity4.025931358337402
INFO:root:current mean train loss 1767.0774901477564
INFO:root:current train perplexity4.02742862701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.78s/it]
INFO:root:final mean train loss: 1766.2516403775353
INFO:root:final train perplexity: 4.026801109313965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it]
INFO:root:eval mean loss: 3232.8869738879503
INFO:root:eval perplexity: 14.19400405883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:05:14<7:01:03, 328.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.5071790907118
INFO:root:current train perplexity3.991655111312866
INFO:root:current mean train loss 1750.6937718441611
INFO:root:current train perplexity3.9535272121429443
INFO:root:current mean train loss 1752.6839477539063
INFO:root:current train perplexity3.9670662879943848
INFO:root:current mean train loss 1757.8297973632812
INFO:root:current train perplexity3.979811191558838
INFO:root:current mean train loss 1749.7017413703763
INFO:root:current train perplexity3.967667818069458
INFO:root:current mean train loss 1753.2302237817796
INFO:root:current train perplexity3.977064847946167
INFO:root:current mean train loss 1755.6133286628171
INFO:root:current train perplexity3.9842121601104736
INFO:root:current mean train loss 1756.0541724868967
INFO:root:current train perplexity3.9814646244049072
INFO:root:current mean train loss 1755.5295353921613
INFO:root:current train perplexity3.9825520515441895
INFO:root:current mean train loss 1757.4658258611505
INFO:root:current train perplexity3.989168167114258
INFO:root:current mean train loss 1755.206890701154
INFO:root:current train perplexity3.9873015880584717
INFO:root:current mean train loss 1753.187204877068
INFO:root:current train perplexity3.979418992996216
INFO:root:current mean train loss 1752.0717693949855
INFO:root:current train perplexity3.9755451679229736
INFO:root:current mean train loss 1752.0674899533499
INFO:root:current train perplexity3.977968454360962
INFO:root:current mean train loss 1752.282320613989
INFO:root:current train perplexity3.9798154830932617
INFO:root:current mean train loss 1753.8967925449588
INFO:root:current train perplexity3.984165668487549
INFO:root:current mean train loss 1753.2096959221292
INFO:root:current train perplexity3.9848082065582275
INFO:root:current mean train loss 1753.5282149501354
INFO:root:current train perplexity3.9859721660614014
INFO:root:current mean train loss 1754.045470610119
INFO:root:current train perplexity3.9872548580169678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.91s/it]
INFO:root:final mean train loss: 1753.7855762322022
INFO:root:final train perplexity: 3.98740553855896
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it]
INFO:root:eval mean loss: 3226.521953594219
INFO:root:eval perplexity: 14.120064735412598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:10:43<6:55:40, 328.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1671.5973597935267
INFO:root:current train perplexity3.8392326831817627
INFO:root:current mean train loss 1715.9918566552278
INFO:root:current train perplexity3.896357297897339
INFO:root:current mean train loss 1725.251341594014
INFO:root:current train perplexity3.913121223449707
INFO:root:current mean train loss 1730.8317083799877
INFO:root:current train perplexity3.9282619953155518
INFO:root:current mean train loss 1731.7616737609414
INFO:root:current train perplexity3.9276280403137207
INFO:root:current mean train loss 1731.5613341924002
INFO:root:current train perplexity3.9249534606933594
INFO:root:current mean train loss 1733.5304224557892
INFO:root:current train perplexity3.932579517364502
INFO:root:current mean train loss 1736.7059992637796
INFO:root:current train perplexity3.940284013748169
INFO:root:current mean train loss 1735.497358773573
INFO:root:current train perplexity3.937068462371826
INFO:root:current mean train loss 1736.8152610501222
INFO:root:current train perplexity3.939646005630493
INFO:root:current mean train loss 1737.535073819203
INFO:root:current train perplexity3.9438018798828125
INFO:root:current mean train loss 1738.4695324850384
INFO:root:current train perplexity3.9436240196228027
INFO:root:current mean train loss 1741.7936893390445
INFO:root:current train perplexity3.9524688720703125
INFO:root:current mean train loss 1741.2897049802446
INFO:root:current train perplexity3.9505817890167236
INFO:root:current mean train loss 1741.3245788010283
INFO:root:current train perplexity3.9507274627685547
INFO:root:current mean train loss 1742.2213534916484
INFO:root:current train perplexity3.9511051177978516
INFO:root:current mean train loss 1744.102891828232
INFO:root:current train perplexity3.95386004447937
INFO:root:current mean train loss 1743.3973530979972
INFO:root:current train perplexity3.9537370204925537
INFO:root:current mean train loss 1743.3627074452218
INFO:root:current train perplexity3.9538750648498535
INFO:root:current mean train loss 1743.0145851299285
INFO:root:current train perplexity3.9532594680786133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.82s/it]
INFO:root:final mean train loss: 1742.2855467765066
INFO:root:final train perplexity: 3.9514050483703613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it]
INFO:root:eval mean loss: 3245.9982089022615
INFO:root:eval perplexity: 14.34753704071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:16:12<6:50:30, 328.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.4663187662761
INFO:root:current train perplexity3.867311954498291
INFO:root:current mean train loss 1702.5133194461946
INFO:root:current train perplexity3.8868730068206787
INFO:root:current mean train loss 1716.920887538365
INFO:root:current train perplexity3.9079666137695312
INFO:root:current mean train loss 1723.815697564019
INFO:root:current train perplexity3.9034969806671143
INFO:root:current mean train loss 1721.7903620881855
INFO:root:current train perplexity3.897145986557007
INFO:root:current mean train loss 1723.7404736234942
INFO:root:current train perplexity3.898125648498535
INFO:root:current mean train loss 1727.482023777106
INFO:root:current train perplexity3.9068217277526855
INFO:root:current mean train loss 1729.6238089714261
INFO:root:current train perplexity3.912478446960449
INFO:root:current mean train loss 1730.4348061570843
INFO:root:current train perplexity3.9121429920196533
INFO:root:current mean train loss 1729.3089146469579
INFO:root:current train perplexity3.90755295753479
INFO:root:current mean train loss 1730.314165711403
INFO:root:current train perplexity3.9133920669555664
INFO:root:current mean train loss 1731.0069065297625
INFO:root:current train perplexity3.911588191986084
INFO:root:current mean train loss 1730.1019655115465
INFO:root:current train perplexity3.9086735248565674
INFO:root:current mean train loss 1730.1468603589383
INFO:root:current train perplexity3.9105944633483887
INFO:root:current mean train loss 1731.308358267452
INFO:root:current train perplexity3.9129536151885986
INFO:root:current mean train loss 1731.6650488345329
INFO:root:current train perplexity3.913804531097412
INFO:root:current mean train loss 1732.191180374822
INFO:root:current train perplexity3.914016008377075
INFO:root:current mean train loss 1733.0656027384534
INFO:root:current train perplexity3.916128635406494
INFO:root:current mean train loss 1732.2292309141997
INFO:root:current train perplexity3.917109727859497
INFO:root:current mean train loss 1732.4184709893939
INFO:root:current train perplexity3.9170260429382324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it]
INFO:root:final mean train loss: 1730.9395349976755
INFO:root:final train perplexity: 3.9162049293518066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 3235.460425757789
INFO:root:eval perplexity: 14.22401237487793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:21:40<6:44:54, 328.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.2509438119284
INFO:root:current train perplexity3.879594564437866
INFO:root:current mean train loss 1712.7053162053967
INFO:root:current train perplexity3.870802640914917
INFO:root:current mean train loss 1714.5692174127983
INFO:root:current train perplexity3.8792073726654053
INFO:root:current mean train loss 1725.2050659537665
INFO:root:current train perplexity3.8938772678375244
INFO:root:current mean train loss 1718.469146105708
INFO:root:current train perplexity3.887032985687256
INFO:root:current mean train loss 1720.699205211703
INFO:root:current train perplexity3.889188051223755
INFO:root:current mean train loss 1720.8248233884433
INFO:root:current train perplexity3.890436887741089
INFO:root:current mean train loss 1720.5688761557967
INFO:root:current train perplexity3.8914804458618164
INFO:root:current mean train loss 1724.8546866871657
INFO:root:current train perplexity3.8989462852478027
INFO:root:current mean train loss 1722.4683626440456
INFO:root:current train perplexity3.8916432857513428
INFO:root:current mean train loss 1720.4573235855323
INFO:root:current train perplexity3.8876421451568604
INFO:root:current mean train loss 1721.7869991800642
INFO:root:current train perplexity3.886953115463257
INFO:root:current mean train loss 1721.62862374723
INFO:root:current train perplexity3.885035276412964
INFO:root:current mean train loss 1721.8722589252422
INFO:root:current train perplexity3.886336088180542
INFO:root:current mean train loss 1722.186360874745
INFO:root:current train perplexity3.888016700744629
INFO:root:current mean train loss 1721.8854397446362
INFO:root:current train perplexity3.887850284576416
INFO:root:current mean train loss 1720.9879573656974
INFO:root:current train perplexity3.8856935501098633
INFO:root:current mean train loss 1720.7704024295708
INFO:root:current train perplexity3.8848116397857666
INFO:root:current mean train loss 1720.880836764475
INFO:root:current train perplexity3.884284734725952
INFO:root:current mean train loss 1720.9862685677688
INFO:root:current train perplexity3.8845064640045166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.30s/it]
INFO:root:final mean train loss: 1720.767911217517
INFO:root:final train perplexity: 3.8849148750305176
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 3245.4670446814002
INFO:root:eval perplexity: 14.34128475189209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:27:08<6:39:27, 328.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.9527461610992
INFO:root:current train perplexity3.846867322921753
INFO:root:current mean train loss 1706.519169674644
INFO:root:current train perplexity3.8289549350738525
INFO:root:current mean train loss 1696.6529370684957
INFO:root:current train perplexity3.8327653408050537
INFO:root:current mean train loss 1697.1215489563328
INFO:root:current train perplexity3.831066608428955
INFO:root:current mean train loss 1699.4623154552744
INFO:root:current train perplexity3.8361241817474365
INFO:root:current mean train loss 1705.1938207482779
INFO:root:current train perplexity3.84511661529541
INFO:root:current mean train loss 1706.5071411132812
INFO:root:current train perplexity3.846421718597412
INFO:root:current mean train loss 1707.9200904866323
INFO:root:current train perplexity3.8488287925720215
INFO:root:current mean train loss 1708.4609133135743
INFO:root:current train perplexity3.850695848464966
INFO:root:current mean train loss 1707.4790083660214
INFO:root:current train perplexity3.846768379211426
INFO:root:current mean train loss 1706.544991678912
INFO:root:current train perplexity3.844736099243164
INFO:root:current mean train loss 1707.923034984213
INFO:root:current train perplexity3.8461503982543945
INFO:root:current mean train loss 1709.2965763255788
INFO:root:current train perplexity3.8481879234313965
INFO:root:current mean train loss 1708.6924398925062
INFO:root:current train perplexity3.8454978466033936
INFO:root:current mean train loss 1708.995484486856
INFO:root:current train perplexity3.8465981483459473
INFO:root:current mean train loss 1709.680458862148
INFO:root:current train perplexity3.847994327545166
INFO:root:current mean train loss 1709.6039833648645
INFO:root:current train perplexity3.8479580879211426
INFO:root:current mean train loss 1708.8634047090532
INFO:root:current train perplexity3.8460865020751953
INFO:root:current mean train loss 1709.820981258725
INFO:root:current train perplexity3.8502793312072754
INFO:root:current mean train loss 1710.274982269256
INFO:root:current train perplexity3.8513853549957275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.39s/it]
INFO:root:final mean train loss: 1710.1043772887415
INFO:root:final train perplexity: 3.8523802757263184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 3245.830682244745
INFO:root:eval perplexity: 14.345562934875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:32:36<6:34:02, 328.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.4192350260416
INFO:root:current train perplexity3.869763135910034
INFO:root:current mean train loss 1707.183185686384
INFO:root:current train perplexity3.8174383640289307
INFO:root:current mean train loss 1703.3030078125
INFO:root:current train perplexity3.818464994430542
INFO:root:current mean train loss 1704.172576171875
INFO:root:current train perplexity3.8251824378967285
INFO:root:current mean train loss 1704.7544939864308
INFO:root:current train perplexity3.8293871879577637
INFO:root:current mean train loss 1699.8041680112092
INFO:root:current train perplexity3.818142890930176
INFO:root:current mean train loss 1699.5825967520254
INFO:root:current train perplexity3.8188529014587402
INFO:root:current mean train loss 1703.257902280746
INFO:root:current train perplexity3.8259904384613037
INFO:root:current mean train loss 1703.4348327287946
INFO:root:current train perplexity3.82505202293396
INFO:root:current mean train loss 1704.9180462489985
INFO:root:current train perplexity3.8264238834381104
INFO:root:current mean train loss 1705.7104932776163
INFO:root:current train perplexity3.8277642726898193
INFO:root:current mean train loss 1704.2313530585106
INFO:root:current train perplexity3.8280179500579834
INFO:root:current mean train loss 1702.048013939951
INFO:root:current train perplexity3.8241491317749023
INFO:root:current mean train loss 1700.806840287642
INFO:root:current train perplexity3.8240749835968018
INFO:root:current mean train loss 1700.659418862553
INFO:root:current train perplexity3.822492837905884
INFO:root:current mean train loss 1702.1857866753471
INFO:root:current train perplexity3.824471950531006
INFO:root:current mean train loss 1702.495655025653
INFO:root:current train perplexity3.8255562782287598
INFO:root:current mean train loss 1701.8486633472712
INFO:root:current train perplexity3.8250656127929688
INFO:root:current mean train loss 1702.0328511067707
INFO:root:current train perplexity3.826148748397827
INFO:root:current mean train loss 1701.5136617385285
INFO:root:current train perplexity3.8253984451293945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it]
INFO:root:final mean train loss: 1701.2378172227607
INFO:root:final train perplexity: 3.825535297393799
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 3251.748481635933
INFO:root:eval perplexity: 14.415395736694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:38:06<6:28:51, 328.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1683.6093418287194
INFO:root:current train perplexity3.767981767654419
INFO:root:current mean train loss 1684.3443298339844
INFO:root:current train perplexity3.779564619064331
INFO:root:current mean train loss 1691.00284900404
INFO:root:current train perplexity3.781568765640259
INFO:root:current mean train loss 1692.7944058788066
INFO:root:current train perplexity3.785897970199585
INFO:root:current mean train loss 1699.0538799006765
INFO:root:current train perplexity3.7930870056152344
INFO:root:current mean train loss 1698.796939128154
INFO:root:current train perplexity3.797191619873047
INFO:root:current mean train loss 1697.9887691784456
INFO:root:current train perplexity3.7920913696289062
INFO:root:current mean train loss 1695.6789355037188
INFO:root:current train perplexity3.79009747505188
INFO:root:current mean train loss 1697.0856417668774
INFO:root:current train perplexity3.791825532913208
INFO:root:current mean train loss 1697.0258777987572
INFO:root:current train perplexity3.7941575050354004
INFO:root:current mean train loss 1695.8927314953926
INFO:root:current train perplexity3.7916126251220703
INFO:root:current mean train loss 1695.505682721234
INFO:root:current train perplexity3.792924165725708
INFO:root:current mean train loss 1695.1344349391688
INFO:root:current train perplexity3.7930498123168945
INFO:root:current mean train loss 1694.7366444379434
INFO:root:current train perplexity3.7947494983673096
INFO:root:current mean train loss 1696.0248490811673
INFO:root:current train perplexity3.7976837158203125
INFO:root:current mean train loss 1695.1437522083072
INFO:root:current train perplexity3.796536445617676
INFO:root:current mean train loss 1693.8808647859182
INFO:root:current train perplexity3.795009136199951
INFO:root:current mean train loss 1691.9491049221583
INFO:root:current train perplexity3.794620990753174
INFO:root:current mean train loss 1691.8091076453695
INFO:root:current train perplexity3.795764207839966

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it]
INFO:root:final mean train loss: 1691.4640479845286
INFO:root:final train perplexity: 3.79616117477417
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 3260.8757382871154
INFO:root:eval perplexity: 14.523768424987793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:43:34<6:23:26, 328.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.1820475260417
INFO:root:current train perplexity3.7752110958099365
INFO:root:current mean train loss 1669.0835028132167
INFO:root:current train perplexity3.7608695030212402
INFO:root:current mean train loss 1680.6353216581938
INFO:root:current train perplexity3.7714173793792725
INFO:root:current mean train loss 1680.4712166894215
INFO:root:current train perplexity3.7747998237609863
INFO:root:current mean train loss 1683.7166676416373
INFO:root:current train perplexity3.7699592113494873
INFO:root:current mean train loss 1678.3650473124385
INFO:root:current train perplexity3.755101203918457
INFO:root:current mean train loss 1679.5790438346676
INFO:root:current train perplexity3.7573087215423584
INFO:root:current mean train loss 1678.7381712317635
INFO:root:current train perplexity3.7575161457061768
INFO:root:current mean train loss 1679.631223775253
INFO:root:current train perplexity3.756803035736084
INFO:root:current mean train loss 1680.1585604727466
INFO:root:current train perplexity3.7590668201446533
INFO:root:current mean train loss 1681.581839373374
INFO:root:current train perplexity3.762047290802002
INFO:root:current mean train loss 1680.8751210796606
INFO:root:current train perplexity3.7610156536102295
INFO:root:current mean train loss 1681.664065730976
INFO:root:current train perplexity3.7649595737457275
INFO:root:current mean train loss 1682.0797950971937
INFO:root:current train perplexity3.765289783477783
INFO:root:current mean train loss 1682.7141815033933
INFO:root:current train perplexity3.765383720397949
INFO:root:current mean train loss 1682.7682664591875
INFO:root:current train perplexity3.766780376434326
INFO:root:current mean train loss 1682.9193585610967
INFO:root:current train perplexity3.7671570777893066
INFO:root:current mean train loss 1683.0628829250704
INFO:root:current train perplexity3.769068956375122
INFO:root:current mean train loss 1682.6591162568236
INFO:root:current train perplexity3.7687392234802246
INFO:root:current mean train loss 1682.4424999590753
INFO:root:current train perplexity3.7684547901153564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.37s/it]
INFO:root:final mean train loss: 1682.110031151014
INFO:root:final train perplexity: 3.768259286880493
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it]
INFO:root:eval mean loss: 3260.512355128566
INFO:root:eval perplexity: 14.519436836242676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:49:04<6:18:17, 328.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1673.8657977764424
INFO:root:current train perplexity3.7566816806793213
INFO:root:current mean train loss 1669.9610440693205
INFO:root:current train perplexity3.7295799255371094
INFO:root:current mean train loss 1671.411106886062
INFO:root:current train perplexity3.7279245853424072
INFO:root:current mean train loss 1662.5245290182852
INFO:root:current train perplexity3.7079994678497314
INFO:root:current mean train loss 1662.1505553912668
INFO:root:current train perplexity3.708134412765503
INFO:root:current mean train loss 1664.1203648092176
INFO:root:current train perplexity3.71225905418396
INFO:root:current mean train loss 1666.092250836162
INFO:root:current train perplexity3.718163251876831
INFO:root:current mean train loss 1668.7872116046833
INFO:root:current train perplexity3.7210285663604736
INFO:root:current mean train loss 1672.3521017670344
INFO:root:current train perplexity3.727280855178833
INFO:root:current mean train loss 1670.6229321869093
INFO:root:current train perplexity3.726102590560913
INFO:root:current mean train loss 1670.970176533184
INFO:root:current train perplexity3.730457305908203
INFO:root:current mean train loss 1672.9295473251207
INFO:root:current train perplexity3.7366318702697754
INFO:root:current mean train loss 1673.1182755786092
INFO:root:current train perplexity3.7386720180511475
INFO:root:current mean train loss 1673.8454177419164
INFO:root:current train perplexity3.7387232780456543
INFO:root:current mean train loss 1673.2192797132495
INFO:root:current train perplexity3.740267038345337
INFO:root:current mean train loss 1672.1313418167135
INFO:root:current train perplexity3.7403347492218018
INFO:root:current mean train loss 1673.2861789830056
INFO:root:current train perplexity3.742509126663208
INFO:root:current mean train loss 1674.1761947755604
INFO:root:current train perplexity3.7446212768554688
INFO:root:current mean train loss 1673.8154780877771
INFO:root:current train perplexity3.7433226108551025
INFO:root:current mean train loss 1673.9452161620586
INFO:root:current train perplexity3.7445695400238037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.05s/it]
INFO:root:final mean train loss: 1674.1540186310199
INFO:root:final train perplexity: 3.7446892261505127
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 3281.851212785051
INFO:root:eval perplexity: 14.775914192199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:54:33<6:12:52, 329.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1638.2511809593022
INFO:root:current train perplexity3.6195783615112305
INFO:root:current mean train loss 1659.2576323822661
INFO:root:current train perplexity3.6729953289031982
INFO:root:current mean train loss 1667.236157829379
INFO:root:current train perplexity3.6996254920959473
INFO:root:current mean train loss 1667.710423238771
INFO:root:current train perplexity3.7079434394836426
INFO:root:current mean train loss 1662.7992811353697
INFO:root:current train perplexity3.702650308609009
INFO:root:current mean train loss 1659.3518320438393
INFO:root:current train perplexity3.699129819869995
INFO:root:current mean train loss 1656.7224521666626
INFO:root:current train perplexity3.699425220489502
INFO:root:current mean train loss 1658.5076178118165
INFO:root:current train perplexity3.7037606239318848
INFO:root:current mean train loss 1659.3807539572213
INFO:root:current train perplexity3.7070908546447754
INFO:root:current mean train loss 1662.4576378475444
INFO:root:current train perplexity3.711407423019409
INFO:root:current mean train loss 1662.9123889780456
INFO:root:current train perplexity3.71301007270813
INFO:root:current mean train loss 1662.8285895720555
INFO:root:current train perplexity3.712749481201172
INFO:root:current mean train loss 1664.2926746224168
INFO:root:current train perplexity3.714233875274658
INFO:root:current mean train loss 1664.5887951996463
INFO:root:current train perplexity3.7137272357940674
INFO:root:current mean train loss 1664.8824664226277
INFO:root:current train perplexity3.714815139770508
INFO:root:current mean train loss 1666.2045951442756
INFO:root:current train perplexity3.7163662910461426
INFO:root:current mean train loss 1666.844659695013
INFO:root:current train perplexity3.7170636653900146
INFO:root:current mean train loss 1666.0943100667178
INFO:root:current train perplexity3.7170166969299316
INFO:root:current mean train loss 1665.70338762007
INFO:root:current train perplexity3.7184619903564453
INFO:root:current mean train loss 1665.8623214619588
INFO:root:current train perplexity3.7187507152557373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.59s/it]
INFO:root:final mean train loss: 1665.105268315841
INFO:root:final train perplexity: 3.7180609703063965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 3285.5197350670983
INFO:root:eval perplexity: 14.820456504821777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:00:02<6:07:18, 328.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1627.647442626953
INFO:root:current train perplexity3.6328811645507812
INFO:root:current mean train loss 1639.8395568847657
INFO:root:current train perplexity3.6737568378448486
INFO:root:current mean train loss 1642.0601323054386
INFO:root:current train perplexity3.6782867908477783
INFO:root:current mean train loss 1645.0683312310114
INFO:root:current train perplexity3.683558464050293
INFO:root:current mean train loss 1643.5827673870583
INFO:root:current train perplexity3.6826653480529785
INFO:root:current mean train loss 1645.7919063023157
INFO:root:current train perplexity3.6815640926361084
INFO:root:current mean train loss 1648.4672598174125
INFO:root:current train perplexity3.686953544616699
INFO:root:current mean train loss 1651.0487550434314
INFO:root:current train perplexity3.6870949268341064
INFO:root:current mean train loss 1653.591531159157
INFO:root:current train perplexity3.6884231567382812
INFO:root:current mean train loss 1654.8537239074708
INFO:root:current train perplexity3.6874778270721436
INFO:root:current mean train loss 1654.4516199651755
INFO:root:current train perplexity3.6865642070770264
INFO:root:current mean train loss 1653.5731998838228
INFO:root:current train perplexity3.6856048107147217
INFO:root:current mean train loss 1654.3927398197234
INFO:root:current train perplexity3.688013792037964
INFO:root:current mean train loss 1654.0120330810546
INFO:root:current train perplexity3.6880340576171875
INFO:root:current mean train loss 1653.8745878036707
INFO:root:current train perplexity3.687243938446045
INFO:root:current mean train loss 1653.4286322960486
INFO:root:current train perplexity3.687483072280884
INFO:root:current mean train loss 1653.801712955337
INFO:root:current train perplexity3.688070058822632
INFO:root:current mean train loss 1655.8695595481179
INFO:root:current train perplexity3.6911892890930176
INFO:root:current mean train loss 1657.0289162256383
INFO:root:current train perplexity3.6938295364379883
INFO:root:current mean train loss 1658.4971198879944
INFO:root:current train perplexity3.6975438594818115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it]
INFO:root:final mean train loss: 1657.664223629119
INFO:root:final train perplexity: 3.6963047981262207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it]
INFO:root:eval mean loss: 3277.5674649258635
INFO:root:eval perplexity: 14.724067687988281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:05:31<6:01:52, 328.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1666.0509810014205
INFO:root:current train perplexity3.6578125953674316
INFO:root:current mean train loss 1659.6823930470957
INFO:root:current train perplexity3.6670427322387695
INFO:root:current mean train loss 1649.826090347896
INFO:root:current train perplexity3.6576051712036133
INFO:root:current mean train loss 1648.9471726961415
INFO:root:current train perplexity3.661851406097412
INFO:root:current mean train loss 1646.110478495152
INFO:root:current train perplexity3.66375470161438
INFO:root:current mean train loss 1647.6626587971864
INFO:root:current train perplexity3.6666882038116455
INFO:root:current mean train loss 1646.3021977704948
INFO:root:current train perplexity3.6627376079559326
INFO:root:current mean train loss 1646.8705465545065
INFO:root:current train perplexity3.6598622798919678
INFO:root:current mean train loss 1645.375952204114
INFO:root:current train perplexity3.6569344997406006
INFO:root:current mean train loss 1645.8849732819697
INFO:root:current train perplexity3.65887188911438
INFO:root:current mean train loss 1646.4675073083508
INFO:root:current train perplexity3.661421775817871
INFO:root:current mean train loss 1647.2895002729729
INFO:root:current train perplexity3.662848949432373
INFO:root:current mean train loss 1649.1073119448047
INFO:root:current train perplexity3.6684186458587646
INFO:root:current mean train loss 1649.2299312682972
INFO:root:current train perplexity3.668766736984253
INFO:root:current mean train loss 1648.5873292007395
INFO:root:current train perplexity3.6684231758117676
INFO:root:current mean train loss 1648.6283883994035
INFO:root:current train perplexity3.6682193279266357
INFO:root:current mean train loss 1649.6074338854958
INFO:root:current train perplexity3.67038631439209
INFO:root:current mean train loss 1649.8254977061497
INFO:root:current train perplexity3.6712071895599365
INFO:root:current mean train loss 1650.2271836473387
INFO:root:current train perplexity3.6727988719940186
INFO:root:current mean train loss 1649.963292956895
INFO:root:current train perplexity3.672818899154663

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.68s/it]
INFO:root:final mean train loss: 1649.5339360393423
INFO:root:final train perplexity: 3.672680139541626
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it]
INFO:root:eval mean loss: 3288.4455837673613
INFO:root:eval perplexity: 14.856088638305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:11:01<5:56:35, 329.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1664.0241608315325
INFO:root:current train perplexity3.6879196166992188
INFO:root:current mean train loss 1649.357676712508
INFO:root:current train perplexity3.657771348953247
INFO:root:current mean train loss 1648.3337821700945
INFO:root:current train perplexity3.6508986949920654
INFO:root:current mean train loss 1643.9234516898994
INFO:root:current train perplexity3.641874313354492
INFO:root:current mean train loss 1641.4480887347388
INFO:root:current train perplexity3.6441378593444824
INFO:root:current mean train loss 1643.2914545849117
INFO:root:current train perplexity3.646867275238037
INFO:root:current mean train loss 1642.5256537621578
INFO:root:current train perplexity3.6486966609954834
INFO:root:current mean train loss 1643.1480268579287
INFO:root:current train perplexity3.6470134258270264
INFO:root:current mean train loss 1642.9048722713053
INFO:root:current train perplexity3.648573160171509
INFO:root:current mean train loss 1641.072529537577
INFO:root:current train perplexity3.645702838897705
INFO:root:current mean train loss 1642.6735911255998
INFO:root:current train perplexity3.6478052139282227
INFO:root:current mean train loss 1643.3883599516134
INFO:root:current train perplexity3.6471121311187744
INFO:root:current mean train loss 1643.1181716093508
INFO:root:current train perplexity3.6498396396636963
INFO:root:current mean train loss 1643.139876202839
INFO:root:current train perplexity3.6493115425109863
INFO:root:current mean train loss 1643.4348941991925
INFO:root:current train perplexity3.649698257446289
INFO:root:current mean train loss 1642.2713212572048
INFO:root:current train perplexity3.648329734802246
INFO:root:current mean train loss 1641.9364938927372
INFO:root:current train perplexity3.6483139991760254
INFO:root:current mean train loss 1642.7408059416805
INFO:root:current train perplexity3.6502695083618164
INFO:root:current mean train loss 1642.7550793882408
INFO:root:current train perplexity3.6513261795043945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.44s/it]
INFO:root:final mean train loss: 1642.2623116189761
INFO:root:final train perplexity: 3.6516788005828857
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.72s/it]
INFO:root:eval mean loss: 3289.769636824324
INFO:root:eval perplexity: 14.872234344482422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:16:29<5:50:58, 329.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1668.7541392933238
INFO:root:current train perplexity3.7272655963897705
INFO:root:current mean train loss 1620.9103695981137
INFO:root:current train perplexity3.620098352432251
INFO:root:current mean train loss 1612.4146682233043
INFO:root:current train perplexity3.5886001586914062
INFO:root:current mean train loss 1620.1722172678858
INFO:root:current train perplexity3.604511022567749
INFO:root:current mean train loss 1622.6208104043112
INFO:root:current train perplexity3.598862648010254
INFO:root:current mean train loss 1625.2151363843109
INFO:root:current train perplexity3.60676908493042
INFO:root:current mean train loss 1628.606192581002
INFO:root:current train perplexity3.613900899887085
INFO:root:current mean train loss 1629.5331864712443
INFO:root:current train perplexity3.6152384281158447
INFO:root:current mean train loss 1628.2340524393592
INFO:root:current train perplexity3.6163220405578613
INFO:root:current mean train loss 1627.1124946937603
INFO:root:current train perplexity3.6163578033447266
INFO:root:current mean train loss 1627.7531124911134
INFO:root:current train perplexity3.617845058441162
INFO:root:current mean train loss 1627.5086910546524
INFO:root:current train perplexity3.617953300476074
INFO:root:current mean train loss 1629.0365068859348
INFO:root:current train perplexity3.61917781829834
INFO:root:current mean train loss 1628.6186655657061
INFO:root:current train perplexity3.61934494972229
INFO:root:current mean train loss 1631.966960644739
INFO:root:current train perplexity3.6226863861083984
INFO:root:current mean train loss 1632.4102745232876
INFO:root:current train perplexity3.625195026397705
INFO:root:current mean train loss 1633.2236141723406
INFO:root:current train perplexity3.6264781951904297
INFO:root:current mean train loss 1634.4028475129903
INFO:root:current train perplexity3.6274633407592773
INFO:root:current mean train loss 1634.621811612412
INFO:root:current train perplexity3.628598928451538
INFO:root:current mean train loss 1634.5444415784643
INFO:root:current train perplexity3.6287620067596436

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.59s/it]
INFO:root:final mean train loss: 1635.1161917312784
INFO:root:final train perplexity: 3.6311559677124023
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it]
INFO:root:eval mean loss: 3298.4611229882225
INFO:root:eval perplexity: 14.978679656982422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:21:58<5:45:25, 328.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1614.657749720982
INFO:root:current train perplexity3.5662944316864014
INFO:root:current mean train loss 1618.3493423461914
INFO:root:current train perplexity3.583415985107422
INFO:root:current mean train loss 1619.2895031309965
INFO:root:current train perplexity3.5810365676879883
INFO:root:current mean train loss 1611.4061290461843
INFO:root:current train perplexity3.570405960083008
INFO:root:current mean train loss 1612.5635983476016
INFO:root:current train perplexity3.5779385566711426
INFO:root:current mean train loss 1614.939620740486
INFO:root:current train perplexity3.584184169769287
INFO:root:current mean train loss 1616.3868274081285
INFO:root:current train perplexity3.586637020111084
INFO:root:current mean train loss 1615.7798441792581
INFO:root:current train perplexity3.5876452922821045
INFO:root:current mean train loss 1616.7176877818822
INFO:root:current train perplexity3.592113971710205
INFO:root:current mean train loss 1617.1738232579723
INFO:root:current train perplexity3.5937094688415527
INFO:root:current mean train loss 1619.863267475529
INFO:root:current train perplexity3.596953868865967
INFO:root:current mean train loss 1621.0166808865595
INFO:root:current train perplexity3.597081184387207
INFO:root:current mean train loss 1620.7053626243764
INFO:root:current train perplexity3.598385810852051
INFO:root:current mean train loss 1621.681286455637
INFO:root:current train perplexity3.5991628170013428
INFO:root:current mean train loss 1620.9910274046142
INFO:root:current train perplexity3.5982344150543213
INFO:root:current mean train loss 1622.9614952047457
INFO:root:current train perplexity3.6014177799224854
INFO:root:current mean train loss 1625.6611011701955
INFO:root:current train perplexity3.605553388595581
INFO:root:current mean train loss 1627.2438658961544
INFO:root:current train perplexity3.607314348220825
INFO:root:current mean train loss 1628.1315078568407
INFO:root:current train perplexity3.6094605922698975
INFO:root:current mean train loss 1627.754987471331
INFO:root:current train perplexity3.608534097671509

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it]
INFO:root:final mean train loss: 1627.3107704551185
INFO:root:final train perplexity: 3.6088716983795166
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.54s/it]
INFO:root:eval mean loss: 3306.8872950098535
INFO:root:eval perplexity: 15.082603454589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:27:27<5:39:57, 328.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1596.3007242838542
INFO:root:current train perplexity3.553980827331543
INFO:root:current mean train loss 1622.8800175107758
INFO:root:current train perplexity3.5817904472351074
INFO:root:current mean train loss 1627.128536053093
INFO:root:current train perplexity3.5924856662750244
INFO:root:current mean train loss 1620.7862279919611
INFO:root:current train perplexity3.586763620376587
INFO:root:current mean train loss 1621.8254784058988
INFO:root:current train perplexity3.587425470352173
INFO:root:current mean train loss 1620.5322509765624
INFO:root:current train perplexity3.5863444805145264
INFO:root:current mean train loss 1620.601102796451
INFO:root:current train perplexity3.5840904712677
INFO:root:current mean train loss 1618.2353856438758
INFO:root:current train perplexity3.578852415084839
INFO:root:current mean train loss 1619.0219626883784
INFO:root:current train perplexity3.5784666538238525
INFO:root:current mean train loss 1618.9966919591186
INFO:root:current train perplexity3.5783071517944336
INFO:root:current mean train loss 1619.41630322032
INFO:root:current train perplexity3.5808184146881104
INFO:root:current mean train loss 1621.3177059523402
INFO:root:current train perplexity3.585681915283203
INFO:root:current mean train loss 1621.5688224578
INFO:root:current train perplexity3.5869274139404297
INFO:root:current mean train loss 1620.0410659052625
INFO:root:current train perplexity3.5875084400177
INFO:root:current mean train loss 1621.2258576178633
INFO:root:current train perplexity3.588001251220703
INFO:root:current mean train loss 1621.2927112567
INFO:root:current train perplexity3.5880932807922363
INFO:root:current mean train loss 1621.615547899055
INFO:root:current train perplexity3.5888352394104004
INFO:root:current mean train loss 1622.2885533024041
INFO:root:current train perplexity3.590416193008423
INFO:root:current mean train loss 1622.4510914210705
INFO:root:current train perplexity3.591595411300659
INFO:root:current mean train loss 1622.2617407163802
INFO:root:current train perplexity3.592094659805298

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it]
INFO:root:final mean train loss: 1621.7983576956867
INFO:root:final train perplexity: 3.593216896057129
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.60s/it]
INFO:root:eval mean loss: 3309.298932966169
INFO:root:eval perplexity: 15.112483024597168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:32:57<5:34:34, 329.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.3013896326866
INFO:root:current train perplexity3.5366835594177246
INFO:root:current mean train loss 1601.5493872371721
INFO:root:current train perplexity3.5387203693389893
INFO:root:current mean train loss 1609.0285411572638
INFO:root:current train perplexity3.545870780944824
INFO:root:current mean train loss 1609.8392249681674
INFO:root:current train perplexity3.549755811691284
INFO:root:current mean train loss 1607.1305156228862
INFO:root:current train perplexity3.552893877029419
INFO:root:current mean train loss 1609.4790699371663
INFO:root:current train perplexity3.5620672702789307
INFO:root:current mean train loss 1609.6587166685351
INFO:root:current train perplexity3.563849687576294
INFO:root:current mean train loss 1609.84687032224
INFO:root:current train perplexity3.5640451908111572
INFO:root:current mean train loss 1611.894891654809
INFO:root:current train perplexity3.568399429321289
INFO:root:current mean train loss 1611.4963088323075
INFO:root:current train perplexity3.5688693523406982
INFO:root:current mean train loss 1612.7477553775307
INFO:root:current train perplexity3.5680289268493652
INFO:root:current mean train loss 1612.7667459038162
INFO:root:current train perplexity3.566094160079956
INFO:root:current mean train loss 1611.775854143968
INFO:root:current train perplexity3.564816951751709
INFO:root:current mean train loss 1612.9034783227503
INFO:root:current train perplexity3.567781686782837
INFO:root:current mean train loss 1612.5107434399313
INFO:root:current train perplexity3.569150686264038
INFO:root:current mean train loss 1613.3095782838009
INFO:root:current train perplexity3.569984197616577
INFO:root:current mean train loss 1614.406618340925
INFO:root:current train perplexity3.571401834487915
INFO:root:current mean train loss 1614.4366441915038
INFO:root:current train perplexity3.571749687194824
INFO:root:current mean train loss 1615.002297504888
INFO:root:current train perplexity3.572317600250244
INFO:root:current mean train loss 1615.0898487896
INFO:root:current train perplexity3.5721209049224854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.03s/it]
INFO:root:final mean train loss: 1614.5235926271748
INFO:root:final train perplexity: 3.572659969329834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it]
INFO:root:eval mean loss: 3311.6103515625
INFO:root:eval perplexity: 15.141176223754883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:38:26<5:29:08, 329.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1604.8140297418909
INFO:root:current train perplexity3.553804397583008
INFO:root:current mean train loss 1609.469777027322
INFO:root:current train perplexity3.5491509437561035
INFO:root:current mean train loss 1607.091312093974
INFO:root:current train perplexity3.549637794494629
INFO:root:current mean train loss 1606.862537555141
INFO:root:current train perplexity3.5527591705322266
INFO:root:current mean train loss 1606.0781300968815
INFO:root:current train perplexity3.553779125213623
INFO:root:current mean train loss 1609.6360915320731
INFO:root:current train perplexity3.5541574954986572
INFO:root:current mean train loss 1609.3665113491234
INFO:root:current train perplexity3.5525622367858887
INFO:root:current mean train loss 1611.4707960488709
INFO:root:current train perplexity3.557696580886841
INFO:root:current mean train loss 1610.606821938993
INFO:root:current train perplexity3.5573835372924805
INFO:root:current mean train loss 1611.2859343079674
INFO:root:current train perplexity3.5585198402404785
INFO:root:current mean train loss 1611.1205951736633
INFO:root:current train perplexity3.557088851928711
INFO:root:current mean train loss 1610.7623646148086
INFO:root:current train perplexity3.5586395263671875
INFO:root:current mean train loss 1611.1980987381805
INFO:root:current train perplexity3.556967258453369
INFO:root:current mean train loss 1612.4302688167093
INFO:root:current train perplexity3.5611729621887207
INFO:root:current mean train loss 1612.68339624205
INFO:root:current train perplexity3.5615122318267822
INFO:root:current mean train loss 1611.4353422390802
INFO:root:current train perplexity3.5606446266174316
INFO:root:current mean train loss 1610.4433892564166
INFO:root:current train perplexity3.5575456619262695
INFO:root:current mean train loss 1609.2197213475795
INFO:root:current train perplexity3.5562140941619873
INFO:root:current mean train loss 1608.6961974610415
INFO:root:current train perplexity3.5558767318725586
INFO:root:current mean train loss 1608.758459182747
INFO:root:current train perplexity3.555205821990967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.45s/it]
INFO:root:final mean train loss: 1608.299158355051
INFO:root:final train perplexity: 3.5551650524139404
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 3314.957374366554
INFO:root:eval perplexity: 15.182816505432129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:43:55<5:23:47, 329.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1586.6952438354492
INFO:root:current train perplexity3.503265380859375
INFO:root:current mean train loss 1585.609414236886
INFO:root:current train perplexity3.50028657913208
INFO:root:current mean train loss 1592.4691021893475
INFO:root:current train perplexity3.5167319774627686
INFO:root:current mean train loss 1593.8761738478536
INFO:root:current train perplexity3.5178215503692627
INFO:root:current mean train loss 1594.0571700065366
INFO:root:current train perplexity3.524061679840088
INFO:root:current mean train loss 1596.7351633366322
INFO:root:current train perplexity3.5213170051574707
INFO:root:current mean train loss 1593.2296065407238
INFO:root:current train perplexity3.5164849758148193
INFO:root:current mean train loss 1594.9036722614537
INFO:root:current train perplexity3.5208356380462646
INFO:root:current mean train loss 1596.1183199201312
INFO:root:current train perplexity3.52262020111084
INFO:root:current mean train loss 1596.1618485661395
INFO:root:current train perplexity3.524045467376709
INFO:root:current mean train loss 1596.2533550401674
INFO:root:current train perplexity3.5209274291992188
INFO:root:current mean train loss 1597.4981423062225
INFO:root:current train perplexity3.5231893062591553
INFO:root:current mean train loss 1599.1487274169922
INFO:root:current train perplexity3.525836229324341
INFO:root:current mean train loss 1598.9134208438732
INFO:root:current train perplexity3.52703857421875
INFO:root:current mean train loss 1599.902650312944
INFO:root:current train perplexity3.530073881149292
INFO:root:current mean train loss 1602.1718443294515
INFO:root:current train perplexity3.533362865447998
INFO:root:current mean train loss 1602.7855105849933
INFO:root:current train perplexity3.535762071609497
INFO:root:current mean train loss 1602.6566474081944
INFO:root:current train perplexity3.5364060401916504
INFO:root:current mean train loss 1602.839936719162
INFO:root:current train perplexity3.5370748043060303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.58s/it]
INFO:root:final mean train loss: 1602.1921412573279
INFO:root:final train perplexity: 3.5380825996398926
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.52s/it]
INFO:root:eval mean loss: 3326.0343409816064
INFO:root:eval perplexity: 15.32144546508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:49:24<5:18:08, 329.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1617.0161602313701
INFO:root:current train perplexity3.613508939743042
INFO:root:current mean train loss 1584.6010904227737
INFO:root:current train perplexity3.529994249343872
INFO:root:current mean train loss 1582.1845101369938
INFO:root:current train perplexity3.5153369903564453
INFO:root:current mean train loss 1585.4479375967203
INFO:root:current train perplexity3.5042641162872314
INFO:root:current mean train loss 1584.7319693576915
INFO:root:current train perplexity3.5036699771881104
INFO:root:current mean train loss 1587.674759476273
INFO:root:current train perplexity3.5027520656585693
INFO:root:current mean train loss 1588.7232638136597
INFO:root:current train perplexity3.507786989212036
INFO:root:current mean train loss 1592.265024578421
INFO:root:current train perplexity3.510300874710083
INFO:root:current mean train loss 1591.580194039245
INFO:root:current train perplexity3.511774778366089
INFO:root:current mean train loss 1593.3092388641926
INFO:root:current train perplexity3.51171612739563
INFO:root:current mean train loss 1594.7344342878516
INFO:root:current train perplexity3.5138638019561768
INFO:root:current mean train loss 1595.32944934773
INFO:root:current train perplexity3.5169801712036133
INFO:root:current mean train loss 1595.3427168806033
INFO:root:current train perplexity3.518235683441162
INFO:root:current mean train loss 1595.2691994381605
INFO:root:current train perplexity3.517667293548584
INFO:root:current mean train loss 1596.8424428196047
INFO:root:current train perplexity3.5202810764312744
INFO:root:current mean train loss 1596.7652469289594
INFO:root:current train perplexity3.520979642868042
INFO:root:current mean train loss 1595.3406456452456
INFO:root:current train perplexity3.517359495162964
INFO:root:current mean train loss 1595.6395882218467
INFO:root:current train perplexity3.5184855461120605
INFO:root:current mean train loss 1594.930349494105
INFO:root:current train perplexity3.5171444416046143
INFO:root:current mean train loss 1595.925925335084
INFO:root:current train perplexity3.5192863941192627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it]
INFO:root:final mean train loss: 1595.9540767544638
INFO:root:final train perplexity: 3.5207197666168213
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.76s/it]
INFO:root:eval mean loss: 3330.8574563332863
INFO:root:eval perplexity: 15.382207870483398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:54:54<5:12:46, 329.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.96728515625
INFO:root:current train perplexity3.550905466079712
INFO:root:current mean train loss 1596.5176908052886
INFO:root:current train perplexity3.5120596885681152
INFO:root:current mean train loss 1601.7834684952445
INFO:root:current train perplexity3.519131898880005
INFO:root:current mean train loss 1597.5345943566524
INFO:root:current train perplexity3.504476547241211
INFO:root:current mean train loss 1593.3836124863735
INFO:root:current train perplexity3.502511978149414
INFO:root:current mean train loss 1592.9466092091686
INFO:root:current train perplexity3.4975674152374268
INFO:root:current mean train loss 1590.595248170883
INFO:root:current train perplexity3.496501922607422
INFO:root:current mean train loss 1591.7983973672945
INFO:root:current train perplexity3.50004243850708
INFO:root:current mean train loss 1592.7063279485128
INFO:root:current train perplexity3.4989848136901855
INFO:root:current mean train loss 1592.8532794911375
INFO:root:current train perplexity3.500490188598633
INFO:root:current mean train loss 1591.6694049131522
INFO:root:current train perplexity3.5003485679626465
INFO:root:current mean train loss 1591.832517694794
INFO:root:current train perplexity3.5011603832244873
INFO:root:current mean train loss 1591.9323302726436
INFO:root:current train perplexity3.5025036334991455
INFO:root:current mean train loss 1591.3124329072193
INFO:root:current train perplexity3.5011508464813232
INFO:root:current mean train loss 1592.0270705003004
INFO:root:current train perplexity3.504345417022705
INFO:root:current mean train loss 1590.512702253753
INFO:root:current train perplexity3.5026707649230957
INFO:root:current mean train loss 1590.6038962896616
INFO:root:current train perplexity3.5050811767578125
INFO:root:current mean train loss 1591.1058467446035
INFO:root:current train perplexity3.504695177078247
INFO:root:current mean train loss 1590.9305092399889
INFO:root:current train perplexity3.505441427230835
INFO:root:current mean train loss 1590.1890790079542
INFO:root:current train perplexity3.5036377906799316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.22s/it]
INFO:root:final mean train loss: 1590.1429806553951
INFO:root:final train perplexity: 3.5046212673187256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 3342.2909459752723
INFO:root:eval perplexity: 15.527203559875488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:00:23<5:07:17, 329.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1572.2033327792553
INFO:root:current train perplexity3.4677181243896484
INFO:root:current mean train loss 1558.6936857262435
INFO:root:current train perplexity3.4438536167144775
INFO:root:current mean train loss 1570.6731520432693
INFO:root:current train perplexity3.450227975845337
INFO:root:current mean train loss 1579.3445995671605
INFO:root:current train perplexity3.4747118949890137
INFO:root:current mean train loss 1579.2057130544777
INFO:root:current train perplexity3.473323106765747
INFO:root:current mean train loss 1580.033376522866
INFO:root:current train perplexity3.4761552810668945
INFO:root:current mean train loss 1580.0983943320132
INFO:root:current train perplexity3.4777958393096924
INFO:root:current mean train loss 1580.2429207389453
INFO:root:current train perplexity3.472222089767456
INFO:root:current mean train loss 1583.3837374672557
INFO:root:current train perplexity3.4794275760650635
INFO:root:current mean train loss 1583.4930948420588
INFO:root:current train perplexity3.4779059886932373
INFO:root:current mean train loss 1583.50033531444
INFO:root:current train perplexity3.482052803039551
INFO:root:current mean train loss 1585.1762161055335
INFO:root:current train perplexity3.484663963317871
INFO:root:current mean train loss 1583.5264285652754
INFO:root:current train perplexity3.483271837234497
INFO:root:current mean train loss 1582.1427483165714
INFO:root:current train perplexity3.481517791748047
INFO:root:current mean train loss 1582.9735887760776
INFO:root:current train perplexity3.4826228618621826
INFO:root:current mean train loss 1584.1585838549663
INFO:root:current train perplexity3.4871459007263184
INFO:root:current mean train loss 1583.521220964016
INFO:root:current train perplexity3.4864752292633057
INFO:root:current mean train loss 1583.2706798429003
INFO:root:current train perplexity3.4851951599121094
INFO:root:current mean train loss 1583.9240422602531
INFO:root:current train perplexity3.4869918823242188
INFO:root:current mean train loss 1585.012834812472
INFO:root:current train perplexity3.4891045093536377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.65s/it]
INFO:root:final mean train loss: 1584.4428520722036
INFO:root:final train perplexity: 3.4889016151428223
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.93s/it]
INFO:root:eval mean loss: 3338.086360530452
INFO:root:eval perplexity: 15.473724365234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:05:52<5:01:47, 329.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1568.347915649414
INFO:root:current train perplexity3.443598747253418
INFO:root:current mean train loss 1578.5932006835938
INFO:root:current train perplexity3.4608919620513916
INFO:root:current mean train loss 1578.8587688099253
INFO:root:current train perplexity3.4681665897369385
INFO:root:current mean train loss 1581.1458914620537
INFO:root:current train perplexity3.4837613105773926
INFO:root:current mean train loss 1579.7260860574656
INFO:root:current train perplexity3.476187229156494
INFO:root:current mean train loss 1578.4828694661458
INFO:root:current train perplexity3.4733994007110596
INFO:root:current mean train loss 1575.8797932820148
INFO:root:current train perplexity3.468534231185913
INFO:root:current mean train loss 1575.1903988503661
INFO:root:current train perplexity3.4686293601989746
INFO:root:current mean train loss 1577.2858571653012
INFO:root:current train perplexity3.4714558124542236
INFO:root:current mean train loss 1578.8666640159006
INFO:root:current train perplexity3.4745452404022217
INFO:root:current mean train loss 1577.6386877074278
INFO:root:current train perplexity3.4739394187927246
INFO:root:current mean train loss 1578.8921184736428
INFO:root:current train perplexity3.4740183353424072
INFO:root:current mean train loss 1579.7340681824503
INFO:root:current train perplexity3.474330186843872
INFO:root:current mean train loss 1580.5856589040447
INFO:root:current train perplexity3.474095582962036
INFO:root:current mean train loss 1581.199575372081
INFO:root:current train perplexity3.47371244430542
INFO:root:current mean train loss 1580.558515543828
INFO:root:current train perplexity3.4724621772766113
INFO:root:current mean train loss 1579.7087529255793
INFO:root:current train perplexity3.4737067222595215
INFO:root:current mean train loss 1579.664081391834
INFO:root:current train perplexity3.4733529090881348
INFO:root:current mean train loss 1579.395777231634
INFO:root:current train perplexity3.47393798828125
INFO:root:current mean train loss 1579.160360239188
INFO:root:current train perplexity3.4728732109069824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it]
INFO:root:final mean train loss: 1578.51723783015
INFO:root:final train perplexity: 3.47263503074646
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it]
INFO:root:eval mean loss: 3335.7174515824418
INFO:root:eval perplexity: 15.44367504119873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:11:22<4:56:20, 329.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1582.9345883969906
INFO:root:current train perplexity3.470212936401367
INFO:root:current mean train loss 1580.338181975138
INFO:root:current train perplexity3.456364154815674
INFO:root:current mean train loss 1581.1509010613602
INFO:root:current train perplexity3.4591002464294434
INFO:root:current mean train loss 1578.9284972343544
INFO:root:current train perplexity3.452741861343384
INFO:root:current mean train loss 1573.8846899972389
INFO:root:current train perplexity3.4487664699554443
INFO:root:current mean train loss 1574.695653918688
INFO:root:current train perplexity3.45147967338562
INFO:root:current mean train loss 1575.974189209343
INFO:root:current train perplexity3.458472728729248
INFO:root:current mean train loss 1577.3974932916033
INFO:root:current train perplexity3.4597601890563965
INFO:root:current mean train loss 1579.7808397273607
INFO:root:current train perplexity3.461726665496826
INFO:root:current mean train loss 1577.0313286426478
INFO:root:current train perplexity3.459439277648926
INFO:root:current mean train loss 1576.7846567893228
INFO:root:current train perplexity3.4592788219451904
INFO:root:current mean train loss 1577.0527556675354
INFO:root:current train perplexity3.4600417613983154
INFO:root:current mean train loss 1577.6196319556254
INFO:root:current train perplexity3.463291645050049
INFO:root:current mean train loss 1576.7975261005952
INFO:root:current train perplexity3.4622859954833984
INFO:root:current mean train loss 1575.828733208532
INFO:root:current train perplexity3.4614040851593018
INFO:root:current mean train loss 1574.2973513907832
INFO:root:current train perplexity3.45862078666687
INFO:root:current mean train loss 1574.55742787322
INFO:root:current train perplexity3.4579665660858154
INFO:root:current mean train loss 1574.5703826852891
INFO:root:current train perplexity3.458916425704956
INFO:root:current mean train loss 1573.613176831535
INFO:root:current train perplexity3.4583301544189453
INFO:root:current mean train loss 1574.0581828025422
INFO:root:current train perplexity3.459127902984619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.38s/it]
INFO:root:final mean train loss: 1573.5274134341118
INFO:root:final train perplexity: 3.458996057510376
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 3347.4235458603134
INFO:root:eval perplexity: 15.59273624420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:16:51<4:50:53, 329.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1564.5907642598054
INFO:root:current train perplexity3.410520076751709
INFO:root:current mean train loss 1563.4508944424715
INFO:root:current train perplexity3.414449453353882
INFO:root:current mean train loss 1563.3165385611105
INFO:root:current train perplexity3.4299330711364746
INFO:root:current mean train loss 1560.453674929825
INFO:root:current train perplexity3.426819086074829
INFO:root:current mean train loss 1562.3514769527328
INFO:root:current train perplexity3.428372621536255
INFO:root:current mean train loss 1562.3905219138665
INFO:root:current train perplexity3.4284136295318604
INFO:root:current mean train loss 1566.0343215199118
INFO:root:current train perplexity3.436148166656494
INFO:root:current mean train loss 1566.0922537973352
INFO:root:current train perplexity3.4381871223449707
INFO:root:current mean train loss 1567.3324133654214
INFO:root:current train perplexity3.441648483276367
INFO:root:current mean train loss 1566.0934258654027
INFO:root:current train perplexity3.4397270679473877
INFO:root:current mean train loss 1568.2536818985513
INFO:root:current train perplexity3.440861225128174
INFO:root:current mean train loss 1568.7568270726276
INFO:root:current train perplexity3.442631721496582
INFO:root:current mean train loss 1566.968281656274
INFO:root:current train perplexity3.4403305053710938
INFO:root:current mean train loss 1567.5332835447123
INFO:root:current train perplexity3.4424057006835938
INFO:root:current mean train loss 1567.774510708288
INFO:root:current train perplexity3.444129228591919
INFO:root:current mean train loss 1568.3061431770182
INFO:root:current train perplexity3.4462759494781494
INFO:root:current mean train loss 1568.7302315827674
INFO:root:current train perplexity3.4470367431640625
INFO:root:current mean train loss 1568.7122082397325
INFO:root:current train perplexity3.446343183517456
INFO:root:current mean train loss 1568.8062463083056
INFO:root:current train perplexity3.445957899093628

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.14s/it]
INFO:root:final mean train loss: 1568.873259066814
INFO:root:final train perplexity: 3.446322202682495
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 3355.8108826600037
INFO:root:eval perplexity: 15.70042610168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:22:19<4:45:06, 328.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1509.6728434244792
INFO:root:current train perplexity3.2753164768218994
INFO:root:current mean train loss 1558.9376581606657
INFO:root:current train perplexity3.415879964828491
INFO:root:current mean train loss 1563.915608534702
INFO:root:current train perplexity3.4138364791870117
INFO:root:current mean train loss 1561.7244419642857
INFO:root:current train perplexity3.4095489978790283
INFO:root:current mean train loss 1566.4070959619728
INFO:root:current train perplexity3.421494245529175
INFO:root:current mean train loss 1561.9393497800363
INFO:root:current train perplexity3.4132156372070312
INFO:root:current mean train loss 1558.53283016546
INFO:root:current train perplexity3.4110870361328125
INFO:root:current mean train loss 1560.2154150049168
INFO:root:current train perplexity3.417367935180664
INFO:root:current mean train loss 1559.4173282927532
INFO:root:current train perplexity3.418883800506592
INFO:root:current mean train loss 1558.6476152930754
INFO:root:current train perplexity3.4200098514556885
INFO:root:current mean train loss 1560.5871628935115
INFO:root:current train perplexity3.4232685565948486
INFO:root:current mean train loss 1562.1819146536925
INFO:root:current train perplexity3.4235081672668457
INFO:root:current mean train loss 1563.2391566398212
INFO:root:current train perplexity3.4240596294403076
INFO:root:current mean train loss 1563.3027923932093
INFO:root:current train perplexity3.4248552322387695
INFO:root:current mean train loss 1562.578774086241
INFO:root:current train perplexity3.425595998764038
INFO:root:current mean train loss 1562.0170777575804
INFO:root:current train perplexity3.4268453121185303
INFO:root:current mean train loss 1562.6513578149188
INFO:root:current train perplexity3.4274630546569824
INFO:root:current mean train loss 1562.432582310268
INFO:root:current train perplexity3.428269624710083
INFO:root:current mean train loss 1563.2710019450542
INFO:root:current train perplexity3.429471731185913
INFO:root:current mean train loss 1563.279479566131
INFO:root:current train perplexity3.4309873580932617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.99s/it]
INFO:root:final mean train loss: 1563.7487499335168
INFO:root:final train perplexity: 3.4324231147766113
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 3357.0412685634856
INFO:root:eval perplexity: 15.716282844543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:27:48<4:39:39, 329.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1574.637538909912
INFO:root:current train perplexity3.441433906555176
INFO:root:current mean train loss 1556.7953093557646
INFO:root:current train perplexity3.386749744415283
INFO:root:current mean train loss 1551.7224994527883
INFO:root:current train perplexity3.3810360431671143
INFO:root:current mean train loss 1554.2992296333773
INFO:root:current train perplexity3.3922603130340576
INFO:root:current mean train loss 1556.9692532574688
INFO:root:current train perplexity3.4012680053710938
INFO:root:current mean train loss 1553.921557892534
INFO:root:current train perplexity3.4022269248962402
INFO:root:current mean train loss 1554.643184613578
INFO:root:current train perplexity3.406226634979248
INFO:root:current mean train loss 1555.5963910212283
INFO:root:current train perplexity3.4083456993103027
INFO:root:current mean train loss 1555.473088484544
INFO:root:current train perplexity3.4092400074005127
INFO:root:current mean train loss 1556.0003439448933
INFO:root:current train perplexity3.411264181137085
INFO:root:current mean train loss 1555.4237769075141
INFO:root:current train perplexity3.41055965423584
INFO:root:current mean train loss 1557.216027034045
INFO:root:current train perplexity3.412710189819336
INFO:root:current mean train loss 1558.062370399376
INFO:root:current train perplexity3.414250373840332
INFO:root:current mean train loss 1556.7521132277298
INFO:root:current train perplexity3.4118990898132324
INFO:root:current mean train loss 1556.2420979078922
INFO:root:current train perplexity3.4116358757019043
INFO:root:current mean train loss 1556.1384584113139
INFO:root:current train perplexity3.410954475402832
INFO:root:current mean train loss 1557.3558568019494
INFO:root:current train perplexity3.4131362438201904
INFO:root:current mean train loss 1556.977145294119
INFO:root:current train perplexity3.4138519763946533
INFO:root:current mean train loss 1558.1987646511027
INFO:root:current train perplexity3.4158308506011963
INFO:root:current mean train loss 1558.2731598721775
INFO:root:current train perplexity3.417344331741333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it]
INFO:root:final mean train loss: 1558.775009824721
INFO:root:final train perplexity: 3.4189846515655518
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it]
INFO:root:eval mean loss: 3364.1767856723914
INFO:root:eval perplexity: 15.80858039855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:33:17<4:34:11, 329.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1530.841475506218
INFO:root:current train perplexity3.3643808364868164
INFO:root:current mean train loss 1542.1452522021812
INFO:root:current train perplexity3.356790542602539
INFO:root:current mean train loss 1542.774933719252
INFO:root:current train perplexity3.3706908226013184
INFO:root:current mean train loss 1545.375299054777
INFO:root:current train perplexity3.3802490234375
INFO:root:current mean train loss 1548.8084298114734
INFO:root:current train perplexity3.380133867263794
INFO:root:current mean train loss 1549.4941281733834
INFO:root:current train perplexity3.38326096534729
INFO:root:current mean train loss 1547.0559849437836
INFO:root:current train perplexity3.3822667598724365
INFO:root:current mean train loss 1549.7514795117447
INFO:root:current train perplexity3.388242721557617
INFO:root:current mean train loss 1549.5829615149257
INFO:root:current train perplexity3.3882007598876953
INFO:root:current mean train loss 1552.0869516225962
INFO:root:current train perplexity3.394472360610962
INFO:root:current mean train loss 1552.8701304534825
INFO:root:current train perplexity3.398489475250244
INFO:root:current mean train loss 1552.6543003809359
INFO:root:current train perplexity3.400607109069824
INFO:root:current mean train loss 1552.8134747055458
INFO:root:current train perplexity3.4027655124664307
INFO:root:current mean train loss 1551.5419981598059
INFO:root:current train perplexity3.401277542114258
INFO:root:current mean train loss 1551.2238502476116
INFO:root:current train perplexity3.4010186195373535
INFO:root:current mean train loss 1551.2265317657057
INFO:root:current train perplexity3.4012248516082764
INFO:root:current mean train loss 1551.6494711372186
INFO:root:current train perplexity3.4021382331848145
INFO:root:current mean train loss 1551.7717916795089
INFO:root:current train perplexity3.4024622440338135
INFO:root:current mean train loss 1552.5508604075471
INFO:root:current train perplexity3.4032325744628906
INFO:root:current mean train loss 1554.1792982403838
INFO:root:current train perplexity3.4055445194244385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it]
INFO:root:final mean train loss: 1553.5244856549223
INFO:root:final train perplexity: 3.4048564434051514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it]
INFO:root:eval mean loss: 3357.2735284112237
INFO:root:eval perplexity: 15.719277381896973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:38:46<4:28:31, 328.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1549.0181181936553
INFO:root:current train perplexity3.3705952167510986
INFO:root:current mean train loss 1539.9612441465079
INFO:root:current train perplexity3.370800495147705
INFO:root:current mean train loss 1543.4441698117364
INFO:root:current train perplexity3.365194320678711
INFO:root:current mean train loss 1543.2568309346184
INFO:root:current train perplexity3.375769853591919
INFO:root:current mean train loss 1543.779362887272
INFO:root:current train perplexity3.375566244125366
INFO:root:current mean train loss 1549.7840222469908
INFO:root:current train perplexity3.380910873413086
INFO:root:current mean train loss 1550.4592745211032
INFO:root:current train perplexity3.382204055786133
INFO:root:current mean train loss 1548.185798505579
INFO:root:current train perplexity3.381282329559326
INFO:root:current mean train loss 1550.4044296581806
INFO:root:current train perplexity3.3863658905029297
INFO:root:current mean train loss 1548.7655112698951
INFO:root:current train perplexity3.3839690685272217
INFO:root:current mean train loss 1549.068993774185
INFO:root:current train perplexity3.3889379501342773
INFO:root:current mean train loss 1547.9986965905741
INFO:root:current train perplexity3.3870890140533447
INFO:root:current mean train loss 1548.7772757724563
INFO:root:current train perplexity3.388347625732422
INFO:root:current mean train loss 1548.0429306812202
INFO:root:current train perplexity3.389430046081543
INFO:root:current mean train loss 1547.2792372553931
INFO:root:current train perplexity3.3888351917266846
INFO:root:current mean train loss 1548.5243584059208
INFO:root:current train perplexity3.3911540508270264
INFO:root:current mean train loss 1548.3301560126004
INFO:root:current train perplexity3.3908302783966064
INFO:root:current mean train loss 1549.1562930633095
INFO:root:current train perplexity3.3915021419525146
INFO:root:current mean train loss 1548.8899857336046
INFO:root:current train perplexity3.3915045261383057
INFO:root:current mean train loss 1548.8149420892478
INFO:root:current train perplexity3.391134738922119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.49s/it]
INFO:root:final mean train loss: 1548.7836122421443
INFO:root:final train perplexity: 3.392150402069092
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.57s/it]
INFO:root:eval mean loss: 3370.984567086618
INFO:root:eval perplexity: 15.897132873535156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:44:15<4:23:14, 329.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1538.270306322948
INFO:root:current train perplexity3.3712096214294434
INFO:root:current mean train loss 1538.6149562147798
INFO:root:current train perplexity3.3720624446868896
INFO:root:current mean train loss 1532.9268117304825
INFO:root:current train perplexity3.3569133281707764
INFO:root:current mean train loss 1534.767944017216
INFO:root:current train perplexity3.362987518310547
INFO:root:current mean train loss 1533.9903804550013
INFO:root:current train perplexity3.35981822013855
INFO:root:current mean train loss 1534.7145215095009
INFO:root:current train perplexity3.3654563426971436
INFO:root:current mean train loss 1537.594533716428
INFO:root:current train perplexity3.36856746673584
INFO:root:current mean train loss 1537.4387743329942
INFO:root:current train perplexity3.3655452728271484
INFO:root:current mean train loss 1538.8210641379264
INFO:root:current train perplexity3.366121530532837
INFO:root:current mean train loss 1539.098945252893
INFO:root:current train perplexity3.3676412105560303
INFO:root:current mean train loss 1538.9017596610256
INFO:root:current train perplexity3.3671321868896484
INFO:root:current mean train loss 1539.6156835483478
INFO:root:current train perplexity3.3707916736602783
INFO:root:current mean train loss 1538.4927824381637
INFO:root:current train perplexity3.3708152770996094
INFO:root:current mean train loss 1539.9986091222095
INFO:root:current train perplexity3.373659133911133
INFO:root:current mean train loss 1541.4978705603612
INFO:root:current train perplexity3.3748369216918945
INFO:root:current mean train loss 1542.5709829999162
INFO:root:current train perplexity3.3755674362182617
INFO:root:current mean train loss 1542.680531039949
INFO:root:current train perplexity3.374891996383667
INFO:root:current mean train loss 1543.7573090198664
INFO:root:current train perplexity3.377183198928833
INFO:root:current mean train loss 1544.024260032196
INFO:root:current train perplexity3.3782505989074707
INFO:root:current mean train loss 1543.9025706542723
INFO:root:current train perplexity3.379117250442505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.46s/it]
INFO:root:final mean train loss: 1543.9025706542723
INFO:root:final train perplexity: 3.379117250442505
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.91s/it]
INFO:root:eval mean loss: 3380.417121222785
INFO:root:eval perplexity: 16.020658493041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:49:44<4:17:44, 329.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1532.393377685547
INFO:root:current train perplexity3.3978919982910156
INFO:root:current mean train loss 1546.3225079345702
INFO:root:current train perplexity3.386397361755371
INFO:root:current mean train loss 1535.1120345052084
INFO:root:current train perplexity3.3686530590057373
INFO:root:current mean train loss 1535.0945028686524
INFO:root:current train perplexity3.364569902420044
INFO:root:current mean train loss 1534.6460061035157
INFO:root:current train perplexity3.362431049346924
INFO:root:current mean train loss 1540.2395739746094
INFO:root:current train perplexity3.3708927631378174
INFO:root:current mean train loss 1537.922190638951
INFO:root:current train perplexity3.364105463027954
INFO:root:current mean train loss 1537.8720669555664
INFO:root:current train perplexity3.3660778999328613
INFO:root:current mean train loss 1539.2970430501302
INFO:root:current train perplexity3.368410348892212
INFO:root:current mean train loss 1539.0270161132812
INFO:root:current train perplexity3.368565320968628
INFO:root:current mean train loss 1542.073105135831
INFO:root:current train perplexity3.373220443725586
INFO:root:current mean train loss 1542.5019318644206
INFO:root:current train perplexity3.373749256134033
INFO:root:current mean train loss 1543.049152738131
INFO:root:current train perplexity3.3734729290008545
INFO:root:current mean train loss 1540.582289603097
INFO:root:current train perplexity3.370143175125122
INFO:root:current mean train loss 1540.4729692382812
INFO:root:current train perplexity3.3699896335601807
INFO:root:current mean train loss 1540.575949935913
INFO:root:current train perplexity3.3698036670684814
INFO:root:current mean train loss 1541.1899812586166
INFO:root:current train perplexity3.3698012828826904
INFO:root:current mean train loss 1542.6765715874567
INFO:root:current train perplexity3.372352361679077
INFO:root:current mean train loss 1541.1375183747944
INFO:root:current train perplexity3.3703114986419678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it]
INFO:root:final mean train loss: 1540.5656118695927
INFO:root:final train perplexity: 3.3702354431152344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.71s/it]
INFO:root:eval mean loss: 3373.8158475858672
INFO:root:eval perplexity: 15.934111595153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:55:14<4:12:20, 329.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1539.4378518497242
INFO:root:current train perplexity3.4062421321868896
INFO:root:current mean train loss 1522.1247944628071
INFO:root:current train perplexity3.336334466934204
INFO:root:current mean train loss 1528.6744328512025
INFO:root:current train perplexity3.337566375732422
INFO:root:current mean train loss 1527.2291460007148
INFO:root:current train perplexity3.3399553298950195
INFO:root:current mean train loss 1533.729318888639
INFO:root:current train perplexity3.35284161567688
INFO:root:current mean train loss 1532.2517210261274
INFO:root:current train perplexity3.348050832748413
INFO:root:current mean train loss 1531.799435113199
INFO:root:current train perplexity3.3480682373046875
INFO:root:current mean train loss 1531.6077971092661
INFO:root:current train perplexity3.351182222366333
INFO:root:current mean train loss 1532.2162507709704
INFO:root:current train perplexity3.3525619506835938
INFO:root:current mean train loss 1532.9131158893215
INFO:root:current train perplexity3.353994846343994
INFO:root:current mean train loss 1533.1037003508711
INFO:root:current train perplexity3.354626417160034
INFO:root:current mean train loss 1533.6917722423693
INFO:root:current train perplexity3.3569512367248535
INFO:root:current mean train loss 1534.1144690533201
INFO:root:current train perplexity3.3585405349731445
INFO:root:current mean train loss 1533.016236741885
INFO:root:current train perplexity3.3574531078338623
INFO:root:current mean train loss 1534.0521968176606
INFO:root:current train perplexity3.3583621978759766
INFO:root:current mean train loss 1533.9299763004954
INFO:root:current train perplexity3.356478452682495
INFO:root:current mean train loss 1534.6077587951017
INFO:root:current train perplexity3.358041524887085
INFO:root:current mean train loss 1534.612027203266
INFO:root:current train perplexity3.357630491256714
INFO:root:current mean train loss 1534.921332032325
INFO:root:current train perplexity3.3570494651794434
INFO:root:current mean train loss 1535.3275210798938
INFO:root:current train perplexity3.3561642169952393

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it]
INFO:root:final mean train loss: 1535.6118415836368
INFO:root:final train perplexity: 3.3570945262908936
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]
INFO:root:eval mean loss: 3382.6498341603324
INFO:root:eval perplexity: 16.05003547668457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:00:51<4:08:44, 331.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1513.8583912568934
INFO:root:current train perplexity3.322688341140747
INFO:root:current mean train loss 1527.0479472146105
INFO:root:current train perplexity3.3347673416137695
INFO:root:current mean train loss 1534.2156919821714
INFO:root:current train perplexity3.3396599292755127
INFO:root:current mean train loss 1534.6515758765672
INFO:root:current train perplexity3.3407764434814453
INFO:root:current mean train loss 1534.2528129612795
INFO:root:current train perplexity3.3425402641296387
INFO:root:current mean train loss 1533.322079547782
INFO:root:current train perplexity3.340588092803955
INFO:root:current mean train loss 1530.92190099289
INFO:root:current train perplexity3.335845708847046
INFO:root:current mean train loss 1530.943787785252
INFO:root:current train perplexity3.336709976196289
INFO:root:current mean train loss 1530.1765057680418
INFO:root:current train perplexity3.3369369506835938
INFO:root:current mean train loss 1527.603930716341
INFO:root:current train perplexity3.334965467453003
INFO:root:current mean train loss 1526.55519313554
INFO:root:current train perplexity3.335973024368286
INFO:root:current mean train loss 1526.419936945409
INFO:root:current train perplexity3.3348388671875
INFO:root:current mean train loss 1527.4996302278541
INFO:root:current train perplexity3.338132619857788
INFO:root:current mean train loss 1527.670539730135
INFO:root:current train perplexity3.339059591293335
INFO:root:current mean train loss 1527.8118741555527
INFO:root:current train perplexity3.3404717445373535
INFO:root:current mean train loss 1528.8761233810962
INFO:root:current train perplexity3.341313600540161
INFO:root:current mean train loss 1529.6813762389315
INFO:root:current train perplexity3.342944860458374
INFO:root:current mean train loss 1530.7254321880407
INFO:root:current train perplexity3.345313549041748
INFO:root:current mean train loss 1530.8074452640446
INFO:root:current train perplexity3.345085859298706
INFO:root:current mean train loss 1531.698101181772
INFO:root:current train perplexity3.34566330909729

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.91s/it]
INFO:root:final mean train loss: 1531.3066288673451
INFO:root:final train perplexity: 3.345715045928955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 3391.238334037162
INFO:root:eval perplexity: 16.163545608520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:06:44<4:07:54, 338.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1535.1372668696386
INFO:root:current train perplexity3.3518009185791016
INFO:root:current mean train loss 1528.6066417567777
INFO:root:current train perplexity3.3325371742248535
INFO:root:current mean train loss 1526.7206292019423
INFO:root:current train perplexity3.335963010787964
INFO:root:current mean train loss 1525.0562973674546
INFO:root:current train perplexity3.327552080154419
INFO:root:current mean train loss 1524.338205950752
INFO:root:current train perplexity3.325826406478882
INFO:root:current mean train loss 1525.3155597333682
INFO:root:current train perplexity3.3256876468658447
INFO:root:current mean train loss 1526.6792847242223
INFO:root:current train perplexity3.329094171524048
INFO:root:current mean train loss 1524.520858906874
INFO:root:current train perplexity3.3276641368865967
INFO:root:current mean train loss 1523.762352195946
INFO:root:current train perplexity3.3270323276519775
INFO:root:current mean train loss 1523.771325208662
INFO:root:current train perplexity3.3284873962402344
INFO:root:current mean train loss 1524.8465785236158
INFO:root:current train perplexity3.3308980464935303
INFO:root:current mean train loss 1525.5046898968628
INFO:root:current train perplexity3.3300435543060303
INFO:root:current mean train loss 1527.1078840052958
INFO:root:current train perplexity3.331676721572876
INFO:root:current mean train loss 1528.1152321161119
INFO:root:current train perplexity3.3336803913116455
INFO:root:current mean train loss 1527.8911646837041
INFO:root:current train perplexity3.3337950706481934
INFO:root:current mean train loss 1527.9073919988616
INFO:root:current train perplexity3.334541082382202
INFO:root:current mean train loss 1527.5521146334136
INFO:root:current train perplexity3.3339874744415283
INFO:root:current mean train loss 1527.4546289536559
INFO:root:current train perplexity3.334116220474243
INFO:root:current mean train loss 1528.1840043441468
INFO:root:current train perplexity3.335176944732666
INFO:root:current mean train loss 1527.5505275364596
INFO:root:current train perplexity3.3346481323242188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.69s/it]
INFO:root:final mean train loss: 1526.9698885842158
INFO:root:final train perplexity: 3.334291934967041
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it]
INFO:root:eval mean loss: 3392.6005742070197
INFO:root:eval perplexity: 16.181617736816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:12:31<4:04:07, 340.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1504.9729147518383
INFO:root:current train perplexity3.268145799636841
INFO:root:current mean train loss 1505.718718755813
INFO:root:current train perplexity3.2905468940734863
INFO:root:current mean train loss 1515.701631916103
INFO:root:current train perplexity3.301133394241333
INFO:root:current mean train loss 1513.8459542315939
INFO:root:current train perplexity3.302072763442993
INFO:root:current mean train loss 1515.6658100878071
INFO:root:current train perplexity3.303304672241211
INFO:root:current mean train loss 1517.0847230293382
INFO:root:current train perplexity3.307161808013916
INFO:root:current mean train loss 1516.0933295152859
INFO:root:current train perplexity3.3050997257232666
INFO:root:current mean train loss 1516.4195594787598
INFO:root:current train perplexity3.305910587310791
INFO:root:current mean train loss 1517.9125601069718
INFO:root:current train perplexity3.3074159622192383
INFO:root:current mean train loss 1520.8348823736521
INFO:root:current train perplexity3.3135478496551514
INFO:root:current mean train loss 1519.388475739554
INFO:root:current train perplexity3.312912940979004
INFO:root:current mean train loss 1519.5354183667328
INFO:root:current train perplexity3.3149406909942627
INFO:root:current mean train loss 1521.2392599304392
INFO:root:current train perplexity3.317380428314209
INFO:root:current mean train loss 1520.0654346845304
INFO:root:current train perplexity3.317922353744507
INFO:root:current mean train loss 1520.6562801849614
INFO:root:current train perplexity3.320495128631592
INFO:root:current mean train loss 1521.2521229958047
INFO:root:current train perplexity3.320899724960327
INFO:root:current mean train loss 1521.5737784772182
INFO:root:current train perplexity3.3209476470947266
INFO:root:current mean train loss 1522.1976834120255
INFO:root:current train perplexity3.3216159343719482
INFO:root:current mean train loss 1522.707779355427
INFO:root:current train perplexity3.32262921333313
INFO:root:current mean train loss 1523.6763912293968
INFO:root:current train perplexity3.325043201446533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it]
INFO:root:final mean train loss: 1523.428077439978
INFO:root:final train perplexity: 3.324991226196289
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.50s/it]
INFO:root:eval mean loss: 3391.868385475319
INFO:root:eval perplexity: 16.171903610229492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:18:16<3:59:28, 342.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1513.907994887408
INFO:root:current train perplexity3.3059000968933105
INFO:root:current mean train loss 1514.5660459776182
INFO:root:current train perplexity3.300539970397949
INFO:root:current mean train loss 1508.6935379831414
INFO:root:current train perplexity3.2852509021759033
INFO:root:current mean train loss 1508.3424519328328
INFO:root:current train perplexity3.2847518920898438
INFO:root:current mean train loss 1510.5668444446683
INFO:root:current train perplexity3.288709878921509
INFO:root:current mean train loss 1510.9047117053954
INFO:root:current train perplexity3.2906339168548584
INFO:root:current mean train loss 1507.9459985886176
INFO:root:current train perplexity3.2890262603759766
INFO:root:current mean train loss 1509.69191319168
INFO:root:current train perplexity3.289921283721924
INFO:root:current mean train loss 1511.4335407838983
INFO:root:current train perplexity3.294790267944336
INFO:root:current mean train loss 1511.7291703432345
INFO:root:current train perplexity3.29709792137146
INFO:root:current mean train loss 1512.570966279342
INFO:root:current train perplexity3.2971854209899902
INFO:root:current mean train loss 1513.75008179226
INFO:root:current train perplexity3.299529790878296
INFO:root:current mean train loss 1513.0081957152845
INFO:root:current train perplexity3.3000292778015137
INFO:root:current mean train loss 1514.2440099172213
INFO:root:current train perplexity3.3009724617004395
INFO:root:current mean train loss 1514.6518341783722
INFO:root:current train perplexity3.3030593395233154
INFO:root:current mean train loss 1515.5417442730925
INFO:root:current train perplexity3.307239294052124
INFO:root:current mean train loss 1515.7393601776937
INFO:root:current train perplexity3.3083715438842773
INFO:root:current mean train loss 1517.5330967152486
INFO:root:current train perplexity3.3107967376708984
INFO:root:current mean train loss 1518.15806331078
INFO:root:current train perplexity3.3118197917938232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.52s/it]
INFO:root:final mean train loss: 1519.2768755983477
INFO:root:final train perplexity: 3.3141236305236816
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it]
INFO:root:eval mean loss: 3402.244502803585
INFO:root:eval perplexity: 16.31018829345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:24:13<3:56:42, 346.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1589.6529541015625
INFO:root:current train perplexity3.477445125579834
INFO:root:current mean train loss 1515.6275945925245
INFO:root:current train perplexity3.284282922744751
INFO:root:current mean train loss 1508.3837546169168
INFO:root:current train perplexity3.282064914703369
INFO:root:current mean train loss 1505.6964838899523
INFO:root:current train perplexity3.275212526321411
INFO:root:current mean train loss 1508.943693398243
INFO:root:current train perplexity3.2826764583587646
INFO:root:current mean train loss 1512.7429379163036
INFO:root:current train perplexity3.2889628410339355
INFO:root:current mean train loss 1511.3614639839857
INFO:root:current train perplexity3.288750410079956
INFO:root:current mean train loss 1515.4066657693977
INFO:root:current train perplexity3.296139717102051
INFO:root:current mean train loss 1515.2471287601309
INFO:root:current train perplexity3.3015077114105225
INFO:root:current mean train loss 1514.1486942265885
INFO:root:current train perplexity3.301584243774414
INFO:root:current mean train loss 1513.223313626653
INFO:root:current train perplexity3.3007028102874756
INFO:root:current mean train loss 1514.1306660785433
INFO:root:current train perplexity3.301262855529785
INFO:root:current mean train loss 1513.4260775904092
INFO:root:current train perplexity3.3006911277770996
INFO:root:current mean train loss 1513.602755826373
INFO:root:current train perplexity3.301380157470703
INFO:root:current mean train loss 1513.944486566345
INFO:root:current train perplexity3.302459716796875
INFO:root:current mean train loss 1515.4350468093323
INFO:root:current train perplexity3.3026235103607178
INFO:root:current mean train loss 1516.1947198265352
INFO:root:current train perplexity3.303462266921997
INFO:root:current mean train loss 1515.7937700246953
INFO:root:current train perplexity3.303433895111084
INFO:root:current mean train loss 1515.8193620180052
INFO:root:current train perplexity3.3034918308258057
INFO:root:current mean train loss 1515.5545300023414
INFO:root:current train perplexity3.303858518600464

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.92s/it]
INFO:root:final mean train loss: 1515.6340404670166
INFO:root:final train perplexity: 3.3046154975891113
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 3403.838425095017
INFO:root:eval perplexity: 16.33153533935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:30:02<3:51:32, 347.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1479.5745464124177
INFO:root:current train perplexity3.275784492492676
INFO:root:current mean train loss 1499.9108055819984
INFO:root:current train perplexity3.2836196422576904
INFO:root:current mean train loss 1512.7803971800085
INFO:root:current train perplexity3.2938358783721924
INFO:root:current mean train loss 1513.1897604054418
INFO:root:current train perplexity3.2968454360961914
INFO:root:current mean train loss 1513.5023158398903
INFO:root:current train perplexity3.2977070808410645
INFO:root:current mean train loss 1510.415253097152
INFO:root:current train perplexity3.2953994274139404
INFO:root:current mean train loss 1509.3607221119623
INFO:root:current train perplexity3.292375326156616
INFO:root:current mean train loss 1505.9013714319476
INFO:root:current train perplexity3.2873268127441406
INFO:root:current mean train loss 1505.5818850339115
INFO:root:current train perplexity3.2866077423095703
INFO:root:current mean train loss 1505.2739940556141
INFO:root:current train perplexity3.284165382385254
INFO:root:current mean train loss 1507.9640880880459
INFO:root:current train perplexity3.2870068550109863
INFO:root:current mean train loss 1507.7726840239961
INFO:root:current train perplexity3.28786563873291
INFO:root:current mean train loss 1508.0621068514793
INFO:root:current train perplexity3.2873756885528564
INFO:root:current mean train loss 1507.1522645292362
INFO:root:current train perplexity3.285905361175537
INFO:root:current mean train loss 1508.582728401383
INFO:root:current train perplexity3.2890985012054443
INFO:root:current mean train loss 1508.8916865857987
INFO:root:current train perplexity3.2898361682891846
INFO:root:current mean train loss 1509.086035744359
INFO:root:current train perplexity3.2894861698150635
INFO:root:current mean train loss 1510.309428713778
INFO:root:current train perplexity3.2906601428985596
INFO:root:current mean train loss 1510.9729560906576
INFO:root:current train perplexity3.2921981811523438
INFO:root:current mean train loss 1512.213475659218
INFO:root:current train perplexity3.2942562103271484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.25s/it]
INFO:root:final mean train loss: 1511.995640772494
INFO:root:final train perplexity: 3.295146942138672
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 3399.9460595849755
INFO:root:eval perplexity: 16.279451370239258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:35:37<3:43:15, 343.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1516.5051642523872
INFO:root:current train perplexity3.2672457695007324
INFO:root:current mean train loss 1497.329548555262
INFO:root:current train perplexity3.247220277786255
INFO:root:current mean train loss 1503.0424121921346
INFO:root:current train perplexity3.264463186264038
INFO:root:current mean train loss 1506.3207637241908
INFO:root:current train perplexity3.281320095062256
INFO:root:current mean train loss 1506.7838593929187
INFO:root:current train perplexity3.2804768085479736
INFO:root:current mean train loss 1508.0984859181874
INFO:root:current train perplexity3.2818288803100586
INFO:root:current mean train loss 1506.9417089306332
INFO:root:current train perplexity3.2807769775390625
INFO:root:current mean train loss 1507.9657302524733
INFO:root:current train perplexity3.282325029373169
INFO:root:current mean train loss 1510.1034576562033
INFO:root:current train perplexity3.2879977226257324
INFO:root:current mean train loss 1510.6272906441973
INFO:root:current train perplexity3.288839817047119
INFO:root:current mean train loss 1509.4907700233018
INFO:root:current train perplexity3.2861735820770264
INFO:root:current mean train loss 1509.4963325178119
INFO:root:current train perplexity3.285156011581421
INFO:root:current mean train loss 1509.1577301519203
INFO:root:current train perplexity3.284212350845337
INFO:root:current mean train loss 1509.62092974086
INFO:root:current train perplexity3.2850217819213867
INFO:root:current mean train loss 1509.2371549048464
INFO:root:current train perplexity3.2860755920410156
INFO:root:current mean train loss 1509.0512092113495
INFO:root:current train perplexity3.286653995513916
INFO:root:current mean train loss 1508.4566917512702
INFO:root:current train perplexity3.2859573364257812
INFO:root:current mean train loss 1508.7763336462908
INFO:root:current train perplexity3.2863762378692627
INFO:root:current mean train loss 1508.8635668120874
INFO:root:current train perplexity3.286194324493408
INFO:root:current mean train loss 1508.9954281010903
INFO:root:current train perplexity3.2862861156463623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.28s/it]
INFO:root:final mean train loss: 1508.6215814772245
INFO:root:final train perplexity: 3.2863898277282715
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 3399.861614055462
INFO:root:eval perplexity: 16.2783260345459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:41:20<3:37:31, 343.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.0306626805718
INFO:root:current train perplexity3.2341935634613037
INFO:root:current mean train loss 1493.1739621629902
INFO:root:current train perplexity3.2550976276397705
INFO:root:current mean train loss 1494.553168134727
INFO:root:current train perplexity3.2538628578186035
INFO:root:current mean train loss 1498.011616736566
INFO:root:current train perplexity3.2612924575805664
INFO:root:current mean train loss 1498.324160813759
INFO:root:current train perplexity3.2627625465393066
INFO:root:current mean train loss 1500.7167706067048
INFO:root:current train perplexity3.2672903537750244
INFO:root:current mean train loss 1501.0739555417306
INFO:root:current train perplexity3.266566038131714
INFO:root:current mean train loss 1502.5322753582027
INFO:root:current train perplexity3.2698047161102295
INFO:root:current mean train loss 1504.3540089149967
INFO:root:current train perplexity3.2714455127716064
INFO:root:current mean train loss 1503.9975401487081
INFO:root:current train perplexity3.2696266174316406
INFO:root:current mean train loss 1504.7249156520804
INFO:root:current train perplexity3.270782470703125
INFO:root:current mean train loss 1504.7984510092558
INFO:root:current train perplexity3.2725796699523926
INFO:root:current mean train loss 1503.9803209601644
INFO:root:current train perplexity3.272576332092285
INFO:root:current mean train loss 1504.2478311542925
INFO:root:current train perplexity3.2728872299194336
INFO:root:current mean train loss 1505.3623104843696
INFO:root:current train perplexity3.2755775451660156
INFO:root:current mean train loss 1506.0999406862475
INFO:root:current train perplexity3.2777154445648193
INFO:root:current mean train loss 1505.6972596433332
INFO:root:current train perplexity3.2776291370391846
INFO:root:current mean train loss 1505.4760678819569
INFO:root:current train perplexity3.277120351791382
INFO:root:current mean train loss 1505.4847934514976
INFO:root:current train perplexity3.2776544094085693
INFO:root:current mean train loss 1505.3471075898858
INFO:root:current train perplexity3.2766497135162354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.21s/it]
INFO:root:final mean train loss: 1504.8418551092489
INFO:root:final train perplexity: 3.2766082286834717
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 3403.150047508446
INFO:root:eval perplexity: 16.322311401367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:46:48<3:28:58, 338.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1499.673161969866
INFO:root:current train perplexity3.2630667686462402
INFO:root:current mean train loss 1502.2425472483915
INFO:root:current train perplexity3.271057367324829
INFO:root:current mean train loss 1502.5011257595486
INFO:root:current train perplexity3.2665956020355225
INFO:root:current mean train loss 1498.955376702386
INFO:root:current train perplexity3.258601188659668
INFO:root:current mean train loss 1501.662770372756
INFO:root:current train perplexity3.2690234184265137
INFO:root:current mean train loss 1500.4285173382675
INFO:root:current train perplexity3.2708754539489746
INFO:root:current mean train loss 1501.3445256019706
INFO:root:current train perplexity3.2668685913085938
INFO:root:current mean train loss 1502.3598050996854
INFO:root:current train perplexity3.26833438873291
INFO:root:current mean train loss 1504.0534322804417
INFO:root:current train perplexity3.270310401916504
INFO:root:current mean train loss 1504.552863366825
INFO:root:current train perplexity3.269437551498413
INFO:root:current mean train loss 1504.4319207022124
INFO:root:current train perplexity3.2688939571380615
INFO:root:current mean train loss 1503.878722205529
INFO:root:current train perplexity3.2662370204925537
INFO:root:current mean train loss 1503.9032521645854
INFO:root:current train perplexity3.2654061317443848
INFO:root:current mean train loss 1503.0405448969263
INFO:root:current train perplexity3.2648181915283203
INFO:root:current mean train loss 1502.7262873020302
INFO:root:current train perplexity3.265418291091919
INFO:root:current mean train loss 1501.8624975896944
INFO:root:current train perplexity3.2642457485198975
INFO:root:current mean train loss 1502.1074671945173
INFO:root:current train perplexity3.2657079696655273
INFO:root:current mean train loss 1502.435980879789
INFO:root:current train perplexity3.2661595344543457
INFO:root:current mean train loss 1501.8980925697695
INFO:root:current train perplexity3.2661654949188232
INFO:root:current mean train loss 1502.0176894134677
INFO:root:current train perplexity3.2679927349090576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.72s/it]
INFO:root:final mean train loss: 1501.5445477230285
INFO:root:final train perplexity: 3.268098831176758
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 3411.3523770352385
INFO:root:eval perplexity: 16.43253517150879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:52:25<3:22:52, 338.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1497.1582929238505
INFO:root:current train perplexity3.242558717727661
INFO:root:current mean train loss 1497.167093368775
INFO:root:current train perplexity3.2484636306762695
INFO:root:current mean train loss 1498.1885607782556
INFO:root:current train perplexity3.247375249862671
INFO:root:current mean train loss 1490.5967475043403
INFO:root:current train perplexity3.242992877960205
INFO:root:current mean train loss 1490.3619109042127
INFO:root:current train perplexity3.2456963062286377
INFO:root:current mean train loss 1489.6034022888496
INFO:root:current train perplexity3.2455530166625977
INFO:root:current mean train loss 1490.0063458793895
INFO:root:current train perplexity3.245327949523926
INFO:root:current mean train loss 1489.6112715104332
INFO:root:current train perplexity3.2437069416046143
INFO:root:current mean train loss 1492.9667653596657
INFO:root:current train perplexity3.2472686767578125
INFO:root:current mean train loss 1494.7299706981778
INFO:root:current train perplexity3.2501673698425293
INFO:root:current mean train loss 1493.8157182990024
INFO:root:current train perplexity3.248063802719116
INFO:root:current mean train loss 1495.6238016130146
INFO:root:current train perplexity3.2531192302703857
INFO:root:current mean train loss 1495.3899586876882
INFO:root:current train perplexity3.2526464462280273
INFO:root:current mean train loss 1496.2780349830457
INFO:root:current train perplexity3.2545108795166016
INFO:root:current mean train loss 1497.211928510634
INFO:root:current train perplexity3.2553529739379883
INFO:root:current mean train loss 1498.1583312719065
INFO:root:current train perplexity3.2577614784240723
INFO:root:current mean train loss 1497.7507937826485
INFO:root:current train perplexity3.2584877014160156
INFO:root:current mean train loss 1497.4804734634033
INFO:root:current train perplexity3.2573866844177246
INFO:root:current mean train loss 1497.652289345584
INFO:root:current train perplexity3.257779359817505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it]
INFO:root:final mean train loss: 1498.066737064856
INFO:root:final train perplexity: 3.2591469287872314
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 3417.445058095205
INFO:root:eval perplexity: 16.514902114868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:58:08<3:18:05, 339.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1493.6773681640625
INFO:root:current train perplexity3.2876763343811035
INFO:root:current mean train loss 1482.6691401554988
INFO:root:current train perplexity3.2278940677642822
INFO:root:current mean train loss 1497.583760579427
INFO:root:current train perplexity3.2541706562042236
INFO:root:current mean train loss 1493.8175213462428
INFO:root:current train perplexity3.243515968322754
INFO:root:current mean train loss 1492.3797075630414
INFO:root:current train perplexity3.2417495250701904
INFO:root:current mean train loss 1493.848365178184
INFO:root:current train perplexity3.2439377307891846
INFO:root:current mean train loss 1493.178362309538
INFO:root:current train perplexity3.241156578063965
INFO:root:current mean train loss 1492.4781261790883
INFO:root:current train perplexity3.2413885593414307
INFO:root:current mean train loss 1494.7057287111804
INFO:root:current train perplexity3.2461092472076416
INFO:root:current mean train loss 1494.3612623636702
INFO:root:current train perplexity3.2437398433685303
INFO:root:current mean train loss 1493.773930401441
INFO:root:current train perplexity3.241657018661499
INFO:root:current mean train loss 1492.7638686912646
INFO:root:current train perplexity3.2415902614593506
INFO:root:current mean train loss 1493.799494239579
INFO:root:current train perplexity3.2445125579833984
INFO:root:current mean train loss 1494.0349183813926
INFO:root:current train perplexity3.2454464435577393
INFO:root:current mean train loss 1493.958627727976
INFO:root:current train perplexity3.2465410232543945
INFO:root:current mean train loss 1493.5816864662982
INFO:root:current train perplexity3.2461037635803223
INFO:root:current mean train loss 1493.7944146439322
INFO:root:current train perplexity3.24570894241333
INFO:root:current mean train loss 1492.9251024129806
INFO:root:current train perplexity3.2459497451782227
INFO:root:current mean train loss 1493.3806176703679
INFO:root:current train perplexity3.247528553009033
INFO:root:current mean train loss 1494.045179992163
INFO:root:current train perplexity3.2484500408172607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.31s/it]
INFO:root:final mean train loss: 1494.5563883586658
INFO:root:final train perplexity: 3.250136375427246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it]
INFO:root:eval mean loss: 3418.5738001184777
INFO:root:eval perplexity: 16.53020668029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:03:36<3:10:29, 336.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1456.3206322079614
INFO:root:current train perplexity3.1626648902893066
INFO:root:current mean train loss 1489.938668243156
INFO:root:current train perplexity3.21199631690979
INFO:root:current mean train loss 1484.365806614112
INFO:root:current train perplexity3.223327159881592
INFO:root:current mean train loss 1489.7931695385514
INFO:root:current train perplexity3.2361886501312256
INFO:root:current mean train loss 1492.4795124842265
INFO:root:current train perplexity3.2418789863586426
INFO:root:current mean train loss 1492.2005751128388
INFO:root:current train perplexity3.243069887161255
INFO:root:current mean train loss 1491.4795892933525
INFO:root:current train perplexity3.240431547164917
INFO:root:current mean train loss 1490.3948221193439
INFO:root:current train perplexity3.234382152557373
INFO:root:current mean train loss 1490.9633793523046
INFO:root:current train perplexity3.2350354194641113
INFO:root:current mean train loss 1491.7803048497303
INFO:root:current train perplexity3.2364351749420166
INFO:root:current mean train loss 1490.174639097507
INFO:root:current train perplexity3.235186815261841
INFO:root:current mean train loss 1489.8172053150786
INFO:root:current train perplexity3.2348499298095703
INFO:root:current mean train loss 1489.9659457819857
INFO:root:current train perplexity3.234970808029175
INFO:root:current mean train loss 1488.178761391997
INFO:root:current train perplexity3.2349929809570312
INFO:root:current mean train loss 1489.266475884198
INFO:root:current train perplexity3.237319231033325
INFO:root:current mean train loss 1489.259087697367
INFO:root:current train perplexity3.2385048866271973
INFO:root:current mean train loss 1490.1372098928612
INFO:root:current train perplexity3.2391464710235596
INFO:root:current mean train loss 1490.6660408051052
INFO:root:current train perplexity3.241353750228882
INFO:root:current mean train loss 1491.905234155126
INFO:root:current train perplexity3.2424254417419434
INFO:root:current mean train loss 1491.3514611454198
INFO:root:current train perplexity3.2416563034057617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.28s/it]
INFO:root:final mean train loss: 1492.0639340645487
INFO:root:final train perplexity: 3.243753671646118
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it]
INFO:root:eval mean loss: 3419.2150812922296
INFO:root:eval perplexity: 16.538898468017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:09:05<3:03:43, 334.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1474.102105391653
INFO:root:current train perplexity3.2090578079223633
INFO:root:current mean train loss 1473.735443557518
INFO:root:current train perplexity3.206270456314087
INFO:root:current mean train loss 1477.2734098033745
INFO:root:current train perplexity3.2113921642303467
INFO:root:current mean train loss 1477.6274937736916
INFO:root:current train perplexity3.216144561767578
INFO:root:current mean train loss 1479.8345532003602
INFO:root:current train perplexity3.218977212905884
INFO:root:current mean train loss 1484.3108327645796
INFO:root:current train perplexity3.223740577697754
INFO:root:current mean train loss 1488.2054967611186
INFO:root:current train perplexity3.228351354598999
INFO:root:current mean train loss 1485.3523533105204
INFO:root:current train perplexity3.2263078689575195
INFO:root:current mean train loss 1486.2932662053438
INFO:root:current train perplexity3.2268669605255127
INFO:root:current mean train loss 1488.3528491835605
INFO:root:current train perplexity3.229231834411621
INFO:root:current mean train loss 1488.2093462346836
INFO:root:current train perplexity3.2304134368896484
INFO:root:current mean train loss 1489.8871729202137
INFO:root:current train perplexity3.2318193912506104
INFO:root:current mean train loss 1489.5678142985157
INFO:root:current train perplexity3.2314703464508057
INFO:root:current mean train loss 1488.5209054989666
INFO:root:current train perplexity3.231027126312256
INFO:root:current mean train loss 1488.858677722151
INFO:root:current train perplexity3.232294797897339
INFO:root:current mean train loss 1489.5655158034226
INFO:root:current train perplexity3.2331929206848145
INFO:root:current mean train loss 1489.3712041200445
INFO:root:current train perplexity3.2335076332092285
INFO:root:current mean train loss 1489.726268491756
INFO:root:current train perplexity3.234875202178955
INFO:root:current mean train loss 1490.2245481405996
INFO:root:current train perplexity3.235846519470215
INFO:root:current mean train loss 1488.9521666409676
INFO:root:current train perplexity3.2348439693450928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.99s/it]
INFO:root:final mean train loss: 1488.7441712195262
INFO:root:final train perplexity: 3.2352733612060547
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 3426.452530411271
INFO:root:eval perplexity: 16.637422561645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:14:33<2:57:11, 332.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1472.1404940518466
INFO:root:current train perplexity3.2097008228302
INFO:root:current mean train loss 1491.0754000756049
INFO:root:current train perplexity3.221317768096924
INFO:root:current mean train loss 1487.5304323682599
INFO:root:current train perplexity3.222973585128784
INFO:root:current mean train loss 1489.2593230771347
INFO:root:current train perplexity3.227539300918579
INFO:root:current mean train loss 1488.9102289556147
INFO:root:current train perplexity3.231231927871704
INFO:root:current mean train loss 1486.4916433523367
INFO:root:current train perplexity3.2259857654571533
INFO:root:current mean train loss 1486.7141694745944
INFO:root:current train perplexity3.2270798683166504
INFO:root:current mean train loss 1486.4077423297806
INFO:root:current train perplexity3.223001718521118
INFO:root:current mean train loss 1484.7114283511514
INFO:root:current train perplexity3.2207751274108887
INFO:root:current mean train loss 1485.2732694136535
INFO:root:current train perplexity3.221925973892212
INFO:root:current mean train loss 1484.7359917663284
INFO:root:current train perplexity3.2216951847076416
INFO:root:current mean train loss 1486.53236744538
INFO:root:current train perplexity3.224853277206421
INFO:root:current mean train loss 1486.9714496506163
INFO:root:current train perplexity3.225785732269287
INFO:root:current mean train loss 1486.5371903648236
INFO:root:current train perplexity3.2257649898529053
INFO:root:current mean train loss 1487.3489157974925
INFO:root:current train perplexity3.227458953857422
INFO:root:current mean train loss 1487.3506072114901
INFO:root:current train perplexity3.226864814758301
INFO:root:current mean train loss 1488.3423103078974
INFO:root:current train perplexity3.229111433029175
INFO:root:current mean train loss 1487.2926155459847
INFO:root:current train perplexity3.227975606918335
INFO:root:current mean train loss 1486.7901611328125
INFO:root:current train perplexity3.227656602859497
INFO:root:current mean train loss 1486.354458657189
INFO:root:current train perplexity3.2276604175567627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.96s/it]
INFO:root:final mean train loss: 1485.9649422434443
INFO:root:final train perplexity: 3.2281887531280518
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it]
INFO:root:eval mean loss: 3430.195240650807
INFO:root:eval perplexity: 16.6885929107666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:20:01<2:50:59, 330.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1465.2467668321397
INFO:root:current train perplexity3.1975812911987305
INFO:root:current mean train loss 1474.2965698242188
INFO:root:current train perplexity3.213003158569336
INFO:root:current mean train loss 1475.6288330975701
INFO:root:current train perplexity3.2167534828186035
INFO:root:current mean train loss 1472.218962638609
INFO:root:current train perplexity3.2058444023132324
INFO:root:current mean train loss 1476.2364398503707
INFO:root:current train perplexity3.2072067260742188
INFO:root:current mean train loss 1479.4683001324847
INFO:root:current train perplexity3.215628147125244
INFO:root:current mean train loss 1480.2885288056873
INFO:root:current train perplexity3.217863082885742
INFO:root:current mean train loss 1479.4150956702356
INFO:root:current train perplexity3.216118097305298
INFO:root:current mean train loss 1477.5942986164619
INFO:root:current train perplexity3.2149031162261963
INFO:root:current mean train loss 1478.3857430666071
INFO:root:current train perplexity3.2162678241729736
INFO:root:current mean train loss 1478.2828710755305
INFO:root:current train perplexity3.2161288261413574
INFO:root:current mean train loss 1479.558703009179
INFO:root:current train perplexity3.217397451400757
INFO:root:current mean train loss 1479.4942106810756
INFO:root:current train perplexity3.216315746307373
INFO:root:current mean train loss 1478.9687039122289
INFO:root:current train perplexity3.2166342735290527
INFO:root:current mean train loss 1480.0446565047555
INFO:root:current train perplexity3.218385696411133
INFO:root:current mean train loss 1480.1115186074915
INFO:root:current train perplexity3.2184903621673584
INFO:root:current mean train loss 1481.7865721780147
INFO:root:current train perplexity3.2199554443359375
INFO:root:current mean train loss 1482.2765546329404
INFO:root:current train perplexity3.2199409008026123
INFO:root:current mean train loss 1483.45887306409
INFO:root:current train perplexity3.221141815185547
INFO:root:current mean train loss 1483.8470744970605
INFO:root:current train perplexity3.2220163345336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it]
INFO:root:final mean train loss: 1483.839924329949
INFO:root:final train perplexity: 3.222783327102661
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.33s/it]
INFO:root:eval mean loss: 3431.3277496246246
INFO:root:eval perplexity: 16.70410919189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:25:29<2:45:02, 330.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1468.7662957009304
INFO:root:current train perplexity3.2177376747131348
INFO:root:current mean train loss 1462.4928165819279
INFO:root:current train perplexity3.1973559856414795
INFO:root:current mean train loss 1468.4295958416685
INFO:root:current train perplexity3.1993930339813232
INFO:root:current mean train loss 1467.6721608767473
INFO:root:current train perplexity3.197356700897217
INFO:root:current mean train loss 1472.701638937484
INFO:root:current train perplexity3.2039995193481445
INFO:root:current mean train loss 1472.7455845364893
INFO:root:current train perplexity3.2049643993377686
INFO:root:current mean train loss 1473.3883503109691
INFO:root:current train perplexity3.2036187648773193
INFO:root:current mean train loss 1473.1330402408112
INFO:root:current train perplexity3.201420545578003
INFO:root:current mean train loss 1474.980090180988
INFO:root:current train perplexity3.2039921283721924
INFO:root:current mean train loss 1477.7444910371507
INFO:root:current train perplexity3.206242322921753
INFO:root:current mean train loss 1476.1807888230674
INFO:root:current train perplexity3.205507755279541
INFO:root:current mean train loss 1475.533651058367
INFO:root:current train perplexity3.2059624195098877
INFO:root:current mean train loss 1476.1292888443077
INFO:root:current train perplexity3.207190752029419
INFO:root:current mean train loss 1476.1943665209908
INFO:root:current train perplexity3.207909107208252
INFO:root:current mean train loss 1476.8029503960029
INFO:root:current train perplexity3.2093210220336914
INFO:root:current mean train loss 1476.5725170637243
INFO:root:current train perplexity3.2093136310577393
INFO:root:current mean train loss 1477.7844616995542
INFO:root:current train perplexity3.209932804107666
INFO:root:current mean train loss 1478.542475760616
INFO:root:current train perplexity3.2096989154815674
INFO:root:current mean train loss 1479.695354116348
INFO:root:current train perplexity3.210928201675415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it]
INFO:root:final mean train loss: 1479.964707090346
INFO:root:final train perplexity: 3.21294903755188
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 3437.214577614724
INFO:root:eval perplexity: 16.78499984741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [6:30:57<2:39:14, 329.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1500.7108764648438
INFO:root:current train perplexity3.184368133544922
INFO:root:current mean train loss 1473.8013489921138
INFO:root:current train perplexity3.1830828189849854
INFO:root:current mean train loss 1466.7895466332297
INFO:root:current train perplexity3.17903995513916
INFO:root:current mean train loss 1465.8324752508424
INFO:root:current train perplexity3.174971580505371
INFO:root:current mean train loss 1468.5928194393666
INFO:root:current train perplexity3.184493064880371
INFO:root:current mean train loss 1466.639244592237
INFO:root:current train perplexity3.181226968765259
INFO:root:current mean train loss 1469.2046539004486
INFO:root:current train perplexity3.1869611740112305
INFO:root:current mean train loss 1471.785611333658
INFO:root:current train perplexity3.1919808387756348
INFO:root:current mean train loss 1473.1223548908092
INFO:root:current train perplexity3.193148136138916
INFO:root:current mean train loss 1473.393243179153
INFO:root:current train perplexity3.193843126296997
INFO:root:current mean train loss 1474.6761735495231
INFO:root:current train perplexity3.1981945037841797
INFO:root:current mean train loss 1470.6473646939987
INFO:root:current train perplexity3.1938960552215576
INFO:root:current mean train loss 1472.7654585956934
INFO:root:current train perplexity3.1962051391601562
INFO:root:current mean train loss 1475.0031264394202
INFO:root:current train perplexity3.199397325515747
INFO:root:current mean train loss 1475.362339502717
INFO:root:current train perplexity3.2013235092163086
INFO:root:current mean train loss 1475.6176513023427
INFO:root:current train perplexity3.2006611824035645
INFO:root:current mean train loss 1475.5777960334294
INFO:root:current train perplexity3.2024033069610596
INFO:root:current mean train loss 1474.8099413175237
INFO:root:current train perplexity3.2018239498138428
INFO:root:current mean train loss 1475.7643924683564
INFO:root:current train perplexity3.2039318084716797
INFO:root:current mean train loss 1477.7476059872606
INFO:root:current train perplexity3.205940008163452

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.53s/it]
INFO:root:final mean train loss: 1477.558655985545
INFO:root:final train perplexity: 3.2068581581115723
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.66s/it]
INFO:root:eval mean loss: 3429.4801769542983
INFO:root:eval perplexity: 16.678802490234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:36:26<2:33:39, 329.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1500.3208591627038
INFO:root:current train perplexity3.2154266834259033
INFO:root:current mean train loss 1484.1912107390117
INFO:root:current train perplexity3.2043986320495605
INFO:root:current mean train loss 1474.4757309986337
INFO:root:current train perplexity3.1902761459350586
INFO:root:current mean train loss 1474.9195522627226
INFO:root:current train perplexity3.1923940181732178
INFO:root:current mean train loss 1474.5480385638298
INFO:root:current train perplexity3.193486452102661
INFO:root:current mean train loss 1476.3254497229027
INFO:root:current train perplexity3.1965460777282715
INFO:root:current mean train loss 1475.1332825588759
INFO:root:current train perplexity3.19417405128479
INFO:root:current mean train loss 1474.827481387232
INFO:root:current train perplexity3.1992180347442627
INFO:root:current mean train loss 1474.4855998561854
INFO:root:current train perplexity3.198692798614502
INFO:root:current mean train loss 1475.0565328381044
INFO:root:current train perplexity3.199812173843384
INFO:root:current mean train loss 1476.313476681826
INFO:root:current train perplexity3.200782537460327
INFO:root:current mean train loss 1476.1002967949967
INFO:root:current train perplexity3.200748920440674
INFO:root:current mean train loss 1475.7477127037766
INFO:root:current train perplexity3.2009897232055664
INFO:root:current mean train loss 1475.3091568604439
INFO:root:current train perplexity3.200655698776245
INFO:root:current mean train loss 1475.2181317563302
INFO:root:current train perplexity3.2010574340820312
INFO:root:current mean train loss 1475.9243220969868
INFO:root:current train perplexity3.2023847103118896
INFO:root:current mean train loss 1476.6639678823456
INFO:root:current train perplexity3.203087568283081
INFO:root:current mean train loss 1476.6348149348883
INFO:root:current train perplexity3.202927827835083
INFO:root:current mean train loss 1476.6424726610712
INFO:root:current train perplexity3.2017509937286377
INFO:root:current mean train loss 1476.3913714507564
INFO:root:current train perplexity3.2023727893829346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.16s/it]
INFO:root:final mean train loss: 1475.9240505047296
INFO:root:final train perplexity: 3.2027266025543213
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 3436.1068214210304
INFO:root:eval perplexity: 16.769746780395508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:41:55<2:28:08, 329.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1463.0337951660156
INFO:root:current train perplexity3.2123286724090576
INFO:root:current mean train loss 1464.7051531110492
INFO:root:current train perplexity3.1818137168884277
INFO:root:current mean train loss 1461.4489741007487
INFO:root:current train perplexity3.1775503158569336
INFO:root:current mean train loss 1465.049475815717
INFO:root:current train perplexity3.1829917430877686
INFO:root:current mean train loss 1470.1498668323864
INFO:root:current train perplexity3.1888394355773926
INFO:root:current mean train loss 1470.852865713614
INFO:root:current train perplexity3.1933772563934326
INFO:root:current mean train loss 1471.3150941848755
INFO:root:current train perplexity3.190074920654297
INFO:root:current mean train loss 1470.7809590107686
INFO:root:current train perplexity3.1895346641540527
INFO:root:current mean train loss 1471.4160619826544
INFO:root:current train perplexity3.190659999847412
INFO:root:current mean train loss 1471.7016808043136
INFO:root:current train perplexity3.1933038234710693
INFO:root:current mean train loss 1472.8591551560621
INFO:root:current train perplexity3.1962168216705322
INFO:root:current mean train loss 1472.9450226365475
INFO:root:current train perplexity3.1983132362365723
INFO:root:current mean train loss 1473.8299549718056
INFO:root:current train perplexity3.1994025707244873
INFO:root:current mean train loss 1473.7396536300432
INFO:root:current train perplexity3.19822096824646
INFO:root:current mean train loss 1472.6761533949111
INFO:root:current train perplexity3.19541072845459
INFO:root:current mean train loss 1472.4081691989652
INFO:root:current train perplexity3.1953554153442383
INFO:root:current mean train loss 1472.7415868247429
INFO:root:current train perplexity3.194983720779419
INFO:root:current mean train loss 1472.8835710898213
INFO:root:current train perplexity3.1948230266571045
INFO:root:current mean train loss 1473.2354242076044
INFO:root:current train perplexity3.195603132247925
INFO:root:current mean train loss 1473.4017406345642
INFO:root:current train perplexity3.195251226425171

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.67s/it]
INFO:root:final mean train loss: 1472.8364467111069
INFO:root:final train perplexity: 3.194937229156494
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it]
INFO:root:eval mean loss: 3437.409593920092
INFO:root:eval perplexity: 16.787681579589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:47:23<2:22:34, 329.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1458.8248462342378
INFO:root:current train perplexity3.1598000526428223
INFO:root:current mean train loss 1477.1781744501393
INFO:root:current train perplexity3.1960275173187256
INFO:root:current mean train loss 1474.438740652359
INFO:root:current train perplexity3.185077428817749
INFO:root:current mean train loss 1470.0618205778405
INFO:root:current train perplexity3.1815974712371826
INFO:root:current mean train loss 1466.3489447996444
INFO:root:current train perplexity3.1776418685913086
INFO:root:current mean train loss 1469.1870640972145
INFO:root:current train perplexity3.185228109359741
INFO:root:current mean train loss 1469.4455666738013
INFO:root:current train perplexity3.182180643081665
INFO:root:current mean train loss 1467.972923772653
INFO:root:current train perplexity3.1811087131500244
INFO:root:current mean train loss 1468.4095118554915
INFO:root:current train perplexity3.1837852001190186
INFO:root:current mean train loss 1468.2655871161098
INFO:root:current train perplexity3.183727502822876
INFO:root:current mean train loss 1467.2698969989874
INFO:root:current train perplexity3.180844783782959
INFO:root:current mean train loss 1469.304054148154
INFO:root:current train perplexity3.1824183464050293
INFO:root:current mean train loss 1468.0904433220837
INFO:root:current train perplexity3.1817264556884766
INFO:root:current mean train loss 1469.0667195668007
INFO:root:current train perplexity3.18489670753479
INFO:root:current mean train loss 1469.2764058109826
INFO:root:current train perplexity3.185699701309204
INFO:root:current mean train loss 1469.058725698835
INFO:root:current train perplexity3.1857528686523438
INFO:root:current mean train loss 1469.6235732433663
INFO:root:current train perplexity3.1869187355041504
INFO:root:current mean train loss 1469.5917726276812
INFO:root:current train perplexity3.186704397201538
INFO:root:current mean train loss 1471.1066486315503
INFO:root:current train perplexity3.1905081272125244
INFO:root:current mean train loss 1470.805344945628
INFO:root:current train perplexity3.189563512802124

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.97s/it]
INFO:root:final mean train loss: 1470.805154051134
INFO:root:final train perplexity: 3.1898233890533447
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 3455.1421030405404
INFO:root:eval perplexity: 17.03373908996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:52:52<2:17:05, 329.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1474.5955084723396
INFO:root:current train perplexity3.201556444168091
INFO:root:current mean train loss 1459.930542693741
INFO:root:current train perplexity3.1715190410614014
INFO:root:current mean train loss 1466.1765956460995
INFO:root:current train perplexity3.174690008163452
INFO:root:current mean train loss 1465.9243983304436
INFO:root:current train perplexity3.1716649532318115
INFO:root:current mean train loss 1467.695380746061
INFO:root:current train perplexity3.1766064167022705
INFO:root:current mean train loss 1465.731771329554
INFO:root:current train perplexity3.1772096157073975
INFO:root:current mean train loss 1464.298157281621
INFO:root:current train perplexity3.173748731613159
INFO:root:current mean train loss 1466.0432078437905
INFO:root:current train perplexity3.177222967147827
INFO:root:current mean train loss 1465.3896836339745
INFO:root:current train perplexity3.1746022701263428
INFO:root:current mean train loss 1467.0959448843766
INFO:root:current train perplexity3.177428722381592
INFO:root:current mean train loss 1466.77395590102
INFO:root:current train perplexity3.175562620162964
INFO:root:current mean train loss 1467.161224833136
INFO:root:current train perplexity3.1754534244537354
INFO:root:current mean train loss 1466.1757753093725
INFO:root:current train perplexity3.175387382507324
INFO:root:current mean train loss 1468.1892933852462
INFO:root:current train perplexity3.1798737049102783
INFO:root:current mean train loss 1467.5660551115163
INFO:root:current train perplexity3.179809808731079
INFO:root:current mean train loss 1467.1860133635196
INFO:root:current train perplexity3.179945945739746
INFO:root:current mean train loss 1467.4987222723921
INFO:root:current train perplexity3.180807113647461
INFO:root:current mean train loss 1467.3913843956982
INFO:root:current train perplexity3.1808416843414307
INFO:root:current mean train loss 1467.9064943360418
INFO:root:current train perplexity3.1816461086273193
INFO:root:current mean train loss 1468.2162223282555
INFO:root:current train perplexity3.1825647354125977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.34s/it]
INFO:root:final mean train loss: 1467.9921525656064
INFO:root:final train perplexity: 3.1827542781829834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it]
INFO:root:eval mean loss: 3451.379371070289
INFO:root:eval perplexity: 16.981231689453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:58:21<2:11:30, 328.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1462.9485815697974
INFO:root:current train perplexity3.182598114013672
INFO:root:current mean train loss 1469.4911591694618
INFO:root:current train perplexity3.193338394165039
INFO:root:current mean train loss 1462.901600421499
INFO:root:current train perplexity3.175757884979248
INFO:root:current mean train loss 1464.076913975084
INFO:root:current train perplexity3.1758532524108887
INFO:root:current mean train loss 1464.804344658939
INFO:root:current train perplexity3.1771676540374756
INFO:root:current mean train loss 1462.407139812024
INFO:root:current train perplexity3.168591022491455
INFO:root:current mean train loss 1462.3989026391214
INFO:root:current train perplexity3.1687557697296143
INFO:root:current mean train loss 1464.6037583767086
INFO:root:current train perplexity3.1708977222442627
INFO:root:current mean train loss 1464.1429758467925
INFO:root:current train perplexity3.1711924076080322
INFO:root:current mean train loss 1464.2548161727027
INFO:root:current train perplexity3.172549247741699
INFO:root:current mean train loss 1465.0314040704127
INFO:root:current train perplexity3.1727795600891113
INFO:root:current mean train loss 1465.8787101790447
INFO:root:current train perplexity3.1742935180664062
INFO:root:current mean train loss 1464.877559410704
INFO:root:current train perplexity3.173243284225464
INFO:root:current mean train loss 1465.353835149089
INFO:root:current train perplexity3.174790382385254
INFO:root:current mean train loss 1465.2987360196335
INFO:root:current train perplexity3.173799753189087
INFO:root:current mean train loss 1465.5962394364294
INFO:root:current train perplexity3.1743953227996826
INFO:root:current mean train loss 1464.8587975662747
INFO:root:current train perplexity3.1725919246673584
INFO:root:current mean train loss 1465.3245457021435
INFO:root:current train perplexity3.1740968227386475
INFO:root:current mean train loss 1464.8703602307187
INFO:root:current train perplexity3.1738531589508057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.47s/it]
INFO:root:final mean train loss: 1464.9645781254924
INFO:root:final train perplexity: 3.175163507461548
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.63s/it]
INFO:root:eval mean loss: 3455.855449687969
INFO:root:eval perplexity: 17.043716430664062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [7:03:49<2:06:00, 328.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.2217864990234
INFO:root:current train perplexity3.0764482021331787
INFO:root:current mean train loss 1455.4451700846355
INFO:root:current train perplexity3.1607279777526855
INFO:root:current mean train loss 1460.442726135254
INFO:root:current train perplexity3.157954216003418
INFO:root:current mean train loss 1463.9028395615614
INFO:root:current train perplexity3.168038845062256
INFO:root:current mean train loss 1463.4079365449793
INFO:root:current train perplexity3.163259983062744
INFO:root:current mean train loss 1461.7409317136749
INFO:root:current train perplexity3.162092685699463
INFO:root:current mean train loss 1461.7946072628624
INFO:root:current train perplexity3.1636874675750732
INFO:root:current mean train loss 1460.8940402100989
INFO:root:current train perplexity3.1647839546203613
INFO:root:current mean train loss 1463.6610187492747
INFO:root:current train perplexity3.1680243015289307
INFO:root:current mean train loss 1464.366068701387
INFO:root:current train perplexity3.17026948928833
INFO:root:current mean train loss 1464.4513380262588
INFO:root:current train perplexity3.1688363552093506
INFO:root:current mean train loss 1462.8293129821116
INFO:root:current train perplexity3.1676816940307617
INFO:root:current mean train loss 1461.85801292571
INFO:root:current train perplexity3.165782928466797
INFO:root:current mean train loss 1461.8175526656871
INFO:root:current train perplexity3.16568922996521
INFO:root:current mean train loss 1462.5175254128196
INFO:root:current train perplexity3.168009042739868
INFO:root:current mean train loss 1462.5257229185231
INFO:root:current train perplexity3.1678788661956787
INFO:root:current mean train loss 1462.1979046721956
INFO:root:current train perplexity3.168264389038086
INFO:root:current mean train loss 1463.6978772630177
INFO:root:current train perplexity3.1700003147125244
INFO:root:current mean train loss 1463.588863136494
INFO:root:current train perplexity3.170302629470825
INFO:root:current mean train loss 1463.183418961691
INFO:root:current train perplexity3.1702351570129395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it]
INFO:root:final mean train loss: 1463.5963963957308
INFO:root:final train perplexity: 3.1717395782470703
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it]
INFO:root:eval mean loss: 3455.1724248662726
INFO:root:eval perplexity: 17.034164428710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [7:09:18<2:00:32, 328.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1466.08470703125
INFO:root:current train perplexity3.190009593963623
INFO:root:current mean train loss 1449.50830859375
INFO:root:current train perplexity3.1457722187042236
INFO:root:current mean train loss 1458.5017339409721
INFO:root:current train perplexity3.1679837703704834
INFO:root:current mean train loss 1455.5033165564903
INFO:root:current train perplexity3.1660776138305664
INFO:root:current mean train loss 1458.7276924402574
INFO:root:current train perplexity3.1661157608032227
INFO:root:current mean train loss 1457.2729029482887
INFO:root:current train perplexity3.161860704421997
INFO:root:current mean train loss 1458.7570509765626
INFO:root:current train perplexity3.1618027687072754
INFO:root:current mean train loss 1459.1942254849139
INFO:root:current train perplexity3.1609389781951904
INFO:root:current mean train loss 1458.3658549360796
INFO:root:current train perplexity3.161129951477051
INFO:root:current mean train loss 1456.7879947476774
INFO:root:current train perplexity3.1593563556671143
INFO:root:current mean train loss 1455.9562470226754
INFO:root:current train perplexity3.1583611965179443
INFO:root:current mean train loss 1458.030859266493
INFO:root:current train perplexity3.1608707904815674
INFO:root:current mean train loss 1458.7134899154973
INFO:root:current train perplexity3.162208318710327
INFO:root:current mean train loss 1459.8763950103184
INFO:root:current train perplexity3.16325306892395
INFO:root:current mean train loss 1459.623429104989
INFO:root:current train perplexity3.1627418994903564
INFO:root:current mean train loss 1460.0691629578637
INFO:root:current train perplexity3.163649320602417
INFO:root:current mean train loss 1460.19041413762
INFO:root:current train perplexity3.1627602577209473
INFO:root:current mean train loss 1461.3764487800045
INFO:root:current train perplexity3.16418719291687
INFO:root:current mean train loss 1461.1542180142337
INFO:root:current train perplexity3.1661460399627686
INFO:root:current mean train loss 1461.5042047991071
INFO:root:current train perplexity3.1660983562469482

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.57s/it]
INFO:root:final mean train loss: 1461.4622134210122
INFO:root:final train perplexity: 3.16640567779541
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it]
INFO:root:eval mean loss: 3457.5851640214432
INFO:root:eval perplexity: 17.067922592163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:14:47<1:55:02, 328.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1459.6567004975818
INFO:root:current train perplexity3.1471548080444336
INFO:root:current mean train loss 1456.91113195285
INFO:root:current train perplexity3.1555280685424805
INFO:root:current mean train loss 1457.5327708346786
INFO:root:current train perplexity3.1576552391052246
INFO:root:current mean train loss 1464.581780327691
INFO:root:current train perplexity3.168367862701416
INFO:root:current mean train loss 1462.1019966505232
INFO:root:current train perplexity3.159937620162964
INFO:root:current mean train loss 1463.7978038154406
INFO:root:current train perplexity3.162989854812622
INFO:root:current mean train loss 1463.3517393308266
INFO:root:current train perplexity3.16092586517334
INFO:root:current mean train loss 1462.1153806290536
INFO:root:current train perplexity3.161591053009033
INFO:root:current mean train loss 1462.8833623963128
INFO:root:current train perplexity3.165670394897461
INFO:root:current mean train loss 1464.1071944510102
INFO:root:current train perplexity3.1687581539154053
INFO:root:current mean train loss 1462.1121946836388
INFO:root:current train perplexity3.165982484817505
INFO:root:current mean train loss 1460.3308930672613
INFO:root:current train perplexity3.1625468730926514
INFO:root:current mean train loss 1460.9635408803845
INFO:root:current train perplexity3.1628599166870117
INFO:root:current mean train loss 1460.5319244794093
INFO:root:current train perplexity3.1629340648651123
INFO:root:current mean train loss 1460.4725546658287
INFO:root:current train perplexity3.1620402336120605
INFO:root:current mean train loss 1460.7518939106071
INFO:root:current train perplexity3.162722110748291
INFO:root:current mean train loss 1461.9288932995441
INFO:root:current train perplexity3.165093421936035
INFO:root:current mean train loss 1461.3952268826017
INFO:root:current train perplexity3.164815664291382
INFO:root:current mean train loss 1460.0477620310166
INFO:root:current train perplexity3.1635830402374268
INFO:root:current mean train loss 1459.8221706465024
INFO:root:current train perplexity3.1624858379364014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it]
INFO:root:final mean train loss: 1459.5880722838463
INFO:root:final train perplexity: 3.161728620529175
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.22s/it]
INFO:root:eval mean loss: 3458.415650513795
INFO:root:eval perplexity: 17.079561233520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:20:16<1:49:36, 328.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1441.3243573722193
INFO:root:current train perplexity3.1566812992095947
INFO:root:current mean train loss 1461.0119813163326
INFO:root:current train perplexity3.1689186096191406
INFO:root:current mean train loss 1451.3513881138392
INFO:root:current train perplexity3.146855354309082
INFO:root:current mean train loss 1448.9812647572467
INFO:root:current train perplexity3.1441965103149414
INFO:root:current mean train loss 1449.4147300304671
INFO:root:current train perplexity3.141653299331665
INFO:root:current mean train loss 1450.4148929711957
INFO:root:current train perplexity3.1403722763061523
INFO:root:current mean train loss 1451.7626302947767
INFO:root:current train perplexity3.140737295150757
INFO:root:current mean train loss 1452.936315322896
INFO:root:current train perplexity3.1439831256866455
INFO:root:current mean train loss 1453.8045232237703
INFO:root:current train perplexity3.1473300457000732
INFO:root:current mean train loss 1453.4756658750978
INFO:root:current train perplexity3.1484575271606445
INFO:root:current mean train loss 1453.095932280601
INFO:root:current train perplexity3.1481716632843018
INFO:root:current mean train loss 1454.884286928218
INFO:root:current train perplexity3.150036334991455
INFO:root:current mean train loss 1456.3203828916178
INFO:root:current train perplexity3.153015613555908
INFO:root:current mean train loss 1456.5521786362042
INFO:root:current train perplexity3.154768705368042
INFO:root:current mean train loss 1457.1376108923866
INFO:root:current train perplexity3.1564269065856934
INFO:root:current mean train loss 1457.5466927166854
INFO:root:current train perplexity3.1565940380096436
INFO:root:current mean train loss 1457.756139717309
INFO:root:current train perplexity3.1575276851654053
INFO:root:current mean train loss 1457.2703243253447
INFO:root:current train perplexity3.156226396560669
INFO:root:current mean train loss 1457.196524732404
INFO:root:current train perplexity3.1555144786834717
INFO:root:current mean train loss 1457.3498409907997
INFO:root:current train perplexity3.1558690071105957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.67s/it]
INFO:root:final mean train loss: 1457.3928588620954
INFO:root:final train perplexity: 3.156259775161743
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 3450.270235078829
INFO:root:eval perplexity: 16.965782165527344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [7:25:44<1:44:07, 328.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1457.8880920410156
INFO:root:current train perplexity3.175985336303711
INFO:root:current mean train loss 1463.5083867853339
INFO:root:current train perplexity3.17090106010437
INFO:root:current mean train loss 1463.3199750375056
INFO:root:current train perplexity3.16401743888855
INFO:root:current mean train loss 1457.1865955109292
INFO:root:current train perplexity3.1526918411254883
INFO:root:current mean train loss 1455.918670910747
INFO:root:current train perplexity3.1517844200134277
INFO:root:current mean train loss 1456.4156720903184
INFO:root:current train perplexity3.151883125305176
INFO:root:current mean train loss 1455.6035022622734
INFO:root:current train perplexity3.149771213531494
INFO:root:current mean train loss 1454.3304680893102
INFO:root:current train perplexity3.1494250297546387
INFO:root:current mean train loss 1456.2685893855682
INFO:root:current train perplexity3.148327112197876
INFO:root:current mean train loss 1457.0222573202163
INFO:root:current train perplexity3.150320529937744
INFO:root:current mean train loss 1454.6827065847176
INFO:root:current train perplexity3.1479198932647705
INFO:root:current mean train loss 1454.6731582953005
INFO:root:current train perplexity3.1497745513916016
INFO:root:current mean train loss 1456.1840767695985
INFO:root:current train perplexity3.15167498588562
INFO:root:current mean train loss 1456.639490438062
INFO:root:current train perplexity3.1514666080474854
INFO:root:current mean train loss 1457.0856492784287
INFO:root:current train perplexity3.15106201171875
INFO:root:current mean train loss 1457.4277385576122
INFO:root:current train perplexity3.1519951820373535
INFO:root:current mean train loss 1458.0357745405029
INFO:root:current train perplexity3.1526780128479004
INFO:root:current mean train loss 1457.17107989337
INFO:root:current train perplexity3.1525001525878906
INFO:root:current mean train loss 1456.5925760818188
INFO:root:current train perplexity3.1529269218444824
INFO:root:current mean train loss 1456.4798731012384
INFO:root:current train perplexity3.152850866317749

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.24s/it]
INFO:root:final mean train loss: 1455.8048620180716
INFO:root:final train perplexity: 3.1523094177246094
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it]
INFO:root:eval mean loss: 3458.9591955236488
INFO:root:eval perplexity: 17.087177276611328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [7:31:13<1:38:35, 328.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1459.3858760710687
INFO:root:current train perplexity3.157851457595825
INFO:root:current mean train loss 1469.192854016556
INFO:root:current train perplexity3.167285680770874
INFO:root:current mean train loss 1455.1598604482188
INFO:root:current train perplexity3.1525588035583496
INFO:root:current mean train loss 1455.1254497654263
INFO:root:current train perplexity3.1525487899780273
INFO:root:current mean train loss 1454.7217623882796
INFO:root:current train perplexity3.1504786014556885
INFO:root:current mean train loss 1453.7525177773898
INFO:root:current train perplexity3.151880979537964
INFO:root:current mean train loss 1454.7327628968253
INFO:root:current train perplexity3.1550590991973877
INFO:root:current mean train loss 1454.3191404402783
INFO:root:current train perplexity3.1553423404693604
INFO:root:current mean train loss 1455.3871390929014
INFO:root:current train perplexity3.159127712249756
INFO:root:current mean train loss 1457.1567549998426
INFO:root:current train perplexity3.161086320877075
INFO:root:current mean train loss 1456.40407116219
INFO:root:current train perplexity3.158849000930786
INFO:root:current mean train loss 1455.1137252257636
INFO:root:current train perplexity3.155770778656006
INFO:root:current mean train loss 1455.015595922153
INFO:root:current train perplexity3.1550681591033936
INFO:root:current mean train loss 1455.0488958639457
INFO:root:current train perplexity3.1528539657592773
INFO:root:current mean train loss 1454.7939851304786
INFO:root:current train perplexity3.151660442352295
INFO:root:current mean train loss 1455.5604708588355
INFO:root:current train perplexity3.1523475646972656
INFO:root:current mean train loss 1455.6158444381506
INFO:root:current train perplexity3.151535749435425
INFO:root:current mean train loss 1455.3743157118176
INFO:root:current train perplexity3.151867389678955
INFO:root:current mean train loss 1455.7104966153056
INFO:root:current train perplexity3.1509196758270264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.14s/it]
INFO:root:final mean train loss: 1454.5716543500614
INFO:root:final train perplexity: 3.149245262145996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 3465.4972514017923
INFO:root:eval perplexity: 17.179096221923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [7:36:41<1:33:03, 328.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1471.9949829101563
INFO:root:current train perplexity3.148292064666748
INFO:root:current mean train loss 1455.0107532848012
INFO:root:current train perplexity3.137040615081787
INFO:root:current mean train loss 1457.538577125186
INFO:root:current train perplexity3.139974355697632
INFO:root:current mean train loss 1455.9794768302672
INFO:root:current train perplexity3.1428184509277344
INFO:root:current mean train loss 1450.9977074599847
INFO:root:current train perplexity3.1393306255340576
INFO:root:current mean train loss 1449.708099006204
INFO:root:current train perplexity3.1424720287323
INFO:root:current mean train loss 1450.5063482565959
INFO:root:current train perplexity3.145251750946045
INFO:root:current mean train loss 1449.4782279860806
INFO:root:current train perplexity3.1438238620758057
INFO:root:current mean train loss 1449.9278098777488
INFO:root:current train perplexity3.142831325531006
INFO:root:current mean train loss 1450.8129177219266
INFO:root:current train perplexity3.1427934169769287
INFO:root:current mean train loss 1449.9268824209082
INFO:root:current train perplexity3.1396336555480957
INFO:root:current mean train loss 1450.2580883129224
INFO:root:current train perplexity3.141216278076172
INFO:root:current mean train loss 1451.3127190203707
INFO:root:current train perplexity3.1432292461395264
INFO:root:current mean train loss 1452.5955471359136
INFO:root:current train perplexity3.1446919441223145
INFO:root:current mean train loss 1452.566202020307
INFO:root:current train perplexity3.145927906036377
INFO:root:current mean train loss 1453.5414634856168
INFO:root:current train perplexity3.14680552482605
INFO:root:current mean train loss 1453.4542234053522
INFO:root:current train perplexity3.145859479904175
INFO:root:current mean train loss 1453.1847691229211
INFO:root:current train perplexity3.1451327800750732
INFO:root:current mean train loss 1451.979280216786
INFO:root:current train perplexity3.1444127559661865
INFO:root:current mean train loss 1452.512313571151
INFO:root:current train perplexity3.1438426971435547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.02s/it]
INFO:root:final mean train loss: 1452.3386023940309
INFO:root:final train perplexity: 3.1437036991119385
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 3461.4472516950545
INFO:root:eval perplexity: 17.122098922729492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:42:09<1:27:35, 328.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1437.22509765625
INFO:root:current train perplexity3.1331257820129395
INFO:root:current mean train loss 1436.9503961998646
INFO:root:current train perplexity3.126018524169922
INFO:root:current mean train loss 1443.5355262252203
INFO:root:current train perplexity3.1343066692352295
INFO:root:current mean train loss 1447.0409424574732
INFO:root:current train perplexity3.1343274116516113
INFO:root:current mean train loss 1446.7751570618962
INFO:root:current train perplexity3.1301419734954834
INFO:root:current mean train loss 1445.748104783118
INFO:root:current train perplexity3.1322991847991943
INFO:root:current mean train loss 1446.679037431781
INFO:root:current train perplexity3.136488914489746
INFO:root:current mean train loss 1446.5050235207832
INFO:root:current train perplexity3.135617256164551
INFO:root:current mean train loss 1446.7298641550785
INFO:root:current train perplexity3.13572096824646
INFO:root:current mean train loss 1448.5622264940248
INFO:root:current train perplexity3.137583017349243
INFO:root:current mean train loss 1448.5403646229536
INFO:root:current train perplexity3.1366169452667236
INFO:root:current mean train loss 1450.0946362283025
INFO:root:current train perplexity3.1388003826141357
INFO:root:current mean train loss 1451.104501439773
INFO:root:current train perplexity3.140084743499756
INFO:root:current mean train loss 1451.4774388857327
INFO:root:current train perplexity3.141037940979004
INFO:root:current mean train loss 1452.659305949435
INFO:root:current train perplexity3.1424076557159424
INFO:root:current mean train loss 1453.361534373465
INFO:root:current train perplexity3.1431198120117188
INFO:root:current mean train loss 1453.3708052679156
INFO:root:current train perplexity3.143038749694824
INFO:root:current mean train loss 1452.7826768160558
INFO:root:current train perplexity3.1424832344055176
INFO:root:current mean train loss 1451.829529576962
INFO:root:current train perplexity3.1412386894226074
INFO:root:current mean train loss 1451.3080568179976
INFO:root:current train perplexity3.140432596206665

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it]
INFO:root:final mean train loss: 1451.2971173246522
INFO:root:final train perplexity: 3.1411221027374268
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.82s/it]
INFO:root:eval mean loss: 3464.262005413617
INFO:root:eval perplexity: 17.161693572998047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:47:39<1:22:12, 328.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1423.0696660822089
INFO:root:current train perplexity3.1194908618927
INFO:root:current mean train loss 1426.34474351671
INFO:root:current train perplexity3.127181053161621
INFO:root:current mean train loss 1442.9093442823066
INFO:root:current train perplexity3.1437013149261475
INFO:root:current mean train loss 1444.0662543718206
INFO:root:current train perplexity3.135887622833252
INFO:root:current mean train loss 1446.5398358869122
INFO:root:current train perplexity3.1380813121795654
INFO:root:current mean train loss 1450.4645605648266
INFO:root:current train perplexity3.141350746154785
INFO:root:current mean train loss 1453.448146654212
INFO:root:current train perplexity3.1414172649383545
INFO:root:current mean train loss 1451.0265461911438
INFO:root:current train perplexity3.1373751163482666
INFO:root:current mean train loss 1452.371277289368
INFO:root:current train perplexity3.1388471126556396
INFO:root:current mean train loss 1451.0879711862337
INFO:root:current train perplexity3.1375513076782227
INFO:root:current mean train loss 1449.7101992318458
INFO:root:current train perplexity3.1385061740875244
INFO:root:current mean train loss 1450.0865501990686
INFO:root:current train perplexity3.1383140087127686
INFO:root:current mean train loss 1449.644803258767
INFO:root:current train perplexity3.13740873336792
INFO:root:current mean train loss 1448.5600855691093
INFO:root:current train perplexity3.1365370750427246
INFO:root:current mean train loss 1449.1440112676646
INFO:root:current train perplexity3.1368062496185303
INFO:root:current mean train loss 1449.51152678969
INFO:root:current train perplexity3.137057065963745
INFO:root:current mean train loss 1450.1143776552522
INFO:root:current train perplexity3.1375913619995117
INFO:root:current mean train loss 1450.0707713135885
INFO:root:current train perplexity3.1366055011749268
INFO:root:current mean train loss 1449.923240280979
INFO:root:current train perplexity3.136587142944336
INFO:root:current mean train loss 1450.0896261081773
INFO:root:current train perplexity3.1360771656036377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it]
INFO:root:final mean train loss: 1449.219167058178
INFO:root:final train perplexity: 3.135979175567627
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 3469.56872228674
INFO:root:eval perplexity: 17.23658561706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:53:08<1:16:44, 328.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1444.524402055584
INFO:root:current train perplexity3.1236701011657715
INFO:root:current mean train loss 1429.9408049968458
INFO:root:current train perplexity3.111093759536743
INFO:root:current mean train loss 1434.4667211072199
INFO:root:current train perplexity3.1123428344726562
INFO:root:current mean train loss 1438.607286278891
INFO:root:current train perplexity3.1186907291412354
INFO:root:current mean train loss 1440.8004534342801
INFO:root:current train perplexity3.127480983734131
INFO:root:current mean train loss 1441.7438338172626
INFO:root:current train perplexity3.1313934326171875
INFO:root:current mean train loss 1441.829793171154
INFO:root:current train perplexity3.1292715072631836
INFO:root:current mean train loss 1443.002058192089
INFO:root:current train perplexity3.130587100982666
INFO:root:current mean train loss 1444.413339718986
INFO:root:current train perplexity3.1313719749450684
INFO:root:current mean train loss 1444.6756552419354
INFO:root:current train perplexity3.1298673152923584
INFO:root:current mean train loss 1445.9884919104545
INFO:root:current train perplexity3.1331534385681152
INFO:root:current mean train loss 1447.040183212714
INFO:root:current train perplexity3.133293867111206
INFO:root:current mean train loss 1446.3538935492666
INFO:root:current train perplexity3.130641222000122
INFO:root:current mean train loss 1446.7904803453343
INFO:root:current train perplexity3.1316134929656982
INFO:root:current mean train loss 1447.5431666860509
INFO:root:current train perplexity3.134162425994873
INFO:root:current mean train loss 1447.9248005428963
INFO:root:current train perplexity3.13394832611084
INFO:root:current mean train loss 1447.516099905695
INFO:root:current train perplexity3.132275104522705
INFO:root:current mean train loss 1447.613475619765
INFO:root:current train perplexity3.132323980331421
INFO:root:current mean train loss 1448.2989265159022
INFO:root:current train perplexity3.13301157951355
INFO:root:current mean train loss 1448.743381747295
INFO:root:current train perplexity3.133870840072632

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it]
INFO:root:final mean train loss: 1448.3545758761484
INFO:root:final train perplexity: 3.1338412761688232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it]
INFO:root:eval mean loss: 3471.737943998686
INFO:root:eval perplexity: 17.267295837402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [7:58:37<1:11:15, 328.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1451.218257023738
INFO:root:current train perplexity3.137403964996338
INFO:root:current mean train loss 1448.4398172785727
INFO:root:current train perplexity3.119727849960327
INFO:root:current mean train loss 1450.3002977988704
INFO:root:current train perplexity3.1220784187316895
INFO:root:current mean train loss 1452.439469594804
INFO:root:current train perplexity3.130871534347534
INFO:root:current mean train loss 1451.8156390968227
INFO:root:current train perplexity3.1297101974487305
INFO:root:current mean train loss 1449.9931575154762
INFO:root:current train perplexity3.12899112701416
INFO:root:current mean train loss 1448.328323949403
INFO:root:current train perplexity3.126802682876587
INFO:root:current mean train loss 1445.6838104326498
INFO:root:current train perplexity3.124619960784912
INFO:root:current mean train loss 1444.7272130318818
INFO:root:current train perplexity3.1229352951049805
INFO:root:current mean train loss 1443.5918235856818
INFO:root:current train perplexity3.1215901374816895
INFO:root:current mean train loss 1444.3617585417512
INFO:root:current train perplexity3.122103214263916
INFO:root:current mean train loss 1445.1725728111073
INFO:root:current train perplexity3.121798038482666
INFO:root:current mean train loss 1445.5908561312538
INFO:root:current train perplexity3.122361183166504
INFO:root:current mean train loss 1444.186800266039
INFO:root:current train perplexity3.121385335922241
INFO:root:current mean train loss 1444.9765316933515
INFO:root:current train perplexity3.1243858337402344
INFO:root:current mean train loss 1445.2829570504348
INFO:root:current train perplexity3.124697685241699
INFO:root:current mean train loss 1446.6774608443832
INFO:root:current train perplexity3.127626895904541
INFO:root:current mean train loss 1446.4483746248638
INFO:root:current train perplexity3.1284842491149902
INFO:root:current mean train loss 1446.6070842641357
INFO:root:current train perplexity3.1288981437683105
INFO:root:current mean train loss 1446.723197913869
INFO:root:current train perplexity3.1289825439453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.36s/it]
INFO:root:final mean train loss: 1446.3587420565036
INFO:root:final train perplexity: 3.1289126873016357
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 3474.5423734281158
INFO:root:eval perplexity: 17.30708122253418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [8:04:05<1:05:44, 328.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1465.52644556949
INFO:root:current train perplexity3.1578094959259033
INFO:root:current mean train loss 1454.458341471354
INFO:root:current train perplexity3.1326568126678467
INFO:root:current mean train loss 1451.7761089777543
INFO:root:current train perplexity3.1334478855133057
INFO:root:current mean train loss 1446.820828594739
INFO:root:current train perplexity3.1255228519439697
INFO:root:current mean train loss 1444.6588595920139
INFO:root:current train perplexity3.119015693664551
INFO:root:current mean train loss 1443.0797705898765
INFO:root:current train perplexity3.11649489402771
INFO:root:current mean train loss 1444.5658881098245
INFO:root:current train perplexity3.1229310035705566
INFO:root:current mean train loss 1446.8506911175805
INFO:root:current train perplexity3.1263020038604736
INFO:root:current mean train loss 1446.661664329827
INFO:root:current train perplexity3.1283490657806396
INFO:root:current mean train loss 1445.5144401205246
INFO:root:current train perplexity3.125275135040283
INFO:root:current mean train loss 1446.1673587328767
INFO:root:current train perplexity3.1260650157928467
INFO:root:current mean train loss 1445.2152718643763
INFO:root:current train perplexity3.1238696575164795
INFO:root:current mean train loss 1444.9399777916867
INFO:root:current train perplexity3.12306547164917
INFO:root:current mean train loss 1443.5416196761594
INFO:root:current train perplexity3.1228928565979004
INFO:root:current mean train loss 1444.1963837792641
INFO:root:current train perplexity3.121750831604004
INFO:root:current mean train loss 1444.222814443941
INFO:root:current train perplexity3.1223020553588867
INFO:root:current mean train loss 1444.473074673903
INFO:root:current train perplexity3.123249053955078
INFO:root:current mean train loss 1445.22562701297
INFO:root:current train perplexity3.1259095668792725
INFO:root:current mean train loss 1445.8528877519996
INFO:root:current train perplexity3.1270911693573

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it]
INFO:root:final mean train loss: 1445.6643183982799
INFO:root:final train perplexity: 3.127199649810791
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it]
INFO:root:eval mean loss: 3472.345172320758
INFO:root:eval perplexity: 17.27590560913086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [8:09:34<1:00:17, 328.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1434.0655008951824
INFO:root:current train perplexity3.108597755432129
INFO:root:current mean train loss 1451.8993573869977
INFO:root:current train perplexity3.134509563446045
INFO:root:current mean train loss 1441.4156540204895
INFO:root:current train perplexity3.119262933731079
INFO:root:current mean train loss 1440.6541939759866
INFO:root:current train perplexity3.119957208633423
INFO:root:current mean train loss 1442.1621881873862
INFO:root:current train perplexity3.1226959228515625
INFO:root:current mean train loss 1441.5606017112732
INFO:root:current train perplexity3.1210827827453613
INFO:root:current mean train loss 1439.813759997
INFO:root:current train perplexity3.1189770698547363
INFO:root:current mean train loss 1439.0494364191977
INFO:root:current train perplexity3.116903781890869
INFO:root:current mean train loss 1437.9974378764337
INFO:root:current train perplexity3.1124372482299805
INFO:root:current mean train loss 1437.9878649795264
INFO:root:current train perplexity3.1120760440826416
INFO:root:current mean train loss 1439.3579657633786
INFO:root:current train perplexity3.1131584644317627
INFO:root:current mean train loss 1439.845786005473
INFO:root:current train perplexity3.116119146347046
INFO:root:current mean train loss 1440.135226007342
INFO:root:current train perplexity3.117455244064331
INFO:root:current mean train loss 1441.595956197599
INFO:root:current train perplexity3.117938280105591
INFO:root:current mean train loss 1443.0015557048678
INFO:root:current train perplexity3.119375228881836
INFO:root:current mean train loss 1442.822625134988
INFO:root:current train perplexity3.119112968444824
INFO:root:current mean train loss 1441.9047392662937
INFO:root:current train perplexity3.118313789367676
INFO:root:current mean train loss 1442.5241955195631
INFO:root:current train perplexity3.119940757751465
INFO:root:current mean train loss 1442.6388037136321
INFO:root:current train perplexity3.1198959350585938
INFO:root:current mean train loss 1443.736975123194
INFO:root:current train perplexity3.121737003326416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.69s/it]
INFO:root:final mean train loss: 1443.7562572269564
INFO:root:final train perplexity: 3.1224966049194336
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.42s/it]
INFO:root:eval mean loss: 3475.069676121434
INFO:root:eval perplexity: 17.314571380615234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:15:03<54:48, 328.83s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1424.3603978650324
INFO:root:current train perplexity3.131671190261841
INFO:root:current mean train loss 1437.9358846974928
INFO:root:current train perplexity3.1120293140411377
INFO:root:current mean train loss 1445.4524080368108
INFO:root:current train perplexity3.1179566383361816
INFO:root:current mean train loss 1447.6300631352108
INFO:root:current train perplexity3.1214993000030518
INFO:root:current mean train loss 1449.1320262988963
INFO:root:current train perplexity3.118460178375244
INFO:root:current mean train loss 1446.722340805544
INFO:root:current train perplexity3.1180830001831055
INFO:root:current mean train loss 1447.5721850857635
INFO:root:current train perplexity3.1216535568237305
INFO:root:current mean train loss 1447.0588738921574
INFO:root:current train perplexity3.117882490158081
INFO:root:current mean train loss 1447.4609573787602
INFO:root:current train perplexity3.120115041732788
INFO:root:current mean train loss 1446.0244894859225
INFO:root:current train perplexity3.1194748878479004
INFO:root:current mean train loss 1446.1918149304922
INFO:root:current train perplexity3.1201040744781494
INFO:root:current mean train loss 1443.7730388523098
INFO:root:current train perplexity3.1174256801605225
INFO:root:current mean train loss 1444.2272718784961
INFO:root:current train perplexity3.118791103363037
INFO:root:current mean train loss 1442.946038033031
INFO:root:current train perplexity3.1180763244628906
INFO:root:current mean train loss 1442.612667652341
INFO:root:current train perplexity3.1195015907287598
INFO:root:current mean train loss 1442.710416884887
INFO:root:current train perplexity3.1200456619262695
INFO:root:current mean train loss 1442.305236853874
INFO:root:current train perplexity3.118896007537842
INFO:root:current mean train loss 1442.8580911083673
INFO:root:current train perplexity3.120173692703247
INFO:root:current mean train loss 1443.6166016425898
INFO:root:current train perplexity3.12076997756958
INFO:root:current mean train loss 1443.1747719076027
INFO:root:current train perplexity3.119755268096924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it]
INFO:root:final mean train loss: 1442.5800126268596
INFO:root:final train perplexity: 3.1196017265319824
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it]
INFO:root:eval mean loss: 3470.549613334037
INFO:root:eval perplexity: 17.250465393066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:20:32<49:19, 328.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1451.3699473505435
INFO:root:current train perplexity3.1515679359436035
INFO:root:current mean train loss 1439.8986231137628
INFO:root:current train perplexity3.1182196140289307
INFO:root:current mean train loss 1442.5743566993776
INFO:root:current train perplexity3.121711015701294
INFO:root:current mean train loss 1439.7950421812907
INFO:root:current train perplexity3.114981174468994
INFO:root:current mean train loss 1440.807527140117
INFO:root:current train perplexity3.119490385055542
INFO:root:current mean train loss 1441.2442946661085
INFO:root:current train perplexity3.1197731494903564
INFO:root:current mean train loss 1440.942270190354
INFO:root:current train perplexity3.118408441543579
INFO:root:current mean train loss 1439.2926246295347
INFO:root:current train perplexity3.1157631874084473
INFO:root:current mean train loss 1438.0524899457928
INFO:root:current train perplexity3.1154463291168213
INFO:root:current mean train loss 1439.2345302331776
INFO:root:current train perplexity3.1166043281555176
INFO:root:current mean train loss 1441.039188304777
INFO:root:current train perplexity3.119450330734253
INFO:root:current mean train loss 1441.4900821599244
INFO:root:current train perplexity3.1198720932006836
INFO:root:current mean train loss 1441.5195878765173
INFO:root:current train perplexity3.117645740509033
INFO:root:current mean train loss 1441.696695449625
INFO:root:current train perplexity3.1191587448120117
INFO:root:current mean train loss 1442.0808187355474
INFO:root:current train perplexity3.118273973464966
INFO:root:current mean train loss 1442.2972403423908
INFO:root:current train perplexity3.1187286376953125
INFO:root:current mean train loss 1441.8296214366742
INFO:root:current train perplexity3.1183013916015625
INFO:root:current mean train loss 1442.137509550289
INFO:root:current train perplexity3.1189959049224854
INFO:root:current mean train loss 1441.9685657042464
INFO:root:current train perplexity3.1180579662323
INFO:root:current mean train loss 1441.7654741371523
INFO:root:current train perplexity3.117215156555176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.92s/it]
INFO:root:final mean train loss: 1441.621834728493
INFO:root:final train perplexity: 3.1172451972961426
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it]
INFO:root:eval mean loss: 3471.532546951248
INFO:root:eval perplexity: 17.264381408691406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [8:26:01<43:50, 328.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1435.7970396980406
INFO:root:current train perplexity3.1019608974456787
INFO:root:current mean train loss 1437.307470403566
INFO:root:current train perplexity3.0942304134368896
INFO:root:current mean train loss 1440.2195826773407
INFO:root:current train perplexity3.1139798164367676
INFO:root:current mean train loss 1438.1994817224088
INFO:root:current train perplexity3.114898681640625
INFO:root:current mean train loss 1443.99155104701
INFO:root:current train perplexity3.1220693588256836
INFO:root:current mean train loss 1444.2252474796708
INFO:root:current train perplexity3.1224117279052734
INFO:root:current mean train loss 1444.1902608511855
INFO:root:current train perplexity3.1216180324554443
INFO:root:current mean train loss 1445.4626890409977
INFO:root:current train perplexity3.1203010082244873
INFO:root:current mean train loss 1445.3704309209336
INFO:root:current train perplexity3.1226184368133545
INFO:root:current mean train loss 1445.6724923233871
INFO:root:current train perplexity3.1235647201538086
INFO:root:current mean train loss 1445.533129285667
INFO:root:current train perplexity3.1234631538391113
INFO:root:current mean train loss 1443.6237400412458
INFO:root:current train perplexity3.119839668273926
INFO:root:current mean train loss 1442.4151135804818
INFO:root:current train perplexity3.1170716285705566
INFO:root:current mean train loss 1441.9575829397468
INFO:root:current train perplexity3.115119218826294
INFO:root:current mean train loss 1440.7512192012346
INFO:root:current train perplexity3.1142032146453857
INFO:root:current mean train loss 1440.9971432579075
INFO:root:current train perplexity3.114952802658081
INFO:root:current mean train loss 1440.4681269496016
INFO:root:current train perplexity3.113332748413086
INFO:root:current mean train loss 1440.1202221555056
INFO:root:current train perplexity3.1128017902374268
INFO:root:current mean train loss 1439.6853729755853
INFO:root:current train perplexity3.1114869117736816
INFO:root:current mean train loss 1440.7977015086722
INFO:root:current train perplexity3.113898515701294

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.04s/it]
INFO:root:final mean train loss: 1440.3336172406864
INFO:root:final train perplexity: 3.1140799522399902
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 3474.088820998733
INFO:root:eval perplexity: 17.300640106201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [8:31:29<38:20, 328.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1426.2636978149415
INFO:root:current train perplexity3.0971617698669434
INFO:root:current mean train loss 1433.923043484158
INFO:root:current train perplexity3.0938284397125244
INFO:root:current mean train loss 1439.6948054722377
INFO:root:current train perplexity3.101836919784546
INFO:root:current mean train loss 1440.5677336040296
INFO:root:current train perplexity3.1144115924835205
INFO:root:current mean train loss 1439.3933512369792
INFO:root:current train perplexity3.112016201019287
INFO:root:current mean train loss 1439.6430085280847
INFO:root:current train perplexity3.113328695297241
INFO:root:current mean train loss 1440.0965380500345
INFO:root:current train perplexity3.114321231842041
INFO:root:current mean train loss 1439.5373794946915
INFO:root:current train perplexity3.1144678592681885
INFO:root:current mean train loss 1438.5800616177646
INFO:root:current train perplexity3.1115024089813232
INFO:root:current mean train loss 1438.2558373276067
INFO:root:current train perplexity3.111114263534546
INFO:root:current mean train loss 1438.4909308539497
INFO:root:current train perplexity3.111571788787842
INFO:root:current mean train loss 1437.6717016187765
INFO:root:current train perplexity3.110826015472412
INFO:root:current mean train loss 1438.7631149291992
INFO:root:current train perplexity3.1127610206604004
INFO:root:current mean train loss 1439.4623160984206
INFO:root:current train perplexity3.1125450134277344
INFO:root:current mean train loss 1441.172455328864
INFO:root:current train perplexity3.114506483078003
INFO:root:current mean train loss 1441.3749334021459
INFO:root:current train perplexity3.114447593688965
INFO:root:current mean train loss 1440.7946315947033
INFO:root:current train perplexity3.1142656803131104
INFO:root:current mean train loss 1441.0994041871488
INFO:root:current train perplexity3.1142590045928955
INFO:root:current mean train loss 1440.3112888417345
INFO:root:current train perplexity3.113039970397949
INFO:root:current mean train loss 1440.320844122376
INFO:root:current train perplexity3.1131653785705566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.88s/it]
INFO:root:final mean train loss: 1439.9122008200072
INFO:root:final train perplexity: 3.1130452156066895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it]
INFO:root:eval mean loss: 3476.1984907270553
INFO:root:eval perplexity: 17.330615997314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [8:36:58<32:52, 328.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.1755459185729
INFO:root:current train perplexity3.13747239112854
INFO:root:current mean train loss 1445.7614547806947
INFO:root:current train perplexity3.1318838596343994
INFO:root:current mean train loss 1444.0109842730692
INFO:root:current train perplexity3.1180081367492676
INFO:root:current mean train loss 1442.1540244460407
INFO:root:current train perplexity3.118366241455078
INFO:root:current mean train loss 1442.0059318312217
INFO:root:current train perplexity3.1166412830352783
INFO:root:current mean train loss 1443.6142066942787
INFO:root:current train perplexity3.113950490951538
INFO:root:current mean train loss 1442.2837117221127
INFO:root:current train perplexity3.11063551902771
INFO:root:current mean train loss 1440.537488911053
INFO:root:current train perplexity3.1105496883392334
INFO:root:current mean train loss 1440.6284767584657
INFO:root:current train perplexity3.109713077545166
INFO:root:current mean train loss 1441.1731373319176
INFO:root:current train perplexity3.1120073795318604
INFO:root:current mean train loss 1441.5006431781278
INFO:root:current train perplexity3.1139345169067383
INFO:root:current mean train loss 1441.3464231052892
INFO:root:current train perplexity3.1143579483032227
INFO:root:current mean train loss 1441.3647693407563
INFO:root:current train perplexity3.115083932876587
INFO:root:current mean train loss 1441.2182389124855
INFO:root:current train perplexity3.113734006881714
INFO:root:current mean train loss 1440.7534214751117
INFO:root:current train perplexity3.113206624984741
INFO:root:current mean train loss 1440.67624102015
INFO:root:current train perplexity3.1128931045532227
INFO:root:current mean train loss 1440.1356405461613
INFO:root:current train perplexity3.11240553855896
INFO:root:current mean train loss 1440.0516046981513
INFO:root:current train perplexity3.1128804683685303
INFO:root:current mean train loss 1440.1654999953669
INFO:root:current train perplexity3.113424777984619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.34s/it]
INFO:root:final mean train loss: 1439.1282396648367
INFO:root:final train perplexity: 3.1111204624176025
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 3473.6170012786224
INFO:root:eval perplexity: 17.293943405151367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [8:42:26<27:23, 328.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.2328404017858
INFO:root:current train perplexity3.0615360736846924
INFO:root:current mean train loss 1428.2339327628151
INFO:root:current train perplexity3.0820066928863525
INFO:root:current mean train loss 1432.6624430718823
INFO:root:current train perplexity3.0832505226135254
INFO:root:current mean train loss 1432.015316714147
INFO:root:current train perplexity3.0860702991485596
INFO:root:current mean train loss 1431.4761744697312
INFO:root:current train perplexity3.0867233276367188
INFO:root:current mean train loss 1434.3290132158925
INFO:root:current train perplexity3.094425678253174
INFO:root:current mean train loss 1435.4302280686966
INFO:root:current train perplexity3.1007063388824463
INFO:root:current mean train loss 1437.5620522378874
INFO:root:current train perplexity3.1017215251922607
INFO:root:current mean train loss 1437.417366496468
INFO:root:current train perplexity3.1030263900756836
INFO:root:current mean train loss 1437.4293297030993
INFO:root:current train perplexity3.1023926734924316
INFO:root:current mean train loss 1437.3050735744498
INFO:root:current train perplexity3.1007800102233887
INFO:root:current mean train loss 1438.4865939621438
INFO:root:current train perplexity3.103097677230835
INFO:root:current mean train loss 1438.622842452475
INFO:root:current train perplexity3.1044564247131348
INFO:root:current mean train loss 1437.8749277239701
INFO:root:current train perplexity3.1041128635406494
INFO:root:current mean train loss 1437.9353246621397
INFO:root:current train perplexity3.1057918071746826
INFO:root:current mean train loss 1439.0995341493715
INFO:root:current train perplexity3.1068031787872314
INFO:root:current mean train loss 1438.9108902601504
INFO:root:current train perplexity3.1077051162719727
INFO:root:current mean train loss 1439.1865324111636
INFO:root:current train perplexity3.107733726501465
INFO:root:current mean train loss 1439.4373168272377
INFO:root:current train perplexity3.107794761657715
INFO:root:current mean train loss 1439.4850844619416
INFO:root:current train perplexity3.10862135887146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.66s/it]
INFO:root:final mean train loss: 1437.9650920765964
INFO:root:final train perplexity: 3.1082687377929688
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.78s/it]
INFO:root:eval mean loss: 3477.0733228345534
INFO:root:eval perplexity: 17.34305763244629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:47:54<21:53, 328.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1466.0279068485384
INFO:root:current train perplexity3.175509214401245
INFO:root:current mean train loss 1447.7707733853172
INFO:root:current train perplexity3.146361827850342
INFO:root:current mean train loss 1443.6015001437365
INFO:root:current train perplexity3.1292965412139893
INFO:root:current mean train loss 1441.7027779662717
INFO:root:current train perplexity3.118053913116455
INFO:root:current mean train loss 1444.62800559201
INFO:root:current train perplexity3.1199028491973877
INFO:root:current mean train loss 1443.1156350690767
INFO:root:current train perplexity3.116227865219116
INFO:root:current mean train loss 1442.0477449686139
INFO:root:current train perplexity3.1127750873565674
INFO:root:current mean train loss 1442.0481571557584
INFO:root:current train perplexity3.112605094909668
INFO:root:current mean train loss 1441.192202571497
INFO:root:current train perplexity3.111830472946167
INFO:root:current mean train loss 1439.8095575941109
INFO:root:current train perplexity3.1099913120269775
INFO:root:current mean train loss 1438.4738706779294
INFO:root:current train perplexity3.1082656383514404
INFO:root:current mean train loss 1438.4457091475672
INFO:root:current train perplexity3.1081433296203613
INFO:root:current mean train loss 1438.7670412536174
INFO:root:current train perplexity3.1082494258880615
INFO:root:current mean train loss 1438.5389519855548
INFO:root:current train perplexity3.107285499572754
INFO:root:current mean train loss 1436.987000919238
INFO:root:current train perplexity3.1063640117645264
INFO:root:current mean train loss 1436.7160536892502
INFO:root:current train perplexity3.106787919998169
INFO:root:current mean train loss 1438.4136534783827
INFO:root:current train perplexity3.1095614433288574
INFO:root:current mean train loss 1438.5094448290142
INFO:root:current train perplexity3.1086995601654053
INFO:root:current mean train loss 1438.0046931401685
INFO:root:current train perplexity3.1083290576934814
INFO:root:current mean train loss 1437.9253419612369
INFO:root:current train perplexity3.1076362133026123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.43s/it]
INFO:root:final mean train loss: 1437.3976465976425
INFO:root:final train perplexity: 3.1068780422210693
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.53s/it]
INFO:root:eval mean loss: 3476.962051895646
INFO:root:eval perplexity: 17.341474533081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:53:23<16:25, 328.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1440.7837549845378
INFO:root:current train perplexity3.1212918758392334
INFO:root:current mean train loss 1436.5286065178948
INFO:root:current train perplexity3.122680187225342
INFO:root:current mean train loss 1438.9922239242062
INFO:root:current train perplexity3.1233904361724854
INFO:root:current mean train loss 1437.5045864061378
INFO:root:current train perplexity3.113405466079712
INFO:root:current mean train loss 1440.6823763166155
INFO:root:current train perplexity3.115154981613159
INFO:root:current mean train loss 1441.6468354385265
INFO:root:current train perplexity3.110128879547119
INFO:root:current mean train loss 1443.4947202706044
INFO:root:current train perplexity3.112598419189453
INFO:root:current mean train loss 1442.485836579838
INFO:root:current train perplexity3.1094720363616943
INFO:root:current mean train loss 1440.10419579272
INFO:root:current train perplexity3.1086244583129883
INFO:root:current mean train loss 1440.1571086127044
INFO:root:current train perplexity3.108968734741211
INFO:root:current mean train loss 1439.7640609158814
INFO:root:current train perplexity3.109127998352051
INFO:root:current mean train loss 1437.7150557780515
INFO:root:current train perplexity3.1079299449920654
INFO:root:current mean train loss 1438.606286562406
INFO:root:current train perplexity3.1082446575164795
INFO:root:current mean train loss 1439.141284161576
INFO:root:current train perplexity3.1080870628356934
INFO:root:current mean train loss 1438.8792133647435
INFO:root:current train perplexity3.1080963611602783
INFO:root:current mean train loss 1438.0301667442618
INFO:root:current train perplexity3.1064672470092773
INFO:root:current mean train loss 1438.2296973663626
INFO:root:current train perplexity3.1062638759613037
INFO:root:current mean train loss 1437.9972929441683
INFO:root:current train perplexity3.1059629917144775
INFO:root:current mean train loss 1437.3050079345703
INFO:root:current train perplexity3.106062889099121
INFO:root:current mean train loss 1436.9760013400162
INFO:root:current train perplexity3.1058132648468018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.90s/it]
INFO:root:final mean train loss: 1436.9659397358012
INFO:root:final train perplexity: 3.1058197021484375
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.41s/it]
INFO:root:eval mean loss: 3478.0856523026932
INFO:root:eval perplexity: 17.35746955871582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [8:58:51<10:57, 328.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1443.5758826622596
INFO:root:current train perplexity3.100027322769165
INFO:root:current mean train loss 1435.6705884528883
INFO:root:current train perplexity3.1052639484405518
INFO:root:current mean train loss 1435.8069349756781
INFO:root:current train perplexity3.109126091003418
INFO:root:current mean train loss 1434.3464773517765
INFO:root:current train perplexity3.1071584224700928
INFO:root:current mean train loss 1437.1712147702453
INFO:root:current train perplexity3.1082568168640137
INFO:root:current mean train loss 1439.4747759523646
INFO:root:current train perplexity3.1060636043548584
INFO:root:current mean train loss 1438.5263950892856
INFO:root:current train perplexity3.102389097213745
INFO:root:current mean train loss 1439.6474891812193
INFO:root:current train perplexity3.1041576862335205
INFO:root:current mean train loss 1439.5815030312951
INFO:root:current train perplexity3.105046272277832
INFO:root:current mean train loss 1439.100410105651
INFO:root:current train perplexity3.1045074462890625
INFO:root:current mean train loss 1438.7325930026775
INFO:root:current train perplexity3.1030921936035156
INFO:root:current mean train loss 1438.4178479370642
INFO:root:current train perplexity3.10491681098938
INFO:root:current mean train loss 1438.1554097895566
INFO:root:current train perplexity3.104649543762207
INFO:root:current mean train loss 1438.20665403932
INFO:root:current train perplexity3.1051907539367676
INFO:root:current mean train loss 1436.9245454651505
INFO:root:current train perplexity3.1033599376678467
INFO:root:current mean train loss 1436.6521173154204
INFO:root:current train perplexity3.1032979488372803
INFO:root:current mean train loss 1436.527115958732
INFO:root:current train perplexity3.102858066558838
INFO:root:current mean train loss 1436.9375562975831
INFO:root:current train perplexity3.1033935546875
INFO:root:current mean train loss 1436.3269863752514
INFO:root:current train perplexity3.102447032928467
INFO:root:current mean train loss 1436.6550845235965
INFO:root:current train perplexity3.103717803955078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.11s/it]
INFO:root:final mean train loss: 1436.1817926742547
INFO:root:final train perplexity: 3.1038997173309326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 3478.0306796053865
INFO:root:eval perplexity: 17.356693267822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [9:04:20<05:28, 328.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.7797077458079
INFO:root:current train perplexity3.0790109634399414
INFO:root:current mean train loss 1426.9601634937328
INFO:root:current train perplexity3.0817110538482666
INFO:root:current mean train loss 1431.717517609292
INFO:root:current train perplexity3.0903127193450928
INFO:root:current mean train loss 1432.6741310638906
INFO:root:current train perplexity3.088420867919922
INFO:root:current mean train loss 1434.5324165059324
INFO:root:current train perplexity3.0922937393188477
INFO:root:current mean train loss 1434.7616407256764
INFO:root:current train perplexity3.0971474647521973
INFO:root:current mean train loss 1436.2874297648232
INFO:root:current train perplexity3.1006417274475098
INFO:root:current mean train loss 1436.907798357327
INFO:root:current train perplexity3.1021416187286377
INFO:root:current mean train loss 1436.2780220568045
INFO:root:current train perplexity3.1015148162841797
INFO:root:current mean train loss 1436.884365850942
INFO:root:current train perplexity3.1027374267578125
INFO:root:current mean train loss 1436.772999761726
INFO:root:current train perplexity3.1025350093841553
INFO:root:current mean train loss 1436.7650093814443
INFO:root:current train perplexity3.1020021438598633
INFO:root:current mean train loss 1436.5946447696774
INFO:root:current train perplexity3.101675033569336
INFO:root:current mean train loss 1436.575700994511
INFO:root:current train perplexity3.101785182952881
INFO:root:current mean train loss 1438.1833971360757
INFO:root:current train perplexity3.1042368412017822
INFO:root:current mean train loss 1436.4168476630402
INFO:root:current train perplexity3.1020684242248535
INFO:root:current mean train loss 1435.2598448763563
INFO:root:current train perplexity3.101148843765259
INFO:root:current mean train loss 1435.04512676406
INFO:root:current train perplexity3.100886344909668
INFO:root:current mean train loss 1436.0440445513832
INFO:root:current train perplexity3.103102445602417
INFO:root:current mean train loss 1436.687033336651
INFO:root:current train perplexity3.1041758060455322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.46s/it]
INFO:root:final mean train loss: 1436.2496319730897
INFO:root:final train perplexity: 3.1040663719177246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 3478.140335403763
INFO:root:eval perplexity: 17.358251571655273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_23/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:09:48<00:00, 328.38s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:09:48<00:00, 329.88s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
INFO:root:eval mean loss: 3478.140335403763
INFO:root:eval perplexity: 17.358251571655273
INFO:root:evalaution complete
INFO:root:save model final: pld_23/final
