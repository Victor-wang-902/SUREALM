INFO:root:Output: small_multiqa_multiqa_corrected
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24473.13034643308
INFO:root:current train perplexity15612.4912109375
INFO:root:current mean train loss 20569.34851012877
INFO:root:current train perplexity3316.3525390625
INFO:root:current mean train loss 17773.96808045046
INFO:root:current train perplexity1104.886962890625
INFO:root:current mean train loss 15876.720884241855
INFO:root:current train perplexity518.565185546875
INFO:root:current mean train loss 14500.221009401615
INFO:root:current train perplexity301.40936279296875
INFO:root:current mean train loss 13455.143169116496
INFO:root:current train perplexity200.27743530273438
INFO:root:current mean train loss 12642.934285307136
INFO:root:current train perplexity145.3921356201172
INFO:root:current mean train loss 11990.218735944345
INFO:root:current train perplexity112.67701721191406
INFO:root:current mean train loss 11456.161507577865
INFO:root:current train perplexity91.33072662353516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.14s/it]
INFO:root:final mean train loss: 11025.722538855767
INFO:root:final train perplexity: 77.475830078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it]
INFO:root:eval mean loss: 6416.15554701352
INFO:root:eval perplexity: 13.389955520629883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 6923.081446005098
INFO:root:eval perplexity: 16.961450576782227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/1
  0%|          | 1/200 [06:50<22:42:09, 410.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6816.836844308035
INFO:root:current train perplexity14.85766887664795
INFO:root:current mean train loss 6833.854405483353
INFO:root:current train perplexity14.465503692626953
INFO:root:current mean train loss 6736.868501377567
INFO:root:current train perplexity14.119361877441406
INFO:root:current mean train loss 6651.7965457680175
INFO:root:current train perplexity13.751811027526855
INFO:root:current mean train loss 6585.77601447328
INFO:root:current train perplexity13.446378707885742
INFO:root:current mean train loss 6534.874885393553
INFO:root:current train perplexity13.13640308380127
INFO:root:current mean train loss 6483.833214547724
INFO:root:current train perplexity12.866458892822266
INFO:root:current mean train loss 6439.072603347109
INFO:root:current train perplexity12.640533447265625
INFO:root:current mean train loss 6394.080654744617
INFO:root:current train perplexity12.43346881866455
INFO:root:current mean train loss 6350.05146495142
INFO:root:current train perplexity12.231647491455078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.87s/it]
INFO:root:final mean train loss: 6316.709288074124
INFO:root:final train perplexity: 12.086928367614746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 5545.055400875443
INFO:root:eval perplexity: 9.41456127166748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it]
INFO:root:eval mean loss: 6162.520788314495
INFO:root:eval perplexity: 12.427844047546387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/2
  1%|          | 2/200 [13:53<22:58:11, 417.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5923.146549479166
INFO:root:current train perplexity10.413890838623047
INFO:root:current mean train loss 5834.703371263587
INFO:root:current train perplexity10.146629333496094
INFO:root:current mean train loss 5841.968468386628
INFO:root:current train perplexity10.079606056213379
INFO:root:current mean train loss 5819.5059105282735
INFO:root:current train perplexity9.976839065551758
INFO:root:current mean train loss 5807.060536285768
INFO:root:current train perplexity9.899453163146973
INFO:root:current mean train loss 5798.578856947815
INFO:root:current train perplexity9.83259105682373
INFO:root:current mean train loss 5772.571212049034
INFO:root:current train perplexity9.735288619995117
INFO:root:current mean train loss 5748.037185178103
INFO:root:current train perplexity9.654414176940918
INFO:root:current mean train loss 5735.587253163343
INFO:root:current train perplexity9.595519065856934
INFO:root:current mean train loss 5716.3523101306355
INFO:root:current train perplexity9.516312599182129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.46s/it]
INFO:root:final mean train loss: 5696.899228742046
INFO:root:final train perplexity: 9.464909553527832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 29.00s/it]
INFO:root:eval mean loss: 5184.726101922651
INFO:root:eval perplexity: 8.138052940368652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 5861.15192819149
INFO:root:eval perplexity: 10.986924171447754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/3
  2%|â–         | 3/200 [20:51<22:52:01, 417.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5596.09814453125
INFO:root:current train perplexity8.78962516784668
INFO:root:current mean train loss 5496.207559228913
INFO:root:current train perplexity8.715185165405273
INFO:root:current mean train loss 5486.905242783072
INFO:root:current train perplexity8.70369815826416
INFO:root:current mean train loss 5463.746816345782
INFO:root:current train perplexity8.623400688171387
INFO:root:current mean train loss 5458.470966312057
INFO:root:current train perplexity8.575457572937012
INFO:root:current mean train loss 5439.761396652426
INFO:root:current train perplexity8.523280143737793
INFO:root:current mean train loss 5431.608790316513
INFO:root:current train perplexity8.487228393554688
INFO:root:current mean train loss 5418.373462217972
INFO:root:current train perplexity8.451826095581055
INFO:root:current mean train loss 5401.2381970022025
INFO:root:current train perplexity8.418375015258789
INFO:root:current mean train loss 5389.164378851232
INFO:root:current train perplexity8.371865272521973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.37s/it]
INFO:root:final mean train loss: 5377.3851282673495
INFO:root:final train perplexity: 8.343928337097168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 4966.580878075133
INFO:root:eval perplexity: 7.450933933258057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 5674.56211214539
INFO:root:eval perplexity: 10.179810523986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/4
  2%|â–         | 4/200 [27:47<22:43:14, 417.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5210.401146673387
INFO:root:current train perplexity7.882821083068848
INFO:root:current mean train loss 5225.776173365935
INFO:root:current train perplexity7.87245512008667
INFO:root:current mean train loss 5216.3001809388525
INFO:root:current train perplexity7.855062007904053
INFO:root:current mean train loss 5220.156859245185
INFO:root:current train perplexity7.84122896194458
INFO:root:current mean train loss 5220.4891445221865
INFO:root:current train perplexity7.824425220489502
INFO:root:current mean train loss 5201.764601540431
INFO:root:current train perplexity7.781823635101318
INFO:root:current mean train loss 5194.926492391789
INFO:root:current train perplexity7.762544631958008
INFO:root:current mean train loss 5193.575003607002
INFO:root:current train perplexity7.748438358306885
INFO:root:current mean train loss 5180.907706617591
INFO:root:current train perplexity7.713483810424805
INFO:root:current mean train loss 5174.71077071865
INFO:root:current train perplexity7.695216178894043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.77s/it]
INFO:root:final mean train loss: 5168.476060067454
INFO:root:final train perplexity: 7.6837944984436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 4813.342153562721
INFO:root:eval perplexity: 7.003249645233154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 5544.702629792775
INFO:root:eval perplexity: 9.653350830078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/5
  2%|â–Ž         | 5/200 [34:45<22:36:37, 417.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5157.838203625802
INFO:root:current train perplexity7.5299272537231445
INFO:root:current mean train loss 5077.801691069019
INFO:root:current train perplexity7.381450176239014
INFO:root:current mean train loss 5076.441291841004
INFO:root:current train perplexity7.366631507873535
INFO:root:current mean train loss 5061.152610216169
INFO:root:current train perplexity7.346261501312256
INFO:root:current mean train loss 5053.371469693195
INFO:root:current train perplexity7.332942962646484
INFO:root:current mean train loss 5047.447195870535
INFO:root:current train perplexity7.310326099395752
INFO:root:current mean train loss 5040.129898859302
INFO:root:current train perplexity7.29456090927124
INFO:root:current mean train loss 5032.170751754906
INFO:root:current train perplexity7.276309490203857
INFO:root:current mean train loss 5026.9461656827325
INFO:root:current train perplexity7.262327194213867
INFO:root:current mean train loss 5017.689145804214
INFO:root:current train perplexity7.235903263092041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.22s/it]
INFO:root:final mean train loss: 5016.320901316981
INFO:root:final train perplexity: 7.236110210418701
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 4702.968320589539
INFO:root:eval perplexity: 6.697554588317871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 5453.65880568484
INFO:root:eval perplexity: 9.300573348999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/6
  3%|â–Ž         | 6/200 [41:43<22:29:59, 417.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4965.956345578457
INFO:root:current train perplexity7.022770881652832
INFO:root:current mean train loss 4911.464940077593
INFO:root:current train perplexity6.951120376586914
INFO:root:current mean train loss 4914.121504934211
INFO:root:current train perplexity6.959677219390869
INFO:root:current mean train loss 4930.22426884456
INFO:root:current train perplexity6.963949680328369
INFO:root:current mean train loss 4931.205513973364
INFO:root:current train perplexity6.970341682434082
INFO:root:current mean train loss 4919.8020952353745
INFO:root:current train perplexity6.949569225311279
INFO:root:current mean train loss 4909.904098392823
INFO:root:current train perplexity6.936582088470459
INFO:root:current mean train loss 4909.655385212726
INFO:root:current train perplexity6.926889419555664
INFO:root:current mean train loss 4905.581310069547
INFO:root:current train perplexity6.916085720062256
INFO:root:current mean train loss 4898.6991249092525
INFO:root:current train perplexity6.897491931915283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.58s/it]
INFO:root:final mean train loss: 4895.204310078775
INFO:root:final train perplexity: 6.898470401763916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.44s/it]
INFO:root:eval mean loss: 4613.383406402371
INFO:root:eval perplexity: 6.459272861480713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 5373.267623143839
INFO:root:eval perplexity: 8.999805450439453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/7
  4%|â–Ž         | 7/200 [48:52<22:35:47, 421.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4819.862801846591
INFO:root:current train perplexity6.6773786544799805
INFO:root:current mean train loss 4819.21529422883
INFO:root:current train perplexity6.705323696136475
INFO:root:current mean train loss 4811.980778952206
INFO:root:current train perplexity6.696582794189453
INFO:root:current mean train loss 4808.533454830545
INFO:root:current train perplexity6.6867218017578125
INFO:root:current mean train loss 4808.9058411315245
INFO:root:current train perplexity6.676535129547119
INFO:root:current mean train loss 4803.376582735079
INFO:root:current train perplexity6.665304660797119
INFO:root:current mean train loss 4802.571112386689
INFO:root:current train perplexity6.6605987548828125
INFO:root:current mean train loss 4800.284345897144
INFO:root:current train perplexity6.649421215057373
INFO:root:current mean train loss 4805.076646450109
INFO:root:current train perplexity6.652238368988037
INFO:root:current mean train loss 4800.893019878927
INFO:root:current train perplexity6.640267372131348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.73s/it]
INFO:root:final mean train loss: 4798.424836927845
INFO:root:final train perplexity: 6.640035629272461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it]
INFO:root:eval mean loss: 4542.300118087876
INFO:root:eval perplexity: 6.276250839233398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it]
INFO:root:eval mean loss: 5311.982160419437
INFO:root:eval perplexity: 8.777069091796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/8
  4%|â–         | 8/200 [55:45<22:20:12, 418.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4743.617590525793
INFO:root:current train perplexity6.440133571624756
INFO:root:current mean train loss 4749.0089148773
INFO:root:current train perplexity6.471606254577637
INFO:root:current mean train loss 4749.034911181084
INFO:root:current train perplexity6.467934608459473
INFO:root:current mean train loss 4748.475540203168
INFO:root:current train perplexity6.476339817047119
INFO:root:current mean train loss 4744.1866985016195
INFO:root:current train perplexity6.459918975830078
INFO:root:current mean train loss 4734.162553424733
INFO:root:current train perplexity6.451803684234619
INFO:root:current mean train loss 4732.015194163603
INFO:root:current train perplexity6.455422401428223
INFO:root:current mean train loss 4727.278143686517
INFO:root:current train perplexity6.445070743560791
INFO:root:current mean train loss 4722.888843876738
INFO:root:current train perplexity6.437506198883057
INFO:root:current mean train loss 4720.283818673741
INFO:root:current train perplexity6.431004524230957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.22s/it]
INFO:root:final mean train loss: 4716.689032769972
INFO:root:final train perplexity: 6.4293293952941895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it]
INFO:root:eval mean loss: 4484.183536610705
INFO:root:eval perplexity: 6.130474090576172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 5265.4300164838205
INFO:root:eval perplexity: 8.611572265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/9
  4%|â–         | 9/200 [1:02:39<22:08:18, 417.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4670.762454610475
INFO:root:current train perplexity6.306809902191162
INFO:root:current mean train loss 4662.618162634777
INFO:root:current train perplexity6.286007404327393
INFO:root:current mean train loss 4656.908326546644
INFO:root:current train perplexity6.2941999435424805
INFO:root:current mean train loss 4645.747346698113
INFO:root:current train perplexity6.274579048156738
INFO:root:current mean train loss 4656.59222917496
INFO:root:current train perplexity6.2783522605896
INFO:root:current mean train loss 4646.026775941331
INFO:root:current train perplexity6.266669273376465
INFO:root:current mean train loss 4643.812446878493
INFO:root:current train perplexity6.264902114868164
INFO:root:current mean train loss 4644.293868682109
INFO:root:current train perplexity6.2521514892578125
INFO:root:current mean train loss 4647.312147944173
INFO:root:current train perplexity6.254600524902344
INFO:root:current mean train loss 4648.830037392991
INFO:root:current train perplexity6.252655029296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.55s/it]
INFO:root:final mean train loss: 4646.60820856402
INFO:root:final train perplexity: 6.253999710083008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.78s/it]
INFO:root:eval mean loss: 4432.528483072917
INFO:root:eval perplexity: 6.003750801086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 5217.724571282137
INFO:root:eval perplexity: 8.445208549499512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/10
  5%|â–Œ         | 10/200 [1:09:34<21:58:39, 416.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4604.651753485958
INFO:root:current train perplexity6.099435806274414
INFO:root:current mean train loss 4597.460607432787
INFO:root:current train perplexity6.110591888427734
INFO:root:current mean train loss 4592.983716957885
INFO:root:current train perplexity6.117255210876465
INFO:root:current mean train loss 4594.071575074208
INFO:root:current train perplexity6.110757350921631
INFO:root:current mean train loss 4596.983121167145
INFO:root:current train perplexity6.114994049072266
INFO:root:current mean train loss 4595.805288785891
INFO:root:current train perplexity6.112141132354736
INFO:root:current mean train loss 4595.249377603208
INFO:root:current train perplexity6.115379810333252
INFO:root:current mean train loss 4592.67096957989
INFO:root:current train perplexity6.110843181610107
INFO:root:current mean train loss 4591.118910927279
INFO:root:current train perplexity6.1074066162109375
INFO:root:current mean train loss 4587.55822367371
INFO:root:current train perplexity6.101115703582764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.76s/it]
INFO:root:final mean train loss: 4585.014354705811
INFO:root:final train perplexity: 6.103856086730957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 4390.538832211325
INFO:root:eval perplexity: 5.9026713371276855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 5182.925639267509
INFO:root:eval perplexity: 8.325888633728027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/11
  6%|â–Œ         | 11/200 [1:16:27<21:48:12, 415.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4530.779162176724
INFO:root:current train perplexity6.0178351402282715
INFO:root:current mean train loss 4542.771104455632
INFO:root:current train perplexity6.021348476409912
INFO:root:current mean train loss 4539.507854182546
INFO:root:current train perplexity6.006958484649658
INFO:root:current mean train loss 4534.007652263001
INFO:root:current train perplexity5.994132041931152
INFO:root:current mean train loss 4533.261728274993
INFO:root:current train perplexity5.988435745239258
INFO:root:current mean train loss 4538.709255965849
INFO:root:current train perplexity5.985452175140381
INFO:root:current mean train loss 4539.647109474504
INFO:root:current train perplexity5.989527702331543
INFO:root:current mean train loss 4540.318816014136
INFO:root:current train perplexity5.991566181182861
INFO:root:current mean train loss 4537.566180825906
INFO:root:current train perplexity5.984086036682129
INFO:root:current mean train loss 4535.8840520022
INFO:root:current train perplexity5.978015422821045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.73s/it]
INFO:root:final mean train loss: 4532.0983909483875
INFO:root:final train perplexity: 5.977749347686768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 4352.621743060173
INFO:root:eval perplexity: 5.812858581542969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 5153.194713403147
INFO:root:eval perplexity: 8.2252779006958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/12
  6%|â–Œ         | 12/200 [1:23:15<21:34:40, 413.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4480.0347270764805
INFO:root:current train perplexity5.8881001472473145
INFO:root:current mean train loss 4477.796304086539
INFO:root:current train perplexity5.879874229431152
INFO:root:current mean train loss 4483.062885659428
INFO:root:current train perplexity5.87024450302124
INFO:root:current mean train loss 4484.5242416188685
INFO:root:current train perplexity5.86595344543457
INFO:root:current mean train loss 4480.578157552083
INFO:root:current train perplexity5.8596978187561035
INFO:root:current mean train loss 4484.756860967043
INFO:root:current train perplexity5.857327461242676
INFO:root:current mean train loss 4481.583001138152
INFO:root:current train perplexity5.857361316680908
INFO:root:current mean train loss 4480.321101427378
INFO:root:current train perplexity5.856231212615967
INFO:root:current mean train loss 4480.821982203649
INFO:root:current train perplexity5.855587959289551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.92s/it]
INFO:root:final mean train loss: 4481.680769151257
INFO:root:final train perplexity: 5.8600172996521
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 4323.100684632646
INFO:root:eval perplexity: 5.743880271911621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.92s/it]
INFO:root:eval mean loss: 5127.91133366578
INFO:root:eval perplexity: 8.140676498413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/13
  6%|â–‹         | 13/200 [1:30:11<21:30:23, 414.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4555.4287109375
INFO:root:current train perplexity5.879029273986816
INFO:root:current mean train loss 4459.009500151699
INFO:root:current train perplexity5.781736850738525
INFO:root:current mean train loss 4448.8053573833895
INFO:root:current train perplexity5.765346050262451
INFO:root:current mean train loss 4440.482858588593
INFO:root:current train perplexity5.760871410369873
INFO:root:current mean train loss 4445.254915526132
INFO:root:current train perplexity5.766845226287842
INFO:root:current mean train loss 4448.439202674577
INFO:root:current train perplexity5.7799458503723145
INFO:root:current mean train loss 4446.15217289205
INFO:root:current train perplexity5.777462959289551
INFO:root:current mean train loss 4442.705663993043
INFO:root:current train perplexity5.773819446563721
INFO:root:current mean train loss 4443.409140466902
INFO:root:current train perplexity5.771488666534424
INFO:root:current mean train loss 4443.0283346419055
INFO:root:current train perplexity5.765923023223877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.70s/it]
INFO:root:final mean train loss: 4439.413903697844
INFO:root:final train perplexity: 5.7631096839904785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 4291.665660668772
INFO:root:eval perplexity: 5.671329975128174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 5099.437849761746
INFO:root:eval perplexity: 8.0464448928833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/14
  7%|â–‹         | 14/200 [1:37:04<21:23:06, 413.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4506.082009055398
INFO:root:current train perplexity5.712604522705078
INFO:root:current mean train loss 4405.401279208896
INFO:root:current train perplexity5.678196430206299
INFO:root:current mean train loss 4407.171479283916
INFO:root:current train perplexity5.686363697052002
INFO:root:current mean train loss 4407.124036782808
INFO:root:current train perplexity5.680308818817139
INFO:root:current mean train loss 4393.57983933052
INFO:root:current train perplexity5.66316556930542
INFO:root:current mean train loss 4399.222941478871
INFO:root:current train perplexity5.666757583618164
INFO:root:current mean train loss 4399.22001106025
INFO:root:current train perplexity5.6688737869262695
INFO:root:current mean train loss 4400.310207619111
INFO:root:current train perplexity5.666450500488281
INFO:root:current mean train loss 4402.187913323154
INFO:root:current train perplexity5.668232440948486
INFO:root:current mean train loss 4404.839306426232
INFO:root:current train perplexity5.674637794494629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.99s/it]
INFO:root:final mean train loss: 4398.164821071009
INFO:root:final train perplexity: 5.670078754425049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 4268.963235192265
INFO:root:eval perplexity: 5.619505405426025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 5083.057639696919
INFO:root:eval perplexity: 7.9927287101745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/15
  8%|â–Š         | 15/200 [1:43:56<21:14:00, 413.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4320.722707648027
INFO:root:current train perplexity5.542591571807861
INFO:root:current mean train loss 4389.029906200762
INFO:root:current train perplexity5.5920562744140625
INFO:root:current mean train loss 4382.879949700343
INFO:root:current train perplexity5.594750881195068
INFO:root:current mean train loss 4375.495893233248
INFO:root:current train perplexity5.603631019592285
INFO:root:current mean train loss 4372.858016203013
INFO:root:current train perplexity5.5997538566589355
INFO:root:current mean train loss 4369.406913272218
INFO:root:current train perplexity5.591094017028809
INFO:root:current mean train loss 4367.24885384062
INFO:root:current train perplexity5.587339878082275
INFO:root:current mean train loss 4369.910941642581
INFO:root:current train perplexity5.593410968780518
INFO:root:current mean train loss 4368.342590704651
INFO:root:current train perplexity5.5930962562561035
INFO:root:current mean train loss 4368.031412051992
INFO:root:current train perplexity5.592568397521973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.94s/it]
INFO:root:final mean train loss: 4361.333097642468
INFO:root:final train perplexity: 5.588282108306885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 4249.72807755707
INFO:root:eval perplexity: 5.575964450836182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 5072.364242229056
INFO:root:eval perplexity: 7.957854270935059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/16
  8%|â–Š         | 16/200 [1:50:43<21:01:47, 411.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4273.152144820602
INFO:root:current train perplexity5.340050220489502
INFO:root:current mean train loss 4333.329932025098
INFO:root:current train perplexity5.481871604919434
INFO:root:current mean train loss 4347.802114881608
INFO:root:current train perplexity5.522571563720703
INFO:root:current mean train loss 4331.6130781727825
INFO:root:current train perplexity5.501262187957764
INFO:root:current mean train loss 4319.903313451405
INFO:root:current train perplexity5.499081134796143
INFO:root:current mean train loss 4316.006160960478
INFO:root:current train perplexity5.4938740730285645
INFO:root:current mean train loss 4318.181627775493
INFO:root:current train perplexity5.492644309997559
INFO:root:current mean train loss 4315.882766828577
INFO:root:current train perplexity5.493869304656982
INFO:root:current mean train loss 4323.412117050521
INFO:root:current train perplexity5.505776882171631
INFO:root:current mean train loss 4326.498255724531
INFO:root:current train perplexity5.507284164428711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.39s/it]
INFO:root:final mean train loss: 4327.9358178415605
INFO:root:final train perplexity: 5.515133380889893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 4225.198775487589
INFO:root:eval perplexity: 5.52092981338501
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 5045.661723251884
INFO:root:eval perplexity: 7.87143611907959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/17
  8%|â–Š         | 17/200 [1:57:31<20:51:10, 410.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4277.038239397321
INFO:root:current train perplexity5.458950996398926
INFO:root:current mean train loss 4291.776452184607
INFO:root:current train perplexity5.419726371765137
INFO:root:current mean train loss 4299.602058053524
INFO:root:current train perplexity5.426133155822754
INFO:root:current mean train loss 4295.529759649021
INFO:root:current train perplexity5.433252334594727
INFO:root:current mean train loss 4306.0089742726295
INFO:root:current train perplexity5.453730583190918
INFO:root:current mean train loss 4300.980146119305
INFO:root:current train perplexity5.4552321434021
INFO:root:current mean train loss 4309.186737589198
INFO:root:current train perplexity5.457443714141846
INFO:root:current mean train loss 4303.920375943346
INFO:root:current train perplexity5.453277111053467
INFO:root:current mean train loss 4301.717200072511
INFO:root:current train perplexity5.449570655822754
INFO:root:current mean train loss 4298.856589707972
INFO:root:current train perplexity5.447414875030518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.39s/it]
INFO:root:final mean train loss: 4296.569334830007
INFO:root:final train perplexity: 5.447305202484131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 4208.633808108932
INFO:root:eval perplexity: 5.484073638916016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 5036.099583402593
INFO:root:eval perplexity: 7.840716361999512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/18
  9%|â–‰         | 18/200 [2:04:18<20:42:01, 409.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4206.190003860828
INFO:root:current train perplexity5.320955753326416
INFO:root:current mean train loss 4254.715151059878
INFO:root:current train perplexity5.363249778747559
INFO:root:current mean train loss 4257.104345502186
INFO:root:current train perplexity5.367835998535156
INFO:root:current mean train loss 4265.597861954491
INFO:root:current train perplexity5.383943557739258
INFO:root:current mean train loss 4261.098076745026
INFO:root:current train perplexity5.378264904022217
INFO:root:current mean train loss 4264.939762909329
INFO:root:current train perplexity5.38123083114624
INFO:root:current mean train loss 4269.800788843799
INFO:root:current train perplexity5.38779354095459
INFO:root:current mean train loss 4268.712777919435
INFO:root:current train perplexity5.386207103729248
INFO:root:current mean train loss 4273.55871075215
INFO:root:current train perplexity5.388699054718018
INFO:root:current mean train loss 4270.477822037795
INFO:root:current train perplexity5.387099266052246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.82s/it]
INFO:root:final mean train loss: 4267.265843176073
INFO:root:final train perplexity: 5.38469123840332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 4193.432187777039
INFO:root:eval perplexity: 5.450464725494385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 5026.882003892398
INFO:root:eval perplexity: 7.811219215393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/19
 10%|â–‰         | 19/200 [2:11:09<20:36:32, 409.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4256.954877068015
INFO:root:current train perplexity5.326528549194336
INFO:root:current mean train loss 4254.906650972682
INFO:root:current train perplexity5.345650672912598
INFO:root:current mean train loss 4248.069340800859
INFO:root:current train perplexity5.333510875701904
INFO:root:current mean train loss 4239.02713230057
INFO:root:current train perplexity5.316664218902588
INFO:root:current mean train loss 4242.815695481396
INFO:root:current train perplexity5.318565845489502
INFO:root:current mean train loss 4243.471591513299
INFO:root:current train perplexity5.32664155960083
INFO:root:current mean train loss 4239.9594959077385
INFO:root:current train perplexity5.324541091918945
INFO:root:current mean train loss 4240.946598870776
INFO:root:current train perplexity5.329216957092285
INFO:root:current mean train loss 4247.936091959827
INFO:root:current train perplexity5.334102153778076
INFO:root:current mean train loss 4243.366230704933
INFO:root:current train perplexity5.32899284362793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.45s/it]
INFO:root:final mean train loss: 4240.7591360768965
INFO:root:final train perplexity: 5.328673839569092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.88s/it]
INFO:root:eval mean loss: 4179.268249944592
INFO:root:eval perplexity: 5.419336318969727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 5015.992933773825
INFO:root:eval perplexity: 7.776513576507568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/20
 10%|â–ˆ         | 20/200 [2:18:02<20:31:48, 410.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4201.108539128708
INFO:root:current train perplexity5.2521586418151855
INFO:root:current mean train loss 4213.458873820755
INFO:root:current train perplexity5.266857624053955
INFO:root:current mean train loss 4220.859956601412
INFO:root:current train perplexity5.27573823928833
INFO:root:current mean train loss 4221.564393279944
INFO:root:current train perplexity5.275092124938965
INFO:root:current mean train loss 4224.877283432905
INFO:root:current train perplexity5.28193473815918
INFO:root:current mean train loss 4225.643208348474
INFO:root:current train perplexity5.281801700592041
INFO:root:current mean train loss 4219.999209414122
INFO:root:current train perplexity5.27496862411499
INFO:root:current mean train loss 4217.177682909256
INFO:root:current train perplexity5.273773193359375
INFO:root:current mean train loss 4215.1052149460675
INFO:root:current train perplexity5.274045944213867
INFO:root:current mean train loss 4218.089039282456
INFO:root:current train perplexity5.272984981536865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.27s/it]
INFO:root:final mean train loss: 4215.031336138325
INFO:root:final train perplexity: 5.274858474731445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4162.104256704344
INFO:root:eval perplexity: 5.3818535804748535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 5001.391151374113
INFO:root:eval perplexity: 7.730220794677734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/21
 10%|â–ˆ         | 21/200 [2:25:04<20:35:20, 414.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4209.392909718983
INFO:root:current train perplexity5.233306884765625
INFO:root:current mean train loss 4212.065606579809
INFO:root:current train perplexity5.252520561218262
INFO:root:current mean train loss 4207.178927646594
INFO:root:current train perplexity5.240188121795654
INFO:root:current mean train loss 4198.760170086853
INFO:root:current train perplexity5.23003625869751
INFO:root:current mean train loss 4202.518895020577
INFO:root:current train perplexity5.233005046844482
INFO:root:current mean train loss 4204.038881655092
INFO:root:current train perplexity5.2358479499816895
INFO:root:current mean train loss 4195.923760775862
INFO:root:current train perplexity5.229992866516113
INFO:root:current mean train loss 4195.725878460622
INFO:root:current train perplexity5.22579288482666
INFO:root:current mean train loss 4196.636384781395
INFO:root:current train perplexity5.228559970855713
INFO:root:current mean train loss 4195.179285816717
INFO:root:current train perplexity5.226650238037109

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.81s/it]
INFO:root:final mean train loss: 4191.471354084631
INFO:root:final train perplexity: 5.22605562210083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 4152.1598567015735
INFO:root:eval perplexity: 5.360254764556885
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 4994.390412026263
INFO:root:eval perplexity: 7.708123207092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/22
 11%|â–ˆ         | 22/200 [2:32:25<20:52:31, 422.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4166.07166015625
INFO:root:current train perplexity5.137248516082764
INFO:root:current mean train loss 4168.825106026786
INFO:root:current train perplexity5.147943019866943
INFO:root:current mean train loss 4179.29142578125
INFO:root:current train perplexity5.171159267425537
INFO:root:current mean train loss 4166.289132161458
INFO:root:current train perplexity5.165509223937988
INFO:root:current mean train loss 4172.509502467105
INFO:root:current train perplexity5.165182590484619
INFO:root:current mean train loss 4175.145018682065
INFO:root:current train perplexity5.171255588531494
INFO:root:current mean train loss 4179.467379918981
INFO:root:current train perplexity5.181933879852295
INFO:root:current mean train loss 4175.283079007057
INFO:root:current train perplexity5.180034160614014
INFO:root:current mean train loss 4173.210348214286
INFO:root:current train perplexity5.178360939025879
INFO:root:current mean train loss 4172.235180789263
INFO:root:current train perplexity5.17882776260376

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.61s/it]
INFO:root:final mean train loss: 4168.463906318911
INFO:root:final train perplexity: 5.178832054138184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it]
INFO:root:eval mean loss: 4142.384857394171
INFO:root:eval perplexity: 5.339109420776367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it]
INFO:root:eval mean loss: 4985.30587876773
INFO:root:eval perplexity: 7.679543972015381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/23
 12%|â–ˆâ–        | 23/200 [2:39:29<20:47:02, 422.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4147.003476797816
INFO:root:current train perplexity5.13287353515625
INFO:root:current mean train loss 4155.206390881148
INFO:root:current train perplexity5.147964000701904
INFO:root:current mean train loss 4160.170930356946
INFO:root:current train perplexity5.148021697998047
INFO:root:current mean train loss 4169.056363337345
INFO:root:current train perplexity5.154024600982666
INFO:root:current mean train loss 4159.258959404924
INFO:root:current train perplexity5.14575719833374
INFO:root:current mean train loss 4155.698913888294
INFO:root:current train perplexity5.1381611824035645
INFO:root:current mean train loss 4156.625702038342
INFO:root:current train perplexity5.136211395263672
INFO:root:current mean train loss 4152.376515667405
INFO:root:current train perplexity5.133203029632568
INFO:root:current mean train loss 4152.060628716025
INFO:root:current train perplexity5.137597560882568
INFO:root:current mean train loss 4150.894036759681
INFO:root:current train perplexity5.135862350463867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.87s/it]
INFO:root:final mean train loss: 4147.008348095802
INFO:root:final train perplexity: 5.135179042816162
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 4128.916325562389
INFO:root:eval perplexity: 5.310110092163086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 4973.04630014406
INFO:root:eval perplexity: 7.641140937805176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/24
 12%|â–ˆâ–        | 24/200 [2:47:16<21:18:37, 435.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4148.334848257212
INFO:root:current train perplexity5.081717014312744
INFO:root:current mean train loss 4133.743731593587
INFO:root:current train perplexity5.085578441619873
INFO:root:current mean train loss 4120.638062781894
INFO:root:current train perplexity5.078500270843506
INFO:root:current mean train loss 4117.403705567655
INFO:root:current train perplexity5.083069324493408
INFO:root:current mean train loss 4125.3263036413255
INFO:root:current train perplexity5.08814001083374
INFO:root:current mean train loss 4127.140022703838
INFO:root:current train perplexity5.092979431152344
INFO:root:current mean train loss 4130.826395170044
INFO:root:current train perplexity5.092597007751465
INFO:root:current mean train loss 4132.298811766652
INFO:root:current train perplexity5.092827320098877
INFO:root:current mean train loss 4130.087566200196
INFO:root:current train perplexity5.093713283538818
INFO:root:current mean train loss 4129.269916800028
INFO:root:current train perplexity5.093023300170898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it]
INFO:root:final mean train loss: 4126.190376158684
INFO:root:final train perplexity: 5.093174934387207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 4118.020679230385
INFO:root:eval perplexity: 5.286766529083252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 4970.237025916999
INFO:root:eval perplexity: 7.632370471954346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/25
 12%|â–ˆâ–Ž        | 25/200 [2:54:19<21:00:19, 432.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4117.437048709754
INFO:root:current train perplexity5.060296058654785
INFO:root:current mean train loss 4109.710450445587
INFO:root:current train perplexity5.047854900360107
INFO:root:current mean train loss 4120.0473600151545
INFO:root:current train perplexity5.0568132400512695
INFO:root:current mean train loss 4114.209079828477
INFO:root:current train perplexity5.054322719573975
INFO:root:current mean train loss 4109.0849266893165
INFO:root:current train perplexity5.0504961013793945
INFO:root:current mean train loss 4112.0718397035425
INFO:root:current train perplexity5.052472114562988
INFO:root:current mean train loss 4108.949950473332
INFO:root:current train perplexity5.051492691040039
INFO:root:current mean train loss 4108.038633802507
INFO:root:current train perplexity5.047579288482666
INFO:root:current mean train loss 4105.9454719110645
INFO:root:current train perplexity5.049318313598633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.76s/it]
INFO:root:final mean train loss: 4105.952172925396
INFO:root:final train perplexity: 5.052670478820801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 4113.174472240691
INFO:root:eval perplexity: 5.276416301727295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 4966.38801910184
INFO:root:eval perplexity: 7.620364189147949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/26
 13%|â–ˆâ–Ž        | 26/200 [3:01:17<20:40:38, 427.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4078.860281808036
INFO:root:current train perplexity4.932703971862793
INFO:root:current mean train loss 4075.205048463055
INFO:root:current train perplexity4.971614360809326
INFO:root:current mean train loss 4075.1632522361865
INFO:root:current train perplexity4.993768692016602
INFO:root:current mean train loss 4087.7915452590596
INFO:root:current train perplexity4.996509552001953
INFO:root:current mean train loss 4086.22413129127
INFO:root:current train perplexity4.997438907623291
INFO:root:current mean train loss 4085.64624793901
INFO:root:current train perplexity4.999876022338867
INFO:root:current mean train loss 4083.246263884241
INFO:root:current train perplexity4.9998674392700195
INFO:root:current mean train loss 4087.026192801339
INFO:root:current train perplexity5.0060248374938965
INFO:root:current mean train loss 4086.52406978489
INFO:root:current train perplexity5.008616924285889
INFO:root:current mean train loss 4089.036236175234
INFO:root:current train perplexity5.015653133392334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.89s/it]
INFO:root:final mean train loss: 4086.5573251170495
INFO:root:final train perplexity: 5.014155864715576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 4102.778451906029
INFO:root:eval perplexity: 5.2542805671691895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 4955.731725814495
INFO:root:eval perplexity: 7.5872321128845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/27
 14%|â–ˆâ–Ž        | 27/200 [3:08:10<20:20:37, 423.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4102.170914713542
INFO:root:current train perplexity5.021856307983398
INFO:root:current mean train loss 4027.0276982846467
INFO:root:current train perplexity4.935704231262207
INFO:root:current mean train loss 4053.923812227471
INFO:root:current train perplexity4.9510698318481445
INFO:root:current mean train loss 4063.7740699404762
INFO:root:current train perplexity4.966141700744629
INFO:root:current mean train loss 4060.719840102598
INFO:root:current train perplexity4.9697489738464355
INFO:root:current mean train loss 4060.4225083434467
INFO:root:current train perplexity4.971803665161133
INFO:root:current mean train loss 4062.6296954395325
INFO:root:current train perplexity4.973212718963623
INFO:root:current mean train loss 4068.9168812144885
INFO:root:current train perplexity4.9760870933532715
INFO:root:current mean train loss 4070.4705494512077
INFO:root:current train perplexity4.978082180023193
INFO:root:current mean train loss 4071.3684031335383
INFO:root:current train perplexity4.979318141937256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.48s/it]
INFO:root:final mean train loss: 4069.3683253872778
INFO:root:final train perplexity: 4.980266571044922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 4092.82943920379
INFO:root:eval perplexity: 5.233184814453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 4951.27852116578
INFO:root:eval perplexity: 7.573428153991699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/28
 14%|â–ˆâ–        | 28/200 [3:15:10<20:10:53, 422.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4053.003662109375
INFO:root:current train perplexity4.931097507476807
INFO:root:current mean train loss 4041.26738162157
INFO:root:current train perplexity4.936550140380859
INFO:root:current mean train loss 4047.1314023963005
INFO:root:current train perplexity4.929818630218506
INFO:root:current mean train loss 4065.742656884917
INFO:root:current train perplexity4.94766902923584
INFO:root:current mean train loss 4061.8728679539745
INFO:root:current train perplexity4.945140361785889
INFO:root:current mean train loss 4058.511011068953
INFO:root:current train perplexity4.943910121917725
INFO:root:current mean train loss 4058.675759304775
INFO:root:current train perplexity4.946822643280029
INFO:root:current mean train loss 4056.804582820064
INFO:root:current train perplexity4.940847873687744
INFO:root:current mean train loss 4054.5606530746886
INFO:root:current train perplexity4.940883159637451
INFO:root:current mean train loss 4055.326300161244
INFO:root:current train perplexity4.943481922149658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.31s/it]
INFO:root:final mean train loss: 4052.400943017775
INFO:root:final train perplexity: 4.947039604187012
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 4086.728913868573
INFO:root:eval perplexity: 5.220290660858154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it]
INFO:root:eval mean loss: 4945.3965692181955
INFO:root:eval perplexity: 7.555236339569092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/29
 14%|â–ˆâ–        | 29/200 [3:22:12<20:03:25, 422.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3969.957795173891
INFO:root:current train perplexity4.86567497253418
INFO:root:current mean train loss 4040.45258639969
INFO:root:current train perplexity4.9170379638671875
INFO:root:current mean train loss 4040.040086622362
INFO:root:current train perplexity4.920246601104736
INFO:root:current mean train loss 4039.918725512179
INFO:root:current train perplexity4.923235893249512
INFO:root:current mean train loss 4037.7012279537053
INFO:root:current train perplexity4.912889003753662
INFO:root:current mean train loss 4043.188700932792
INFO:root:current train perplexity4.915557861328125
INFO:root:current mean train loss 4042.8605871910904
INFO:root:current train perplexity4.914641380310059
INFO:root:current mean train loss 4040.860677528642
INFO:root:current train perplexity4.915935039520264
INFO:root:current mean train loss 4038.451230633273
INFO:root:current train perplexity4.913275718688965
INFO:root:current mean train loss 4038.8794364888226
INFO:root:current train perplexity4.913253307342529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it]
INFO:root:final mean train loss: 4035.3999628866873
INFO:root:final train perplexity: 4.91396951675415
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 4079.721042497784
INFO:root:eval perplexity: 5.20551872253418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 4940.042560117465
INFO:root:eval perplexity: 7.538712978363037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/30
 15%|â–ˆâ–Œ        | 30/200 [3:29:12<19:54:58, 421.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4021.861171624599
INFO:root:current train perplexity4.89668083190918
INFO:root:current mean train loss 4020.7234905435025
INFO:root:current train perplexity4.878108024597168
INFO:root:current mean train loss 4015.5196579171024
INFO:root:current train perplexity4.8811798095703125
INFO:root:current mean train loss 4023.6504431980547
INFO:root:current train perplexity4.877528667449951
INFO:root:current mean train loss 4025.5593017021997
INFO:root:current train perplexity4.884122371673584
INFO:root:current mean train loss 4027.4912068609406
INFO:root:current train perplexity4.884533882141113
INFO:root:current mean train loss 4028.1202631369815
INFO:root:current train perplexity4.885453224182129
INFO:root:current mean train loss 4031.071473737208
INFO:root:current train perplexity4.890996932983398
INFO:root:current mean train loss 4025.1351927983465
INFO:root:current train perplexity4.884175777435303
INFO:root:current mean train loss 4022.15517177724
INFO:root:current train perplexity4.883662700653076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.71s/it]
INFO:root:final mean train loss: 4018.782345987135
INFO:root:final train perplexity: 4.881857872009277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 4074.69409872285
INFO:root:eval perplexity: 5.194948673248291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 4941.339833361038
INFO:root:eval perplexity: 7.54271125793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/31
 16%|â–ˆâ–Œ        | 31/200 [3:36:14<19:48:02, 421.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3986.1975720994014
INFO:root:current train perplexity4.839920520782471
INFO:root:current mean train loss 4003.980787627551
INFO:root:current train perplexity4.85426139831543
INFO:root:current mean train loss 4002.549617875443
INFO:root:current train perplexity4.849336624145508
INFO:root:current mean train loss 4007.1364415413364
INFO:root:current train perplexity4.8483967781066895
INFO:root:current mean train loss 4011.5631362949175
INFO:root:current train perplexity4.8497633934021
INFO:root:current mean train loss 4009.343493808558
INFO:root:current train perplexity4.8488898277282715
INFO:root:current mean train loss 4011.2452768033954
INFO:root:current train perplexity4.8528618812561035
INFO:root:current mean train loss 4007.676579364332
INFO:root:current train perplexity4.850012302398682
INFO:root:current mean train loss 4005.30029296875
INFO:root:current train perplexity4.847214221954346
INFO:root:current mean train loss 4006.0600395162355
INFO:root:current train perplexity4.8507795333862305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.92s/it]
INFO:root:final mean train loss: 4003.376247406006
INFO:root:final train perplexity: 4.852275371551514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4066.3388273631426
INFO:root:eval perplexity: 5.177425861358643
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 4936.2867803911795
INFO:root:eval perplexity: 7.527143478393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/32
 16%|â–ˆâ–Œ        | 32/200 [3:43:22<19:45:49, 423.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3948.4457652698866
INFO:root:current train perplexity4.781935214996338
INFO:root:current mean train loss 3976.3786699848793
INFO:root:current train perplexity4.803333282470703
INFO:root:current mean train loss 3981.2329254748774
INFO:root:current train perplexity4.803888320922852
INFO:root:current mean train loss 3982.8857875770245
INFO:root:current train perplexity4.805415630340576
INFO:root:current mean train loss 3980.154500236092
INFO:root:current train perplexity4.803257942199707
INFO:root:current mean train loss 3981.6480860254787
INFO:root:current train perplexity4.8074541091918945
INFO:root:current mean train loss 3987.169024332061
INFO:root:current train perplexity4.811629295349121
INFO:root:current mean train loss 3987.8746310404595
INFO:root:current train perplexity4.816718578338623
INFO:root:current mean train loss 3988.450686449196
INFO:root:current train perplexity4.816654682159424
INFO:root:current mean train loss 3988.761842226358
INFO:root:current train perplexity4.820491313934326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it]
INFO:root:final mean train loss: 3987.9490769909276
INFO:root:final train perplexity: 4.822831630706787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it]
INFO:root:eval mean loss: 4061.6679081477173
INFO:root:eval perplexity: 5.167656898498535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 4932.633982989805
INFO:root:eval perplexity: 7.515906810760498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/33
 16%|â–ˆâ–‹        | 33/200 [3:50:21<19:35:43, 422.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3933.4682733444943
INFO:root:current train perplexity4.746687412261963
INFO:root:current mean train loss 3964.370262473639
INFO:root:current train perplexity4.77396297454834
INFO:root:current mean train loss 3967.129970071887
INFO:root:current train perplexity4.777871131896973
INFO:root:current mean train loss 3968.0435115089103
INFO:root:current train perplexity4.775799751281738
INFO:root:current mean train loss 3976.6066973626484
INFO:root:current train perplexity4.782864093780518
INFO:root:current mean train loss 3977.874270179979
INFO:root:current train perplexity4.790860652923584
INFO:root:current mean train loss 3971.55078714178
INFO:root:current train perplexity4.786359786987305
INFO:root:current mean train loss 3975.299052747174
INFO:root:current train perplexity4.793275356292725
INFO:root:current mean train loss 3972.2142171318255
INFO:root:current train perplexity4.79000997543335
INFO:root:current mean train loss 3976.4579784040757
INFO:root:current train perplexity4.795022010803223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.17s/it]
INFO:root:final mean train loss: 3973.7641095807476
INFO:root:final train perplexity: 4.795917510986328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 4057.285021193484
INFO:root:eval perplexity: 5.158505439758301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.69s/it]
INFO:root:eval mean loss: 4932.5173374473625
INFO:root:eval perplexity: 7.515550136566162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/34
 17%|â–ˆâ–‹        | 34/200 [3:57:23<19:27:45, 422.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3918.5552514304577
INFO:root:current train perplexity4.719505786895752
INFO:root:current mean train loss 3934.1146704244334
INFO:root:current train perplexity4.729429244995117
INFO:root:current mean train loss 3945.993524417666
INFO:root:current train perplexity4.73813009262085
INFO:root:current mean train loss 3960.481562447355
INFO:root:current train perplexity4.7574872970581055
INFO:root:current mean train loss 3962.0158509985404
INFO:root:current train perplexity4.763350486755371
INFO:root:current mean train loss 3959.241090791238
INFO:root:current train perplexity4.765038013458252
INFO:root:current mean train loss 3957.971269269281
INFO:root:current train perplexity4.767310619354248
INFO:root:current mean train loss 3960.8941705805164
INFO:root:current train perplexity4.766913414001465
INFO:root:current mean train loss 3961.1986379700056
INFO:root:current train perplexity4.770090579986572
INFO:root:current mean train loss 3963.793895780365
INFO:root:current train perplexity4.770249843597412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.65s/it]
INFO:root:final mean train loss: 3960.4052208931216
INFO:root:final train perplexity: 4.770706653594971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4054.0857124058066
INFO:root:eval perplexity: 5.151837348937988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it]
INFO:root:eval mean loss: 4932.801756081006
INFO:root:eval perplexity: 7.516424655914307
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/35
 18%|â–ˆâ–Š        | 35/200 [4:04:23<19:18:50, 421.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3954.7035607446596
INFO:root:current train perplexity4.789638042449951
INFO:root:current mean train loss 3946.138148131983
INFO:root:current train perplexity4.747490882873535
INFO:root:current mean train loss 3946.8458160072246
INFO:root:current train perplexity4.749746322631836
INFO:root:current mean train loss 3948.482583561799
INFO:root:current train perplexity4.750354766845703
INFO:root:current mean train loss 3951.1366168123695
INFO:root:current train perplexity4.747942924499512
INFO:root:current mean train loss 3947.5590419736345
INFO:root:current train perplexity4.740045547485352
INFO:root:current mean train loss 3945.4953634854796
INFO:root:current train perplexity4.739231109619141
INFO:root:current mean train loss 3948.6614139346316
INFO:root:current train perplexity4.739470481872559
INFO:root:current mean train loss 3948.6458761065487
INFO:root:current train perplexity4.7416486740112305
INFO:root:current mean train loss 3948.1253633430956
INFO:root:current train perplexity4.742884635925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.93s/it]
INFO:root:final mean train loss: 3945.3519803939325
INFO:root:final train perplexity: 4.742457866668701
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 4048.661764807735
INFO:root:eval perplexity: 5.140549182891846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it]
INFO:root:eval mean loss: 4928.949859402704
INFO:root:eval perplexity: 7.504593849182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/36
 18%|â–ˆâ–Š        | 36/200 [4:11:25<19:12:47, 421.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3942.2588788613507
INFO:root:current train perplexity4.703537940979004
INFO:root:current mean train loss 3942.2520797647894
INFO:root:current train perplexity4.700713634490967
INFO:root:current mean train loss 3930.567554646668
INFO:root:current train perplexity4.693974494934082
INFO:root:current mean train loss 3927.22352935239
INFO:root:current train perplexity4.701521873474121
INFO:root:current mean train loss 3926.74886251524
INFO:root:current train perplexity4.706103801727295
INFO:root:current mean train loss 3931.2916207776566
INFO:root:current train perplexity4.701440811157227
INFO:root:current mean train loss 3932.57006409491
INFO:root:current train perplexity4.705878734588623
INFO:root:current mean train loss 3932.388637440935
INFO:root:current train perplexity4.709589958190918
INFO:root:current mean train loss 3933.4212664375177
INFO:root:current train perplexity4.712331295013428
INFO:root:current mean train loss 3936.0786377695194
INFO:root:current train perplexity4.719818592071533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.99s/it]
INFO:root:final mean train loss: 3933.3682545077418
INFO:root:final train perplexity: 4.720088958740234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it]
INFO:root:eval mean loss: 4043.8878407579787
INFO:root:eval perplexity: 5.130635738372803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it]
INFO:root:eval mean loss: 4927.991408327793
INFO:root:eval perplexity: 7.501652717590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/37
 18%|â–ˆâ–Š        | 37/200 [4:18:22<19:01:36, 420.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3898.6871633429278
INFO:root:current train perplexity4.665948390960693
INFO:root:current mean train loss 3919.7592272636216
INFO:root:current train perplexity4.67426872253418
INFO:root:current mean train loss 3917.280793167373
INFO:root:current train perplexity4.687417507171631
INFO:root:current mean train loss 3916.696781052215
INFO:root:current train perplexity4.68303108215332
INFO:root:current mean train loss 3918.8052601207387
INFO:root:current train perplexity4.68300199508667
INFO:root:current mean train loss 3918.172762522978
INFO:root:current train perplexity4.681174278259277
INFO:root:current mean train loss 3920.0762136774956
INFO:root:current train perplexity4.682679176330566
INFO:root:current mean train loss 3920.5910140895244
INFO:root:current train perplexity4.688735008239746
INFO:root:current mean train loss 3922.053674657385
INFO:root:current train perplexity4.692320823669434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.46s/it]
INFO:root:final mean train loss: 3919.631566324542
INFO:root:final train perplexity: 4.694576740264893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 4040.714119985594
INFO:root:eval perplexity: 5.1240553855896
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 4924.876011192376
INFO:root:eval perplexity: 7.49210262298584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/38
 19%|â–ˆâ–‰        | 38/200 [4:25:20<18:52:33, 419.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4007.0194498697915
INFO:root:current train perplexity4.77993631362915
INFO:root:current mean train loss 3902.5750483540655
INFO:root:current train perplexity4.651707172393799
INFO:root:current mean train loss 3900.033549491995
INFO:root:current train perplexity4.652738571166992
INFO:root:current mean train loss 3903.7437079401298
INFO:root:current train perplexity4.657580852508545
INFO:root:current mean train loss 3909.5025734723945
INFO:root:current train perplexity4.668913841247559
INFO:root:current mean train loss 3914.739648534574
INFO:root:current train perplexity4.670111656188965
INFO:root:current mean train loss 3916.098646578306
INFO:root:current train perplexity4.6714582443237305
INFO:root:current mean train loss 3912.701543816123
INFO:root:current train perplexity4.669743537902832
INFO:root:current mean train loss 3911.2746147260273
INFO:root:current train perplexity4.669662952423096
INFO:root:current mean train loss 3910.9081790624136
INFO:root:current train perplexity4.671031951904297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.68s/it]
INFO:root:final mean train loss: 3906.990514755249
INFO:root:final train perplexity: 4.671222686767578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it]
INFO:root:eval mean loss: 4035.987335854388
INFO:root:eval perplexity: 5.1142706871032715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 4921.593777703901
INFO:root:eval perplexity: 7.482054710388184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/39
 20%|â–ˆâ–‰        | 39/200 [4:32:19<18:45:39, 419.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3898.320467862216
INFO:root:current train perplexity4.712130069732666
INFO:root:current mean train loss 3878.1964012352196
INFO:root:current train perplexity4.62273645401001
INFO:root:current mean train loss 3880.6627098915137
INFO:root:current train perplexity4.626901626586914
INFO:root:current mean train loss 3880.6923090207997
INFO:root:current train perplexity4.636284351348877
INFO:root:current mean train loss 3886.9222480421226
INFO:root:current train perplexity4.633992671966553
INFO:root:current mean train loss 3889.8234237402153
INFO:root:current train perplexity4.636805057525635
INFO:root:current mean train loss 3887.2839219613084
INFO:root:current train perplexity4.641091823577881
INFO:root:current mean train loss 3890.6629997500218
INFO:root:current train perplexity4.645495891571045
INFO:root:current mean train loss 3897.0701842584385
INFO:root:current train perplexity4.648119926452637
INFO:root:current mean train loss 3898.735404088913
INFO:root:current train perplexity4.649518013000488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it]
INFO:root:final mean train loss: 3895.810121843892
INFO:root:final train perplexity: 4.650662422180176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 4034.521579607159
INFO:root:eval perplexity: 5.111240863800049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 4923.884124972296
INFO:root:eval perplexity: 7.489063262939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/40
 20%|â–ˆâ–ˆ        | 40/200 [4:39:19<18:39:07, 419.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3876.4023052014804
INFO:root:current train perplexity4.635916709899902
INFO:root:current mean train loss 3880.7882828912816
INFO:root:current train perplexity4.624885559082031
INFO:root:current mean train loss 3887.2789200734874
INFO:root:current train perplexity4.61362886428833
INFO:root:current mean train loss 3888.0046065279685
INFO:root:current train perplexity4.619905471801758
INFO:root:current mean train loss 3891.626761425082
INFO:root:current train perplexity4.626582145690918
INFO:root:current mean train loss 3896.429433480853
INFO:root:current train perplexity4.629439830780029
INFO:root:current mean train loss 3889.8417633500353
INFO:root:current train perplexity4.626262664794922
INFO:root:current mean train loss 3886.868515842316
INFO:root:current train perplexity4.624275207519531
INFO:root:current mean train loss 3884.7368357824903
INFO:root:current train perplexity4.625443935394287
INFO:root:current mean train loss 3885.8057727170326
INFO:root:current train perplexity4.626392364501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.85s/it]
INFO:root:final mean train loss: 3882.5174817731304
INFO:root:final train perplexity: 4.626338005065918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it]
INFO:root:eval mean loss: 4030.321524545656
INFO:root:eval perplexity: 5.102565288543701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 4917.259627105496
INFO:root:eval perplexity: 7.468805313110352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/41
 20%|â–ˆâ–ˆ        | 41/200 [4:46:18<18:31:50, 419.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3878.7268880208335
INFO:root:current train perplexity4.607995986938477
INFO:root:current mean train loss 3871.1894473578986
INFO:root:current train perplexity4.615869522094727
INFO:root:current mean train loss 3874.3717379801074
INFO:root:current train perplexity4.608576774597168
INFO:root:current mean train loss 3877.145138241829
INFO:root:current train perplexity4.6093854904174805
INFO:root:current mean train loss 3869.4418104828383
INFO:root:current train perplexity4.602457046508789
INFO:root:current mean train loss 3870.7761438937973
INFO:root:current train perplexity4.601738452911377
INFO:root:current mean train loss 3874.312843042888
INFO:root:current train perplexity4.606358051300049
INFO:root:current mean train loss 3874.10159104464
INFO:root:current train perplexity4.603907585144043
INFO:root:current mean train loss 3874.050535338101
INFO:root:current train perplexity4.605070114135742
INFO:root:current mean train loss 3874.3896594988873
INFO:root:current train perplexity4.607035160064697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it]
INFO:root:final mean train loss: 3872.0957825568416
INFO:root:final train perplexity: 4.607355117797852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 4025.4583229443706
INFO:root:eval perplexity: 5.09254264831543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it]
INFO:root:eval mean loss: 4917.786638408688
INFO:root:eval perplexity: 7.4704132080078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/42
 21%|â–ˆâ–ˆ        | 42/200 [4:53:19<18:25:15, 419.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.622328404018
INFO:root:current train perplexity4.616565227508545
INFO:root:current mean train loss 3851.2373498987267
INFO:root:current train perplexity4.568807601928711
INFO:root:current mean train loss 3852.41754176363
INFO:root:current train perplexity4.562878131866455
INFO:root:current mean train loss 3857.176469945196
INFO:root:current train perplexity4.56710958480835
INFO:root:current mean train loss 3852.874627896013
INFO:root:current train perplexity4.5712103843688965
INFO:root:current mean train loss 3856.365648729556
INFO:root:current train perplexity4.576152801513672
INFO:root:current mean train loss 3864.4073934239664
INFO:root:current train perplexity4.58329439163208
INFO:root:current mean train loss 3863.541580968325
INFO:root:current train perplexity4.584062576293945
INFO:root:current mean train loss 3864.6284282021893
INFO:root:current train perplexity4.586118221282959
INFO:root:current mean train loss 3864.5589786305145
INFO:root:current train perplexity4.586329460144043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it]
INFO:root:final mean train loss: 3859.817845805999
INFO:root:final train perplexity: 4.585090160369873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it]
INFO:root:eval mean loss: 4025.50335390348
INFO:root:eval perplexity: 5.092635631561279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 4919.396020334663
INFO:root:eval perplexity: 7.475332736968994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:00:16<18:16:43, 419.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3865.936886809593
INFO:root:current train perplexity4.567422389984131
INFO:root:current mean train loss 3835.256014737216
INFO:root:current train perplexity4.555402755737305
INFO:root:current mean train loss 3829.9497030124744
INFO:root:current train perplexity4.546279430389404
INFO:root:current mean train loss 3834.3332768654336
INFO:root:current train perplexity4.541759490966797
INFO:root:current mean train loss 3840.289667064934
INFO:root:current train perplexity4.544070720672607
INFO:root:current mean train loss 3843.5963092052257
INFO:root:current train perplexity4.547749996185303
INFO:root:current mean train loss 3847.3142674566243
INFO:root:current train perplexity4.5533647537231445
INFO:root:current mean train loss 3847.0700677021996
INFO:root:current train perplexity4.55617618560791
INFO:root:current mean train loss 3847.3393140546227
INFO:root:current train perplexity4.559558868408203
INFO:root:current mean train loss 3851.132170692355
INFO:root:current train perplexity4.565499782562256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.11s/it]
INFO:root:final mean train loss: 3849.652240445537
INFO:root:final train perplexity: 4.566737651824951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 4021.19356022828
INFO:root:eval perplexity: 5.083766937255859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it]
INFO:root:eval mean loss: 4911.451431599069
INFO:root:eval perplexity: 7.45108699798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:07:16<18:09:50, 419.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.8369475719974
INFO:root:current train perplexity4.606987953186035
INFO:root:current mean train loss 3848.5144641194124
INFO:root:current train perplexity4.553598880767822
INFO:root:current mean train loss 3844.5192676559386
INFO:root:current train perplexity4.545796871185303
INFO:root:current mean train loss 3834.5741366742345
INFO:root:current train perplexity4.532829284667969
INFO:root:current mean train loss 3831.513021194221
INFO:root:current train perplexity4.528046131134033
INFO:root:current mean train loss 3828.7459882954286
INFO:root:current train perplexity4.530040264129639
INFO:root:current mean train loss 3832.6729580693163
INFO:root:current train perplexity4.533756256103516
INFO:root:current mean train loss 3836.5560756231275
INFO:root:current train perplexity4.537763595581055
INFO:root:current mean train loss 3839.7485658531323
INFO:root:current train perplexity4.545586585998535
INFO:root:current mean train loss 3841.703842275401
INFO:root:current train perplexity4.546354293823242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.09s/it]
INFO:root:final mean train loss: 3838.272145117483
INFO:root:final train perplexity: 4.546280860900879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 4020.1184636109265
INFO:root:eval perplexity: 5.081557750701904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 4919.0966762245125
INFO:root:eval perplexity: 7.4744181632995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:14:13<18:01:32, 418.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3800.141994670286
INFO:root:current train perplexity4.510610103607178
INFO:root:current mean train loss 3832.018335114485
INFO:root:current train perplexity4.530782699584961
INFO:root:current mean train loss 3829.243229103825
INFO:root:current train perplexity4.534447193145752
INFO:root:current mean train loss 3819.341043371344
INFO:root:current train perplexity4.522894382476807
INFO:root:current mean train loss 3817.0977642250477
INFO:root:current train perplexity4.516891956329346
INFO:root:current mean train loss 3823.475349221545
INFO:root:current train perplexity4.523370265960693
INFO:root:current mean train loss 3821.301689275299
INFO:root:current train perplexity4.518118381500244
INFO:root:current mean train loss 3823.755906337492
INFO:root:current train perplexity4.52237606048584
INFO:root:current mean train loss 3828.0401422325194
INFO:root:current train perplexity4.524340629577637
INFO:root:current mean train loss 3831.2015349037083
INFO:root:current train perplexity4.5277018547058105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.92s/it]
INFO:root:final mean train loss: 3828.4929795419016
INFO:root:final train perplexity: 4.528773784637451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4019.215205632203
INFO:root:eval perplexity: 5.079701900482178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 4915.274511026152
INFO:root:eval perplexity: 7.462744235992432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:21:16<17:57:34, 419.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3808.060889400653
INFO:root:current train perplexity4.475234031677246
INFO:root:current mean train loss 3819.594385935161
INFO:root:current train perplexity4.50697660446167
INFO:root:current mean train loss 3818.3564288535813
INFO:root:current train perplexity4.50698184967041
INFO:root:current mean train loss 3810.482262884239
INFO:root:current train perplexity4.496404647827148
INFO:root:current mean train loss 3808.645652101178
INFO:root:current train perplexity4.493325710296631
INFO:root:current mean train loss 3813.182003606564
INFO:root:current train perplexity4.501885414123535
INFO:root:current mean train loss 3813.5390544473858
INFO:root:current train perplexity4.503848075866699
INFO:root:current mean train loss 3817.849486508923
INFO:root:current train perplexity4.507410049438477
INFO:root:current mean train loss 3821.069794651546
INFO:root:current train perplexity4.509998321533203
INFO:root:current mean train loss 3819.925256612752
INFO:root:current train perplexity4.509793758392334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.47s/it]
INFO:root:final mean train loss: 3818.370221353346
INFO:root:final train perplexity: 4.51072359085083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 4014.8565249612147
INFO:root:eval perplexity: 5.070756912231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 4916.477660267065
INFO:root:eval perplexity: 7.4664177894592285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:28:15<17:49:55, 419.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3792.3614485677085
INFO:root:current train perplexity4.423007011413574
INFO:root:current mean train loss 3794.8254464285715
INFO:root:current train perplexity4.461638927459717
INFO:root:current mean train loss 3802.765074573864
INFO:root:current train perplexity4.472911357879639
INFO:root:current mean train loss 3800.798125
INFO:root:current train perplexity4.479062557220459
INFO:root:current mean train loss 3798.644261924342
INFO:root:current train perplexity4.477066993713379
INFO:root:current mean train loss 3802.0084812330165
INFO:root:current train perplexity4.478525638580322
INFO:root:current mean train loss 3801.816146195023
INFO:root:current train perplexity4.476255893707275
INFO:root:current mean train loss 3808.5190521043346
INFO:root:current train perplexity4.486361503601074
INFO:root:current mean train loss 3807.482328125
INFO:root:current train perplexity4.484909534454346
INFO:root:current mean train loss 3809.168021834936
INFO:root:current train perplexity4.487476348876953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it]
INFO:root:final mean train loss: 3805.845242715651
INFO:root:final train perplexity: 4.488489151000977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it]
INFO:root:eval mean loss: 4014.8104499113474
INFO:root:eval perplexity: 5.070662021636963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it]
INFO:root:eval mean loss: 4918.001125470966
INFO:root:eval perplexity: 7.471068859100342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:35:16<17:43:56, 419.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3811.9365410862197
INFO:root:current train perplexity4.4705400466918945
INFO:root:current mean train loss 3791.5939834678106
INFO:root:current train perplexity4.4596171379089355
INFO:root:current mean train loss 3783.5638388913426
INFO:root:current train perplexity4.457278728485107
INFO:root:current mean train loss 3782.7311221289574
INFO:root:current train perplexity4.454222202301025
INFO:root:current mean train loss 3792.796693031832
INFO:root:current train perplexity4.462975025177002
INFO:root:current mean train loss 3794.7334013688624
INFO:root:current train perplexity4.4665141105651855
INFO:root:current mean train loss 3796.4378270697975
INFO:root:current train perplexity4.468329429626465
INFO:root:current mean train loss 3801.0667931957414
INFO:root:current train perplexity4.472987651824951
INFO:root:current mean train loss 3799.1516467188385
INFO:root:current train perplexity4.472898960113525
INFO:root:current mean train loss 3801.2769948002765
INFO:root:current train perplexity4.4749369621276855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.90s/it]
INFO:root:final mean train loss: 3798.2434493034116
INFO:root:final train perplexity: 4.4750471115112305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 4009.6630461131426
INFO:root:eval perplexity: 5.06011962890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 4915.470244279145
INFO:root:eval perplexity: 7.463342189788818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:42:14<17:35:50, 419.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.1241736778848
INFO:root:current train perplexity4.4325079917907715
INFO:root:current mean train loss 3792.3511534685863
INFO:root:current train perplexity4.448453426361084
INFO:root:current mean train loss 3787.397215957904
INFO:root:current train perplexity4.441150665283203
INFO:root:current mean train loss 3794.013596946931
INFO:root:current train perplexity4.44927453994751
INFO:root:current mean train loss 3796.7824135215124
INFO:root:current train perplexity4.453896999359131
INFO:root:current mean train loss 3792.609584027337
INFO:root:current train perplexity4.452819347381592
INFO:root:current mean train loss 3792.407500734895
INFO:root:current train perplexity4.456032752990723
INFO:root:current mean train loss 3790.816029082056
INFO:root:current train perplexity4.453672409057617
INFO:root:current mean train loss 3789.592257481499
INFO:root:current train perplexity4.453752040863037
INFO:root:current mean train loss 3790.6914375374463
INFO:root:current train perplexity4.4564032554626465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.71s/it]
INFO:root:final mean train loss: 3787.6583504830637
INFO:root:final train perplexity: 4.456398010253906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 4010.286165710882
INFO:root:eval perplexity: 5.061394691467285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it]
INFO:root:eval mean loss: 4920.4133266151375
INFO:root:eval perplexity: 7.478443145751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:49:16<17:30:45, 420.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3761.4506737294823
INFO:root:current train perplexity4.414295673370361
INFO:root:current mean train loss 3772.336252797189
INFO:root:current train perplexity4.428102970123291
INFO:root:current mean train loss 3771.310136163514
INFO:root:current train perplexity4.422399044036865
INFO:root:current mean train loss 3765.164021503955
INFO:root:current train perplexity4.414803981781006
INFO:root:current mean train loss 3770.9268184807115
INFO:root:current train perplexity4.4199442863464355
INFO:root:current mean train loss 3773.1724056696057
INFO:root:current train perplexity4.425540447235107
INFO:root:current mean train loss 3774.856280805727
INFO:root:current train perplexity4.428376197814941
INFO:root:current mean train loss 3778.2715384587177
INFO:root:current train perplexity4.43464469909668
INFO:root:current mean train loss 3781.7514243799533
INFO:root:current train perplexity4.440344333648682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.42s/it]
INFO:root:final mean train loss: 3778.6122136269846
INFO:root:final train perplexity: 4.440521717071533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it]
INFO:root:eval mean loss: 4007.114164311835
INFO:root:eval perplexity: 5.054905414581299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 4914.729213416999
INFO:root:eval perplexity: 7.461079120635986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:56:16<17:23:23, 420.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.191476004464
INFO:root:current train perplexity4.372466087341309
INFO:root:current mean train loss 3770.195125401577
INFO:root:current train perplexity4.404259204864502
INFO:root:current mean train loss 3781.015201587032
INFO:root:current train perplexity4.4318037033081055
INFO:root:current mean train loss 3774.0077329753663
INFO:root:current train perplexity4.422878265380859
INFO:root:current mean train loss 3768.016701138283
INFO:root:current train perplexity4.410296440124512
INFO:root:current mean train loss 3769.8052393444896
INFO:root:current train perplexity4.413482666015625
INFO:root:current mean train loss 3771.8800453047775
INFO:root:current train perplexity4.417526721954346
INFO:root:current mean train loss 3772.589971172759
INFO:root:current train perplexity4.419451713562012
INFO:root:current mean train loss 3774.5776158442727
INFO:root:current train perplexity4.421247482299805
INFO:root:current mean train loss 3772.6638735400015
INFO:root:current train perplexity4.422079563140869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.57s/it]
INFO:root:final mean train loss: 3767.9546099016743
INFO:root:final train perplexity: 4.421889781951904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.93s/it]
INFO:root:eval mean loss: 4008.384656540891
INFO:root:eval perplexity: 5.057504177093506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it]
INFO:root:eval mean loss: 4919.479424659242
INFO:root:eval perplexity: 7.475587368011475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:03:17<17:17:01, 420.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3789.454768880208
INFO:root:current train perplexity4.3994975090026855
INFO:root:current mean train loss 3770.3109077785325
INFO:root:current train perplexity4.399311065673828
INFO:root:current mean train loss 3767.9869061137356
INFO:root:current train perplexity4.406015396118164
INFO:root:current mean train loss 3763.9093060205855
INFO:root:current train perplexity4.400153160095215
INFO:root:current mean train loss 3766.7096673804595
INFO:root:current train perplexity4.406145095825195
INFO:root:current mean train loss 3766.95388823574
INFO:root:current train perplexity4.402573585510254
INFO:root:current mean train loss 3766.1107267054117
INFO:root:current train perplexity4.403210163116455
INFO:root:current mean train loss 3766.2538669826267
INFO:root:current train perplexity4.407714366912842
INFO:root:current mean train loss 3764.451768297067
INFO:root:current train perplexity4.408738136291504
INFO:root:current mean train loss 3763.1763605169913
INFO:root:current train perplexity4.408283233642578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.60s/it]
INFO:root:final mean train loss: 3758.393617691532
INFO:root:final train perplexity: 4.405241012573242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4013.262771498227
INFO:root:eval perplexity: 5.067490100860596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 4926.26998316988
INFO:root:eval perplexity: 7.496373176574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:10:16<17:09:06, 420.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3738.159285835598
INFO:root:current train perplexity4.320085048675537
INFO:root:current mean train loss 3719.3102094448677
INFO:root:current train perplexity4.333699703216553
INFO:root:current mean train loss 3738.362043030059
INFO:root:current train perplexity4.353490829467773
INFO:root:current mean train loss 3735.203801488729
INFO:root:current train perplexity4.361250877380371
INFO:root:current mean train loss 3744.12953131926
INFO:root:current train perplexity4.3700103759765625
INFO:root:current mean train loss 3747.591697444879
INFO:root:current train perplexity4.378810882568359
INFO:root:current mean train loss 3746.04412400933
INFO:root:current train perplexity4.38121223449707
INFO:root:current mean train loss 3749.3333252290804
INFO:root:current train perplexity4.3863372802734375
INFO:root:current mean train loss 3747.443604998861
INFO:root:current train perplexity4.387868881225586
INFO:root:current mean train loss 3751.532547145856
INFO:root:current train perplexity4.390866279602051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.41s/it]
INFO:root:final mean train loss: 3750.7848846681654
INFO:root:final train perplexity: 4.3920369148254395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 4008.447946102061
INFO:root:eval perplexity: 5.057632923126221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 4919.826684397163
INFO:root:eval perplexity: 7.476649761199951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:17:13<17:00:07, 419.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3773.5968293220767
INFO:root:current train perplexity4.379795551300049
INFO:root:current mean train loss 3731.814719629652
INFO:root:current train perplexity4.341984272003174
INFO:root:current mean train loss 3738.4305372362014
INFO:root:current train perplexity4.351758003234863
INFO:root:current mean train loss 3737.367358619713
INFO:root:current train perplexity4.3581624031066895
INFO:root:current mean train loss 3738.4899908008265
INFO:root:current train perplexity4.366764545440674
INFO:root:current mean train loss 3741.2496124095164
INFO:root:current train perplexity4.370006084442139
INFO:root:current mean train loss 3740.271100172717
INFO:root:current train perplexity4.367888927459717
INFO:root:current mean train loss 3741.753338147123
INFO:root:current train perplexity4.371903896331787
INFO:root:current mean train loss 3743.852100431991
INFO:root:current train perplexity4.374377250671387
INFO:root:current mean train loss 3743.905918797412
INFO:root:current train perplexity4.37405252456665

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.58s/it]
INFO:root:final mean train loss: 3741.0978831014327
INFO:root:final train perplexity: 4.375283718109131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 4009.40655127992
INFO:root:eval perplexity: 5.059595584869385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 4924.3657780640515
INFO:root:eval perplexity: 7.490538120269775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:24:15<16:54:33, 419.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3787.4115271935098
INFO:root:current train perplexity4.36042594909668
INFO:root:current mean train loss 3753.1238144250224
INFO:root:current train perplexity4.345118522644043
INFO:root:current mean train loss 3742.283768019417
INFO:root:current train perplexity4.339858055114746
INFO:root:current mean train loss 3734.363626215662
INFO:root:current train perplexity4.3448967933654785
INFO:root:current mean train loss 3739.6569117934937
INFO:root:current train perplexity4.349757194519043
INFO:root:current mean train loss 3739.960761302035
INFO:root:current train perplexity4.353701591491699
INFO:root:current mean train loss 3737.7068631406496
INFO:root:current train perplexity4.354280471801758
INFO:root:current mean train loss 3735.6197973930143
INFO:root:current train perplexity4.356222629547119
INFO:root:current mean train loss 3734.012685127849
INFO:root:current train perplexity4.3576154708862305
INFO:root:current mean train loss 3736.047192720813
INFO:root:current train perplexity4.362092018127441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.34s/it]
INFO:root:final mean train loss: 3733.005308458882
INFO:root:final train perplexity: 4.361337184906006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 4008.930520348515
INFO:root:eval perplexity: 5.058621406555176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.79s/it]
INFO:root:eval mean loss: 4929.203547484486
INFO:root:eval perplexity: 7.505372047424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:31:15<16:47:55, 419.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.0787015874334
INFO:root:current train perplexity4.341742992401123
INFO:root:current mean train loss 3722.242293792517
INFO:root:current train perplexity4.325840473175049
INFO:root:current mean train loss 3713.3154494559717
INFO:root:current train perplexity4.3376007080078125
INFO:root:current mean train loss 3715.059023634501
INFO:root:current train perplexity4.338485240936279
INFO:root:current mean train loss 3714.3269900464907
INFO:root:current train perplexity4.338537216186523
INFO:root:current mean train loss 3715.6873031699897
INFO:root:current train perplexity4.336484909057617
INFO:root:current mean train loss 3717.237303932815
INFO:root:current train perplexity4.340576171875
INFO:root:current mean train loss 3723.259093666332
INFO:root:current train perplexity4.344444751739502
INFO:root:current mean train loss 3724.6887368446537
INFO:root:current train perplexity4.34772253036499
INFO:root:current mean train loss 3726.4061945720864
INFO:root:current train perplexity4.348299503326416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it]
INFO:root:final mean train loss: 3725.339082779423
INFO:root:final train perplexity: 4.348165988922119
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 4010.4691586325353
INFO:root:eval perplexity: 5.061769485473633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 4929.53038771609
INFO:root:eval perplexity: 7.506375789642334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:38:16<16:41:28, 420.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3709.5250088778407
INFO:root:current train perplexity4.332577705383301
INFO:root:current mean train loss 3708.9192430065523
INFO:root:current train perplexity4.326207160949707
INFO:root:current mean train loss 3712.620733762255
INFO:root:current train perplexity4.32415246963501
INFO:root:current mean train loss 3710.6734808263645
INFO:root:current train perplexity4.317246437072754
INFO:root:current mean train loss 3711.9452727936127
INFO:root:current train perplexity4.319705486297607
INFO:root:current mean train loss 3714.105838700028
INFO:root:current train perplexity4.3214945793151855
INFO:root:current mean train loss 3715.336481318583
INFO:root:current train perplexity4.327086448669434
INFO:root:current mean train loss 3718.646165537045
INFO:root:current train perplexity4.329832553863525
INFO:root:current mean train loss 3717.7451651589913
INFO:root:current train perplexity4.327549457550049
INFO:root:current mean train loss 3718.2001467400196
INFO:root:current train perplexity4.330943584442139

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.75s/it]
INFO:root:final mean train loss: 3715.884340347782
INFO:root:final train perplexity: 4.331975936889648
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 4005.5581175892066
INFO:root:eval perplexity: 5.051726818084717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 4930.665906540891
INFO:root:eval perplexity: 7.509861469268799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:45:15<16:33:45, 419.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3692.734343998016
INFO:root:current train perplexity4.305486679077148
INFO:root:current mean train loss 3706.3613251294096
INFO:root:current train perplexity4.306785583496094
INFO:root:current mean train loss 3711.684705843037
INFO:root:current train perplexity4.314420223236084
INFO:root:current mean train loss 3707.4487654420627
INFO:root:current train perplexity4.310155868530273
INFO:root:current mean train loss 3710.9654396007695
INFO:root:current train perplexity4.3149542808532715
INFO:root:current mean train loss 3709.5036187451433
INFO:root:current train perplexity4.314111232757568
INFO:root:current mean train loss 3708.2713746406016
INFO:root:current train perplexity4.315150737762451
INFO:root:current mean train loss 3711.658019459576
INFO:root:current train perplexity4.31735372543335
INFO:root:current mean train loss 3711.633687502263
INFO:root:current train perplexity4.316859722137451
INFO:root:current mean train loss 3710.706986376801
INFO:root:current train perplexity4.316799640655518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.46s/it]
INFO:root:final mean train loss: 3707.3277717713386
INFO:root:final train perplexity: 4.317377090454102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it]
INFO:root:eval mean loss: 4005.76894254211
INFO:root:eval perplexity: 5.052157878875732
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 4928.408081920435
INFO:root:eval perplexity: 7.502931594848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:52:14<16:25:58, 419.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3685.738346583407
INFO:root:current train perplexity4.296163558959961
INFO:root:current mean train loss 3686.2142512449745
INFO:root:current train perplexity4.294716835021973
INFO:root:current mean train loss 3703.2620088359085
INFO:root:current train perplexity4.292812824249268
INFO:root:current mean train loss 3702.4380448744946
INFO:root:current train perplexity4.297666072845459
INFO:root:current mean train loss 3698.2984761685575
INFO:root:current train perplexity4.2929606437683105
INFO:root:current mean train loss 3699.0064023847963
INFO:root:current train perplexity4.295175552368164
INFO:root:current mean train loss 3701.9158933727645
INFO:root:current train perplexity4.299883842468262
INFO:root:current mean train loss 3700.7356447845737
INFO:root:current train perplexity4.300741672515869
INFO:root:current mean train loss 3699.7255416502226
INFO:root:current train perplexity4.301345348358154
INFO:root:current mean train loss 3702.2248283724093
INFO:root:current train perplexity4.30380392074585

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.50s/it]
INFO:root:final mean train loss: 3699.4082340117425
INFO:root:final train perplexity: 4.303908348083496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 4004.846748947252
INFO:root:eval perplexity: 5.050273895263672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 4930.11464566711
INFO:root:eval perplexity: 7.508169651031494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [6:59:19<16:22:51, 421.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3681.8495321153086
INFO:root:current train perplexity4.279687404632568
INFO:root:current mean train loss 3666.5851218793646
INFO:root:current train perplexity4.2595624923706055
INFO:root:current mean train loss 3670.8851795264895
INFO:root:current train perplexity4.255446434020996
INFO:root:current mean train loss 3678.2374998711657
INFO:root:current train perplexity4.263000011444092
INFO:root:current mean train loss 3679.465920721066
INFO:root:current train perplexity4.270480632781982
INFO:root:current mean train loss 3683.36765680659
INFO:root:current train perplexity4.273549556732178
INFO:root:current mean train loss 3687.263537759458
INFO:root:current train perplexity4.281232833862305
INFO:root:current mean train loss 3689.996658814887
INFO:root:current train perplexity4.285090923309326
INFO:root:current mean train loss 3690.8737706866823
INFO:root:current train perplexity4.286596775054932
INFO:root:current mean train loss 3692.4305156828555
INFO:root:current train perplexity4.2886061668396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.90s/it]
INFO:root:final mean train loss: 3690.7846131478586
INFO:root:final train perplexity: 4.289290428161621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 4003.8506257618574
INFO:root:eval perplexity: 5.048239707946777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it]
INFO:root:eval mean loss: 4931.777058053524
INFO:root:eval perplexity: 7.513274669647217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [7:06:20<16:15:35, 421.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3638.2995072288077
INFO:root:current train perplexity4.221634864807129
INFO:root:current mean train loss 3658.2155905330883
INFO:root:current train perplexity4.25056266784668
INFO:root:current mean train loss 3649.6367987124345
INFO:root:current train perplexity4.245110034942627
INFO:root:current mean train loss 3652.3882756984817
INFO:root:current train perplexity4.250916957855225
INFO:root:current mean train loss 3665.099261963392
INFO:root:current train perplexity4.256917476654053
INFO:root:current mean train loss 3672.9384083528535
INFO:root:current train perplexity4.261675834655762
INFO:root:current mean train loss 3674.6324429130277
INFO:root:current train perplexity4.264053821563721
INFO:root:current mean train loss 3681.2937998208185
INFO:root:current train perplexity4.269091606140137
INFO:root:current mean train loss 3685.141511007522
INFO:root:current train perplexity4.27347993850708
INFO:root:current mean train loss 3686.691023342515
INFO:root:current train perplexity4.277231216430664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.50s/it]
INFO:root:final mean train loss: 3683.3740135315925
INFO:root:final train perplexity: 4.276768207550049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4003.815015860483
INFO:root:eval perplexity: 5.048166275024414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 4931.891573858599
INFO:root:eval perplexity: 7.513625621795654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [7:13:17<16:06:06, 420.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.909544613487
INFO:root:current train perplexity4.239147186279297
INFO:root:current mean train loss 3682.891328625801
INFO:root:current train perplexity4.247821807861328
INFO:root:current mean train loss 3678.5935563426906
INFO:root:current train perplexity4.247125148773193
INFO:root:current mean train loss 3673.814591574367
INFO:root:current train perplexity4.249349117279053
INFO:root:current mean train loss 3673.683905954072
INFO:root:current train perplexity4.249223709106445
INFO:root:current mean train loss 3673.9805286567753
INFO:root:current train perplexity4.254230976104736
INFO:root:current mean train loss 3674.0912218272256
INFO:root:current train perplexity4.256785869598389
INFO:root:current mean train loss 3679.8851679196146
INFO:root:current train perplexity4.260974884033203
INFO:root:current mean train loss 3678.1967413364177
INFO:root:current train perplexity4.261205196380615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.23s/it]
INFO:root:final mean train loss: 3675.1025045456427
INFO:root:final train perplexity: 4.262834072113037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 4002.449597947141
INFO:root:eval perplexity: 5.045380592346191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 29.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 29.00s/it]
INFO:root:eval mean loss: 4933.789381094858
INFO:root:eval perplexity: 7.519459247589111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:20:17<15:58:46, 419.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3463.5638020833335
INFO:root:current train perplexity4.123835563659668
INFO:root:current mean train loss 3647.7337255385314
INFO:root:current train perplexity4.236379623413086
INFO:root:current mean train loss 3657.9598214285716
INFO:root:current train perplexity4.227423667907715
INFO:root:current mean train loss 3654.121967982931
INFO:root:current train perplexity4.2347283363342285
INFO:root:current mean train loss 3654.8050909681297
INFO:root:current train perplexity4.2334089279174805
INFO:root:current mean train loss 3657.4491609910847
INFO:root:current train perplexity4.237119197845459
INFO:root:current mean train loss 3663.425553304441
INFO:root:current train perplexity4.241853713989258
INFO:root:current mean train loss 3668.3115706681187
INFO:root:current train perplexity4.246562480926514
INFO:root:current mean train loss 3672.1616058919676
INFO:root:current train perplexity4.24887228012085
INFO:root:current mean train loss 3670.031295962244
INFO:root:current train perplexity4.249643802642822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.79s/it]
INFO:root:final mean train loss: 3667.621456638459
INFO:root:final train perplexity: 4.250270843505859
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 4005.045983280696
INFO:root:eval perplexity: 5.050680637359619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 4932.694843265182
INFO:root:eval perplexity: 7.51609468460083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:27:18<15:52:48, 420.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3673.135076349432
INFO:root:current train perplexity4.15118932723999
INFO:root:current mean train loss 3642.8244804863457
INFO:root:current train perplexity4.207371234893799
INFO:root:current mean train loss 3655.017119927429
INFO:root:current train perplexity4.220134258270264
INFO:root:current mean train loss 3644.324002870026
INFO:root:current train perplexity4.216474533081055
INFO:root:current mean train loss 3650.796335633364
INFO:root:current train perplexity4.222254753112793
INFO:root:current mean train loss 3650.878815951413
INFO:root:current train perplexity4.219489574432373
INFO:root:current mean train loss 3651.8997385177986
INFO:root:current train perplexity4.224349021911621
INFO:root:current mean train loss 3654.3509821938733
INFO:root:current train perplexity4.226585388183594
INFO:root:current mean train loss 3659.0850771376004
INFO:root:current train perplexity4.230123996734619
INFO:root:current mean train loss 3658.218730704583
INFO:root:current train perplexity4.230928897857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.44s/it]
INFO:root:final mean train loss: 3660.257365195982
INFO:root:final train perplexity: 4.237940311431885
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.91s/it]
INFO:root:eval mean loss: 4002.586908868019
INFO:root:eval perplexity: 5.045660495758057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 4936.269209192154
INFO:root:eval perplexity: 7.527087688446045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:34:14<15:42:31, 418.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3638.6128058182567
INFO:root:current train perplexity4.240360260009766
INFO:root:current mean train loss 3628.7397358357407
INFO:root:current train perplexity4.197160720825195
INFO:root:current mean train loss 3635.1428066584617
INFO:root:current train perplexity4.204604625701904
INFO:root:current mean train loss 3642.446464323325
INFO:root:current train perplexity4.208984375
INFO:root:current mean train loss 3638.875434675194
INFO:root:current train perplexity4.2078938484191895
INFO:root:current mean train loss 3642.689447009724
INFO:root:current train perplexity4.208590030670166
INFO:root:current mean train loss 3651.0877632301344
INFO:root:current train perplexity4.217738628387451
INFO:root:current mean train loss 3657.0710194551893
INFO:root:current train perplexity4.224040508270264
INFO:root:current mean train loss 3658.2857124971383
INFO:root:current train perplexity4.225460529327393
INFO:root:current mean train loss 3657.046377952003
INFO:root:current train perplexity4.227726936340332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.65s/it]
INFO:root:final mean train loss: 3654.936940531577
INFO:root:final train perplexity: 4.2290544509887695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 4002.5126295157356
INFO:root:eval perplexity: 5.0455098152160645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it]
INFO:root:eval mean loss: 4934.924811613475
INFO:root:eval perplexity: 7.522952079772949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:41:11<15:34:16, 418.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3705.5583405671296
INFO:root:current train perplexity4.2733612060546875
INFO:root:current mean train loss 3652.966045229454
INFO:root:current train perplexity4.210000038146973
INFO:root:current mean train loss 3643.6097482017485
INFO:root:current train perplexity4.203736305236816
INFO:root:current mean train loss 3644.212350081231
INFO:root:current train perplexity4.202356815338135
INFO:root:current mean train loss 3644.4771902901784
INFO:root:current train perplexity4.2073493003845215
INFO:root:current mean train loss 3648.0365516040088
INFO:root:current train perplexity4.209672927856445
INFO:root:current mean train loss 3646.024452221641
INFO:root:current train perplexity4.2071075439453125
INFO:root:current mean train loss 3643.8963678457058
INFO:root:current train perplexity4.205810546875
INFO:root:current mean train loss 3645.20027147729
INFO:root:current train perplexity4.206826210021973
INFO:root:current mean train loss 3646.210088406823
INFO:root:current train perplexity4.212384223937988

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.34s/it]
INFO:root:final mean train loss: 3645.483298763152
INFO:root:final train perplexity: 4.2133097648620605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 4005.3361833721187
INFO:root:eval perplexity: 5.051273822784424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 4938.4450129515735
INFO:root:eval perplexity: 7.533788204193115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:48:10<15:28:16, 418.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3641.205580357143
INFO:root:current train perplexity4.208481311798096
INFO:root:current mean train loss 3627.0259620949073
INFO:root:current train perplexity4.155893325805664
INFO:root:current mean train loss 3631.5066042636304
INFO:root:current train perplexity4.168457508087158
INFO:root:current mean train loss 3639.7017293901586
INFO:root:current train perplexity4.1869354248046875
INFO:root:current mean train loss 3637.080373338721
INFO:root:current train perplexity4.185716152191162
INFO:root:current mean train loss 3639.425004563376
INFO:root:current train perplexity4.191079139709473
INFO:root:current mean train loss 3640.8159871739667
INFO:root:current train perplexity4.192785739898682
INFO:root:current mean train loss 3640.257527835353
INFO:root:current train perplexity4.19701623916626
INFO:root:current mean train loss 3641.038798477264
INFO:root:current train perplexity4.200690269470215
INFO:root:current mean train loss 3642.7397714217077
INFO:root:current train perplexity4.202070236206055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.16s/it]
INFO:root:final mean train loss: 3638.9853583920385
INFO:root:final train perplexity: 4.202522277832031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 4005.129555560173
INFO:root:eval perplexity: 5.050851345062256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 4941.832980108599
INFO:root:eval perplexity: 7.5442328453063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [7:55:07<15:19:40, 418.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3633.4637649890988
INFO:root:current train perplexity4.169644832611084
INFO:root:current mean train loss 3612.166229034637
INFO:root:current train perplexity4.179884433746338
INFO:root:current mean train loss 3615.7826224119085
INFO:root:current train perplexity4.173059463500977
INFO:root:current mean train loss 3617.8901836962464
INFO:root:current train perplexity4.172791957855225
INFO:root:current mean train loss 3625.08567241729
INFO:root:current train perplexity4.176938533782959
INFO:root:current mean train loss 3628.282662238864
INFO:root:current train perplexity4.179269790649414
INFO:root:current mean train loss 3632.839267760376
INFO:root:current train perplexity4.185912132263184
INFO:root:current mean train loss 3633.7703573193558
INFO:root:current train perplexity4.1886749267578125
INFO:root:current mean train loss 3635.5254013405433
INFO:root:current train perplexity4.189877986907959
INFO:root:current mean train loss 3633.9116529381795
INFO:root:current train perplexity4.191008567810059

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.03s/it]
INFO:root:final mean train loss: 3632.1598990040443
INFO:root:final train perplexity: 4.191221237182617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it]
INFO:root:eval mean loss: 4004.3712980662676
INFO:root:eval perplexity: 5.049302101135254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it]
INFO:root:eval mean loss: 4943.164862450133
INFO:root:eval perplexity: 7.548342227935791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [8:02:07<15:14:17, 418.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.078297334559
INFO:root:current train perplexity4.127988815307617
INFO:root:current mean train loss 3617.639488371792
INFO:root:current train perplexity4.165103435516357
INFO:root:current mean train loss 3628.6412659907246
INFO:root:current train perplexity4.177426815032959
INFO:root:current mean train loss 3628.1198292267627
INFO:root:current train perplexity4.175745487213135
INFO:root:current mean train loss 3633.9709938201568
INFO:root:current train perplexity4.18363618850708
INFO:root:current mean train loss 3632.0719395133847
INFO:root:current train perplexity4.183585166931152
INFO:root:current mean train loss 3629.6042859242993
INFO:root:current train perplexity4.1786603927612305
INFO:root:current mean train loss 3625.27991811699
INFO:root:current train perplexity4.176712989807129
INFO:root:current mean train loss 3625.8412142080088
INFO:root:current train perplexity4.177065849304199
INFO:root:current mean train loss 3627.094040093487
INFO:root:current train perplexity4.1783976554870605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.08s/it]
INFO:root:final mean train loss: 3625.57655771317
INFO:root:final train perplexity: 4.180349826812744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it]
INFO:root:eval mean loss: 4004.4074152953235
INFO:root:eval perplexity: 5.049376964569092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 4943.404612006871
INFO:root:eval perplexity: 7.549083709716797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [8:09:03<15:05:25, 417.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3621.1291131488347
INFO:root:current train perplexity4.164527893066406
INFO:root:current mean train loss 3628.863227508353
INFO:root:current train perplexity4.166420936584473
INFO:root:current mean train loss 3621.235615498311
INFO:root:current train perplexity4.164346218109131
INFO:root:current mean train loss 3619.8600264950383
INFO:root:current train perplexity4.167276382446289
INFO:root:current mean train loss 3615.353236379187
INFO:root:current train perplexity4.165078639984131
INFO:root:current mean train loss 3617.747406606384
INFO:root:current train perplexity4.169547080993652
INFO:root:current mean train loss 3612.9977982887185
INFO:root:current train perplexity4.162506103515625
INFO:root:current mean train loss 3621.111638849432
INFO:root:current train perplexity4.164699077606201
INFO:root:current mean train loss 3619.456620559426
INFO:root:current train perplexity4.16494607925415
INFO:root:current mean train loss 3622.034200308345
INFO:root:current train perplexity4.168780326843262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.64s/it]
INFO:root:final mean train loss: 3618.754405975342
INFO:root:final train perplexity: 4.169112682342529
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 4006.5450032552085
INFO:root:eval perplexity: 5.053743362426758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 4950.6274275543
INFO:root:eval perplexity: 7.571414947509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [8:16:08<15:03:16, 420.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3600.6941245918842
INFO:root:current train perplexity4.137082576751709
INFO:root:current mean train loss 3598.8914173605913
INFO:root:current train perplexity4.125954627990723
INFO:root:current mean train loss 3610.5014008368444
INFO:root:current train perplexity4.139033794403076
INFO:root:current mean train loss 3603.402428899864
INFO:root:current train perplexity4.139158725738525
INFO:root:current mean train loss 3605.703304315277
INFO:root:current train perplexity4.1407670974731445
INFO:root:current mean train loss 3609.6712196525023
INFO:root:current train perplexity4.147096633911133
INFO:root:current mean train loss 3613.1795839140977
INFO:root:current train perplexity4.151973724365234
INFO:root:current mean train loss 3613.8472430889424
INFO:root:current train perplexity4.155998706817627
INFO:root:current mean train loss 3614.1998911926903
INFO:root:current train perplexity4.154923915863037
INFO:root:current mean train loss 3614.0732187075846
INFO:root:current train perplexity4.156927108764648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.60s/it]
INFO:root:final mean train loss: 3611.5908209277736
INFO:root:final train perplexity: 4.157347202301025
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it]
INFO:root:eval mean loss: 4008.42020930297
INFO:root:eval perplexity: 5.057577133178711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 4954.985536832336
INFO:root:eval perplexity: 7.584917068481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:23:06<14:54:45, 419.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3605.4246647135415
INFO:root:current train perplexity4.1687331199646
INFO:root:current mean train loss 3605.35578125
INFO:root:current train perplexity4.148768424987793
INFO:root:current mean train loss 3612.6631844815342
INFO:root:current train perplexity4.1493096351623535
INFO:root:current mean train loss 3609.5435475260415
INFO:root:current train perplexity4.142604827880859
INFO:root:current mean train loss 3606.228634868421
INFO:root:current train perplexity4.142880916595459
INFO:root:current mean train loss 3606.8879369055708
INFO:root:current train perplexity4.1420135498046875
INFO:root:current mean train loss 3604.5700231481483
INFO:root:current train perplexity4.1421918869018555
INFO:root:current mean train loss 3604.156064453125
INFO:root:current train perplexity4.143136978149414
INFO:root:current mean train loss 3608.015474330357
INFO:root:current train perplexity4.145748138427734
INFO:root:current mean train loss 3607.030430438702
INFO:root:current train perplexity4.145631790161133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.45s/it]
INFO:root:final mean train loss: 3604.421646425801
INFO:root:final train perplexity: 4.145604133605957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 4008.946635361259
INFO:root:eval perplexity: 5.058652877807617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 4956.771089594415
INFO:root:eval perplexity: 7.590457916259766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:30:14<14:53:22, 422.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3574.4130359327937
INFO:root:current train perplexity4.108482360839844
INFO:root:current mean train loss 3586.1299668609117
INFO:root:current train perplexity4.108370304107666
INFO:root:current mean train loss 3597.9670323887476
INFO:root:current train perplexity4.12453031539917
INFO:root:current mean train loss 3604.246509362761
INFO:root:current train perplexity4.1265668869018555
INFO:root:current mean train loss 3607.036017060527
INFO:root:current train perplexity4.131518840789795
INFO:root:current mean train loss 3608.313873133978
INFO:root:current train perplexity4.13491153717041
INFO:root:current mean train loss 3608.0605257852535
INFO:root:current train perplexity4.136136531829834
INFO:root:current mean train loss 3607.4055945931113
INFO:root:current train perplexity4.135128498077393
INFO:root:current mean train loss 3604.799875468927
INFO:root:current train perplexity4.134397983551025
INFO:root:current mean train loss 3601.4300424104304
INFO:root:current train perplexity4.136099338531494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.38s/it]
INFO:root:final mean train loss: 3597.876962169524
INFO:root:final train perplexity: 4.134914398193359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 4007.4750439799423
INFO:root:eval perplexity: 5.055644512176514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 4954.286472185284
INFO:root:eval perplexity: 7.582748889923096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:37:14<14:44:40, 421.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3580.978816105769
INFO:root:current train perplexity4.072968006134033
INFO:root:current mean train loss 3593.3197730898232
INFO:root:current train perplexity4.0938286781311035
INFO:root:current mean train loss 3593.1974694950063
INFO:root:current train perplexity4.104862689971924
INFO:root:current mean train loss 3597.2440962925593
INFO:root:current train perplexity4.113557815551758
INFO:root:current mean train loss 3595.0921469259165
INFO:root:current train perplexity4.113945007324219
INFO:root:current mean train loss 3594.9820723945113
INFO:root:current train perplexity4.114444732666016
INFO:root:current mean train loss 3593.602482532109
INFO:root:current train perplexity4.116865634918213
INFO:root:current mean train loss 3593.0731461979494
INFO:root:current train perplexity4.116631031036377
INFO:root:current mean train loss 3593.565540386504
INFO:root:current train perplexity4.120528697967529
INFO:root:current mean train loss 3593.789519001088
INFO:root:current train perplexity4.123810768127441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.98s/it]
INFO:root:final mean train loss: 3591.0440248673963
INFO:root:final train perplexity: 4.123782157897949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 4008.1058600675974
INFO:root:eval perplexity: 5.056934356689453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 4956.915712613586
INFO:root:eval perplexity: 7.590907096862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:44:12<14:35:55, 420.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.6433623342805
INFO:root:current train perplexity4.074140548706055
INFO:root:current mean train loss 3569.424391243326
INFO:root:current train perplexity4.097949981689453
INFO:root:current mean train loss 3572.8353740985576
INFO:root:current train perplexity4.099815845489502
INFO:root:current mean train loss 3570.9688264851584
INFO:root:current train perplexity4.096665382385254
INFO:root:current mean train loss 3576.408897873873
INFO:root:current train perplexity4.098963260650635
INFO:root:current mean train loss 3578.8648814104235
INFO:root:current train perplexity4.103146076202393
INFO:root:current mean train loss 3585.0818615041576
INFO:root:current train perplexity4.109345436096191
INFO:root:current mean train loss 3589.2316818141817
INFO:root:current train perplexity4.113080978393555
INFO:root:current mean train loss 3588.4964036103484
INFO:root:current train perplexity4.114067554473877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.39s/it]
INFO:root:final mean train loss: 3585.1254114950857
INFO:root:final train perplexity: 4.114163875579834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4008.2599283854165
INFO:root:eval perplexity: 5.057248592376709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.96s/it]
INFO:root:eval mean loss: 4957.839189245346
INFO:root:eval perplexity: 7.593774318695068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:51:10<14:27:16, 419.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3528.6296037946427
INFO:root:current train perplexity4.074992656707764
INFO:root:current mean train loss 3600.854946243429
INFO:root:current train perplexity4.097972393035889
INFO:root:current mean train loss 3581.382619074577
INFO:root:current train perplexity4.092778205871582
INFO:root:current mean train loss 3577.561241125051
INFO:root:current train perplexity4.0993266105651855
INFO:root:current mean train loss 3574.7768842617475
INFO:root:current train perplexity4.100653171539307
INFO:root:current mean train loss 3576.220661712586
INFO:root:current train perplexity4.100424289703369
INFO:root:current mean train loss 3576.429216915929
INFO:root:current train perplexity4.097750186920166
INFO:root:current mean train loss 3579.3929669543404
INFO:root:current train perplexity4.098855495452881
INFO:root:current mean train loss 3583.4995779725255
INFO:root:current train perplexity4.102871417999268
INFO:root:current mean train loss 3583.8004959257855
INFO:root:current train perplexity4.1045732498168945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.92s/it]
INFO:root:final mean train loss: 3579.8541739679154
INFO:root:final train perplexity: 4.105617523193359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it]
INFO:root:eval mean loss: 4010.0019133006426
INFO:root:eval perplexity: 5.060811996459961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 4959.367035128546
INFO:root:eval perplexity: 7.598519325256348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [8:58:07<14:18:49, 418.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3535.1978678385417
INFO:root:current train perplexity4.062427997589111
INFO:root:current mean train loss 3563.2011761209237
INFO:root:current train perplexity4.077785015106201
INFO:root:current mean train loss 3564.4977118913516
INFO:root:current train perplexity4.07969856262207
INFO:root:current mean train loss 3571.071227058532
INFO:root:current train perplexity4.076812267303467
INFO:root:current mean train loss 3566.0895754894577
INFO:root:current train perplexity4.076744556427002
INFO:root:current mean train loss 3571.8683119690536
INFO:root:current train perplexity4.081864356994629
INFO:root:current mean train loss 3577.4849791984248
INFO:root:current train perplexity4.089813232421875
INFO:root:current mean train loss 3573.774921123798
INFO:root:current train perplexity4.086400985717773
INFO:root:current mean train loss 3574.3916788487345
INFO:root:current train perplexity4.092599868774414
INFO:root:current mean train loss 3576.6340465441426
INFO:root:current train perplexity4.094383716583252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.11s/it]
INFO:root:final mean train loss: 3573.310280461465
INFO:root:final train perplexity: 4.095031261444092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it]
INFO:root:eval mean loss: 4008.143622215758
INFO:root:eval perplexity: 5.057011127471924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 4958.7705078125
INFO:root:eval perplexity: 7.59666633605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [9:05:06<14:11:40, 418.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3510.1063179347825
INFO:root:current train perplexity4.006693363189697
INFO:root:current mean train loss 3533.4428512449185
INFO:root:current train perplexity4.043140411376953
INFO:root:current mean train loss 3531.972488745446
INFO:root:current train perplexity4.052575588226318
INFO:root:current mean train loss 3542.1773231907896
INFO:root:current train perplexity4.063779830932617
INFO:root:current mean train loss 3547.341653161015
INFO:root:current train perplexity4.06654167175293
INFO:root:current mean train loss 3552.588588036269
INFO:root:current train perplexity4.069021224975586
INFO:root:current mean train loss 3557.6008774954857
INFO:root:current train perplexity4.073905944824219
INFO:root:current mean train loss 3561.9946677391295
INFO:root:current train perplexity4.078072547912598
INFO:root:current mean train loss 3567.882551747133
INFO:root:current train perplexity4.084435939788818
INFO:root:current mean train loss 3570.036783236982
INFO:root:current train perplexity4.0846662521362305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.85s/it]
INFO:root:final mean train loss: 3567.299269645445
INFO:root:final train perplexity: 4.085331439971924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 4009.9100575548537
INFO:root:eval perplexity: 5.060624599456787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it]
INFO:root:eval mean loss: 4961.242119971742
INFO:root:eval perplexity: 7.6043477058410645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [9:12:05<14:04:37, 418.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3566.4846900201615
INFO:root:current train perplexity4.087439060211182
INFO:root:current mean train loss 3558.8467225518843
INFO:root:current train perplexity4.077033519744873
INFO:root:current mean train loss 3561.163379751759
INFO:root:current train perplexity4.055663585662842
INFO:root:current mean train loss 3556.659184850595
INFO:root:current train perplexity4.056908130645752
INFO:root:current mean train loss 3552.6019221967445
INFO:root:current train perplexity4.056321144104004
INFO:root:current mean train loss 3551.4212887866347
INFO:root:current train perplexity4.054080486297607
INFO:root:current mean train loss 3556.273869292294
INFO:root:current train perplexity4.060647487640381
INFO:root:current mean train loss 3560.84797787438
INFO:root:current train perplexity4.067066192626953
INFO:root:current mean train loss 3561.605977890437
INFO:root:current train perplexity4.070714473724365
INFO:root:current mean train loss 3560.7863879669876
INFO:root:current train perplexity4.071338176727295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.62s/it]
INFO:root:final mean train loss: 3559.974718278454
INFO:root:final train perplexity: 4.073542594909668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 4014.502349637079
INFO:root:eval perplexity: 5.070030212402344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it]
INFO:root:eval mean loss: 4966.801788979388
INFO:root:eval perplexity: 7.621652603149414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [9:19:03<13:57:29, 418.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3557.4876802884614
INFO:root:current train perplexity4.051562786102295
INFO:root:current mean train loss 3560.641053563399
INFO:root:current train perplexity4.058234214782715
INFO:root:current mean train loss 3556.0616960725024
INFO:root:current train perplexity4.060309410095215
INFO:root:current mean train loss 3567.671897325544
INFO:root:current train perplexity4.061614990234375
INFO:root:current mean train loss 3565.4583170202163
INFO:root:current train perplexity4.063043117523193
INFO:root:current mean train loss 3561.453989230635
INFO:root:current train perplexity4.063737869262695
INFO:root:current mean train loss 3557.2911993990856
INFO:root:current train perplexity4.061225891113281
INFO:root:current mean train loss 3554.55565712481
INFO:root:current train perplexity4.060632228851318
INFO:root:current mean train loss 3554.9525470938247
INFO:root:current train perplexity4.063056945800781
INFO:root:current mean train loss 3556.2746392230765
INFO:root:current train perplexity4.063037395477295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it]
INFO:root:final mean train loss: 3553.6627684562436
INFO:root:final train perplexity: 4.063411235809326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 4011.817718722296
INFO:root:eval perplexity: 5.064530372619629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it]
INFO:root:eval mean loss: 4970.01492201352
INFO:root:eval perplexity: 7.631673336029053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [9:26:02<13:50:33, 418.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.0001973902927
INFO:root:current train perplexity4.0701093673706055
INFO:root:current mean train loss 3519.7607471699616
INFO:root:current train perplexity4.0429229736328125
INFO:root:current mean train loss 3524.722821316738
INFO:root:current train perplexity4.039044380187988
INFO:root:current mean train loss 3533.43039529674
INFO:root:current train perplexity4.045053005218506
INFO:root:current mean train loss 3540.3605465472947
INFO:root:current train perplexity4.042031288146973
INFO:root:current mean train loss 3545.107340197241
INFO:root:current train perplexity4.047030448913574
INFO:root:current mean train loss 3546.8939146722855
INFO:root:current train perplexity4.046821117401123
INFO:root:current mean train loss 3549.5378349334837
INFO:root:current train perplexity4.048928737640381
INFO:root:current mean train loss 3548.7381521177685
INFO:root:current train perplexity4.050477027893066
INFO:root:current mean train loss 3550.502747419895
INFO:root:current train perplexity4.054240703582764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.97s/it]
INFO:root:final mean train loss: 3548.838690726988
INFO:root:final train perplexity: 4.055684566497803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 4010.459652731605
INFO:root:eval perplexity: 5.061749458312988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it]
INFO:root:eval mean loss: 4965.944574883643
INFO:root:eval perplexity: 7.618985652923584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:33:01<13:43:17, 418.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.1734818892046
INFO:root:current train perplexity4.043179988861084
INFO:root:current mean train loss 3530.520588142641
INFO:root:current train perplexity4.045424938201904
INFO:root:current mean train loss 3527.887957643995
INFO:root:current train perplexity4.037252426147461
INFO:root:current mean train loss 3527.915534908671
INFO:root:current train perplexity4.028866291046143
INFO:root:current mean train loss 3535.6937945355426
INFO:root:current train perplexity4.033267974853516
INFO:root:current mean train loss 3540.8242117117115
INFO:root:current train perplexity4.0388031005859375
INFO:root:current mean train loss 3540.574946326336
INFO:root:current train perplexity4.041823387145996
INFO:root:current mean train loss 3542.483288170012
INFO:root:current train perplexity4.044806003570557
INFO:root:current mean train loss 3545.758777355172
INFO:root:current train perplexity4.045607089996338
INFO:root:current mean train loss 3546.2248161915086
INFO:root:current train perplexity4.047293186187744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it]
INFO:root:final mean train loss: 3542.7102488856162
INFO:root:final train perplexity: 4.0458903312683105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 4012.30297158965
INFO:root:eval perplexity: 5.065523624420166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 4970.561213500111
INFO:root:eval perplexity: 7.63338041305542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:40:00<13:36:50, 418.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3496.351256355407
INFO:root:current train perplexity3.990649700164795
INFO:root:current mean train loss 3508.132328712136
INFO:root:current train perplexity4.007761001586914
INFO:root:current mean train loss 3516.1399900487168
INFO:root:current train perplexity4.01084566116333
INFO:root:current mean train loss 3530.4057610461864
INFO:root:current train perplexity4.0239386558532715
INFO:root:current mean train loss 3530.2465598845843
INFO:root:current train perplexity4.025378227233887
INFO:root:current mean train loss 3534.570163327043
INFO:root:current train perplexity4.031189918518066
INFO:root:current mean train loss 3533.249238487462
INFO:root:current train perplexity4.030121326446533
INFO:root:current mean train loss 3534.548597743283
INFO:root:current train perplexity4.030802249908447
INFO:root:current mean train loss 3535.4883081252715
INFO:root:current train perplexity4.032177925109863
INFO:root:current mean train loss 3536.674897222628
INFO:root:current train perplexity4.031787872314453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.43s/it]
INFO:root:final mean train loss: 3535.182619956232
INFO:root:final train perplexity: 4.0338921546936035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 4018.507047179743
INFO:root:eval perplexity: 5.0782470703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it]
INFO:root:eval mean loss: 4977.658857629654
INFO:root:eval perplexity: 7.655566692352295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:47:01<13:30:51, 419.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.5699927101673
INFO:root:current train perplexity3.9953525066375732
INFO:root:current mean train loss 3508.7057620042947
INFO:root:current train perplexity4.008082866668701
INFO:root:current mean train loss 3508.483326366467
INFO:root:current train perplexity4.007613658905029
INFO:root:current mean train loss 3523.615644346993
INFO:root:current train perplexity4.016993045806885
INFO:root:current mean train loss 3525.123499908771
INFO:root:current train perplexity4.02254056930542
INFO:root:current mean train loss 3522.3653442596597
INFO:root:current train perplexity4.017487525939941
INFO:root:current mean train loss 3524.528339960181
INFO:root:current train perplexity4.01958703994751
INFO:root:current mean train loss 3529.5024243069065
INFO:root:current train perplexity4.0237250328063965
INFO:root:current mean train loss 3530.9885567841384
INFO:root:current train perplexity4.02585506439209
INFO:root:current mean train loss 3532.05920322155
INFO:root:current train perplexity4.02747917175293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.23s/it]
INFO:root:final mean train loss: 3531.351468240061
INFO:root:final train perplexity: 4.0278000831604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 4017.0579998476287
INFO:root:eval perplexity: 5.075273036956787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it]
INFO:root:eval mean loss: 4977.679226922651
INFO:root:eval perplexity: 7.655630588531494
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [9:53:59<13:22:58, 418.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.206215387658
INFO:root:current train perplexity3.996256113052368
INFO:root:current mean train loss 3498.204371617493
INFO:root:current train perplexity3.9943673610687256
INFO:root:current mean train loss 3514.0579059559814
INFO:root:current train perplexity4.005372524261475
INFO:root:current mean train loss 3516.48463782157
INFO:root:current train perplexity4.0052876472473145
INFO:root:current mean train loss 3517.8440022956356
INFO:root:current train perplexity4.006521701812744
INFO:root:current mean train loss 3520.647202038806
INFO:root:current train perplexity4.007943630218506
INFO:root:current mean train loss 3520.016171529823
INFO:root:current train perplexity4.0108208656311035
INFO:root:current mean train loss 3521.469957226813
INFO:root:current train perplexity4.011760234832764
INFO:root:current mean train loss 3526.069005694948
INFO:root:current train perplexity4.016570091247559
INFO:root:current mean train loss 3527.986271765673
INFO:root:current train perplexity4.018749237060547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it]
INFO:root:final mean train loss: 3525.4710160532304
INFO:root:final train perplexity: 4.018466472625732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 4016.2030124529033
INFO:root:eval perplexity: 5.073517799377441
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 4977.971158507868
INFO:root:eval perplexity: 7.656545162200928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [10:00:58<13:16:33, 419.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3510.187109936243
INFO:root:current train perplexity3.9848320484161377
INFO:root:current mean train loss 3507.546540775401
INFO:root:current train perplexity3.9889841079711914
INFO:root:current mean train loss 3512.1260446156357
INFO:root:current train perplexity3.9901230335235596
INFO:root:current mean train loss 3514.9993413880816
INFO:root:current train perplexity3.9943888187408447
INFO:root:current mean train loss 3517.9243304430825
INFO:root:current train perplexity3.9987151622772217
INFO:root:current mean train loss 3519.3208531862224
INFO:root:current train perplexity4.00272798538208
INFO:root:current mean train loss 3519.9880786879094
INFO:root:current train perplexity4.0060272216796875
INFO:root:current mean train loss 3522.6203473683686
INFO:root:current train perplexity4.009452819824219
INFO:root:current mean train loss 3522.902350080591
INFO:root:current train perplexity4.00999641418457
INFO:root:current mean train loss 3523.073972630525
INFO:root:current train perplexity4.010562896728516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.36s/it]
INFO:root:final mean train loss: 3520.3452798781855
INFO:root:final train perplexity: 4.010348320007324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 4020.7880478446364
INFO:root:eval perplexity: 5.082934379577637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it]
INFO:root:eval mean loss: 4982.347140264849
INFO:root:eval perplexity: 7.670257568359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [10:07:58<13:09:39, 419.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3528.3297800164473
INFO:root:current train perplexity4.002419948577881
INFO:root:current mean train loss 3518.7988869691508
INFO:root:current train perplexity3.9895689487457275
INFO:root:current mean train loss 3516.0667761851164
INFO:root:current train perplexity3.9914281368255615
INFO:root:current mean train loss 3514.962200850475
INFO:root:current train perplexity3.9928791522979736
INFO:root:current mean train loss 3517.150575580019
INFO:root:current train perplexity3.9935989379882812
INFO:root:current mean train loss 3514.7734633501836
INFO:root:current train perplexity3.9931883811950684
INFO:root:current mean train loss 3517.8049966276976
INFO:root:current train perplexity3.9979166984558105
INFO:root:current mean train loss 3517.7364190251574
INFO:root:current train perplexity3.9985926151275635
INFO:root:current mean train loss 3517.7959821818263
INFO:root:current train perplexity4.000535488128662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.43s/it]
INFO:root:final mean train loss: 3514.578696712371
INFO:root:final train perplexity: 4.001235008239746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 4019.2498545545213
INFO:root:eval perplexity: 5.079773426055908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it]
INFO:root:eval mean loss: 4983.683084690824
INFO:root:eval perplexity: 7.674448013305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:14:57<13:02:33, 419.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.408203125
INFO:root:current train perplexity4.051741600036621
INFO:root:current mean train loss 3475.6931910838894
INFO:root:current train perplexity3.945103406906128
INFO:root:current mean train loss 3483.6277444773705
INFO:root:current train perplexity3.9617104530334473
INFO:root:current mean train loss 3497.771910613913
INFO:root:current train perplexity3.9810712337493896
INFO:root:current mean train loss 3496.3651186656716
INFO:root:current train perplexity3.982332229614258
INFO:root:current mean train loss 3506.8610466109594
INFO:root:current train perplexity3.9913063049316406
INFO:root:current mean train loss 3508.089381380856
INFO:root:current train perplexity3.9906058311462402
INFO:root:current mean train loss 3509.65890706959
INFO:root:current train perplexity3.9896750450134277
INFO:root:current mean train loss 3509.87536393067
INFO:root:current train perplexity3.990311861038208
INFO:root:current mean train loss 3510.553103695148
INFO:root:current train perplexity3.9919352531433105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.30s/it]
INFO:root:final mean train loss: 3509.5721543835057
INFO:root:final train perplexity: 3.9933388233184814
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it]
INFO:root:eval mean loss: 4021.441574204898
INFO:root:eval perplexity: 5.084277153015137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 4986.506579676418
INFO:root:eval perplexity: 7.683316707611084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:21:51<12:52:49, 417.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.241122159091
INFO:root:current train perplexity4.069814682006836
INFO:root:current mean train loss 3509.0345338013794
INFO:root:current train perplexity3.9715898036956787
INFO:root:current mean train loss 3495.31324630665
INFO:root:current train perplexity3.9611990451812744
INFO:root:current mean train loss 3490.581189710611
INFO:root:current train perplexity3.957606554031372
INFO:root:current mean train loss 3499.2733341411954
INFO:root:current train perplexity3.969431161880493
INFO:root:current mean train loss 3503.0496513232324
INFO:root:current train perplexity3.9729857444763184
INFO:root:current mean train loss 3506.182336685505
INFO:root:current train perplexity3.976923942565918
INFO:root:current mean train loss 3506.270395528415
INFO:root:current train perplexity3.978508710861206
INFO:root:current mean train loss 3505.2271200196515
INFO:root:current train perplexity3.978756904602051
INFO:root:current mean train loss 3508.2435923135636
INFO:root:current train perplexity3.9839632511138916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.53s/it]
INFO:root:final mean train loss: 3504.947392555975
INFO:root:final train perplexity: 3.9860596656799316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 4019.9779061391846
INFO:root:eval perplexity: 5.081268787384033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4985.35217371731
INFO:root:eval perplexity: 7.679688453674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:28:52<12:47:24, 418.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.6131399054275
INFO:root:current train perplexity4.022923469543457
INFO:root:current mean train loss 3490.188213957458
INFO:root:current train perplexity3.959059476852417
INFO:root:current mean train loss 3483.5282768354023
INFO:root:current train perplexity3.9471962451934814
INFO:root:current mean train loss 3486.0137438161246
INFO:root:current train perplexity3.9506261348724365
INFO:root:current mean train loss 3489.2129634593152
INFO:root:current train perplexity3.960386276245117
INFO:root:current mean train loss 3491.487849887855
INFO:root:current train perplexity3.96623158454895
INFO:root:current mean train loss 3495.931075433537
INFO:root:current train perplexity3.970975875854492
INFO:root:current mean train loss 3500.7139469831145
INFO:root:current train perplexity3.9762303829193115
INFO:root:current mean train loss 3501.6887397812693
INFO:root:current train perplexity3.9779505729675293
INFO:root:current mean train loss 3501.402455061123
INFO:root:current train perplexity3.976167917251587

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.90s/it]
INFO:root:final mean train loss: 3499.0524619317825
INFO:root:final train perplexity: 3.976799726486206
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.70s/it]
INFO:root:eval mean loss: 4022.5046178939497
INFO:root:eval perplexity: 5.086463928222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 4991.23706747285
INFO:root:eval perplexity: 7.698190689086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:35:50<12:40:00, 418.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.691062644676
INFO:root:current train perplexity3.9465408325195312
INFO:root:current mean train loss 3495.4371712752213
INFO:root:current train perplexity3.952742099761963
INFO:root:current mean train loss 3500.167790215446
INFO:root:current train perplexity3.9668827056884766
INFO:root:current mean train loss 3506.2390435361717
INFO:root:current train perplexity3.966691255569458
INFO:root:current mean train loss 3503.378148670777
INFO:root:current train perplexity3.965895414352417
INFO:root:current mean train loss 3501.6314903418524
INFO:root:current train perplexity3.965482711791992
INFO:root:current mean train loss 3501.1855044326903
INFO:root:current train perplexity3.964778423309326
INFO:root:current mean train loss 3499.1895092068216
INFO:root:current train perplexity3.9661664962768555
INFO:root:current mean train loss 3497.393826578087
INFO:root:current train perplexity3.9682071208953857
INFO:root:current mean train loss 3496.8858833518743
INFO:root:current train perplexity3.9674134254455566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.49s/it]
INFO:root:final mean train loss: 3493.481441067111
INFO:root:final train perplexity: 3.968069076538086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.77s/it]
INFO:root:eval mean loss: 4024.982749127327
INFO:root:eval perplexity: 5.091562747955322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 4993.88927443484
INFO:root:eval perplexity: 7.706544399261475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:42:46<12:31:54, 417.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.094398716518
INFO:root:current train perplexity3.9491922855377197
INFO:root:current mean train loss 3489.211181640625
INFO:root:current train perplexity3.930394172668457
INFO:root:current mean train loss 3483.0646577875664
INFO:root:current train perplexity3.937147378921509
INFO:root:current mean train loss 3486.013725075793
INFO:root:current train perplexity3.9455182552337646
INFO:root:current mean train loss 3491.408520788434
INFO:root:current train perplexity3.9500463008880615
INFO:root:current mean train loss 3488.0005006023657
INFO:root:current train perplexity3.953087568283081
INFO:root:current mean train loss 3485.712675704355
INFO:root:current train perplexity3.9537577629089355
INFO:root:current mean train loss 3486.4842122395835
INFO:root:current train perplexity3.953683853149414
INFO:root:current mean train loss 3487.064344358159
INFO:root:current train perplexity3.9553463459014893
INFO:root:current mean train loss 3489.6871634253844
INFO:root:current train perplexity3.9587669372558594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.11s/it]
INFO:root:final mean train loss: 3488.9324297135877
INFO:root:final train perplexity: 3.9609534740448
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 4024.692557693373
INFO:root:eval perplexity: 5.09096622467041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 4994.056806848404
INFO:root:eval perplexity: 7.707071781158447
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:49:45<12:25:35, 418.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3437.346810274346
INFO:root:current train perplexity3.8678698539733887
INFO:root:current mean train loss 3469.0300378332604
INFO:root:current train perplexity3.923022985458374
INFO:root:current mean train loss 3478.8716011204347
INFO:root:current train perplexity3.9338595867156982
INFO:root:current mean train loss 3479.494982661033
INFO:root:current train perplexity3.9321272373199463
INFO:root:current mean train loss 3481.2064735292042
INFO:root:current train perplexity3.93556547164917
INFO:root:current mean train loss 3481.517794839146
INFO:root:current train perplexity3.9396541118621826
INFO:root:current mean train loss 3484.318929669275
INFO:root:current train perplexity3.944349527359009
INFO:root:current mean train loss 3488.061950601447
INFO:root:current train perplexity3.9465839862823486
INFO:root:current mean train loss 3485.2577635560315
INFO:root:current train perplexity3.946019172668457
INFO:root:current mean train loss 3486.9062753719845
INFO:root:current train perplexity3.9508607387542725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.25s/it]
INFO:root:final mean train loss: 3482.597127668319
INFO:root:final train perplexity: 3.9510655403137207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 4024.724204205452
INFO:root:eval perplexity: 5.091030120849609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 4996.779205105829
INFO:root:eval perplexity: 7.715657711029053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [10:56:44<12:19:14, 418.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3470.0763777190564
INFO:root:current train perplexity3.9358527660369873
INFO:root:current mean train loss 3465.371313638245
INFO:root:current train perplexity3.9340481758117676
INFO:root:current mean train loss 3466.454163813496
INFO:root:current train perplexity3.929494619369507
INFO:root:current mean train loss 3473.2056763043092
INFO:root:current train perplexity3.9340641498565674
INFO:root:current mean train loss 3474.792523775291
INFO:root:current train perplexity3.9362070560455322
INFO:root:current mean train loss 3472.3920721202926
INFO:root:current train perplexity3.9330806732177734
INFO:root:current mean train loss 3477.1549077890986
INFO:root:current train perplexity3.9386041164398193
INFO:root:current mean train loss 3477.6269612521846
INFO:root:current train perplexity3.9388694763183594
INFO:root:current mean train loss 3478.1327244257673
INFO:root:current train perplexity3.942042827606201
INFO:root:current mean train loss 3481.4401532001675
INFO:root:current train perplexity3.944594621658325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it]
INFO:root:final mean train loss: 3479.765315271193
INFO:root:final train perplexity: 3.9466540813446045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 4026.7850419714096
INFO:root:eval perplexity: 5.095274925231934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 4997.365597988697
INFO:root:eval perplexity: 7.717508792877197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [11:03:45<12:13:33, 419.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.497169623941
INFO:root:current train perplexity3.895764112472534
INFO:root:current mean train loss 3455.3793883893477
INFO:root:current train perplexity3.912363052368164
INFO:root:current mean train loss 3453.5057830221403
INFO:root:current train perplexity3.915173292160034
INFO:root:current mean train loss 3463.782884858113
INFO:root:current train perplexity3.922370672225952
INFO:root:current mean train loss 3464.320260374115
INFO:root:current train perplexity3.9240095615386963
INFO:root:current mean train loss 3474.4025874538797
INFO:root:current train perplexity3.9324276447296143
INFO:root:current mean train loss 3475.461083095244
INFO:root:current train perplexity3.9356603622436523
INFO:root:current mean train loss 3473.102334807827
INFO:root:current train perplexity3.9342737197875977
INFO:root:current mean train loss 3475.235119358902
INFO:root:current train perplexity3.9381463527679443
INFO:root:current mean train loss 3476.0666167862846
INFO:root:current train perplexity3.938192844390869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.76s/it]
INFO:root:final mean train loss: 3474.2719533981817
INFO:root:final train perplexity: 3.9381091594696045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 4026.5453911098184
INFO:root:eval perplexity: 5.094780921936035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it]
INFO:root:eval mean loss: 4997.815872949911
INFO:root:eval perplexity: 7.718927383422852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:10:45<12:06:57, 419.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3454.563341738573
INFO:root:current train perplexity3.92507004737854
INFO:root:current mean train loss 3470.4826075388287
INFO:root:current train perplexity3.921926498413086
INFO:root:current mean train loss 3464.4116494396653
INFO:root:current train perplexity3.9182815551757812
INFO:root:current mean train loss 3469.89326131961
INFO:root:current train perplexity3.927424669265747
INFO:root:current mean train loss 3465.5984655212796
INFO:root:current train perplexity3.924031972885132
INFO:root:current mean train loss 3468.156802438134
INFO:root:current train perplexity3.9272327423095703
INFO:root:current mean train loss 3469.752436647887
INFO:root:current train perplexity3.92848539352417
INFO:root:current mean train loss 3470.9506934612327
INFO:root:current train perplexity3.9306042194366455
INFO:root:current mean train loss 3468.103631359483
INFO:root:current train perplexity3.9280765056610107
INFO:root:current mean train loss 3470.317568379573
INFO:root:current train perplexity3.9292280673980713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.40s/it]
INFO:root:final mean train loss: 3468.7724257438413
INFO:root:final train perplexity: 3.9295737743377686
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4028.788615774601
INFO:root:eval perplexity: 5.099405765533447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 5002.532058607602
INFO:root:eval perplexity: 7.733828067779541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:17:47<12:01:25, 420.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.3512565104165
INFO:root:current train perplexity3.8903403282165527
INFO:root:current mean train loss 3441.913076171875
INFO:root:current train perplexity3.886928081512451
INFO:root:current mean train loss 3454.225384410511
INFO:root:current train perplexity3.8953945636749268
INFO:root:current mean train loss 3461.9199765625
INFO:root:current train perplexity3.908153533935547
INFO:root:current mean train loss 3461.62646484375
INFO:root:current train perplexity3.908662796020508
INFO:root:current mean train loss 3463.5948378057064
INFO:root:current train perplexity3.912855625152588
INFO:root:current mean train loss 3466.873484519676
INFO:root:current train perplexity3.9152114391326904
INFO:root:current mean train loss 3466.4214657888106
INFO:root:current train perplexity3.917567729949951
INFO:root:current mean train loss 3465.220336495536
INFO:root:current train perplexity3.919826030731201
INFO:root:current mean train loss 3466.1994060496795
INFO:root:current train perplexity3.922173261642456

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.68s/it]
INFO:root:final mean train loss: 3463.9267349858437
INFO:root:final train perplexity: 3.9220690727233887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 4028.832493558843
INFO:root:eval perplexity: 5.0994954109191895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 5003.510269489694
INFO:root:eval perplexity: 7.736924648284912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:24:44<11:52:54, 419.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3452.7390725009413
INFO:root:current train perplexity3.8974921703338623
INFO:root:current mean train loss 3450.3775948279545
INFO:root:current train perplexity3.899686813354492
INFO:root:current mean train loss 3458.123506687555
INFO:root:current train perplexity3.9065120220184326
INFO:root:current mean train loss 3456.200933471361
INFO:root:current train perplexity3.9052083492279053
INFO:root:current mean train loss 3459.2400953715387
INFO:root:current train perplexity3.9063479900360107
INFO:root:current mean train loss 3455.2411296968803
INFO:root:current train perplexity3.9045491218566895
INFO:root:current mean train loss 3459.049438655289
INFO:root:current train perplexity3.907658338546753
INFO:root:current mean train loss 3462.4288637202667
INFO:root:current train perplexity3.9110300540924072
INFO:root:current mean train loss 3461.7318984795265
INFO:root:current train perplexity3.9134411811828613
INFO:root:current mean train loss 3462.66375030797
INFO:root:current train perplexity3.9151554107666016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.09s/it]
INFO:root:final mean train loss: 3459.3268471379433
INFO:root:final train perplexity: 3.9149580001831055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it]
INFO:root:eval mean loss: 4029.908478432513
INFO:root:eval perplexity: 5.101714134216309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 5006.907538231383
INFO:root:eval perplexity: 7.747679233551025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:31:43<11:45:38, 419.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3428.365051940247
INFO:root:current train perplexity3.886199474334717
INFO:root:current mean train loss 3429.5141166966623
INFO:root:current train perplexity3.891876220703125
INFO:root:current mean train loss 3433.6771445782324
INFO:root:current train perplexity3.891187906265259
INFO:root:current mean train loss 3434.788731567695
INFO:root:current train perplexity3.887000322341919
INFO:root:current mean train loss 3438.4910836462577
INFO:root:current train perplexity3.8915793895721436
INFO:root:current mean train loss 3442.7950821568315
INFO:root:current train perplexity3.8938968181610107
INFO:root:current mean train loss 3446.9562712695597
INFO:root:current train perplexity3.8989601135253906
INFO:root:current mean train loss 3449.4690521664625
INFO:root:current train perplexity3.9000303745269775
INFO:root:current mean train loss 3451.8497165119074
INFO:root:current train perplexity3.903064250946045
INFO:root:current mean train loss 3456.7516202955508
INFO:root:current train perplexity3.9069535732269287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.90s/it]
INFO:root:final mean train loss: 3454.222257675663
INFO:root:final train perplexity: 3.907081127166748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it]
INFO:root:eval mean loss: 4035.255052498892
INFO:root:eval perplexity: 5.112756729125977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it]
INFO:root:eval mean loss: 5013.371658216977
INFO:root:eval perplexity: 7.768186092376709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:38:42<11:38:17, 418.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3444.7532256155305
INFO:root:current train perplexity3.8696413040161133
INFO:root:current mean train loss 3452.04184619386
INFO:root:current train perplexity3.8778579235076904
INFO:root:current mean train loss 3443.3668290460387
INFO:root:current train perplexity3.8836536407470703
INFO:root:current mean train loss 3449.3565089481517
INFO:root:current train perplexity3.8887147903442383
INFO:root:current mean train loss 3449.2102168203596
INFO:root:current train perplexity3.8958537578582764
INFO:root:current mean train loss 3451.5544784112844
INFO:root:current train perplexity3.8983964920043945
INFO:root:current mean train loss 3447.941153377593
INFO:root:current train perplexity3.8958144187927246
INFO:root:current mean train loss 3450.257138439651
INFO:root:current train perplexity3.8986756801605225
INFO:root:current mean train loss 3452.1045397120934
INFO:root:current train perplexity3.8993399143218994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.76s/it]
INFO:root:final mean train loss: 3449.5553403054514
INFO:root:final train perplexity: 3.8998939990997314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 4038.9926723182625
INFO:root:eval perplexity: 5.120489120483398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.70s/it]
INFO:root:eval mean loss: 5015.675301626219
INFO:root:eval perplexity: 7.775505065917969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:45:40<11:30:45, 418.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3512.3793596540177
INFO:root:current train perplexity3.891633987426758
INFO:root:current mean train loss 3440.6587918005257
INFO:root:current train perplexity3.8623228073120117
INFO:root:current mean train loss 3438.6398182744565
INFO:root:current train perplexity3.8849575519561768
INFO:root:current mean train loss 3440.4686569561786
INFO:root:current train perplexity3.8838870525360107
INFO:root:current mean train loss 3440.7196821732955
INFO:root:current train perplexity3.8797495365142822
INFO:root:current mean train loss 3439.968612761187
INFO:root:current train perplexity3.8822076320648193
INFO:root:current mean train loss 3440.846059884035
INFO:root:current train perplexity3.8856797218322754
INFO:root:current mean train loss 3441.826279959888
INFO:root:current train perplexity3.8891565799713135
INFO:root:current mean train loss 3442.857250643781
INFO:root:current train perplexity3.8918566703796387
INFO:root:current mean train loss 3445.6675757562707
INFO:root:current train perplexity3.8911614418029785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.15s/it]
INFO:root:final mean train loss: 3444.7529795862015
INFO:root:final train perplexity: 3.8925118446350098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it]
INFO:root:eval mean loss: 4034.0270857574246
INFO:root:eval perplexity: 5.110218524932861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it]
INFO:root:eval mean loss: 5013.58251953125
INFO:root:eval perplexity: 7.76885461807251
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:52:38<11:23:46, 418.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3430.880712890625
INFO:root:current train perplexity3.875410318374634
INFO:root:current mean train loss 3425.5673679517663
INFO:root:current train perplexity3.8718507289886475
INFO:root:current mean train loss 3435.1414743822675
INFO:root:current train perplexity3.8753771781921387
INFO:root:current mean train loss 3432.8530079675097
INFO:root:current train perplexity3.8779678344726562
INFO:root:current mean train loss 3442.1773619870105
INFO:root:current train perplexity3.8828930854797363
INFO:root:current mean train loss 3447.1899451987256
INFO:root:current train perplexity3.8855600357055664
INFO:root:current mean train loss 3446.268595179116
INFO:root:current train perplexity3.882108449935913
INFO:root:current mean train loss 3443.683973789882
INFO:root:current train perplexity3.884082317352295
INFO:root:current mean train loss 3443.9365162480826
INFO:root:current train perplexity3.884514808654785
INFO:root:current mean train loss 3443.0627836300378
INFO:root:current train perplexity3.8851048946380615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it]
INFO:root:final mean train loss: 3440.9507561345254
INFO:root:final train perplexity: 3.8866770267486572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it]
INFO:root:eval mean loss: 4035.9433888103945
INFO:root:eval perplexity: 5.114179611206055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it]
INFO:root:eval mean loss: 5017.154714165004
INFO:root:eval perplexity: 7.780211448669434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [11:59:38<11:17:10, 418.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3447.6421747622285
INFO:root:current train perplexity3.856593370437622
INFO:root:current mean train loss 3431.542109295605
INFO:root:current train perplexity3.8527629375457764
INFO:root:current mean train loss 3432.721913974916
INFO:root:current train perplexity3.858149528503418
INFO:root:current mean train loss 3432.55520299197
INFO:root:current train perplexity3.8665809631347656
INFO:root:current mean train loss 3427.2053822907433
INFO:root:current train perplexity3.866157293319702
INFO:root:current mean train loss 3431.636992299534
INFO:root:current train perplexity3.8712737560272217
INFO:root:current mean train loss 3433.2915466210625
INFO:root:current train perplexity3.8727331161499023
INFO:root:current mean train loss 3434.203400882283
INFO:root:current train perplexity3.873804807662964
INFO:root:current mean train loss 3435.8830020575447
INFO:root:current train perplexity3.877181053161621
INFO:root:current mean train loss 3438.1007464936856
INFO:root:current train perplexity3.8787682056427

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.40s/it]
INFO:root:final mean train loss: 3437.046654301305
INFO:root:final train perplexity: 3.8806958198547363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 4036.7646484375
INFO:root:eval perplexity: 5.115879058837891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it]
INFO:root:eval mean loss: 5018.673069730718
INFO:root:eval perplexity: 7.785043239593506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:06:37<11:10:15, 418.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3366.6176836567543
INFO:root:current train perplexity3.84605073928833
INFO:root:current mean train loss 3417.4103966632874
INFO:root:current train perplexity3.848677396774292
INFO:root:current mean train loss 3417.825284090909
INFO:root:current train perplexity3.858457565307617
INFO:root:current mean train loss 3421.352948422158
INFO:root:current train perplexity3.863278388977051
INFO:root:current mean train loss 3424.10341083146
INFO:root:current train perplexity3.8637588024139404
INFO:root:current mean train loss 3430.952803157368
INFO:root:current train perplexity3.870776653289795
INFO:root:current mean train loss 3432.7885916297296
INFO:root:current train perplexity3.8728325366973877
INFO:root:current mean train loss 3435.1216712043647
INFO:root:current train perplexity3.8713765144348145
INFO:root:current mean train loss 3437.322545608172
INFO:root:current train perplexity3.8711254596710205
INFO:root:current mean train loss 3433.644146813742
INFO:root:current train perplexity3.87217378616333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.96s/it]
INFO:root:final mean train loss: 3432.2331373153193
INFO:root:final train perplexity: 3.8733325004577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 4041.485687472296
INFO:root:eval perplexity: 5.125654697418213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 5024.335598127216
INFO:root:eval perplexity: 7.803090572357178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:13:31<11:01:10, 417.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3401.41302333734
INFO:root:current train perplexity3.8244993686676025
INFO:root:current mean train loss 3404.4121480159624
INFO:root:current train perplexity3.8408801555633545
INFO:root:current mean train loss 3408.119028259022
INFO:root:current train perplexity3.8568670749664307
INFO:root:current mean train loss 3411.9744048442108
INFO:root:current train perplexity3.857727289199829
INFO:root:current mean train loss 3420.4320338081934
INFO:root:current train perplexity3.8606066703796387
INFO:root:current mean train loss 3421.0908547367812
INFO:root:current train perplexity3.860124111175537
INFO:root:current mean train loss 3422.9702614558882
INFO:root:current train perplexity3.8599119186401367
INFO:root:current mean train loss 3426.371604496152
INFO:root:current train perplexity3.8650546073913574
INFO:root:current mean train loss 3426.5693970454035
INFO:root:current train perplexity3.8635478019714355
INFO:root:current mean train loss 3428.803497996955
INFO:root:current train perplexity3.865058660507202

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.91s/it]
INFO:root:final mean train loss: 3428.478410659298
INFO:root:final train perplexity: 3.8675992488861084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 4037.2797609153367
INFO:root:eval perplexity: 5.116943836212158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it]
INFO:root:eval mean loss: 5022.261898825354
INFO:root:eval perplexity: 7.796475887298584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_corrected/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:20:31<10:55:31, 418.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][Aslurmstepd: error: *** JOB 26219465 ON gv008 CANCELLED AT 2022-10-24T11:45:52 ***
